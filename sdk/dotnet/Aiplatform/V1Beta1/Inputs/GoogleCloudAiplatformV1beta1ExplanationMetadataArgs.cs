// *** WARNING: this file was generated by the Pulumi SDK Generator. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

using System;
using System.Collections.Generic;
using System.Collections.Immutable;
using System.Threading.Tasks;
using Pulumi.Serialization;

namespace Pulumi.GoogleNative.Aiplatform.V1Beta1.Inputs
{

    /// <summary>
    /// Metadata describing the Model's input and output for explanation.
    /// </summary>
    public sealed class GoogleCloudAiplatformV1beta1ExplanationMetadataArgs : global::Pulumi.ResourceArgs
    {
        /// <summary>
        /// Points to a YAML file stored on Google Cloud Storage describing the format of the feature attributions. The schema is defined as an OpenAPI 3.0.2 [Schema Object](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject). AutoML tabular Models always have this field populated by Vertex AI. Note: The URI given on output may be different, including the URI scheme, than the one given on input. The output URI will point to a location where the user only has a read access.
        /// </summary>
        [Input("featureAttributionsSchemaUri")]
        public Input<string>? FeatureAttributionsSchemaUri { get; set; }

        [Input("inputs", required: true)]
        private InputMap<Inputs.GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataArgs>? _inputs;

        /// <summary>
        /// Map from feature names to feature input metadata. Keys are the name of the features. Values are the specification of the feature. An empty InputMetadata is valid. It describes a text feature which has the name specified as the key in ExplanationMetadata.inputs. The baseline of the empty feature is chosen by Vertex AI. For Vertex AI-provided Tensorflow images, the key can be any friendly name of the feature. Once specified, featureAttributions are keyed by this key (if not grouped with another feature). For custom images, the key must match with the key in instance.
        /// </summary>
        public InputMap<Inputs.GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataArgs> Inputs
        {
            get => _inputs ?? (_inputs = new InputMap<Inputs.GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataArgs>());
            set => _inputs = value;
        }

        /// <summary>
        /// Name of the source to generate embeddings for example based explanations.
        /// </summary>
        [Input("latentSpaceSource")]
        public Input<string>? LatentSpaceSource { get; set; }

        [Input("outputs", required: true)]
        private InputMap<Inputs.GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataArgs>? _outputs;

        /// <summary>
        /// Map from output names to output metadata. For Vertex AI-provided Tensorflow images, keys can be any user defined string that consists of any UTF-8 characters. For custom images, keys are the name of the output field in the prediction to be explained. Currently only one key is allowed.
        /// </summary>
        public InputMap<Inputs.GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataArgs> Outputs
        {
            get => _outputs ?? (_outputs = new InputMap<Inputs.GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataArgs>());
            set => _outputs = value;
        }

        public GoogleCloudAiplatformV1beta1ExplanationMetadataArgs()
        {
        }
        public static new GoogleCloudAiplatformV1beta1ExplanationMetadataArgs Empty => new GoogleCloudAiplatformV1beta1ExplanationMetadataArgs();
    }
}

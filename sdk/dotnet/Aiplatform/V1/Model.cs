// *** WARNING: this file was generated by the Pulumi SDK Generator. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

using System;
using System.Collections.Generic;
using System.Collections.Immutable;
using System.Threading.Tasks;
using Pulumi.Serialization;

namespace Pulumi.GoogleNative.Aiplatform.V1
{
    /// <summary>
    /// Uploads a Model artifact into Vertex AI.
    /// </summary>
    [GoogleNativeResourceType("google-native:aiplatform/v1:Model")]
    public partial class Model : global::Pulumi.CustomResource
    {
        /// <summary>
        /// Immutable. The path to the directory containing the Model artifact and any of its supporting files. Not present for AutoML Models or Large Models.
        /// </summary>
        [Output("artifactUri")]
        public Output<string> ArtifactUri { get; private set; } = null!;

        /// <summary>
        /// Input only. The specification of the container that is to be used when deploying this Model. The specification is ingested upon ModelService.UploadModel, and all binaries it contains are copied and stored internally by Vertex AI. Not present for AutoML Models or Large Models.
        /// </summary>
        [Output("containerSpec")]
        public Output<Outputs.GoogleCloudAiplatformV1ModelContainerSpecResponse> ContainerSpec { get; private set; } = null!;

        /// <summary>
        /// Timestamp when this Model was uploaded into Vertex AI.
        /// </summary>
        [Output("createTime")]
        public Output<string> CreateTime { get; private set; } = null!;

        /// <summary>
        /// The pointers to DeployedModels created from this Model. Note that Model could have been deployed to Endpoints in different Locations.
        /// </summary>
        [Output("deployedModels")]
        public Output<ImmutableArray<Outputs.GoogleCloudAiplatformV1DeployedModelRefResponse>> DeployedModels { get; private set; } = null!;

        /// <summary>
        /// The description of the Model.
        /// </summary>
        [Output("description")]
        public Output<string> Description { get; private set; } = null!;

        /// <summary>
        /// The display name of the Model. The name can be up to 128 characters long and can consist of any UTF-8 characters.
        /// </summary>
        [Output("displayName")]
        public Output<string> DisplayName { get; private set; } = null!;

        /// <summary>
        /// Customer-managed encryption key spec for a Model. If set, this Model and all sub-resources of this Model will be secured by this key.
        /// </summary>
        [Output("encryptionSpec")]
        public Output<Outputs.GoogleCloudAiplatformV1EncryptionSpecResponse> EncryptionSpec { get; private set; } = null!;

        /// <summary>
        /// Used to perform consistent read-modify-write updates. If not set, a blind "overwrite" update happens.
        /// </summary>
        [Output("etag")]
        public Output<string> Etag { get; private set; } = null!;

        /// <summary>
        /// The default explanation specification for this Model. The Model can be used for requesting explanation after being deployed if it is populated. The Model can be used for batch explanation if it is populated. All fields of the explanation_spec can be overridden by explanation_spec of DeployModelRequest.deployed_model, or explanation_spec of BatchPredictionJob. If the default explanation specification is not set for this Model, this Model can still be used for requesting explanation by setting explanation_spec of DeployModelRequest.deployed_model and for batch explanation by setting explanation_spec of BatchPredictionJob.
        /// </summary>
        [Output("explanationSpec")]
        public Output<Outputs.GoogleCloudAiplatformV1ExplanationSpecResponse> ExplanationSpec { get; private set; } = null!;

        /// <summary>
        /// The labels with user-defined metadata to organize your Models. Label keys and values can be no longer than 64 characters (Unicode codepoints), can only contain lowercase letters, numeric characters, underscores and dashes. International characters are allowed. See https://goo.gl/xmQnxf for more information and examples of labels.
        /// </summary>
        [Output("labels")]
        public Output<ImmutableDictionary<string, string>> Labels { get; private set; } = null!;

        [Output("location")]
        public Output<string> Location { get; private set; } = null!;

        /// <summary>
        /// Immutable. An additional information about the Model; the schema of the metadata can be found in metadata_schema. Unset if the Model does not have any additional information.
        /// </summary>
        [Output("metadata")]
        public Output<object> Metadata { get; private set; } = null!;

        /// <summary>
        /// The resource name of the Artifact that was created in MetadataStore when creating the Model. The Artifact resource name pattern is `projects/{project}/locations/{location}/metadataStores/{metadata_store}/artifacts/{artifact}`.
        /// </summary>
        [Output("metadataArtifact")]
        public Output<string> MetadataArtifact { get; private set; } = null!;

        /// <summary>
        /// Immutable. Points to a YAML file stored on Google Cloud Storage describing additional information about the Model, that is specific to it. Unset if the Model does not have any additional information. The schema is defined as an OpenAPI 3.0.2 [Schema Object](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject). AutoML Models always have this field populated by Vertex AI, if no additional metadata is needed, this field is set to an empty string. Note: The URI given on output will be immutable and probably different, including the URI scheme, than the one given on input. The output URI will point to a location where the user only has a read access.
        /// </summary>
        [Output("metadataSchemaUri")]
        public Output<string> MetadataSchemaUri { get; private set; } = null!;

        /// <summary>
        /// Source of a model. It can either be automl training pipeline, custom training pipeline, BigQuery ML, or existing Vertex AI Model.
        /// </summary>
        [Output("modelSourceInfo")]
        public Output<Outputs.GoogleCloudAiplatformV1ModelSourceInfoResponse> ModelSourceInfo { get; private set; } = null!;

        /// <summary>
        /// The resource name of the Model.
        /// </summary>
        [Output("name")]
        public Output<string> Name { get; private set; } = null!;

        /// <summary>
        /// If this Model is a copy of another Model, this contains info about the original.
        /// </summary>
        [Output("originalModelInfo")]
        public Output<Outputs.GoogleCloudAiplatformV1ModelOriginalModelInfoResponse> OriginalModelInfo { get; private set; } = null!;

        /// <summary>
        /// Optional. This field is populated if the model is produced by a pipeline job.
        /// </summary>
        [Output("pipelineJob")]
        public Output<string> PipelineJob { get; private set; } = null!;

        /// <summary>
        /// The schemata that describe formats of the Model's predictions and explanations as given and returned via PredictionService.Predict and PredictionService.Explain.
        /// </summary>
        [Output("predictSchemata")]
        public Output<Outputs.GoogleCloudAiplatformV1PredictSchemataResponse> PredictSchemata { get; private set; } = null!;

        [Output("project")]
        public Output<string> Project { get; private set; } = null!;

        /// <summary>
        /// When this Model is deployed, its prediction resources are described by the `prediction_resources` field of the Endpoint.deployed_models object. Because not all Models support all resource configuration types, the configuration types this Model supports are listed here. If no configuration types are listed, the Model cannot be deployed to an Endpoint and does not support online predictions (PredictionService.Predict or PredictionService.Explain). Such a Model can serve predictions by using a BatchPredictionJob, if it has at least one entry each in supported_input_storage_formats and supported_output_storage_formats.
        /// </summary>
        [Output("supportedDeploymentResourcesTypes")]
        public Output<ImmutableArray<string>> SupportedDeploymentResourcesTypes { get; private set; } = null!;

        /// <summary>
        /// The formats in which this Model may be exported. If empty, this Model is not available for export.
        /// </summary>
        [Output("supportedExportFormats")]
        public Output<ImmutableArray<Outputs.GoogleCloudAiplatformV1ModelExportFormatResponse>> SupportedExportFormats { get; private set; } = null!;

        /// <summary>
        /// The formats this Model supports in BatchPredictionJob.input_config. If PredictSchemata.instance_schema_uri exists, the instances should be given as per that schema. The possible formats are: * `jsonl` The JSON Lines format, where each instance is a single line. Uses GcsSource. * `csv` The CSV format, where each instance is a single comma-separated line. The first line in the file is the header, containing comma-separated field names. Uses GcsSource. * `tf-record` The TFRecord format, where each instance is a single record in tfrecord syntax. Uses GcsSource. * `tf-record-gzip` Similar to `tf-record`, but the file is gzipped. Uses GcsSource. * `bigquery` Each instance is a single row in BigQuery. Uses BigQuerySource. * `file-list` Each line of the file is the location of an instance to process, uses `gcs_source` field of the InputConfig object. If this Model doesn't support any of these formats it means it cannot be used with a BatchPredictionJob. However, if it has supported_deployment_resources_types, it could serve online predictions by using PredictionService.Predict or PredictionService.Explain.
        /// </summary>
        [Output("supportedInputStorageFormats")]
        public Output<ImmutableArray<string>> SupportedInputStorageFormats { get; private set; } = null!;

        /// <summary>
        /// The formats this Model supports in BatchPredictionJob.output_config. If both PredictSchemata.instance_schema_uri and PredictSchemata.prediction_schema_uri exist, the predictions are returned together with their instances. In other words, the prediction has the original instance data first, followed by the actual prediction content (as per the schema). The possible formats are: * `jsonl` The JSON Lines format, where each prediction is a single line. Uses GcsDestination. * `csv` The CSV format, where each prediction is a single comma-separated line. The first line in the file is the header, containing comma-separated field names. Uses GcsDestination. * `bigquery` Each prediction is a single row in a BigQuery table, uses BigQueryDestination . If this Model doesn't support any of these formats it means it cannot be used with a BatchPredictionJob. However, if it has supported_deployment_resources_types, it could serve online predictions by using PredictionService.Predict or PredictionService.Explain.
        /// </summary>
        [Output("supportedOutputStorageFormats")]
        public Output<ImmutableArray<string>> SupportedOutputStorageFormats { get; private set; } = null!;

        /// <summary>
        /// The resource name of the TrainingPipeline that uploaded this Model, if any.
        /// </summary>
        [Output("trainingPipeline")]
        public Output<string> TrainingPipeline { get; private set; } = null!;

        /// <summary>
        /// Timestamp when this Model was most recently updated.
        /// </summary>
        [Output("updateTime")]
        public Output<string> UpdateTime { get; private set; } = null!;

        /// <summary>
        /// User provided version aliases so that a model version can be referenced via alias (i.e. `projects/{project}/locations/{location}/models/{model_id}@{version_alias}` instead of auto-generated version id (i.e. `projects/{project}/locations/{location}/models/{model_id}@{version_id})`. The format is a-z{0,126}[a-z0-9] to distinguish from version_id. A default version alias will be created for the first version of the model, and there must be exactly one default version alias for a model.
        /// </summary>
        [Output("versionAliases")]
        public Output<ImmutableArray<string>> VersionAliases { get; private set; } = null!;

        /// <summary>
        /// Timestamp when this version was created.
        /// </summary>
        [Output("versionCreateTime")]
        public Output<string> VersionCreateTime { get; private set; } = null!;

        /// <summary>
        /// The description of this version.
        /// </summary>
        [Output("versionDescription")]
        public Output<string> VersionDescription { get; private set; } = null!;

        /// <summary>
        /// Immutable. The version ID of the model. A new version is committed when a new model version is uploaded or trained under an existing model id. It is an auto-incrementing decimal number in string representation.
        /// </summary>
        [Output("versionId")]
        public Output<string> VersionId { get; private set; } = null!;

        /// <summary>
        /// Timestamp when this version was most recently updated.
        /// </summary>
        [Output("versionUpdateTime")]
        public Output<string> VersionUpdateTime { get; private set; } = null!;


        /// <summary>
        /// Create a Model resource with the given unique name, arguments, and options.
        /// </summary>
        ///
        /// <param name="name">The unique name of the resource</param>
        /// <param name="args">The arguments used to populate this resource's properties</param>
        /// <param name="options">A bag of options that control this resource's behavior</param>
        public Model(string name, ModelArgs args, CustomResourceOptions? options = null)
            : base("google-native:aiplatform/v1:Model", name, args ?? new ModelArgs(), MakeResourceOptions(options, ""))
        {
        }

        private Model(string name, Input<string> id, CustomResourceOptions? options = null)
            : base("google-native:aiplatform/v1:Model", name, null, MakeResourceOptions(options, id))
        {
        }

        private static CustomResourceOptions MakeResourceOptions(CustomResourceOptions? options, Input<string>? id)
        {
            var defaultOptions = new CustomResourceOptions
            {
                Version = Utilities.Version,
                ReplaceOnChanges =
                {
                    "location",
                    "project",
                },
            };
            var merged = CustomResourceOptions.Merge(defaultOptions, options);
            // Override the ID if one was specified for consistency with other language SDKs.
            merged.Id = id ?? merged.Id;
            return merged;
        }
        /// <summary>
        /// Get an existing Model resource's state with the given name, ID, and optional extra
        /// properties used to qualify the lookup.
        /// </summary>
        ///
        /// <param name="name">The unique name of the resulting resource.</param>
        /// <param name="id">The unique provider ID of the resource to lookup.</param>
        /// <param name="options">A bag of options that control this resource's behavior</param>
        public static Model Get(string name, Input<string> id, CustomResourceOptions? options = null)
        {
            return new Model(name, id, options);
        }
    }

    public sealed class ModelArgs : global::Pulumi.ResourceArgs
    {
        /// <summary>
        /// Immutable. The path to the directory containing the Model artifact and any of its supporting files. Not present for AutoML Models or Large Models.
        /// </summary>
        [Input("artifactUri")]
        public Input<string>? ArtifactUri { get; set; }

        /// <summary>
        /// Input only. The specification of the container that is to be used when deploying this Model. The specification is ingested upon ModelService.UploadModel, and all binaries it contains are copied and stored internally by Vertex AI. Not present for AutoML Models or Large Models.
        /// </summary>
        [Input("containerSpec")]
        public Input<Inputs.GoogleCloudAiplatformV1ModelContainerSpecArgs>? ContainerSpec { get; set; }

        /// <summary>
        /// The description of the Model.
        /// </summary>
        [Input("description")]
        public Input<string>? Description { get; set; }

        /// <summary>
        /// The display name of the Model. The name can be up to 128 characters long and can consist of any UTF-8 characters.
        /// </summary>
        [Input("displayName", required: true)]
        public Input<string> DisplayName { get; set; } = null!;

        /// <summary>
        /// Customer-managed encryption key spec for a Model. If set, this Model and all sub-resources of this Model will be secured by this key.
        /// </summary>
        [Input("encryptionSpec")]
        public Input<Inputs.GoogleCloudAiplatformV1EncryptionSpecArgs>? EncryptionSpec { get; set; }

        /// <summary>
        /// Used to perform consistent read-modify-write updates. If not set, a blind "overwrite" update happens.
        /// </summary>
        [Input("etag")]
        public Input<string>? Etag { get; set; }

        /// <summary>
        /// The default explanation specification for this Model. The Model can be used for requesting explanation after being deployed if it is populated. The Model can be used for batch explanation if it is populated. All fields of the explanation_spec can be overridden by explanation_spec of DeployModelRequest.deployed_model, or explanation_spec of BatchPredictionJob. If the default explanation specification is not set for this Model, this Model can still be used for requesting explanation by setting explanation_spec of DeployModelRequest.deployed_model and for batch explanation by setting explanation_spec of BatchPredictionJob.
        /// </summary>
        [Input("explanationSpec")]
        public Input<Inputs.GoogleCloudAiplatformV1ExplanationSpecArgs>? ExplanationSpec { get; set; }

        [Input("labels")]
        private InputMap<string>? _labels;

        /// <summary>
        /// The labels with user-defined metadata to organize your Models. Label keys and values can be no longer than 64 characters (Unicode codepoints), can only contain lowercase letters, numeric characters, underscores and dashes. International characters are allowed. See https://goo.gl/xmQnxf for more information and examples of labels.
        /// </summary>
        public InputMap<string> Labels
        {
            get => _labels ?? (_labels = new InputMap<string>());
            set => _labels = value;
        }

        [Input("location")]
        public Input<string>? Location { get; set; }

        /// <summary>
        /// Immutable. An additional information about the Model; the schema of the metadata can be found in metadata_schema. Unset if the Model does not have any additional information.
        /// </summary>
        [Input("metadata")]
        public Input<object>? Metadata { get; set; }

        /// <summary>
        /// Immutable. Points to a YAML file stored on Google Cloud Storage describing additional information about the Model, that is specific to it. Unset if the Model does not have any additional information. The schema is defined as an OpenAPI 3.0.2 [Schema Object](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject). AutoML Models always have this field populated by Vertex AI, if no additional metadata is needed, this field is set to an empty string. Note: The URI given on output will be immutable and probably different, including the URI scheme, than the one given on input. The output URI will point to a location where the user only has a read access.
        /// </summary>
        [Input("metadataSchemaUri")]
        public Input<string>? MetadataSchemaUri { get; set; }

        /// <summary>
        /// Optional. The ID to use for the uploaded Model, which will become the final component of the model resource name. This value may be up to 63 characters, and valid characters are `[a-z0-9_-]`. The first character cannot be a number or hyphen.
        /// </summary>
        [Input("modelId")]
        public Input<string>? ModelId { get; set; }

        /// <summary>
        /// The resource name of the Model.
        /// </summary>
        [Input("name")]
        public Input<string>? Name { get; set; }

        /// <summary>
        /// Optional. The resource name of the model into which to upload the version. Only specify this field when uploading a new version.
        /// </summary>
        [Input("parentModel")]
        public Input<string>? ParentModel { get; set; }

        /// <summary>
        /// Optional. This field is populated if the model is produced by a pipeline job.
        /// </summary>
        [Input("pipelineJob")]
        public Input<string>? PipelineJob { get; set; }

        /// <summary>
        /// The schemata that describe formats of the Model's predictions and explanations as given and returned via PredictionService.Predict and PredictionService.Explain.
        /// </summary>
        [Input("predictSchemata")]
        public Input<Inputs.GoogleCloudAiplatformV1PredictSchemataArgs>? PredictSchemata { get; set; }

        [Input("project")]
        public Input<string>? Project { get; set; }

        /// <summary>
        /// Optional. The user-provided custom service account to use to do the model upload. If empty, [Vertex AI Service Agent](https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents) will be used to access resources needed to upload the model. This account must belong to the target project where the model is uploaded to, i.e., the project specified in the `parent` field of this request and have necessary read permissions (to Google Cloud Storage, Artifact Registry, etc.).
        /// </summary>
        [Input("serviceAccount")]
        public Input<string>? ServiceAccount { get; set; }

        [Input("versionAliases")]
        private InputList<string>? _versionAliases;

        /// <summary>
        /// User provided version aliases so that a model version can be referenced via alias (i.e. `projects/{project}/locations/{location}/models/{model_id}@{version_alias}` instead of auto-generated version id (i.e. `projects/{project}/locations/{location}/models/{model_id}@{version_id})`. The format is a-z{0,126}[a-z0-9] to distinguish from version_id. A default version alias will be created for the first version of the model, and there must be exactly one default version alias for a model.
        /// </summary>
        public InputList<string> VersionAliases
        {
            get => _versionAliases ?? (_versionAliases = new InputList<string>());
            set => _versionAliases = value;
        }

        /// <summary>
        /// The description of this version.
        /// </summary>
        [Input("versionDescription")]
        public Input<string>? VersionDescription { get; set; }

        public ModelArgs()
        {
        }
        public static new ModelArgs Empty => new ModelArgs();
    }
}

# coding=utf-8
# *** WARNING: this file was generated by the Pulumi SDK Generator. ***
# *** Do not edit by hand unless you're certain you know what you are doing! ***

import copy
import warnings
import pulumi
import pulumi.runtime
from typing import Any, Mapping, Optional, Sequence, Union, overload
from ... import _utilities
from . import outputs
from ._enums import *
from ._inputs import *

__all__ = ['ModelArgs', 'Model']

@pulumi.input_type
class ModelArgs:
    def __init__(__self__, *,
                 display_name: pulumi.Input[str],
                 artifact_uri: Optional[pulumi.Input[str]] = None,
                 base_model_source: Optional[pulumi.Input['GoogleCloudAiplatformV1beta1ModelBaseModelSourceArgs']] = None,
                 container_spec: Optional[pulumi.Input['GoogleCloudAiplatformV1beta1ModelContainerSpecArgs']] = None,
                 description: Optional[pulumi.Input[str]] = None,
                 encryption_spec: Optional[pulumi.Input['GoogleCloudAiplatformV1beta1EncryptionSpecArgs']] = None,
                 etag: Optional[pulumi.Input[str]] = None,
                 explanation_spec: Optional[pulumi.Input['GoogleCloudAiplatformV1beta1ExplanationSpecArgs']] = None,
                 labels: Optional[pulumi.Input[Mapping[str, pulumi.Input[str]]]] = None,
                 location: Optional[pulumi.Input[str]] = None,
                 metadata: Optional[Any] = None,
                 metadata_schema_uri: Optional[pulumi.Input[str]] = None,
                 model_id: Optional[pulumi.Input[str]] = None,
                 name: Optional[pulumi.Input[str]] = None,
                 parent_model: Optional[pulumi.Input[str]] = None,
                 predict_schemata: Optional[pulumi.Input['GoogleCloudAiplatformV1beta1PredictSchemataArgs']] = None,
                 project: Optional[pulumi.Input[str]] = None,
                 service_account: Optional[pulumi.Input[str]] = None,
                 version_aliases: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]] = None,
                 version_description: Optional[pulumi.Input[str]] = None):
        """
        The set of arguments for constructing a Model resource.
        :param pulumi.Input[str] display_name: The display name of the Model. The name can be up to 128 characters long and can consist of any UTF-8 characters.
        :param pulumi.Input[str] artifact_uri: Immutable. The path to the directory containing the Model artifact and any of its supporting files. Not required for AutoML Models.
        :param pulumi.Input['GoogleCloudAiplatformV1beta1ModelBaseModelSourceArgs'] base_model_source: Optional. User input field to specify the base model source. Currently it only supports specifing the Model Garden models and Genie models.
        :param pulumi.Input['GoogleCloudAiplatformV1beta1ModelContainerSpecArgs'] container_spec: Input only. The specification of the container that is to be used when deploying this Model. The specification is ingested upon ModelService.UploadModel, and all binaries it contains are copied and stored internally by Vertex AI. Not required for AutoML Models.
        :param pulumi.Input[str] description: The description of the Model.
        :param pulumi.Input['GoogleCloudAiplatformV1beta1EncryptionSpecArgs'] encryption_spec: Customer-managed encryption key spec for a Model. If set, this Model and all sub-resources of this Model will be secured by this key.
        :param pulumi.Input[str] etag: Used to perform consistent read-modify-write updates. If not set, a blind "overwrite" update happens.
        :param pulumi.Input['GoogleCloudAiplatformV1beta1ExplanationSpecArgs'] explanation_spec: The default explanation specification for this Model. The Model can be used for requesting explanation after being deployed if it is populated. The Model can be used for batch explanation if it is populated. All fields of the explanation_spec can be overridden by explanation_spec of DeployModelRequest.deployed_model, or explanation_spec of BatchPredictionJob. If the default explanation specification is not set for this Model, this Model can still be used for requesting explanation by setting explanation_spec of DeployModelRequest.deployed_model and for batch explanation by setting explanation_spec of BatchPredictionJob.
        :param pulumi.Input[Mapping[str, pulumi.Input[str]]] labels: The labels with user-defined metadata to organize your Models. Label keys and values can be no longer than 64 characters (Unicode codepoints), can only contain lowercase letters, numeric characters, underscores and dashes. International characters are allowed. See https://goo.gl/xmQnxf for more information and examples of labels.
        :param Any metadata: Immutable. An additional information about the Model; the schema of the metadata can be found in metadata_schema. Unset if the Model does not have any additional information.
        :param pulumi.Input[str] metadata_schema_uri: Immutable. Points to a YAML file stored on Google Cloud Storage describing additional information about the Model, that is specific to it. Unset if the Model does not have any additional information. The schema is defined as an OpenAPI 3.0.2 [Schema Object](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject). AutoML Models always have this field populated by Vertex AI, if no additional metadata is needed, this field is set to an empty string. Note: The URI given on output will be immutable and probably different, including the URI scheme, than the one given on input. The output URI will point to a location where the user only has a read access.
        :param pulumi.Input[str] model_id: Optional. The ID to use for the uploaded Model, which will become the final component of the model resource name. This value may be up to 63 characters, and valid characters are `[a-z0-9_-]`. The first character cannot be a number or hyphen.
        :param pulumi.Input[str] name: The resource name of the Model.
        :param pulumi.Input[str] parent_model: Optional. The resource name of the model into which to upload the version. Only specify this field when uploading a new version.
        :param pulumi.Input['GoogleCloudAiplatformV1beta1PredictSchemataArgs'] predict_schemata: The schemata that describe formats of the Model's predictions and explanations as given and returned via PredictionService.Predict and PredictionService.Explain.
        :param pulumi.Input[str] service_account: Optional. The user-provided custom service account to use to do the model upload. If empty, [Vertex AI Service Agent](https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents) will be used to access resources needed to upload the model. This account must belong to the target project where the model is uploaded to, i.e., the project specified in the `parent` field of this request and have necessary read permissions (to Google Cloud Storage, Artifact Registry, etc.).
        :param pulumi.Input[Sequence[pulumi.Input[str]]] version_aliases: User provided version aliases so that a model version can be referenced via alias (i.e. `projects/{project}/locations/{location}/models/{model_id}@{version_alias}` instead of auto-generated version id (i.e. `projects/{project}/locations/{location}/models/{model_id}@{version_id})`. The format is a-z{0,126}[a-z0-9] to distinguish from version_id. A default version alias will be created for the first version of the model, and there must be exactly one default version alias for a model.
        :param pulumi.Input[str] version_description: The description of this version.
        """
        pulumi.set(__self__, "display_name", display_name)
        if artifact_uri is not None:
            pulumi.set(__self__, "artifact_uri", artifact_uri)
        if base_model_source is not None:
            pulumi.set(__self__, "base_model_source", base_model_source)
        if container_spec is not None:
            pulumi.set(__self__, "container_spec", container_spec)
        if description is not None:
            pulumi.set(__self__, "description", description)
        if encryption_spec is not None:
            pulumi.set(__self__, "encryption_spec", encryption_spec)
        if etag is not None:
            pulumi.set(__self__, "etag", etag)
        if explanation_spec is not None:
            pulumi.set(__self__, "explanation_spec", explanation_spec)
        if labels is not None:
            pulumi.set(__self__, "labels", labels)
        if location is not None:
            pulumi.set(__self__, "location", location)
        if metadata is not None:
            pulumi.set(__self__, "metadata", metadata)
        if metadata_schema_uri is not None:
            pulumi.set(__self__, "metadata_schema_uri", metadata_schema_uri)
        if model_id is not None:
            pulumi.set(__self__, "model_id", model_id)
        if name is not None:
            pulumi.set(__self__, "name", name)
        if parent_model is not None:
            pulumi.set(__self__, "parent_model", parent_model)
        if predict_schemata is not None:
            pulumi.set(__self__, "predict_schemata", predict_schemata)
        if project is not None:
            pulumi.set(__self__, "project", project)
        if service_account is not None:
            pulumi.set(__self__, "service_account", service_account)
        if version_aliases is not None:
            pulumi.set(__self__, "version_aliases", version_aliases)
        if version_description is not None:
            pulumi.set(__self__, "version_description", version_description)

    @property
    @pulumi.getter(name="displayName")
    def display_name(self) -> pulumi.Input[str]:
        """
        The display name of the Model. The name can be up to 128 characters long and can consist of any UTF-8 characters.
        """
        return pulumi.get(self, "display_name")

    @display_name.setter
    def display_name(self, value: pulumi.Input[str]):
        pulumi.set(self, "display_name", value)

    @property
    @pulumi.getter(name="artifactUri")
    def artifact_uri(self) -> Optional[pulumi.Input[str]]:
        """
        Immutable. The path to the directory containing the Model artifact and any of its supporting files. Not required for AutoML Models.
        """
        return pulumi.get(self, "artifact_uri")

    @artifact_uri.setter
    def artifact_uri(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "artifact_uri", value)

    @property
    @pulumi.getter(name="baseModelSource")
    def base_model_source(self) -> Optional[pulumi.Input['GoogleCloudAiplatformV1beta1ModelBaseModelSourceArgs']]:
        """
        Optional. User input field to specify the base model source. Currently it only supports specifing the Model Garden models and Genie models.
        """
        return pulumi.get(self, "base_model_source")

    @base_model_source.setter
    def base_model_source(self, value: Optional[pulumi.Input['GoogleCloudAiplatformV1beta1ModelBaseModelSourceArgs']]):
        pulumi.set(self, "base_model_source", value)

    @property
    @pulumi.getter(name="containerSpec")
    def container_spec(self) -> Optional[pulumi.Input['GoogleCloudAiplatformV1beta1ModelContainerSpecArgs']]:
        """
        Input only. The specification of the container that is to be used when deploying this Model. The specification is ingested upon ModelService.UploadModel, and all binaries it contains are copied and stored internally by Vertex AI. Not required for AutoML Models.
        """
        return pulumi.get(self, "container_spec")

    @container_spec.setter
    def container_spec(self, value: Optional[pulumi.Input['GoogleCloudAiplatformV1beta1ModelContainerSpecArgs']]):
        pulumi.set(self, "container_spec", value)

    @property
    @pulumi.getter
    def description(self) -> Optional[pulumi.Input[str]]:
        """
        The description of the Model.
        """
        return pulumi.get(self, "description")

    @description.setter
    def description(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "description", value)

    @property
    @pulumi.getter(name="encryptionSpec")
    def encryption_spec(self) -> Optional[pulumi.Input['GoogleCloudAiplatformV1beta1EncryptionSpecArgs']]:
        """
        Customer-managed encryption key spec for a Model. If set, this Model and all sub-resources of this Model will be secured by this key.
        """
        return pulumi.get(self, "encryption_spec")

    @encryption_spec.setter
    def encryption_spec(self, value: Optional[pulumi.Input['GoogleCloudAiplatformV1beta1EncryptionSpecArgs']]):
        pulumi.set(self, "encryption_spec", value)

    @property
    @pulumi.getter
    def etag(self) -> Optional[pulumi.Input[str]]:
        """
        Used to perform consistent read-modify-write updates. If not set, a blind "overwrite" update happens.
        """
        return pulumi.get(self, "etag")

    @etag.setter
    def etag(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "etag", value)

    @property
    @pulumi.getter(name="explanationSpec")
    def explanation_spec(self) -> Optional[pulumi.Input['GoogleCloudAiplatformV1beta1ExplanationSpecArgs']]:
        """
        The default explanation specification for this Model. The Model can be used for requesting explanation after being deployed if it is populated. The Model can be used for batch explanation if it is populated. All fields of the explanation_spec can be overridden by explanation_spec of DeployModelRequest.deployed_model, or explanation_spec of BatchPredictionJob. If the default explanation specification is not set for this Model, this Model can still be used for requesting explanation by setting explanation_spec of DeployModelRequest.deployed_model and for batch explanation by setting explanation_spec of BatchPredictionJob.
        """
        return pulumi.get(self, "explanation_spec")

    @explanation_spec.setter
    def explanation_spec(self, value: Optional[pulumi.Input['GoogleCloudAiplatformV1beta1ExplanationSpecArgs']]):
        pulumi.set(self, "explanation_spec", value)

    @property
    @pulumi.getter
    def labels(self) -> Optional[pulumi.Input[Mapping[str, pulumi.Input[str]]]]:
        """
        The labels with user-defined metadata to organize your Models. Label keys and values can be no longer than 64 characters (Unicode codepoints), can only contain lowercase letters, numeric characters, underscores and dashes. International characters are allowed. See https://goo.gl/xmQnxf for more information and examples of labels.
        """
        return pulumi.get(self, "labels")

    @labels.setter
    def labels(self, value: Optional[pulumi.Input[Mapping[str, pulumi.Input[str]]]]):
        pulumi.set(self, "labels", value)

    @property
    @pulumi.getter
    def location(self) -> Optional[pulumi.Input[str]]:
        return pulumi.get(self, "location")

    @location.setter
    def location(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "location", value)

    @property
    @pulumi.getter
    def metadata(self) -> Optional[Any]:
        """
        Immutable. An additional information about the Model; the schema of the metadata can be found in metadata_schema. Unset if the Model does not have any additional information.
        """
        return pulumi.get(self, "metadata")

    @metadata.setter
    def metadata(self, value: Optional[Any]):
        pulumi.set(self, "metadata", value)

    @property
    @pulumi.getter(name="metadataSchemaUri")
    def metadata_schema_uri(self) -> Optional[pulumi.Input[str]]:
        """
        Immutable. Points to a YAML file stored on Google Cloud Storage describing additional information about the Model, that is specific to it. Unset if the Model does not have any additional information. The schema is defined as an OpenAPI 3.0.2 [Schema Object](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject). AutoML Models always have this field populated by Vertex AI, if no additional metadata is needed, this field is set to an empty string. Note: The URI given on output will be immutable and probably different, including the URI scheme, than the one given on input. The output URI will point to a location where the user only has a read access.
        """
        return pulumi.get(self, "metadata_schema_uri")

    @metadata_schema_uri.setter
    def metadata_schema_uri(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "metadata_schema_uri", value)

    @property
    @pulumi.getter(name="modelId")
    def model_id(self) -> Optional[pulumi.Input[str]]:
        """
        Optional. The ID to use for the uploaded Model, which will become the final component of the model resource name. This value may be up to 63 characters, and valid characters are `[a-z0-9_-]`. The first character cannot be a number or hyphen.
        """
        return pulumi.get(self, "model_id")

    @model_id.setter
    def model_id(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "model_id", value)

    @property
    @pulumi.getter
    def name(self) -> Optional[pulumi.Input[str]]:
        """
        The resource name of the Model.
        """
        return pulumi.get(self, "name")

    @name.setter
    def name(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "name", value)

    @property
    @pulumi.getter(name="parentModel")
    def parent_model(self) -> Optional[pulumi.Input[str]]:
        """
        Optional. The resource name of the model into which to upload the version. Only specify this field when uploading a new version.
        """
        return pulumi.get(self, "parent_model")

    @parent_model.setter
    def parent_model(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "parent_model", value)

    @property
    @pulumi.getter(name="predictSchemata")
    def predict_schemata(self) -> Optional[pulumi.Input['GoogleCloudAiplatformV1beta1PredictSchemataArgs']]:
        """
        The schemata that describe formats of the Model's predictions and explanations as given and returned via PredictionService.Predict and PredictionService.Explain.
        """
        return pulumi.get(self, "predict_schemata")

    @predict_schemata.setter
    def predict_schemata(self, value: Optional[pulumi.Input['GoogleCloudAiplatformV1beta1PredictSchemataArgs']]):
        pulumi.set(self, "predict_schemata", value)

    @property
    @pulumi.getter
    def project(self) -> Optional[pulumi.Input[str]]:
        return pulumi.get(self, "project")

    @project.setter
    def project(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "project", value)

    @property
    @pulumi.getter(name="serviceAccount")
    def service_account(self) -> Optional[pulumi.Input[str]]:
        """
        Optional. The user-provided custom service account to use to do the model upload. If empty, [Vertex AI Service Agent](https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents) will be used to access resources needed to upload the model. This account must belong to the target project where the model is uploaded to, i.e., the project specified in the `parent` field of this request and have necessary read permissions (to Google Cloud Storage, Artifact Registry, etc.).
        """
        return pulumi.get(self, "service_account")

    @service_account.setter
    def service_account(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "service_account", value)

    @property
    @pulumi.getter(name="versionAliases")
    def version_aliases(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]:
        """
        User provided version aliases so that a model version can be referenced via alias (i.e. `projects/{project}/locations/{location}/models/{model_id}@{version_alias}` instead of auto-generated version id (i.e. `projects/{project}/locations/{location}/models/{model_id}@{version_id})`. The format is a-z{0,126}[a-z0-9] to distinguish from version_id. A default version alias will be created for the first version of the model, and there must be exactly one default version alias for a model.
        """
        return pulumi.get(self, "version_aliases")

    @version_aliases.setter
    def version_aliases(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]):
        pulumi.set(self, "version_aliases", value)

    @property
    @pulumi.getter(name="versionDescription")
    def version_description(self) -> Optional[pulumi.Input[str]]:
        """
        The description of this version.
        """
        return pulumi.get(self, "version_description")

    @version_description.setter
    def version_description(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "version_description", value)


class Model(pulumi.CustomResource):
    @overload
    def __init__(__self__,
                 resource_name: str,
                 opts: Optional[pulumi.ResourceOptions] = None,
                 artifact_uri: Optional[pulumi.Input[str]] = None,
                 base_model_source: Optional[pulumi.Input[pulumi.InputType['GoogleCloudAiplatformV1beta1ModelBaseModelSourceArgs']]] = None,
                 container_spec: Optional[pulumi.Input[pulumi.InputType['GoogleCloudAiplatformV1beta1ModelContainerSpecArgs']]] = None,
                 description: Optional[pulumi.Input[str]] = None,
                 display_name: Optional[pulumi.Input[str]] = None,
                 encryption_spec: Optional[pulumi.Input[pulumi.InputType['GoogleCloudAiplatformV1beta1EncryptionSpecArgs']]] = None,
                 etag: Optional[pulumi.Input[str]] = None,
                 explanation_spec: Optional[pulumi.Input[pulumi.InputType['GoogleCloudAiplatformV1beta1ExplanationSpecArgs']]] = None,
                 labels: Optional[pulumi.Input[Mapping[str, pulumi.Input[str]]]] = None,
                 location: Optional[pulumi.Input[str]] = None,
                 metadata: Optional[Any] = None,
                 metadata_schema_uri: Optional[pulumi.Input[str]] = None,
                 model_id: Optional[pulumi.Input[str]] = None,
                 name: Optional[pulumi.Input[str]] = None,
                 parent_model: Optional[pulumi.Input[str]] = None,
                 predict_schemata: Optional[pulumi.Input[pulumi.InputType['GoogleCloudAiplatformV1beta1PredictSchemataArgs']]] = None,
                 project: Optional[pulumi.Input[str]] = None,
                 service_account: Optional[pulumi.Input[str]] = None,
                 version_aliases: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]] = None,
                 version_description: Optional[pulumi.Input[str]] = None,
                 __props__=None):
        """
        Uploads a Model artifact into Vertex AI.

        :param str resource_name: The name of the resource.
        :param pulumi.ResourceOptions opts: Options for the resource.
        :param pulumi.Input[str] artifact_uri: Immutable. The path to the directory containing the Model artifact and any of its supporting files. Not required for AutoML Models.
        :param pulumi.Input[pulumi.InputType['GoogleCloudAiplatformV1beta1ModelBaseModelSourceArgs']] base_model_source: Optional. User input field to specify the base model source. Currently it only supports specifing the Model Garden models and Genie models.
        :param pulumi.Input[pulumi.InputType['GoogleCloudAiplatformV1beta1ModelContainerSpecArgs']] container_spec: Input only. The specification of the container that is to be used when deploying this Model. The specification is ingested upon ModelService.UploadModel, and all binaries it contains are copied and stored internally by Vertex AI. Not required for AutoML Models.
        :param pulumi.Input[str] description: The description of the Model.
        :param pulumi.Input[str] display_name: The display name of the Model. The name can be up to 128 characters long and can consist of any UTF-8 characters.
        :param pulumi.Input[pulumi.InputType['GoogleCloudAiplatformV1beta1EncryptionSpecArgs']] encryption_spec: Customer-managed encryption key spec for a Model. If set, this Model and all sub-resources of this Model will be secured by this key.
        :param pulumi.Input[str] etag: Used to perform consistent read-modify-write updates. If not set, a blind "overwrite" update happens.
        :param pulumi.Input[pulumi.InputType['GoogleCloudAiplatformV1beta1ExplanationSpecArgs']] explanation_spec: The default explanation specification for this Model. The Model can be used for requesting explanation after being deployed if it is populated. The Model can be used for batch explanation if it is populated. All fields of the explanation_spec can be overridden by explanation_spec of DeployModelRequest.deployed_model, or explanation_spec of BatchPredictionJob. If the default explanation specification is not set for this Model, this Model can still be used for requesting explanation by setting explanation_spec of DeployModelRequest.deployed_model and for batch explanation by setting explanation_spec of BatchPredictionJob.
        :param pulumi.Input[Mapping[str, pulumi.Input[str]]] labels: The labels with user-defined metadata to organize your Models. Label keys and values can be no longer than 64 characters (Unicode codepoints), can only contain lowercase letters, numeric characters, underscores and dashes. International characters are allowed. See https://goo.gl/xmQnxf for more information and examples of labels.
        :param Any metadata: Immutable. An additional information about the Model; the schema of the metadata can be found in metadata_schema. Unset if the Model does not have any additional information.
        :param pulumi.Input[str] metadata_schema_uri: Immutable. Points to a YAML file stored on Google Cloud Storage describing additional information about the Model, that is specific to it. Unset if the Model does not have any additional information. The schema is defined as an OpenAPI 3.0.2 [Schema Object](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject). AutoML Models always have this field populated by Vertex AI, if no additional metadata is needed, this field is set to an empty string. Note: The URI given on output will be immutable and probably different, including the URI scheme, than the one given on input. The output URI will point to a location where the user only has a read access.
        :param pulumi.Input[str] model_id: Optional. The ID to use for the uploaded Model, which will become the final component of the model resource name. This value may be up to 63 characters, and valid characters are `[a-z0-9_-]`. The first character cannot be a number or hyphen.
        :param pulumi.Input[str] name: The resource name of the Model.
        :param pulumi.Input[str] parent_model: Optional. The resource name of the model into which to upload the version. Only specify this field when uploading a new version.
        :param pulumi.Input[pulumi.InputType['GoogleCloudAiplatformV1beta1PredictSchemataArgs']] predict_schemata: The schemata that describe formats of the Model's predictions and explanations as given and returned via PredictionService.Predict and PredictionService.Explain.
        :param pulumi.Input[str] service_account: Optional. The user-provided custom service account to use to do the model upload. If empty, [Vertex AI Service Agent](https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents) will be used to access resources needed to upload the model. This account must belong to the target project where the model is uploaded to, i.e., the project specified in the `parent` field of this request and have necessary read permissions (to Google Cloud Storage, Artifact Registry, etc.).
        :param pulumi.Input[Sequence[pulumi.Input[str]]] version_aliases: User provided version aliases so that a model version can be referenced via alias (i.e. `projects/{project}/locations/{location}/models/{model_id}@{version_alias}` instead of auto-generated version id (i.e. `projects/{project}/locations/{location}/models/{model_id}@{version_id})`. The format is a-z{0,126}[a-z0-9] to distinguish from version_id. A default version alias will be created for the first version of the model, and there must be exactly one default version alias for a model.
        :param pulumi.Input[str] version_description: The description of this version.
        """
        ...
    @overload
    def __init__(__self__,
                 resource_name: str,
                 args: ModelArgs,
                 opts: Optional[pulumi.ResourceOptions] = None):
        """
        Uploads a Model artifact into Vertex AI.

        :param str resource_name: The name of the resource.
        :param ModelArgs args: The arguments to use to populate this resource's properties.
        :param pulumi.ResourceOptions opts: Options for the resource.
        """
        ...
    def __init__(__self__, resource_name: str, *args, **kwargs):
        resource_args, opts = _utilities.get_resource_args_opts(ModelArgs, pulumi.ResourceOptions, *args, **kwargs)
        if resource_args is not None:
            __self__._internal_init(resource_name, opts, **resource_args.__dict__)
        else:
            __self__._internal_init(resource_name, *args, **kwargs)

    def _internal_init(__self__,
                 resource_name: str,
                 opts: Optional[pulumi.ResourceOptions] = None,
                 artifact_uri: Optional[pulumi.Input[str]] = None,
                 base_model_source: Optional[pulumi.Input[pulumi.InputType['GoogleCloudAiplatformV1beta1ModelBaseModelSourceArgs']]] = None,
                 container_spec: Optional[pulumi.Input[pulumi.InputType['GoogleCloudAiplatformV1beta1ModelContainerSpecArgs']]] = None,
                 description: Optional[pulumi.Input[str]] = None,
                 display_name: Optional[pulumi.Input[str]] = None,
                 encryption_spec: Optional[pulumi.Input[pulumi.InputType['GoogleCloudAiplatformV1beta1EncryptionSpecArgs']]] = None,
                 etag: Optional[pulumi.Input[str]] = None,
                 explanation_spec: Optional[pulumi.Input[pulumi.InputType['GoogleCloudAiplatformV1beta1ExplanationSpecArgs']]] = None,
                 labels: Optional[pulumi.Input[Mapping[str, pulumi.Input[str]]]] = None,
                 location: Optional[pulumi.Input[str]] = None,
                 metadata: Optional[Any] = None,
                 metadata_schema_uri: Optional[pulumi.Input[str]] = None,
                 model_id: Optional[pulumi.Input[str]] = None,
                 name: Optional[pulumi.Input[str]] = None,
                 parent_model: Optional[pulumi.Input[str]] = None,
                 predict_schemata: Optional[pulumi.Input[pulumi.InputType['GoogleCloudAiplatformV1beta1PredictSchemataArgs']]] = None,
                 project: Optional[pulumi.Input[str]] = None,
                 service_account: Optional[pulumi.Input[str]] = None,
                 version_aliases: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]] = None,
                 version_description: Optional[pulumi.Input[str]] = None,
                 __props__=None):
        opts = pulumi.ResourceOptions.merge(_utilities.get_resource_opts_defaults(), opts)
        if not isinstance(opts, pulumi.ResourceOptions):
            raise TypeError('Expected resource options to be a ResourceOptions instance')
        if opts.id is None:
            if __props__ is not None:
                raise TypeError('__props__ is only valid when passed in combination with a valid opts.id to get an existing resource')
            __props__ = ModelArgs.__new__(ModelArgs)

            __props__.__dict__["artifact_uri"] = artifact_uri
            __props__.__dict__["base_model_source"] = base_model_source
            __props__.__dict__["container_spec"] = container_spec
            __props__.__dict__["description"] = description
            if display_name is None and not opts.urn:
                raise TypeError("Missing required property 'display_name'")
            __props__.__dict__["display_name"] = display_name
            __props__.__dict__["encryption_spec"] = encryption_spec
            __props__.__dict__["etag"] = etag
            __props__.__dict__["explanation_spec"] = explanation_spec
            __props__.__dict__["labels"] = labels
            __props__.__dict__["location"] = location
            __props__.__dict__["metadata"] = metadata
            __props__.__dict__["metadata_schema_uri"] = metadata_schema_uri
            __props__.__dict__["model_id"] = model_id
            __props__.__dict__["name"] = name
            __props__.__dict__["parent_model"] = parent_model
            __props__.__dict__["predict_schemata"] = predict_schemata
            __props__.__dict__["project"] = project
            __props__.__dict__["service_account"] = service_account
            __props__.__dict__["version_aliases"] = version_aliases
            __props__.__dict__["version_description"] = version_description
            __props__.__dict__["create_time"] = None
            __props__.__dict__["deployed_models"] = None
            __props__.__dict__["metadata_artifact"] = None
            __props__.__dict__["model_source_info"] = None
            __props__.__dict__["original_model_info"] = None
            __props__.__dict__["supported_deployment_resources_types"] = None
            __props__.__dict__["supported_export_formats"] = None
            __props__.__dict__["supported_input_storage_formats"] = None
            __props__.__dict__["supported_output_storage_formats"] = None
            __props__.__dict__["training_pipeline"] = None
            __props__.__dict__["update_time"] = None
            __props__.__dict__["version_create_time"] = None
            __props__.__dict__["version_id"] = None
            __props__.__dict__["version_update_time"] = None
        replace_on_changes = pulumi.ResourceOptions(replace_on_changes=["location", "project"])
        opts = pulumi.ResourceOptions.merge(opts, replace_on_changes)
        super(Model, __self__).__init__(
            'google-native:aiplatform/v1beta1:Model',
            resource_name,
            __props__,
            opts)

    @staticmethod
    def get(resource_name: str,
            id: pulumi.Input[str],
            opts: Optional[pulumi.ResourceOptions] = None) -> 'Model':
        """
        Get an existing Model resource's state with the given name, id, and optional extra
        properties used to qualify the lookup.

        :param str resource_name: The unique name of the resulting resource.
        :param pulumi.Input[str] id: The unique provider ID of the resource to lookup.
        :param pulumi.ResourceOptions opts: Options for the resource.
        """
        opts = pulumi.ResourceOptions.merge(opts, pulumi.ResourceOptions(id=id))

        __props__ = ModelArgs.__new__(ModelArgs)

        __props__.__dict__["artifact_uri"] = None
        __props__.__dict__["base_model_source"] = None
        __props__.__dict__["container_spec"] = None
        __props__.__dict__["create_time"] = None
        __props__.__dict__["deployed_models"] = None
        __props__.__dict__["description"] = None
        __props__.__dict__["display_name"] = None
        __props__.__dict__["encryption_spec"] = None
        __props__.__dict__["etag"] = None
        __props__.__dict__["explanation_spec"] = None
        __props__.__dict__["labels"] = None
        __props__.__dict__["location"] = None
        __props__.__dict__["metadata"] = None
        __props__.__dict__["metadata_artifact"] = None
        __props__.__dict__["metadata_schema_uri"] = None
        __props__.__dict__["model_source_info"] = None
        __props__.__dict__["name"] = None
        __props__.__dict__["original_model_info"] = None
        __props__.__dict__["predict_schemata"] = None
        __props__.__dict__["project"] = None
        __props__.__dict__["supported_deployment_resources_types"] = None
        __props__.__dict__["supported_export_formats"] = None
        __props__.__dict__["supported_input_storage_formats"] = None
        __props__.__dict__["supported_output_storage_formats"] = None
        __props__.__dict__["training_pipeline"] = None
        __props__.__dict__["update_time"] = None
        __props__.__dict__["version_aliases"] = None
        __props__.__dict__["version_create_time"] = None
        __props__.__dict__["version_description"] = None
        __props__.__dict__["version_id"] = None
        __props__.__dict__["version_update_time"] = None
        return Model(resource_name, opts=opts, __props__=__props__)

    @property
    @pulumi.getter(name="artifactUri")
    def artifact_uri(self) -> pulumi.Output[str]:
        """
        Immutable. The path to the directory containing the Model artifact and any of its supporting files. Not required for AutoML Models.
        """
        return pulumi.get(self, "artifact_uri")

    @property
    @pulumi.getter(name="baseModelSource")
    def base_model_source(self) -> pulumi.Output['outputs.GoogleCloudAiplatformV1beta1ModelBaseModelSourceResponse']:
        """
        Optional. User input field to specify the base model source. Currently it only supports specifing the Model Garden models and Genie models.
        """
        return pulumi.get(self, "base_model_source")

    @property
    @pulumi.getter(name="containerSpec")
    def container_spec(self) -> pulumi.Output['outputs.GoogleCloudAiplatformV1beta1ModelContainerSpecResponse']:
        """
        Input only. The specification of the container that is to be used when deploying this Model. The specification is ingested upon ModelService.UploadModel, and all binaries it contains are copied and stored internally by Vertex AI. Not required for AutoML Models.
        """
        return pulumi.get(self, "container_spec")

    @property
    @pulumi.getter(name="createTime")
    def create_time(self) -> pulumi.Output[str]:
        """
        Timestamp when this Model was uploaded into Vertex AI.
        """
        return pulumi.get(self, "create_time")

    @property
    @pulumi.getter(name="deployedModels")
    def deployed_models(self) -> pulumi.Output[Sequence['outputs.GoogleCloudAiplatformV1beta1DeployedModelRefResponse']]:
        """
        The pointers to DeployedModels created from this Model. Note that Model could have been deployed to Endpoints in different Locations.
        """
        return pulumi.get(self, "deployed_models")

    @property
    @pulumi.getter
    def description(self) -> pulumi.Output[str]:
        """
        The description of the Model.
        """
        return pulumi.get(self, "description")

    @property
    @pulumi.getter(name="displayName")
    def display_name(self) -> pulumi.Output[str]:
        """
        The display name of the Model. The name can be up to 128 characters long and can consist of any UTF-8 characters.
        """
        return pulumi.get(self, "display_name")

    @property
    @pulumi.getter(name="encryptionSpec")
    def encryption_spec(self) -> pulumi.Output['outputs.GoogleCloudAiplatformV1beta1EncryptionSpecResponse']:
        """
        Customer-managed encryption key spec for a Model. If set, this Model and all sub-resources of this Model will be secured by this key.
        """
        return pulumi.get(self, "encryption_spec")

    @property
    @pulumi.getter
    def etag(self) -> pulumi.Output[str]:
        """
        Used to perform consistent read-modify-write updates. If not set, a blind "overwrite" update happens.
        """
        return pulumi.get(self, "etag")

    @property
    @pulumi.getter(name="explanationSpec")
    def explanation_spec(self) -> pulumi.Output['outputs.GoogleCloudAiplatformV1beta1ExplanationSpecResponse']:
        """
        The default explanation specification for this Model. The Model can be used for requesting explanation after being deployed if it is populated. The Model can be used for batch explanation if it is populated. All fields of the explanation_spec can be overridden by explanation_spec of DeployModelRequest.deployed_model, or explanation_spec of BatchPredictionJob. If the default explanation specification is not set for this Model, this Model can still be used for requesting explanation by setting explanation_spec of DeployModelRequest.deployed_model and for batch explanation by setting explanation_spec of BatchPredictionJob.
        """
        return pulumi.get(self, "explanation_spec")

    @property
    @pulumi.getter
    def labels(self) -> pulumi.Output[Mapping[str, str]]:
        """
        The labels with user-defined metadata to organize your Models. Label keys and values can be no longer than 64 characters (Unicode codepoints), can only contain lowercase letters, numeric characters, underscores and dashes. International characters are allowed. See https://goo.gl/xmQnxf for more information and examples of labels.
        """
        return pulumi.get(self, "labels")

    @property
    @pulumi.getter
    def location(self) -> pulumi.Output[str]:
        return pulumi.get(self, "location")

    @property
    @pulumi.getter
    def metadata(self) -> pulumi.Output[Any]:
        """
        Immutable. An additional information about the Model; the schema of the metadata can be found in metadata_schema. Unset if the Model does not have any additional information.
        """
        return pulumi.get(self, "metadata")

    @property
    @pulumi.getter(name="metadataArtifact")
    def metadata_artifact(self) -> pulumi.Output[str]:
        """
        The resource name of the Artifact that was created in MetadataStore when creating the Model. The Artifact resource name pattern is `projects/{project}/locations/{location}/metadataStores/{metadata_store}/artifacts/{artifact}`.
        """
        return pulumi.get(self, "metadata_artifact")

    @property
    @pulumi.getter(name="metadataSchemaUri")
    def metadata_schema_uri(self) -> pulumi.Output[str]:
        """
        Immutable. Points to a YAML file stored on Google Cloud Storage describing additional information about the Model, that is specific to it. Unset if the Model does not have any additional information. The schema is defined as an OpenAPI 3.0.2 [Schema Object](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject). AutoML Models always have this field populated by Vertex AI, if no additional metadata is needed, this field is set to an empty string. Note: The URI given on output will be immutable and probably different, including the URI scheme, than the one given on input. The output URI will point to a location where the user only has a read access.
        """
        return pulumi.get(self, "metadata_schema_uri")

    @property
    @pulumi.getter(name="modelSourceInfo")
    def model_source_info(self) -> pulumi.Output['outputs.GoogleCloudAiplatformV1beta1ModelSourceInfoResponse']:
        """
        Source of a model. It can either be automl training pipeline, custom training pipeline, BigQuery ML, or saved and tuned from Genie or Model Garden.
        """
        return pulumi.get(self, "model_source_info")

    @property
    @pulumi.getter
    def name(self) -> pulumi.Output[str]:
        """
        The resource name of the Model.
        """
        return pulumi.get(self, "name")

    @property
    @pulumi.getter(name="originalModelInfo")
    def original_model_info(self) -> pulumi.Output['outputs.GoogleCloudAiplatformV1beta1ModelOriginalModelInfoResponse']:
        """
        If this Model is a copy of another Model, this contains info about the original.
        """
        return pulumi.get(self, "original_model_info")

    @property
    @pulumi.getter(name="predictSchemata")
    def predict_schemata(self) -> pulumi.Output['outputs.GoogleCloudAiplatformV1beta1PredictSchemataResponse']:
        """
        The schemata that describe formats of the Model's predictions and explanations as given and returned via PredictionService.Predict and PredictionService.Explain.
        """
        return pulumi.get(self, "predict_schemata")

    @property
    @pulumi.getter
    def project(self) -> pulumi.Output[str]:
        return pulumi.get(self, "project")

    @property
    @pulumi.getter(name="supportedDeploymentResourcesTypes")
    def supported_deployment_resources_types(self) -> pulumi.Output[Sequence[str]]:
        """
        When this Model is deployed, its prediction resources are described by the `prediction_resources` field of the Endpoint.deployed_models object. Because not all Models support all resource configuration types, the configuration types this Model supports are listed here. If no configuration types are listed, the Model cannot be deployed to an Endpoint and does not support online predictions (PredictionService.Predict or PredictionService.Explain). Such a Model can serve predictions by using a BatchPredictionJob, if it has at least one entry each in supported_input_storage_formats and supported_output_storage_formats.
        """
        return pulumi.get(self, "supported_deployment_resources_types")

    @property
    @pulumi.getter(name="supportedExportFormats")
    def supported_export_formats(self) -> pulumi.Output[Sequence['outputs.GoogleCloudAiplatformV1beta1ModelExportFormatResponse']]:
        """
        The formats in which this Model may be exported. If empty, this Model is not available for export.
        """
        return pulumi.get(self, "supported_export_formats")

    @property
    @pulumi.getter(name="supportedInputStorageFormats")
    def supported_input_storage_formats(self) -> pulumi.Output[Sequence[str]]:
        """
        The formats this Model supports in BatchPredictionJob.input_config. If PredictSchemata.instance_schema_uri exists, the instances should be given as per that schema. The possible formats are: * `jsonl` The JSON Lines format, where each instance is a single line. Uses GcsSource. * `csv` The CSV format, where each instance is a single comma-separated line. The first line in the file is the header, containing comma-separated field names. Uses GcsSource. * `tf-record` The TFRecord format, where each instance is a single record in tfrecord syntax. Uses GcsSource. * `tf-record-gzip` Similar to `tf-record`, but the file is gzipped. Uses GcsSource. * `bigquery` Each instance is a single row in BigQuery. Uses BigQuerySource. * `file-list` Each line of the file is the location of an instance to process, uses `gcs_source` field of the InputConfig object. If this Model doesn't support any of these formats it means it cannot be used with a BatchPredictionJob. However, if it has supported_deployment_resources_types, it could serve online predictions by using PredictionService.Predict or PredictionService.Explain.
        """
        return pulumi.get(self, "supported_input_storage_formats")

    @property
    @pulumi.getter(name="supportedOutputStorageFormats")
    def supported_output_storage_formats(self) -> pulumi.Output[Sequence[str]]:
        """
        The formats this Model supports in BatchPredictionJob.output_config. If both PredictSchemata.instance_schema_uri and PredictSchemata.prediction_schema_uri exist, the predictions are returned together with their instances. In other words, the prediction has the original instance data first, followed by the actual prediction content (as per the schema). The possible formats are: * `jsonl` The JSON Lines format, where each prediction is a single line. Uses GcsDestination. * `csv` The CSV format, where each prediction is a single comma-separated line. The first line in the file is the header, containing comma-separated field names. Uses GcsDestination. * `bigquery` Each prediction is a single row in a BigQuery table, uses BigQueryDestination . If this Model doesn't support any of these formats it means it cannot be used with a BatchPredictionJob. However, if it has supported_deployment_resources_types, it could serve online predictions by using PredictionService.Predict or PredictionService.Explain.
        """
        return pulumi.get(self, "supported_output_storage_formats")

    @property
    @pulumi.getter(name="trainingPipeline")
    def training_pipeline(self) -> pulumi.Output[str]:
        """
        The resource name of the TrainingPipeline that uploaded this Model, if any.
        """
        return pulumi.get(self, "training_pipeline")

    @property
    @pulumi.getter(name="updateTime")
    def update_time(self) -> pulumi.Output[str]:
        """
        Timestamp when this Model was most recently updated.
        """
        return pulumi.get(self, "update_time")

    @property
    @pulumi.getter(name="versionAliases")
    def version_aliases(self) -> pulumi.Output[Sequence[str]]:
        """
        User provided version aliases so that a model version can be referenced via alias (i.e. `projects/{project}/locations/{location}/models/{model_id}@{version_alias}` instead of auto-generated version id (i.e. `projects/{project}/locations/{location}/models/{model_id}@{version_id})`. The format is a-z{0,126}[a-z0-9] to distinguish from version_id. A default version alias will be created for the first version of the model, and there must be exactly one default version alias for a model.
        """
        return pulumi.get(self, "version_aliases")

    @property
    @pulumi.getter(name="versionCreateTime")
    def version_create_time(self) -> pulumi.Output[str]:
        """
        Timestamp when this version was created.
        """
        return pulumi.get(self, "version_create_time")

    @property
    @pulumi.getter(name="versionDescription")
    def version_description(self) -> pulumi.Output[str]:
        """
        The description of this version.
        """
        return pulumi.get(self, "version_description")

    @property
    @pulumi.getter(name="versionId")
    def version_id(self) -> pulumi.Output[str]:
        """
        Immutable. The version ID of the model. A new version is committed when a new model version is uploaded or trained under an existing model id. It is an auto-incrementing decimal number in string representation.
        """
        return pulumi.get(self, "version_id")

    @property
    @pulumi.getter(name="versionUpdateTime")
    def version_update_time(self) -> pulumi.Output[str]:
        """
        Timestamp when this version was most recently updated.
        """
        return pulumi.get(self, "version_update_time")


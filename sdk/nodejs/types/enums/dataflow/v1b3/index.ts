// *** WARNING: this file was generated by the Pulumi SDK Generator. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***


export const AutoscalingSettingsAlgorithm = {
    /**
     * The algorithm is unknown, or unspecified.
     */
    AutoscalingAlgorithmUnknown: "AUTOSCALING_ALGORITHM_UNKNOWN",
    /**
     * Disable autoscaling.
     */
    AutoscalingAlgorithmNone: "AUTOSCALING_ALGORITHM_NONE",
    /**
     * Increase worker count over time to reduce job execution time.
     */
    AutoscalingAlgorithmBasic: "AUTOSCALING_ALGORITHM_BASIC",
} as const;

/**
 * The algorithm to use for autoscaling.
 */
export type AutoscalingSettingsAlgorithm = (typeof AutoscalingSettingsAlgorithm)[keyof typeof AutoscalingSettingsAlgorithm];

export const DataSamplingConfigBehaviorsItem = {
    /**
     * If given, has no effect on sampling behavior. Used as an unknown or unset sentinel value.
     */
    DataSamplingBehaviorUnspecified: "DATA_SAMPLING_BEHAVIOR_UNSPECIFIED",
    /**
     * When given, disables element sampling. Has same behavior as not setting the behavior.
     */
    Disabled: "DISABLED",
    /**
     * When given, enables sampling in-flight from all PCollections.
     */
    AlwaysOn: "ALWAYS_ON",
    /**
     * When given, enables sampling input elements when a user-defined DoFn causes an exception.
     */
    Exceptions: "EXCEPTIONS",
} as const;

export type DataSamplingConfigBehaviorsItem = (typeof DataSamplingConfigBehaviorsItem)[keyof typeof DataSamplingConfigBehaviorsItem];

export const EnvironmentFlexResourceSchedulingGoal = {
    /**
     * Run in the default mode.
     */
    FlexrsUnspecified: "FLEXRS_UNSPECIFIED",
    /**
     * Optimize for lower execution time.
     */
    FlexrsSpeedOptimized: "FLEXRS_SPEED_OPTIMIZED",
    /**
     * Optimize for lower cost.
     */
    FlexrsCostOptimized: "FLEXRS_COST_OPTIMIZED",
} as const;

/**
 * Which Flexible Resource Scheduling mode to run in.
 */
export type EnvironmentFlexResourceSchedulingGoal = (typeof EnvironmentFlexResourceSchedulingGoal)[keyof typeof EnvironmentFlexResourceSchedulingGoal];

export const ExecutionStageStateExecutionStageState = {
    /**
     * The job's run state isn't specified.
     */
    JobStateUnknown: "JOB_STATE_UNKNOWN",
    /**
     * `JOB_STATE_STOPPED` indicates that the job has not yet started to run.
     */
    JobStateStopped: "JOB_STATE_STOPPED",
    /**
     * `JOB_STATE_RUNNING` indicates that the job is currently running.
     */
    JobStateRunning: "JOB_STATE_RUNNING",
    /**
     * `JOB_STATE_DONE` indicates that the job has successfully completed. This is a terminal job state. This state may be set by the Cloud Dataflow service, as a transition from `JOB_STATE_RUNNING`. It may also be set via a Cloud Dataflow `UpdateJob` call, if the job has not yet reached a terminal state.
     */
    JobStateDone: "JOB_STATE_DONE",
    /**
     * `JOB_STATE_FAILED` indicates that the job has failed. This is a terminal job state. This state may only be set by the Cloud Dataflow service, and only as a transition from `JOB_STATE_RUNNING`.
     */
    JobStateFailed: "JOB_STATE_FAILED",
    /**
     * `JOB_STATE_CANCELLED` indicates that the job has been explicitly cancelled. This is a terminal job state. This state may only be set via a Cloud Dataflow `UpdateJob` call, and only if the job has not yet reached another terminal state.
     */
    JobStateCancelled: "JOB_STATE_CANCELLED",
    /**
     * `JOB_STATE_UPDATED` indicates that the job was successfully updated, meaning that this job was stopped and another job was started, inheriting state from this one. This is a terminal job state. This state may only be set by the Cloud Dataflow service, and only as a transition from `JOB_STATE_RUNNING`.
     */
    JobStateUpdated: "JOB_STATE_UPDATED",
    /**
     * `JOB_STATE_DRAINING` indicates that the job is in the process of draining. A draining job has stopped pulling from its input sources and is processing any data that remains in-flight. This state may be set via a Cloud Dataflow `UpdateJob` call, but only as a transition from `JOB_STATE_RUNNING`. Jobs that are draining may only transition to `JOB_STATE_DRAINED`, `JOB_STATE_CANCELLED`, or `JOB_STATE_FAILED`.
     */
    JobStateDraining: "JOB_STATE_DRAINING",
    /**
     * `JOB_STATE_DRAINED` indicates that the job has been drained. A drained job terminated by stopping pulling from its input sources and processing any data that remained in-flight when draining was requested. This state is a terminal state, may only be set by the Cloud Dataflow service, and only as a transition from `JOB_STATE_DRAINING`.
     */
    JobStateDrained: "JOB_STATE_DRAINED",
    /**
     * `JOB_STATE_PENDING` indicates that the job has been created but is not yet running. Jobs that are pending may only transition to `JOB_STATE_RUNNING`, or `JOB_STATE_FAILED`.
     */
    JobStatePending: "JOB_STATE_PENDING",
    /**
     * `JOB_STATE_CANCELLING` indicates that the job has been explicitly cancelled and is in the process of stopping. Jobs that are cancelling may only transition to `JOB_STATE_CANCELLED` or `JOB_STATE_FAILED`.
     */
    JobStateCancelling: "JOB_STATE_CANCELLING",
    /**
     * `JOB_STATE_QUEUED` indicates that the job has been created but is being delayed until launch. Jobs that are queued may only transition to `JOB_STATE_PENDING` or `JOB_STATE_CANCELLED`.
     */
    JobStateQueued: "JOB_STATE_QUEUED",
    /**
     * `JOB_STATE_RESOURCE_CLEANING_UP` indicates that the batch job's associated resources are currently being cleaned up after a successful run. Currently, this is an opt-in feature, please reach out to Cloud support team if you are interested.
     */
    JobStateResourceCleaningUp: "JOB_STATE_RESOURCE_CLEANING_UP",
} as const;

/**
 * Executions stage states allow the same set of values as JobState.
 */
export type ExecutionStageStateExecutionStageState = (typeof ExecutionStageStateExecutionStageState)[keyof typeof ExecutionStageStateExecutionStageState];

export const ExecutionStageSummaryKind = {
    /**
     * Unrecognized transform type.
     */
    UnknownKind: "UNKNOWN_KIND",
    /**
     * ParDo transform.
     */
    ParDoKind: "PAR_DO_KIND",
    /**
     * Group By Key transform.
     */
    GroupByKeyKind: "GROUP_BY_KEY_KIND",
    /**
     * Flatten transform.
     */
    FlattenKind: "FLATTEN_KIND",
    /**
     * Read transform.
     */
    ReadKind: "READ_KIND",
    /**
     * Write transform.
     */
    WriteKind: "WRITE_KIND",
    /**
     * Constructs from a constant value, such as with Create.of.
     */
    ConstantKind: "CONSTANT_KIND",
    /**
     * Creates a Singleton view of a collection.
     */
    SingletonKind: "SINGLETON_KIND",
    /**
     * Opening or closing a shuffle session, often as part of a GroupByKey.
     */
    ShuffleKind: "SHUFFLE_KIND",
} as const;

/**
 * Type of transform this stage is executing.
 */
export type ExecutionStageSummaryKind = (typeof ExecutionStageSummaryKind)[keyof typeof ExecutionStageSummaryKind];

export const JobCurrentState = {
    /**
     * The job's run state isn't specified.
     */
    JobStateUnknown: "JOB_STATE_UNKNOWN",
    /**
     * `JOB_STATE_STOPPED` indicates that the job has not yet started to run.
     */
    JobStateStopped: "JOB_STATE_STOPPED",
    /**
     * `JOB_STATE_RUNNING` indicates that the job is currently running.
     */
    JobStateRunning: "JOB_STATE_RUNNING",
    /**
     * `JOB_STATE_DONE` indicates that the job has successfully completed. This is a terminal job state. This state may be set by the Cloud Dataflow service, as a transition from `JOB_STATE_RUNNING`. It may also be set via a Cloud Dataflow `UpdateJob` call, if the job has not yet reached a terminal state.
     */
    JobStateDone: "JOB_STATE_DONE",
    /**
     * `JOB_STATE_FAILED` indicates that the job has failed. This is a terminal job state. This state may only be set by the Cloud Dataflow service, and only as a transition from `JOB_STATE_RUNNING`.
     */
    JobStateFailed: "JOB_STATE_FAILED",
    /**
     * `JOB_STATE_CANCELLED` indicates that the job has been explicitly cancelled. This is a terminal job state. This state may only be set via a Cloud Dataflow `UpdateJob` call, and only if the job has not yet reached another terminal state.
     */
    JobStateCancelled: "JOB_STATE_CANCELLED",
    /**
     * `JOB_STATE_UPDATED` indicates that the job was successfully updated, meaning that this job was stopped and another job was started, inheriting state from this one. This is a terminal job state. This state may only be set by the Cloud Dataflow service, and only as a transition from `JOB_STATE_RUNNING`.
     */
    JobStateUpdated: "JOB_STATE_UPDATED",
    /**
     * `JOB_STATE_DRAINING` indicates that the job is in the process of draining. A draining job has stopped pulling from its input sources and is processing any data that remains in-flight. This state may be set via a Cloud Dataflow `UpdateJob` call, but only as a transition from `JOB_STATE_RUNNING`. Jobs that are draining may only transition to `JOB_STATE_DRAINED`, `JOB_STATE_CANCELLED`, or `JOB_STATE_FAILED`.
     */
    JobStateDraining: "JOB_STATE_DRAINING",
    /**
     * `JOB_STATE_DRAINED` indicates that the job has been drained. A drained job terminated by stopping pulling from its input sources and processing any data that remained in-flight when draining was requested. This state is a terminal state, may only be set by the Cloud Dataflow service, and only as a transition from `JOB_STATE_DRAINING`.
     */
    JobStateDrained: "JOB_STATE_DRAINED",
    /**
     * `JOB_STATE_PENDING` indicates that the job has been created but is not yet running. Jobs that are pending may only transition to `JOB_STATE_RUNNING`, or `JOB_STATE_FAILED`.
     */
    JobStatePending: "JOB_STATE_PENDING",
    /**
     * `JOB_STATE_CANCELLING` indicates that the job has been explicitly cancelled and is in the process of stopping. Jobs that are cancelling may only transition to `JOB_STATE_CANCELLED` or `JOB_STATE_FAILED`.
     */
    JobStateCancelling: "JOB_STATE_CANCELLING",
    /**
     * `JOB_STATE_QUEUED` indicates that the job has been created but is being delayed until launch. Jobs that are queued may only transition to `JOB_STATE_PENDING` or `JOB_STATE_CANCELLED`.
     */
    JobStateQueued: "JOB_STATE_QUEUED",
    /**
     * `JOB_STATE_RESOURCE_CLEANING_UP` indicates that the batch job's associated resources are currently being cleaned up after a successful run. Currently, this is an opt-in feature, please reach out to Cloud support team if you are interested.
     */
    JobStateResourceCleaningUp: "JOB_STATE_RESOURCE_CLEANING_UP",
} as const;

/**
 * The current state of the job. Jobs are created in the `JOB_STATE_STOPPED` state unless otherwise specified. A job in the `JOB_STATE_RUNNING` state may asynchronously enter a terminal state. After a job has reached a terminal state, no further state updates may be made. This field might be mutated by the Dataflow service; callers cannot mutate it.
 */
export type JobCurrentState = (typeof JobCurrentState)[keyof typeof JobCurrentState];

export const JobRequestedState = {
    /**
     * The job's run state isn't specified.
     */
    JobStateUnknown: "JOB_STATE_UNKNOWN",
    /**
     * `JOB_STATE_STOPPED` indicates that the job has not yet started to run.
     */
    JobStateStopped: "JOB_STATE_STOPPED",
    /**
     * `JOB_STATE_RUNNING` indicates that the job is currently running.
     */
    JobStateRunning: "JOB_STATE_RUNNING",
    /**
     * `JOB_STATE_DONE` indicates that the job has successfully completed. This is a terminal job state. This state may be set by the Cloud Dataflow service, as a transition from `JOB_STATE_RUNNING`. It may also be set via a Cloud Dataflow `UpdateJob` call, if the job has not yet reached a terminal state.
     */
    JobStateDone: "JOB_STATE_DONE",
    /**
     * `JOB_STATE_FAILED` indicates that the job has failed. This is a terminal job state. This state may only be set by the Cloud Dataflow service, and only as a transition from `JOB_STATE_RUNNING`.
     */
    JobStateFailed: "JOB_STATE_FAILED",
    /**
     * `JOB_STATE_CANCELLED` indicates that the job has been explicitly cancelled. This is a terminal job state. This state may only be set via a Cloud Dataflow `UpdateJob` call, and only if the job has not yet reached another terminal state.
     */
    JobStateCancelled: "JOB_STATE_CANCELLED",
    /**
     * `JOB_STATE_UPDATED` indicates that the job was successfully updated, meaning that this job was stopped and another job was started, inheriting state from this one. This is a terminal job state. This state may only be set by the Cloud Dataflow service, and only as a transition from `JOB_STATE_RUNNING`.
     */
    JobStateUpdated: "JOB_STATE_UPDATED",
    /**
     * `JOB_STATE_DRAINING` indicates that the job is in the process of draining. A draining job has stopped pulling from its input sources and is processing any data that remains in-flight. This state may be set via a Cloud Dataflow `UpdateJob` call, but only as a transition from `JOB_STATE_RUNNING`. Jobs that are draining may only transition to `JOB_STATE_DRAINED`, `JOB_STATE_CANCELLED`, or `JOB_STATE_FAILED`.
     */
    JobStateDraining: "JOB_STATE_DRAINING",
    /**
     * `JOB_STATE_DRAINED` indicates that the job has been drained. A drained job terminated by stopping pulling from its input sources and processing any data that remained in-flight when draining was requested. This state is a terminal state, may only be set by the Cloud Dataflow service, and only as a transition from `JOB_STATE_DRAINING`.
     */
    JobStateDrained: "JOB_STATE_DRAINED",
    /**
     * `JOB_STATE_PENDING` indicates that the job has been created but is not yet running. Jobs that are pending may only transition to `JOB_STATE_RUNNING`, or `JOB_STATE_FAILED`.
     */
    JobStatePending: "JOB_STATE_PENDING",
    /**
     * `JOB_STATE_CANCELLING` indicates that the job has been explicitly cancelled and is in the process of stopping. Jobs that are cancelling may only transition to `JOB_STATE_CANCELLED` or `JOB_STATE_FAILED`.
     */
    JobStateCancelling: "JOB_STATE_CANCELLING",
    /**
     * `JOB_STATE_QUEUED` indicates that the job has been created but is being delayed until launch. Jobs that are queued may only transition to `JOB_STATE_PENDING` or `JOB_STATE_CANCELLED`.
     */
    JobStateQueued: "JOB_STATE_QUEUED",
    /**
     * `JOB_STATE_RESOURCE_CLEANING_UP` indicates that the batch job's associated resources are currently being cleaned up after a successful run. Currently, this is an opt-in feature, please reach out to Cloud support team if you are interested.
     */
    JobStateResourceCleaningUp: "JOB_STATE_RESOURCE_CLEANING_UP",
} as const;

/**
 * The job's requested state. Applies to `UpdateJob` requests. Set `requested_state` with `UpdateJob` requests to switch between the states `JOB_STATE_STOPPED` and `JOB_STATE_RUNNING`. You can also use `UpdateJob` requests to change a job's state from `JOB_STATE_RUNNING` to `JOB_STATE_CANCELLED`, `JOB_STATE_DONE`, or `JOB_STATE_DRAINED`. These states irrevocably terminate the job if it hasn't already reached a terminal state. This field has no effect on `CreateJob` requests.
 */
export type JobRequestedState = (typeof JobRequestedState)[keyof typeof JobRequestedState];

export const JobType = {
    /**
     * The type of the job is unspecified, or unknown.
     */
    JobTypeUnknown: "JOB_TYPE_UNKNOWN",
    /**
     * A batch job with a well-defined end point: data is read, data is processed, data is written, and the job is done.
     */
    JobTypeBatch: "JOB_TYPE_BATCH",
    /**
     * A continuously streaming job with no end: data is read, processed, and written continuously.
     */
    JobTypeStreaming: "JOB_TYPE_STREAMING",
} as const;

/**
 * The type of Dataflow job.
 */
export type JobType = (typeof JobType)[keyof typeof JobType];

export const RuntimeEnvironmentIpConfiguration = {
    /**
     * The configuration is unknown, or unspecified.
     */
    WorkerIpUnspecified: "WORKER_IP_UNSPECIFIED",
    /**
     * Workers should have public IP addresses.
     */
    WorkerIpPublic: "WORKER_IP_PUBLIC",
    /**
     * Workers should have private IP addresses.
     */
    WorkerIpPrivate: "WORKER_IP_PRIVATE",
} as const;

/**
 * Optional. Configuration for VM IPs.
 */
export type RuntimeEnvironmentIpConfiguration = (typeof RuntimeEnvironmentIpConfiguration)[keyof typeof RuntimeEnvironmentIpConfiguration];

export const SdkVersionSdkSupportStatus = {
    /**
     * Cloud Dataflow is unaware of this version.
     */
    Unknown: "UNKNOWN",
    /**
     * This is a known version of an SDK, and is supported.
     */
    Supported: "SUPPORTED",
    /**
     * A newer version of the SDK family exists, and an update is recommended.
     */
    Stale: "STALE",
    /**
     * This version of the SDK is deprecated and will eventually be unsupported.
     */
    Deprecated: "DEPRECATED",
    /**
     * Support for this SDK version has ended and it should no longer be used.
     */
    Unsupported: "UNSUPPORTED",
} as const;

/**
 * The support status for this SDK version.
 */
export type SdkVersionSdkSupportStatus = (typeof SdkVersionSdkSupportStatus)[keyof typeof SdkVersionSdkSupportStatus];

export const TransformSummaryKind = {
    /**
     * Unrecognized transform type.
     */
    UnknownKind: "UNKNOWN_KIND",
    /**
     * ParDo transform.
     */
    ParDoKind: "PAR_DO_KIND",
    /**
     * Group By Key transform.
     */
    GroupByKeyKind: "GROUP_BY_KEY_KIND",
    /**
     * Flatten transform.
     */
    FlattenKind: "FLATTEN_KIND",
    /**
     * Read transform.
     */
    ReadKind: "READ_KIND",
    /**
     * Write transform.
     */
    WriteKind: "WRITE_KIND",
    /**
     * Constructs from a constant value, such as with Create.of.
     */
    ConstantKind: "CONSTANT_KIND",
    /**
     * Creates a Singleton view of a collection.
     */
    SingletonKind: "SINGLETON_KIND",
    /**
     * Opening or closing a shuffle session, often as part of a GroupByKey.
     */
    ShuffleKind: "SHUFFLE_KIND",
} as const;

/**
 * Type of transform.
 */
export type TransformSummaryKind = (typeof TransformSummaryKind)[keyof typeof TransformSummaryKind];

export const WorkerPoolDefaultPackageSet = {
    /**
     * The default set of packages to stage is unknown, or unspecified.
     */
    DefaultPackageSetUnknown: "DEFAULT_PACKAGE_SET_UNKNOWN",
    /**
     * Indicates that no packages should be staged at the worker unless explicitly specified by the job.
     */
    DefaultPackageSetNone: "DEFAULT_PACKAGE_SET_NONE",
    /**
     * Stage packages typically useful to workers written in Java.
     */
    DefaultPackageSetJava: "DEFAULT_PACKAGE_SET_JAVA",
    /**
     * Stage packages typically useful to workers written in Python.
     */
    DefaultPackageSetPython: "DEFAULT_PACKAGE_SET_PYTHON",
} as const;

/**
 * The default package set to install. This allows the service to select a default set of packages which are useful to worker harnesses written in a particular language.
 */
export type WorkerPoolDefaultPackageSet = (typeof WorkerPoolDefaultPackageSet)[keyof typeof WorkerPoolDefaultPackageSet];

export const WorkerPoolIpConfiguration = {
    /**
     * The configuration is unknown, or unspecified.
     */
    WorkerIpUnspecified: "WORKER_IP_UNSPECIFIED",
    /**
     * Workers should have public IP addresses.
     */
    WorkerIpPublic: "WORKER_IP_PUBLIC",
    /**
     * Workers should have private IP addresses.
     */
    WorkerIpPrivate: "WORKER_IP_PRIVATE",
} as const;

/**
 * Configuration for VM IPs.
 */
export type WorkerPoolIpConfiguration = (typeof WorkerPoolIpConfiguration)[keyof typeof WorkerPoolIpConfiguration];

export const WorkerPoolTeardownPolicy = {
    /**
     * The teardown policy isn't specified, or is unknown.
     */
    TeardownPolicyUnknown: "TEARDOWN_POLICY_UNKNOWN",
    /**
     * Always teardown the resource.
     */
    TeardownAlways: "TEARDOWN_ALWAYS",
    /**
     * Teardown the resource on success. This is useful for debugging failures.
     */
    TeardownOnSuccess: "TEARDOWN_ON_SUCCESS",
    /**
     * Never teardown the resource. This is useful for debugging and development.
     */
    TeardownNever: "TEARDOWN_NEVER",
} as const;

/**
 * Sets the policy for determining when to turndown worker pool. Allowed values are: `TEARDOWN_ALWAYS`, `TEARDOWN_ON_SUCCESS`, and `TEARDOWN_NEVER`. `TEARDOWN_ALWAYS` means workers are always torn down regardless of whether the job succeeds. `TEARDOWN_ON_SUCCESS` means workers are torn down if the job succeeds. `TEARDOWN_NEVER` means the workers are never torn down. If the workers are not torn down by the service, they will continue to run and use Google Compute Engine VM resources in the user's project until they are explicitly terminated by the user. Because of this, Google recommends using the `TEARDOWN_ALWAYS` policy except for small, manually supervised test jobs. If unknown or unspecified, the service will attempt to choose a reasonable default.
 */
export type WorkerPoolTeardownPolicy = (typeof WorkerPoolTeardownPolicy)[keyof typeof WorkerPoolTeardownPolicy];

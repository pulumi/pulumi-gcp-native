// Code generated by the Pulumi SDK Generator DO NOT EDIT.
// *** WARNING: Do not edit by hand unless you're certain you know what you are doing! ***

package v1beta1

import (
	"context"
	"reflect"

	"github.com/pulumi/pulumi-google-native/sdk/go/google/internal"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

var _ = internal.GetEnvOrDefault

// Parameters that configure the active learning pipeline. Active learning will label the data incrementally by several iterations. For every iteration, it will select a batch of data based on the sampling strategy.
type GoogleCloudAiplatformV1beta1ActiveLearningConfig struct {
	// Max number of human labeled DataItems.
	MaxDataItemCount *string `pulumi:"maxDataItemCount"`
	// Max percent of total DataItems for human labeling.
	MaxDataItemPercentage *int `pulumi:"maxDataItemPercentage"`
	// Active learning data sampling config. For every active learning labeling iteration, it will select a batch of data based on the sampling strategy.
	SampleConfig *GoogleCloudAiplatformV1beta1SampleConfig `pulumi:"sampleConfig"`
	// CMLE training config. For every active learning labeling iteration, system will train a machine learning model on CMLE. The trained model will be used by data sampling algorithm to select DataItems.
	TrainingConfig *GoogleCloudAiplatformV1beta1TrainingConfig `pulumi:"trainingConfig"`
}

// GoogleCloudAiplatformV1beta1ActiveLearningConfigInput is an input type that accepts GoogleCloudAiplatformV1beta1ActiveLearningConfigArgs and GoogleCloudAiplatformV1beta1ActiveLearningConfigOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1ActiveLearningConfigInput` via:
//
//	GoogleCloudAiplatformV1beta1ActiveLearningConfigArgs{...}
type GoogleCloudAiplatformV1beta1ActiveLearningConfigInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1ActiveLearningConfigOutput() GoogleCloudAiplatformV1beta1ActiveLearningConfigOutput
	ToGoogleCloudAiplatformV1beta1ActiveLearningConfigOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1ActiveLearningConfigOutput
}

// Parameters that configure the active learning pipeline. Active learning will label the data incrementally by several iterations. For every iteration, it will select a batch of data based on the sampling strategy.
type GoogleCloudAiplatformV1beta1ActiveLearningConfigArgs struct {
	// Max number of human labeled DataItems.
	MaxDataItemCount pulumi.StringPtrInput `pulumi:"maxDataItemCount"`
	// Max percent of total DataItems for human labeling.
	MaxDataItemPercentage pulumi.IntPtrInput `pulumi:"maxDataItemPercentage"`
	// Active learning data sampling config. For every active learning labeling iteration, it will select a batch of data based on the sampling strategy.
	SampleConfig GoogleCloudAiplatformV1beta1SampleConfigPtrInput `pulumi:"sampleConfig"`
	// CMLE training config. For every active learning labeling iteration, system will train a machine learning model on CMLE. The trained model will be used by data sampling algorithm to select DataItems.
	TrainingConfig GoogleCloudAiplatformV1beta1TrainingConfigPtrInput `pulumi:"trainingConfig"`
}

func (GoogleCloudAiplatformV1beta1ActiveLearningConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ActiveLearningConfig)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1ActiveLearningConfigArgs) ToGoogleCloudAiplatformV1beta1ActiveLearningConfigOutput() GoogleCloudAiplatformV1beta1ActiveLearningConfigOutput {
	return i.ToGoogleCloudAiplatformV1beta1ActiveLearningConfigOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1ActiveLearningConfigArgs) ToGoogleCloudAiplatformV1beta1ActiveLearningConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ActiveLearningConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ActiveLearningConfigOutput)
}

func (i GoogleCloudAiplatformV1beta1ActiveLearningConfigArgs) ToGoogleCloudAiplatformV1beta1ActiveLearningConfigPtrOutput() GoogleCloudAiplatformV1beta1ActiveLearningConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1ActiveLearningConfigPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1ActiveLearningConfigArgs) ToGoogleCloudAiplatformV1beta1ActiveLearningConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ActiveLearningConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ActiveLearningConfigOutput).ToGoogleCloudAiplatformV1beta1ActiveLearningConfigPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1ActiveLearningConfigPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1ActiveLearningConfigArgs, GoogleCloudAiplatformV1beta1ActiveLearningConfigPtr and GoogleCloudAiplatformV1beta1ActiveLearningConfigPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1ActiveLearningConfigPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1ActiveLearningConfigArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1ActiveLearningConfigPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1ActiveLearningConfigPtrOutput() GoogleCloudAiplatformV1beta1ActiveLearningConfigPtrOutput
	ToGoogleCloudAiplatformV1beta1ActiveLearningConfigPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1ActiveLearningConfigPtrOutput
}

type googleCloudAiplatformV1beta1ActiveLearningConfigPtrType GoogleCloudAiplatformV1beta1ActiveLearningConfigArgs

func GoogleCloudAiplatformV1beta1ActiveLearningConfigPtr(v *GoogleCloudAiplatformV1beta1ActiveLearningConfigArgs) GoogleCloudAiplatformV1beta1ActiveLearningConfigPtrInput {
	return (*googleCloudAiplatformV1beta1ActiveLearningConfigPtrType)(v)
}

func (*googleCloudAiplatformV1beta1ActiveLearningConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1ActiveLearningConfig)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1ActiveLearningConfigPtrType) ToGoogleCloudAiplatformV1beta1ActiveLearningConfigPtrOutput() GoogleCloudAiplatformV1beta1ActiveLearningConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1ActiveLearningConfigPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1ActiveLearningConfigPtrType) ToGoogleCloudAiplatformV1beta1ActiveLearningConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ActiveLearningConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ActiveLearningConfigPtrOutput)
}

// Parameters that configure the active learning pipeline. Active learning will label the data incrementally by several iterations. For every iteration, it will select a batch of data based on the sampling strategy.
type GoogleCloudAiplatformV1beta1ActiveLearningConfigOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ActiveLearningConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ActiveLearningConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ActiveLearningConfigOutput) ToGoogleCloudAiplatformV1beta1ActiveLearningConfigOutput() GoogleCloudAiplatformV1beta1ActiveLearningConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ActiveLearningConfigOutput) ToGoogleCloudAiplatformV1beta1ActiveLearningConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ActiveLearningConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ActiveLearningConfigOutput) ToGoogleCloudAiplatformV1beta1ActiveLearningConfigPtrOutput() GoogleCloudAiplatformV1beta1ActiveLearningConfigPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1ActiveLearningConfigPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1ActiveLearningConfigOutput) ToGoogleCloudAiplatformV1beta1ActiveLearningConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ActiveLearningConfigPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1ActiveLearningConfig) *GoogleCloudAiplatformV1beta1ActiveLearningConfig {
		return &v
	}).(GoogleCloudAiplatformV1beta1ActiveLearningConfigPtrOutput)
}

// Max number of human labeled DataItems.
func (o GoogleCloudAiplatformV1beta1ActiveLearningConfigOutput) MaxDataItemCount() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ActiveLearningConfig) *string { return v.MaxDataItemCount }).(pulumi.StringPtrOutput)
}

// Max percent of total DataItems for human labeling.
func (o GoogleCloudAiplatformV1beta1ActiveLearningConfigOutput) MaxDataItemPercentage() pulumi.IntPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ActiveLearningConfig) *int { return v.MaxDataItemPercentage }).(pulumi.IntPtrOutput)
}

// Active learning data sampling config. For every active learning labeling iteration, it will select a batch of data based on the sampling strategy.
func (o GoogleCloudAiplatformV1beta1ActiveLearningConfigOutput) SampleConfig() GoogleCloudAiplatformV1beta1SampleConfigPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ActiveLearningConfig) *GoogleCloudAiplatformV1beta1SampleConfig {
		return v.SampleConfig
	}).(GoogleCloudAiplatformV1beta1SampleConfigPtrOutput)
}

// CMLE training config. For every active learning labeling iteration, system will train a machine learning model on CMLE. The trained model will be used by data sampling algorithm to select DataItems.
func (o GoogleCloudAiplatformV1beta1ActiveLearningConfigOutput) TrainingConfig() GoogleCloudAiplatformV1beta1TrainingConfigPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ActiveLearningConfig) *GoogleCloudAiplatformV1beta1TrainingConfig {
		return v.TrainingConfig
	}).(GoogleCloudAiplatformV1beta1TrainingConfigPtrOutput)
}

type GoogleCloudAiplatformV1beta1ActiveLearningConfigPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ActiveLearningConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1ActiveLearningConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ActiveLearningConfigPtrOutput) ToGoogleCloudAiplatformV1beta1ActiveLearningConfigPtrOutput() GoogleCloudAiplatformV1beta1ActiveLearningConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ActiveLearningConfigPtrOutput) ToGoogleCloudAiplatformV1beta1ActiveLearningConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ActiveLearningConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ActiveLearningConfigPtrOutput) Elem() GoogleCloudAiplatformV1beta1ActiveLearningConfigOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ActiveLearningConfig) GoogleCloudAiplatformV1beta1ActiveLearningConfig {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1ActiveLearningConfig
		return ret
	}).(GoogleCloudAiplatformV1beta1ActiveLearningConfigOutput)
}

// Max number of human labeled DataItems.
func (o GoogleCloudAiplatformV1beta1ActiveLearningConfigPtrOutput) MaxDataItemCount() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ActiveLearningConfig) *string {
		if v == nil {
			return nil
		}
		return v.MaxDataItemCount
	}).(pulumi.StringPtrOutput)
}

// Max percent of total DataItems for human labeling.
func (o GoogleCloudAiplatformV1beta1ActiveLearningConfigPtrOutput) MaxDataItemPercentage() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ActiveLearningConfig) *int {
		if v == nil {
			return nil
		}
		return v.MaxDataItemPercentage
	}).(pulumi.IntPtrOutput)
}

// Active learning data sampling config. For every active learning labeling iteration, it will select a batch of data based on the sampling strategy.
func (o GoogleCloudAiplatformV1beta1ActiveLearningConfigPtrOutput) SampleConfig() GoogleCloudAiplatformV1beta1SampleConfigPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ActiveLearningConfig) *GoogleCloudAiplatformV1beta1SampleConfig {
		if v == nil {
			return nil
		}
		return v.SampleConfig
	}).(GoogleCloudAiplatformV1beta1SampleConfigPtrOutput)
}

// CMLE training config. For every active learning labeling iteration, system will train a machine learning model on CMLE. The trained model will be used by data sampling algorithm to select DataItems.
func (o GoogleCloudAiplatformV1beta1ActiveLearningConfigPtrOutput) TrainingConfig() GoogleCloudAiplatformV1beta1TrainingConfigPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ActiveLearningConfig) *GoogleCloudAiplatformV1beta1TrainingConfig {
		if v == nil {
			return nil
		}
		return v.TrainingConfig
	}).(GoogleCloudAiplatformV1beta1TrainingConfigPtrOutput)
}

// Parameters that configure the active learning pipeline. Active learning will label the data incrementally by several iterations. For every iteration, it will select a batch of data based on the sampling strategy.
type GoogleCloudAiplatformV1beta1ActiveLearningConfigResponse struct {
	// Max number of human labeled DataItems.
	MaxDataItemCount string `pulumi:"maxDataItemCount"`
	// Max percent of total DataItems for human labeling.
	MaxDataItemPercentage int `pulumi:"maxDataItemPercentage"`
	// Active learning data sampling config. For every active learning labeling iteration, it will select a batch of data based on the sampling strategy.
	SampleConfig GoogleCloudAiplatformV1beta1SampleConfigResponse `pulumi:"sampleConfig"`
	// CMLE training config. For every active learning labeling iteration, system will train a machine learning model on CMLE. The trained model will be used by data sampling algorithm to select DataItems.
	TrainingConfig GoogleCloudAiplatformV1beta1TrainingConfigResponse `pulumi:"trainingConfig"`
}

// Parameters that configure the active learning pipeline. Active learning will label the data incrementally by several iterations. For every iteration, it will select a batch of data based on the sampling strategy.
type GoogleCloudAiplatformV1beta1ActiveLearningConfigResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ActiveLearningConfigResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ActiveLearningConfigResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ActiveLearningConfigResponseOutput) ToGoogleCloudAiplatformV1beta1ActiveLearningConfigResponseOutput() GoogleCloudAiplatformV1beta1ActiveLearningConfigResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ActiveLearningConfigResponseOutput) ToGoogleCloudAiplatformV1beta1ActiveLearningConfigResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ActiveLearningConfigResponseOutput {
	return o
}

// Max number of human labeled DataItems.
func (o GoogleCloudAiplatformV1beta1ActiveLearningConfigResponseOutput) MaxDataItemCount() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ActiveLearningConfigResponse) string { return v.MaxDataItemCount }).(pulumi.StringOutput)
}

// Max percent of total DataItems for human labeling.
func (o GoogleCloudAiplatformV1beta1ActiveLearningConfigResponseOutput) MaxDataItemPercentage() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ActiveLearningConfigResponse) int { return v.MaxDataItemPercentage }).(pulumi.IntOutput)
}

// Active learning data sampling config. For every active learning labeling iteration, it will select a batch of data based on the sampling strategy.
func (o GoogleCloudAiplatformV1beta1ActiveLearningConfigResponseOutput) SampleConfig() GoogleCloudAiplatformV1beta1SampleConfigResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ActiveLearningConfigResponse) GoogleCloudAiplatformV1beta1SampleConfigResponse {
		return v.SampleConfig
	}).(GoogleCloudAiplatformV1beta1SampleConfigResponseOutput)
}

// CMLE training config. For every active learning labeling iteration, system will train a machine learning model on CMLE. The trained model will be used by data sampling algorithm to select DataItems.
func (o GoogleCloudAiplatformV1beta1ActiveLearningConfigResponseOutput) TrainingConfig() GoogleCloudAiplatformV1beta1TrainingConfigResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ActiveLearningConfigResponse) GoogleCloudAiplatformV1beta1TrainingConfigResponse {
		return v.TrainingConfig
	}).(GoogleCloudAiplatformV1beta1TrainingConfigResponseOutput)
}

// Instance of a general artifact.
type GoogleCloudAiplatformV1beta1ArtifactResponse struct {
	// Timestamp when this Artifact was created.
	CreateTime string `pulumi:"createTime"`
	// Description of the Artifact
	Description string `pulumi:"description"`
	// User provided display name of the Artifact. May be up to 128 Unicode characters.
	DisplayName string `pulumi:"displayName"`
	// An eTag used to perform consistent read-modify-write updates. If not set, a blind "overwrite" update happens.
	Etag string `pulumi:"etag"`
	// The labels with user-defined metadata to organize your Artifacts. Label keys and values can be no longer than 64 characters (Unicode codepoints), can only contain lowercase letters, numeric characters, underscores and dashes. International characters are allowed. No more than 64 user labels can be associated with one Artifact (System labels are excluded).
	Labels map[string]string `pulumi:"labels"`
	// Properties of the Artifact. Top level metadata keys' heading and trailing spaces will be trimmed. The size of this field should not exceed 200KB.
	Metadata map[string]interface{} `pulumi:"metadata"`
	// The resource name of the Artifact.
	Name string `pulumi:"name"`
	// The title of the schema describing the metadata. Schema title and version is expected to be registered in earlier Create Schema calls. And both are used together as unique identifiers to identify schemas within the local metadata store.
	SchemaTitle string `pulumi:"schemaTitle"`
	// The version of the schema in schema_name to use. Schema title and version is expected to be registered in earlier Create Schema calls. And both are used together as unique identifiers to identify schemas within the local metadata store.
	SchemaVersion string `pulumi:"schemaVersion"`
	// The state of this Artifact. This is a property of the Artifact, and does not imply or capture any ongoing process. This property is managed by clients (such as Vertex AI Pipelines), and the system does not prescribe or check the validity of state transitions.
	State string `pulumi:"state"`
	// Timestamp when this Artifact was last updated.
	UpdateTime string `pulumi:"updateTime"`
	// The uniform resource identifier of the artifact file. May be empty if there is no actual artifact file.
	Uri string `pulumi:"uri"`
}

// Instance of a general artifact.
type GoogleCloudAiplatformV1beta1ArtifactResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ArtifactResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ArtifactResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ArtifactResponseOutput) ToGoogleCloudAiplatformV1beta1ArtifactResponseOutput() GoogleCloudAiplatformV1beta1ArtifactResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ArtifactResponseOutput) ToGoogleCloudAiplatformV1beta1ArtifactResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ArtifactResponseOutput {
	return o
}

// Timestamp when this Artifact was created.
func (o GoogleCloudAiplatformV1beta1ArtifactResponseOutput) CreateTime() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ArtifactResponse) string { return v.CreateTime }).(pulumi.StringOutput)
}

// Description of the Artifact
func (o GoogleCloudAiplatformV1beta1ArtifactResponseOutput) Description() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ArtifactResponse) string { return v.Description }).(pulumi.StringOutput)
}

// User provided display name of the Artifact. May be up to 128 Unicode characters.
func (o GoogleCloudAiplatformV1beta1ArtifactResponseOutput) DisplayName() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ArtifactResponse) string { return v.DisplayName }).(pulumi.StringOutput)
}

// An eTag used to perform consistent read-modify-write updates. If not set, a blind "overwrite" update happens.
func (o GoogleCloudAiplatformV1beta1ArtifactResponseOutput) Etag() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ArtifactResponse) string { return v.Etag }).(pulumi.StringOutput)
}

// The labels with user-defined metadata to organize your Artifacts. Label keys and values can be no longer than 64 characters (Unicode codepoints), can only contain lowercase letters, numeric characters, underscores and dashes. International characters are allowed. No more than 64 user labels can be associated with one Artifact (System labels are excluded).
func (o GoogleCloudAiplatformV1beta1ArtifactResponseOutput) Labels() pulumi.StringMapOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ArtifactResponse) map[string]string { return v.Labels }).(pulumi.StringMapOutput)
}

// Properties of the Artifact. Top level metadata keys' heading and trailing spaces will be trimmed. The size of this field should not exceed 200KB.
func (o GoogleCloudAiplatformV1beta1ArtifactResponseOutput) Metadata() pulumi.MapOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ArtifactResponse) map[string]interface{} { return v.Metadata }).(pulumi.MapOutput)
}

// The resource name of the Artifact.
func (o GoogleCloudAiplatformV1beta1ArtifactResponseOutput) Name() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ArtifactResponse) string { return v.Name }).(pulumi.StringOutput)
}

// The title of the schema describing the metadata. Schema title and version is expected to be registered in earlier Create Schema calls. And both are used together as unique identifiers to identify schemas within the local metadata store.
func (o GoogleCloudAiplatformV1beta1ArtifactResponseOutput) SchemaTitle() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ArtifactResponse) string { return v.SchemaTitle }).(pulumi.StringOutput)
}

// The version of the schema in schema_name to use. Schema title and version is expected to be registered in earlier Create Schema calls. And both are used together as unique identifiers to identify schemas within the local metadata store.
func (o GoogleCloudAiplatformV1beta1ArtifactResponseOutput) SchemaVersion() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ArtifactResponse) string { return v.SchemaVersion }).(pulumi.StringOutput)
}

// The state of this Artifact. This is a property of the Artifact, and does not imply or capture any ongoing process. This property is managed by clients (such as Vertex AI Pipelines), and the system does not prescribe or check the validity of state transitions.
func (o GoogleCloudAiplatformV1beta1ArtifactResponseOutput) State() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ArtifactResponse) string { return v.State }).(pulumi.StringOutput)
}

// Timestamp when this Artifact was last updated.
func (o GoogleCloudAiplatformV1beta1ArtifactResponseOutput) UpdateTime() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ArtifactResponse) string { return v.UpdateTime }).(pulumi.StringOutput)
}

// The uniform resource identifier of the artifact file. May be empty if there is no actual artifact file.
func (o GoogleCloudAiplatformV1beta1ArtifactResponseOutput) Uri() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ArtifactResponse) string { return v.Uri }).(pulumi.StringOutput)
}

type GoogleCloudAiplatformV1beta1ArtifactResponseArrayOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ArtifactResponseArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1beta1ArtifactResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ArtifactResponseArrayOutput) ToGoogleCloudAiplatformV1beta1ArtifactResponseArrayOutput() GoogleCloudAiplatformV1beta1ArtifactResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ArtifactResponseArrayOutput) ToGoogleCloudAiplatformV1beta1ArtifactResponseArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ArtifactResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ArtifactResponseArrayOutput) Index(i pulumi.IntInput) GoogleCloudAiplatformV1beta1ArtifactResponseOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GoogleCloudAiplatformV1beta1ArtifactResponse {
		return vs[0].([]GoogleCloudAiplatformV1beta1ArtifactResponse)[vs[1].(int)]
	}).(GoogleCloudAiplatformV1beta1ArtifactResponseOutput)
}

// A description of resources that to large degree are decided by Vertex AI, and require only a modest additional configuration. Each Model supporting these resources documents its specific guidelines.
type GoogleCloudAiplatformV1beta1AutomaticResourcesResponse struct {
	// Immutable. The maximum number of replicas this DeployedModel may be deployed on when the traffic against it increases. If the requested value is too large, the deployment will error, but if deployment succeeds then the ability to scale the model to that many replicas is guaranteed (barring service outages). If traffic against the DeployedModel increases beyond what its replicas at maximum may handle, a portion of the traffic will be dropped. If this value is not provided, a no upper bound for scaling under heavy traffic will be assume, though Vertex AI may be unable to scale beyond certain replica number.
	MaxReplicaCount int `pulumi:"maxReplicaCount"`
	// Immutable. The minimum number of replicas this DeployedModel will be always deployed on. If traffic against it increases, it may dynamically be deployed onto more replicas up to max_replica_count, and as traffic decreases, some of these extra replicas may be freed. If the requested value is too large, the deployment will error.
	MinReplicaCount int `pulumi:"minReplicaCount"`
}

// A description of resources that to large degree are decided by Vertex AI, and require only a modest additional configuration. Each Model supporting these resources documents its specific guidelines.
type GoogleCloudAiplatformV1beta1AutomaticResourcesResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1AutomaticResourcesResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1AutomaticResourcesResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1AutomaticResourcesResponseOutput) ToGoogleCloudAiplatformV1beta1AutomaticResourcesResponseOutput() GoogleCloudAiplatformV1beta1AutomaticResourcesResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1AutomaticResourcesResponseOutput) ToGoogleCloudAiplatformV1beta1AutomaticResourcesResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1AutomaticResourcesResponseOutput {
	return o
}

// Immutable. The maximum number of replicas this DeployedModel may be deployed on when the traffic against it increases. If the requested value is too large, the deployment will error, but if deployment succeeds then the ability to scale the model to that many replicas is guaranteed (barring service outages). If traffic against the DeployedModel increases beyond what its replicas at maximum may handle, a portion of the traffic will be dropped. If this value is not provided, a no upper bound for scaling under heavy traffic will be assume, though Vertex AI may be unable to scale beyond certain replica number.
func (o GoogleCloudAiplatformV1beta1AutomaticResourcesResponseOutput) MaxReplicaCount() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1AutomaticResourcesResponse) int { return v.MaxReplicaCount }).(pulumi.IntOutput)
}

// Immutable. The minimum number of replicas this DeployedModel will be always deployed on. If traffic against it increases, it may dynamically be deployed onto more replicas up to max_replica_count, and as traffic decreases, some of these extra replicas may be freed. If the requested value is too large, the deployment will error.
func (o GoogleCloudAiplatformV1beta1AutomaticResourcesResponseOutput) MinReplicaCount() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1AutomaticResourcesResponse) int { return v.MinReplicaCount }).(pulumi.IntOutput)
}

// The metric specification that defines the target resource utilization (CPU utilization, accelerator's duty cycle, and so on) for calculating the desired replica count.
type GoogleCloudAiplatformV1beta1AutoscalingMetricSpec struct {
	// The resource metric name. Supported metrics: * For Online Prediction: * `aiplatform.googleapis.com/prediction/online/accelerator/duty_cycle` * `aiplatform.googleapis.com/prediction/online/cpu/utilization`
	MetricName string `pulumi:"metricName"`
	// The target resource utilization in percentage (1% - 100%) for the given metric; once the real usage deviates from the target by a certain percentage, the machine replicas change. The default value is 60 (representing 60%) if not provided.
	Target *int `pulumi:"target"`
}

// GoogleCloudAiplatformV1beta1AutoscalingMetricSpecInput is an input type that accepts GoogleCloudAiplatformV1beta1AutoscalingMetricSpecArgs and GoogleCloudAiplatformV1beta1AutoscalingMetricSpecOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1AutoscalingMetricSpecInput` via:
//
//	GoogleCloudAiplatformV1beta1AutoscalingMetricSpecArgs{...}
type GoogleCloudAiplatformV1beta1AutoscalingMetricSpecInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1AutoscalingMetricSpecOutput() GoogleCloudAiplatformV1beta1AutoscalingMetricSpecOutput
	ToGoogleCloudAiplatformV1beta1AutoscalingMetricSpecOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1AutoscalingMetricSpecOutput
}

// The metric specification that defines the target resource utilization (CPU utilization, accelerator's duty cycle, and so on) for calculating the desired replica count.
type GoogleCloudAiplatformV1beta1AutoscalingMetricSpecArgs struct {
	// The resource metric name. Supported metrics: * For Online Prediction: * `aiplatform.googleapis.com/prediction/online/accelerator/duty_cycle` * `aiplatform.googleapis.com/prediction/online/cpu/utilization`
	MetricName pulumi.StringInput `pulumi:"metricName"`
	// The target resource utilization in percentage (1% - 100%) for the given metric; once the real usage deviates from the target by a certain percentage, the machine replicas change. The default value is 60 (representing 60%) if not provided.
	Target pulumi.IntPtrInput `pulumi:"target"`
}

func (GoogleCloudAiplatformV1beta1AutoscalingMetricSpecArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1AutoscalingMetricSpec)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1AutoscalingMetricSpecArgs) ToGoogleCloudAiplatformV1beta1AutoscalingMetricSpecOutput() GoogleCloudAiplatformV1beta1AutoscalingMetricSpecOutput {
	return i.ToGoogleCloudAiplatformV1beta1AutoscalingMetricSpecOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1AutoscalingMetricSpecArgs) ToGoogleCloudAiplatformV1beta1AutoscalingMetricSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1AutoscalingMetricSpecOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1AutoscalingMetricSpecOutput)
}

// GoogleCloudAiplatformV1beta1AutoscalingMetricSpecArrayInput is an input type that accepts GoogleCloudAiplatformV1beta1AutoscalingMetricSpecArray and GoogleCloudAiplatformV1beta1AutoscalingMetricSpecArrayOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1AutoscalingMetricSpecArrayInput` via:
//
//	GoogleCloudAiplatformV1beta1AutoscalingMetricSpecArray{ GoogleCloudAiplatformV1beta1AutoscalingMetricSpecArgs{...} }
type GoogleCloudAiplatformV1beta1AutoscalingMetricSpecArrayInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1AutoscalingMetricSpecArrayOutput() GoogleCloudAiplatformV1beta1AutoscalingMetricSpecArrayOutput
	ToGoogleCloudAiplatformV1beta1AutoscalingMetricSpecArrayOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1AutoscalingMetricSpecArrayOutput
}

type GoogleCloudAiplatformV1beta1AutoscalingMetricSpecArray []GoogleCloudAiplatformV1beta1AutoscalingMetricSpecInput

func (GoogleCloudAiplatformV1beta1AutoscalingMetricSpecArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1beta1AutoscalingMetricSpec)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1AutoscalingMetricSpecArray) ToGoogleCloudAiplatformV1beta1AutoscalingMetricSpecArrayOutput() GoogleCloudAiplatformV1beta1AutoscalingMetricSpecArrayOutput {
	return i.ToGoogleCloudAiplatformV1beta1AutoscalingMetricSpecArrayOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1AutoscalingMetricSpecArray) ToGoogleCloudAiplatformV1beta1AutoscalingMetricSpecArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1AutoscalingMetricSpecArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1AutoscalingMetricSpecArrayOutput)
}

// The metric specification that defines the target resource utilization (CPU utilization, accelerator's duty cycle, and so on) for calculating the desired replica count.
type GoogleCloudAiplatformV1beta1AutoscalingMetricSpecOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1AutoscalingMetricSpecOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1AutoscalingMetricSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1AutoscalingMetricSpecOutput) ToGoogleCloudAiplatformV1beta1AutoscalingMetricSpecOutput() GoogleCloudAiplatformV1beta1AutoscalingMetricSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1AutoscalingMetricSpecOutput) ToGoogleCloudAiplatformV1beta1AutoscalingMetricSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1AutoscalingMetricSpecOutput {
	return o
}

// The resource metric name. Supported metrics: * For Online Prediction: * `aiplatform.googleapis.com/prediction/online/accelerator/duty_cycle` * `aiplatform.googleapis.com/prediction/online/cpu/utilization`
func (o GoogleCloudAiplatformV1beta1AutoscalingMetricSpecOutput) MetricName() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1AutoscalingMetricSpec) string { return v.MetricName }).(pulumi.StringOutput)
}

// The target resource utilization in percentage (1% - 100%) for the given metric; once the real usage deviates from the target by a certain percentage, the machine replicas change. The default value is 60 (representing 60%) if not provided.
func (o GoogleCloudAiplatformV1beta1AutoscalingMetricSpecOutput) Target() pulumi.IntPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1AutoscalingMetricSpec) *int { return v.Target }).(pulumi.IntPtrOutput)
}

type GoogleCloudAiplatformV1beta1AutoscalingMetricSpecArrayOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1AutoscalingMetricSpecArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1beta1AutoscalingMetricSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1AutoscalingMetricSpecArrayOutput) ToGoogleCloudAiplatformV1beta1AutoscalingMetricSpecArrayOutput() GoogleCloudAiplatformV1beta1AutoscalingMetricSpecArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1AutoscalingMetricSpecArrayOutput) ToGoogleCloudAiplatformV1beta1AutoscalingMetricSpecArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1AutoscalingMetricSpecArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1AutoscalingMetricSpecArrayOutput) Index(i pulumi.IntInput) GoogleCloudAiplatformV1beta1AutoscalingMetricSpecOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GoogleCloudAiplatformV1beta1AutoscalingMetricSpec {
		return vs[0].([]GoogleCloudAiplatformV1beta1AutoscalingMetricSpec)[vs[1].(int)]
	}).(GoogleCloudAiplatformV1beta1AutoscalingMetricSpecOutput)
}

// The metric specification that defines the target resource utilization (CPU utilization, accelerator's duty cycle, and so on) for calculating the desired replica count.
type GoogleCloudAiplatformV1beta1AutoscalingMetricSpecResponse struct {
	// The resource metric name. Supported metrics: * For Online Prediction: * `aiplatform.googleapis.com/prediction/online/accelerator/duty_cycle` * `aiplatform.googleapis.com/prediction/online/cpu/utilization`
	MetricName string `pulumi:"metricName"`
	// The target resource utilization in percentage (1% - 100%) for the given metric; once the real usage deviates from the target by a certain percentage, the machine replicas change. The default value is 60 (representing 60%) if not provided.
	Target int `pulumi:"target"`
}

// The metric specification that defines the target resource utilization (CPU utilization, accelerator's duty cycle, and so on) for calculating the desired replica count.
type GoogleCloudAiplatformV1beta1AutoscalingMetricSpecResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1AutoscalingMetricSpecResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1AutoscalingMetricSpecResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1AutoscalingMetricSpecResponseOutput) ToGoogleCloudAiplatformV1beta1AutoscalingMetricSpecResponseOutput() GoogleCloudAiplatformV1beta1AutoscalingMetricSpecResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1AutoscalingMetricSpecResponseOutput) ToGoogleCloudAiplatformV1beta1AutoscalingMetricSpecResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1AutoscalingMetricSpecResponseOutput {
	return o
}

// The resource metric name. Supported metrics: * For Online Prediction: * `aiplatform.googleapis.com/prediction/online/accelerator/duty_cycle` * `aiplatform.googleapis.com/prediction/online/cpu/utilization`
func (o GoogleCloudAiplatformV1beta1AutoscalingMetricSpecResponseOutput) MetricName() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1AutoscalingMetricSpecResponse) string { return v.MetricName }).(pulumi.StringOutput)
}

// The target resource utilization in percentage (1% - 100%) for the given metric; once the real usage deviates from the target by a certain percentage, the machine replicas change. The default value is 60 (representing 60%) if not provided.
func (o GoogleCloudAiplatformV1beta1AutoscalingMetricSpecResponseOutput) Target() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1AutoscalingMetricSpecResponse) int { return v.Target }).(pulumi.IntOutput)
}

type GoogleCloudAiplatformV1beta1AutoscalingMetricSpecResponseArrayOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1AutoscalingMetricSpecResponseArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1beta1AutoscalingMetricSpecResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1AutoscalingMetricSpecResponseArrayOutput) ToGoogleCloudAiplatformV1beta1AutoscalingMetricSpecResponseArrayOutput() GoogleCloudAiplatformV1beta1AutoscalingMetricSpecResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1AutoscalingMetricSpecResponseArrayOutput) ToGoogleCloudAiplatformV1beta1AutoscalingMetricSpecResponseArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1AutoscalingMetricSpecResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1AutoscalingMetricSpecResponseArrayOutput) Index(i pulumi.IntInput) GoogleCloudAiplatformV1beta1AutoscalingMetricSpecResponseOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GoogleCloudAiplatformV1beta1AutoscalingMetricSpecResponse {
		return vs[0].([]GoogleCloudAiplatformV1beta1AutoscalingMetricSpecResponse)[vs[1].(int)]
	}).(GoogleCloudAiplatformV1beta1AutoscalingMetricSpecResponseOutput)
}

// A description of resources that are used for performing batch operations, are dedicated to a Model, and need manual configuration.
type GoogleCloudAiplatformV1beta1BatchDedicatedResources struct {
	// Immutable. The specification of a single machine.
	MachineSpec GoogleCloudAiplatformV1beta1MachineSpec `pulumi:"machineSpec"`
	// Immutable. The maximum number of machine replicas the batch operation may be scaled to. The default value is 10.
	MaxReplicaCount *int `pulumi:"maxReplicaCount"`
	// Immutable. The number of machine replicas used at the start of the batch operation. If not set, Vertex AI decides starting number, not greater than max_replica_count
	StartingReplicaCount *int `pulumi:"startingReplicaCount"`
}

// GoogleCloudAiplatformV1beta1BatchDedicatedResourcesInput is an input type that accepts GoogleCloudAiplatformV1beta1BatchDedicatedResourcesArgs and GoogleCloudAiplatformV1beta1BatchDedicatedResourcesOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1BatchDedicatedResourcesInput` via:
//
//	GoogleCloudAiplatformV1beta1BatchDedicatedResourcesArgs{...}
type GoogleCloudAiplatformV1beta1BatchDedicatedResourcesInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1BatchDedicatedResourcesOutput() GoogleCloudAiplatformV1beta1BatchDedicatedResourcesOutput
	ToGoogleCloudAiplatformV1beta1BatchDedicatedResourcesOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1BatchDedicatedResourcesOutput
}

// A description of resources that are used for performing batch operations, are dedicated to a Model, and need manual configuration.
type GoogleCloudAiplatformV1beta1BatchDedicatedResourcesArgs struct {
	// Immutable. The specification of a single machine.
	MachineSpec GoogleCloudAiplatformV1beta1MachineSpecInput `pulumi:"machineSpec"`
	// Immutable. The maximum number of machine replicas the batch operation may be scaled to. The default value is 10.
	MaxReplicaCount pulumi.IntPtrInput `pulumi:"maxReplicaCount"`
	// Immutable. The number of machine replicas used at the start of the batch operation. If not set, Vertex AI decides starting number, not greater than max_replica_count
	StartingReplicaCount pulumi.IntPtrInput `pulumi:"startingReplicaCount"`
}

func (GoogleCloudAiplatformV1beta1BatchDedicatedResourcesArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1BatchDedicatedResources)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1BatchDedicatedResourcesArgs) ToGoogleCloudAiplatformV1beta1BatchDedicatedResourcesOutput() GoogleCloudAiplatformV1beta1BatchDedicatedResourcesOutput {
	return i.ToGoogleCloudAiplatformV1beta1BatchDedicatedResourcesOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1BatchDedicatedResourcesArgs) ToGoogleCloudAiplatformV1beta1BatchDedicatedResourcesOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1BatchDedicatedResourcesOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1BatchDedicatedResourcesOutput)
}

func (i GoogleCloudAiplatformV1beta1BatchDedicatedResourcesArgs) ToGoogleCloudAiplatformV1beta1BatchDedicatedResourcesPtrOutput() GoogleCloudAiplatformV1beta1BatchDedicatedResourcesPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1BatchDedicatedResourcesPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1BatchDedicatedResourcesArgs) ToGoogleCloudAiplatformV1beta1BatchDedicatedResourcesPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1BatchDedicatedResourcesPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1BatchDedicatedResourcesOutput).ToGoogleCloudAiplatformV1beta1BatchDedicatedResourcesPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1BatchDedicatedResourcesPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1BatchDedicatedResourcesArgs, GoogleCloudAiplatformV1beta1BatchDedicatedResourcesPtr and GoogleCloudAiplatformV1beta1BatchDedicatedResourcesPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1BatchDedicatedResourcesPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1BatchDedicatedResourcesArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1BatchDedicatedResourcesPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1BatchDedicatedResourcesPtrOutput() GoogleCloudAiplatformV1beta1BatchDedicatedResourcesPtrOutput
	ToGoogleCloudAiplatformV1beta1BatchDedicatedResourcesPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1BatchDedicatedResourcesPtrOutput
}

type googleCloudAiplatformV1beta1BatchDedicatedResourcesPtrType GoogleCloudAiplatformV1beta1BatchDedicatedResourcesArgs

func GoogleCloudAiplatformV1beta1BatchDedicatedResourcesPtr(v *GoogleCloudAiplatformV1beta1BatchDedicatedResourcesArgs) GoogleCloudAiplatformV1beta1BatchDedicatedResourcesPtrInput {
	return (*googleCloudAiplatformV1beta1BatchDedicatedResourcesPtrType)(v)
}

func (*googleCloudAiplatformV1beta1BatchDedicatedResourcesPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1BatchDedicatedResources)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1BatchDedicatedResourcesPtrType) ToGoogleCloudAiplatformV1beta1BatchDedicatedResourcesPtrOutput() GoogleCloudAiplatformV1beta1BatchDedicatedResourcesPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1BatchDedicatedResourcesPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1BatchDedicatedResourcesPtrType) ToGoogleCloudAiplatformV1beta1BatchDedicatedResourcesPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1BatchDedicatedResourcesPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1BatchDedicatedResourcesPtrOutput)
}

// A description of resources that are used for performing batch operations, are dedicated to a Model, and need manual configuration.
type GoogleCloudAiplatformV1beta1BatchDedicatedResourcesOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1BatchDedicatedResourcesOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1BatchDedicatedResources)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1BatchDedicatedResourcesOutput) ToGoogleCloudAiplatformV1beta1BatchDedicatedResourcesOutput() GoogleCloudAiplatformV1beta1BatchDedicatedResourcesOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1BatchDedicatedResourcesOutput) ToGoogleCloudAiplatformV1beta1BatchDedicatedResourcesOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1BatchDedicatedResourcesOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1BatchDedicatedResourcesOutput) ToGoogleCloudAiplatformV1beta1BatchDedicatedResourcesPtrOutput() GoogleCloudAiplatformV1beta1BatchDedicatedResourcesPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1BatchDedicatedResourcesPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1BatchDedicatedResourcesOutput) ToGoogleCloudAiplatformV1beta1BatchDedicatedResourcesPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1BatchDedicatedResourcesPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1BatchDedicatedResources) *GoogleCloudAiplatformV1beta1BatchDedicatedResources {
		return &v
	}).(GoogleCloudAiplatformV1beta1BatchDedicatedResourcesPtrOutput)
}

// Immutable. The specification of a single machine.
func (o GoogleCloudAiplatformV1beta1BatchDedicatedResourcesOutput) MachineSpec() GoogleCloudAiplatformV1beta1MachineSpecOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1BatchDedicatedResources) GoogleCloudAiplatformV1beta1MachineSpec {
		return v.MachineSpec
	}).(GoogleCloudAiplatformV1beta1MachineSpecOutput)
}

// Immutable. The maximum number of machine replicas the batch operation may be scaled to. The default value is 10.
func (o GoogleCloudAiplatformV1beta1BatchDedicatedResourcesOutput) MaxReplicaCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1BatchDedicatedResources) *int { return v.MaxReplicaCount }).(pulumi.IntPtrOutput)
}

// Immutable. The number of machine replicas used at the start of the batch operation. If not set, Vertex AI decides starting number, not greater than max_replica_count
func (o GoogleCloudAiplatformV1beta1BatchDedicatedResourcesOutput) StartingReplicaCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1BatchDedicatedResources) *int { return v.StartingReplicaCount }).(pulumi.IntPtrOutput)
}

type GoogleCloudAiplatformV1beta1BatchDedicatedResourcesPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1BatchDedicatedResourcesPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1BatchDedicatedResources)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1BatchDedicatedResourcesPtrOutput) ToGoogleCloudAiplatformV1beta1BatchDedicatedResourcesPtrOutput() GoogleCloudAiplatformV1beta1BatchDedicatedResourcesPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1BatchDedicatedResourcesPtrOutput) ToGoogleCloudAiplatformV1beta1BatchDedicatedResourcesPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1BatchDedicatedResourcesPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1BatchDedicatedResourcesPtrOutput) Elem() GoogleCloudAiplatformV1beta1BatchDedicatedResourcesOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1BatchDedicatedResources) GoogleCloudAiplatformV1beta1BatchDedicatedResources {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1BatchDedicatedResources
		return ret
	}).(GoogleCloudAiplatformV1beta1BatchDedicatedResourcesOutput)
}

// Immutable. The specification of a single machine.
func (o GoogleCloudAiplatformV1beta1BatchDedicatedResourcesPtrOutput) MachineSpec() GoogleCloudAiplatformV1beta1MachineSpecPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1BatchDedicatedResources) *GoogleCloudAiplatformV1beta1MachineSpec {
		if v == nil {
			return nil
		}
		return &v.MachineSpec
	}).(GoogleCloudAiplatformV1beta1MachineSpecPtrOutput)
}

// Immutable. The maximum number of machine replicas the batch operation may be scaled to. The default value is 10.
func (o GoogleCloudAiplatformV1beta1BatchDedicatedResourcesPtrOutput) MaxReplicaCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1BatchDedicatedResources) *int {
		if v == nil {
			return nil
		}
		return v.MaxReplicaCount
	}).(pulumi.IntPtrOutput)
}

// Immutable. The number of machine replicas used at the start of the batch operation. If not set, Vertex AI decides starting number, not greater than max_replica_count
func (o GoogleCloudAiplatformV1beta1BatchDedicatedResourcesPtrOutput) StartingReplicaCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1BatchDedicatedResources) *int {
		if v == nil {
			return nil
		}
		return v.StartingReplicaCount
	}).(pulumi.IntPtrOutput)
}

// A description of resources that are used for performing batch operations, are dedicated to a Model, and need manual configuration.
type GoogleCloudAiplatformV1beta1BatchDedicatedResourcesResponse struct {
	// Immutable. The specification of a single machine.
	MachineSpec GoogleCloudAiplatformV1beta1MachineSpecResponse `pulumi:"machineSpec"`
	// Immutable. The maximum number of machine replicas the batch operation may be scaled to. The default value is 10.
	MaxReplicaCount int `pulumi:"maxReplicaCount"`
	// Immutable. The number of machine replicas used at the start of the batch operation. If not set, Vertex AI decides starting number, not greater than max_replica_count
	StartingReplicaCount int `pulumi:"startingReplicaCount"`
}

// A description of resources that are used for performing batch operations, are dedicated to a Model, and need manual configuration.
type GoogleCloudAiplatformV1beta1BatchDedicatedResourcesResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1BatchDedicatedResourcesResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1BatchDedicatedResourcesResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1BatchDedicatedResourcesResponseOutput) ToGoogleCloudAiplatformV1beta1BatchDedicatedResourcesResponseOutput() GoogleCloudAiplatformV1beta1BatchDedicatedResourcesResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1BatchDedicatedResourcesResponseOutput) ToGoogleCloudAiplatformV1beta1BatchDedicatedResourcesResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1BatchDedicatedResourcesResponseOutput {
	return o
}

// Immutable. The specification of a single machine.
func (o GoogleCloudAiplatformV1beta1BatchDedicatedResourcesResponseOutput) MachineSpec() GoogleCloudAiplatformV1beta1MachineSpecResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1BatchDedicatedResourcesResponse) GoogleCloudAiplatformV1beta1MachineSpecResponse {
		return v.MachineSpec
	}).(GoogleCloudAiplatformV1beta1MachineSpecResponseOutput)
}

// Immutable. The maximum number of machine replicas the batch operation may be scaled to. The default value is 10.
func (o GoogleCloudAiplatformV1beta1BatchDedicatedResourcesResponseOutput) MaxReplicaCount() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1BatchDedicatedResourcesResponse) int { return v.MaxReplicaCount }).(pulumi.IntOutput)
}

// Immutable. The number of machine replicas used at the start of the batch operation. If not set, Vertex AI decides starting number, not greater than max_replica_count
func (o GoogleCloudAiplatformV1beta1BatchDedicatedResourcesResponseOutput) StartingReplicaCount() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1BatchDedicatedResourcesResponse) int { return v.StartingReplicaCount }).(pulumi.IntOutput)
}

// Configures the input to BatchPredictionJob. See Model.supported_input_storage_formats for Model's supported input formats, and how instances should be expressed via any of them.
type GoogleCloudAiplatformV1beta1BatchPredictionJobInputConfig struct {
	// The BigQuery location of the input table. The schema of the table should be in the format described by the given context OpenAPI Schema, if one is provided. The table may contain additional columns that are not described by the schema, and they will be ignored.
	BigquerySource *GoogleCloudAiplatformV1beta1BigQuerySource `pulumi:"bigquerySource"`
	// The Cloud Storage location for the input instances.
	GcsSource *GoogleCloudAiplatformV1beta1GcsSource `pulumi:"gcsSource"`
	// The format in which instances are given, must be one of the Model's supported_input_storage_formats.
	InstancesFormat string `pulumi:"instancesFormat"`
}

// GoogleCloudAiplatformV1beta1BatchPredictionJobInputConfigInput is an input type that accepts GoogleCloudAiplatformV1beta1BatchPredictionJobInputConfigArgs and GoogleCloudAiplatformV1beta1BatchPredictionJobInputConfigOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1BatchPredictionJobInputConfigInput` via:
//
//	GoogleCloudAiplatformV1beta1BatchPredictionJobInputConfigArgs{...}
type GoogleCloudAiplatformV1beta1BatchPredictionJobInputConfigInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1BatchPredictionJobInputConfigOutput() GoogleCloudAiplatformV1beta1BatchPredictionJobInputConfigOutput
	ToGoogleCloudAiplatformV1beta1BatchPredictionJobInputConfigOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1BatchPredictionJobInputConfigOutput
}

// Configures the input to BatchPredictionJob. See Model.supported_input_storage_formats for Model's supported input formats, and how instances should be expressed via any of them.
type GoogleCloudAiplatformV1beta1BatchPredictionJobInputConfigArgs struct {
	// The BigQuery location of the input table. The schema of the table should be in the format described by the given context OpenAPI Schema, if one is provided. The table may contain additional columns that are not described by the schema, and they will be ignored.
	BigquerySource GoogleCloudAiplatformV1beta1BigQuerySourcePtrInput `pulumi:"bigquerySource"`
	// The Cloud Storage location for the input instances.
	GcsSource GoogleCloudAiplatformV1beta1GcsSourcePtrInput `pulumi:"gcsSource"`
	// The format in which instances are given, must be one of the Model's supported_input_storage_formats.
	InstancesFormat pulumi.StringInput `pulumi:"instancesFormat"`
}

func (GoogleCloudAiplatformV1beta1BatchPredictionJobInputConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1BatchPredictionJobInputConfig)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1BatchPredictionJobInputConfigArgs) ToGoogleCloudAiplatformV1beta1BatchPredictionJobInputConfigOutput() GoogleCloudAiplatformV1beta1BatchPredictionJobInputConfigOutput {
	return i.ToGoogleCloudAiplatformV1beta1BatchPredictionJobInputConfigOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1BatchPredictionJobInputConfigArgs) ToGoogleCloudAiplatformV1beta1BatchPredictionJobInputConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1BatchPredictionJobInputConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1BatchPredictionJobInputConfigOutput)
}

// Configures the input to BatchPredictionJob. See Model.supported_input_storage_formats for Model's supported input formats, and how instances should be expressed via any of them.
type GoogleCloudAiplatformV1beta1BatchPredictionJobInputConfigOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1BatchPredictionJobInputConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1BatchPredictionJobInputConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1BatchPredictionJobInputConfigOutput) ToGoogleCloudAiplatformV1beta1BatchPredictionJobInputConfigOutput() GoogleCloudAiplatformV1beta1BatchPredictionJobInputConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1BatchPredictionJobInputConfigOutput) ToGoogleCloudAiplatformV1beta1BatchPredictionJobInputConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1BatchPredictionJobInputConfigOutput {
	return o
}

// The BigQuery location of the input table. The schema of the table should be in the format described by the given context OpenAPI Schema, if one is provided. The table may contain additional columns that are not described by the schema, and they will be ignored.
func (o GoogleCloudAiplatformV1beta1BatchPredictionJobInputConfigOutput) BigquerySource() GoogleCloudAiplatformV1beta1BigQuerySourcePtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1BatchPredictionJobInputConfig) *GoogleCloudAiplatformV1beta1BigQuerySource {
		return v.BigquerySource
	}).(GoogleCloudAiplatformV1beta1BigQuerySourcePtrOutput)
}

// The Cloud Storage location for the input instances.
func (o GoogleCloudAiplatformV1beta1BatchPredictionJobInputConfigOutput) GcsSource() GoogleCloudAiplatformV1beta1GcsSourcePtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1BatchPredictionJobInputConfig) *GoogleCloudAiplatformV1beta1GcsSource {
		return v.GcsSource
	}).(GoogleCloudAiplatformV1beta1GcsSourcePtrOutput)
}

// The format in which instances are given, must be one of the Model's supported_input_storage_formats.
func (o GoogleCloudAiplatformV1beta1BatchPredictionJobInputConfigOutput) InstancesFormat() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1BatchPredictionJobInputConfig) string { return v.InstancesFormat }).(pulumi.StringOutput)
}

// Configures the input to BatchPredictionJob. See Model.supported_input_storage_formats for Model's supported input formats, and how instances should be expressed via any of them.
type GoogleCloudAiplatformV1beta1BatchPredictionJobInputConfigResponse struct {
	// The BigQuery location of the input table. The schema of the table should be in the format described by the given context OpenAPI Schema, if one is provided. The table may contain additional columns that are not described by the schema, and they will be ignored.
	BigquerySource GoogleCloudAiplatformV1beta1BigQuerySourceResponse `pulumi:"bigquerySource"`
	// The Cloud Storage location for the input instances.
	GcsSource GoogleCloudAiplatformV1beta1GcsSourceResponse `pulumi:"gcsSource"`
	// The format in which instances are given, must be one of the Model's supported_input_storage_formats.
	InstancesFormat string `pulumi:"instancesFormat"`
}

// Configures the input to BatchPredictionJob. See Model.supported_input_storage_formats for Model's supported input formats, and how instances should be expressed via any of them.
type GoogleCloudAiplatformV1beta1BatchPredictionJobInputConfigResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1BatchPredictionJobInputConfigResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1BatchPredictionJobInputConfigResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1BatchPredictionJobInputConfigResponseOutput) ToGoogleCloudAiplatformV1beta1BatchPredictionJobInputConfigResponseOutput() GoogleCloudAiplatformV1beta1BatchPredictionJobInputConfigResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1BatchPredictionJobInputConfigResponseOutput) ToGoogleCloudAiplatformV1beta1BatchPredictionJobInputConfigResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1BatchPredictionJobInputConfigResponseOutput {
	return o
}

// The BigQuery location of the input table. The schema of the table should be in the format described by the given context OpenAPI Schema, if one is provided. The table may contain additional columns that are not described by the schema, and they will be ignored.
func (o GoogleCloudAiplatformV1beta1BatchPredictionJobInputConfigResponseOutput) BigquerySource() GoogleCloudAiplatformV1beta1BigQuerySourceResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1BatchPredictionJobInputConfigResponse) GoogleCloudAiplatformV1beta1BigQuerySourceResponse {
		return v.BigquerySource
	}).(GoogleCloudAiplatformV1beta1BigQuerySourceResponseOutput)
}

// The Cloud Storage location for the input instances.
func (o GoogleCloudAiplatformV1beta1BatchPredictionJobInputConfigResponseOutput) GcsSource() GoogleCloudAiplatformV1beta1GcsSourceResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1BatchPredictionJobInputConfigResponse) GoogleCloudAiplatformV1beta1GcsSourceResponse {
		return v.GcsSource
	}).(GoogleCloudAiplatformV1beta1GcsSourceResponseOutput)
}

// The format in which instances are given, must be one of the Model's supported_input_storage_formats.
func (o GoogleCloudAiplatformV1beta1BatchPredictionJobInputConfigResponseOutput) InstancesFormat() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1BatchPredictionJobInputConfigResponse) string {
		return v.InstancesFormat
	}).(pulumi.StringOutput)
}

// Configuration defining how to transform batch prediction input instances to the instances that the Model accepts.
type GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfig struct {
	// Fields that will be excluded in the prediction instance that is sent to the Model. Excluded will be attached to the batch prediction output if key_field is not specified. When excluded_fields is populated, included_fields must be empty. The input must be JSONL with objects at each line, CSV, BigQuery or TfRecord.
	ExcludedFields []string `pulumi:"excludedFields"`
	// Fields that will be included in the prediction instance that is sent to the Model. If instance_type is `array`, the order of field names in included_fields also determines the order of the values in the array. When included_fields is populated, excluded_fields must be empty. The input must be JSONL with objects at each line, CSV, BigQuery or TfRecord.
	IncludedFields []string `pulumi:"includedFields"`
	// The format of the instance that the Model accepts. Vertex AI will convert compatible batch prediction input instance formats to the specified format. Supported values are: * `object`: Each input is converted to JSON object format. * For `bigquery`, each row is converted to an object. * For `jsonl`, each line of the JSONL input must be an object. * Does not apply to `csv`, `file-list`, `tf-record`, or `tf-record-gzip`. * `array`: Each input is converted to JSON array format. * For `bigquery`, each row is converted to an array. The order of columns is determined by the BigQuery column order, unless included_fields is populated. included_fields must be populated for specifying field orders. * For `jsonl`, if each line of the JSONL input is an object, included_fields must be populated for specifying field orders. * Does not apply to `csv`, `file-list`, `tf-record`, or `tf-record-gzip`. If not specified, Vertex AI converts the batch prediction input as follows: * For `bigquery` and `csv`, the behavior is the same as `array`. The order of columns is the same as defined in the file or table, unless included_fields is populated. * For `jsonl`, the prediction instance format is determined by each line of the input. * For `tf-record`/`tf-record-gzip`, each record will be converted to an object in the format of `{"b64": }`, where ``is the Base64-encoded string of the content of the record. * For `file-list`, each file in the list will be converted to an object in the format of `{"b64": }`, where`` is the Base64-encoded string of the content of the file.
	InstanceType *string `pulumi:"instanceType"`
	// The name of the field that is considered as a key. The values identified by the key field is not included in the transformed instances that is sent to the Model. This is similar to specifying this name of the field in excluded_fields. In addition, the batch prediction output will not include the instances. Instead the output will only include the value of the key field, in a field named `key` in the output: * For `jsonl` output format, the output will have a `key` field instead of the `instance` field. * For `csv`/`bigquery` output format, the output will have have a `key` column instead of the instance feature columns. The input must be JSONL with objects at each line, CSV, BigQuery or TfRecord.
	KeyField *string `pulumi:"keyField"`
}

// GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigInput is an input type that accepts GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigArgs and GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigInput` via:
//
//	GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigArgs{...}
type GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigOutput() GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigOutput
	ToGoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigOutput
}

// Configuration defining how to transform batch prediction input instances to the instances that the Model accepts.
type GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigArgs struct {
	// Fields that will be excluded in the prediction instance that is sent to the Model. Excluded will be attached to the batch prediction output if key_field is not specified. When excluded_fields is populated, included_fields must be empty. The input must be JSONL with objects at each line, CSV, BigQuery or TfRecord.
	ExcludedFields pulumi.StringArrayInput `pulumi:"excludedFields"`
	// Fields that will be included in the prediction instance that is sent to the Model. If instance_type is `array`, the order of field names in included_fields also determines the order of the values in the array. When included_fields is populated, excluded_fields must be empty. The input must be JSONL with objects at each line, CSV, BigQuery or TfRecord.
	IncludedFields pulumi.StringArrayInput `pulumi:"includedFields"`
	// The format of the instance that the Model accepts. Vertex AI will convert compatible batch prediction input instance formats to the specified format. Supported values are: * `object`: Each input is converted to JSON object format. * For `bigquery`, each row is converted to an object. * For `jsonl`, each line of the JSONL input must be an object. * Does not apply to `csv`, `file-list`, `tf-record`, or `tf-record-gzip`. * `array`: Each input is converted to JSON array format. * For `bigquery`, each row is converted to an array. The order of columns is determined by the BigQuery column order, unless included_fields is populated. included_fields must be populated for specifying field orders. * For `jsonl`, if each line of the JSONL input is an object, included_fields must be populated for specifying field orders. * Does not apply to `csv`, `file-list`, `tf-record`, or `tf-record-gzip`. If not specified, Vertex AI converts the batch prediction input as follows: * For `bigquery` and `csv`, the behavior is the same as `array`. The order of columns is the same as defined in the file or table, unless included_fields is populated. * For `jsonl`, the prediction instance format is determined by each line of the input. * For `tf-record`/`tf-record-gzip`, each record will be converted to an object in the format of `{"b64": }`, where ``is the Base64-encoded string of the content of the record. * For `file-list`, each file in the list will be converted to an object in the format of `{"b64": }`, where`` is the Base64-encoded string of the content of the file.
	InstanceType pulumi.StringPtrInput `pulumi:"instanceType"`
	// The name of the field that is considered as a key. The values identified by the key field is not included in the transformed instances that is sent to the Model. This is similar to specifying this name of the field in excluded_fields. In addition, the batch prediction output will not include the instances. Instead the output will only include the value of the key field, in a field named `key` in the output: * For `jsonl` output format, the output will have a `key` field instead of the `instance` field. * For `csv`/`bigquery` output format, the output will have have a `key` column instead of the instance feature columns. The input must be JSONL with objects at each line, CSV, BigQuery or TfRecord.
	KeyField pulumi.StringPtrInput `pulumi:"keyField"`
}

func (GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfig)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigArgs) ToGoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigOutput() GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigOutput {
	return i.ToGoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigArgs) ToGoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigOutput)
}

func (i GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigArgs) ToGoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigPtrOutput() GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigArgs) ToGoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigOutput).ToGoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigArgs, GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigPtr and GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigPtrOutput() GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigPtrOutput
	ToGoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigPtrOutput
}

type googleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigPtrType GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigArgs

func GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigPtr(v *GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigArgs) GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigPtrInput {
	return (*googleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigPtrType)(v)
}

func (*googleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfig)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigPtrType) ToGoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigPtrOutput() GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigPtrType) ToGoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigPtrOutput)
}

// Configuration defining how to transform batch prediction input instances to the instances that the Model accepts.
type GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigOutput) ToGoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigOutput() GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigOutput) ToGoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigOutput) ToGoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigPtrOutput() GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigOutput) ToGoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfig) *GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfig {
		return &v
	}).(GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigPtrOutput)
}

// Fields that will be excluded in the prediction instance that is sent to the Model. Excluded will be attached to the batch prediction output if key_field is not specified. When excluded_fields is populated, included_fields must be empty. The input must be JSONL with objects at each line, CSV, BigQuery or TfRecord.
func (o GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigOutput) ExcludedFields() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfig) []string { return v.ExcludedFields }).(pulumi.StringArrayOutput)
}

// Fields that will be included in the prediction instance that is sent to the Model. If instance_type is `array`, the order of field names in included_fields also determines the order of the values in the array. When included_fields is populated, excluded_fields must be empty. The input must be JSONL with objects at each line, CSV, BigQuery or TfRecord.
func (o GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigOutput) IncludedFields() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfig) []string { return v.IncludedFields }).(pulumi.StringArrayOutput)
}

// The format of the instance that the Model accepts. Vertex AI will convert compatible batch prediction input instance formats to the specified format. Supported values are: * `object`: Each input is converted to JSON object format. * For `bigquery`, each row is converted to an object. * For `jsonl`, each line of the JSONL input must be an object. * Does not apply to `csv`, `file-list`, `tf-record`, or `tf-record-gzip`. * `array`: Each input is converted to JSON array format. * For `bigquery`, each row is converted to an array. The order of columns is determined by the BigQuery column order, unless included_fields is populated. included_fields must be populated for specifying field orders. * For `jsonl`, if each line of the JSONL input is an object, included_fields must be populated for specifying field orders. * Does not apply to `csv`, `file-list`, `tf-record`, or `tf-record-gzip`. If not specified, Vertex AI converts the batch prediction input as follows: * For `bigquery` and `csv`, the behavior is the same as `array`. The order of columns is the same as defined in the file or table, unless included_fields is populated. * For `jsonl`, the prediction instance format is determined by each line of the input. * For `tf-record`/`tf-record-gzip`, each record will be converted to an object in the format of `{"b64": }`, where “is the Base64-encoded string of the content of the record. * For `file-list`, each file in the list will be converted to an object in the format of `{"b64": }`, where“ is the Base64-encoded string of the content of the file.
func (o GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigOutput) InstanceType() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfig) *string { return v.InstanceType }).(pulumi.StringPtrOutput)
}

// The name of the field that is considered as a key. The values identified by the key field is not included in the transformed instances that is sent to the Model. This is similar to specifying this name of the field in excluded_fields. In addition, the batch prediction output will not include the instances. Instead the output will only include the value of the key field, in a field named `key` in the output: * For `jsonl` output format, the output will have a `key` field instead of the `instance` field. * For `csv`/`bigquery` output format, the output will have have a `key` column instead of the instance feature columns. The input must be JSONL with objects at each line, CSV, BigQuery or TfRecord.
func (o GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigOutput) KeyField() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfig) *string { return v.KeyField }).(pulumi.StringPtrOutput)
}

type GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigPtrOutput) ToGoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigPtrOutput() GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigPtrOutput) ToGoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigPtrOutput) Elem() GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfig) GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfig {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfig
		return ret
	}).(GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigOutput)
}

// Fields that will be excluded in the prediction instance that is sent to the Model. Excluded will be attached to the batch prediction output if key_field is not specified. When excluded_fields is populated, included_fields must be empty. The input must be JSONL with objects at each line, CSV, BigQuery or TfRecord.
func (o GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigPtrOutput) ExcludedFields() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfig) []string {
		if v == nil {
			return nil
		}
		return v.ExcludedFields
	}).(pulumi.StringArrayOutput)
}

// Fields that will be included in the prediction instance that is sent to the Model. If instance_type is `array`, the order of field names in included_fields also determines the order of the values in the array. When included_fields is populated, excluded_fields must be empty. The input must be JSONL with objects at each line, CSV, BigQuery or TfRecord.
func (o GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigPtrOutput) IncludedFields() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfig) []string {
		if v == nil {
			return nil
		}
		return v.IncludedFields
	}).(pulumi.StringArrayOutput)
}

// The format of the instance that the Model accepts. Vertex AI will convert compatible batch prediction input instance formats to the specified format. Supported values are: * `object`: Each input is converted to JSON object format. * For `bigquery`, each row is converted to an object. * For `jsonl`, each line of the JSONL input must be an object. * Does not apply to `csv`, `file-list`, `tf-record`, or `tf-record-gzip`. * `array`: Each input is converted to JSON array format. * For `bigquery`, each row is converted to an array. The order of columns is determined by the BigQuery column order, unless included_fields is populated. included_fields must be populated for specifying field orders. * For `jsonl`, if each line of the JSONL input is an object, included_fields must be populated for specifying field orders. * Does not apply to `csv`, `file-list`, `tf-record`, or `tf-record-gzip`. If not specified, Vertex AI converts the batch prediction input as follows: * For `bigquery` and `csv`, the behavior is the same as `array`. The order of columns is the same as defined in the file or table, unless included_fields is populated. * For `jsonl`, the prediction instance format is determined by each line of the input. * For `tf-record`/`tf-record-gzip`, each record will be converted to an object in the format of `{"b64": }`, where “is the Base64-encoded string of the content of the record. * For `file-list`, each file in the list will be converted to an object in the format of `{"b64": }`, where“ is the Base64-encoded string of the content of the file.
func (o GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigPtrOutput) InstanceType() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfig) *string {
		if v == nil {
			return nil
		}
		return v.InstanceType
	}).(pulumi.StringPtrOutput)
}

// The name of the field that is considered as a key. The values identified by the key field is not included in the transformed instances that is sent to the Model. This is similar to specifying this name of the field in excluded_fields. In addition, the batch prediction output will not include the instances. Instead the output will only include the value of the key field, in a field named `key` in the output: * For `jsonl` output format, the output will have a `key` field instead of the `instance` field. * For `csv`/`bigquery` output format, the output will have have a `key` column instead of the instance feature columns. The input must be JSONL with objects at each line, CSV, BigQuery or TfRecord.
func (o GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigPtrOutput) KeyField() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfig) *string {
		if v == nil {
			return nil
		}
		return v.KeyField
	}).(pulumi.StringPtrOutput)
}

// Configuration defining how to transform batch prediction input instances to the instances that the Model accepts.
type GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigResponse struct {
	// Fields that will be excluded in the prediction instance that is sent to the Model. Excluded will be attached to the batch prediction output if key_field is not specified. When excluded_fields is populated, included_fields must be empty. The input must be JSONL with objects at each line, CSV, BigQuery or TfRecord.
	ExcludedFields []string `pulumi:"excludedFields"`
	// Fields that will be included in the prediction instance that is sent to the Model. If instance_type is `array`, the order of field names in included_fields also determines the order of the values in the array. When included_fields is populated, excluded_fields must be empty. The input must be JSONL with objects at each line, CSV, BigQuery or TfRecord.
	IncludedFields []string `pulumi:"includedFields"`
	// The format of the instance that the Model accepts. Vertex AI will convert compatible batch prediction input instance formats to the specified format. Supported values are: * `object`: Each input is converted to JSON object format. * For `bigquery`, each row is converted to an object. * For `jsonl`, each line of the JSONL input must be an object. * Does not apply to `csv`, `file-list`, `tf-record`, or `tf-record-gzip`. * `array`: Each input is converted to JSON array format. * For `bigquery`, each row is converted to an array. The order of columns is determined by the BigQuery column order, unless included_fields is populated. included_fields must be populated for specifying field orders. * For `jsonl`, if each line of the JSONL input is an object, included_fields must be populated for specifying field orders. * Does not apply to `csv`, `file-list`, `tf-record`, or `tf-record-gzip`. If not specified, Vertex AI converts the batch prediction input as follows: * For `bigquery` and `csv`, the behavior is the same as `array`. The order of columns is the same as defined in the file or table, unless included_fields is populated. * For `jsonl`, the prediction instance format is determined by each line of the input. * For `tf-record`/`tf-record-gzip`, each record will be converted to an object in the format of `{"b64": }`, where ``is the Base64-encoded string of the content of the record. * For `file-list`, each file in the list will be converted to an object in the format of `{"b64": }`, where`` is the Base64-encoded string of the content of the file.
	InstanceType string `pulumi:"instanceType"`
	// The name of the field that is considered as a key. The values identified by the key field is not included in the transformed instances that is sent to the Model. This is similar to specifying this name of the field in excluded_fields. In addition, the batch prediction output will not include the instances. Instead the output will only include the value of the key field, in a field named `key` in the output: * For `jsonl` output format, the output will have a `key` field instead of the `instance` field. * For `csv`/`bigquery` output format, the output will have have a `key` column instead of the instance feature columns. The input must be JSONL with objects at each line, CSV, BigQuery or TfRecord.
	KeyField string `pulumi:"keyField"`
}

// Configuration defining how to transform batch prediction input instances to the instances that the Model accepts.
type GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigResponseOutput) ToGoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigResponseOutput() GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigResponseOutput) ToGoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigResponseOutput {
	return o
}

// Fields that will be excluded in the prediction instance that is sent to the Model. Excluded will be attached to the batch prediction output if key_field is not specified. When excluded_fields is populated, included_fields must be empty. The input must be JSONL with objects at each line, CSV, BigQuery or TfRecord.
func (o GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigResponseOutput) ExcludedFields() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigResponse) []string {
		return v.ExcludedFields
	}).(pulumi.StringArrayOutput)
}

// Fields that will be included in the prediction instance that is sent to the Model. If instance_type is `array`, the order of field names in included_fields also determines the order of the values in the array. When included_fields is populated, excluded_fields must be empty. The input must be JSONL with objects at each line, CSV, BigQuery or TfRecord.
func (o GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigResponseOutput) IncludedFields() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigResponse) []string {
		return v.IncludedFields
	}).(pulumi.StringArrayOutput)
}

// The format of the instance that the Model accepts. Vertex AI will convert compatible batch prediction input instance formats to the specified format. Supported values are: * `object`: Each input is converted to JSON object format. * For `bigquery`, each row is converted to an object. * For `jsonl`, each line of the JSONL input must be an object. * Does not apply to `csv`, `file-list`, `tf-record`, or `tf-record-gzip`. * `array`: Each input is converted to JSON array format. * For `bigquery`, each row is converted to an array. The order of columns is determined by the BigQuery column order, unless included_fields is populated. included_fields must be populated for specifying field orders. * For `jsonl`, if each line of the JSONL input is an object, included_fields must be populated for specifying field orders. * Does not apply to `csv`, `file-list`, `tf-record`, or `tf-record-gzip`. If not specified, Vertex AI converts the batch prediction input as follows: * For `bigquery` and `csv`, the behavior is the same as `array`. The order of columns is the same as defined in the file or table, unless included_fields is populated. * For `jsonl`, the prediction instance format is determined by each line of the input. * For `tf-record`/`tf-record-gzip`, each record will be converted to an object in the format of `{"b64": }`, where “is the Base64-encoded string of the content of the record. * For `file-list`, each file in the list will be converted to an object in the format of `{"b64": }`, where“ is the Base64-encoded string of the content of the file.
func (o GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigResponseOutput) InstanceType() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigResponse) string {
		return v.InstanceType
	}).(pulumi.StringOutput)
}

// The name of the field that is considered as a key. The values identified by the key field is not included in the transformed instances that is sent to the Model. This is similar to specifying this name of the field in excluded_fields. In addition, the batch prediction output will not include the instances. Instead the output will only include the value of the key field, in a field named `key` in the output: * For `jsonl` output format, the output will have a `key` field instead of the `instance` field. * For `csv`/`bigquery` output format, the output will have have a `key` column instead of the instance feature columns. The input must be JSONL with objects at each line, CSV, BigQuery or TfRecord.
func (o GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigResponseOutput) KeyField() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigResponse) string { return v.KeyField }).(pulumi.StringOutput)
}

// Configures the output of BatchPredictionJob. See Model.supported_output_storage_formats for supported output formats, and how predictions are expressed via any of them.
type GoogleCloudAiplatformV1beta1BatchPredictionJobOutputConfig struct {
	// The BigQuery project or dataset location where the output is to be written to. If project is provided, a new dataset is created with name `prediction__` where is made BigQuery-dataset-name compatible (for example, most special characters become underscores), and timestamp is in YYYY_MM_DDThh_mm_ss_sssZ "based on ISO-8601" format. In the dataset two tables will be created, `predictions`, and `errors`. If the Model has both instance and prediction schemata defined then the tables have columns as follows: The `predictions` table contains instances for which the prediction succeeded, it has columns as per a concatenation of the Model's instance and prediction schemata. The `errors` table contains rows for which the prediction has failed, it has instance columns, as per the instance schema, followed by a single "errors" column, which as values has google.rpc.Status represented as a STRUCT, and containing only `code` and `message`.
	BigqueryDestination *GoogleCloudAiplatformV1beta1BigQueryDestination `pulumi:"bigqueryDestination"`
	// The Cloud Storage location of the directory where the output is to be written to. In the given directory a new directory is created. Its name is `prediction--`, where timestamp is in YYYY-MM-DDThh:mm:ss.sssZ ISO-8601 format. Inside of it files `predictions_0001.`, `predictions_0002.`, ..., `predictions_N.` are created where `` depends on chosen predictions_format, and N may equal 0001 and depends on the total number of successfully predicted instances. If the Model has both instance and prediction schemata defined then each such file contains predictions as per the predictions_format. If prediction for any instance failed (partially or completely), then an additional `errors_0001.`, `errors_0002.`,..., `errors_N.` files are created (N depends on total number of failed predictions). These files contain the failed instances, as per their schema, followed by an additional `error` field which as value has google.rpc.Status containing only `code` and `message` fields.
	GcsDestination *GoogleCloudAiplatformV1beta1GcsDestination `pulumi:"gcsDestination"`
	// The format in which Vertex AI gives the predictions, must be one of the Model's supported_output_storage_formats.
	PredictionsFormat string `pulumi:"predictionsFormat"`
}

// GoogleCloudAiplatformV1beta1BatchPredictionJobOutputConfigInput is an input type that accepts GoogleCloudAiplatformV1beta1BatchPredictionJobOutputConfigArgs and GoogleCloudAiplatformV1beta1BatchPredictionJobOutputConfigOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1BatchPredictionJobOutputConfigInput` via:
//
//	GoogleCloudAiplatformV1beta1BatchPredictionJobOutputConfigArgs{...}
type GoogleCloudAiplatformV1beta1BatchPredictionJobOutputConfigInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1BatchPredictionJobOutputConfigOutput() GoogleCloudAiplatformV1beta1BatchPredictionJobOutputConfigOutput
	ToGoogleCloudAiplatformV1beta1BatchPredictionJobOutputConfigOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1BatchPredictionJobOutputConfigOutput
}

// Configures the output of BatchPredictionJob. See Model.supported_output_storage_formats for supported output formats, and how predictions are expressed via any of them.
type GoogleCloudAiplatformV1beta1BatchPredictionJobOutputConfigArgs struct {
	// The BigQuery project or dataset location where the output is to be written to. If project is provided, a new dataset is created with name `prediction__` where is made BigQuery-dataset-name compatible (for example, most special characters become underscores), and timestamp is in YYYY_MM_DDThh_mm_ss_sssZ "based on ISO-8601" format. In the dataset two tables will be created, `predictions`, and `errors`. If the Model has both instance and prediction schemata defined then the tables have columns as follows: The `predictions` table contains instances for which the prediction succeeded, it has columns as per a concatenation of the Model's instance and prediction schemata. The `errors` table contains rows for which the prediction has failed, it has instance columns, as per the instance schema, followed by a single "errors" column, which as values has google.rpc.Status represented as a STRUCT, and containing only `code` and `message`.
	BigqueryDestination GoogleCloudAiplatformV1beta1BigQueryDestinationPtrInput `pulumi:"bigqueryDestination"`
	// The Cloud Storage location of the directory where the output is to be written to. In the given directory a new directory is created. Its name is `prediction--`, where timestamp is in YYYY-MM-DDThh:mm:ss.sssZ ISO-8601 format. Inside of it files `predictions_0001.`, `predictions_0002.`, ..., `predictions_N.` are created where `` depends on chosen predictions_format, and N may equal 0001 and depends on the total number of successfully predicted instances. If the Model has both instance and prediction schemata defined then each such file contains predictions as per the predictions_format. If prediction for any instance failed (partially or completely), then an additional `errors_0001.`, `errors_0002.`,..., `errors_N.` files are created (N depends on total number of failed predictions). These files contain the failed instances, as per their schema, followed by an additional `error` field which as value has google.rpc.Status containing only `code` and `message` fields.
	GcsDestination GoogleCloudAiplatformV1beta1GcsDestinationPtrInput `pulumi:"gcsDestination"`
	// The format in which Vertex AI gives the predictions, must be one of the Model's supported_output_storage_formats.
	PredictionsFormat pulumi.StringInput `pulumi:"predictionsFormat"`
}

func (GoogleCloudAiplatformV1beta1BatchPredictionJobOutputConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1BatchPredictionJobOutputConfig)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1BatchPredictionJobOutputConfigArgs) ToGoogleCloudAiplatformV1beta1BatchPredictionJobOutputConfigOutput() GoogleCloudAiplatformV1beta1BatchPredictionJobOutputConfigOutput {
	return i.ToGoogleCloudAiplatformV1beta1BatchPredictionJobOutputConfigOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1BatchPredictionJobOutputConfigArgs) ToGoogleCloudAiplatformV1beta1BatchPredictionJobOutputConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1BatchPredictionJobOutputConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1BatchPredictionJobOutputConfigOutput)
}

// Configures the output of BatchPredictionJob. See Model.supported_output_storage_formats for supported output formats, and how predictions are expressed via any of them.
type GoogleCloudAiplatformV1beta1BatchPredictionJobOutputConfigOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1BatchPredictionJobOutputConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1BatchPredictionJobOutputConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1BatchPredictionJobOutputConfigOutput) ToGoogleCloudAiplatformV1beta1BatchPredictionJobOutputConfigOutput() GoogleCloudAiplatformV1beta1BatchPredictionJobOutputConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1BatchPredictionJobOutputConfigOutput) ToGoogleCloudAiplatformV1beta1BatchPredictionJobOutputConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1BatchPredictionJobOutputConfigOutput {
	return o
}

// The BigQuery project or dataset location where the output is to be written to. If project is provided, a new dataset is created with name `prediction__` where is made BigQuery-dataset-name compatible (for example, most special characters become underscores), and timestamp is in YYYY_MM_DDThh_mm_ss_sssZ "based on ISO-8601" format. In the dataset two tables will be created, `predictions`, and `errors`. If the Model has both instance and prediction schemata defined then the tables have columns as follows: The `predictions` table contains instances for which the prediction succeeded, it has columns as per a concatenation of the Model's instance and prediction schemata. The `errors` table contains rows for which the prediction has failed, it has instance columns, as per the instance schema, followed by a single "errors" column, which as values has google.rpc.Status represented as a STRUCT, and containing only `code` and `message`.
func (o GoogleCloudAiplatformV1beta1BatchPredictionJobOutputConfigOutput) BigqueryDestination() GoogleCloudAiplatformV1beta1BigQueryDestinationPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1BatchPredictionJobOutputConfig) *GoogleCloudAiplatformV1beta1BigQueryDestination {
		return v.BigqueryDestination
	}).(GoogleCloudAiplatformV1beta1BigQueryDestinationPtrOutput)
}

// The Cloud Storage location of the directory where the output is to be written to. In the given directory a new directory is created. Its name is `prediction--`, where timestamp is in YYYY-MM-DDThh:mm:ss.sssZ ISO-8601 format. Inside of it files `predictions_0001.`, `predictions_0002.`, ..., `predictions_N.` are created where “ depends on chosen predictions_format, and N may equal 0001 and depends on the total number of successfully predicted instances. If the Model has both instance and prediction schemata defined then each such file contains predictions as per the predictions_format. If prediction for any instance failed (partially or completely), then an additional `errors_0001.`, `errors_0002.`,..., `errors_N.` files are created (N depends on total number of failed predictions). These files contain the failed instances, as per their schema, followed by an additional `error` field which as value has google.rpc.Status containing only `code` and `message` fields.
func (o GoogleCloudAiplatformV1beta1BatchPredictionJobOutputConfigOutput) GcsDestination() GoogleCloudAiplatformV1beta1GcsDestinationPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1BatchPredictionJobOutputConfig) *GoogleCloudAiplatformV1beta1GcsDestination {
		return v.GcsDestination
	}).(GoogleCloudAiplatformV1beta1GcsDestinationPtrOutput)
}

// The format in which Vertex AI gives the predictions, must be one of the Model's supported_output_storage_formats.
func (o GoogleCloudAiplatformV1beta1BatchPredictionJobOutputConfigOutput) PredictionsFormat() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1BatchPredictionJobOutputConfig) string { return v.PredictionsFormat }).(pulumi.StringOutput)
}

// Configures the output of BatchPredictionJob. See Model.supported_output_storage_formats for supported output formats, and how predictions are expressed via any of them.
type GoogleCloudAiplatformV1beta1BatchPredictionJobOutputConfigResponse struct {
	// The BigQuery project or dataset location where the output is to be written to. If project is provided, a new dataset is created with name `prediction__` where is made BigQuery-dataset-name compatible (for example, most special characters become underscores), and timestamp is in YYYY_MM_DDThh_mm_ss_sssZ "based on ISO-8601" format. In the dataset two tables will be created, `predictions`, and `errors`. If the Model has both instance and prediction schemata defined then the tables have columns as follows: The `predictions` table contains instances for which the prediction succeeded, it has columns as per a concatenation of the Model's instance and prediction schemata. The `errors` table contains rows for which the prediction has failed, it has instance columns, as per the instance schema, followed by a single "errors" column, which as values has google.rpc.Status represented as a STRUCT, and containing only `code` and `message`.
	BigqueryDestination GoogleCloudAiplatformV1beta1BigQueryDestinationResponse `pulumi:"bigqueryDestination"`
	// The Cloud Storage location of the directory where the output is to be written to. In the given directory a new directory is created. Its name is `prediction--`, where timestamp is in YYYY-MM-DDThh:mm:ss.sssZ ISO-8601 format. Inside of it files `predictions_0001.`, `predictions_0002.`, ..., `predictions_N.` are created where `` depends on chosen predictions_format, and N may equal 0001 and depends on the total number of successfully predicted instances. If the Model has both instance and prediction schemata defined then each such file contains predictions as per the predictions_format. If prediction for any instance failed (partially or completely), then an additional `errors_0001.`, `errors_0002.`,..., `errors_N.` files are created (N depends on total number of failed predictions). These files contain the failed instances, as per their schema, followed by an additional `error` field which as value has google.rpc.Status containing only `code` and `message` fields.
	GcsDestination GoogleCloudAiplatformV1beta1GcsDestinationResponse `pulumi:"gcsDestination"`
	// The format in which Vertex AI gives the predictions, must be one of the Model's supported_output_storage_formats.
	PredictionsFormat string `pulumi:"predictionsFormat"`
}

// Configures the output of BatchPredictionJob. See Model.supported_output_storage_formats for supported output formats, and how predictions are expressed via any of them.
type GoogleCloudAiplatformV1beta1BatchPredictionJobOutputConfigResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1BatchPredictionJobOutputConfigResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1BatchPredictionJobOutputConfigResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1BatchPredictionJobOutputConfigResponseOutput) ToGoogleCloudAiplatformV1beta1BatchPredictionJobOutputConfigResponseOutput() GoogleCloudAiplatformV1beta1BatchPredictionJobOutputConfigResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1BatchPredictionJobOutputConfigResponseOutput) ToGoogleCloudAiplatformV1beta1BatchPredictionJobOutputConfigResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1BatchPredictionJobOutputConfigResponseOutput {
	return o
}

// The BigQuery project or dataset location where the output is to be written to. If project is provided, a new dataset is created with name `prediction__` where is made BigQuery-dataset-name compatible (for example, most special characters become underscores), and timestamp is in YYYY_MM_DDThh_mm_ss_sssZ "based on ISO-8601" format. In the dataset two tables will be created, `predictions`, and `errors`. If the Model has both instance and prediction schemata defined then the tables have columns as follows: The `predictions` table contains instances for which the prediction succeeded, it has columns as per a concatenation of the Model's instance and prediction schemata. The `errors` table contains rows for which the prediction has failed, it has instance columns, as per the instance schema, followed by a single "errors" column, which as values has google.rpc.Status represented as a STRUCT, and containing only `code` and `message`.
func (o GoogleCloudAiplatformV1beta1BatchPredictionJobOutputConfigResponseOutput) BigqueryDestination() GoogleCloudAiplatformV1beta1BigQueryDestinationResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1BatchPredictionJobOutputConfigResponse) GoogleCloudAiplatformV1beta1BigQueryDestinationResponse {
		return v.BigqueryDestination
	}).(GoogleCloudAiplatformV1beta1BigQueryDestinationResponseOutput)
}

// The Cloud Storage location of the directory where the output is to be written to. In the given directory a new directory is created. Its name is `prediction--`, where timestamp is in YYYY-MM-DDThh:mm:ss.sssZ ISO-8601 format. Inside of it files `predictions_0001.`, `predictions_0002.`, ..., `predictions_N.` are created where “ depends on chosen predictions_format, and N may equal 0001 and depends on the total number of successfully predicted instances. If the Model has both instance and prediction schemata defined then each such file contains predictions as per the predictions_format. If prediction for any instance failed (partially or completely), then an additional `errors_0001.`, `errors_0002.`,..., `errors_N.` files are created (N depends on total number of failed predictions). These files contain the failed instances, as per their schema, followed by an additional `error` field which as value has google.rpc.Status containing only `code` and `message` fields.
func (o GoogleCloudAiplatformV1beta1BatchPredictionJobOutputConfigResponseOutput) GcsDestination() GoogleCloudAiplatformV1beta1GcsDestinationResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1BatchPredictionJobOutputConfigResponse) GoogleCloudAiplatformV1beta1GcsDestinationResponse {
		return v.GcsDestination
	}).(GoogleCloudAiplatformV1beta1GcsDestinationResponseOutput)
}

// The format in which Vertex AI gives the predictions, must be one of the Model's supported_output_storage_formats.
func (o GoogleCloudAiplatformV1beta1BatchPredictionJobOutputConfigResponseOutput) PredictionsFormat() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1BatchPredictionJobOutputConfigResponse) string {
		return v.PredictionsFormat
	}).(pulumi.StringOutput)
}

// Further describes this job's output. Supplements output_config.
type GoogleCloudAiplatformV1beta1BatchPredictionJobOutputInfoResponse struct {
	// The path of the BigQuery dataset created, in `bq://projectId.bqDatasetId` format, into which the prediction output is written.
	BigqueryOutputDataset string `pulumi:"bigqueryOutputDataset"`
	// The name of the BigQuery table created, in `predictions_` format, into which the prediction output is written. Can be used by UI to generate the BigQuery output path, for example.
	BigqueryOutputTable string `pulumi:"bigqueryOutputTable"`
	// The full path of the Cloud Storage directory created, into which the prediction output is written.
	GcsOutputDirectory string `pulumi:"gcsOutputDirectory"`
}

// Further describes this job's output. Supplements output_config.
type GoogleCloudAiplatformV1beta1BatchPredictionJobOutputInfoResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1BatchPredictionJobOutputInfoResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1BatchPredictionJobOutputInfoResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1BatchPredictionJobOutputInfoResponseOutput) ToGoogleCloudAiplatformV1beta1BatchPredictionJobOutputInfoResponseOutput() GoogleCloudAiplatformV1beta1BatchPredictionJobOutputInfoResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1BatchPredictionJobOutputInfoResponseOutput) ToGoogleCloudAiplatformV1beta1BatchPredictionJobOutputInfoResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1BatchPredictionJobOutputInfoResponseOutput {
	return o
}

// The path of the BigQuery dataset created, in `bq://projectId.bqDatasetId` format, into which the prediction output is written.
func (o GoogleCloudAiplatformV1beta1BatchPredictionJobOutputInfoResponseOutput) BigqueryOutputDataset() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1BatchPredictionJobOutputInfoResponse) string {
		return v.BigqueryOutputDataset
	}).(pulumi.StringOutput)
}

// The name of the BigQuery table created, in `predictions_` format, into which the prediction output is written. Can be used by UI to generate the BigQuery output path, for example.
func (o GoogleCloudAiplatformV1beta1BatchPredictionJobOutputInfoResponseOutput) BigqueryOutputTable() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1BatchPredictionJobOutputInfoResponse) string {
		return v.BigqueryOutputTable
	}).(pulumi.StringOutput)
}

// The full path of the Cloud Storage directory created, into which the prediction output is written.
func (o GoogleCloudAiplatformV1beta1BatchPredictionJobOutputInfoResponseOutput) GcsOutputDirectory() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1BatchPredictionJobOutputInfoResponse) string {
		return v.GcsOutputDirectory
	}).(pulumi.StringOutput)
}

// The BigQuery location for the output content.
type GoogleCloudAiplatformV1beta1BigQueryDestination struct {
	// BigQuery URI to a project or table, up to 2000 characters long. When only the project is specified, the Dataset and Table is created. When the full table reference is specified, the Dataset must exist and table must not exist. Accepted forms: * BigQuery path. For example: `bq://projectId` or `bq://projectId.bqDatasetId` or `bq://projectId.bqDatasetId.bqTableId`.
	OutputUri string `pulumi:"outputUri"`
}

// GoogleCloudAiplatformV1beta1BigQueryDestinationInput is an input type that accepts GoogleCloudAiplatformV1beta1BigQueryDestinationArgs and GoogleCloudAiplatformV1beta1BigQueryDestinationOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1BigQueryDestinationInput` via:
//
//	GoogleCloudAiplatformV1beta1BigQueryDestinationArgs{...}
type GoogleCloudAiplatformV1beta1BigQueryDestinationInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1BigQueryDestinationOutput() GoogleCloudAiplatformV1beta1BigQueryDestinationOutput
	ToGoogleCloudAiplatformV1beta1BigQueryDestinationOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1BigQueryDestinationOutput
}

// The BigQuery location for the output content.
type GoogleCloudAiplatformV1beta1BigQueryDestinationArgs struct {
	// BigQuery URI to a project or table, up to 2000 characters long. When only the project is specified, the Dataset and Table is created. When the full table reference is specified, the Dataset must exist and table must not exist. Accepted forms: * BigQuery path. For example: `bq://projectId` or `bq://projectId.bqDatasetId` or `bq://projectId.bqDatasetId.bqTableId`.
	OutputUri pulumi.StringInput `pulumi:"outputUri"`
}

func (GoogleCloudAiplatformV1beta1BigQueryDestinationArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1BigQueryDestination)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1BigQueryDestinationArgs) ToGoogleCloudAiplatformV1beta1BigQueryDestinationOutput() GoogleCloudAiplatformV1beta1BigQueryDestinationOutput {
	return i.ToGoogleCloudAiplatformV1beta1BigQueryDestinationOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1BigQueryDestinationArgs) ToGoogleCloudAiplatformV1beta1BigQueryDestinationOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1BigQueryDestinationOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1BigQueryDestinationOutput)
}

func (i GoogleCloudAiplatformV1beta1BigQueryDestinationArgs) ToGoogleCloudAiplatformV1beta1BigQueryDestinationPtrOutput() GoogleCloudAiplatformV1beta1BigQueryDestinationPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1BigQueryDestinationPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1BigQueryDestinationArgs) ToGoogleCloudAiplatformV1beta1BigQueryDestinationPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1BigQueryDestinationPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1BigQueryDestinationOutput).ToGoogleCloudAiplatformV1beta1BigQueryDestinationPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1BigQueryDestinationPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1BigQueryDestinationArgs, GoogleCloudAiplatformV1beta1BigQueryDestinationPtr and GoogleCloudAiplatformV1beta1BigQueryDestinationPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1BigQueryDestinationPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1BigQueryDestinationArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1BigQueryDestinationPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1BigQueryDestinationPtrOutput() GoogleCloudAiplatformV1beta1BigQueryDestinationPtrOutput
	ToGoogleCloudAiplatformV1beta1BigQueryDestinationPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1BigQueryDestinationPtrOutput
}

type googleCloudAiplatformV1beta1BigQueryDestinationPtrType GoogleCloudAiplatformV1beta1BigQueryDestinationArgs

func GoogleCloudAiplatformV1beta1BigQueryDestinationPtr(v *GoogleCloudAiplatformV1beta1BigQueryDestinationArgs) GoogleCloudAiplatformV1beta1BigQueryDestinationPtrInput {
	return (*googleCloudAiplatformV1beta1BigQueryDestinationPtrType)(v)
}

func (*googleCloudAiplatformV1beta1BigQueryDestinationPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1BigQueryDestination)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1BigQueryDestinationPtrType) ToGoogleCloudAiplatformV1beta1BigQueryDestinationPtrOutput() GoogleCloudAiplatformV1beta1BigQueryDestinationPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1BigQueryDestinationPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1BigQueryDestinationPtrType) ToGoogleCloudAiplatformV1beta1BigQueryDestinationPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1BigQueryDestinationPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1BigQueryDestinationPtrOutput)
}

// The BigQuery location for the output content.
type GoogleCloudAiplatformV1beta1BigQueryDestinationOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1BigQueryDestinationOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1BigQueryDestination)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1BigQueryDestinationOutput) ToGoogleCloudAiplatformV1beta1BigQueryDestinationOutput() GoogleCloudAiplatformV1beta1BigQueryDestinationOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1BigQueryDestinationOutput) ToGoogleCloudAiplatformV1beta1BigQueryDestinationOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1BigQueryDestinationOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1BigQueryDestinationOutput) ToGoogleCloudAiplatformV1beta1BigQueryDestinationPtrOutput() GoogleCloudAiplatformV1beta1BigQueryDestinationPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1BigQueryDestinationPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1BigQueryDestinationOutput) ToGoogleCloudAiplatformV1beta1BigQueryDestinationPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1BigQueryDestinationPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1BigQueryDestination) *GoogleCloudAiplatformV1beta1BigQueryDestination {
		return &v
	}).(GoogleCloudAiplatformV1beta1BigQueryDestinationPtrOutput)
}

// BigQuery URI to a project or table, up to 2000 characters long. When only the project is specified, the Dataset and Table is created. When the full table reference is specified, the Dataset must exist and table must not exist. Accepted forms: * BigQuery path. For example: `bq://projectId` or `bq://projectId.bqDatasetId` or `bq://projectId.bqDatasetId.bqTableId`.
func (o GoogleCloudAiplatformV1beta1BigQueryDestinationOutput) OutputUri() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1BigQueryDestination) string { return v.OutputUri }).(pulumi.StringOutput)
}

type GoogleCloudAiplatformV1beta1BigQueryDestinationPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1BigQueryDestinationPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1BigQueryDestination)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1BigQueryDestinationPtrOutput) ToGoogleCloudAiplatformV1beta1BigQueryDestinationPtrOutput() GoogleCloudAiplatformV1beta1BigQueryDestinationPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1BigQueryDestinationPtrOutput) ToGoogleCloudAiplatformV1beta1BigQueryDestinationPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1BigQueryDestinationPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1BigQueryDestinationPtrOutput) Elem() GoogleCloudAiplatformV1beta1BigQueryDestinationOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1BigQueryDestination) GoogleCloudAiplatformV1beta1BigQueryDestination {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1BigQueryDestination
		return ret
	}).(GoogleCloudAiplatformV1beta1BigQueryDestinationOutput)
}

// BigQuery URI to a project or table, up to 2000 characters long. When only the project is specified, the Dataset and Table is created. When the full table reference is specified, the Dataset must exist and table must not exist. Accepted forms: * BigQuery path. For example: `bq://projectId` or `bq://projectId.bqDatasetId` or `bq://projectId.bqDatasetId.bqTableId`.
func (o GoogleCloudAiplatformV1beta1BigQueryDestinationPtrOutput) OutputUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1BigQueryDestination) *string {
		if v == nil {
			return nil
		}
		return &v.OutputUri
	}).(pulumi.StringPtrOutput)
}

// The BigQuery location for the output content.
type GoogleCloudAiplatformV1beta1BigQueryDestinationResponse struct {
	// BigQuery URI to a project or table, up to 2000 characters long. When only the project is specified, the Dataset and Table is created. When the full table reference is specified, the Dataset must exist and table must not exist. Accepted forms: * BigQuery path. For example: `bq://projectId` or `bq://projectId.bqDatasetId` or `bq://projectId.bqDatasetId.bqTableId`.
	OutputUri string `pulumi:"outputUri"`
}

// The BigQuery location for the output content.
type GoogleCloudAiplatformV1beta1BigQueryDestinationResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1BigQueryDestinationResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1BigQueryDestinationResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1BigQueryDestinationResponseOutput) ToGoogleCloudAiplatformV1beta1BigQueryDestinationResponseOutput() GoogleCloudAiplatformV1beta1BigQueryDestinationResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1BigQueryDestinationResponseOutput) ToGoogleCloudAiplatformV1beta1BigQueryDestinationResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1BigQueryDestinationResponseOutput {
	return o
}

// BigQuery URI to a project or table, up to 2000 characters long. When only the project is specified, the Dataset and Table is created. When the full table reference is specified, the Dataset must exist and table must not exist. Accepted forms: * BigQuery path. For example: `bq://projectId` or `bq://projectId.bqDatasetId` or `bq://projectId.bqDatasetId.bqTableId`.
func (o GoogleCloudAiplatformV1beta1BigQueryDestinationResponseOutput) OutputUri() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1BigQueryDestinationResponse) string { return v.OutputUri }).(pulumi.StringOutput)
}

// The BigQuery location for the input content.
type GoogleCloudAiplatformV1beta1BigQuerySource struct {
	// BigQuery URI to a table, up to 2000 characters long. Accepted forms: * BigQuery path. For example: `bq://projectId.bqDatasetId.bqTableId`.
	InputUri string `pulumi:"inputUri"`
}

// GoogleCloudAiplatformV1beta1BigQuerySourceInput is an input type that accepts GoogleCloudAiplatformV1beta1BigQuerySourceArgs and GoogleCloudAiplatformV1beta1BigQuerySourceOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1BigQuerySourceInput` via:
//
//	GoogleCloudAiplatformV1beta1BigQuerySourceArgs{...}
type GoogleCloudAiplatformV1beta1BigQuerySourceInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1BigQuerySourceOutput() GoogleCloudAiplatformV1beta1BigQuerySourceOutput
	ToGoogleCloudAiplatformV1beta1BigQuerySourceOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1BigQuerySourceOutput
}

// The BigQuery location for the input content.
type GoogleCloudAiplatformV1beta1BigQuerySourceArgs struct {
	// BigQuery URI to a table, up to 2000 characters long. Accepted forms: * BigQuery path. For example: `bq://projectId.bqDatasetId.bqTableId`.
	InputUri pulumi.StringInput `pulumi:"inputUri"`
}

func (GoogleCloudAiplatformV1beta1BigQuerySourceArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1BigQuerySource)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1BigQuerySourceArgs) ToGoogleCloudAiplatformV1beta1BigQuerySourceOutput() GoogleCloudAiplatformV1beta1BigQuerySourceOutput {
	return i.ToGoogleCloudAiplatformV1beta1BigQuerySourceOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1BigQuerySourceArgs) ToGoogleCloudAiplatformV1beta1BigQuerySourceOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1BigQuerySourceOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1BigQuerySourceOutput)
}

func (i GoogleCloudAiplatformV1beta1BigQuerySourceArgs) ToGoogleCloudAiplatformV1beta1BigQuerySourcePtrOutput() GoogleCloudAiplatformV1beta1BigQuerySourcePtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1BigQuerySourcePtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1BigQuerySourceArgs) ToGoogleCloudAiplatformV1beta1BigQuerySourcePtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1BigQuerySourcePtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1BigQuerySourceOutput).ToGoogleCloudAiplatformV1beta1BigQuerySourcePtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1BigQuerySourcePtrInput is an input type that accepts GoogleCloudAiplatformV1beta1BigQuerySourceArgs, GoogleCloudAiplatformV1beta1BigQuerySourcePtr and GoogleCloudAiplatformV1beta1BigQuerySourcePtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1BigQuerySourcePtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1BigQuerySourceArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1BigQuerySourcePtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1BigQuerySourcePtrOutput() GoogleCloudAiplatformV1beta1BigQuerySourcePtrOutput
	ToGoogleCloudAiplatformV1beta1BigQuerySourcePtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1BigQuerySourcePtrOutput
}

type googleCloudAiplatformV1beta1BigQuerySourcePtrType GoogleCloudAiplatformV1beta1BigQuerySourceArgs

func GoogleCloudAiplatformV1beta1BigQuerySourcePtr(v *GoogleCloudAiplatformV1beta1BigQuerySourceArgs) GoogleCloudAiplatformV1beta1BigQuerySourcePtrInput {
	return (*googleCloudAiplatformV1beta1BigQuerySourcePtrType)(v)
}

func (*googleCloudAiplatformV1beta1BigQuerySourcePtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1BigQuerySource)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1BigQuerySourcePtrType) ToGoogleCloudAiplatformV1beta1BigQuerySourcePtrOutput() GoogleCloudAiplatformV1beta1BigQuerySourcePtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1BigQuerySourcePtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1BigQuerySourcePtrType) ToGoogleCloudAiplatformV1beta1BigQuerySourcePtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1BigQuerySourcePtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1BigQuerySourcePtrOutput)
}

// The BigQuery location for the input content.
type GoogleCloudAiplatformV1beta1BigQuerySourceOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1BigQuerySourceOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1BigQuerySource)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1BigQuerySourceOutput) ToGoogleCloudAiplatformV1beta1BigQuerySourceOutput() GoogleCloudAiplatformV1beta1BigQuerySourceOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1BigQuerySourceOutput) ToGoogleCloudAiplatformV1beta1BigQuerySourceOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1BigQuerySourceOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1BigQuerySourceOutput) ToGoogleCloudAiplatformV1beta1BigQuerySourcePtrOutput() GoogleCloudAiplatformV1beta1BigQuerySourcePtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1BigQuerySourcePtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1BigQuerySourceOutput) ToGoogleCloudAiplatformV1beta1BigQuerySourcePtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1BigQuerySourcePtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1BigQuerySource) *GoogleCloudAiplatformV1beta1BigQuerySource {
		return &v
	}).(GoogleCloudAiplatformV1beta1BigQuerySourcePtrOutput)
}

// BigQuery URI to a table, up to 2000 characters long. Accepted forms: * BigQuery path. For example: `bq://projectId.bqDatasetId.bqTableId`.
func (o GoogleCloudAiplatformV1beta1BigQuerySourceOutput) InputUri() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1BigQuerySource) string { return v.InputUri }).(pulumi.StringOutput)
}

type GoogleCloudAiplatformV1beta1BigQuerySourcePtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1BigQuerySourcePtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1BigQuerySource)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1BigQuerySourcePtrOutput) ToGoogleCloudAiplatformV1beta1BigQuerySourcePtrOutput() GoogleCloudAiplatformV1beta1BigQuerySourcePtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1BigQuerySourcePtrOutput) ToGoogleCloudAiplatformV1beta1BigQuerySourcePtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1BigQuerySourcePtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1BigQuerySourcePtrOutput) Elem() GoogleCloudAiplatformV1beta1BigQuerySourceOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1BigQuerySource) GoogleCloudAiplatformV1beta1BigQuerySource {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1BigQuerySource
		return ret
	}).(GoogleCloudAiplatformV1beta1BigQuerySourceOutput)
}

// BigQuery URI to a table, up to 2000 characters long. Accepted forms: * BigQuery path. For example: `bq://projectId.bqDatasetId.bqTableId`.
func (o GoogleCloudAiplatformV1beta1BigQuerySourcePtrOutput) InputUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1BigQuerySource) *string {
		if v == nil {
			return nil
		}
		return &v.InputUri
	}).(pulumi.StringPtrOutput)
}

// The BigQuery location for the input content.
type GoogleCloudAiplatformV1beta1BigQuerySourceResponse struct {
	// BigQuery URI to a table, up to 2000 characters long. Accepted forms: * BigQuery path. For example: `bq://projectId.bqDatasetId.bqTableId`.
	InputUri string `pulumi:"inputUri"`
}

// The BigQuery location for the input content.
type GoogleCloudAiplatformV1beta1BigQuerySourceResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1BigQuerySourceResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1BigQuerySourceResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1BigQuerySourceResponseOutput) ToGoogleCloudAiplatformV1beta1BigQuerySourceResponseOutput() GoogleCloudAiplatformV1beta1BigQuerySourceResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1BigQuerySourceResponseOutput) ToGoogleCloudAiplatformV1beta1BigQuerySourceResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1BigQuerySourceResponseOutput {
	return o
}

// BigQuery URI to a table, up to 2000 characters long. Accepted forms: * BigQuery path. For example: `bq://projectId.bqDatasetId.bqTableId`.
func (o GoogleCloudAiplatformV1beta1BigQuerySourceResponseOutput) InputUri() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1BigQuerySourceResponse) string { return v.InputUri }).(pulumi.StringOutput)
}

// Config for blur baseline. When enabled, a linear path from the maximally blurred image to the input image is created. Using a blurred baseline instead of zero (black image) is motivated by the BlurIG approach explained here: https://arxiv.org/abs/2004.03383
type GoogleCloudAiplatformV1beta1BlurBaselineConfig struct {
	// The standard deviation of the blur kernel for the blurred baseline. The same blurring parameter is used for both the height and the width dimension. If not set, the method defaults to the zero (i.e. black for images) baseline.
	MaxBlurSigma *float64 `pulumi:"maxBlurSigma"`
}

// GoogleCloudAiplatformV1beta1BlurBaselineConfigInput is an input type that accepts GoogleCloudAiplatformV1beta1BlurBaselineConfigArgs and GoogleCloudAiplatformV1beta1BlurBaselineConfigOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1BlurBaselineConfigInput` via:
//
//	GoogleCloudAiplatformV1beta1BlurBaselineConfigArgs{...}
type GoogleCloudAiplatformV1beta1BlurBaselineConfigInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1BlurBaselineConfigOutput() GoogleCloudAiplatformV1beta1BlurBaselineConfigOutput
	ToGoogleCloudAiplatformV1beta1BlurBaselineConfigOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1BlurBaselineConfigOutput
}

// Config for blur baseline. When enabled, a linear path from the maximally blurred image to the input image is created. Using a blurred baseline instead of zero (black image) is motivated by the BlurIG approach explained here: https://arxiv.org/abs/2004.03383
type GoogleCloudAiplatformV1beta1BlurBaselineConfigArgs struct {
	// The standard deviation of the blur kernel for the blurred baseline. The same blurring parameter is used for both the height and the width dimension. If not set, the method defaults to the zero (i.e. black for images) baseline.
	MaxBlurSigma pulumi.Float64PtrInput `pulumi:"maxBlurSigma"`
}

func (GoogleCloudAiplatformV1beta1BlurBaselineConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1BlurBaselineConfig)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1BlurBaselineConfigArgs) ToGoogleCloudAiplatformV1beta1BlurBaselineConfigOutput() GoogleCloudAiplatformV1beta1BlurBaselineConfigOutput {
	return i.ToGoogleCloudAiplatformV1beta1BlurBaselineConfigOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1BlurBaselineConfigArgs) ToGoogleCloudAiplatformV1beta1BlurBaselineConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1BlurBaselineConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1BlurBaselineConfigOutput)
}

func (i GoogleCloudAiplatformV1beta1BlurBaselineConfigArgs) ToGoogleCloudAiplatformV1beta1BlurBaselineConfigPtrOutput() GoogleCloudAiplatformV1beta1BlurBaselineConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1BlurBaselineConfigPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1BlurBaselineConfigArgs) ToGoogleCloudAiplatformV1beta1BlurBaselineConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1BlurBaselineConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1BlurBaselineConfigOutput).ToGoogleCloudAiplatformV1beta1BlurBaselineConfigPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1BlurBaselineConfigPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1BlurBaselineConfigArgs, GoogleCloudAiplatformV1beta1BlurBaselineConfigPtr and GoogleCloudAiplatformV1beta1BlurBaselineConfigPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1BlurBaselineConfigPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1BlurBaselineConfigArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1BlurBaselineConfigPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1BlurBaselineConfigPtrOutput() GoogleCloudAiplatformV1beta1BlurBaselineConfigPtrOutput
	ToGoogleCloudAiplatformV1beta1BlurBaselineConfigPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1BlurBaselineConfigPtrOutput
}

type googleCloudAiplatformV1beta1BlurBaselineConfigPtrType GoogleCloudAiplatformV1beta1BlurBaselineConfigArgs

func GoogleCloudAiplatformV1beta1BlurBaselineConfigPtr(v *GoogleCloudAiplatformV1beta1BlurBaselineConfigArgs) GoogleCloudAiplatformV1beta1BlurBaselineConfigPtrInput {
	return (*googleCloudAiplatformV1beta1BlurBaselineConfigPtrType)(v)
}

func (*googleCloudAiplatformV1beta1BlurBaselineConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1BlurBaselineConfig)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1BlurBaselineConfigPtrType) ToGoogleCloudAiplatformV1beta1BlurBaselineConfigPtrOutput() GoogleCloudAiplatformV1beta1BlurBaselineConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1BlurBaselineConfigPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1BlurBaselineConfigPtrType) ToGoogleCloudAiplatformV1beta1BlurBaselineConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1BlurBaselineConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1BlurBaselineConfigPtrOutput)
}

// Config for blur baseline. When enabled, a linear path from the maximally blurred image to the input image is created. Using a blurred baseline instead of zero (black image) is motivated by the BlurIG approach explained here: https://arxiv.org/abs/2004.03383
type GoogleCloudAiplatformV1beta1BlurBaselineConfigOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1BlurBaselineConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1BlurBaselineConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1BlurBaselineConfigOutput) ToGoogleCloudAiplatformV1beta1BlurBaselineConfigOutput() GoogleCloudAiplatformV1beta1BlurBaselineConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1BlurBaselineConfigOutput) ToGoogleCloudAiplatformV1beta1BlurBaselineConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1BlurBaselineConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1BlurBaselineConfigOutput) ToGoogleCloudAiplatformV1beta1BlurBaselineConfigPtrOutput() GoogleCloudAiplatformV1beta1BlurBaselineConfigPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1BlurBaselineConfigPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1BlurBaselineConfigOutput) ToGoogleCloudAiplatformV1beta1BlurBaselineConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1BlurBaselineConfigPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1BlurBaselineConfig) *GoogleCloudAiplatformV1beta1BlurBaselineConfig {
		return &v
	}).(GoogleCloudAiplatformV1beta1BlurBaselineConfigPtrOutput)
}

// The standard deviation of the blur kernel for the blurred baseline. The same blurring parameter is used for both the height and the width dimension. If not set, the method defaults to the zero (i.e. black for images) baseline.
func (o GoogleCloudAiplatformV1beta1BlurBaselineConfigOutput) MaxBlurSigma() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1BlurBaselineConfig) *float64 { return v.MaxBlurSigma }).(pulumi.Float64PtrOutput)
}

type GoogleCloudAiplatformV1beta1BlurBaselineConfigPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1BlurBaselineConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1BlurBaselineConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1BlurBaselineConfigPtrOutput) ToGoogleCloudAiplatformV1beta1BlurBaselineConfigPtrOutput() GoogleCloudAiplatformV1beta1BlurBaselineConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1BlurBaselineConfigPtrOutput) ToGoogleCloudAiplatformV1beta1BlurBaselineConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1BlurBaselineConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1BlurBaselineConfigPtrOutput) Elem() GoogleCloudAiplatformV1beta1BlurBaselineConfigOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1BlurBaselineConfig) GoogleCloudAiplatformV1beta1BlurBaselineConfig {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1BlurBaselineConfig
		return ret
	}).(GoogleCloudAiplatformV1beta1BlurBaselineConfigOutput)
}

// The standard deviation of the blur kernel for the blurred baseline. The same blurring parameter is used for both the height and the width dimension. If not set, the method defaults to the zero (i.e. black for images) baseline.
func (o GoogleCloudAiplatformV1beta1BlurBaselineConfigPtrOutput) MaxBlurSigma() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1BlurBaselineConfig) *float64 {
		if v == nil {
			return nil
		}
		return v.MaxBlurSigma
	}).(pulumi.Float64PtrOutput)
}

// Config for blur baseline. When enabled, a linear path from the maximally blurred image to the input image is created. Using a blurred baseline instead of zero (black image) is motivated by the BlurIG approach explained here: https://arxiv.org/abs/2004.03383
type GoogleCloudAiplatformV1beta1BlurBaselineConfigResponse struct {
	// The standard deviation of the blur kernel for the blurred baseline. The same blurring parameter is used for both the height and the width dimension. If not set, the method defaults to the zero (i.e. black for images) baseline.
	MaxBlurSigma float64 `pulumi:"maxBlurSigma"`
}

// Config for blur baseline. When enabled, a linear path from the maximally blurred image to the input image is created. Using a blurred baseline instead of zero (black image) is motivated by the BlurIG approach explained here: https://arxiv.org/abs/2004.03383
type GoogleCloudAiplatformV1beta1BlurBaselineConfigResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1BlurBaselineConfigResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1BlurBaselineConfigResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1BlurBaselineConfigResponseOutput) ToGoogleCloudAiplatformV1beta1BlurBaselineConfigResponseOutput() GoogleCloudAiplatformV1beta1BlurBaselineConfigResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1BlurBaselineConfigResponseOutput) ToGoogleCloudAiplatformV1beta1BlurBaselineConfigResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1BlurBaselineConfigResponseOutput {
	return o
}

// The standard deviation of the blur kernel for the blurred baseline. The same blurring parameter is used for both the height and the width dimension. If not set, the method defaults to the zero (i.e. black for images) baseline.
func (o GoogleCloudAiplatformV1beta1BlurBaselineConfigResponseOutput) MaxBlurSigma() pulumi.Float64Output {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1BlurBaselineConfigResponse) float64 { return v.MaxBlurSigma }).(pulumi.Float64Output)
}

// Success and error statistics of processing multiple entities (for example, DataItems or structured data rows) in batch.
type GoogleCloudAiplatformV1beta1CompletionStatsResponse struct {
	// The number of entities for which any error was encountered.
	FailedCount string `pulumi:"failedCount"`
	// In cases when enough errors are encountered a job, pipeline, or operation may be failed as a whole. Below is the number of entities for which the processing had not been finished (either in successful or failed state). Set to -1 if the number is unknown (for example, the operation failed before the total entity number could be collected).
	IncompleteCount string `pulumi:"incompleteCount"`
	// The number of entities that had been processed successfully.
	SuccessfulCount string `pulumi:"successfulCount"`
	// The number of the successful forecast points that are generated by the forecasting model. This is ONLY used by the forecasting batch prediction.
	SuccessfulForecastPointCount string `pulumi:"successfulForecastPointCount"`
}

// Success and error statistics of processing multiple entities (for example, DataItems or structured data rows) in batch.
type GoogleCloudAiplatformV1beta1CompletionStatsResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1CompletionStatsResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1CompletionStatsResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1CompletionStatsResponseOutput) ToGoogleCloudAiplatformV1beta1CompletionStatsResponseOutput() GoogleCloudAiplatformV1beta1CompletionStatsResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1CompletionStatsResponseOutput) ToGoogleCloudAiplatformV1beta1CompletionStatsResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1CompletionStatsResponseOutput {
	return o
}

// The number of entities for which any error was encountered.
func (o GoogleCloudAiplatformV1beta1CompletionStatsResponseOutput) FailedCount() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1CompletionStatsResponse) string { return v.FailedCount }).(pulumi.StringOutput)
}

// In cases when enough errors are encountered a job, pipeline, or operation may be failed as a whole. Below is the number of entities for which the processing had not been finished (either in successful or failed state). Set to -1 if the number is unknown (for example, the operation failed before the total entity number could be collected).
func (o GoogleCloudAiplatformV1beta1CompletionStatsResponseOutput) IncompleteCount() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1CompletionStatsResponse) string { return v.IncompleteCount }).(pulumi.StringOutput)
}

// The number of entities that had been processed successfully.
func (o GoogleCloudAiplatformV1beta1CompletionStatsResponseOutput) SuccessfulCount() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1CompletionStatsResponse) string { return v.SuccessfulCount }).(pulumi.StringOutput)
}

// The number of the successful forecast points that are generated by the forecasting model. This is ONLY used by the forecasting batch prediction.
func (o GoogleCloudAiplatformV1beta1CompletionStatsResponseOutput) SuccessfulForecastPointCount() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1CompletionStatsResponse) string {
		return v.SuccessfulForecastPointCount
	}).(pulumi.StringOutput)
}

// The spec of a Container.
type GoogleCloudAiplatformV1beta1ContainerSpec struct {
	// The arguments to be passed when starting the container.
	Args []string `pulumi:"args"`
	// The command to be invoked when the container is started. It overrides the entrypoint instruction in Dockerfile when provided.
	Command []string `pulumi:"command"`
	// Environment variables to be passed to the container. Maximum limit is 100.
	Env []GoogleCloudAiplatformV1beta1EnvVar `pulumi:"env"`
	// The URI of a container image in the Container Registry that is to be run on each worker replica.
	ImageUri string `pulumi:"imageUri"`
}

// GoogleCloudAiplatformV1beta1ContainerSpecInput is an input type that accepts GoogleCloudAiplatformV1beta1ContainerSpecArgs and GoogleCloudAiplatformV1beta1ContainerSpecOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1ContainerSpecInput` via:
//
//	GoogleCloudAiplatformV1beta1ContainerSpecArgs{...}
type GoogleCloudAiplatformV1beta1ContainerSpecInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1ContainerSpecOutput() GoogleCloudAiplatformV1beta1ContainerSpecOutput
	ToGoogleCloudAiplatformV1beta1ContainerSpecOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1ContainerSpecOutput
}

// The spec of a Container.
type GoogleCloudAiplatformV1beta1ContainerSpecArgs struct {
	// The arguments to be passed when starting the container.
	Args pulumi.StringArrayInput `pulumi:"args"`
	// The command to be invoked when the container is started. It overrides the entrypoint instruction in Dockerfile when provided.
	Command pulumi.StringArrayInput `pulumi:"command"`
	// Environment variables to be passed to the container. Maximum limit is 100.
	Env GoogleCloudAiplatformV1beta1EnvVarArrayInput `pulumi:"env"`
	// The URI of a container image in the Container Registry that is to be run on each worker replica.
	ImageUri pulumi.StringInput `pulumi:"imageUri"`
}

func (GoogleCloudAiplatformV1beta1ContainerSpecArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ContainerSpec)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1ContainerSpecArgs) ToGoogleCloudAiplatformV1beta1ContainerSpecOutput() GoogleCloudAiplatformV1beta1ContainerSpecOutput {
	return i.ToGoogleCloudAiplatformV1beta1ContainerSpecOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1ContainerSpecArgs) ToGoogleCloudAiplatformV1beta1ContainerSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ContainerSpecOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ContainerSpecOutput)
}

func (i GoogleCloudAiplatformV1beta1ContainerSpecArgs) ToGoogleCloudAiplatformV1beta1ContainerSpecPtrOutput() GoogleCloudAiplatformV1beta1ContainerSpecPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1ContainerSpecPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1ContainerSpecArgs) ToGoogleCloudAiplatformV1beta1ContainerSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ContainerSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ContainerSpecOutput).ToGoogleCloudAiplatformV1beta1ContainerSpecPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1ContainerSpecPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1ContainerSpecArgs, GoogleCloudAiplatformV1beta1ContainerSpecPtr and GoogleCloudAiplatformV1beta1ContainerSpecPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1ContainerSpecPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1ContainerSpecArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1ContainerSpecPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1ContainerSpecPtrOutput() GoogleCloudAiplatformV1beta1ContainerSpecPtrOutput
	ToGoogleCloudAiplatformV1beta1ContainerSpecPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1ContainerSpecPtrOutput
}

type googleCloudAiplatformV1beta1ContainerSpecPtrType GoogleCloudAiplatformV1beta1ContainerSpecArgs

func GoogleCloudAiplatformV1beta1ContainerSpecPtr(v *GoogleCloudAiplatformV1beta1ContainerSpecArgs) GoogleCloudAiplatformV1beta1ContainerSpecPtrInput {
	return (*googleCloudAiplatformV1beta1ContainerSpecPtrType)(v)
}

func (*googleCloudAiplatformV1beta1ContainerSpecPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1ContainerSpec)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1ContainerSpecPtrType) ToGoogleCloudAiplatformV1beta1ContainerSpecPtrOutput() GoogleCloudAiplatformV1beta1ContainerSpecPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1ContainerSpecPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1ContainerSpecPtrType) ToGoogleCloudAiplatformV1beta1ContainerSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ContainerSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ContainerSpecPtrOutput)
}

// The spec of a Container.
type GoogleCloudAiplatformV1beta1ContainerSpecOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ContainerSpecOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ContainerSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ContainerSpecOutput) ToGoogleCloudAiplatformV1beta1ContainerSpecOutput() GoogleCloudAiplatformV1beta1ContainerSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ContainerSpecOutput) ToGoogleCloudAiplatformV1beta1ContainerSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ContainerSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ContainerSpecOutput) ToGoogleCloudAiplatformV1beta1ContainerSpecPtrOutput() GoogleCloudAiplatformV1beta1ContainerSpecPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1ContainerSpecPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1ContainerSpecOutput) ToGoogleCloudAiplatformV1beta1ContainerSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ContainerSpecPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1ContainerSpec) *GoogleCloudAiplatformV1beta1ContainerSpec {
		return &v
	}).(GoogleCloudAiplatformV1beta1ContainerSpecPtrOutput)
}

// The arguments to be passed when starting the container.
func (o GoogleCloudAiplatformV1beta1ContainerSpecOutput) Args() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ContainerSpec) []string { return v.Args }).(pulumi.StringArrayOutput)
}

// The command to be invoked when the container is started. It overrides the entrypoint instruction in Dockerfile when provided.
func (o GoogleCloudAiplatformV1beta1ContainerSpecOutput) Command() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ContainerSpec) []string { return v.Command }).(pulumi.StringArrayOutput)
}

// Environment variables to be passed to the container. Maximum limit is 100.
func (o GoogleCloudAiplatformV1beta1ContainerSpecOutput) Env() GoogleCloudAiplatformV1beta1EnvVarArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ContainerSpec) []GoogleCloudAiplatformV1beta1EnvVar { return v.Env }).(GoogleCloudAiplatformV1beta1EnvVarArrayOutput)
}

// The URI of a container image in the Container Registry that is to be run on each worker replica.
func (o GoogleCloudAiplatformV1beta1ContainerSpecOutput) ImageUri() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ContainerSpec) string { return v.ImageUri }).(pulumi.StringOutput)
}

type GoogleCloudAiplatformV1beta1ContainerSpecPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ContainerSpecPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1ContainerSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ContainerSpecPtrOutput) ToGoogleCloudAiplatformV1beta1ContainerSpecPtrOutput() GoogleCloudAiplatformV1beta1ContainerSpecPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ContainerSpecPtrOutput) ToGoogleCloudAiplatformV1beta1ContainerSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ContainerSpecPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ContainerSpecPtrOutput) Elem() GoogleCloudAiplatformV1beta1ContainerSpecOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ContainerSpec) GoogleCloudAiplatformV1beta1ContainerSpec {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1ContainerSpec
		return ret
	}).(GoogleCloudAiplatformV1beta1ContainerSpecOutput)
}

// The arguments to be passed when starting the container.
func (o GoogleCloudAiplatformV1beta1ContainerSpecPtrOutput) Args() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ContainerSpec) []string {
		if v == nil {
			return nil
		}
		return v.Args
	}).(pulumi.StringArrayOutput)
}

// The command to be invoked when the container is started. It overrides the entrypoint instruction in Dockerfile when provided.
func (o GoogleCloudAiplatformV1beta1ContainerSpecPtrOutput) Command() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ContainerSpec) []string {
		if v == nil {
			return nil
		}
		return v.Command
	}).(pulumi.StringArrayOutput)
}

// Environment variables to be passed to the container. Maximum limit is 100.
func (o GoogleCloudAiplatformV1beta1ContainerSpecPtrOutput) Env() GoogleCloudAiplatformV1beta1EnvVarArrayOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ContainerSpec) []GoogleCloudAiplatformV1beta1EnvVar {
		if v == nil {
			return nil
		}
		return v.Env
	}).(GoogleCloudAiplatformV1beta1EnvVarArrayOutput)
}

// The URI of a container image in the Container Registry that is to be run on each worker replica.
func (o GoogleCloudAiplatformV1beta1ContainerSpecPtrOutput) ImageUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ContainerSpec) *string {
		if v == nil {
			return nil
		}
		return &v.ImageUri
	}).(pulumi.StringPtrOutput)
}

// The spec of a Container.
type GoogleCloudAiplatformV1beta1ContainerSpecResponse struct {
	// The arguments to be passed when starting the container.
	Args []string `pulumi:"args"`
	// The command to be invoked when the container is started. It overrides the entrypoint instruction in Dockerfile when provided.
	Command []string `pulumi:"command"`
	// Environment variables to be passed to the container. Maximum limit is 100.
	Env []GoogleCloudAiplatformV1beta1EnvVarResponse `pulumi:"env"`
	// The URI of a container image in the Container Registry that is to be run on each worker replica.
	ImageUri string `pulumi:"imageUri"`
}

// The spec of a Container.
type GoogleCloudAiplatformV1beta1ContainerSpecResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ContainerSpecResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ContainerSpecResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ContainerSpecResponseOutput) ToGoogleCloudAiplatformV1beta1ContainerSpecResponseOutput() GoogleCloudAiplatformV1beta1ContainerSpecResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ContainerSpecResponseOutput) ToGoogleCloudAiplatformV1beta1ContainerSpecResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ContainerSpecResponseOutput {
	return o
}

// The arguments to be passed when starting the container.
func (o GoogleCloudAiplatformV1beta1ContainerSpecResponseOutput) Args() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ContainerSpecResponse) []string { return v.Args }).(pulumi.StringArrayOutput)
}

// The command to be invoked when the container is started. It overrides the entrypoint instruction in Dockerfile when provided.
func (o GoogleCloudAiplatformV1beta1ContainerSpecResponseOutput) Command() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ContainerSpecResponse) []string { return v.Command }).(pulumi.StringArrayOutput)
}

// Environment variables to be passed to the container. Maximum limit is 100.
func (o GoogleCloudAiplatformV1beta1ContainerSpecResponseOutput) Env() GoogleCloudAiplatformV1beta1EnvVarResponseArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ContainerSpecResponse) []GoogleCloudAiplatformV1beta1EnvVarResponse {
		return v.Env
	}).(GoogleCloudAiplatformV1beta1EnvVarResponseArrayOutput)
}

// The URI of a container image in the Container Registry that is to be run on each worker replica.
func (o GoogleCloudAiplatformV1beta1ContainerSpecResponseOutput) ImageUri() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ContainerSpecResponse) string { return v.ImageUri }).(pulumi.StringOutput)
}

// Instance of a general context.
type GoogleCloudAiplatformV1beta1ContextResponse struct {
	// Timestamp when this Context was created.
	CreateTime string `pulumi:"createTime"`
	// Description of the Context
	Description string `pulumi:"description"`
	// User provided display name of the Context. May be up to 128 Unicode characters.
	DisplayName string `pulumi:"displayName"`
	// An eTag used to perform consistent read-modify-write updates. If not set, a blind "overwrite" update happens.
	Etag string `pulumi:"etag"`
	// The labels with user-defined metadata to organize your Contexts. Label keys and values can be no longer than 64 characters (Unicode codepoints), can only contain lowercase letters, numeric characters, underscores and dashes. International characters are allowed. No more than 64 user labels can be associated with one Context (System labels are excluded).
	Labels map[string]string `pulumi:"labels"`
	// Properties of the Context. Top level metadata keys' heading and trailing spaces will be trimmed. The size of this field should not exceed 200KB.
	Metadata map[string]interface{} `pulumi:"metadata"`
	// Immutable. The resource name of the Context.
	Name string `pulumi:"name"`
	// A list of resource names of Contexts that are parents of this Context. A Context may have at most 10 parent_contexts.
	ParentContexts []string `pulumi:"parentContexts"`
	// The title of the schema describing the metadata. Schema title and version is expected to be registered in earlier Create Schema calls. And both are used together as unique identifiers to identify schemas within the local metadata store.
	SchemaTitle string `pulumi:"schemaTitle"`
	// The version of the schema in schema_name to use. Schema title and version is expected to be registered in earlier Create Schema calls. And both are used together as unique identifiers to identify schemas within the local metadata store.
	SchemaVersion string `pulumi:"schemaVersion"`
	// Timestamp when this Context was last updated.
	UpdateTime string `pulumi:"updateTime"`
}

// Instance of a general context.
type GoogleCloudAiplatformV1beta1ContextResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ContextResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ContextResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ContextResponseOutput) ToGoogleCloudAiplatformV1beta1ContextResponseOutput() GoogleCloudAiplatformV1beta1ContextResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ContextResponseOutput) ToGoogleCloudAiplatformV1beta1ContextResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ContextResponseOutput {
	return o
}

// Timestamp when this Context was created.
func (o GoogleCloudAiplatformV1beta1ContextResponseOutput) CreateTime() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ContextResponse) string { return v.CreateTime }).(pulumi.StringOutput)
}

// Description of the Context
func (o GoogleCloudAiplatformV1beta1ContextResponseOutput) Description() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ContextResponse) string { return v.Description }).(pulumi.StringOutput)
}

// User provided display name of the Context. May be up to 128 Unicode characters.
func (o GoogleCloudAiplatformV1beta1ContextResponseOutput) DisplayName() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ContextResponse) string { return v.DisplayName }).(pulumi.StringOutput)
}

// An eTag used to perform consistent read-modify-write updates. If not set, a blind "overwrite" update happens.
func (o GoogleCloudAiplatformV1beta1ContextResponseOutput) Etag() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ContextResponse) string { return v.Etag }).(pulumi.StringOutput)
}

// The labels with user-defined metadata to organize your Contexts. Label keys and values can be no longer than 64 characters (Unicode codepoints), can only contain lowercase letters, numeric characters, underscores and dashes. International characters are allowed. No more than 64 user labels can be associated with one Context (System labels are excluded).
func (o GoogleCloudAiplatformV1beta1ContextResponseOutput) Labels() pulumi.StringMapOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ContextResponse) map[string]string { return v.Labels }).(pulumi.StringMapOutput)
}

// Properties of the Context. Top level metadata keys' heading and trailing spaces will be trimmed. The size of this field should not exceed 200KB.
func (o GoogleCloudAiplatformV1beta1ContextResponseOutput) Metadata() pulumi.MapOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ContextResponse) map[string]interface{} { return v.Metadata }).(pulumi.MapOutput)
}

// Immutable. The resource name of the Context.
func (o GoogleCloudAiplatformV1beta1ContextResponseOutput) Name() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ContextResponse) string { return v.Name }).(pulumi.StringOutput)
}

// A list of resource names of Contexts that are parents of this Context. A Context may have at most 10 parent_contexts.
func (o GoogleCloudAiplatformV1beta1ContextResponseOutput) ParentContexts() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ContextResponse) []string { return v.ParentContexts }).(pulumi.StringArrayOutput)
}

// The title of the schema describing the metadata. Schema title and version is expected to be registered in earlier Create Schema calls. And both are used together as unique identifiers to identify schemas within the local metadata store.
func (o GoogleCloudAiplatformV1beta1ContextResponseOutput) SchemaTitle() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ContextResponse) string { return v.SchemaTitle }).(pulumi.StringOutput)
}

// The version of the schema in schema_name to use. Schema title and version is expected to be registered in earlier Create Schema calls. And both are used together as unique identifiers to identify schemas within the local metadata store.
func (o GoogleCloudAiplatformV1beta1ContextResponseOutput) SchemaVersion() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ContextResponse) string { return v.SchemaVersion }).(pulumi.StringOutput)
}

// Timestamp when this Context was last updated.
func (o GoogleCloudAiplatformV1beta1ContextResponseOutput) UpdateTime() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ContextResponse) string { return v.UpdateTime }).(pulumi.StringOutput)
}

// Request message for PipelineService.CreatePipelineJob.
type GoogleCloudAiplatformV1beta1CreatePipelineJobRequest struct {
	// The resource name of the Location to create the PipelineJob in. Format: `projects/{project}/locations/{location}`
	Parent string `pulumi:"parent"`
	// The PipelineJob to create.
	PipelineJob GoogleCloudAiplatformV1beta1PipelineJob `pulumi:"pipelineJob"`
	// The ID to use for the PipelineJob, which will become the final component of the PipelineJob name. If not provided, an ID will be automatically generated. This value should be less than 128 characters, and valid characters are `/a-z-/`.
	PipelineJobId *string `pulumi:"pipelineJobId"`
}

// GoogleCloudAiplatformV1beta1CreatePipelineJobRequestInput is an input type that accepts GoogleCloudAiplatformV1beta1CreatePipelineJobRequestArgs and GoogleCloudAiplatformV1beta1CreatePipelineJobRequestOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1CreatePipelineJobRequestInput` via:
//
//	GoogleCloudAiplatformV1beta1CreatePipelineJobRequestArgs{...}
type GoogleCloudAiplatformV1beta1CreatePipelineJobRequestInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1CreatePipelineJobRequestOutput() GoogleCloudAiplatformV1beta1CreatePipelineJobRequestOutput
	ToGoogleCloudAiplatformV1beta1CreatePipelineJobRequestOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1CreatePipelineJobRequestOutput
}

// Request message for PipelineService.CreatePipelineJob.
type GoogleCloudAiplatformV1beta1CreatePipelineJobRequestArgs struct {
	// The resource name of the Location to create the PipelineJob in. Format: `projects/{project}/locations/{location}`
	Parent pulumi.StringInput `pulumi:"parent"`
	// The PipelineJob to create.
	PipelineJob GoogleCloudAiplatformV1beta1PipelineJobInput `pulumi:"pipelineJob"`
	// The ID to use for the PipelineJob, which will become the final component of the PipelineJob name. If not provided, an ID will be automatically generated. This value should be less than 128 characters, and valid characters are `/a-z-/`.
	PipelineJobId pulumi.StringPtrInput `pulumi:"pipelineJobId"`
}

func (GoogleCloudAiplatformV1beta1CreatePipelineJobRequestArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1CreatePipelineJobRequest)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1CreatePipelineJobRequestArgs) ToGoogleCloudAiplatformV1beta1CreatePipelineJobRequestOutput() GoogleCloudAiplatformV1beta1CreatePipelineJobRequestOutput {
	return i.ToGoogleCloudAiplatformV1beta1CreatePipelineJobRequestOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1CreatePipelineJobRequestArgs) ToGoogleCloudAiplatformV1beta1CreatePipelineJobRequestOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1CreatePipelineJobRequestOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1CreatePipelineJobRequestOutput)
}

func (i GoogleCloudAiplatformV1beta1CreatePipelineJobRequestArgs) ToGoogleCloudAiplatformV1beta1CreatePipelineJobRequestPtrOutput() GoogleCloudAiplatformV1beta1CreatePipelineJobRequestPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1CreatePipelineJobRequestPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1CreatePipelineJobRequestArgs) ToGoogleCloudAiplatformV1beta1CreatePipelineJobRequestPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1CreatePipelineJobRequestPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1CreatePipelineJobRequestOutput).ToGoogleCloudAiplatformV1beta1CreatePipelineJobRequestPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1CreatePipelineJobRequestPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1CreatePipelineJobRequestArgs, GoogleCloudAiplatformV1beta1CreatePipelineJobRequestPtr and GoogleCloudAiplatformV1beta1CreatePipelineJobRequestPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1CreatePipelineJobRequestPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1CreatePipelineJobRequestArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1CreatePipelineJobRequestPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1CreatePipelineJobRequestPtrOutput() GoogleCloudAiplatformV1beta1CreatePipelineJobRequestPtrOutput
	ToGoogleCloudAiplatformV1beta1CreatePipelineJobRequestPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1CreatePipelineJobRequestPtrOutput
}

type googleCloudAiplatformV1beta1CreatePipelineJobRequestPtrType GoogleCloudAiplatformV1beta1CreatePipelineJobRequestArgs

func GoogleCloudAiplatformV1beta1CreatePipelineJobRequestPtr(v *GoogleCloudAiplatformV1beta1CreatePipelineJobRequestArgs) GoogleCloudAiplatformV1beta1CreatePipelineJobRequestPtrInput {
	return (*googleCloudAiplatformV1beta1CreatePipelineJobRequestPtrType)(v)
}

func (*googleCloudAiplatformV1beta1CreatePipelineJobRequestPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1CreatePipelineJobRequest)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1CreatePipelineJobRequestPtrType) ToGoogleCloudAiplatformV1beta1CreatePipelineJobRequestPtrOutput() GoogleCloudAiplatformV1beta1CreatePipelineJobRequestPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1CreatePipelineJobRequestPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1CreatePipelineJobRequestPtrType) ToGoogleCloudAiplatformV1beta1CreatePipelineJobRequestPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1CreatePipelineJobRequestPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1CreatePipelineJobRequestPtrOutput)
}

// Request message for PipelineService.CreatePipelineJob.
type GoogleCloudAiplatformV1beta1CreatePipelineJobRequestOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1CreatePipelineJobRequestOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1CreatePipelineJobRequest)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1CreatePipelineJobRequestOutput) ToGoogleCloudAiplatformV1beta1CreatePipelineJobRequestOutput() GoogleCloudAiplatformV1beta1CreatePipelineJobRequestOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1CreatePipelineJobRequestOutput) ToGoogleCloudAiplatformV1beta1CreatePipelineJobRequestOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1CreatePipelineJobRequestOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1CreatePipelineJobRequestOutput) ToGoogleCloudAiplatformV1beta1CreatePipelineJobRequestPtrOutput() GoogleCloudAiplatformV1beta1CreatePipelineJobRequestPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1CreatePipelineJobRequestPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1CreatePipelineJobRequestOutput) ToGoogleCloudAiplatformV1beta1CreatePipelineJobRequestPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1CreatePipelineJobRequestPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1CreatePipelineJobRequest) *GoogleCloudAiplatformV1beta1CreatePipelineJobRequest {
		return &v
	}).(GoogleCloudAiplatformV1beta1CreatePipelineJobRequestPtrOutput)
}

// The resource name of the Location to create the PipelineJob in. Format: `projects/{project}/locations/{location}`
func (o GoogleCloudAiplatformV1beta1CreatePipelineJobRequestOutput) Parent() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1CreatePipelineJobRequest) string { return v.Parent }).(pulumi.StringOutput)
}

// The PipelineJob to create.
func (o GoogleCloudAiplatformV1beta1CreatePipelineJobRequestOutput) PipelineJob() GoogleCloudAiplatformV1beta1PipelineJobOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1CreatePipelineJobRequest) GoogleCloudAiplatformV1beta1PipelineJob {
		return v.PipelineJob
	}).(GoogleCloudAiplatformV1beta1PipelineJobOutput)
}

// The ID to use for the PipelineJob, which will become the final component of the PipelineJob name. If not provided, an ID will be automatically generated. This value should be less than 128 characters, and valid characters are `/a-z-/`.
func (o GoogleCloudAiplatformV1beta1CreatePipelineJobRequestOutput) PipelineJobId() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1CreatePipelineJobRequest) *string { return v.PipelineJobId }).(pulumi.StringPtrOutput)
}

type GoogleCloudAiplatformV1beta1CreatePipelineJobRequestPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1CreatePipelineJobRequestPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1CreatePipelineJobRequest)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1CreatePipelineJobRequestPtrOutput) ToGoogleCloudAiplatformV1beta1CreatePipelineJobRequestPtrOutput() GoogleCloudAiplatformV1beta1CreatePipelineJobRequestPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1CreatePipelineJobRequestPtrOutput) ToGoogleCloudAiplatformV1beta1CreatePipelineJobRequestPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1CreatePipelineJobRequestPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1CreatePipelineJobRequestPtrOutput) Elem() GoogleCloudAiplatformV1beta1CreatePipelineJobRequestOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1CreatePipelineJobRequest) GoogleCloudAiplatformV1beta1CreatePipelineJobRequest {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1CreatePipelineJobRequest
		return ret
	}).(GoogleCloudAiplatformV1beta1CreatePipelineJobRequestOutput)
}

// The resource name of the Location to create the PipelineJob in. Format: `projects/{project}/locations/{location}`
func (o GoogleCloudAiplatformV1beta1CreatePipelineJobRequestPtrOutput) Parent() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1CreatePipelineJobRequest) *string {
		if v == nil {
			return nil
		}
		return &v.Parent
	}).(pulumi.StringPtrOutput)
}

// The PipelineJob to create.
func (o GoogleCloudAiplatformV1beta1CreatePipelineJobRequestPtrOutput) PipelineJob() GoogleCloudAiplatformV1beta1PipelineJobPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1CreatePipelineJobRequest) *GoogleCloudAiplatformV1beta1PipelineJob {
		if v == nil {
			return nil
		}
		return &v.PipelineJob
	}).(GoogleCloudAiplatformV1beta1PipelineJobPtrOutput)
}

// The ID to use for the PipelineJob, which will become the final component of the PipelineJob name. If not provided, an ID will be automatically generated. This value should be less than 128 characters, and valid characters are `/a-z-/`.
func (o GoogleCloudAiplatformV1beta1CreatePipelineJobRequestPtrOutput) PipelineJobId() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1CreatePipelineJobRequest) *string {
		if v == nil {
			return nil
		}
		return v.PipelineJobId
	}).(pulumi.StringPtrOutput)
}

// Request message for PipelineService.CreatePipelineJob.
type GoogleCloudAiplatformV1beta1CreatePipelineJobRequestResponse struct {
	// The resource name of the Location to create the PipelineJob in. Format: `projects/{project}/locations/{location}`
	Parent string `pulumi:"parent"`
	// The PipelineJob to create.
	PipelineJob GoogleCloudAiplatformV1beta1PipelineJobResponse `pulumi:"pipelineJob"`
	// The ID to use for the PipelineJob, which will become the final component of the PipelineJob name. If not provided, an ID will be automatically generated. This value should be less than 128 characters, and valid characters are `/a-z-/`.
	PipelineJobId string `pulumi:"pipelineJobId"`
}

// Request message for PipelineService.CreatePipelineJob.
type GoogleCloudAiplatformV1beta1CreatePipelineJobRequestResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1CreatePipelineJobRequestResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1CreatePipelineJobRequestResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1CreatePipelineJobRequestResponseOutput) ToGoogleCloudAiplatformV1beta1CreatePipelineJobRequestResponseOutput() GoogleCloudAiplatformV1beta1CreatePipelineJobRequestResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1CreatePipelineJobRequestResponseOutput) ToGoogleCloudAiplatformV1beta1CreatePipelineJobRequestResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1CreatePipelineJobRequestResponseOutput {
	return o
}

// The resource name of the Location to create the PipelineJob in. Format: `projects/{project}/locations/{location}`
func (o GoogleCloudAiplatformV1beta1CreatePipelineJobRequestResponseOutput) Parent() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1CreatePipelineJobRequestResponse) string { return v.Parent }).(pulumi.StringOutput)
}

// The PipelineJob to create.
func (o GoogleCloudAiplatformV1beta1CreatePipelineJobRequestResponseOutput) PipelineJob() GoogleCloudAiplatformV1beta1PipelineJobResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1CreatePipelineJobRequestResponse) GoogleCloudAiplatformV1beta1PipelineJobResponse {
		return v.PipelineJob
	}).(GoogleCloudAiplatformV1beta1PipelineJobResponseOutput)
}

// The ID to use for the PipelineJob, which will become the final component of the PipelineJob name. If not provided, an ID will be automatically generated. This value should be less than 128 characters, and valid characters are `/a-z-/`.
func (o GoogleCloudAiplatformV1beta1CreatePipelineJobRequestResponseOutput) PipelineJobId() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1CreatePipelineJobRequestResponse) string { return v.PipelineJobId }).(pulumi.StringOutput)
}

// Represents the spec of a CustomJob.
type GoogleCloudAiplatformV1beta1CustomJobSpec struct {
	// The Cloud Storage location to store the output of this CustomJob or HyperparameterTuningJob. For HyperparameterTuningJob, the baseOutputDirectory of each child CustomJob backing a Trial is set to a subdirectory of name id under its parent HyperparameterTuningJob's baseOutputDirectory. The following Vertex AI environment variables will be passed to containers or python modules when this field is set: For CustomJob: * AIP_MODEL_DIR = `/model/` * AIP_CHECKPOINT_DIR = `/checkpoints/` * AIP_TENSORBOARD_LOG_DIR = `/logs/` For CustomJob backing a Trial of HyperparameterTuningJob: * AIP_MODEL_DIR = `//model/` * AIP_CHECKPOINT_DIR = `//checkpoints/` * AIP_TENSORBOARD_LOG_DIR = `//logs/`
	BaseOutputDirectory *GoogleCloudAiplatformV1beta1GcsDestination `pulumi:"baseOutputDirectory"`
	// Optional. Whether you want Vertex AI to enable access to the customized dashboard in training chief container. If set to `true`, you can access the dashboard at the URIs given by CustomJob.web_access_uris or Trial.web_access_uris (within HyperparameterTuningJob.trials).
	EnableDashboardAccess *bool `pulumi:"enableDashboardAccess"`
	// Optional. Whether you want Vertex AI to enable [interactive shell access](https://cloud.google.com/vertex-ai/docs/training/monitor-debug-interactive-shell) to training containers. If set to `true`, you can access interactive shells at the URIs given by CustomJob.web_access_uris or Trial.web_access_uris (within HyperparameterTuningJob.trials).
	EnableWebAccess *bool `pulumi:"enableWebAccess"`
	// Optional. The Experiment associated with this job. Format: `projects/{project}/locations/{location}/metadataStores/{metadataStores}/contexts/{experiment-name}`
	Experiment *string `pulumi:"experiment"`
	// Optional. The Experiment Run associated with this job. Format: `projects/{project}/locations/{location}/metadataStores/{metadataStores}/contexts/{experiment-name}-{experiment-run-name}`
	ExperimentRun *string `pulumi:"experimentRun"`
	// Optional. The full name of the Compute Engine [network](/compute/docs/networks-and-firewalls#networks) to which the Job should be peered. For example, `projects/12345/global/networks/myVPC`. [Format](/compute/docs/reference/rest/v1/networks/insert) is of the form `projects/{project}/global/networks/{network}`. Where {project} is a project number, as in `12345`, and {network} is a network name. To specify this field, you must have already [configured VPC Network Peering for Vertex AI](https://cloud.google.com/vertex-ai/docs/general/vpc-peering). If this field is left unspecified, the job is not peered with any network.
	Network *string `pulumi:"network"`
	// Optional. The ID of the PersistentResource in the same Project and Location which to run If this is specified, the job will be run on existing machines held by the PersistentResource instead of on-demand short-live machines. The network and CMEK configs on the job should be consistent with those on the PersistentResource, otherwise, the job will be rejected.
	PersistentResourceId *string `pulumi:"persistentResourceId"`
	// The ID of the location to store protected artifacts. e.g. us-central1. Populate only when the location is different than CustomJob location. List of supported locations: https://cloud.google.com/vertex-ai/docs/general/locations
	ProtectedArtifactLocationId *string `pulumi:"protectedArtifactLocationId"`
	// Optional. A list of names for the reserved ip ranges under the VPC network that can be used for this job. If set, we will deploy the job within the provided ip ranges. Otherwise, the job will be deployed to any ip ranges under the provided VPC network. Example: ['vertex-ai-ip-range'].
	ReservedIpRanges []string `pulumi:"reservedIpRanges"`
	// Scheduling options for a CustomJob.
	Scheduling *GoogleCloudAiplatformV1beta1Scheduling `pulumi:"scheduling"`
	// Specifies the service account for workload run-as account. Users submitting jobs must have act-as permission on this run-as account. If unspecified, the [Vertex AI Custom Code Service Agent](https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents) for the CustomJob's project is used.
	ServiceAccount *string `pulumi:"serviceAccount"`
	// Optional. The name of a Vertex AI Tensorboard resource to which this CustomJob will upload Tensorboard logs. Format: `projects/{project}/locations/{location}/tensorboards/{tensorboard}`
	Tensorboard *string `pulumi:"tensorboard"`
	// The spec of the worker pools including machine type and Docker image. All worker pools except the first one are optional and can be skipped by providing an empty value.
	WorkerPoolSpecs []GoogleCloudAiplatformV1beta1WorkerPoolSpec `pulumi:"workerPoolSpecs"`
}

// GoogleCloudAiplatformV1beta1CustomJobSpecInput is an input type that accepts GoogleCloudAiplatformV1beta1CustomJobSpecArgs and GoogleCloudAiplatformV1beta1CustomJobSpecOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1CustomJobSpecInput` via:
//
//	GoogleCloudAiplatformV1beta1CustomJobSpecArgs{...}
type GoogleCloudAiplatformV1beta1CustomJobSpecInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1CustomJobSpecOutput() GoogleCloudAiplatformV1beta1CustomJobSpecOutput
	ToGoogleCloudAiplatformV1beta1CustomJobSpecOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1CustomJobSpecOutput
}

// Represents the spec of a CustomJob.
type GoogleCloudAiplatformV1beta1CustomJobSpecArgs struct {
	// The Cloud Storage location to store the output of this CustomJob or HyperparameterTuningJob. For HyperparameterTuningJob, the baseOutputDirectory of each child CustomJob backing a Trial is set to a subdirectory of name id under its parent HyperparameterTuningJob's baseOutputDirectory. The following Vertex AI environment variables will be passed to containers or python modules when this field is set: For CustomJob: * AIP_MODEL_DIR = `/model/` * AIP_CHECKPOINT_DIR = `/checkpoints/` * AIP_TENSORBOARD_LOG_DIR = `/logs/` For CustomJob backing a Trial of HyperparameterTuningJob: * AIP_MODEL_DIR = `//model/` * AIP_CHECKPOINT_DIR = `//checkpoints/` * AIP_TENSORBOARD_LOG_DIR = `//logs/`
	BaseOutputDirectory GoogleCloudAiplatformV1beta1GcsDestinationPtrInput `pulumi:"baseOutputDirectory"`
	// Optional. Whether you want Vertex AI to enable access to the customized dashboard in training chief container. If set to `true`, you can access the dashboard at the URIs given by CustomJob.web_access_uris or Trial.web_access_uris (within HyperparameterTuningJob.trials).
	EnableDashboardAccess pulumi.BoolPtrInput `pulumi:"enableDashboardAccess"`
	// Optional. Whether you want Vertex AI to enable [interactive shell access](https://cloud.google.com/vertex-ai/docs/training/monitor-debug-interactive-shell) to training containers. If set to `true`, you can access interactive shells at the URIs given by CustomJob.web_access_uris or Trial.web_access_uris (within HyperparameterTuningJob.trials).
	EnableWebAccess pulumi.BoolPtrInput `pulumi:"enableWebAccess"`
	// Optional. The Experiment associated with this job. Format: `projects/{project}/locations/{location}/metadataStores/{metadataStores}/contexts/{experiment-name}`
	Experiment pulumi.StringPtrInput `pulumi:"experiment"`
	// Optional. The Experiment Run associated with this job. Format: `projects/{project}/locations/{location}/metadataStores/{metadataStores}/contexts/{experiment-name}-{experiment-run-name}`
	ExperimentRun pulumi.StringPtrInput `pulumi:"experimentRun"`
	// Optional. The full name of the Compute Engine [network](/compute/docs/networks-and-firewalls#networks) to which the Job should be peered. For example, `projects/12345/global/networks/myVPC`. [Format](/compute/docs/reference/rest/v1/networks/insert) is of the form `projects/{project}/global/networks/{network}`. Where {project} is a project number, as in `12345`, and {network} is a network name. To specify this field, you must have already [configured VPC Network Peering for Vertex AI](https://cloud.google.com/vertex-ai/docs/general/vpc-peering). If this field is left unspecified, the job is not peered with any network.
	Network pulumi.StringPtrInput `pulumi:"network"`
	// Optional. The ID of the PersistentResource in the same Project and Location which to run If this is specified, the job will be run on existing machines held by the PersistentResource instead of on-demand short-live machines. The network and CMEK configs on the job should be consistent with those on the PersistentResource, otherwise, the job will be rejected.
	PersistentResourceId pulumi.StringPtrInput `pulumi:"persistentResourceId"`
	// The ID of the location to store protected artifacts. e.g. us-central1. Populate only when the location is different than CustomJob location. List of supported locations: https://cloud.google.com/vertex-ai/docs/general/locations
	ProtectedArtifactLocationId pulumi.StringPtrInput `pulumi:"protectedArtifactLocationId"`
	// Optional. A list of names for the reserved ip ranges under the VPC network that can be used for this job. If set, we will deploy the job within the provided ip ranges. Otherwise, the job will be deployed to any ip ranges under the provided VPC network. Example: ['vertex-ai-ip-range'].
	ReservedIpRanges pulumi.StringArrayInput `pulumi:"reservedIpRanges"`
	// Scheduling options for a CustomJob.
	Scheduling GoogleCloudAiplatformV1beta1SchedulingPtrInput `pulumi:"scheduling"`
	// Specifies the service account for workload run-as account. Users submitting jobs must have act-as permission on this run-as account. If unspecified, the [Vertex AI Custom Code Service Agent](https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents) for the CustomJob's project is used.
	ServiceAccount pulumi.StringPtrInput `pulumi:"serviceAccount"`
	// Optional. The name of a Vertex AI Tensorboard resource to which this CustomJob will upload Tensorboard logs. Format: `projects/{project}/locations/{location}/tensorboards/{tensorboard}`
	Tensorboard pulumi.StringPtrInput `pulumi:"tensorboard"`
	// The spec of the worker pools including machine type and Docker image. All worker pools except the first one are optional and can be skipped by providing an empty value.
	WorkerPoolSpecs GoogleCloudAiplatformV1beta1WorkerPoolSpecArrayInput `pulumi:"workerPoolSpecs"`
}

func (GoogleCloudAiplatformV1beta1CustomJobSpecArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1CustomJobSpec)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1CustomJobSpecArgs) ToGoogleCloudAiplatformV1beta1CustomJobSpecOutput() GoogleCloudAiplatformV1beta1CustomJobSpecOutput {
	return i.ToGoogleCloudAiplatformV1beta1CustomJobSpecOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1CustomJobSpecArgs) ToGoogleCloudAiplatformV1beta1CustomJobSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1CustomJobSpecOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1CustomJobSpecOutput)
}

func (i GoogleCloudAiplatformV1beta1CustomJobSpecArgs) ToGoogleCloudAiplatformV1beta1CustomJobSpecPtrOutput() GoogleCloudAiplatformV1beta1CustomJobSpecPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1CustomJobSpecPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1CustomJobSpecArgs) ToGoogleCloudAiplatformV1beta1CustomJobSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1CustomJobSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1CustomJobSpecOutput).ToGoogleCloudAiplatformV1beta1CustomJobSpecPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1CustomJobSpecPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1CustomJobSpecArgs, GoogleCloudAiplatformV1beta1CustomJobSpecPtr and GoogleCloudAiplatformV1beta1CustomJobSpecPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1CustomJobSpecPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1CustomJobSpecArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1CustomJobSpecPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1CustomJobSpecPtrOutput() GoogleCloudAiplatformV1beta1CustomJobSpecPtrOutput
	ToGoogleCloudAiplatformV1beta1CustomJobSpecPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1CustomJobSpecPtrOutput
}

type googleCloudAiplatformV1beta1CustomJobSpecPtrType GoogleCloudAiplatformV1beta1CustomJobSpecArgs

func GoogleCloudAiplatformV1beta1CustomJobSpecPtr(v *GoogleCloudAiplatformV1beta1CustomJobSpecArgs) GoogleCloudAiplatformV1beta1CustomJobSpecPtrInput {
	return (*googleCloudAiplatformV1beta1CustomJobSpecPtrType)(v)
}

func (*googleCloudAiplatformV1beta1CustomJobSpecPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1CustomJobSpec)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1CustomJobSpecPtrType) ToGoogleCloudAiplatformV1beta1CustomJobSpecPtrOutput() GoogleCloudAiplatformV1beta1CustomJobSpecPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1CustomJobSpecPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1CustomJobSpecPtrType) ToGoogleCloudAiplatformV1beta1CustomJobSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1CustomJobSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1CustomJobSpecPtrOutput)
}

// Represents the spec of a CustomJob.
type GoogleCloudAiplatformV1beta1CustomJobSpecOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1CustomJobSpecOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1CustomJobSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1CustomJobSpecOutput) ToGoogleCloudAiplatformV1beta1CustomJobSpecOutput() GoogleCloudAiplatformV1beta1CustomJobSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1CustomJobSpecOutput) ToGoogleCloudAiplatformV1beta1CustomJobSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1CustomJobSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1CustomJobSpecOutput) ToGoogleCloudAiplatformV1beta1CustomJobSpecPtrOutput() GoogleCloudAiplatformV1beta1CustomJobSpecPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1CustomJobSpecPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1CustomJobSpecOutput) ToGoogleCloudAiplatformV1beta1CustomJobSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1CustomJobSpecPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1CustomJobSpec) *GoogleCloudAiplatformV1beta1CustomJobSpec {
		return &v
	}).(GoogleCloudAiplatformV1beta1CustomJobSpecPtrOutput)
}

// The Cloud Storage location to store the output of this CustomJob or HyperparameterTuningJob. For HyperparameterTuningJob, the baseOutputDirectory of each child CustomJob backing a Trial is set to a subdirectory of name id under its parent HyperparameterTuningJob's baseOutputDirectory. The following Vertex AI environment variables will be passed to containers or python modules when this field is set: For CustomJob: * AIP_MODEL_DIR = `/model/` * AIP_CHECKPOINT_DIR = `/checkpoints/` * AIP_TENSORBOARD_LOG_DIR = `/logs/` For CustomJob backing a Trial of HyperparameterTuningJob: * AIP_MODEL_DIR = `//model/` * AIP_CHECKPOINT_DIR = `//checkpoints/` * AIP_TENSORBOARD_LOG_DIR = `//logs/`
func (o GoogleCloudAiplatformV1beta1CustomJobSpecOutput) BaseOutputDirectory() GoogleCloudAiplatformV1beta1GcsDestinationPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1CustomJobSpec) *GoogleCloudAiplatformV1beta1GcsDestination {
		return v.BaseOutputDirectory
	}).(GoogleCloudAiplatformV1beta1GcsDestinationPtrOutput)
}

// Optional. Whether you want Vertex AI to enable access to the customized dashboard in training chief container. If set to `true`, you can access the dashboard at the URIs given by CustomJob.web_access_uris or Trial.web_access_uris (within HyperparameterTuningJob.trials).
func (o GoogleCloudAiplatformV1beta1CustomJobSpecOutput) EnableDashboardAccess() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1CustomJobSpec) *bool { return v.EnableDashboardAccess }).(pulumi.BoolPtrOutput)
}

// Optional. Whether you want Vertex AI to enable [interactive shell access](https://cloud.google.com/vertex-ai/docs/training/monitor-debug-interactive-shell) to training containers. If set to `true`, you can access interactive shells at the URIs given by CustomJob.web_access_uris or Trial.web_access_uris (within HyperparameterTuningJob.trials).
func (o GoogleCloudAiplatformV1beta1CustomJobSpecOutput) EnableWebAccess() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1CustomJobSpec) *bool { return v.EnableWebAccess }).(pulumi.BoolPtrOutput)
}

// Optional. The Experiment associated with this job. Format: `projects/{project}/locations/{location}/metadataStores/{metadataStores}/contexts/{experiment-name}`
func (o GoogleCloudAiplatformV1beta1CustomJobSpecOutput) Experiment() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1CustomJobSpec) *string { return v.Experiment }).(pulumi.StringPtrOutput)
}

// Optional. The Experiment Run associated with this job. Format: `projects/{project}/locations/{location}/metadataStores/{metadataStores}/contexts/{experiment-name}-{experiment-run-name}`
func (o GoogleCloudAiplatformV1beta1CustomJobSpecOutput) ExperimentRun() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1CustomJobSpec) *string { return v.ExperimentRun }).(pulumi.StringPtrOutput)
}

// Optional. The full name of the Compute Engine [network](/compute/docs/networks-and-firewalls#networks) to which the Job should be peered. For example, `projects/12345/global/networks/myVPC`. [Format](/compute/docs/reference/rest/v1/networks/insert) is of the form `projects/{project}/global/networks/{network}`. Where {project} is a project number, as in `12345`, and {network} is a network name. To specify this field, you must have already [configured VPC Network Peering for Vertex AI](https://cloud.google.com/vertex-ai/docs/general/vpc-peering). If this field is left unspecified, the job is not peered with any network.
func (o GoogleCloudAiplatformV1beta1CustomJobSpecOutput) Network() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1CustomJobSpec) *string { return v.Network }).(pulumi.StringPtrOutput)
}

// Optional. The ID of the PersistentResource in the same Project and Location which to run If this is specified, the job will be run on existing machines held by the PersistentResource instead of on-demand short-live machines. The network and CMEK configs on the job should be consistent with those on the PersistentResource, otherwise, the job will be rejected.
func (o GoogleCloudAiplatformV1beta1CustomJobSpecOutput) PersistentResourceId() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1CustomJobSpec) *string { return v.PersistentResourceId }).(pulumi.StringPtrOutput)
}

// The ID of the location to store protected artifacts. e.g. us-central1. Populate only when the location is different than CustomJob location. List of supported locations: https://cloud.google.com/vertex-ai/docs/general/locations
func (o GoogleCloudAiplatformV1beta1CustomJobSpecOutput) ProtectedArtifactLocationId() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1CustomJobSpec) *string { return v.ProtectedArtifactLocationId }).(pulumi.StringPtrOutput)
}

// Optional. A list of names for the reserved ip ranges under the VPC network that can be used for this job. If set, we will deploy the job within the provided ip ranges. Otherwise, the job will be deployed to any ip ranges under the provided VPC network. Example: ['vertex-ai-ip-range'].
func (o GoogleCloudAiplatformV1beta1CustomJobSpecOutput) ReservedIpRanges() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1CustomJobSpec) []string { return v.ReservedIpRanges }).(pulumi.StringArrayOutput)
}

// Scheduling options for a CustomJob.
func (o GoogleCloudAiplatformV1beta1CustomJobSpecOutput) Scheduling() GoogleCloudAiplatformV1beta1SchedulingPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1CustomJobSpec) *GoogleCloudAiplatformV1beta1Scheduling {
		return v.Scheduling
	}).(GoogleCloudAiplatformV1beta1SchedulingPtrOutput)
}

// Specifies the service account for workload run-as account. Users submitting jobs must have act-as permission on this run-as account. If unspecified, the [Vertex AI Custom Code Service Agent](https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents) for the CustomJob's project is used.
func (o GoogleCloudAiplatformV1beta1CustomJobSpecOutput) ServiceAccount() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1CustomJobSpec) *string { return v.ServiceAccount }).(pulumi.StringPtrOutput)
}

// Optional. The name of a Vertex AI Tensorboard resource to which this CustomJob will upload Tensorboard logs. Format: `projects/{project}/locations/{location}/tensorboards/{tensorboard}`
func (o GoogleCloudAiplatformV1beta1CustomJobSpecOutput) Tensorboard() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1CustomJobSpec) *string { return v.Tensorboard }).(pulumi.StringPtrOutput)
}

// The spec of the worker pools including machine type and Docker image. All worker pools except the first one are optional and can be skipped by providing an empty value.
func (o GoogleCloudAiplatformV1beta1CustomJobSpecOutput) WorkerPoolSpecs() GoogleCloudAiplatformV1beta1WorkerPoolSpecArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1CustomJobSpec) []GoogleCloudAiplatformV1beta1WorkerPoolSpec {
		return v.WorkerPoolSpecs
	}).(GoogleCloudAiplatformV1beta1WorkerPoolSpecArrayOutput)
}

type GoogleCloudAiplatformV1beta1CustomJobSpecPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1CustomJobSpecPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1CustomJobSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1CustomJobSpecPtrOutput) ToGoogleCloudAiplatformV1beta1CustomJobSpecPtrOutput() GoogleCloudAiplatformV1beta1CustomJobSpecPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1CustomJobSpecPtrOutput) ToGoogleCloudAiplatformV1beta1CustomJobSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1CustomJobSpecPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1CustomJobSpecPtrOutput) Elem() GoogleCloudAiplatformV1beta1CustomJobSpecOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1CustomJobSpec) GoogleCloudAiplatformV1beta1CustomJobSpec {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1CustomJobSpec
		return ret
	}).(GoogleCloudAiplatformV1beta1CustomJobSpecOutput)
}

// The Cloud Storage location to store the output of this CustomJob or HyperparameterTuningJob. For HyperparameterTuningJob, the baseOutputDirectory of each child CustomJob backing a Trial is set to a subdirectory of name id under its parent HyperparameterTuningJob's baseOutputDirectory. The following Vertex AI environment variables will be passed to containers or python modules when this field is set: For CustomJob: * AIP_MODEL_DIR = `/model/` * AIP_CHECKPOINT_DIR = `/checkpoints/` * AIP_TENSORBOARD_LOG_DIR = `/logs/` For CustomJob backing a Trial of HyperparameterTuningJob: * AIP_MODEL_DIR = `//model/` * AIP_CHECKPOINT_DIR = `//checkpoints/` * AIP_TENSORBOARD_LOG_DIR = `//logs/`
func (o GoogleCloudAiplatformV1beta1CustomJobSpecPtrOutput) BaseOutputDirectory() GoogleCloudAiplatformV1beta1GcsDestinationPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1CustomJobSpec) *GoogleCloudAiplatformV1beta1GcsDestination {
		if v == nil {
			return nil
		}
		return v.BaseOutputDirectory
	}).(GoogleCloudAiplatformV1beta1GcsDestinationPtrOutput)
}

// Optional. Whether you want Vertex AI to enable access to the customized dashboard in training chief container. If set to `true`, you can access the dashboard at the URIs given by CustomJob.web_access_uris or Trial.web_access_uris (within HyperparameterTuningJob.trials).
func (o GoogleCloudAiplatformV1beta1CustomJobSpecPtrOutput) EnableDashboardAccess() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1CustomJobSpec) *bool {
		if v == nil {
			return nil
		}
		return v.EnableDashboardAccess
	}).(pulumi.BoolPtrOutput)
}

// Optional. Whether you want Vertex AI to enable [interactive shell access](https://cloud.google.com/vertex-ai/docs/training/monitor-debug-interactive-shell) to training containers. If set to `true`, you can access interactive shells at the URIs given by CustomJob.web_access_uris or Trial.web_access_uris (within HyperparameterTuningJob.trials).
func (o GoogleCloudAiplatformV1beta1CustomJobSpecPtrOutput) EnableWebAccess() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1CustomJobSpec) *bool {
		if v == nil {
			return nil
		}
		return v.EnableWebAccess
	}).(pulumi.BoolPtrOutput)
}

// Optional. The Experiment associated with this job. Format: `projects/{project}/locations/{location}/metadataStores/{metadataStores}/contexts/{experiment-name}`
func (o GoogleCloudAiplatformV1beta1CustomJobSpecPtrOutput) Experiment() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1CustomJobSpec) *string {
		if v == nil {
			return nil
		}
		return v.Experiment
	}).(pulumi.StringPtrOutput)
}

// Optional. The Experiment Run associated with this job. Format: `projects/{project}/locations/{location}/metadataStores/{metadataStores}/contexts/{experiment-name}-{experiment-run-name}`
func (o GoogleCloudAiplatformV1beta1CustomJobSpecPtrOutput) ExperimentRun() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1CustomJobSpec) *string {
		if v == nil {
			return nil
		}
		return v.ExperimentRun
	}).(pulumi.StringPtrOutput)
}

// Optional. The full name of the Compute Engine [network](/compute/docs/networks-and-firewalls#networks) to which the Job should be peered. For example, `projects/12345/global/networks/myVPC`. [Format](/compute/docs/reference/rest/v1/networks/insert) is of the form `projects/{project}/global/networks/{network}`. Where {project} is a project number, as in `12345`, and {network} is a network name. To specify this field, you must have already [configured VPC Network Peering for Vertex AI](https://cloud.google.com/vertex-ai/docs/general/vpc-peering). If this field is left unspecified, the job is not peered with any network.
func (o GoogleCloudAiplatformV1beta1CustomJobSpecPtrOutput) Network() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1CustomJobSpec) *string {
		if v == nil {
			return nil
		}
		return v.Network
	}).(pulumi.StringPtrOutput)
}

// Optional. The ID of the PersistentResource in the same Project and Location which to run If this is specified, the job will be run on existing machines held by the PersistentResource instead of on-demand short-live machines. The network and CMEK configs on the job should be consistent with those on the PersistentResource, otherwise, the job will be rejected.
func (o GoogleCloudAiplatformV1beta1CustomJobSpecPtrOutput) PersistentResourceId() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1CustomJobSpec) *string {
		if v == nil {
			return nil
		}
		return v.PersistentResourceId
	}).(pulumi.StringPtrOutput)
}

// The ID of the location to store protected artifacts. e.g. us-central1. Populate only when the location is different than CustomJob location. List of supported locations: https://cloud.google.com/vertex-ai/docs/general/locations
func (o GoogleCloudAiplatformV1beta1CustomJobSpecPtrOutput) ProtectedArtifactLocationId() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1CustomJobSpec) *string {
		if v == nil {
			return nil
		}
		return v.ProtectedArtifactLocationId
	}).(pulumi.StringPtrOutput)
}

// Optional. A list of names for the reserved ip ranges under the VPC network that can be used for this job. If set, we will deploy the job within the provided ip ranges. Otherwise, the job will be deployed to any ip ranges under the provided VPC network. Example: ['vertex-ai-ip-range'].
func (o GoogleCloudAiplatformV1beta1CustomJobSpecPtrOutput) ReservedIpRanges() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1CustomJobSpec) []string {
		if v == nil {
			return nil
		}
		return v.ReservedIpRanges
	}).(pulumi.StringArrayOutput)
}

// Scheduling options for a CustomJob.
func (o GoogleCloudAiplatformV1beta1CustomJobSpecPtrOutput) Scheduling() GoogleCloudAiplatformV1beta1SchedulingPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1CustomJobSpec) *GoogleCloudAiplatformV1beta1Scheduling {
		if v == nil {
			return nil
		}
		return v.Scheduling
	}).(GoogleCloudAiplatformV1beta1SchedulingPtrOutput)
}

// Specifies the service account for workload run-as account. Users submitting jobs must have act-as permission on this run-as account. If unspecified, the [Vertex AI Custom Code Service Agent](https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents) for the CustomJob's project is used.
func (o GoogleCloudAiplatformV1beta1CustomJobSpecPtrOutput) ServiceAccount() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1CustomJobSpec) *string {
		if v == nil {
			return nil
		}
		return v.ServiceAccount
	}).(pulumi.StringPtrOutput)
}

// Optional. The name of a Vertex AI Tensorboard resource to which this CustomJob will upload Tensorboard logs. Format: `projects/{project}/locations/{location}/tensorboards/{tensorboard}`
func (o GoogleCloudAiplatformV1beta1CustomJobSpecPtrOutput) Tensorboard() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1CustomJobSpec) *string {
		if v == nil {
			return nil
		}
		return v.Tensorboard
	}).(pulumi.StringPtrOutput)
}

// The spec of the worker pools including machine type and Docker image. All worker pools except the first one are optional and can be skipped by providing an empty value.
func (o GoogleCloudAiplatformV1beta1CustomJobSpecPtrOutput) WorkerPoolSpecs() GoogleCloudAiplatformV1beta1WorkerPoolSpecArrayOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1CustomJobSpec) []GoogleCloudAiplatformV1beta1WorkerPoolSpec {
		if v == nil {
			return nil
		}
		return v.WorkerPoolSpecs
	}).(GoogleCloudAiplatformV1beta1WorkerPoolSpecArrayOutput)
}

// Represents the spec of a CustomJob.
type GoogleCloudAiplatformV1beta1CustomJobSpecResponse struct {
	// The Cloud Storage location to store the output of this CustomJob or HyperparameterTuningJob. For HyperparameterTuningJob, the baseOutputDirectory of each child CustomJob backing a Trial is set to a subdirectory of name id under its parent HyperparameterTuningJob's baseOutputDirectory. The following Vertex AI environment variables will be passed to containers or python modules when this field is set: For CustomJob: * AIP_MODEL_DIR = `/model/` * AIP_CHECKPOINT_DIR = `/checkpoints/` * AIP_TENSORBOARD_LOG_DIR = `/logs/` For CustomJob backing a Trial of HyperparameterTuningJob: * AIP_MODEL_DIR = `//model/` * AIP_CHECKPOINT_DIR = `//checkpoints/` * AIP_TENSORBOARD_LOG_DIR = `//logs/`
	BaseOutputDirectory GoogleCloudAiplatformV1beta1GcsDestinationResponse `pulumi:"baseOutputDirectory"`
	// Optional. Whether you want Vertex AI to enable access to the customized dashboard in training chief container. If set to `true`, you can access the dashboard at the URIs given by CustomJob.web_access_uris or Trial.web_access_uris (within HyperparameterTuningJob.trials).
	EnableDashboardAccess bool `pulumi:"enableDashboardAccess"`
	// Optional. Whether you want Vertex AI to enable [interactive shell access](https://cloud.google.com/vertex-ai/docs/training/monitor-debug-interactive-shell) to training containers. If set to `true`, you can access interactive shells at the URIs given by CustomJob.web_access_uris or Trial.web_access_uris (within HyperparameterTuningJob.trials).
	EnableWebAccess bool `pulumi:"enableWebAccess"`
	// Optional. The Experiment associated with this job. Format: `projects/{project}/locations/{location}/metadataStores/{metadataStores}/contexts/{experiment-name}`
	Experiment string `pulumi:"experiment"`
	// Optional. The Experiment Run associated with this job. Format: `projects/{project}/locations/{location}/metadataStores/{metadataStores}/contexts/{experiment-name}-{experiment-run-name}`
	ExperimentRun string `pulumi:"experimentRun"`
	// Optional. The full name of the Compute Engine [network](/compute/docs/networks-and-firewalls#networks) to which the Job should be peered. For example, `projects/12345/global/networks/myVPC`. [Format](/compute/docs/reference/rest/v1/networks/insert) is of the form `projects/{project}/global/networks/{network}`. Where {project} is a project number, as in `12345`, and {network} is a network name. To specify this field, you must have already [configured VPC Network Peering for Vertex AI](https://cloud.google.com/vertex-ai/docs/general/vpc-peering). If this field is left unspecified, the job is not peered with any network.
	Network string `pulumi:"network"`
	// Optional. The ID of the PersistentResource in the same Project and Location which to run If this is specified, the job will be run on existing machines held by the PersistentResource instead of on-demand short-live machines. The network and CMEK configs on the job should be consistent with those on the PersistentResource, otherwise, the job will be rejected.
	PersistentResourceId string `pulumi:"persistentResourceId"`
	// The ID of the location to store protected artifacts. e.g. us-central1. Populate only when the location is different than CustomJob location. List of supported locations: https://cloud.google.com/vertex-ai/docs/general/locations
	ProtectedArtifactLocationId string `pulumi:"protectedArtifactLocationId"`
	// Optional. A list of names for the reserved ip ranges under the VPC network that can be used for this job. If set, we will deploy the job within the provided ip ranges. Otherwise, the job will be deployed to any ip ranges under the provided VPC network. Example: ['vertex-ai-ip-range'].
	ReservedIpRanges []string `pulumi:"reservedIpRanges"`
	// Scheduling options for a CustomJob.
	Scheduling GoogleCloudAiplatformV1beta1SchedulingResponse `pulumi:"scheduling"`
	// Specifies the service account for workload run-as account. Users submitting jobs must have act-as permission on this run-as account. If unspecified, the [Vertex AI Custom Code Service Agent](https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents) for the CustomJob's project is used.
	ServiceAccount string `pulumi:"serviceAccount"`
	// Optional. The name of a Vertex AI Tensorboard resource to which this CustomJob will upload Tensorboard logs. Format: `projects/{project}/locations/{location}/tensorboards/{tensorboard}`
	Tensorboard string `pulumi:"tensorboard"`
	// The spec of the worker pools including machine type and Docker image. All worker pools except the first one are optional and can be skipped by providing an empty value.
	WorkerPoolSpecs []GoogleCloudAiplatformV1beta1WorkerPoolSpecResponse `pulumi:"workerPoolSpecs"`
}

// Represents the spec of a CustomJob.
type GoogleCloudAiplatformV1beta1CustomJobSpecResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1CustomJobSpecResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1CustomJobSpecResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1CustomJobSpecResponseOutput) ToGoogleCloudAiplatformV1beta1CustomJobSpecResponseOutput() GoogleCloudAiplatformV1beta1CustomJobSpecResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1CustomJobSpecResponseOutput) ToGoogleCloudAiplatformV1beta1CustomJobSpecResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1CustomJobSpecResponseOutput {
	return o
}

// The Cloud Storage location to store the output of this CustomJob or HyperparameterTuningJob. For HyperparameterTuningJob, the baseOutputDirectory of each child CustomJob backing a Trial is set to a subdirectory of name id under its parent HyperparameterTuningJob's baseOutputDirectory. The following Vertex AI environment variables will be passed to containers or python modules when this field is set: For CustomJob: * AIP_MODEL_DIR = `/model/` * AIP_CHECKPOINT_DIR = `/checkpoints/` * AIP_TENSORBOARD_LOG_DIR = `/logs/` For CustomJob backing a Trial of HyperparameterTuningJob: * AIP_MODEL_DIR = `//model/` * AIP_CHECKPOINT_DIR = `//checkpoints/` * AIP_TENSORBOARD_LOG_DIR = `//logs/`
func (o GoogleCloudAiplatformV1beta1CustomJobSpecResponseOutput) BaseOutputDirectory() GoogleCloudAiplatformV1beta1GcsDestinationResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1CustomJobSpecResponse) GoogleCloudAiplatformV1beta1GcsDestinationResponse {
		return v.BaseOutputDirectory
	}).(GoogleCloudAiplatformV1beta1GcsDestinationResponseOutput)
}

// Optional. Whether you want Vertex AI to enable access to the customized dashboard in training chief container. If set to `true`, you can access the dashboard at the URIs given by CustomJob.web_access_uris or Trial.web_access_uris (within HyperparameterTuningJob.trials).
func (o GoogleCloudAiplatformV1beta1CustomJobSpecResponseOutput) EnableDashboardAccess() pulumi.BoolOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1CustomJobSpecResponse) bool { return v.EnableDashboardAccess }).(pulumi.BoolOutput)
}

// Optional. Whether you want Vertex AI to enable [interactive shell access](https://cloud.google.com/vertex-ai/docs/training/monitor-debug-interactive-shell) to training containers. If set to `true`, you can access interactive shells at the URIs given by CustomJob.web_access_uris or Trial.web_access_uris (within HyperparameterTuningJob.trials).
func (o GoogleCloudAiplatformV1beta1CustomJobSpecResponseOutput) EnableWebAccess() pulumi.BoolOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1CustomJobSpecResponse) bool { return v.EnableWebAccess }).(pulumi.BoolOutput)
}

// Optional. The Experiment associated with this job. Format: `projects/{project}/locations/{location}/metadataStores/{metadataStores}/contexts/{experiment-name}`
func (o GoogleCloudAiplatformV1beta1CustomJobSpecResponseOutput) Experiment() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1CustomJobSpecResponse) string { return v.Experiment }).(pulumi.StringOutput)
}

// Optional. The Experiment Run associated with this job. Format: `projects/{project}/locations/{location}/metadataStores/{metadataStores}/contexts/{experiment-name}-{experiment-run-name}`
func (o GoogleCloudAiplatformV1beta1CustomJobSpecResponseOutput) ExperimentRun() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1CustomJobSpecResponse) string { return v.ExperimentRun }).(pulumi.StringOutput)
}

// Optional. The full name of the Compute Engine [network](/compute/docs/networks-and-firewalls#networks) to which the Job should be peered. For example, `projects/12345/global/networks/myVPC`. [Format](/compute/docs/reference/rest/v1/networks/insert) is of the form `projects/{project}/global/networks/{network}`. Where {project} is a project number, as in `12345`, and {network} is a network name. To specify this field, you must have already [configured VPC Network Peering for Vertex AI](https://cloud.google.com/vertex-ai/docs/general/vpc-peering). If this field is left unspecified, the job is not peered with any network.
func (o GoogleCloudAiplatformV1beta1CustomJobSpecResponseOutput) Network() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1CustomJobSpecResponse) string { return v.Network }).(pulumi.StringOutput)
}

// Optional. The ID of the PersistentResource in the same Project and Location which to run If this is specified, the job will be run on existing machines held by the PersistentResource instead of on-demand short-live machines. The network and CMEK configs on the job should be consistent with those on the PersistentResource, otherwise, the job will be rejected.
func (o GoogleCloudAiplatformV1beta1CustomJobSpecResponseOutput) PersistentResourceId() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1CustomJobSpecResponse) string { return v.PersistentResourceId }).(pulumi.StringOutput)
}

// The ID of the location to store protected artifacts. e.g. us-central1. Populate only when the location is different than CustomJob location. List of supported locations: https://cloud.google.com/vertex-ai/docs/general/locations
func (o GoogleCloudAiplatformV1beta1CustomJobSpecResponseOutput) ProtectedArtifactLocationId() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1CustomJobSpecResponse) string { return v.ProtectedArtifactLocationId }).(pulumi.StringOutput)
}

// Optional. A list of names for the reserved ip ranges under the VPC network that can be used for this job. If set, we will deploy the job within the provided ip ranges. Otherwise, the job will be deployed to any ip ranges under the provided VPC network. Example: ['vertex-ai-ip-range'].
func (o GoogleCloudAiplatformV1beta1CustomJobSpecResponseOutput) ReservedIpRanges() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1CustomJobSpecResponse) []string { return v.ReservedIpRanges }).(pulumi.StringArrayOutput)
}

// Scheduling options for a CustomJob.
func (o GoogleCloudAiplatformV1beta1CustomJobSpecResponseOutput) Scheduling() GoogleCloudAiplatformV1beta1SchedulingResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1CustomJobSpecResponse) GoogleCloudAiplatformV1beta1SchedulingResponse {
		return v.Scheduling
	}).(GoogleCloudAiplatformV1beta1SchedulingResponseOutput)
}

// Specifies the service account for workload run-as account. Users submitting jobs must have act-as permission on this run-as account. If unspecified, the [Vertex AI Custom Code Service Agent](https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents) for the CustomJob's project is used.
func (o GoogleCloudAiplatformV1beta1CustomJobSpecResponseOutput) ServiceAccount() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1CustomJobSpecResponse) string { return v.ServiceAccount }).(pulumi.StringOutput)
}

// Optional. The name of a Vertex AI Tensorboard resource to which this CustomJob will upload Tensorboard logs. Format: `projects/{project}/locations/{location}/tensorboards/{tensorboard}`
func (o GoogleCloudAiplatformV1beta1CustomJobSpecResponseOutput) Tensorboard() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1CustomJobSpecResponse) string { return v.Tensorboard }).(pulumi.StringOutput)
}

// The spec of the worker pools including machine type and Docker image. All worker pools except the first one are optional and can be skipped by providing an empty value.
func (o GoogleCloudAiplatformV1beta1CustomJobSpecResponseOutput) WorkerPoolSpecs() GoogleCloudAiplatformV1beta1WorkerPoolSpecResponseArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1CustomJobSpecResponse) []GoogleCloudAiplatformV1beta1WorkerPoolSpecResponse {
		return v.WorkerPoolSpecs
	}).(GoogleCloudAiplatformV1beta1WorkerPoolSpecResponseArrayOutput)
}

// A description of resources that are dedicated to a DeployedModel, and that need a higher degree of manual configuration.
type GoogleCloudAiplatformV1beta1DedicatedResources struct {
	// Immutable. The metric specifications that overrides a resource utilization metric (CPU utilization, accelerator's duty cycle, and so on) target value (default to 60 if not set). At most one entry is allowed per metric. If machine_spec.accelerator_count is above 0, the autoscaling will be based on both CPU utilization and accelerator's duty cycle metrics and scale up when either metrics exceeds its target value while scale down if both metrics are under their target value. The default target value is 60 for both metrics. If machine_spec.accelerator_count is 0, the autoscaling will be based on CPU utilization metric only with default target value 60 if not explicitly set. For example, in the case of Online Prediction, if you want to override target CPU utilization to 80, you should set autoscaling_metric_specs.metric_name to `aiplatform.googleapis.com/prediction/online/cpu/utilization` and autoscaling_metric_specs.target to `80`.
	AutoscalingMetricSpecs []GoogleCloudAiplatformV1beta1AutoscalingMetricSpec `pulumi:"autoscalingMetricSpecs"`
	// Immutable. The specification of a single machine used by the prediction.
	MachineSpec GoogleCloudAiplatformV1beta1MachineSpec `pulumi:"machineSpec"`
	// Immutable. The maximum number of replicas this DeployedModel may be deployed on when the traffic against it increases. If the requested value is too large, the deployment will error, but if deployment succeeds then the ability to scale the model to that many replicas is guaranteed (barring service outages). If traffic against the DeployedModel increases beyond what its replicas at maximum may handle, a portion of the traffic will be dropped. If this value is not provided, will use min_replica_count as the default value. The value of this field impacts the charge against Vertex CPU and GPU quotas. Specifically, you will be charged for (max_replica_count * number of cores in the selected machine type) and (max_replica_count * number of GPUs per replica in the selected machine type).
	MaxReplicaCount *int `pulumi:"maxReplicaCount"`
	// Immutable. The minimum number of machine replicas this DeployedModel will be always deployed on. This value must be greater than or equal to 1. If traffic against the DeployedModel increases, it may dynamically be deployed onto more replicas, and as traffic decreases, some of these extra replicas may be freed.
	MinReplicaCount int `pulumi:"minReplicaCount"`
}

// GoogleCloudAiplatformV1beta1DedicatedResourcesInput is an input type that accepts GoogleCloudAiplatformV1beta1DedicatedResourcesArgs and GoogleCloudAiplatformV1beta1DedicatedResourcesOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1DedicatedResourcesInput` via:
//
//	GoogleCloudAiplatformV1beta1DedicatedResourcesArgs{...}
type GoogleCloudAiplatformV1beta1DedicatedResourcesInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1DedicatedResourcesOutput() GoogleCloudAiplatformV1beta1DedicatedResourcesOutput
	ToGoogleCloudAiplatformV1beta1DedicatedResourcesOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1DedicatedResourcesOutput
}

// A description of resources that are dedicated to a DeployedModel, and that need a higher degree of manual configuration.
type GoogleCloudAiplatformV1beta1DedicatedResourcesArgs struct {
	// Immutable. The metric specifications that overrides a resource utilization metric (CPU utilization, accelerator's duty cycle, and so on) target value (default to 60 if not set). At most one entry is allowed per metric. If machine_spec.accelerator_count is above 0, the autoscaling will be based on both CPU utilization and accelerator's duty cycle metrics and scale up when either metrics exceeds its target value while scale down if both metrics are under their target value. The default target value is 60 for both metrics. If machine_spec.accelerator_count is 0, the autoscaling will be based on CPU utilization metric only with default target value 60 if not explicitly set. For example, in the case of Online Prediction, if you want to override target CPU utilization to 80, you should set autoscaling_metric_specs.metric_name to `aiplatform.googleapis.com/prediction/online/cpu/utilization` and autoscaling_metric_specs.target to `80`.
	AutoscalingMetricSpecs GoogleCloudAiplatformV1beta1AutoscalingMetricSpecArrayInput `pulumi:"autoscalingMetricSpecs"`
	// Immutable. The specification of a single machine used by the prediction.
	MachineSpec GoogleCloudAiplatformV1beta1MachineSpecInput `pulumi:"machineSpec"`
	// Immutable. The maximum number of replicas this DeployedModel may be deployed on when the traffic against it increases. If the requested value is too large, the deployment will error, but if deployment succeeds then the ability to scale the model to that many replicas is guaranteed (barring service outages). If traffic against the DeployedModel increases beyond what its replicas at maximum may handle, a portion of the traffic will be dropped. If this value is not provided, will use min_replica_count as the default value. The value of this field impacts the charge against Vertex CPU and GPU quotas. Specifically, you will be charged for (max_replica_count * number of cores in the selected machine type) and (max_replica_count * number of GPUs per replica in the selected machine type).
	MaxReplicaCount pulumi.IntPtrInput `pulumi:"maxReplicaCount"`
	// Immutable. The minimum number of machine replicas this DeployedModel will be always deployed on. This value must be greater than or equal to 1. If traffic against the DeployedModel increases, it may dynamically be deployed onto more replicas, and as traffic decreases, some of these extra replicas may be freed.
	MinReplicaCount pulumi.IntInput `pulumi:"minReplicaCount"`
}

func (GoogleCloudAiplatformV1beta1DedicatedResourcesArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1DedicatedResources)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1DedicatedResourcesArgs) ToGoogleCloudAiplatformV1beta1DedicatedResourcesOutput() GoogleCloudAiplatformV1beta1DedicatedResourcesOutput {
	return i.ToGoogleCloudAiplatformV1beta1DedicatedResourcesOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1DedicatedResourcesArgs) ToGoogleCloudAiplatformV1beta1DedicatedResourcesOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1DedicatedResourcesOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1DedicatedResourcesOutput)
}

// A description of resources that are dedicated to a DeployedModel, and that need a higher degree of manual configuration.
type GoogleCloudAiplatformV1beta1DedicatedResourcesOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1DedicatedResourcesOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1DedicatedResources)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1DedicatedResourcesOutput) ToGoogleCloudAiplatformV1beta1DedicatedResourcesOutput() GoogleCloudAiplatformV1beta1DedicatedResourcesOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1DedicatedResourcesOutput) ToGoogleCloudAiplatformV1beta1DedicatedResourcesOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1DedicatedResourcesOutput {
	return o
}

// Immutable. The metric specifications that overrides a resource utilization metric (CPU utilization, accelerator's duty cycle, and so on) target value (default to 60 if not set). At most one entry is allowed per metric. If machine_spec.accelerator_count is above 0, the autoscaling will be based on both CPU utilization and accelerator's duty cycle metrics and scale up when either metrics exceeds its target value while scale down if both metrics are under their target value. The default target value is 60 for both metrics. If machine_spec.accelerator_count is 0, the autoscaling will be based on CPU utilization metric only with default target value 60 if not explicitly set. For example, in the case of Online Prediction, if you want to override target CPU utilization to 80, you should set autoscaling_metric_specs.metric_name to `aiplatform.googleapis.com/prediction/online/cpu/utilization` and autoscaling_metric_specs.target to `80`.
func (o GoogleCloudAiplatformV1beta1DedicatedResourcesOutput) AutoscalingMetricSpecs() GoogleCloudAiplatformV1beta1AutoscalingMetricSpecArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1DedicatedResources) []GoogleCloudAiplatformV1beta1AutoscalingMetricSpec {
		return v.AutoscalingMetricSpecs
	}).(GoogleCloudAiplatformV1beta1AutoscalingMetricSpecArrayOutput)
}

// Immutable. The specification of a single machine used by the prediction.
func (o GoogleCloudAiplatformV1beta1DedicatedResourcesOutput) MachineSpec() GoogleCloudAiplatformV1beta1MachineSpecOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1DedicatedResources) GoogleCloudAiplatformV1beta1MachineSpec {
		return v.MachineSpec
	}).(GoogleCloudAiplatformV1beta1MachineSpecOutput)
}

// Immutable. The maximum number of replicas this DeployedModel may be deployed on when the traffic against it increases. If the requested value is too large, the deployment will error, but if deployment succeeds then the ability to scale the model to that many replicas is guaranteed (barring service outages). If traffic against the DeployedModel increases beyond what its replicas at maximum may handle, a portion of the traffic will be dropped. If this value is not provided, will use min_replica_count as the default value. The value of this field impacts the charge against Vertex CPU and GPU quotas. Specifically, you will be charged for (max_replica_count * number of cores in the selected machine type) and (max_replica_count * number of GPUs per replica in the selected machine type).
func (o GoogleCloudAiplatformV1beta1DedicatedResourcesOutput) MaxReplicaCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1DedicatedResources) *int { return v.MaxReplicaCount }).(pulumi.IntPtrOutput)
}

// Immutable. The minimum number of machine replicas this DeployedModel will be always deployed on. This value must be greater than or equal to 1. If traffic against the DeployedModel increases, it may dynamically be deployed onto more replicas, and as traffic decreases, some of these extra replicas may be freed.
func (o GoogleCloudAiplatformV1beta1DedicatedResourcesOutput) MinReplicaCount() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1DedicatedResources) int { return v.MinReplicaCount }).(pulumi.IntOutput)
}

// A description of resources that are dedicated to a DeployedModel, and that need a higher degree of manual configuration.
type GoogleCloudAiplatformV1beta1DedicatedResourcesResponse struct {
	// Immutable. The metric specifications that overrides a resource utilization metric (CPU utilization, accelerator's duty cycle, and so on) target value (default to 60 if not set). At most one entry is allowed per metric. If machine_spec.accelerator_count is above 0, the autoscaling will be based on both CPU utilization and accelerator's duty cycle metrics and scale up when either metrics exceeds its target value while scale down if both metrics are under their target value. The default target value is 60 for both metrics. If machine_spec.accelerator_count is 0, the autoscaling will be based on CPU utilization metric only with default target value 60 if not explicitly set. For example, in the case of Online Prediction, if you want to override target CPU utilization to 80, you should set autoscaling_metric_specs.metric_name to `aiplatform.googleapis.com/prediction/online/cpu/utilization` and autoscaling_metric_specs.target to `80`.
	AutoscalingMetricSpecs []GoogleCloudAiplatformV1beta1AutoscalingMetricSpecResponse `pulumi:"autoscalingMetricSpecs"`
	// Immutable. The specification of a single machine used by the prediction.
	MachineSpec GoogleCloudAiplatformV1beta1MachineSpecResponse `pulumi:"machineSpec"`
	// Immutable. The maximum number of replicas this DeployedModel may be deployed on when the traffic against it increases. If the requested value is too large, the deployment will error, but if deployment succeeds then the ability to scale the model to that many replicas is guaranteed (barring service outages). If traffic against the DeployedModel increases beyond what its replicas at maximum may handle, a portion of the traffic will be dropped. If this value is not provided, will use min_replica_count as the default value. The value of this field impacts the charge against Vertex CPU and GPU quotas. Specifically, you will be charged for (max_replica_count * number of cores in the selected machine type) and (max_replica_count * number of GPUs per replica in the selected machine type).
	MaxReplicaCount int `pulumi:"maxReplicaCount"`
	// Immutable. The minimum number of machine replicas this DeployedModel will be always deployed on. This value must be greater than or equal to 1. If traffic against the DeployedModel increases, it may dynamically be deployed onto more replicas, and as traffic decreases, some of these extra replicas may be freed.
	MinReplicaCount int `pulumi:"minReplicaCount"`
}

// A description of resources that are dedicated to a DeployedModel, and that need a higher degree of manual configuration.
type GoogleCloudAiplatformV1beta1DedicatedResourcesResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1DedicatedResourcesResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1DedicatedResourcesResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1DedicatedResourcesResponseOutput) ToGoogleCloudAiplatformV1beta1DedicatedResourcesResponseOutput() GoogleCloudAiplatformV1beta1DedicatedResourcesResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1DedicatedResourcesResponseOutput) ToGoogleCloudAiplatformV1beta1DedicatedResourcesResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1DedicatedResourcesResponseOutput {
	return o
}

// Immutable. The metric specifications that overrides a resource utilization metric (CPU utilization, accelerator's duty cycle, and so on) target value (default to 60 if not set). At most one entry is allowed per metric. If machine_spec.accelerator_count is above 0, the autoscaling will be based on both CPU utilization and accelerator's duty cycle metrics and scale up when either metrics exceeds its target value while scale down if both metrics are under their target value. The default target value is 60 for both metrics. If machine_spec.accelerator_count is 0, the autoscaling will be based on CPU utilization metric only with default target value 60 if not explicitly set. For example, in the case of Online Prediction, if you want to override target CPU utilization to 80, you should set autoscaling_metric_specs.metric_name to `aiplatform.googleapis.com/prediction/online/cpu/utilization` and autoscaling_metric_specs.target to `80`.
func (o GoogleCloudAiplatformV1beta1DedicatedResourcesResponseOutput) AutoscalingMetricSpecs() GoogleCloudAiplatformV1beta1AutoscalingMetricSpecResponseArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1DedicatedResourcesResponse) []GoogleCloudAiplatformV1beta1AutoscalingMetricSpecResponse {
		return v.AutoscalingMetricSpecs
	}).(GoogleCloudAiplatformV1beta1AutoscalingMetricSpecResponseArrayOutput)
}

// Immutable. The specification of a single machine used by the prediction.
func (o GoogleCloudAiplatformV1beta1DedicatedResourcesResponseOutput) MachineSpec() GoogleCloudAiplatformV1beta1MachineSpecResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1DedicatedResourcesResponse) GoogleCloudAiplatformV1beta1MachineSpecResponse {
		return v.MachineSpec
	}).(GoogleCloudAiplatformV1beta1MachineSpecResponseOutput)
}

// Immutable. The maximum number of replicas this DeployedModel may be deployed on when the traffic against it increases. If the requested value is too large, the deployment will error, but if deployment succeeds then the ability to scale the model to that many replicas is guaranteed (barring service outages). If traffic against the DeployedModel increases beyond what its replicas at maximum may handle, a portion of the traffic will be dropped. If this value is not provided, will use min_replica_count as the default value. The value of this field impacts the charge against Vertex CPU and GPU quotas. Specifically, you will be charged for (max_replica_count * number of cores in the selected machine type) and (max_replica_count * number of GPUs per replica in the selected machine type).
func (o GoogleCloudAiplatformV1beta1DedicatedResourcesResponseOutput) MaxReplicaCount() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1DedicatedResourcesResponse) int { return v.MaxReplicaCount }).(pulumi.IntOutput)
}

// Immutable. The minimum number of machine replicas this DeployedModel will be always deployed on. This value must be greater than or equal to 1. If traffic against the DeployedModel increases, it may dynamically be deployed onto more replicas, and as traffic decreases, some of these extra replicas may be freed.
func (o GoogleCloudAiplatformV1beta1DedicatedResourcesResponseOutput) MinReplicaCount() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1DedicatedResourcesResponse) int { return v.MinReplicaCount }).(pulumi.IntOutput)
}

// Configuration for an authentication provider, including support for [JSON Web Token (JWT)](https://tools.ietf.org/html/draft-ietf-oauth-json-web-token-32).
type GoogleCloudAiplatformV1beta1DeployedIndexAuthConfigAuthProviderResponse struct {
	// A list of allowed JWT issuers. Each entry must be a valid Google service account, in the following format: `service-account-name@project-id.iam.gserviceaccount.com`
	AllowedIssuers []string `pulumi:"allowedIssuers"`
	// The list of JWT [audiences](https://tools.ietf.org/html/draft-ietf-oauth-json-web-token-32#section-4.1.3). that are allowed to access. A JWT containing any of these audiences will be accepted.
	Audiences []string `pulumi:"audiences"`
}

// Configuration for an authentication provider, including support for [JSON Web Token (JWT)](https://tools.ietf.org/html/draft-ietf-oauth-json-web-token-32).
type GoogleCloudAiplatformV1beta1DeployedIndexAuthConfigAuthProviderResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1DeployedIndexAuthConfigAuthProviderResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1DeployedIndexAuthConfigAuthProviderResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1DeployedIndexAuthConfigAuthProviderResponseOutput) ToGoogleCloudAiplatformV1beta1DeployedIndexAuthConfigAuthProviderResponseOutput() GoogleCloudAiplatformV1beta1DeployedIndexAuthConfigAuthProviderResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1DeployedIndexAuthConfigAuthProviderResponseOutput) ToGoogleCloudAiplatformV1beta1DeployedIndexAuthConfigAuthProviderResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1DeployedIndexAuthConfigAuthProviderResponseOutput {
	return o
}

// A list of allowed JWT issuers. Each entry must be a valid Google service account, in the following format: `service-account-name@project-id.iam.gserviceaccount.com`
func (o GoogleCloudAiplatformV1beta1DeployedIndexAuthConfigAuthProviderResponseOutput) AllowedIssuers() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1DeployedIndexAuthConfigAuthProviderResponse) []string {
		return v.AllowedIssuers
	}).(pulumi.StringArrayOutput)
}

// The list of JWT [audiences](https://tools.ietf.org/html/draft-ietf-oauth-json-web-token-32#section-4.1.3). that are allowed to access. A JWT containing any of these audiences will be accepted.
func (o GoogleCloudAiplatformV1beta1DeployedIndexAuthConfigAuthProviderResponseOutput) Audiences() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1DeployedIndexAuthConfigAuthProviderResponse) []string {
		return v.Audiences
	}).(pulumi.StringArrayOutput)
}

// Used to set up the auth on the DeployedIndex's private endpoint.
type GoogleCloudAiplatformV1beta1DeployedIndexAuthConfigResponse struct {
	// Defines the authentication provider that the DeployedIndex uses.
	AuthProvider GoogleCloudAiplatformV1beta1DeployedIndexAuthConfigAuthProviderResponse `pulumi:"authProvider"`
}

// Used to set up the auth on the DeployedIndex's private endpoint.
type GoogleCloudAiplatformV1beta1DeployedIndexAuthConfigResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1DeployedIndexAuthConfigResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1DeployedIndexAuthConfigResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1DeployedIndexAuthConfigResponseOutput) ToGoogleCloudAiplatformV1beta1DeployedIndexAuthConfigResponseOutput() GoogleCloudAiplatformV1beta1DeployedIndexAuthConfigResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1DeployedIndexAuthConfigResponseOutput) ToGoogleCloudAiplatformV1beta1DeployedIndexAuthConfigResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1DeployedIndexAuthConfigResponseOutput {
	return o
}

// Defines the authentication provider that the DeployedIndex uses.
func (o GoogleCloudAiplatformV1beta1DeployedIndexAuthConfigResponseOutput) AuthProvider() GoogleCloudAiplatformV1beta1DeployedIndexAuthConfigAuthProviderResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1DeployedIndexAuthConfigResponse) GoogleCloudAiplatformV1beta1DeployedIndexAuthConfigAuthProviderResponse {
		return v.AuthProvider
	}).(GoogleCloudAiplatformV1beta1DeployedIndexAuthConfigAuthProviderResponseOutput)
}

// Points to a DeployedIndex.
type GoogleCloudAiplatformV1beta1DeployedIndexRefResponse struct {
	// Immutable. The ID of the DeployedIndex in the above IndexEndpoint.
	DeployedIndexId string `pulumi:"deployedIndexId"`
	// Immutable. A resource name of the IndexEndpoint.
	IndexEndpoint string `pulumi:"indexEndpoint"`
}

// Points to a DeployedIndex.
type GoogleCloudAiplatformV1beta1DeployedIndexRefResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1DeployedIndexRefResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1DeployedIndexRefResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1DeployedIndexRefResponseOutput) ToGoogleCloudAiplatformV1beta1DeployedIndexRefResponseOutput() GoogleCloudAiplatformV1beta1DeployedIndexRefResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1DeployedIndexRefResponseOutput) ToGoogleCloudAiplatformV1beta1DeployedIndexRefResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1DeployedIndexRefResponseOutput {
	return o
}

// Immutable. The ID of the DeployedIndex in the above IndexEndpoint.
func (o GoogleCloudAiplatformV1beta1DeployedIndexRefResponseOutput) DeployedIndexId() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1DeployedIndexRefResponse) string { return v.DeployedIndexId }).(pulumi.StringOutput)
}

// Immutable. A resource name of the IndexEndpoint.
func (o GoogleCloudAiplatformV1beta1DeployedIndexRefResponseOutput) IndexEndpoint() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1DeployedIndexRefResponse) string { return v.IndexEndpoint }).(pulumi.StringOutput)
}

type GoogleCloudAiplatformV1beta1DeployedIndexRefResponseArrayOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1DeployedIndexRefResponseArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1beta1DeployedIndexRefResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1DeployedIndexRefResponseArrayOutput) ToGoogleCloudAiplatformV1beta1DeployedIndexRefResponseArrayOutput() GoogleCloudAiplatformV1beta1DeployedIndexRefResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1DeployedIndexRefResponseArrayOutput) ToGoogleCloudAiplatformV1beta1DeployedIndexRefResponseArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1DeployedIndexRefResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1DeployedIndexRefResponseArrayOutput) Index(i pulumi.IntInput) GoogleCloudAiplatformV1beta1DeployedIndexRefResponseOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GoogleCloudAiplatformV1beta1DeployedIndexRefResponse {
		return vs[0].([]GoogleCloudAiplatformV1beta1DeployedIndexRefResponse)[vs[1].(int)]
	}).(GoogleCloudAiplatformV1beta1DeployedIndexRefResponseOutput)
}

// A deployment of an Index. IndexEndpoints contain one or more DeployedIndexes.
type GoogleCloudAiplatformV1beta1DeployedIndexResponse struct {
	// Optional. A description of resources that the DeployedIndex uses, which to large degree are decided by Vertex AI, and optionally allows only a modest additional configuration. If min_replica_count is not set, the default value is 2 (we don't provide SLA when min_replica_count=1). If max_replica_count is not set, the default value is min_replica_count. The max allowed replica count is 1000.
	AutomaticResources GoogleCloudAiplatformV1beta1AutomaticResourcesResponse `pulumi:"automaticResources"`
	// Timestamp when the DeployedIndex was created.
	CreateTime string `pulumi:"createTime"`
	// Optional. A description of resources that are dedicated to the DeployedIndex, and that need a higher degree of manual configuration. The field min_replica_count must be set to a value strictly greater than 0, or else validation will fail. We don't provide SLA when min_replica_count=1. If max_replica_count is not set, the default value is min_replica_count. The max allowed replica count is 1000. Available machine types for SMALL shard: e2-standard-2 and all machine types available for MEDIUM and LARGE shard. Available machine types for MEDIUM shard: e2-standard-16 and all machine types available for LARGE shard. Available machine types for LARGE shard: e2-highmem-16, n2d-standard-32. n1-standard-16 and n1-standard-32 are still available, but we recommend e2-standard-16 and e2-highmem-16 for cost efficiency.
	DedicatedResources GoogleCloudAiplatformV1beta1DedicatedResourcesResponse `pulumi:"dedicatedResources"`
	// Optional. If set, the authentication is enabled for the private endpoint.
	DeployedIndexAuthConfig GoogleCloudAiplatformV1beta1DeployedIndexAuthConfigResponse `pulumi:"deployedIndexAuthConfig"`
	// Optional. The deployment group can be no longer than 64 characters (eg: 'test', 'prod'). If not set, we will use the 'default' deployment group. Creating `deployment_groups` with `reserved_ip_ranges` is a recommended practice when the peered network has multiple peering ranges. This creates your deployments from predictable IP spaces for easier traffic administration. Also, one deployment_group (except 'default') can only be used with the same reserved_ip_ranges which means if the deployment_group has been used with reserved_ip_ranges: [a, b, c], using it with [a, b] or [d, e] is disallowed. Note: we only support up to 5 deployment groups(not including 'default').
	DeploymentGroup string `pulumi:"deploymentGroup"`
	// The display name of the DeployedIndex. If not provided upon creation, the Index's display_name is used.
	DisplayName string `pulumi:"displayName"`
	// Optional. If true, private endpoint's access logs are sent to Cloud Logging. These logs are like standard server access logs, containing information like timestamp and latency for each MatchRequest. Note that logs may incur a cost, especially if the deployed index receives a high queries per second rate (QPS). Estimate your costs before enabling this option.
	EnableAccessLogging bool `pulumi:"enableAccessLogging"`
	// The name of the Index this is the deployment of. We may refer to this Index as the DeployedIndex's "original" Index.
	Index string `pulumi:"index"`
	// The DeployedIndex may depend on various data on its original Index. Additionally when certain changes to the original Index are being done (e.g. when what the Index contains is being changed) the DeployedIndex may be asynchronously updated in the background to reflect these changes. If this timestamp's value is at least the Index.update_time of the original Index, it means that this DeployedIndex and the original Index are in sync. If this timestamp is older, then to see which updates this DeployedIndex already contains (and which it does not), one must list the operations that are running on the original Index. Only the successfully completed Operations with update_time equal or before this sync time are contained in this DeployedIndex.
	IndexSyncTime string `pulumi:"indexSyncTime"`
	// Provides paths for users to send requests directly to the deployed index services running on Cloud via private services access. This field is populated if network is configured.
	PrivateEndpoints GoogleCloudAiplatformV1beta1IndexPrivateEndpointsResponse `pulumi:"privateEndpoints"`
	// Optional. A list of reserved ip ranges under the VPC network that can be used for this DeployedIndex. If set, we will deploy the index within the provided ip ranges. Otherwise, the index might be deployed to any ip ranges under the provided VPC network. The value should be the name of the address (https://cloud.google.com/compute/docs/reference/rest/v1/addresses) Example: ['vertex-ai-ip-range']. For more information about subnets and network IP ranges, please see https://cloud.google.com/vpc/docs/subnets#manually_created_subnet_ip_ranges.
	ReservedIpRanges []string `pulumi:"reservedIpRanges"`
}

// A deployment of an Index. IndexEndpoints contain one or more DeployedIndexes.
type GoogleCloudAiplatformV1beta1DeployedIndexResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1DeployedIndexResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1DeployedIndexResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1DeployedIndexResponseOutput) ToGoogleCloudAiplatformV1beta1DeployedIndexResponseOutput() GoogleCloudAiplatformV1beta1DeployedIndexResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1DeployedIndexResponseOutput) ToGoogleCloudAiplatformV1beta1DeployedIndexResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1DeployedIndexResponseOutput {
	return o
}

// Optional. A description of resources that the DeployedIndex uses, which to large degree are decided by Vertex AI, and optionally allows only a modest additional configuration. If min_replica_count is not set, the default value is 2 (we don't provide SLA when min_replica_count=1). If max_replica_count is not set, the default value is min_replica_count. The max allowed replica count is 1000.
func (o GoogleCloudAiplatformV1beta1DeployedIndexResponseOutput) AutomaticResources() GoogleCloudAiplatformV1beta1AutomaticResourcesResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1DeployedIndexResponse) GoogleCloudAiplatformV1beta1AutomaticResourcesResponse {
		return v.AutomaticResources
	}).(GoogleCloudAiplatformV1beta1AutomaticResourcesResponseOutput)
}

// Timestamp when the DeployedIndex was created.
func (o GoogleCloudAiplatformV1beta1DeployedIndexResponseOutput) CreateTime() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1DeployedIndexResponse) string { return v.CreateTime }).(pulumi.StringOutput)
}

// Optional. A description of resources that are dedicated to the DeployedIndex, and that need a higher degree of manual configuration. The field min_replica_count must be set to a value strictly greater than 0, or else validation will fail. We don't provide SLA when min_replica_count=1. If max_replica_count is not set, the default value is min_replica_count. The max allowed replica count is 1000. Available machine types for SMALL shard: e2-standard-2 and all machine types available for MEDIUM and LARGE shard. Available machine types for MEDIUM shard: e2-standard-16 and all machine types available for LARGE shard. Available machine types for LARGE shard: e2-highmem-16, n2d-standard-32. n1-standard-16 and n1-standard-32 are still available, but we recommend e2-standard-16 and e2-highmem-16 for cost efficiency.
func (o GoogleCloudAiplatformV1beta1DeployedIndexResponseOutput) DedicatedResources() GoogleCloudAiplatformV1beta1DedicatedResourcesResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1DeployedIndexResponse) GoogleCloudAiplatformV1beta1DedicatedResourcesResponse {
		return v.DedicatedResources
	}).(GoogleCloudAiplatformV1beta1DedicatedResourcesResponseOutput)
}

// Optional. If set, the authentication is enabled for the private endpoint.
func (o GoogleCloudAiplatformV1beta1DeployedIndexResponseOutput) DeployedIndexAuthConfig() GoogleCloudAiplatformV1beta1DeployedIndexAuthConfigResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1DeployedIndexResponse) GoogleCloudAiplatformV1beta1DeployedIndexAuthConfigResponse {
		return v.DeployedIndexAuthConfig
	}).(GoogleCloudAiplatformV1beta1DeployedIndexAuthConfigResponseOutput)
}

// Optional. The deployment group can be no longer than 64 characters (eg: 'test', 'prod'). If not set, we will use the 'default' deployment group. Creating `deployment_groups` with `reserved_ip_ranges` is a recommended practice when the peered network has multiple peering ranges. This creates your deployments from predictable IP spaces for easier traffic administration. Also, one deployment_group (except 'default') can only be used with the same reserved_ip_ranges which means if the deployment_group has been used with reserved_ip_ranges: [a, b, c], using it with [a, b] or [d, e] is disallowed. Note: we only support up to 5 deployment groups(not including 'default').
func (o GoogleCloudAiplatformV1beta1DeployedIndexResponseOutput) DeploymentGroup() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1DeployedIndexResponse) string { return v.DeploymentGroup }).(pulumi.StringOutput)
}

// The display name of the DeployedIndex. If not provided upon creation, the Index's display_name is used.
func (o GoogleCloudAiplatformV1beta1DeployedIndexResponseOutput) DisplayName() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1DeployedIndexResponse) string { return v.DisplayName }).(pulumi.StringOutput)
}

// Optional. If true, private endpoint's access logs are sent to Cloud Logging. These logs are like standard server access logs, containing information like timestamp and latency for each MatchRequest. Note that logs may incur a cost, especially if the deployed index receives a high queries per second rate (QPS). Estimate your costs before enabling this option.
func (o GoogleCloudAiplatformV1beta1DeployedIndexResponseOutput) EnableAccessLogging() pulumi.BoolOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1DeployedIndexResponse) bool { return v.EnableAccessLogging }).(pulumi.BoolOutput)
}

// The name of the Index this is the deployment of. We may refer to this Index as the DeployedIndex's "original" Index.
func (o GoogleCloudAiplatformV1beta1DeployedIndexResponseOutput) Index() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1DeployedIndexResponse) string { return v.Index }).(pulumi.StringOutput)
}

// The DeployedIndex may depend on various data on its original Index. Additionally when certain changes to the original Index are being done (e.g. when what the Index contains is being changed) the DeployedIndex may be asynchronously updated in the background to reflect these changes. If this timestamp's value is at least the Index.update_time of the original Index, it means that this DeployedIndex and the original Index are in sync. If this timestamp is older, then to see which updates this DeployedIndex already contains (and which it does not), one must list the operations that are running on the original Index. Only the successfully completed Operations with update_time equal or before this sync time are contained in this DeployedIndex.
func (o GoogleCloudAiplatformV1beta1DeployedIndexResponseOutput) IndexSyncTime() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1DeployedIndexResponse) string { return v.IndexSyncTime }).(pulumi.StringOutput)
}

// Provides paths for users to send requests directly to the deployed index services running on Cloud via private services access. This field is populated if network is configured.
func (o GoogleCloudAiplatformV1beta1DeployedIndexResponseOutput) PrivateEndpoints() GoogleCloudAiplatformV1beta1IndexPrivateEndpointsResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1DeployedIndexResponse) GoogleCloudAiplatformV1beta1IndexPrivateEndpointsResponse {
		return v.PrivateEndpoints
	}).(GoogleCloudAiplatformV1beta1IndexPrivateEndpointsResponseOutput)
}

// Optional. A list of reserved ip ranges under the VPC network that can be used for this DeployedIndex. If set, we will deploy the index within the provided ip ranges. Otherwise, the index might be deployed to any ip ranges under the provided VPC network. The value should be the name of the address (https://cloud.google.com/compute/docs/reference/rest/v1/addresses) Example: ['vertex-ai-ip-range']. For more information about subnets and network IP ranges, please see https://cloud.google.com/vpc/docs/subnets#manually_created_subnet_ip_ranges.
func (o GoogleCloudAiplatformV1beta1DeployedIndexResponseOutput) ReservedIpRanges() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1DeployedIndexResponse) []string { return v.ReservedIpRanges }).(pulumi.StringArrayOutput)
}

type GoogleCloudAiplatformV1beta1DeployedIndexResponseArrayOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1DeployedIndexResponseArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1beta1DeployedIndexResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1DeployedIndexResponseArrayOutput) ToGoogleCloudAiplatformV1beta1DeployedIndexResponseArrayOutput() GoogleCloudAiplatformV1beta1DeployedIndexResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1DeployedIndexResponseArrayOutput) ToGoogleCloudAiplatformV1beta1DeployedIndexResponseArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1DeployedIndexResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1DeployedIndexResponseArrayOutput) Index(i pulumi.IntInput) GoogleCloudAiplatformV1beta1DeployedIndexResponseOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GoogleCloudAiplatformV1beta1DeployedIndexResponse {
		return vs[0].([]GoogleCloudAiplatformV1beta1DeployedIndexResponse)[vs[1].(int)]
	}).(GoogleCloudAiplatformV1beta1DeployedIndexResponseOutput)
}

// Points to a DeployedModel.
type GoogleCloudAiplatformV1beta1DeployedModelRefResponse struct {
	// Immutable. An ID of a DeployedModel in the above Endpoint.
	DeployedModelId string `pulumi:"deployedModelId"`
	// Immutable. A resource name of an Endpoint.
	Endpoint string `pulumi:"endpoint"`
}

// Points to a DeployedModel.
type GoogleCloudAiplatformV1beta1DeployedModelRefResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1DeployedModelRefResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1DeployedModelRefResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1DeployedModelRefResponseOutput) ToGoogleCloudAiplatformV1beta1DeployedModelRefResponseOutput() GoogleCloudAiplatformV1beta1DeployedModelRefResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1DeployedModelRefResponseOutput) ToGoogleCloudAiplatformV1beta1DeployedModelRefResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1DeployedModelRefResponseOutput {
	return o
}

// Immutable. An ID of a DeployedModel in the above Endpoint.
func (o GoogleCloudAiplatformV1beta1DeployedModelRefResponseOutput) DeployedModelId() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1DeployedModelRefResponse) string { return v.DeployedModelId }).(pulumi.StringOutput)
}

// Immutable. A resource name of an Endpoint.
func (o GoogleCloudAiplatformV1beta1DeployedModelRefResponseOutput) Endpoint() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1DeployedModelRefResponse) string { return v.Endpoint }).(pulumi.StringOutput)
}

type GoogleCloudAiplatformV1beta1DeployedModelRefResponseArrayOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1DeployedModelRefResponseArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1beta1DeployedModelRefResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1DeployedModelRefResponseArrayOutput) ToGoogleCloudAiplatformV1beta1DeployedModelRefResponseArrayOutput() GoogleCloudAiplatformV1beta1DeployedModelRefResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1DeployedModelRefResponseArrayOutput) ToGoogleCloudAiplatformV1beta1DeployedModelRefResponseArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1DeployedModelRefResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1DeployedModelRefResponseArrayOutput) Index(i pulumi.IntInput) GoogleCloudAiplatformV1beta1DeployedModelRefResponseOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GoogleCloudAiplatformV1beta1DeployedModelRefResponse {
		return vs[0].([]GoogleCloudAiplatformV1beta1DeployedModelRefResponse)[vs[1].(int)]
	}).(GoogleCloudAiplatformV1beta1DeployedModelRefResponseOutput)
}

// A deployment of a Model. Endpoints contain one or more DeployedModels.
type GoogleCloudAiplatformV1beta1DeployedModelResponse struct {
	// A description of resources that to large degree are decided by Vertex AI, and require only a modest additional configuration.
	AutomaticResources GoogleCloudAiplatformV1beta1AutomaticResourcesResponse `pulumi:"automaticResources"`
	// Timestamp when the DeployedModel was created.
	CreateTime string `pulumi:"createTime"`
	// A description of resources that are dedicated to the DeployedModel, and that need a higher degree of manual configuration.
	DedicatedResources GoogleCloudAiplatformV1beta1DedicatedResourcesResponse `pulumi:"dedicatedResources"`
	// If true, deploy the model without explainable feature, regardless the existence of Model.explanation_spec or explanation_spec.
	DisableExplanations bool `pulumi:"disableExplanations"`
	// The display name of the DeployedModel. If not provided upon creation, the Model's display_name is used.
	DisplayName string `pulumi:"displayName"`
	// If true, online prediction access logs are sent to Cloud Logging. These logs are like standard server access logs, containing information like timestamp and latency for each prediction request. Note that logs may incur a cost, especially if your project receives prediction requests at a high queries per second rate (QPS). Estimate your costs before enabling this option.
	EnableAccessLogging bool `pulumi:"enableAccessLogging"`
	// If true, the container of the DeployedModel instances will send `stderr` and `stdout` streams to Cloud Logging. Only supported for custom-trained Models and AutoML Tabular Models.
	EnableContainerLogging bool `pulumi:"enableContainerLogging"`
	// Explanation configuration for this DeployedModel. When deploying a Model using EndpointService.DeployModel, this value overrides the value of Model.explanation_spec. All fields of explanation_spec are optional in the request. If a field of explanation_spec is not populated, the value of the same field of Model.explanation_spec is inherited. If the corresponding Model.explanation_spec is not populated, all fields of the explanation_spec will be used for the explanation configuration.
	ExplanationSpec GoogleCloudAiplatformV1beta1ExplanationSpecResponse `pulumi:"explanationSpec"`
	// The resource name of the Model that this is the deployment of. Note that the Model may be in a different location than the DeployedModel's Endpoint. The resource name may contain version id or version alias to specify the version. Example: `projects/{project}/locations/{location}/models/{model}@2` or `projects/{project}/locations/{location}/models/{model}@golden` if no version is specified, the default version will be deployed.
	Model string `pulumi:"model"`
	// The version ID of the model that is deployed.
	ModelVersionId string `pulumi:"modelVersionId"`
	// Provide paths for users to send predict/explain/health requests directly to the deployed model services running on Cloud via private services access. This field is populated if network is configured.
	PrivateEndpoints GoogleCloudAiplatformV1beta1PrivateEndpointsResponse `pulumi:"privateEndpoints"`
	// The service account that the DeployedModel's container runs as. Specify the email address of the service account. If this service account is not specified, the container runs as a service account that doesn't have access to the resource project. Users deploying the Model must have the `iam.serviceAccounts.actAs` permission on this service account.
	ServiceAccount string `pulumi:"serviceAccount"`
	// The resource name of the shared DeploymentResourcePool to deploy on. Format: `projects/{project}/locations/{location}/deploymentResourcePools/{deployment_resource_pool}`
	SharedResources string `pulumi:"sharedResources"`
}

// A deployment of a Model. Endpoints contain one or more DeployedModels.
type GoogleCloudAiplatformV1beta1DeployedModelResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1DeployedModelResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1DeployedModelResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1DeployedModelResponseOutput) ToGoogleCloudAiplatformV1beta1DeployedModelResponseOutput() GoogleCloudAiplatformV1beta1DeployedModelResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1DeployedModelResponseOutput) ToGoogleCloudAiplatformV1beta1DeployedModelResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1DeployedModelResponseOutput {
	return o
}

// A description of resources that to large degree are decided by Vertex AI, and require only a modest additional configuration.
func (o GoogleCloudAiplatformV1beta1DeployedModelResponseOutput) AutomaticResources() GoogleCloudAiplatformV1beta1AutomaticResourcesResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1DeployedModelResponse) GoogleCloudAiplatformV1beta1AutomaticResourcesResponse {
		return v.AutomaticResources
	}).(GoogleCloudAiplatformV1beta1AutomaticResourcesResponseOutput)
}

// Timestamp when the DeployedModel was created.
func (o GoogleCloudAiplatformV1beta1DeployedModelResponseOutput) CreateTime() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1DeployedModelResponse) string { return v.CreateTime }).(pulumi.StringOutput)
}

// A description of resources that are dedicated to the DeployedModel, and that need a higher degree of manual configuration.
func (o GoogleCloudAiplatformV1beta1DeployedModelResponseOutput) DedicatedResources() GoogleCloudAiplatformV1beta1DedicatedResourcesResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1DeployedModelResponse) GoogleCloudAiplatformV1beta1DedicatedResourcesResponse {
		return v.DedicatedResources
	}).(GoogleCloudAiplatformV1beta1DedicatedResourcesResponseOutput)
}

// If true, deploy the model without explainable feature, regardless the existence of Model.explanation_spec or explanation_spec.
func (o GoogleCloudAiplatformV1beta1DeployedModelResponseOutput) DisableExplanations() pulumi.BoolOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1DeployedModelResponse) bool { return v.DisableExplanations }).(pulumi.BoolOutput)
}

// The display name of the DeployedModel. If not provided upon creation, the Model's display_name is used.
func (o GoogleCloudAiplatformV1beta1DeployedModelResponseOutput) DisplayName() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1DeployedModelResponse) string { return v.DisplayName }).(pulumi.StringOutput)
}

// If true, online prediction access logs are sent to Cloud Logging. These logs are like standard server access logs, containing information like timestamp and latency for each prediction request. Note that logs may incur a cost, especially if your project receives prediction requests at a high queries per second rate (QPS). Estimate your costs before enabling this option.
func (o GoogleCloudAiplatformV1beta1DeployedModelResponseOutput) EnableAccessLogging() pulumi.BoolOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1DeployedModelResponse) bool { return v.EnableAccessLogging }).(pulumi.BoolOutput)
}

// If true, the container of the DeployedModel instances will send `stderr` and `stdout` streams to Cloud Logging. Only supported for custom-trained Models and AutoML Tabular Models.
func (o GoogleCloudAiplatformV1beta1DeployedModelResponseOutput) EnableContainerLogging() pulumi.BoolOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1DeployedModelResponse) bool { return v.EnableContainerLogging }).(pulumi.BoolOutput)
}

// Explanation configuration for this DeployedModel. When deploying a Model using EndpointService.DeployModel, this value overrides the value of Model.explanation_spec. All fields of explanation_spec are optional in the request. If a field of explanation_spec is not populated, the value of the same field of Model.explanation_spec is inherited. If the corresponding Model.explanation_spec is not populated, all fields of the explanation_spec will be used for the explanation configuration.
func (o GoogleCloudAiplatformV1beta1DeployedModelResponseOutput) ExplanationSpec() GoogleCloudAiplatformV1beta1ExplanationSpecResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1DeployedModelResponse) GoogleCloudAiplatformV1beta1ExplanationSpecResponse {
		return v.ExplanationSpec
	}).(GoogleCloudAiplatformV1beta1ExplanationSpecResponseOutput)
}

// The resource name of the Model that this is the deployment of. Note that the Model may be in a different location than the DeployedModel's Endpoint. The resource name may contain version id or version alias to specify the version. Example: `projects/{project}/locations/{location}/models/{model}@2` or `projects/{project}/locations/{location}/models/{model}@golden` if no version is specified, the default version will be deployed.
func (o GoogleCloudAiplatformV1beta1DeployedModelResponseOutput) Model() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1DeployedModelResponse) string { return v.Model }).(pulumi.StringOutput)
}

// The version ID of the model that is deployed.
func (o GoogleCloudAiplatformV1beta1DeployedModelResponseOutput) ModelVersionId() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1DeployedModelResponse) string { return v.ModelVersionId }).(pulumi.StringOutput)
}

// Provide paths for users to send predict/explain/health requests directly to the deployed model services running on Cloud via private services access. This field is populated if network is configured.
func (o GoogleCloudAiplatformV1beta1DeployedModelResponseOutput) PrivateEndpoints() GoogleCloudAiplatformV1beta1PrivateEndpointsResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1DeployedModelResponse) GoogleCloudAiplatformV1beta1PrivateEndpointsResponse {
		return v.PrivateEndpoints
	}).(GoogleCloudAiplatformV1beta1PrivateEndpointsResponseOutput)
}

// The service account that the DeployedModel's container runs as. Specify the email address of the service account. If this service account is not specified, the container runs as a service account that doesn't have access to the resource project. Users deploying the Model must have the `iam.serviceAccounts.actAs` permission on this service account.
func (o GoogleCloudAiplatformV1beta1DeployedModelResponseOutput) ServiceAccount() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1DeployedModelResponse) string { return v.ServiceAccount }).(pulumi.StringOutput)
}

// The resource name of the shared DeploymentResourcePool to deploy on. Format: `projects/{project}/locations/{location}/deploymentResourcePools/{deployment_resource_pool}`
func (o GoogleCloudAiplatformV1beta1DeployedModelResponseOutput) SharedResources() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1DeployedModelResponse) string { return v.SharedResources }).(pulumi.StringOutput)
}

type GoogleCloudAiplatformV1beta1DeployedModelResponseArrayOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1DeployedModelResponseArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1beta1DeployedModelResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1DeployedModelResponseArrayOutput) ToGoogleCloudAiplatformV1beta1DeployedModelResponseArrayOutput() GoogleCloudAiplatformV1beta1DeployedModelResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1DeployedModelResponseArrayOutput) ToGoogleCloudAiplatformV1beta1DeployedModelResponseArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1DeployedModelResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1DeployedModelResponseArrayOutput) Index(i pulumi.IntInput) GoogleCloudAiplatformV1beta1DeployedModelResponseOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GoogleCloudAiplatformV1beta1DeployedModelResponse {
		return vs[0].([]GoogleCloudAiplatformV1beta1DeployedModelResponse)[vs[1].(int)]
	}).(GoogleCloudAiplatformV1beta1DeployedModelResponseOutput)
}

// Represents the spec of disk options.
type GoogleCloudAiplatformV1beta1DiskSpec struct {
	// Size in GB of the boot disk (default is 100GB).
	BootDiskSizeGb *int `pulumi:"bootDiskSizeGb"`
	// Type of the boot disk (default is "pd-ssd"). Valid values: "pd-ssd" (Persistent Disk Solid State Drive) or "pd-standard" (Persistent Disk Hard Disk Drive).
	BootDiskType *string `pulumi:"bootDiskType"`
}

// GoogleCloudAiplatformV1beta1DiskSpecInput is an input type that accepts GoogleCloudAiplatformV1beta1DiskSpecArgs and GoogleCloudAiplatformV1beta1DiskSpecOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1DiskSpecInput` via:
//
//	GoogleCloudAiplatformV1beta1DiskSpecArgs{...}
type GoogleCloudAiplatformV1beta1DiskSpecInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1DiskSpecOutput() GoogleCloudAiplatformV1beta1DiskSpecOutput
	ToGoogleCloudAiplatformV1beta1DiskSpecOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1DiskSpecOutput
}

// Represents the spec of disk options.
type GoogleCloudAiplatformV1beta1DiskSpecArgs struct {
	// Size in GB of the boot disk (default is 100GB).
	BootDiskSizeGb pulumi.IntPtrInput `pulumi:"bootDiskSizeGb"`
	// Type of the boot disk (default is "pd-ssd"). Valid values: "pd-ssd" (Persistent Disk Solid State Drive) or "pd-standard" (Persistent Disk Hard Disk Drive).
	BootDiskType pulumi.StringPtrInput `pulumi:"bootDiskType"`
}

func (GoogleCloudAiplatformV1beta1DiskSpecArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1DiskSpec)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1DiskSpecArgs) ToGoogleCloudAiplatformV1beta1DiskSpecOutput() GoogleCloudAiplatformV1beta1DiskSpecOutput {
	return i.ToGoogleCloudAiplatformV1beta1DiskSpecOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1DiskSpecArgs) ToGoogleCloudAiplatformV1beta1DiskSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1DiskSpecOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1DiskSpecOutput)
}

func (i GoogleCloudAiplatformV1beta1DiskSpecArgs) ToGoogleCloudAiplatformV1beta1DiskSpecPtrOutput() GoogleCloudAiplatformV1beta1DiskSpecPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1DiskSpecPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1DiskSpecArgs) ToGoogleCloudAiplatformV1beta1DiskSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1DiskSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1DiskSpecOutput).ToGoogleCloudAiplatformV1beta1DiskSpecPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1DiskSpecPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1DiskSpecArgs, GoogleCloudAiplatformV1beta1DiskSpecPtr and GoogleCloudAiplatformV1beta1DiskSpecPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1DiskSpecPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1DiskSpecArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1DiskSpecPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1DiskSpecPtrOutput() GoogleCloudAiplatformV1beta1DiskSpecPtrOutput
	ToGoogleCloudAiplatformV1beta1DiskSpecPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1DiskSpecPtrOutput
}

type googleCloudAiplatformV1beta1DiskSpecPtrType GoogleCloudAiplatformV1beta1DiskSpecArgs

func GoogleCloudAiplatformV1beta1DiskSpecPtr(v *GoogleCloudAiplatformV1beta1DiskSpecArgs) GoogleCloudAiplatformV1beta1DiskSpecPtrInput {
	return (*googleCloudAiplatformV1beta1DiskSpecPtrType)(v)
}

func (*googleCloudAiplatformV1beta1DiskSpecPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1DiskSpec)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1DiskSpecPtrType) ToGoogleCloudAiplatformV1beta1DiskSpecPtrOutput() GoogleCloudAiplatformV1beta1DiskSpecPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1DiskSpecPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1DiskSpecPtrType) ToGoogleCloudAiplatformV1beta1DiskSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1DiskSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1DiskSpecPtrOutput)
}

// Represents the spec of disk options.
type GoogleCloudAiplatformV1beta1DiskSpecOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1DiskSpecOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1DiskSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1DiskSpecOutput) ToGoogleCloudAiplatformV1beta1DiskSpecOutput() GoogleCloudAiplatformV1beta1DiskSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1DiskSpecOutput) ToGoogleCloudAiplatformV1beta1DiskSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1DiskSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1DiskSpecOutput) ToGoogleCloudAiplatformV1beta1DiskSpecPtrOutput() GoogleCloudAiplatformV1beta1DiskSpecPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1DiskSpecPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1DiskSpecOutput) ToGoogleCloudAiplatformV1beta1DiskSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1DiskSpecPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1DiskSpec) *GoogleCloudAiplatformV1beta1DiskSpec {
		return &v
	}).(GoogleCloudAiplatformV1beta1DiskSpecPtrOutput)
}

// Size in GB of the boot disk (default is 100GB).
func (o GoogleCloudAiplatformV1beta1DiskSpecOutput) BootDiskSizeGb() pulumi.IntPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1DiskSpec) *int { return v.BootDiskSizeGb }).(pulumi.IntPtrOutput)
}

// Type of the boot disk (default is "pd-ssd"). Valid values: "pd-ssd" (Persistent Disk Solid State Drive) or "pd-standard" (Persistent Disk Hard Disk Drive).
func (o GoogleCloudAiplatformV1beta1DiskSpecOutput) BootDiskType() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1DiskSpec) *string { return v.BootDiskType }).(pulumi.StringPtrOutput)
}

type GoogleCloudAiplatformV1beta1DiskSpecPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1DiskSpecPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1DiskSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1DiskSpecPtrOutput) ToGoogleCloudAiplatformV1beta1DiskSpecPtrOutput() GoogleCloudAiplatformV1beta1DiskSpecPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1DiskSpecPtrOutput) ToGoogleCloudAiplatformV1beta1DiskSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1DiskSpecPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1DiskSpecPtrOutput) Elem() GoogleCloudAiplatformV1beta1DiskSpecOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1DiskSpec) GoogleCloudAiplatformV1beta1DiskSpec {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1DiskSpec
		return ret
	}).(GoogleCloudAiplatformV1beta1DiskSpecOutput)
}

// Size in GB of the boot disk (default is 100GB).
func (o GoogleCloudAiplatformV1beta1DiskSpecPtrOutput) BootDiskSizeGb() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1DiskSpec) *int {
		if v == nil {
			return nil
		}
		return v.BootDiskSizeGb
	}).(pulumi.IntPtrOutput)
}

// Type of the boot disk (default is "pd-ssd"). Valid values: "pd-ssd" (Persistent Disk Solid State Drive) or "pd-standard" (Persistent Disk Hard Disk Drive).
func (o GoogleCloudAiplatformV1beta1DiskSpecPtrOutput) BootDiskType() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1DiskSpec) *string {
		if v == nil {
			return nil
		}
		return v.BootDiskType
	}).(pulumi.StringPtrOutput)
}

// Represents the spec of disk options.
type GoogleCloudAiplatformV1beta1DiskSpecResponse struct {
	// Size in GB of the boot disk (default is 100GB).
	BootDiskSizeGb int `pulumi:"bootDiskSizeGb"`
	// Type of the boot disk (default is "pd-ssd"). Valid values: "pd-ssd" (Persistent Disk Solid State Drive) or "pd-standard" (Persistent Disk Hard Disk Drive).
	BootDiskType string `pulumi:"bootDiskType"`
}

// Represents the spec of disk options.
type GoogleCloudAiplatformV1beta1DiskSpecResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1DiskSpecResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1DiskSpecResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1DiskSpecResponseOutput) ToGoogleCloudAiplatformV1beta1DiskSpecResponseOutput() GoogleCloudAiplatformV1beta1DiskSpecResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1DiskSpecResponseOutput) ToGoogleCloudAiplatformV1beta1DiskSpecResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1DiskSpecResponseOutput {
	return o
}

// Size in GB of the boot disk (default is 100GB).
func (o GoogleCloudAiplatformV1beta1DiskSpecResponseOutput) BootDiskSizeGb() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1DiskSpecResponse) int { return v.BootDiskSizeGb }).(pulumi.IntOutput)
}

// Type of the boot disk (default is "pd-ssd"). Valid values: "pd-ssd" (Persistent Disk Solid State Drive) or "pd-standard" (Persistent Disk Hard Disk Drive).
func (o GoogleCloudAiplatformV1beta1DiskSpecResponseOutput) BootDiskType() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1DiskSpecResponse) string { return v.BootDiskType }).(pulumi.StringOutput)
}

// Represents a customer-managed encryption key spec that can be applied to a top-level resource.
type GoogleCloudAiplatformV1beta1EncryptionSpec struct {
	// The Cloud KMS resource identifier of the customer managed encryption key used to protect a resource. Has the form: `projects/my-project/locations/my-region/keyRings/my-kr/cryptoKeys/my-key`. The key needs to be in the same region as where the compute resource is created.
	KmsKeyName string `pulumi:"kmsKeyName"`
}

// GoogleCloudAiplatformV1beta1EncryptionSpecInput is an input type that accepts GoogleCloudAiplatformV1beta1EncryptionSpecArgs and GoogleCloudAiplatformV1beta1EncryptionSpecOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1EncryptionSpecInput` via:
//
//	GoogleCloudAiplatformV1beta1EncryptionSpecArgs{...}
type GoogleCloudAiplatformV1beta1EncryptionSpecInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1EncryptionSpecOutput() GoogleCloudAiplatformV1beta1EncryptionSpecOutput
	ToGoogleCloudAiplatformV1beta1EncryptionSpecOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1EncryptionSpecOutput
}

// Represents a customer-managed encryption key spec that can be applied to a top-level resource.
type GoogleCloudAiplatformV1beta1EncryptionSpecArgs struct {
	// The Cloud KMS resource identifier of the customer managed encryption key used to protect a resource. Has the form: `projects/my-project/locations/my-region/keyRings/my-kr/cryptoKeys/my-key`. The key needs to be in the same region as where the compute resource is created.
	KmsKeyName pulumi.StringInput `pulumi:"kmsKeyName"`
}

func (GoogleCloudAiplatformV1beta1EncryptionSpecArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1EncryptionSpec)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1EncryptionSpecArgs) ToGoogleCloudAiplatformV1beta1EncryptionSpecOutput() GoogleCloudAiplatformV1beta1EncryptionSpecOutput {
	return i.ToGoogleCloudAiplatformV1beta1EncryptionSpecOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1EncryptionSpecArgs) ToGoogleCloudAiplatformV1beta1EncryptionSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1EncryptionSpecOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1EncryptionSpecOutput)
}

func (i GoogleCloudAiplatformV1beta1EncryptionSpecArgs) ToGoogleCloudAiplatformV1beta1EncryptionSpecPtrOutput() GoogleCloudAiplatformV1beta1EncryptionSpecPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1EncryptionSpecPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1EncryptionSpecArgs) ToGoogleCloudAiplatformV1beta1EncryptionSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1EncryptionSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1EncryptionSpecOutput).ToGoogleCloudAiplatformV1beta1EncryptionSpecPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1EncryptionSpecPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1EncryptionSpecArgs, GoogleCloudAiplatformV1beta1EncryptionSpecPtr and GoogleCloudAiplatformV1beta1EncryptionSpecPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1EncryptionSpecPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1EncryptionSpecArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1EncryptionSpecPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1EncryptionSpecPtrOutput() GoogleCloudAiplatformV1beta1EncryptionSpecPtrOutput
	ToGoogleCloudAiplatformV1beta1EncryptionSpecPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1EncryptionSpecPtrOutput
}

type googleCloudAiplatformV1beta1EncryptionSpecPtrType GoogleCloudAiplatformV1beta1EncryptionSpecArgs

func GoogleCloudAiplatformV1beta1EncryptionSpecPtr(v *GoogleCloudAiplatformV1beta1EncryptionSpecArgs) GoogleCloudAiplatformV1beta1EncryptionSpecPtrInput {
	return (*googleCloudAiplatformV1beta1EncryptionSpecPtrType)(v)
}

func (*googleCloudAiplatformV1beta1EncryptionSpecPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1EncryptionSpec)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1EncryptionSpecPtrType) ToGoogleCloudAiplatformV1beta1EncryptionSpecPtrOutput() GoogleCloudAiplatformV1beta1EncryptionSpecPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1EncryptionSpecPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1EncryptionSpecPtrType) ToGoogleCloudAiplatformV1beta1EncryptionSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1EncryptionSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1EncryptionSpecPtrOutput)
}

// Represents a customer-managed encryption key spec that can be applied to a top-level resource.
type GoogleCloudAiplatformV1beta1EncryptionSpecOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1EncryptionSpecOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1EncryptionSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1EncryptionSpecOutput) ToGoogleCloudAiplatformV1beta1EncryptionSpecOutput() GoogleCloudAiplatformV1beta1EncryptionSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1EncryptionSpecOutput) ToGoogleCloudAiplatformV1beta1EncryptionSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1EncryptionSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1EncryptionSpecOutput) ToGoogleCloudAiplatformV1beta1EncryptionSpecPtrOutput() GoogleCloudAiplatformV1beta1EncryptionSpecPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1EncryptionSpecPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1EncryptionSpecOutput) ToGoogleCloudAiplatformV1beta1EncryptionSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1EncryptionSpecPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1EncryptionSpec) *GoogleCloudAiplatformV1beta1EncryptionSpec {
		return &v
	}).(GoogleCloudAiplatformV1beta1EncryptionSpecPtrOutput)
}

// The Cloud KMS resource identifier of the customer managed encryption key used to protect a resource. Has the form: `projects/my-project/locations/my-region/keyRings/my-kr/cryptoKeys/my-key`. The key needs to be in the same region as where the compute resource is created.
func (o GoogleCloudAiplatformV1beta1EncryptionSpecOutput) KmsKeyName() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1EncryptionSpec) string { return v.KmsKeyName }).(pulumi.StringOutput)
}

type GoogleCloudAiplatformV1beta1EncryptionSpecPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1EncryptionSpecPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1EncryptionSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1EncryptionSpecPtrOutput) ToGoogleCloudAiplatformV1beta1EncryptionSpecPtrOutput() GoogleCloudAiplatformV1beta1EncryptionSpecPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1EncryptionSpecPtrOutput) ToGoogleCloudAiplatformV1beta1EncryptionSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1EncryptionSpecPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1EncryptionSpecPtrOutput) Elem() GoogleCloudAiplatformV1beta1EncryptionSpecOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1EncryptionSpec) GoogleCloudAiplatformV1beta1EncryptionSpec {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1EncryptionSpec
		return ret
	}).(GoogleCloudAiplatformV1beta1EncryptionSpecOutput)
}

// The Cloud KMS resource identifier of the customer managed encryption key used to protect a resource. Has the form: `projects/my-project/locations/my-region/keyRings/my-kr/cryptoKeys/my-key`. The key needs to be in the same region as where the compute resource is created.
func (o GoogleCloudAiplatformV1beta1EncryptionSpecPtrOutput) KmsKeyName() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1EncryptionSpec) *string {
		if v == nil {
			return nil
		}
		return &v.KmsKeyName
	}).(pulumi.StringPtrOutput)
}

// Represents a customer-managed encryption key spec that can be applied to a top-level resource.
type GoogleCloudAiplatformV1beta1EncryptionSpecResponse struct {
	// The Cloud KMS resource identifier of the customer managed encryption key used to protect a resource. Has the form: `projects/my-project/locations/my-region/keyRings/my-kr/cryptoKeys/my-key`. The key needs to be in the same region as where the compute resource is created.
	KmsKeyName string `pulumi:"kmsKeyName"`
}

// Represents a customer-managed encryption key spec that can be applied to a top-level resource.
type GoogleCloudAiplatformV1beta1EncryptionSpecResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1EncryptionSpecResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1EncryptionSpecResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1EncryptionSpecResponseOutput) ToGoogleCloudAiplatformV1beta1EncryptionSpecResponseOutput() GoogleCloudAiplatformV1beta1EncryptionSpecResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1EncryptionSpecResponseOutput) ToGoogleCloudAiplatformV1beta1EncryptionSpecResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1EncryptionSpecResponseOutput {
	return o
}

// The Cloud KMS resource identifier of the customer managed encryption key used to protect a resource. Has the form: `projects/my-project/locations/my-region/keyRings/my-kr/cryptoKeys/my-key`. The key needs to be in the same region as where the compute resource is created.
func (o GoogleCloudAiplatformV1beta1EncryptionSpecResponseOutput) KmsKeyName() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1EncryptionSpecResponse) string { return v.KmsKeyName }).(pulumi.StringOutput)
}

// Represents an environment variable present in a Container or Python Module.
type GoogleCloudAiplatformV1beta1EnvVar struct {
	// Name of the environment variable. Must be a valid C identifier.
	Name string `pulumi:"name"`
	// Variables that reference a $(VAR_NAME) are expanded using the previous defined environment variables in the container and any service environment variables. If a variable cannot be resolved, the reference in the input string will be unchanged. The $(VAR_NAME) syntax can be escaped with a double $$, ie: $$(VAR_NAME). Escaped references will never be expanded, regardless of whether the variable exists or not.
	Value string `pulumi:"value"`
}

// GoogleCloudAiplatformV1beta1EnvVarInput is an input type that accepts GoogleCloudAiplatformV1beta1EnvVarArgs and GoogleCloudAiplatformV1beta1EnvVarOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1EnvVarInput` via:
//
//	GoogleCloudAiplatformV1beta1EnvVarArgs{...}
type GoogleCloudAiplatformV1beta1EnvVarInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1EnvVarOutput() GoogleCloudAiplatformV1beta1EnvVarOutput
	ToGoogleCloudAiplatformV1beta1EnvVarOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1EnvVarOutput
}

// Represents an environment variable present in a Container or Python Module.
type GoogleCloudAiplatformV1beta1EnvVarArgs struct {
	// Name of the environment variable. Must be a valid C identifier.
	Name pulumi.StringInput `pulumi:"name"`
	// Variables that reference a $(VAR_NAME) are expanded using the previous defined environment variables in the container and any service environment variables. If a variable cannot be resolved, the reference in the input string will be unchanged. The $(VAR_NAME) syntax can be escaped with a double $$, ie: $$(VAR_NAME). Escaped references will never be expanded, regardless of whether the variable exists or not.
	Value pulumi.StringInput `pulumi:"value"`
}

func (GoogleCloudAiplatformV1beta1EnvVarArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1EnvVar)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1EnvVarArgs) ToGoogleCloudAiplatformV1beta1EnvVarOutput() GoogleCloudAiplatformV1beta1EnvVarOutput {
	return i.ToGoogleCloudAiplatformV1beta1EnvVarOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1EnvVarArgs) ToGoogleCloudAiplatformV1beta1EnvVarOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1EnvVarOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1EnvVarOutput)
}

// GoogleCloudAiplatformV1beta1EnvVarArrayInput is an input type that accepts GoogleCloudAiplatformV1beta1EnvVarArray and GoogleCloudAiplatformV1beta1EnvVarArrayOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1EnvVarArrayInput` via:
//
//	GoogleCloudAiplatformV1beta1EnvVarArray{ GoogleCloudAiplatformV1beta1EnvVarArgs{...} }
type GoogleCloudAiplatformV1beta1EnvVarArrayInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1EnvVarArrayOutput() GoogleCloudAiplatformV1beta1EnvVarArrayOutput
	ToGoogleCloudAiplatformV1beta1EnvVarArrayOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1EnvVarArrayOutput
}

type GoogleCloudAiplatformV1beta1EnvVarArray []GoogleCloudAiplatformV1beta1EnvVarInput

func (GoogleCloudAiplatformV1beta1EnvVarArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1beta1EnvVar)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1EnvVarArray) ToGoogleCloudAiplatformV1beta1EnvVarArrayOutput() GoogleCloudAiplatformV1beta1EnvVarArrayOutput {
	return i.ToGoogleCloudAiplatformV1beta1EnvVarArrayOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1EnvVarArray) ToGoogleCloudAiplatformV1beta1EnvVarArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1EnvVarArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1EnvVarArrayOutput)
}

// Represents an environment variable present in a Container or Python Module.
type GoogleCloudAiplatformV1beta1EnvVarOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1EnvVarOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1EnvVar)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1EnvVarOutput) ToGoogleCloudAiplatformV1beta1EnvVarOutput() GoogleCloudAiplatformV1beta1EnvVarOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1EnvVarOutput) ToGoogleCloudAiplatformV1beta1EnvVarOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1EnvVarOutput {
	return o
}

// Name of the environment variable. Must be a valid C identifier.
func (o GoogleCloudAiplatformV1beta1EnvVarOutput) Name() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1EnvVar) string { return v.Name }).(pulumi.StringOutput)
}

// Variables that reference a $(VAR_NAME) are expanded using the previous defined environment variables in the container and any service environment variables. If a variable cannot be resolved, the reference in the input string will be unchanged. The $(VAR_NAME) syntax can be escaped with a double $$, ie: $$(VAR_NAME). Escaped references will never be expanded, regardless of whether the variable exists or not.
func (o GoogleCloudAiplatformV1beta1EnvVarOutput) Value() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1EnvVar) string { return v.Value }).(pulumi.StringOutput)
}

type GoogleCloudAiplatformV1beta1EnvVarArrayOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1EnvVarArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1beta1EnvVar)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1EnvVarArrayOutput) ToGoogleCloudAiplatformV1beta1EnvVarArrayOutput() GoogleCloudAiplatformV1beta1EnvVarArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1EnvVarArrayOutput) ToGoogleCloudAiplatformV1beta1EnvVarArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1EnvVarArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1EnvVarArrayOutput) Index(i pulumi.IntInput) GoogleCloudAiplatformV1beta1EnvVarOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GoogleCloudAiplatformV1beta1EnvVar {
		return vs[0].([]GoogleCloudAiplatformV1beta1EnvVar)[vs[1].(int)]
	}).(GoogleCloudAiplatformV1beta1EnvVarOutput)
}

// Represents an environment variable present in a Container or Python Module.
type GoogleCloudAiplatformV1beta1EnvVarResponse struct {
	// Name of the environment variable. Must be a valid C identifier.
	Name string `pulumi:"name"`
	// Variables that reference a $(VAR_NAME) are expanded using the previous defined environment variables in the container and any service environment variables. If a variable cannot be resolved, the reference in the input string will be unchanged. The $(VAR_NAME) syntax can be escaped with a double $$, ie: $$(VAR_NAME). Escaped references will never be expanded, regardless of whether the variable exists or not.
	Value string `pulumi:"value"`
}

// Represents an environment variable present in a Container or Python Module.
type GoogleCloudAiplatformV1beta1EnvVarResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1EnvVarResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1EnvVarResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1EnvVarResponseOutput) ToGoogleCloudAiplatformV1beta1EnvVarResponseOutput() GoogleCloudAiplatformV1beta1EnvVarResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1EnvVarResponseOutput) ToGoogleCloudAiplatformV1beta1EnvVarResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1EnvVarResponseOutput {
	return o
}

// Name of the environment variable. Must be a valid C identifier.
func (o GoogleCloudAiplatformV1beta1EnvVarResponseOutput) Name() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1EnvVarResponse) string { return v.Name }).(pulumi.StringOutput)
}

// Variables that reference a $(VAR_NAME) are expanded using the previous defined environment variables in the container and any service environment variables. If a variable cannot be resolved, the reference in the input string will be unchanged. The $(VAR_NAME) syntax can be escaped with a double $$, ie: $$(VAR_NAME). Escaped references will never be expanded, regardless of whether the variable exists or not.
func (o GoogleCloudAiplatformV1beta1EnvVarResponseOutput) Value() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1EnvVarResponse) string { return v.Value }).(pulumi.StringOutput)
}

type GoogleCloudAiplatformV1beta1EnvVarResponseArrayOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1EnvVarResponseArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1beta1EnvVarResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1EnvVarResponseArrayOutput) ToGoogleCloudAiplatformV1beta1EnvVarResponseArrayOutput() GoogleCloudAiplatformV1beta1EnvVarResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1EnvVarResponseArrayOutput) ToGoogleCloudAiplatformV1beta1EnvVarResponseArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1EnvVarResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1EnvVarResponseArrayOutput) Index(i pulumi.IntInput) GoogleCloudAiplatformV1beta1EnvVarResponseOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GoogleCloudAiplatformV1beta1EnvVarResponse {
		return vs[0].([]GoogleCloudAiplatformV1beta1EnvVarResponse)[vs[1].(int)]
	}).(GoogleCloudAiplatformV1beta1EnvVarResponseOutput)
}

// Example-based explainability that returns the nearest neighbors from the provided dataset.
type GoogleCloudAiplatformV1beta1Examples struct {
	// The Cloud Storage input instances.
	ExampleGcsSource *GoogleCloudAiplatformV1beta1ExamplesExampleGcsSource `pulumi:"exampleGcsSource"`
	// The Cloud Storage locations that contain the instances to be indexed for approximate nearest neighbor search.
	GcsSource *GoogleCloudAiplatformV1beta1GcsSource `pulumi:"gcsSource"`
	// The full configuration for the generated index, the semantics are the same as metadata and should match [NearestNeighborSearchConfig](https://cloud.google.com/vertex-ai/docs/explainable-ai/configuring-explanations-example-based#nearest-neighbor-search-config).
	NearestNeighborSearchConfig interface{} `pulumi:"nearestNeighborSearchConfig"`
	// The number of neighbors to return when querying for examples.
	NeighborCount *int `pulumi:"neighborCount"`
	// Simplified preset configuration, which automatically sets configuration values based on the desired query speed-precision trade-off and modality.
	Presets *GoogleCloudAiplatformV1beta1Presets `pulumi:"presets"`
}

// GoogleCloudAiplatformV1beta1ExamplesInput is an input type that accepts GoogleCloudAiplatformV1beta1ExamplesArgs and GoogleCloudAiplatformV1beta1ExamplesOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1ExamplesInput` via:
//
//	GoogleCloudAiplatformV1beta1ExamplesArgs{...}
type GoogleCloudAiplatformV1beta1ExamplesInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1ExamplesOutput() GoogleCloudAiplatformV1beta1ExamplesOutput
	ToGoogleCloudAiplatformV1beta1ExamplesOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1ExamplesOutput
}

// Example-based explainability that returns the nearest neighbors from the provided dataset.
type GoogleCloudAiplatformV1beta1ExamplesArgs struct {
	// The Cloud Storage input instances.
	ExampleGcsSource GoogleCloudAiplatformV1beta1ExamplesExampleGcsSourcePtrInput `pulumi:"exampleGcsSource"`
	// The Cloud Storage locations that contain the instances to be indexed for approximate nearest neighbor search.
	GcsSource GoogleCloudAiplatformV1beta1GcsSourcePtrInput `pulumi:"gcsSource"`
	// The full configuration for the generated index, the semantics are the same as metadata and should match [NearestNeighborSearchConfig](https://cloud.google.com/vertex-ai/docs/explainable-ai/configuring-explanations-example-based#nearest-neighbor-search-config).
	NearestNeighborSearchConfig pulumi.Input `pulumi:"nearestNeighborSearchConfig"`
	// The number of neighbors to return when querying for examples.
	NeighborCount pulumi.IntPtrInput `pulumi:"neighborCount"`
	// Simplified preset configuration, which automatically sets configuration values based on the desired query speed-precision trade-off and modality.
	Presets GoogleCloudAiplatformV1beta1PresetsPtrInput `pulumi:"presets"`
}

func (GoogleCloudAiplatformV1beta1ExamplesArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1Examples)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1ExamplesArgs) ToGoogleCloudAiplatformV1beta1ExamplesOutput() GoogleCloudAiplatformV1beta1ExamplesOutput {
	return i.ToGoogleCloudAiplatformV1beta1ExamplesOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1ExamplesArgs) ToGoogleCloudAiplatformV1beta1ExamplesOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ExamplesOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ExamplesOutput)
}

func (i GoogleCloudAiplatformV1beta1ExamplesArgs) ToGoogleCloudAiplatformV1beta1ExamplesPtrOutput() GoogleCloudAiplatformV1beta1ExamplesPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1ExamplesPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1ExamplesArgs) ToGoogleCloudAiplatformV1beta1ExamplesPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ExamplesPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ExamplesOutput).ToGoogleCloudAiplatformV1beta1ExamplesPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1ExamplesPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1ExamplesArgs, GoogleCloudAiplatformV1beta1ExamplesPtr and GoogleCloudAiplatformV1beta1ExamplesPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1ExamplesPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1ExamplesArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1ExamplesPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1ExamplesPtrOutput() GoogleCloudAiplatformV1beta1ExamplesPtrOutput
	ToGoogleCloudAiplatformV1beta1ExamplesPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1ExamplesPtrOutput
}

type googleCloudAiplatformV1beta1ExamplesPtrType GoogleCloudAiplatformV1beta1ExamplesArgs

func GoogleCloudAiplatformV1beta1ExamplesPtr(v *GoogleCloudAiplatformV1beta1ExamplesArgs) GoogleCloudAiplatformV1beta1ExamplesPtrInput {
	return (*googleCloudAiplatformV1beta1ExamplesPtrType)(v)
}

func (*googleCloudAiplatformV1beta1ExamplesPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1Examples)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1ExamplesPtrType) ToGoogleCloudAiplatformV1beta1ExamplesPtrOutput() GoogleCloudAiplatformV1beta1ExamplesPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1ExamplesPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1ExamplesPtrType) ToGoogleCloudAiplatformV1beta1ExamplesPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ExamplesPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ExamplesPtrOutput)
}

// Example-based explainability that returns the nearest neighbors from the provided dataset.
type GoogleCloudAiplatformV1beta1ExamplesOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ExamplesOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1Examples)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ExamplesOutput) ToGoogleCloudAiplatformV1beta1ExamplesOutput() GoogleCloudAiplatformV1beta1ExamplesOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ExamplesOutput) ToGoogleCloudAiplatformV1beta1ExamplesOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ExamplesOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ExamplesOutput) ToGoogleCloudAiplatformV1beta1ExamplesPtrOutput() GoogleCloudAiplatformV1beta1ExamplesPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1ExamplesPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1ExamplesOutput) ToGoogleCloudAiplatformV1beta1ExamplesPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ExamplesPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1Examples) *GoogleCloudAiplatformV1beta1Examples {
		return &v
	}).(GoogleCloudAiplatformV1beta1ExamplesPtrOutput)
}

// The Cloud Storage input instances.
func (o GoogleCloudAiplatformV1beta1ExamplesOutput) ExampleGcsSource() GoogleCloudAiplatformV1beta1ExamplesExampleGcsSourcePtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1Examples) *GoogleCloudAiplatformV1beta1ExamplesExampleGcsSource {
		return v.ExampleGcsSource
	}).(GoogleCloudAiplatformV1beta1ExamplesExampleGcsSourcePtrOutput)
}

// The Cloud Storage locations that contain the instances to be indexed for approximate nearest neighbor search.
func (o GoogleCloudAiplatformV1beta1ExamplesOutput) GcsSource() GoogleCloudAiplatformV1beta1GcsSourcePtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1Examples) *GoogleCloudAiplatformV1beta1GcsSource {
		return v.GcsSource
	}).(GoogleCloudAiplatformV1beta1GcsSourcePtrOutput)
}

// The full configuration for the generated index, the semantics are the same as metadata and should match [NearestNeighborSearchConfig](https://cloud.google.com/vertex-ai/docs/explainable-ai/configuring-explanations-example-based#nearest-neighbor-search-config).
func (o GoogleCloudAiplatformV1beta1ExamplesOutput) NearestNeighborSearchConfig() pulumi.AnyOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1Examples) interface{} { return v.NearestNeighborSearchConfig }).(pulumi.AnyOutput)
}

// The number of neighbors to return when querying for examples.
func (o GoogleCloudAiplatformV1beta1ExamplesOutput) NeighborCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1Examples) *int { return v.NeighborCount }).(pulumi.IntPtrOutput)
}

// Simplified preset configuration, which automatically sets configuration values based on the desired query speed-precision trade-off and modality.
func (o GoogleCloudAiplatformV1beta1ExamplesOutput) Presets() GoogleCloudAiplatformV1beta1PresetsPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1Examples) *GoogleCloudAiplatformV1beta1Presets { return v.Presets }).(GoogleCloudAiplatformV1beta1PresetsPtrOutput)
}

type GoogleCloudAiplatformV1beta1ExamplesPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ExamplesPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1Examples)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ExamplesPtrOutput) ToGoogleCloudAiplatformV1beta1ExamplesPtrOutput() GoogleCloudAiplatformV1beta1ExamplesPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ExamplesPtrOutput) ToGoogleCloudAiplatformV1beta1ExamplesPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ExamplesPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ExamplesPtrOutput) Elem() GoogleCloudAiplatformV1beta1ExamplesOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1Examples) GoogleCloudAiplatformV1beta1Examples {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1Examples
		return ret
	}).(GoogleCloudAiplatformV1beta1ExamplesOutput)
}

// The Cloud Storage input instances.
func (o GoogleCloudAiplatformV1beta1ExamplesPtrOutput) ExampleGcsSource() GoogleCloudAiplatformV1beta1ExamplesExampleGcsSourcePtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1Examples) *GoogleCloudAiplatformV1beta1ExamplesExampleGcsSource {
		if v == nil {
			return nil
		}
		return v.ExampleGcsSource
	}).(GoogleCloudAiplatformV1beta1ExamplesExampleGcsSourcePtrOutput)
}

// The Cloud Storage locations that contain the instances to be indexed for approximate nearest neighbor search.
func (o GoogleCloudAiplatformV1beta1ExamplesPtrOutput) GcsSource() GoogleCloudAiplatformV1beta1GcsSourcePtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1Examples) *GoogleCloudAiplatformV1beta1GcsSource {
		if v == nil {
			return nil
		}
		return v.GcsSource
	}).(GoogleCloudAiplatformV1beta1GcsSourcePtrOutput)
}

// The full configuration for the generated index, the semantics are the same as metadata and should match [NearestNeighborSearchConfig](https://cloud.google.com/vertex-ai/docs/explainable-ai/configuring-explanations-example-based#nearest-neighbor-search-config).
func (o GoogleCloudAiplatformV1beta1ExamplesPtrOutput) NearestNeighborSearchConfig() pulumi.AnyOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1Examples) interface{} {
		if v == nil {
			return nil
		}
		return v.NearestNeighborSearchConfig
	}).(pulumi.AnyOutput)
}

// The number of neighbors to return when querying for examples.
func (o GoogleCloudAiplatformV1beta1ExamplesPtrOutput) NeighborCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1Examples) *int {
		if v == nil {
			return nil
		}
		return v.NeighborCount
	}).(pulumi.IntPtrOutput)
}

// Simplified preset configuration, which automatically sets configuration values based on the desired query speed-precision trade-off and modality.
func (o GoogleCloudAiplatformV1beta1ExamplesPtrOutput) Presets() GoogleCloudAiplatformV1beta1PresetsPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1Examples) *GoogleCloudAiplatformV1beta1Presets {
		if v == nil {
			return nil
		}
		return v.Presets
	}).(GoogleCloudAiplatformV1beta1PresetsPtrOutput)
}

// The Cloud Storage input instances.
type GoogleCloudAiplatformV1beta1ExamplesExampleGcsSource struct {
	// The format in which instances are given, if not specified, assume it's JSONL format. Currently only JSONL format is supported.
	DataFormat *GoogleCloudAiplatformV1beta1ExamplesExampleGcsSourceDataFormat `pulumi:"dataFormat"`
	// The Cloud Storage location for the input instances.
	GcsSource *GoogleCloudAiplatformV1beta1GcsSource `pulumi:"gcsSource"`
}

// GoogleCloudAiplatformV1beta1ExamplesExampleGcsSourceInput is an input type that accepts GoogleCloudAiplatformV1beta1ExamplesExampleGcsSourceArgs and GoogleCloudAiplatformV1beta1ExamplesExampleGcsSourceOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1ExamplesExampleGcsSourceInput` via:
//
//	GoogleCloudAiplatformV1beta1ExamplesExampleGcsSourceArgs{...}
type GoogleCloudAiplatformV1beta1ExamplesExampleGcsSourceInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1ExamplesExampleGcsSourceOutput() GoogleCloudAiplatformV1beta1ExamplesExampleGcsSourceOutput
	ToGoogleCloudAiplatformV1beta1ExamplesExampleGcsSourceOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1ExamplesExampleGcsSourceOutput
}

// The Cloud Storage input instances.
type GoogleCloudAiplatformV1beta1ExamplesExampleGcsSourceArgs struct {
	// The format in which instances are given, if not specified, assume it's JSONL format. Currently only JSONL format is supported.
	DataFormat GoogleCloudAiplatformV1beta1ExamplesExampleGcsSourceDataFormatPtrInput `pulumi:"dataFormat"`
	// The Cloud Storage location for the input instances.
	GcsSource GoogleCloudAiplatformV1beta1GcsSourcePtrInput `pulumi:"gcsSource"`
}

func (GoogleCloudAiplatformV1beta1ExamplesExampleGcsSourceArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ExamplesExampleGcsSource)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1ExamplesExampleGcsSourceArgs) ToGoogleCloudAiplatformV1beta1ExamplesExampleGcsSourceOutput() GoogleCloudAiplatformV1beta1ExamplesExampleGcsSourceOutput {
	return i.ToGoogleCloudAiplatformV1beta1ExamplesExampleGcsSourceOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1ExamplesExampleGcsSourceArgs) ToGoogleCloudAiplatformV1beta1ExamplesExampleGcsSourceOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ExamplesExampleGcsSourceOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ExamplesExampleGcsSourceOutput)
}

func (i GoogleCloudAiplatformV1beta1ExamplesExampleGcsSourceArgs) ToGoogleCloudAiplatformV1beta1ExamplesExampleGcsSourcePtrOutput() GoogleCloudAiplatformV1beta1ExamplesExampleGcsSourcePtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1ExamplesExampleGcsSourcePtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1ExamplesExampleGcsSourceArgs) ToGoogleCloudAiplatformV1beta1ExamplesExampleGcsSourcePtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ExamplesExampleGcsSourcePtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ExamplesExampleGcsSourceOutput).ToGoogleCloudAiplatformV1beta1ExamplesExampleGcsSourcePtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1ExamplesExampleGcsSourcePtrInput is an input type that accepts GoogleCloudAiplatformV1beta1ExamplesExampleGcsSourceArgs, GoogleCloudAiplatformV1beta1ExamplesExampleGcsSourcePtr and GoogleCloudAiplatformV1beta1ExamplesExampleGcsSourcePtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1ExamplesExampleGcsSourcePtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1ExamplesExampleGcsSourceArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1ExamplesExampleGcsSourcePtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1ExamplesExampleGcsSourcePtrOutput() GoogleCloudAiplatformV1beta1ExamplesExampleGcsSourcePtrOutput
	ToGoogleCloudAiplatformV1beta1ExamplesExampleGcsSourcePtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1ExamplesExampleGcsSourcePtrOutput
}

type googleCloudAiplatformV1beta1ExamplesExampleGcsSourcePtrType GoogleCloudAiplatformV1beta1ExamplesExampleGcsSourceArgs

func GoogleCloudAiplatformV1beta1ExamplesExampleGcsSourcePtr(v *GoogleCloudAiplatformV1beta1ExamplesExampleGcsSourceArgs) GoogleCloudAiplatformV1beta1ExamplesExampleGcsSourcePtrInput {
	return (*googleCloudAiplatformV1beta1ExamplesExampleGcsSourcePtrType)(v)
}

func (*googleCloudAiplatformV1beta1ExamplesExampleGcsSourcePtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1ExamplesExampleGcsSource)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1ExamplesExampleGcsSourcePtrType) ToGoogleCloudAiplatformV1beta1ExamplesExampleGcsSourcePtrOutput() GoogleCloudAiplatformV1beta1ExamplesExampleGcsSourcePtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1ExamplesExampleGcsSourcePtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1ExamplesExampleGcsSourcePtrType) ToGoogleCloudAiplatformV1beta1ExamplesExampleGcsSourcePtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ExamplesExampleGcsSourcePtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ExamplesExampleGcsSourcePtrOutput)
}

// The Cloud Storage input instances.
type GoogleCloudAiplatformV1beta1ExamplesExampleGcsSourceOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ExamplesExampleGcsSourceOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ExamplesExampleGcsSource)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ExamplesExampleGcsSourceOutput) ToGoogleCloudAiplatformV1beta1ExamplesExampleGcsSourceOutput() GoogleCloudAiplatformV1beta1ExamplesExampleGcsSourceOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ExamplesExampleGcsSourceOutput) ToGoogleCloudAiplatformV1beta1ExamplesExampleGcsSourceOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ExamplesExampleGcsSourceOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ExamplesExampleGcsSourceOutput) ToGoogleCloudAiplatformV1beta1ExamplesExampleGcsSourcePtrOutput() GoogleCloudAiplatformV1beta1ExamplesExampleGcsSourcePtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1ExamplesExampleGcsSourcePtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1ExamplesExampleGcsSourceOutput) ToGoogleCloudAiplatformV1beta1ExamplesExampleGcsSourcePtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ExamplesExampleGcsSourcePtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1ExamplesExampleGcsSource) *GoogleCloudAiplatformV1beta1ExamplesExampleGcsSource {
		return &v
	}).(GoogleCloudAiplatformV1beta1ExamplesExampleGcsSourcePtrOutput)
}

// The format in which instances are given, if not specified, assume it's JSONL format. Currently only JSONL format is supported.
func (o GoogleCloudAiplatformV1beta1ExamplesExampleGcsSourceOutput) DataFormat() GoogleCloudAiplatformV1beta1ExamplesExampleGcsSourceDataFormatPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ExamplesExampleGcsSource) *GoogleCloudAiplatformV1beta1ExamplesExampleGcsSourceDataFormat {
		return v.DataFormat
	}).(GoogleCloudAiplatformV1beta1ExamplesExampleGcsSourceDataFormatPtrOutput)
}

// The Cloud Storage location for the input instances.
func (o GoogleCloudAiplatformV1beta1ExamplesExampleGcsSourceOutput) GcsSource() GoogleCloudAiplatformV1beta1GcsSourcePtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ExamplesExampleGcsSource) *GoogleCloudAiplatformV1beta1GcsSource {
		return v.GcsSource
	}).(GoogleCloudAiplatformV1beta1GcsSourcePtrOutput)
}

type GoogleCloudAiplatformV1beta1ExamplesExampleGcsSourcePtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ExamplesExampleGcsSourcePtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1ExamplesExampleGcsSource)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ExamplesExampleGcsSourcePtrOutput) ToGoogleCloudAiplatformV1beta1ExamplesExampleGcsSourcePtrOutput() GoogleCloudAiplatformV1beta1ExamplesExampleGcsSourcePtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ExamplesExampleGcsSourcePtrOutput) ToGoogleCloudAiplatformV1beta1ExamplesExampleGcsSourcePtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ExamplesExampleGcsSourcePtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ExamplesExampleGcsSourcePtrOutput) Elem() GoogleCloudAiplatformV1beta1ExamplesExampleGcsSourceOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ExamplesExampleGcsSource) GoogleCloudAiplatformV1beta1ExamplesExampleGcsSource {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1ExamplesExampleGcsSource
		return ret
	}).(GoogleCloudAiplatformV1beta1ExamplesExampleGcsSourceOutput)
}

// The format in which instances are given, if not specified, assume it's JSONL format. Currently only JSONL format is supported.
func (o GoogleCloudAiplatformV1beta1ExamplesExampleGcsSourcePtrOutput) DataFormat() GoogleCloudAiplatformV1beta1ExamplesExampleGcsSourceDataFormatPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ExamplesExampleGcsSource) *GoogleCloudAiplatformV1beta1ExamplesExampleGcsSourceDataFormat {
		if v == nil {
			return nil
		}
		return v.DataFormat
	}).(GoogleCloudAiplatformV1beta1ExamplesExampleGcsSourceDataFormatPtrOutput)
}

// The Cloud Storage location for the input instances.
func (o GoogleCloudAiplatformV1beta1ExamplesExampleGcsSourcePtrOutput) GcsSource() GoogleCloudAiplatformV1beta1GcsSourcePtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ExamplesExampleGcsSource) *GoogleCloudAiplatformV1beta1GcsSource {
		if v == nil {
			return nil
		}
		return v.GcsSource
	}).(GoogleCloudAiplatformV1beta1GcsSourcePtrOutput)
}

// The Cloud Storage input instances.
type GoogleCloudAiplatformV1beta1ExamplesExampleGcsSourceResponse struct {
	// The format in which instances are given, if not specified, assume it's JSONL format. Currently only JSONL format is supported.
	DataFormat string `pulumi:"dataFormat"`
	// The Cloud Storage location for the input instances.
	GcsSource GoogleCloudAiplatformV1beta1GcsSourceResponse `pulumi:"gcsSource"`
}

// The Cloud Storage input instances.
type GoogleCloudAiplatformV1beta1ExamplesExampleGcsSourceResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ExamplesExampleGcsSourceResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ExamplesExampleGcsSourceResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ExamplesExampleGcsSourceResponseOutput) ToGoogleCloudAiplatformV1beta1ExamplesExampleGcsSourceResponseOutput() GoogleCloudAiplatformV1beta1ExamplesExampleGcsSourceResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ExamplesExampleGcsSourceResponseOutput) ToGoogleCloudAiplatformV1beta1ExamplesExampleGcsSourceResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ExamplesExampleGcsSourceResponseOutput {
	return o
}

// The format in which instances are given, if not specified, assume it's JSONL format. Currently only JSONL format is supported.
func (o GoogleCloudAiplatformV1beta1ExamplesExampleGcsSourceResponseOutput) DataFormat() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ExamplesExampleGcsSourceResponse) string { return v.DataFormat }).(pulumi.StringOutput)
}

// The Cloud Storage location for the input instances.
func (o GoogleCloudAiplatformV1beta1ExamplesExampleGcsSourceResponseOutput) GcsSource() GoogleCloudAiplatformV1beta1GcsSourceResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ExamplesExampleGcsSourceResponse) GoogleCloudAiplatformV1beta1GcsSourceResponse {
		return v.GcsSource
	}).(GoogleCloudAiplatformV1beta1GcsSourceResponseOutput)
}

// Example-based explainability that returns the nearest neighbors from the provided dataset.
type GoogleCloudAiplatformV1beta1ExamplesResponse struct {
	// The Cloud Storage input instances.
	ExampleGcsSource GoogleCloudAiplatformV1beta1ExamplesExampleGcsSourceResponse `pulumi:"exampleGcsSource"`
	// The Cloud Storage locations that contain the instances to be indexed for approximate nearest neighbor search.
	GcsSource GoogleCloudAiplatformV1beta1GcsSourceResponse `pulumi:"gcsSource"`
	// The full configuration for the generated index, the semantics are the same as metadata and should match [NearestNeighborSearchConfig](https://cloud.google.com/vertex-ai/docs/explainable-ai/configuring-explanations-example-based#nearest-neighbor-search-config).
	NearestNeighborSearchConfig interface{} `pulumi:"nearestNeighborSearchConfig"`
	// The number of neighbors to return when querying for examples.
	NeighborCount int `pulumi:"neighborCount"`
	// Simplified preset configuration, which automatically sets configuration values based on the desired query speed-precision trade-off and modality.
	Presets GoogleCloudAiplatformV1beta1PresetsResponse `pulumi:"presets"`
}

// Example-based explainability that returns the nearest neighbors from the provided dataset.
type GoogleCloudAiplatformV1beta1ExamplesResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ExamplesResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ExamplesResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ExamplesResponseOutput) ToGoogleCloudAiplatformV1beta1ExamplesResponseOutput() GoogleCloudAiplatformV1beta1ExamplesResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ExamplesResponseOutput) ToGoogleCloudAiplatformV1beta1ExamplesResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ExamplesResponseOutput {
	return o
}

// The Cloud Storage input instances.
func (o GoogleCloudAiplatformV1beta1ExamplesResponseOutput) ExampleGcsSource() GoogleCloudAiplatformV1beta1ExamplesExampleGcsSourceResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ExamplesResponse) GoogleCloudAiplatformV1beta1ExamplesExampleGcsSourceResponse {
		return v.ExampleGcsSource
	}).(GoogleCloudAiplatformV1beta1ExamplesExampleGcsSourceResponseOutput)
}

// The Cloud Storage locations that contain the instances to be indexed for approximate nearest neighbor search.
func (o GoogleCloudAiplatformV1beta1ExamplesResponseOutput) GcsSource() GoogleCloudAiplatformV1beta1GcsSourceResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ExamplesResponse) GoogleCloudAiplatformV1beta1GcsSourceResponse {
		return v.GcsSource
	}).(GoogleCloudAiplatformV1beta1GcsSourceResponseOutput)
}

// The full configuration for the generated index, the semantics are the same as metadata and should match [NearestNeighborSearchConfig](https://cloud.google.com/vertex-ai/docs/explainable-ai/configuring-explanations-example-based#nearest-neighbor-search-config).
func (o GoogleCloudAiplatformV1beta1ExamplesResponseOutput) NearestNeighborSearchConfig() pulumi.AnyOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ExamplesResponse) interface{} { return v.NearestNeighborSearchConfig }).(pulumi.AnyOutput)
}

// The number of neighbors to return when querying for examples.
func (o GoogleCloudAiplatformV1beta1ExamplesResponseOutput) NeighborCount() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ExamplesResponse) int { return v.NeighborCount }).(pulumi.IntOutput)
}

// Simplified preset configuration, which automatically sets configuration values based on the desired query speed-precision trade-off and modality.
func (o GoogleCloudAiplatformV1beta1ExamplesResponseOutput) Presets() GoogleCloudAiplatformV1beta1PresetsResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ExamplesResponse) GoogleCloudAiplatformV1beta1PresetsResponse {
		return v.Presets
	}).(GoogleCloudAiplatformV1beta1PresetsResponseOutput)
}

// Instance of a general execution.
type GoogleCloudAiplatformV1beta1ExecutionResponse struct {
	// Timestamp when this Execution was created.
	CreateTime string `pulumi:"createTime"`
	// Description of the Execution
	Description string `pulumi:"description"`
	// User provided display name of the Execution. May be up to 128 Unicode characters.
	DisplayName string `pulumi:"displayName"`
	// An eTag used to perform consistent read-modify-write updates. If not set, a blind "overwrite" update happens.
	Etag string `pulumi:"etag"`
	// The labels with user-defined metadata to organize your Executions. Label keys and values can be no longer than 64 characters (Unicode codepoints), can only contain lowercase letters, numeric characters, underscores and dashes. International characters are allowed. No more than 64 user labels can be associated with one Execution (System labels are excluded).
	Labels map[string]string `pulumi:"labels"`
	// Properties of the Execution. Top level metadata keys' heading and trailing spaces will be trimmed. The size of this field should not exceed 200KB.
	Metadata map[string]interface{} `pulumi:"metadata"`
	// The resource name of the Execution.
	Name string `pulumi:"name"`
	// The title of the schema describing the metadata. Schema title and version is expected to be registered in earlier Create Schema calls. And both are used together as unique identifiers to identify schemas within the local metadata store.
	SchemaTitle string `pulumi:"schemaTitle"`
	// The version of the schema in `schema_title` to use. Schema title and version is expected to be registered in earlier Create Schema calls. And both are used together as unique identifiers to identify schemas within the local metadata store.
	SchemaVersion string `pulumi:"schemaVersion"`
	// The state of this Execution. This is a property of the Execution, and does not imply or capture any ongoing process. This property is managed by clients (such as Vertex AI Pipelines) and the system does not prescribe or check the validity of state transitions.
	State string `pulumi:"state"`
	// Timestamp when this Execution was last updated.
	UpdateTime string `pulumi:"updateTime"`
}

// Instance of a general execution.
type GoogleCloudAiplatformV1beta1ExecutionResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ExecutionResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ExecutionResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ExecutionResponseOutput) ToGoogleCloudAiplatformV1beta1ExecutionResponseOutput() GoogleCloudAiplatformV1beta1ExecutionResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ExecutionResponseOutput) ToGoogleCloudAiplatformV1beta1ExecutionResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ExecutionResponseOutput {
	return o
}

// Timestamp when this Execution was created.
func (o GoogleCloudAiplatformV1beta1ExecutionResponseOutput) CreateTime() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ExecutionResponse) string { return v.CreateTime }).(pulumi.StringOutput)
}

// Description of the Execution
func (o GoogleCloudAiplatformV1beta1ExecutionResponseOutput) Description() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ExecutionResponse) string { return v.Description }).(pulumi.StringOutput)
}

// User provided display name of the Execution. May be up to 128 Unicode characters.
func (o GoogleCloudAiplatformV1beta1ExecutionResponseOutput) DisplayName() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ExecutionResponse) string { return v.DisplayName }).(pulumi.StringOutput)
}

// An eTag used to perform consistent read-modify-write updates. If not set, a blind "overwrite" update happens.
func (o GoogleCloudAiplatformV1beta1ExecutionResponseOutput) Etag() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ExecutionResponse) string { return v.Etag }).(pulumi.StringOutput)
}

// The labels with user-defined metadata to organize your Executions. Label keys and values can be no longer than 64 characters (Unicode codepoints), can only contain lowercase letters, numeric characters, underscores and dashes. International characters are allowed. No more than 64 user labels can be associated with one Execution (System labels are excluded).
func (o GoogleCloudAiplatformV1beta1ExecutionResponseOutput) Labels() pulumi.StringMapOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ExecutionResponse) map[string]string { return v.Labels }).(pulumi.StringMapOutput)
}

// Properties of the Execution. Top level metadata keys' heading and trailing spaces will be trimmed. The size of this field should not exceed 200KB.
func (o GoogleCloudAiplatformV1beta1ExecutionResponseOutput) Metadata() pulumi.MapOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ExecutionResponse) map[string]interface{} { return v.Metadata }).(pulumi.MapOutput)
}

// The resource name of the Execution.
func (o GoogleCloudAiplatformV1beta1ExecutionResponseOutput) Name() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ExecutionResponse) string { return v.Name }).(pulumi.StringOutput)
}

// The title of the schema describing the metadata. Schema title and version is expected to be registered in earlier Create Schema calls. And both are used together as unique identifiers to identify schemas within the local metadata store.
func (o GoogleCloudAiplatformV1beta1ExecutionResponseOutput) SchemaTitle() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ExecutionResponse) string { return v.SchemaTitle }).(pulumi.StringOutput)
}

// The version of the schema in `schema_title` to use. Schema title and version is expected to be registered in earlier Create Schema calls. And both are used together as unique identifiers to identify schemas within the local metadata store.
func (o GoogleCloudAiplatformV1beta1ExecutionResponseOutput) SchemaVersion() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ExecutionResponse) string { return v.SchemaVersion }).(pulumi.StringOutput)
}

// The state of this Execution. This is a property of the Execution, and does not imply or capture any ongoing process. This property is managed by clients (such as Vertex AI Pipelines) and the system does not prescribe or check the validity of state transitions.
func (o GoogleCloudAiplatformV1beta1ExecutionResponseOutput) State() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ExecutionResponse) string { return v.State }).(pulumi.StringOutput)
}

// Timestamp when this Execution was last updated.
func (o GoogleCloudAiplatformV1beta1ExecutionResponseOutput) UpdateTime() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ExecutionResponse) string { return v.UpdateTime }).(pulumi.StringOutput)
}

// Metadata describing the Model's input and output for explanation.
type GoogleCloudAiplatformV1beta1ExplanationMetadata struct {
	// Points to a YAML file stored on Google Cloud Storage describing the format of the feature attributions. The schema is defined as an OpenAPI 3.0.2 [Schema Object](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject). AutoML tabular Models always have this field populated by Vertex AI. Note: The URI given on output may be different, including the URI scheme, than the one given on input. The output URI will point to a location where the user only has a read access.
	FeatureAttributionsSchemaUri *string `pulumi:"featureAttributionsSchemaUri"`
	// Map from feature names to feature input metadata. Keys are the name of the features. Values are the specification of the feature. An empty InputMetadata is valid. It describes a text feature which has the name specified as the key in ExplanationMetadata.inputs. The baseline of the empty feature is chosen by Vertex AI. For Vertex AI-provided Tensorflow images, the key can be any friendly name of the feature. Once specified, featureAttributions are keyed by this key (if not grouped with another feature). For custom images, the key must match with the key in instance.
	Inputs GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadata `pulumi:"inputs"`
	// Name of the source to generate embeddings for example based explanations.
	LatentSpaceSource *string `pulumi:"latentSpaceSource"`
	// Map from output names to output metadata. For Vertex AI-provided Tensorflow images, keys can be any user defined string that consists of any UTF-8 characters. For custom images, keys are the name of the output field in the prediction to be explained. Currently only one key is allowed.
	Outputs GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadata `pulumi:"outputs"`
}

// GoogleCloudAiplatformV1beta1ExplanationMetadataInput is an input type that accepts GoogleCloudAiplatformV1beta1ExplanationMetadataArgs and GoogleCloudAiplatformV1beta1ExplanationMetadataOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1ExplanationMetadataInput` via:
//
//	GoogleCloudAiplatformV1beta1ExplanationMetadataArgs{...}
type GoogleCloudAiplatformV1beta1ExplanationMetadataInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1ExplanationMetadataOutput() GoogleCloudAiplatformV1beta1ExplanationMetadataOutput
	ToGoogleCloudAiplatformV1beta1ExplanationMetadataOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1ExplanationMetadataOutput
}

// Metadata describing the Model's input and output for explanation.
type GoogleCloudAiplatformV1beta1ExplanationMetadataArgs struct {
	// Points to a YAML file stored on Google Cloud Storage describing the format of the feature attributions. The schema is defined as an OpenAPI 3.0.2 [Schema Object](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject). AutoML tabular Models always have this field populated by Vertex AI. Note: The URI given on output may be different, including the URI scheme, than the one given on input. The output URI will point to a location where the user only has a read access.
	FeatureAttributionsSchemaUri pulumi.StringPtrInput `pulumi:"featureAttributionsSchemaUri"`
	// Map from feature names to feature input metadata. Keys are the name of the features. Values are the specification of the feature. An empty InputMetadata is valid. It describes a text feature which has the name specified as the key in ExplanationMetadata.inputs. The baseline of the empty feature is chosen by Vertex AI. For Vertex AI-provided Tensorflow images, the key can be any friendly name of the feature. Once specified, featureAttributions are keyed by this key (if not grouped with another feature). For custom images, the key must match with the key in instance.
	Inputs GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataInput `pulumi:"inputs"`
	// Name of the source to generate embeddings for example based explanations.
	LatentSpaceSource pulumi.StringPtrInput `pulumi:"latentSpaceSource"`
	// Map from output names to output metadata. For Vertex AI-provided Tensorflow images, keys can be any user defined string that consists of any UTF-8 characters. For custom images, keys are the name of the output field in the prediction to be explained. Currently only one key is allowed.
	Outputs GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataInput `pulumi:"outputs"`
}

func (GoogleCloudAiplatformV1beta1ExplanationMetadataArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ExplanationMetadata)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1ExplanationMetadataArgs) ToGoogleCloudAiplatformV1beta1ExplanationMetadataOutput() GoogleCloudAiplatformV1beta1ExplanationMetadataOutput {
	return i.ToGoogleCloudAiplatformV1beta1ExplanationMetadataOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1ExplanationMetadataArgs) ToGoogleCloudAiplatformV1beta1ExplanationMetadataOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ExplanationMetadataOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ExplanationMetadataOutput)
}

func (i GoogleCloudAiplatformV1beta1ExplanationMetadataArgs) ToGoogleCloudAiplatformV1beta1ExplanationMetadataPtrOutput() GoogleCloudAiplatformV1beta1ExplanationMetadataPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1ExplanationMetadataPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1ExplanationMetadataArgs) ToGoogleCloudAiplatformV1beta1ExplanationMetadataPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ExplanationMetadataPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ExplanationMetadataOutput).ToGoogleCloudAiplatformV1beta1ExplanationMetadataPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1ExplanationMetadataPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1ExplanationMetadataArgs, GoogleCloudAiplatformV1beta1ExplanationMetadataPtr and GoogleCloudAiplatformV1beta1ExplanationMetadataPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1ExplanationMetadataPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1ExplanationMetadataArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1ExplanationMetadataPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1ExplanationMetadataPtrOutput() GoogleCloudAiplatformV1beta1ExplanationMetadataPtrOutput
	ToGoogleCloudAiplatformV1beta1ExplanationMetadataPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1ExplanationMetadataPtrOutput
}

type googleCloudAiplatformV1beta1ExplanationMetadataPtrType GoogleCloudAiplatformV1beta1ExplanationMetadataArgs

func GoogleCloudAiplatformV1beta1ExplanationMetadataPtr(v *GoogleCloudAiplatformV1beta1ExplanationMetadataArgs) GoogleCloudAiplatformV1beta1ExplanationMetadataPtrInput {
	return (*googleCloudAiplatformV1beta1ExplanationMetadataPtrType)(v)
}

func (*googleCloudAiplatformV1beta1ExplanationMetadataPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1ExplanationMetadata)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1ExplanationMetadataPtrType) ToGoogleCloudAiplatformV1beta1ExplanationMetadataPtrOutput() GoogleCloudAiplatformV1beta1ExplanationMetadataPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1ExplanationMetadataPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1ExplanationMetadataPtrType) ToGoogleCloudAiplatformV1beta1ExplanationMetadataPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ExplanationMetadataPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ExplanationMetadataPtrOutput)
}

// Metadata describing the Model's input and output for explanation.
type GoogleCloudAiplatformV1beta1ExplanationMetadataOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ExplanationMetadataOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ExplanationMetadata)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ExplanationMetadataOutput) ToGoogleCloudAiplatformV1beta1ExplanationMetadataOutput() GoogleCloudAiplatformV1beta1ExplanationMetadataOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ExplanationMetadataOutput) ToGoogleCloudAiplatformV1beta1ExplanationMetadataOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ExplanationMetadataOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ExplanationMetadataOutput) ToGoogleCloudAiplatformV1beta1ExplanationMetadataPtrOutput() GoogleCloudAiplatformV1beta1ExplanationMetadataPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1ExplanationMetadataPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1ExplanationMetadataOutput) ToGoogleCloudAiplatformV1beta1ExplanationMetadataPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ExplanationMetadataPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1ExplanationMetadata) *GoogleCloudAiplatformV1beta1ExplanationMetadata {
		return &v
	}).(GoogleCloudAiplatformV1beta1ExplanationMetadataPtrOutput)
}

// Points to a YAML file stored on Google Cloud Storage describing the format of the feature attributions. The schema is defined as an OpenAPI 3.0.2 [Schema Object](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject). AutoML tabular Models always have this field populated by Vertex AI. Note: The URI given on output may be different, including the URI scheme, than the one given on input. The output URI will point to a location where the user only has a read access.
func (o GoogleCloudAiplatformV1beta1ExplanationMetadataOutput) FeatureAttributionsSchemaUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ExplanationMetadata) *string { return v.FeatureAttributionsSchemaUri }).(pulumi.StringPtrOutput)
}

// Map from feature names to feature input metadata. Keys are the name of the features. Values are the specification of the feature. An empty InputMetadata is valid. It describes a text feature which has the name specified as the key in ExplanationMetadata.inputs. The baseline of the empty feature is chosen by Vertex AI. For Vertex AI-provided Tensorflow images, the key can be any friendly name of the feature. Once specified, featureAttributions are keyed by this key (if not grouped with another feature). For custom images, the key must match with the key in instance.
func (o GoogleCloudAiplatformV1beta1ExplanationMetadataOutput) Inputs() GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ExplanationMetadata) GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadata {
		return v.Inputs
	}).(GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataOutput)
}

// Name of the source to generate embeddings for example based explanations.
func (o GoogleCloudAiplatformV1beta1ExplanationMetadataOutput) LatentSpaceSource() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ExplanationMetadata) *string { return v.LatentSpaceSource }).(pulumi.StringPtrOutput)
}

// Map from output names to output metadata. For Vertex AI-provided Tensorflow images, keys can be any user defined string that consists of any UTF-8 characters. For custom images, keys are the name of the output field in the prediction to be explained. Currently only one key is allowed.
func (o GoogleCloudAiplatformV1beta1ExplanationMetadataOutput) Outputs() GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ExplanationMetadata) GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadata {
		return v.Outputs
	}).(GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataOutput)
}

type GoogleCloudAiplatformV1beta1ExplanationMetadataPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ExplanationMetadataPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1ExplanationMetadata)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ExplanationMetadataPtrOutput) ToGoogleCloudAiplatformV1beta1ExplanationMetadataPtrOutput() GoogleCloudAiplatformV1beta1ExplanationMetadataPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ExplanationMetadataPtrOutput) ToGoogleCloudAiplatformV1beta1ExplanationMetadataPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ExplanationMetadataPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ExplanationMetadataPtrOutput) Elem() GoogleCloudAiplatformV1beta1ExplanationMetadataOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ExplanationMetadata) GoogleCloudAiplatformV1beta1ExplanationMetadata {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1ExplanationMetadata
		return ret
	}).(GoogleCloudAiplatformV1beta1ExplanationMetadataOutput)
}

// Points to a YAML file stored on Google Cloud Storage describing the format of the feature attributions. The schema is defined as an OpenAPI 3.0.2 [Schema Object](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject). AutoML tabular Models always have this field populated by Vertex AI. Note: The URI given on output may be different, including the URI scheme, than the one given on input. The output URI will point to a location where the user only has a read access.
func (o GoogleCloudAiplatformV1beta1ExplanationMetadataPtrOutput) FeatureAttributionsSchemaUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ExplanationMetadata) *string {
		if v == nil {
			return nil
		}
		return v.FeatureAttributionsSchemaUri
	}).(pulumi.StringPtrOutput)
}

// Map from feature names to feature input metadata. Keys are the name of the features. Values are the specification of the feature. An empty InputMetadata is valid. It describes a text feature which has the name specified as the key in ExplanationMetadata.inputs. The baseline of the empty feature is chosen by Vertex AI. For Vertex AI-provided Tensorflow images, the key can be any friendly name of the feature. Once specified, featureAttributions are keyed by this key (if not grouped with another feature). For custom images, the key must match with the key in instance.
func (o GoogleCloudAiplatformV1beta1ExplanationMetadataPtrOutput) Inputs() GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ExplanationMetadata) *GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadata {
		if v == nil {
			return nil
		}
		return &v.Inputs
	}).(GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataPtrOutput)
}

// Name of the source to generate embeddings for example based explanations.
func (o GoogleCloudAiplatformV1beta1ExplanationMetadataPtrOutput) LatentSpaceSource() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ExplanationMetadata) *string {
		if v == nil {
			return nil
		}
		return v.LatentSpaceSource
	}).(pulumi.StringPtrOutput)
}

// Map from output names to output metadata. For Vertex AI-provided Tensorflow images, keys can be any user defined string that consists of any UTF-8 characters. For custom images, keys are the name of the output field in the prediction to be explained. Currently only one key is allowed.
func (o GoogleCloudAiplatformV1beta1ExplanationMetadataPtrOutput) Outputs() GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ExplanationMetadata) *GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadata {
		if v == nil {
			return nil
		}
		return &v.Outputs
	}).(GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataPtrOutput)
}

// Metadata of the input of a feature. Fields other than InputMetadata.input_baselines are applicable only for Models that are using Vertex AI-provided images for Tensorflow.
type GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadata struct {
	// Specifies the shape of the values of the input if the input is a sparse representation. Refer to Tensorflow documentation for more details: https://www.tensorflow.org/api_docs/python/tf/sparse/SparseTensor.
	DenseShapeTensorName *string `pulumi:"denseShapeTensorName"`
	// A list of baselines for the encoded tensor. The shape of each baseline should match the shape of the encoded tensor. If a scalar is provided, Vertex AI broadcasts to the same shape as the encoded tensor.
	EncodedBaselines []interface{} `pulumi:"encodedBaselines"`
	// Encoded tensor is a transformation of the input tensor. Must be provided if choosing Integrated Gradients attribution or XRAI attribution and the input tensor is not differentiable. An encoded tensor is generated if the input tensor is encoded by a lookup table.
	EncodedTensorName *string `pulumi:"encodedTensorName"`
	// Defines how the feature is encoded into the input tensor. Defaults to IDENTITY.
	Encoding *GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataEncoding `pulumi:"encoding"`
	// The domain details of the input feature value. Like min/max, original mean or standard deviation if normalized.
	FeatureValueDomain *GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomain `pulumi:"featureValueDomain"`
	// Name of the group that the input belongs to. Features with the same group name will be treated as one feature when computing attributions. Features grouped together can have different shapes in value. If provided, there will be one single attribution generated in Attribution.feature_attributions, keyed by the group name.
	GroupName *string `pulumi:"groupName"`
	// A list of feature names for each index in the input tensor. Required when the input InputMetadata.encoding is BAG_OF_FEATURES, BAG_OF_FEATURES_SPARSE, INDICATOR.
	IndexFeatureMapping []string `pulumi:"indexFeatureMapping"`
	// Specifies the index of the values of the input tensor. Required when the input tensor is a sparse representation. Refer to Tensorflow documentation for more details: https://www.tensorflow.org/api_docs/python/tf/sparse/SparseTensor.
	IndicesTensorName *string `pulumi:"indicesTensorName"`
	// Baseline inputs for this feature. If no baseline is specified, Vertex AI chooses the baseline for this feature. If multiple baselines are specified, Vertex AI returns the average attributions across them in Attribution.feature_attributions. For Vertex AI-provided Tensorflow images (both 1.x and 2.x), the shape of each baseline must match the shape of the input tensor. If a scalar is provided, we broadcast to the same shape as the input tensor. For custom images, the element of the baselines must be in the same format as the feature's input in the instance[]. The schema of any single instance may be specified via Endpoint's DeployedModels' Model's PredictSchemata's instance_schema_uri.
	InputBaselines []interface{} `pulumi:"inputBaselines"`
	// Name of the input tensor for this feature. Required and is only applicable to Vertex AI-provided images for Tensorflow.
	InputTensorName *string `pulumi:"inputTensorName"`
	// Modality of the feature. Valid values are: numeric, image. Defaults to numeric.
	Modality *string `pulumi:"modality"`
	// Visualization configurations for image explanation.
	Visualization *GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualization `pulumi:"visualization"`
}

// GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataInput is an input type that accepts GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataArgs and GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataInput` via:
//
//	GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataArgs{...}
type GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataOutput() GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataOutput
	ToGoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataOutput
}

// Metadata of the input of a feature. Fields other than InputMetadata.input_baselines are applicable only for Models that are using Vertex AI-provided images for Tensorflow.
type GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataArgs struct {
	// Specifies the shape of the values of the input if the input is a sparse representation. Refer to Tensorflow documentation for more details: https://www.tensorflow.org/api_docs/python/tf/sparse/SparseTensor.
	DenseShapeTensorName pulumi.StringPtrInput `pulumi:"denseShapeTensorName"`
	// A list of baselines for the encoded tensor. The shape of each baseline should match the shape of the encoded tensor. If a scalar is provided, Vertex AI broadcasts to the same shape as the encoded tensor.
	EncodedBaselines pulumi.ArrayInput `pulumi:"encodedBaselines"`
	// Encoded tensor is a transformation of the input tensor. Must be provided if choosing Integrated Gradients attribution or XRAI attribution and the input tensor is not differentiable. An encoded tensor is generated if the input tensor is encoded by a lookup table.
	EncodedTensorName pulumi.StringPtrInput `pulumi:"encodedTensorName"`
	// Defines how the feature is encoded into the input tensor. Defaults to IDENTITY.
	Encoding GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataEncodingPtrInput `pulumi:"encoding"`
	// The domain details of the input feature value. Like min/max, original mean or standard deviation if normalized.
	FeatureValueDomain GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainPtrInput `pulumi:"featureValueDomain"`
	// Name of the group that the input belongs to. Features with the same group name will be treated as one feature when computing attributions. Features grouped together can have different shapes in value. If provided, there will be one single attribution generated in Attribution.feature_attributions, keyed by the group name.
	GroupName pulumi.StringPtrInput `pulumi:"groupName"`
	// A list of feature names for each index in the input tensor. Required when the input InputMetadata.encoding is BAG_OF_FEATURES, BAG_OF_FEATURES_SPARSE, INDICATOR.
	IndexFeatureMapping pulumi.StringArrayInput `pulumi:"indexFeatureMapping"`
	// Specifies the index of the values of the input tensor. Required when the input tensor is a sparse representation. Refer to Tensorflow documentation for more details: https://www.tensorflow.org/api_docs/python/tf/sparse/SparseTensor.
	IndicesTensorName pulumi.StringPtrInput `pulumi:"indicesTensorName"`
	// Baseline inputs for this feature. If no baseline is specified, Vertex AI chooses the baseline for this feature. If multiple baselines are specified, Vertex AI returns the average attributions across them in Attribution.feature_attributions. For Vertex AI-provided Tensorflow images (both 1.x and 2.x), the shape of each baseline must match the shape of the input tensor. If a scalar is provided, we broadcast to the same shape as the input tensor. For custom images, the element of the baselines must be in the same format as the feature's input in the instance[]. The schema of any single instance may be specified via Endpoint's DeployedModels' Model's PredictSchemata's instance_schema_uri.
	InputBaselines pulumi.ArrayInput `pulumi:"inputBaselines"`
	// Name of the input tensor for this feature. Required and is only applicable to Vertex AI-provided images for Tensorflow.
	InputTensorName pulumi.StringPtrInput `pulumi:"inputTensorName"`
	// Modality of the feature. Valid values are: numeric, image. Defaults to numeric.
	Modality pulumi.StringPtrInput `pulumi:"modality"`
	// Visualization configurations for image explanation.
	Visualization GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationPtrInput `pulumi:"visualization"`
}

func (GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadata)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataArgs) ToGoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataOutput() GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataOutput {
	return i.ToGoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataArgs) ToGoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataOutput)
}

func (i GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataArgs) ToGoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataPtrOutput() GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataArgs) ToGoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataOutput).ToGoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataArgs, GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataPtr and GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataPtrOutput() GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataPtrOutput
	ToGoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataPtrOutput
}

type googleCloudAiplatformV1beta1ExplanationMetadataInputMetadataPtrType GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataArgs

func GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataPtr(v *GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataArgs) GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataPtrInput {
	return (*googleCloudAiplatformV1beta1ExplanationMetadataInputMetadataPtrType)(v)
}

func (*googleCloudAiplatformV1beta1ExplanationMetadataInputMetadataPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadata)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1ExplanationMetadataInputMetadataPtrType) ToGoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataPtrOutput() GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1ExplanationMetadataInputMetadataPtrType) ToGoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataPtrOutput)
}

// Metadata of the input of a feature. Fields other than InputMetadata.input_baselines are applicable only for Models that are using Vertex AI-provided images for Tensorflow.
type GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadata)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataOutput) ToGoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataOutput() GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataOutput) ToGoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataOutput) ToGoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataPtrOutput() GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataOutput) ToGoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadata) *GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadata {
		return &v
	}).(GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataPtrOutput)
}

// Specifies the shape of the values of the input if the input is a sparse representation. Refer to Tensorflow documentation for more details: https://www.tensorflow.org/api_docs/python/tf/sparse/SparseTensor.
func (o GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataOutput) DenseShapeTensorName() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadata) *string {
		return v.DenseShapeTensorName
	}).(pulumi.StringPtrOutput)
}

// A list of baselines for the encoded tensor. The shape of each baseline should match the shape of the encoded tensor. If a scalar is provided, Vertex AI broadcasts to the same shape as the encoded tensor.
func (o GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataOutput) EncodedBaselines() pulumi.ArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadata) []interface{} {
		return v.EncodedBaselines
	}).(pulumi.ArrayOutput)
}

// Encoded tensor is a transformation of the input tensor. Must be provided if choosing Integrated Gradients attribution or XRAI attribution and the input tensor is not differentiable. An encoded tensor is generated if the input tensor is encoded by a lookup table.
func (o GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataOutput) EncodedTensorName() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadata) *string {
		return v.EncodedTensorName
	}).(pulumi.StringPtrOutput)
}

// Defines how the feature is encoded into the input tensor. Defaults to IDENTITY.
func (o GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataOutput) Encoding() GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataEncodingPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadata) *GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataEncoding {
		return v.Encoding
	}).(GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataEncodingPtrOutput)
}

// The domain details of the input feature value. Like min/max, original mean or standard deviation if normalized.
func (o GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataOutput) FeatureValueDomain() GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadata) *GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomain {
		return v.FeatureValueDomain
	}).(GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainPtrOutput)
}

// Name of the group that the input belongs to. Features with the same group name will be treated as one feature when computing attributions. Features grouped together can have different shapes in value. If provided, there will be one single attribution generated in Attribution.feature_attributions, keyed by the group name.
func (o GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataOutput) GroupName() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadata) *string { return v.GroupName }).(pulumi.StringPtrOutput)
}

// A list of feature names for each index in the input tensor. Required when the input InputMetadata.encoding is BAG_OF_FEATURES, BAG_OF_FEATURES_SPARSE, INDICATOR.
func (o GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataOutput) IndexFeatureMapping() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadata) []string {
		return v.IndexFeatureMapping
	}).(pulumi.StringArrayOutput)
}

// Specifies the index of the values of the input tensor. Required when the input tensor is a sparse representation. Refer to Tensorflow documentation for more details: https://www.tensorflow.org/api_docs/python/tf/sparse/SparseTensor.
func (o GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataOutput) IndicesTensorName() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadata) *string {
		return v.IndicesTensorName
	}).(pulumi.StringPtrOutput)
}

// Baseline inputs for this feature. If no baseline is specified, Vertex AI chooses the baseline for this feature. If multiple baselines are specified, Vertex AI returns the average attributions across them in Attribution.feature_attributions. For Vertex AI-provided Tensorflow images (both 1.x and 2.x), the shape of each baseline must match the shape of the input tensor. If a scalar is provided, we broadcast to the same shape as the input tensor. For custom images, the element of the baselines must be in the same format as the feature's input in the instance[]. The schema of any single instance may be specified via Endpoint's DeployedModels' Model's PredictSchemata's instance_schema_uri.
func (o GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataOutput) InputBaselines() pulumi.ArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadata) []interface{} {
		return v.InputBaselines
	}).(pulumi.ArrayOutput)
}

// Name of the input tensor for this feature. Required and is only applicable to Vertex AI-provided images for Tensorflow.
func (o GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataOutput) InputTensorName() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadata) *string { return v.InputTensorName }).(pulumi.StringPtrOutput)
}

// Modality of the feature. Valid values are: numeric, image. Defaults to numeric.
func (o GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataOutput) Modality() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadata) *string { return v.Modality }).(pulumi.StringPtrOutput)
}

// Visualization configurations for image explanation.
func (o GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataOutput) Visualization() GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadata) *GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualization {
		return v.Visualization
	}).(GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationPtrOutput)
}

type GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadata)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataPtrOutput) ToGoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataPtrOutput() GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataPtrOutput) ToGoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataPtrOutput) Elem() GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadata) GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadata {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadata
		return ret
	}).(GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataOutput)
}

// Specifies the shape of the values of the input if the input is a sparse representation. Refer to Tensorflow documentation for more details: https://www.tensorflow.org/api_docs/python/tf/sparse/SparseTensor.
func (o GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataPtrOutput) DenseShapeTensorName() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadata) *string {
		if v == nil {
			return nil
		}
		return v.DenseShapeTensorName
	}).(pulumi.StringPtrOutput)
}

// A list of baselines for the encoded tensor. The shape of each baseline should match the shape of the encoded tensor. If a scalar is provided, Vertex AI broadcasts to the same shape as the encoded tensor.
func (o GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataPtrOutput) EncodedBaselines() pulumi.ArrayOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadata) []interface{} {
		if v == nil {
			return nil
		}
		return v.EncodedBaselines
	}).(pulumi.ArrayOutput)
}

// Encoded tensor is a transformation of the input tensor. Must be provided if choosing Integrated Gradients attribution or XRAI attribution and the input tensor is not differentiable. An encoded tensor is generated if the input tensor is encoded by a lookup table.
func (o GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataPtrOutput) EncodedTensorName() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadata) *string {
		if v == nil {
			return nil
		}
		return v.EncodedTensorName
	}).(pulumi.StringPtrOutput)
}

// Defines how the feature is encoded into the input tensor. Defaults to IDENTITY.
func (o GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataPtrOutput) Encoding() GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataEncodingPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadata) *GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataEncoding {
		if v == nil {
			return nil
		}
		return v.Encoding
	}).(GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataEncodingPtrOutput)
}

// The domain details of the input feature value. Like min/max, original mean or standard deviation if normalized.
func (o GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataPtrOutput) FeatureValueDomain() GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadata) *GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomain {
		if v == nil {
			return nil
		}
		return v.FeatureValueDomain
	}).(GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainPtrOutput)
}

// Name of the group that the input belongs to. Features with the same group name will be treated as one feature when computing attributions. Features grouped together can have different shapes in value. If provided, there will be one single attribution generated in Attribution.feature_attributions, keyed by the group name.
func (o GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataPtrOutput) GroupName() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadata) *string {
		if v == nil {
			return nil
		}
		return v.GroupName
	}).(pulumi.StringPtrOutput)
}

// A list of feature names for each index in the input tensor. Required when the input InputMetadata.encoding is BAG_OF_FEATURES, BAG_OF_FEATURES_SPARSE, INDICATOR.
func (o GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataPtrOutput) IndexFeatureMapping() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadata) []string {
		if v == nil {
			return nil
		}
		return v.IndexFeatureMapping
	}).(pulumi.StringArrayOutput)
}

// Specifies the index of the values of the input tensor. Required when the input tensor is a sparse representation. Refer to Tensorflow documentation for more details: https://www.tensorflow.org/api_docs/python/tf/sparse/SparseTensor.
func (o GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataPtrOutput) IndicesTensorName() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadata) *string {
		if v == nil {
			return nil
		}
		return v.IndicesTensorName
	}).(pulumi.StringPtrOutput)
}

// Baseline inputs for this feature. If no baseline is specified, Vertex AI chooses the baseline for this feature. If multiple baselines are specified, Vertex AI returns the average attributions across them in Attribution.feature_attributions. For Vertex AI-provided Tensorflow images (both 1.x and 2.x), the shape of each baseline must match the shape of the input tensor. If a scalar is provided, we broadcast to the same shape as the input tensor. For custom images, the element of the baselines must be in the same format as the feature's input in the instance[]. The schema of any single instance may be specified via Endpoint's DeployedModels' Model's PredictSchemata's instance_schema_uri.
func (o GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataPtrOutput) InputBaselines() pulumi.ArrayOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadata) []interface{} {
		if v == nil {
			return nil
		}
		return v.InputBaselines
	}).(pulumi.ArrayOutput)
}

// Name of the input tensor for this feature. Required and is only applicable to Vertex AI-provided images for Tensorflow.
func (o GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataPtrOutput) InputTensorName() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadata) *string {
		if v == nil {
			return nil
		}
		return v.InputTensorName
	}).(pulumi.StringPtrOutput)
}

// Modality of the feature. Valid values are: numeric, image. Defaults to numeric.
func (o GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataPtrOutput) Modality() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadata) *string {
		if v == nil {
			return nil
		}
		return v.Modality
	}).(pulumi.StringPtrOutput)
}

// Visualization configurations for image explanation.
func (o GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataPtrOutput) Visualization() GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadata) *GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualization {
		if v == nil {
			return nil
		}
		return v.Visualization
	}).(GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationPtrOutput)
}

// Domain details of the input feature value. Provides numeric information about the feature, such as its range (min, max). If the feature has been pre-processed, for example with z-scoring, then it provides information about how to recover the original feature. For example, if the input feature is an image and it has been pre-processed to obtain 0-mean and stddev = 1 values, then original_mean, and original_stddev refer to the mean and stddev of the original feature (e.g. image tensor) from which input feature (with mean = 0 and stddev = 1) was obtained.
type GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomain struct {
	// The maximum permissible value for this feature.
	MaxValue *float64 `pulumi:"maxValue"`
	// The minimum permissible value for this feature.
	MinValue *float64 `pulumi:"minValue"`
	// If this input feature has been normalized to a mean value of 0, the original_mean specifies the mean value of the domain prior to normalization.
	OriginalMean *float64 `pulumi:"originalMean"`
	// If this input feature has been normalized to a standard deviation of 1.0, the original_stddev specifies the standard deviation of the domain prior to normalization.
	OriginalStddev *float64 `pulumi:"originalStddev"`
}

// GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainInput is an input type that accepts GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainArgs and GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainInput` via:
//
//	GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainArgs{...}
type GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainOutput() GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainOutput
	ToGoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainOutput
}

// Domain details of the input feature value. Provides numeric information about the feature, such as its range (min, max). If the feature has been pre-processed, for example with z-scoring, then it provides information about how to recover the original feature. For example, if the input feature is an image and it has been pre-processed to obtain 0-mean and stddev = 1 values, then original_mean, and original_stddev refer to the mean and stddev of the original feature (e.g. image tensor) from which input feature (with mean = 0 and stddev = 1) was obtained.
type GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainArgs struct {
	// The maximum permissible value for this feature.
	MaxValue pulumi.Float64PtrInput `pulumi:"maxValue"`
	// The minimum permissible value for this feature.
	MinValue pulumi.Float64PtrInput `pulumi:"minValue"`
	// If this input feature has been normalized to a mean value of 0, the original_mean specifies the mean value of the domain prior to normalization.
	OriginalMean pulumi.Float64PtrInput `pulumi:"originalMean"`
	// If this input feature has been normalized to a standard deviation of 1.0, the original_stddev specifies the standard deviation of the domain prior to normalization.
	OriginalStddev pulumi.Float64PtrInput `pulumi:"originalStddev"`
}

func (GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomain)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainArgs) ToGoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainOutput() GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainOutput {
	return i.ToGoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainArgs) ToGoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainOutput)
}

func (i GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainArgs) ToGoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainPtrOutput() GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainArgs) ToGoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainOutput).ToGoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainArgs, GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainPtr and GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainPtrOutput() GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainPtrOutput
	ToGoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainPtrOutput
}

type googleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainPtrType GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainArgs

func GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainPtr(v *GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainArgs) GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainPtrInput {
	return (*googleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainPtrType)(v)
}

func (*googleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomain)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainPtrType) ToGoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainPtrOutput() GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainPtrType) ToGoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainPtrOutput)
}

// Domain details of the input feature value. Provides numeric information about the feature, such as its range (min, max). If the feature has been pre-processed, for example with z-scoring, then it provides information about how to recover the original feature. For example, if the input feature is an image and it has been pre-processed to obtain 0-mean and stddev = 1 values, then original_mean, and original_stddev refer to the mean and stddev of the original feature (e.g. image tensor) from which input feature (with mean = 0 and stddev = 1) was obtained.
type GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomain)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainOutput) ToGoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainOutput() GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainOutput) ToGoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainOutput) ToGoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainPtrOutput() GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainOutput) ToGoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomain) *GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomain {
		return &v
	}).(GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainPtrOutput)
}

// The maximum permissible value for this feature.
func (o GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainOutput) MaxValue() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomain) *float64 {
		return v.MaxValue
	}).(pulumi.Float64PtrOutput)
}

// The minimum permissible value for this feature.
func (o GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainOutput) MinValue() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomain) *float64 {
		return v.MinValue
	}).(pulumi.Float64PtrOutput)
}

// If this input feature has been normalized to a mean value of 0, the original_mean specifies the mean value of the domain prior to normalization.
func (o GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainOutput) OriginalMean() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomain) *float64 {
		return v.OriginalMean
	}).(pulumi.Float64PtrOutput)
}

// If this input feature has been normalized to a standard deviation of 1.0, the original_stddev specifies the standard deviation of the domain prior to normalization.
func (o GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainOutput) OriginalStddev() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomain) *float64 {
		return v.OriginalStddev
	}).(pulumi.Float64PtrOutput)
}

type GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomain)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainPtrOutput) ToGoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainPtrOutput() GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainPtrOutput) ToGoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainPtrOutput) Elem() GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomain) GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomain {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomain
		return ret
	}).(GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainOutput)
}

// The maximum permissible value for this feature.
func (o GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainPtrOutput) MaxValue() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomain) *float64 {
		if v == nil {
			return nil
		}
		return v.MaxValue
	}).(pulumi.Float64PtrOutput)
}

// The minimum permissible value for this feature.
func (o GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainPtrOutput) MinValue() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomain) *float64 {
		if v == nil {
			return nil
		}
		return v.MinValue
	}).(pulumi.Float64PtrOutput)
}

// If this input feature has been normalized to a mean value of 0, the original_mean specifies the mean value of the domain prior to normalization.
func (o GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainPtrOutput) OriginalMean() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomain) *float64 {
		if v == nil {
			return nil
		}
		return v.OriginalMean
	}).(pulumi.Float64PtrOutput)
}

// If this input feature has been normalized to a standard deviation of 1.0, the original_stddev specifies the standard deviation of the domain prior to normalization.
func (o GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainPtrOutput) OriginalStddev() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomain) *float64 {
		if v == nil {
			return nil
		}
		return v.OriginalStddev
	}).(pulumi.Float64PtrOutput)
}

// Domain details of the input feature value. Provides numeric information about the feature, such as its range (min, max). If the feature has been pre-processed, for example with z-scoring, then it provides information about how to recover the original feature. For example, if the input feature is an image and it has been pre-processed to obtain 0-mean and stddev = 1 values, then original_mean, and original_stddev refer to the mean and stddev of the original feature (e.g. image tensor) from which input feature (with mean = 0 and stddev = 1) was obtained.
type GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainResponse struct {
	// The maximum permissible value for this feature.
	MaxValue float64 `pulumi:"maxValue"`
	// The minimum permissible value for this feature.
	MinValue float64 `pulumi:"minValue"`
	// If this input feature has been normalized to a mean value of 0, the original_mean specifies the mean value of the domain prior to normalization.
	OriginalMean float64 `pulumi:"originalMean"`
	// If this input feature has been normalized to a standard deviation of 1.0, the original_stddev specifies the standard deviation of the domain prior to normalization.
	OriginalStddev float64 `pulumi:"originalStddev"`
}

// Domain details of the input feature value. Provides numeric information about the feature, such as its range (min, max). If the feature has been pre-processed, for example with z-scoring, then it provides information about how to recover the original feature. For example, if the input feature is an image and it has been pre-processed to obtain 0-mean and stddev = 1 values, then original_mean, and original_stddev refer to the mean and stddev of the original feature (e.g. image tensor) from which input feature (with mean = 0 and stddev = 1) was obtained.
type GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainResponseOutput) ToGoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainResponseOutput() GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainResponseOutput) ToGoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainResponseOutput {
	return o
}

// The maximum permissible value for this feature.
func (o GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainResponseOutput) MaxValue() pulumi.Float64Output {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainResponse) float64 {
		return v.MaxValue
	}).(pulumi.Float64Output)
}

// The minimum permissible value for this feature.
func (o GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainResponseOutput) MinValue() pulumi.Float64Output {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainResponse) float64 {
		return v.MinValue
	}).(pulumi.Float64Output)
}

// If this input feature has been normalized to a mean value of 0, the original_mean specifies the mean value of the domain prior to normalization.
func (o GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainResponseOutput) OriginalMean() pulumi.Float64Output {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainResponse) float64 {
		return v.OriginalMean
	}).(pulumi.Float64Output)
}

// If this input feature has been normalized to a standard deviation of 1.0, the original_stddev specifies the standard deviation of the domain prior to normalization.
func (o GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainResponseOutput) OriginalStddev() pulumi.Float64Output {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainResponse) float64 {
		return v.OriginalStddev
	}).(pulumi.Float64Output)
}

// Metadata of the input of a feature. Fields other than InputMetadata.input_baselines are applicable only for Models that are using Vertex AI-provided images for Tensorflow.
type GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataResponse struct {
	// Specifies the shape of the values of the input if the input is a sparse representation. Refer to Tensorflow documentation for more details: https://www.tensorflow.org/api_docs/python/tf/sparse/SparseTensor.
	DenseShapeTensorName string `pulumi:"denseShapeTensorName"`
	// A list of baselines for the encoded tensor. The shape of each baseline should match the shape of the encoded tensor. If a scalar is provided, Vertex AI broadcasts to the same shape as the encoded tensor.
	EncodedBaselines []interface{} `pulumi:"encodedBaselines"`
	// Encoded tensor is a transformation of the input tensor. Must be provided if choosing Integrated Gradients attribution or XRAI attribution and the input tensor is not differentiable. An encoded tensor is generated if the input tensor is encoded by a lookup table.
	EncodedTensorName string `pulumi:"encodedTensorName"`
	// Defines how the feature is encoded into the input tensor. Defaults to IDENTITY.
	Encoding string `pulumi:"encoding"`
	// The domain details of the input feature value. Like min/max, original mean or standard deviation if normalized.
	FeatureValueDomain GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainResponse `pulumi:"featureValueDomain"`
	// Name of the group that the input belongs to. Features with the same group name will be treated as one feature when computing attributions. Features grouped together can have different shapes in value. If provided, there will be one single attribution generated in Attribution.feature_attributions, keyed by the group name.
	GroupName string `pulumi:"groupName"`
	// A list of feature names for each index in the input tensor. Required when the input InputMetadata.encoding is BAG_OF_FEATURES, BAG_OF_FEATURES_SPARSE, INDICATOR.
	IndexFeatureMapping []string `pulumi:"indexFeatureMapping"`
	// Specifies the index of the values of the input tensor. Required when the input tensor is a sparse representation. Refer to Tensorflow documentation for more details: https://www.tensorflow.org/api_docs/python/tf/sparse/SparseTensor.
	IndicesTensorName string `pulumi:"indicesTensorName"`
	// Baseline inputs for this feature. If no baseline is specified, Vertex AI chooses the baseline for this feature. If multiple baselines are specified, Vertex AI returns the average attributions across them in Attribution.feature_attributions. For Vertex AI-provided Tensorflow images (both 1.x and 2.x), the shape of each baseline must match the shape of the input tensor. If a scalar is provided, we broadcast to the same shape as the input tensor. For custom images, the element of the baselines must be in the same format as the feature's input in the instance[]. The schema of any single instance may be specified via Endpoint's DeployedModels' Model's PredictSchemata's instance_schema_uri.
	InputBaselines []interface{} `pulumi:"inputBaselines"`
	// Name of the input tensor for this feature. Required and is only applicable to Vertex AI-provided images for Tensorflow.
	InputTensorName string `pulumi:"inputTensorName"`
	// Modality of the feature. Valid values are: numeric, image. Defaults to numeric.
	Modality string `pulumi:"modality"`
	// Visualization configurations for image explanation.
	Visualization GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationResponse `pulumi:"visualization"`
}

// Metadata of the input of a feature. Fields other than InputMetadata.input_baselines are applicable only for Models that are using Vertex AI-provided images for Tensorflow.
type GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataResponseOutput) ToGoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataResponseOutput() GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataResponseOutput) ToGoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataResponseOutput {
	return o
}

// Specifies the shape of the values of the input if the input is a sparse representation. Refer to Tensorflow documentation for more details: https://www.tensorflow.org/api_docs/python/tf/sparse/SparseTensor.
func (o GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataResponseOutput) DenseShapeTensorName() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataResponse) string {
		return v.DenseShapeTensorName
	}).(pulumi.StringOutput)
}

// A list of baselines for the encoded tensor. The shape of each baseline should match the shape of the encoded tensor. If a scalar is provided, Vertex AI broadcasts to the same shape as the encoded tensor.
func (o GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataResponseOutput) EncodedBaselines() pulumi.ArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataResponse) []interface{} {
		return v.EncodedBaselines
	}).(pulumi.ArrayOutput)
}

// Encoded tensor is a transformation of the input tensor. Must be provided if choosing Integrated Gradients attribution or XRAI attribution and the input tensor is not differentiable. An encoded tensor is generated if the input tensor is encoded by a lookup table.
func (o GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataResponseOutput) EncodedTensorName() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataResponse) string {
		return v.EncodedTensorName
	}).(pulumi.StringOutput)
}

// Defines how the feature is encoded into the input tensor. Defaults to IDENTITY.
func (o GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataResponseOutput) Encoding() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataResponse) string { return v.Encoding }).(pulumi.StringOutput)
}

// The domain details of the input feature value. Like min/max, original mean or standard deviation if normalized.
func (o GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataResponseOutput) FeatureValueDomain() GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataResponse) GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainResponse {
		return v.FeatureValueDomain
	}).(GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainResponseOutput)
}

// Name of the group that the input belongs to. Features with the same group name will be treated as one feature when computing attributions. Features grouped together can have different shapes in value. If provided, there will be one single attribution generated in Attribution.feature_attributions, keyed by the group name.
func (o GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataResponseOutput) GroupName() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataResponse) string {
		return v.GroupName
	}).(pulumi.StringOutput)
}

// A list of feature names for each index in the input tensor. Required when the input InputMetadata.encoding is BAG_OF_FEATURES, BAG_OF_FEATURES_SPARSE, INDICATOR.
func (o GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataResponseOutput) IndexFeatureMapping() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataResponse) []string {
		return v.IndexFeatureMapping
	}).(pulumi.StringArrayOutput)
}

// Specifies the index of the values of the input tensor. Required when the input tensor is a sparse representation. Refer to Tensorflow documentation for more details: https://www.tensorflow.org/api_docs/python/tf/sparse/SparseTensor.
func (o GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataResponseOutput) IndicesTensorName() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataResponse) string {
		return v.IndicesTensorName
	}).(pulumi.StringOutput)
}

// Baseline inputs for this feature. If no baseline is specified, Vertex AI chooses the baseline for this feature. If multiple baselines are specified, Vertex AI returns the average attributions across them in Attribution.feature_attributions. For Vertex AI-provided Tensorflow images (both 1.x and 2.x), the shape of each baseline must match the shape of the input tensor. If a scalar is provided, we broadcast to the same shape as the input tensor. For custom images, the element of the baselines must be in the same format as the feature's input in the instance[]. The schema of any single instance may be specified via Endpoint's DeployedModels' Model's PredictSchemata's instance_schema_uri.
func (o GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataResponseOutput) InputBaselines() pulumi.ArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataResponse) []interface{} {
		return v.InputBaselines
	}).(pulumi.ArrayOutput)
}

// Name of the input tensor for this feature. Required and is only applicable to Vertex AI-provided images for Tensorflow.
func (o GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataResponseOutput) InputTensorName() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataResponse) string {
		return v.InputTensorName
	}).(pulumi.StringOutput)
}

// Modality of the feature. Valid values are: numeric, image. Defaults to numeric.
func (o GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataResponseOutput) Modality() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataResponse) string { return v.Modality }).(pulumi.StringOutput)
}

// Visualization configurations for image explanation.
func (o GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataResponseOutput) Visualization() GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataResponse) GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationResponse {
		return v.Visualization
	}).(GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationResponseOutput)
}

// Visualization configurations for image explanation.
type GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualization struct {
	// Excludes attributions below the specified percentile, from the highlighted areas. Defaults to 62.
	ClipPercentLowerbound *float64 `pulumi:"clipPercentLowerbound"`
	// Excludes attributions above the specified percentile from the highlighted areas. Using the clip_percent_upperbound and clip_percent_lowerbound together can be useful for filtering out noise and making it easier to see areas of strong attribution. Defaults to 99.9.
	ClipPercentUpperbound *float64 `pulumi:"clipPercentUpperbound"`
	// The color scheme used for the highlighted areas. Defaults to PINK_GREEN for Integrated Gradients attribution, which shows positive attributions in green and negative in pink. Defaults to VIRIDIS for XRAI attribution, which highlights the most influential regions in yellow and the least influential in blue.
	ColorMap *GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationColorMap `pulumi:"colorMap"`
	// How the original image is displayed in the visualization. Adjusting the overlay can help increase visual clarity if the original image makes it difficult to view the visualization. Defaults to NONE.
	OverlayType *GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationOverlayType `pulumi:"overlayType"`
	// Whether to only highlight pixels with positive contributions, negative or both. Defaults to POSITIVE.
	Polarity *GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationPolarity `pulumi:"polarity"`
	// Type of the image visualization. Only applicable to Integrated Gradients attribution. OUTLINES shows regions of attribution, while PIXELS shows per-pixel attribution. Defaults to OUTLINES.
	Type *GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationType `pulumi:"type"`
}

// GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationInput is an input type that accepts GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationArgs and GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationInput` via:
//
//	GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationArgs{...}
type GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationOutput() GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationOutput
	ToGoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationOutput
}

// Visualization configurations for image explanation.
type GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationArgs struct {
	// Excludes attributions below the specified percentile, from the highlighted areas. Defaults to 62.
	ClipPercentLowerbound pulumi.Float64PtrInput `pulumi:"clipPercentLowerbound"`
	// Excludes attributions above the specified percentile from the highlighted areas. Using the clip_percent_upperbound and clip_percent_lowerbound together can be useful for filtering out noise and making it easier to see areas of strong attribution. Defaults to 99.9.
	ClipPercentUpperbound pulumi.Float64PtrInput `pulumi:"clipPercentUpperbound"`
	// The color scheme used for the highlighted areas. Defaults to PINK_GREEN for Integrated Gradients attribution, which shows positive attributions in green and negative in pink. Defaults to VIRIDIS for XRAI attribution, which highlights the most influential regions in yellow and the least influential in blue.
	ColorMap GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationColorMapPtrInput `pulumi:"colorMap"`
	// How the original image is displayed in the visualization. Adjusting the overlay can help increase visual clarity if the original image makes it difficult to view the visualization. Defaults to NONE.
	OverlayType GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationOverlayTypePtrInput `pulumi:"overlayType"`
	// Whether to only highlight pixels with positive contributions, negative or both. Defaults to POSITIVE.
	Polarity GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationPolarityPtrInput `pulumi:"polarity"`
	// Type of the image visualization. Only applicable to Integrated Gradients attribution. OUTLINES shows regions of attribution, while PIXELS shows per-pixel attribution. Defaults to OUTLINES.
	Type GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationTypePtrInput `pulumi:"type"`
}

func (GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualization)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationArgs) ToGoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationOutput() GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationOutput {
	return i.ToGoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationArgs) ToGoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationOutput)
}

func (i GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationArgs) ToGoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationPtrOutput() GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationArgs) ToGoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationOutput).ToGoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationArgs, GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationPtr and GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationPtrOutput() GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationPtrOutput
	ToGoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationPtrOutput
}

type googleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationPtrType GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationArgs

func GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationPtr(v *GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationArgs) GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationPtrInput {
	return (*googleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationPtrType)(v)
}

func (*googleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualization)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationPtrType) ToGoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationPtrOutput() GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationPtrType) ToGoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationPtrOutput)
}

// Visualization configurations for image explanation.
type GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualization)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationOutput) ToGoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationOutput() GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationOutput) ToGoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationOutput) ToGoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationPtrOutput() GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationOutput) ToGoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualization) *GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualization {
		return &v
	}).(GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationPtrOutput)
}

// Excludes attributions below the specified percentile, from the highlighted areas. Defaults to 62.
func (o GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationOutput) ClipPercentLowerbound() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualization) *float64 {
		return v.ClipPercentLowerbound
	}).(pulumi.Float64PtrOutput)
}

// Excludes attributions above the specified percentile from the highlighted areas. Using the clip_percent_upperbound and clip_percent_lowerbound together can be useful for filtering out noise and making it easier to see areas of strong attribution. Defaults to 99.9.
func (o GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationOutput) ClipPercentUpperbound() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualization) *float64 {
		return v.ClipPercentUpperbound
	}).(pulumi.Float64PtrOutput)
}

// The color scheme used for the highlighted areas. Defaults to PINK_GREEN for Integrated Gradients attribution, which shows positive attributions in green and negative in pink. Defaults to VIRIDIS for XRAI attribution, which highlights the most influential regions in yellow and the least influential in blue.
func (o GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationOutput) ColorMap() GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationColorMapPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualization) *GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationColorMap {
		return v.ColorMap
	}).(GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationColorMapPtrOutput)
}

// How the original image is displayed in the visualization. Adjusting the overlay can help increase visual clarity if the original image makes it difficult to view the visualization. Defaults to NONE.
func (o GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationOutput) OverlayType() GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationOverlayTypePtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualization) *GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationOverlayType {
		return v.OverlayType
	}).(GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationOverlayTypePtrOutput)
}

// Whether to only highlight pixels with positive contributions, negative or both. Defaults to POSITIVE.
func (o GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationOutput) Polarity() GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationPolarityPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualization) *GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationPolarity {
		return v.Polarity
	}).(GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationPolarityPtrOutput)
}

// Type of the image visualization. Only applicable to Integrated Gradients attribution. OUTLINES shows regions of attribution, while PIXELS shows per-pixel attribution. Defaults to OUTLINES.
func (o GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationOutput) Type() GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationTypePtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualization) *GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationType {
		return v.Type
	}).(GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationTypePtrOutput)
}

type GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualization)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationPtrOutput) ToGoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationPtrOutput() GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationPtrOutput) ToGoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationPtrOutput) Elem() GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualization) GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualization {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualization
		return ret
	}).(GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationOutput)
}

// Excludes attributions below the specified percentile, from the highlighted areas. Defaults to 62.
func (o GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationPtrOutput) ClipPercentLowerbound() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualization) *float64 {
		if v == nil {
			return nil
		}
		return v.ClipPercentLowerbound
	}).(pulumi.Float64PtrOutput)
}

// Excludes attributions above the specified percentile from the highlighted areas. Using the clip_percent_upperbound and clip_percent_lowerbound together can be useful for filtering out noise and making it easier to see areas of strong attribution. Defaults to 99.9.
func (o GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationPtrOutput) ClipPercentUpperbound() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualization) *float64 {
		if v == nil {
			return nil
		}
		return v.ClipPercentUpperbound
	}).(pulumi.Float64PtrOutput)
}

// The color scheme used for the highlighted areas. Defaults to PINK_GREEN for Integrated Gradients attribution, which shows positive attributions in green and negative in pink. Defaults to VIRIDIS for XRAI attribution, which highlights the most influential regions in yellow and the least influential in blue.
func (o GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationPtrOutput) ColorMap() GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationColorMapPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualization) *GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationColorMap {
		if v == nil {
			return nil
		}
		return v.ColorMap
	}).(GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationColorMapPtrOutput)
}

// How the original image is displayed in the visualization. Adjusting the overlay can help increase visual clarity if the original image makes it difficult to view the visualization. Defaults to NONE.
func (o GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationPtrOutput) OverlayType() GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationOverlayTypePtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualization) *GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationOverlayType {
		if v == nil {
			return nil
		}
		return v.OverlayType
	}).(GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationOverlayTypePtrOutput)
}

// Whether to only highlight pixels with positive contributions, negative or both. Defaults to POSITIVE.
func (o GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationPtrOutput) Polarity() GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationPolarityPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualization) *GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationPolarity {
		if v == nil {
			return nil
		}
		return v.Polarity
	}).(GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationPolarityPtrOutput)
}

// Type of the image visualization. Only applicable to Integrated Gradients attribution. OUTLINES shows regions of attribution, while PIXELS shows per-pixel attribution. Defaults to OUTLINES.
func (o GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationPtrOutput) Type() GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationTypePtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualization) *GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationType {
		if v == nil {
			return nil
		}
		return v.Type
	}).(GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationTypePtrOutput)
}

// Visualization configurations for image explanation.
type GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationResponse struct {
	// Excludes attributions below the specified percentile, from the highlighted areas. Defaults to 62.
	ClipPercentLowerbound float64 `pulumi:"clipPercentLowerbound"`
	// Excludes attributions above the specified percentile from the highlighted areas. Using the clip_percent_upperbound and clip_percent_lowerbound together can be useful for filtering out noise and making it easier to see areas of strong attribution. Defaults to 99.9.
	ClipPercentUpperbound float64 `pulumi:"clipPercentUpperbound"`
	// The color scheme used for the highlighted areas. Defaults to PINK_GREEN for Integrated Gradients attribution, which shows positive attributions in green and negative in pink. Defaults to VIRIDIS for XRAI attribution, which highlights the most influential regions in yellow and the least influential in blue.
	ColorMap string `pulumi:"colorMap"`
	// How the original image is displayed in the visualization. Adjusting the overlay can help increase visual clarity if the original image makes it difficult to view the visualization. Defaults to NONE.
	OverlayType string `pulumi:"overlayType"`
	// Whether to only highlight pixels with positive contributions, negative or both. Defaults to POSITIVE.
	Polarity string `pulumi:"polarity"`
	// Type of the image visualization. Only applicable to Integrated Gradients attribution. OUTLINES shows regions of attribution, while PIXELS shows per-pixel attribution. Defaults to OUTLINES.
	Type string `pulumi:"type"`
}

// Visualization configurations for image explanation.
type GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationResponseOutput) ToGoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationResponseOutput() GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationResponseOutput) ToGoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationResponseOutput {
	return o
}

// Excludes attributions below the specified percentile, from the highlighted areas. Defaults to 62.
func (o GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationResponseOutput) ClipPercentLowerbound() pulumi.Float64Output {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationResponse) float64 {
		return v.ClipPercentLowerbound
	}).(pulumi.Float64Output)
}

// Excludes attributions above the specified percentile from the highlighted areas. Using the clip_percent_upperbound and clip_percent_lowerbound together can be useful for filtering out noise and making it easier to see areas of strong attribution. Defaults to 99.9.
func (o GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationResponseOutput) ClipPercentUpperbound() pulumi.Float64Output {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationResponse) float64 {
		return v.ClipPercentUpperbound
	}).(pulumi.Float64Output)
}

// The color scheme used for the highlighted areas. Defaults to PINK_GREEN for Integrated Gradients attribution, which shows positive attributions in green and negative in pink. Defaults to VIRIDIS for XRAI attribution, which highlights the most influential regions in yellow and the least influential in blue.
func (o GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationResponseOutput) ColorMap() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationResponse) string {
		return v.ColorMap
	}).(pulumi.StringOutput)
}

// How the original image is displayed in the visualization. Adjusting the overlay can help increase visual clarity if the original image makes it difficult to view the visualization. Defaults to NONE.
func (o GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationResponseOutput) OverlayType() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationResponse) string {
		return v.OverlayType
	}).(pulumi.StringOutput)
}

// Whether to only highlight pixels with positive contributions, negative or both. Defaults to POSITIVE.
func (o GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationResponseOutput) Polarity() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationResponse) string {
		return v.Polarity
	}).(pulumi.StringOutput)
}

// Type of the image visualization. Only applicable to Integrated Gradients attribution. OUTLINES shows regions of attribution, while PIXELS shows per-pixel attribution. Defaults to OUTLINES.
func (o GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationResponseOutput) Type() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationResponse) string {
		return v.Type
	}).(pulumi.StringOutput)
}

// Metadata of the prediction output to be explained.
type GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadata struct {
	// Specify a field name in the prediction to look for the display name. Use this if the prediction contains the display names for the outputs. The display names in the prediction must have the same shape of the outputs, so that it can be located by Attribution.output_index for a specific output.
	DisplayNameMappingKey *string `pulumi:"displayNameMappingKey"`
	// Static mapping between the index and display name. Use this if the outputs are a deterministic n-dimensional array, e.g. a list of scores of all the classes in a pre-defined order for a multi-classification Model. It's not feasible if the outputs are non-deterministic, e.g. the Model produces top-k classes or sort the outputs by their values. The shape of the value must be an n-dimensional array of strings. The number of dimensions must match that of the outputs to be explained. The Attribution.output_display_name is populated by locating in the mapping with Attribution.output_index.
	IndexDisplayNameMapping interface{} `pulumi:"indexDisplayNameMapping"`
	// Name of the output tensor. Required and is only applicable to Vertex AI provided images for Tensorflow.
	OutputTensorName *string `pulumi:"outputTensorName"`
}

// GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataInput is an input type that accepts GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataArgs and GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataInput` via:
//
//	GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataArgs{...}
type GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataOutput() GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataOutput
	ToGoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataOutput
}

// Metadata of the prediction output to be explained.
type GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataArgs struct {
	// Specify a field name in the prediction to look for the display name. Use this if the prediction contains the display names for the outputs. The display names in the prediction must have the same shape of the outputs, so that it can be located by Attribution.output_index for a specific output.
	DisplayNameMappingKey pulumi.StringPtrInput `pulumi:"displayNameMappingKey"`
	// Static mapping between the index and display name. Use this if the outputs are a deterministic n-dimensional array, e.g. a list of scores of all the classes in a pre-defined order for a multi-classification Model. It's not feasible if the outputs are non-deterministic, e.g. the Model produces top-k classes or sort the outputs by their values. The shape of the value must be an n-dimensional array of strings. The number of dimensions must match that of the outputs to be explained. The Attribution.output_display_name is populated by locating in the mapping with Attribution.output_index.
	IndexDisplayNameMapping pulumi.Input `pulumi:"indexDisplayNameMapping"`
	// Name of the output tensor. Required and is only applicable to Vertex AI provided images for Tensorflow.
	OutputTensorName pulumi.StringPtrInput `pulumi:"outputTensorName"`
}

func (GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadata)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataArgs) ToGoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataOutput() GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataOutput {
	return i.ToGoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataArgs) ToGoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataOutput)
}

func (i GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataArgs) ToGoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataPtrOutput() GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataArgs) ToGoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataOutput).ToGoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataArgs, GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataPtr and GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataPtrOutput() GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataPtrOutput
	ToGoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataPtrOutput
}

type googleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataPtrType GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataArgs

func GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataPtr(v *GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataArgs) GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataPtrInput {
	return (*googleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataPtrType)(v)
}

func (*googleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadata)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataPtrType) ToGoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataPtrOutput() GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataPtrType) ToGoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataPtrOutput)
}

// Metadata of the prediction output to be explained.
type GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadata)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataOutput) ToGoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataOutput() GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataOutput) ToGoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataOutput) ToGoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataPtrOutput() GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataOutput) ToGoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadata) *GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadata {
		return &v
	}).(GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataPtrOutput)
}

// Specify a field name in the prediction to look for the display name. Use this if the prediction contains the display names for the outputs. The display names in the prediction must have the same shape of the outputs, so that it can be located by Attribution.output_index for a specific output.
func (o GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataOutput) DisplayNameMappingKey() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadata) *string {
		return v.DisplayNameMappingKey
	}).(pulumi.StringPtrOutput)
}

// Static mapping between the index and display name. Use this if the outputs are a deterministic n-dimensional array, e.g. a list of scores of all the classes in a pre-defined order for a multi-classification Model. It's not feasible if the outputs are non-deterministic, e.g. the Model produces top-k classes or sort the outputs by their values. The shape of the value must be an n-dimensional array of strings. The number of dimensions must match that of the outputs to be explained. The Attribution.output_display_name is populated by locating in the mapping with Attribution.output_index.
func (o GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataOutput) IndexDisplayNameMapping() pulumi.AnyOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadata) interface{} {
		return v.IndexDisplayNameMapping
	}).(pulumi.AnyOutput)
}

// Name of the output tensor. Required and is only applicable to Vertex AI provided images for Tensorflow.
func (o GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataOutput) OutputTensorName() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadata) *string {
		return v.OutputTensorName
	}).(pulumi.StringPtrOutput)
}

type GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadata)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataPtrOutput) ToGoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataPtrOutput() GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataPtrOutput) ToGoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataPtrOutput) Elem() GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadata) GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadata {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadata
		return ret
	}).(GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataOutput)
}

// Specify a field name in the prediction to look for the display name. Use this if the prediction contains the display names for the outputs. The display names in the prediction must have the same shape of the outputs, so that it can be located by Attribution.output_index for a specific output.
func (o GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataPtrOutput) DisplayNameMappingKey() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadata) *string {
		if v == nil {
			return nil
		}
		return v.DisplayNameMappingKey
	}).(pulumi.StringPtrOutput)
}

// Static mapping between the index and display name. Use this if the outputs are a deterministic n-dimensional array, e.g. a list of scores of all the classes in a pre-defined order for a multi-classification Model. It's not feasible if the outputs are non-deterministic, e.g. the Model produces top-k classes or sort the outputs by their values. The shape of the value must be an n-dimensional array of strings. The number of dimensions must match that of the outputs to be explained. The Attribution.output_display_name is populated by locating in the mapping with Attribution.output_index.
func (o GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataPtrOutput) IndexDisplayNameMapping() pulumi.AnyOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadata) interface{} {
		if v == nil {
			return nil
		}
		return v.IndexDisplayNameMapping
	}).(pulumi.AnyOutput)
}

// Name of the output tensor. Required and is only applicable to Vertex AI provided images for Tensorflow.
func (o GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataPtrOutput) OutputTensorName() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadata) *string {
		if v == nil {
			return nil
		}
		return v.OutputTensorName
	}).(pulumi.StringPtrOutput)
}

// Metadata of the prediction output to be explained.
type GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataResponse struct {
	// Specify a field name in the prediction to look for the display name. Use this if the prediction contains the display names for the outputs. The display names in the prediction must have the same shape of the outputs, so that it can be located by Attribution.output_index for a specific output.
	DisplayNameMappingKey string `pulumi:"displayNameMappingKey"`
	// Static mapping between the index and display name. Use this if the outputs are a deterministic n-dimensional array, e.g. a list of scores of all the classes in a pre-defined order for a multi-classification Model. It's not feasible if the outputs are non-deterministic, e.g. the Model produces top-k classes or sort the outputs by their values. The shape of the value must be an n-dimensional array of strings. The number of dimensions must match that of the outputs to be explained. The Attribution.output_display_name is populated by locating in the mapping with Attribution.output_index.
	IndexDisplayNameMapping interface{} `pulumi:"indexDisplayNameMapping"`
	// Name of the output tensor. Required and is only applicable to Vertex AI provided images for Tensorflow.
	OutputTensorName string `pulumi:"outputTensorName"`
}

// Metadata of the prediction output to be explained.
type GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataResponseOutput) ToGoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataResponseOutput() GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataResponseOutput) ToGoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataResponseOutput {
	return o
}

// Specify a field name in the prediction to look for the display name. Use this if the prediction contains the display names for the outputs. The display names in the prediction must have the same shape of the outputs, so that it can be located by Attribution.output_index for a specific output.
func (o GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataResponseOutput) DisplayNameMappingKey() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataResponse) string {
		return v.DisplayNameMappingKey
	}).(pulumi.StringOutput)
}

// Static mapping between the index and display name. Use this if the outputs are a deterministic n-dimensional array, e.g. a list of scores of all the classes in a pre-defined order for a multi-classification Model. It's not feasible if the outputs are non-deterministic, e.g. the Model produces top-k classes or sort the outputs by their values. The shape of the value must be an n-dimensional array of strings. The number of dimensions must match that of the outputs to be explained. The Attribution.output_display_name is populated by locating in the mapping with Attribution.output_index.
func (o GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataResponseOutput) IndexDisplayNameMapping() pulumi.AnyOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataResponse) interface{} {
		return v.IndexDisplayNameMapping
	}).(pulumi.AnyOutput)
}

// Name of the output tensor. Required and is only applicable to Vertex AI provided images for Tensorflow.
func (o GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataResponseOutput) OutputTensorName() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataResponse) string {
		return v.OutputTensorName
	}).(pulumi.StringOutput)
}

// Metadata describing the Model's input and output for explanation.
type GoogleCloudAiplatformV1beta1ExplanationMetadataResponse struct {
	// Points to a YAML file stored on Google Cloud Storage describing the format of the feature attributions. The schema is defined as an OpenAPI 3.0.2 [Schema Object](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject). AutoML tabular Models always have this field populated by Vertex AI. Note: The URI given on output may be different, including the URI scheme, than the one given on input. The output URI will point to a location where the user only has a read access.
	FeatureAttributionsSchemaUri string `pulumi:"featureAttributionsSchemaUri"`
	// Map from feature names to feature input metadata. Keys are the name of the features. Values are the specification of the feature. An empty InputMetadata is valid. It describes a text feature which has the name specified as the key in ExplanationMetadata.inputs. The baseline of the empty feature is chosen by Vertex AI. For Vertex AI-provided Tensorflow images, the key can be any friendly name of the feature. Once specified, featureAttributions are keyed by this key (if not grouped with another feature). For custom images, the key must match with the key in instance.
	Inputs GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataResponse `pulumi:"inputs"`
	// Name of the source to generate embeddings for example based explanations.
	LatentSpaceSource string `pulumi:"latentSpaceSource"`
	// Map from output names to output metadata. For Vertex AI-provided Tensorflow images, keys can be any user defined string that consists of any UTF-8 characters. For custom images, keys are the name of the output field in the prediction to be explained. Currently only one key is allowed.
	Outputs GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataResponse `pulumi:"outputs"`
}

// Metadata describing the Model's input and output for explanation.
type GoogleCloudAiplatformV1beta1ExplanationMetadataResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ExplanationMetadataResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ExplanationMetadataResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ExplanationMetadataResponseOutput) ToGoogleCloudAiplatformV1beta1ExplanationMetadataResponseOutput() GoogleCloudAiplatformV1beta1ExplanationMetadataResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ExplanationMetadataResponseOutput) ToGoogleCloudAiplatformV1beta1ExplanationMetadataResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ExplanationMetadataResponseOutput {
	return o
}

// Points to a YAML file stored on Google Cloud Storage describing the format of the feature attributions. The schema is defined as an OpenAPI 3.0.2 [Schema Object](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject). AutoML tabular Models always have this field populated by Vertex AI. Note: The URI given on output may be different, including the URI scheme, than the one given on input. The output URI will point to a location where the user only has a read access.
func (o GoogleCloudAiplatformV1beta1ExplanationMetadataResponseOutput) FeatureAttributionsSchemaUri() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ExplanationMetadataResponse) string {
		return v.FeatureAttributionsSchemaUri
	}).(pulumi.StringOutput)
}

// Map from feature names to feature input metadata. Keys are the name of the features. Values are the specification of the feature. An empty InputMetadata is valid. It describes a text feature which has the name specified as the key in ExplanationMetadata.inputs. The baseline of the empty feature is chosen by Vertex AI. For Vertex AI-provided Tensorflow images, the key can be any friendly name of the feature. Once specified, featureAttributions are keyed by this key (if not grouped with another feature). For custom images, the key must match with the key in instance.
func (o GoogleCloudAiplatformV1beta1ExplanationMetadataResponseOutput) Inputs() GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ExplanationMetadataResponse) GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataResponse {
		return v.Inputs
	}).(GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataResponseOutput)
}

// Name of the source to generate embeddings for example based explanations.
func (o GoogleCloudAiplatformV1beta1ExplanationMetadataResponseOutput) LatentSpaceSource() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ExplanationMetadataResponse) string { return v.LatentSpaceSource }).(pulumi.StringOutput)
}

// Map from output names to output metadata. For Vertex AI-provided Tensorflow images, keys can be any user defined string that consists of any UTF-8 characters. For custom images, keys are the name of the output field in the prediction to be explained. Currently only one key is allowed.
func (o GoogleCloudAiplatformV1beta1ExplanationMetadataResponseOutput) Outputs() GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ExplanationMetadataResponse) GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataResponse {
		return v.Outputs
	}).(GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataResponseOutput)
}

// Parameters to configure explaining for Model's predictions.
type GoogleCloudAiplatformV1beta1ExplanationParameters struct {
	// Example-based explanations that returns the nearest neighbors from the provided dataset.
	Examples *GoogleCloudAiplatformV1beta1Examples `pulumi:"examples"`
	// An attribution method that computes Aumann-Shapley values taking advantage of the model's fully differentiable structure. Refer to this paper for more details: https://arxiv.org/abs/1703.01365
	IntegratedGradientsAttribution *GoogleCloudAiplatformV1beta1IntegratedGradientsAttribution `pulumi:"integratedGradientsAttribution"`
	// If populated, only returns attributions that have output_index contained in output_indices. It must be an ndarray of integers, with the same shape of the output it's explaining. If not populated, returns attributions for top_k indices of outputs. If neither top_k nor output_indices is populated, returns the argmax index of the outputs. Only applicable to Models that predict multiple outputs (e,g, multi-class Models that predict multiple classes).
	OutputIndices []interface{} `pulumi:"outputIndices"`
	// An attribution method that approximates Shapley values for features that contribute to the label being predicted. A sampling strategy is used to approximate the value rather than considering all subsets of features. Refer to this paper for model details: https://arxiv.org/abs/1306.4265.
	SampledShapleyAttribution *GoogleCloudAiplatformV1beta1SampledShapleyAttribution `pulumi:"sampledShapleyAttribution"`
	// If populated, returns attributions for top K indices of outputs (defaults to 1). Only applies to Models that predicts more than one outputs (e,g, multi-class Models). When set to -1, returns explanations for all outputs.
	TopK *int `pulumi:"topK"`
	// An attribution method that redistributes Integrated Gradients attribution to segmented regions, taking advantage of the model's fully differentiable structure. Refer to this paper for more details: https://arxiv.org/abs/1906.02825 XRAI currently performs better on natural images, like a picture of a house or an animal. If the images are taken in artificial environments, like a lab or manufacturing line, or from diagnostic equipment, like x-rays or quality-control cameras, use Integrated Gradients instead.
	XraiAttribution *GoogleCloudAiplatformV1beta1XraiAttribution `pulumi:"xraiAttribution"`
}

// GoogleCloudAiplatformV1beta1ExplanationParametersInput is an input type that accepts GoogleCloudAiplatformV1beta1ExplanationParametersArgs and GoogleCloudAiplatformV1beta1ExplanationParametersOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1ExplanationParametersInput` via:
//
//	GoogleCloudAiplatformV1beta1ExplanationParametersArgs{...}
type GoogleCloudAiplatformV1beta1ExplanationParametersInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1ExplanationParametersOutput() GoogleCloudAiplatformV1beta1ExplanationParametersOutput
	ToGoogleCloudAiplatformV1beta1ExplanationParametersOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1ExplanationParametersOutput
}

// Parameters to configure explaining for Model's predictions.
type GoogleCloudAiplatformV1beta1ExplanationParametersArgs struct {
	// Example-based explanations that returns the nearest neighbors from the provided dataset.
	Examples GoogleCloudAiplatformV1beta1ExamplesPtrInput `pulumi:"examples"`
	// An attribution method that computes Aumann-Shapley values taking advantage of the model's fully differentiable structure. Refer to this paper for more details: https://arxiv.org/abs/1703.01365
	IntegratedGradientsAttribution GoogleCloudAiplatformV1beta1IntegratedGradientsAttributionPtrInput `pulumi:"integratedGradientsAttribution"`
	// If populated, only returns attributions that have output_index contained in output_indices. It must be an ndarray of integers, with the same shape of the output it's explaining. If not populated, returns attributions for top_k indices of outputs. If neither top_k nor output_indices is populated, returns the argmax index of the outputs. Only applicable to Models that predict multiple outputs (e,g, multi-class Models that predict multiple classes).
	OutputIndices pulumi.ArrayInput `pulumi:"outputIndices"`
	// An attribution method that approximates Shapley values for features that contribute to the label being predicted. A sampling strategy is used to approximate the value rather than considering all subsets of features. Refer to this paper for model details: https://arxiv.org/abs/1306.4265.
	SampledShapleyAttribution GoogleCloudAiplatformV1beta1SampledShapleyAttributionPtrInput `pulumi:"sampledShapleyAttribution"`
	// If populated, returns attributions for top K indices of outputs (defaults to 1). Only applies to Models that predicts more than one outputs (e,g, multi-class Models). When set to -1, returns explanations for all outputs.
	TopK pulumi.IntPtrInput `pulumi:"topK"`
	// An attribution method that redistributes Integrated Gradients attribution to segmented regions, taking advantage of the model's fully differentiable structure. Refer to this paper for more details: https://arxiv.org/abs/1906.02825 XRAI currently performs better on natural images, like a picture of a house or an animal. If the images are taken in artificial environments, like a lab or manufacturing line, or from diagnostic equipment, like x-rays or quality-control cameras, use Integrated Gradients instead.
	XraiAttribution GoogleCloudAiplatformV1beta1XraiAttributionPtrInput `pulumi:"xraiAttribution"`
}

func (GoogleCloudAiplatformV1beta1ExplanationParametersArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ExplanationParameters)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1ExplanationParametersArgs) ToGoogleCloudAiplatformV1beta1ExplanationParametersOutput() GoogleCloudAiplatformV1beta1ExplanationParametersOutput {
	return i.ToGoogleCloudAiplatformV1beta1ExplanationParametersOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1ExplanationParametersArgs) ToGoogleCloudAiplatformV1beta1ExplanationParametersOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ExplanationParametersOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ExplanationParametersOutput)
}

func (i GoogleCloudAiplatformV1beta1ExplanationParametersArgs) ToGoogleCloudAiplatformV1beta1ExplanationParametersPtrOutput() GoogleCloudAiplatformV1beta1ExplanationParametersPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1ExplanationParametersPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1ExplanationParametersArgs) ToGoogleCloudAiplatformV1beta1ExplanationParametersPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ExplanationParametersPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ExplanationParametersOutput).ToGoogleCloudAiplatformV1beta1ExplanationParametersPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1ExplanationParametersPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1ExplanationParametersArgs, GoogleCloudAiplatformV1beta1ExplanationParametersPtr and GoogleCloudAiplatformV1beta1ExplanationParametersPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1ExplanationParametersPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1ExplanationParametersArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1ExplanationParametersPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1ExplanationParametersPtrOutput() GoogleCloudAiplatformV1beta1ExplanationParametersPtrOutput
	ToGoogleCloudAiplatformV1beta1ExplanationParametersPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1ExplanationParametersPtrOutput
}

type googleCloudAiplatformV1beta1ExplanationParametersPtrType GoogleCloudAiplatformV1beta1ExplanationParametersArgs

func GoogleCloudAiplatformV1beta1ExplanationParametersPtr(v *GoogleCloudAiplatformV1beta1ExplanationParametersArgs) GoogleCloudAiplatformV1beta1ExplanationParametersPtrInput {
	return (*googleCloudAiplatformV1beta1ExplanationParametersPtrType)(v)
}

func (*googleCloudAiplatformV1beta1ExplanationParametersPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1ExplanationParameters)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1ExplanationParametersPtrType) ToGoogleCloudAiplatformV1beta1ExplanationParametersPtrOutput() GoogleCloudAiplatformV1beta1ExplanationParametersPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1ExplanationParametersPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1ExplanationParametersPtrType) ToGoogleCloudAiplatformV1beta1ExplanationParametersPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ExplanationParametersPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ExplanationParametersPtrOutput)
}

// Parameters to configure explaining for Model's predictions.
type GoogleCloudAiplatformV1beta1ExplanationParametersOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ExplanationParametersOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ExplanationParameters)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ExplanationParametersOutput) ToGoogleCloudAiplatformV1beta1ExplanationParametersOutput() GoogleCloudAiplatformV1beta1ExplanationParametersOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ExplanationParametersOutput) ToGoogleCloudAiplatformV1beta1ExplanationParametersOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ExplanationParametersOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ExplanationParametersOutput) ToGoogleCloudAiplatformV1beta1ExplanationParametersPtrOutput() GoogleCloudAiplatformV1beta1ExplanationParametersPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1ExplanationParametersPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1ExplanationParametersOutput) ToGoogleCloudAiplatformV1beta1ExplanationParametersPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ExplanationParametersPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1ExplanationParameters) *GoogleCloudAiplatformV1beta1ExplanationParameters {
		return &v
	}).(GoogleCloudAiplatformV1beta1ExplanationParametersPtrOutput)
}

// Example-based explanations that returns the nearest neighbors from the provided dataset.
func (o GoogleCloudAiplatformV1beta1ExplanationParametersOutput) Examples() GoogleCloudAiplatformV1beta1ExamplesPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ExplanationParameters) *GoogleCloudAiplatformV1beta1Examples {
		return v.Examples
	}).(GoogleCloudAiplatformV1beta1ExamplesPtrOutput)
}

// An attribution method that computes Aumann-Shapley values taking advantage of the model's fully differentiable structure. Refer to this paper for more details: https://arxiv.org/abs/1703.01365
func (o GoogleCloudAiplatformV1beta1ExplanationParametersOutput) IntegratedGradientsAttribution() GoogleCloudAiplatformV1beta1IntegratedGradientsAttributionPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ExplanationParameters) *GoogleCloudAiplatformV1beta1IntegratedGradientsAttribution {
		return v.IntegratedGradientsAttribution
	}).(GoogleCloudAiplatformV1beta1IntegratedGradientsAttributionPtrOutput)
}

// If populated, only returns attributions that have output_index contained in output_indices. It must be an ndarray of integers, with the same shape of the output it's explaining. If not populated, returns attributions for top_k indices of outputs. If neither top_k nor output_indices is populated, returns the argmax index of the outputs. Only applicable to Models that predict multiple outputs (e,g, multi-class Models that predict multiple classes).
func (o GoogleCloudAiplatformV1beta1ExplanationParametersOutput) OutputIndices() pulumi.ArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ExplanationParameters) []interface{} { return v.OutputIndices }).(pulumi.ArrayOutput)
}

// An attribution method that approximates Shapley values for features that contribute to the label being predicted. A sampling strategy is used to approximate the value rather than considering all subsets of features. Refer to this paper for model details: https://arxiv.org/abs/1306.4265.
func (o GoogleCloudAiplatformV1beta1ExplanationParametersOutput) SampledShapleyAttribution() GoogleCloudAiplatformV1beta1SampledShapleyAttributionPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ExplanationParameters) *GoogleCloudAiplatformV1beta1SampledShapleyAttribution {
		return v.SampledShapleyAttribution
	}).(GoogleCloudAiplatformV1beta1SampledShapleyAttributionPtrOutput)
}

// If populated, returns attributions for top K indices of outputs (defaults to 1). Only applies to Models that predicts more than one outputs (e,g, multi-class Models). When set to -1, returns explanations for all outputs.
func (o GoogleCloudAiplatformV1beta1ExplanationParametersOutput) TopK() pulumi.IntPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ExplanationParameters) *int { return v.TopK }).(pulumi.IntPtrOutput)
}

// An attribution method that redistributes Integrated Gradients attribution to segmented regions, taking advantage of the model's fully differentiable structure. Refer to this paper for more details: https://arxiv.org/abs/1906.02825 XRAI currently performs better on natural images, like a picture of a house or an animal. If the images are taken in artificial environments, like a lab or manufacturing line, or from diagnostic equipment, like x-rays or quality-control cameras, use Integrated Gradients instead.
func (o GoogleCloudAiplatformV1beta1ExplanationParametersOutput) XraiAttribution() GoogleCloudAiplatformV1beta1XraiAttributionPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ExplanationParameters) *GoogleCloudAiplatformV1beta1XraiAttribution {
		return v.XraiAttribution
	}).(GoogleCloudAiplatformV1beta1XraiAttributionPtrOutput)
}

type GoogleCloudAiplatformV1beta1ExplanationParametersPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ExplanationParametersPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1ExplanationParameters)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ExplanationParametersPtrOutput) ToGoogleCloudAiplatformV1beta1ExplanationParametersPtrOutput() GoogleCloudAiplatformV1beta1ExplanationParametersPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ExplanationParametersPtrOutput) ToGoogleCloudAiplatformV1beta1ExplanationParametersPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ExplanationParametersPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ExplanationParametersPtrOutput) Elem() GoogleCloudAiplatformV1beta1ExplanationParametersOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ExplanationParameters) GoogleCloudAiplatformV1beta1ExplanationParameters {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1ExplanationParameters
		return ret
	}).(GoogleCloudAiplatformV1beta1ExplanationParametersOutput)
}

// Example-based explanations that returns the nearest neighbors from the provided dataset.
func (o GoogleCloudAiplatformV1beta1ExplanationParametersPtrOutput) Examples() GoogleCloudAiplatformV1beta1ExamplesPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ExplanationParameters) *GoogleCloudAiplatformV1beta1Examples {
		if v == nil {
			return nil
		}
		return v.Examples
	}).(GoogleCloudAiplatformV1beta1ExamplesPtrOutput)
}

// An attribution method that computes Aumann-Shapley values taking advantage of the model's fully differentiable structure. Refer to this paper for more details: https://arxiv.org/abs/1703.01365
func (o GoogleCloudAiplatformV1beta1ExplanationParametersPtrOutput) IntegratedGradientsAttribution() GoogleCloudAiplatformV1beta1IntegratedGradientsAttributionPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ExplanationParameters) *GoogleCloudAiplatformV1beta1IntegratedGradientsAttribution {
		if v == nil {
			return nil
		}
		return v.IntegratedGradientsAttribution
	}).(GoogleCloudAiplatformV1beta1IntegratedGradientsAttributionPtrOutput)
}

// If populated, only returns attributions that have output_index contained in output_indices. It must be an ndarray of integers, with the same shape of the output it's explaining. If not populated, returns attributions for top_k indices of outputs. If neither top_k nor output_indices is populated, returns the argmax index of the outputs. Only applicable to Models that predict multiple outputs (e,g, multi-class Models that predict multiple classes).
func (o GoogleCloudAiplatformV1beta1ExplanationParametersPtrOutput) OutputIndices() pulumi.ArrayOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ExplanationParameters) []interface{} {
		if v == nil {
			return nil
		}
		return v.OutputIndices
	}).(pulumi.ArrayOutput)
}

// An attribution method that approximates Shapley values for features that contribute to the label being predicted. A sampling strategy is used to approximate the value rather than considering all subsets of features. Refer to this paper for model details: https://arxiv.org/abs/1306.4265.
func (o GoogleCloudAiplatformV1beta1ExplanationParametersPtrOutput) SampledShapleyAttribution() GoogleCloudAiplatformV1beta1SampledShapleyAttributionPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ExplanationParameters) *GoogleCloudAiplatformV1beta1SampledShapleyAttribution {
		if v == nil {
			return nil
		}
		return v.SampledShapleyAttribution
	}).(GoogleCloudAiplatformV1beta1SampledShapleyAttributionPtrOutput)
}

// If populated, returns attributions for top K indices of outputs (defaults to 1). Only applies to Models that predicts more than one outputs (e,g, multi-class Models). When set to -1, returns explanations for all outputs.
func (o GoogleCloudAiplatformV1beta1ExplanationParametersPtrOutput) TopK() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ExplanationParameters) *int {
		if v == nil {
			return nil
		}
		return v.TopK
	}).(pulumi.IntPtrOutput)
}

// An attribution method that redistributes Integrated Gradients attribution to segmented regions, taking advantage of the model's fully differentiable structure. Refer to this paper for more details: https://arxiv.org/abs/1906.02825 XRAI currently performs better on natural images, like a picture of a house or an animal. If the images are taken in artificial environments, like a lab or manufacturing line, or from diagnostic equipment, like x-rays or quality-control cameras, use Integrated Gradients instead.
func (o GoogleCloudAiplatformV1beta1ExplanationParametersPtrOutput) XraiAttribution() GoogleCloudAiplatformV1beta1XraiAttributionPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ExplanationParameters) *GoogleCloudAiplatformV1beta1XraiAttribution {
		if v == nil {
			return nil
		}
		return v.XraiAttribution
	}).(GoogleCloudAiplatformV1beta1XraiAttributionPtrOutput)
}

// Parameters to configure explaining for Model's predictions.
type GoogleCloudAiplatformV1beta1ExplanationParametersResponse struct {
	// Example-based explanations that returns the nearest neighbors from the provided dataset.
	Examples GoogleCloudAiplatformV1beta1ExamplesResponse `pulumi:"examples"`
	// An attribution method that computes Aumann-Shapley values taking advantage of the model's fully differentiable structure. Refer to this paper for more details: https://arxiv.org/abs/1703.01365
	IntegratedGradientsAttribution GoogleCloudAiplatformV1beta1IntegratedGradientsAttributionResponse `pulumi:"integratedGradientsAttribution"`
	// If populated, only returns attributions that have output_index contained in output_indices. It must be an ndarray of integers, with the same shape of the output it's explaining. If not populated, returns attributions for top_k indices of outputs. If neither top_k nor output_indices is populated, returns the argmax index of the outputs. Only applicable to Models that predict multiple outputs (e,g, multi-class Models that predict multiple classes).
	OutputIndices []interface{} `pulumi:"outputIndices"`
	// An attribution method that approximates Shapley values for features that contribute to the label being predicted. A sampling strategy is used to approximate the value rather than considering all subsets of features. Refer to this paper for model details: https://arxiv.org/abs/1306.4265.
	SampledShapleyAttribution GoogleCloudAiplatformV1beta1SampledShapleyAttributionResponse `pulumi:"sampledShapleyAttribution"`
	// If populated, returns attributions for top K indices of outputs (defaults to 1). Only applies to Models that predicts more than one outputs (e,g, multi-class Models). When set to -1, returns explanations for all outputs.
	TopK int `pulumi:"topK"`
	// An attribution method that redistributes Integrated Gradients attribution to segmented regions, taking advantage of the model's fully differentiable structure. Refer to this paper for more details: https://arxiv.org/abs/1906.02825 XRAI currently performs better on natural images, like a picture of a house or an animal. If the images are taken in artificial environments, like a lab or manufacturing line, or from diagnostic equipment, like x-rays or quality-control cameras, use Integrated Gradients instead.
	XraiAttribution GoogleCloudAiplatformV1beta1XraiAttributionResponse `pulumi:"xraiAttribution"`
}

// Parameters to configure explaining for Model's predictions.
type GoogleCloudAiplatformV1beta1ExplanationParametersResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ExplanationParametersResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ExplanationParametersResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ExplanationParametersResponseOutput) ToGoogleCloudAiplatformV1beta1ExplanationParametersResponseOutput() GoogleCloudAiplatformV1beta1ExplanationParametersResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ExplanationParametersResponseOutput) ToGoogleCloudAiplatformV1beta1ExplanationParametersResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ExplanationParametersResponseOutput {
	return o
}

// Example-based explanations that returns the nearest neighbors from the provided dataset.
func (o GoogleCloudAiplatformV1beta1ExplanationParametersResponseOutput) Examples() GoogleCloudAiplatformV1beta1ExamplesResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ExplanationParametersResponse) GoogleCloudAiplatformV1beta1ExamplesResponse {
		return v.Examples
	}).(GoogleCloudAiplatformV1beta1ExamplesResponseOutput)
}

// An attribution method that computes Aumann-Shapley values taking advantage of the model's fully differentiable structure. Refer to this paper for more details: https://arxiv.org/abs/1703.01365
func (o GoogleCloudAiplatformV1beta1ExplanationParametersResponseOutput) IntegratedGradientsAttribution() GoogleCloudAiplatformV1beta1IntegratedGradientsAttributionResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ExplanationParametersResponse) GoogleCloudAiplatformV1beta1IntegratedGradientsAttributionResponse {
		return v.IntegratedGradientsAttribution
	}).(GoogleCloudAiplatformV1beta1IntegratedGradientsAttributionResponseOutput)
}

// If populated, only returns attributions that have output_index contained in output_indices. It must be an ndarray of integers, with the same shape of the output it's explaining. If not populated, returns attributions for top_k indices of outputs. If neither top_k nor output_indices is populated, returns the argmax index of the outputs. Only applicable to Models that predict multiple outputs (e,g, multi-class Models that predict multiple classes).
func (o GoogleCloudAiplatformV1beta1ExplanationParametersResponseOutput) OutputIndices() pulumi.ArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ExplanationParametersResponse) []interface{} {
		return v.OutputIndices
	}).(pulumi.ArrayOutput)
}

// An attribution method that approximates Shapley values for features that contribute to the label being predicted. A sampling strategy is used to approximate the value rather than considering all subsets of features. Refer to this paper for model details: https://arxiv.org/abs/1306.4265.
func (o GoogleCloudAiplatformV1beta1ExplanationParametersResponseOutput) SampledShapleyAttribution() GoogleCloudAiplatformV1beta1SampledShapleyAttributionResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ExplanationParametersResponse) GoogleCloudAiplatformV1beta1SampledShapleyAttributionResponse {
		return v.SampledShapleyAttribution
	}).(GoogleCloudAiplatformV1beta1SampledShapleyAttributionResponseOutput)
}

// If populated, returns attributions for top K indices of outputs (defaults to 1). Only applies to Models that predicts more than one outputs (e,g, multi-class Models). When set to -1, returns explanations for all outputs.
func (o GoogleCloudAiplatformV1beta1ExplanationParametersResponseOutput) TopK() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ExplanationParametersResponse) int { return v.TopK }).(pulumi.IntOutput)
}

// An attribution method that redistributes Integrated Gradients attribution to segmented regions, taking advantage of the model's fully differentiable structure. Refer to this paper for more details: https://arxiv.org/abs/1906.02825 XRAI currently performs better on natural images, like a picture of a house or an animal. If the images are taken in artificial environments, like a lab or manufacturing line, or from diagnostic equipment, like x-rays or quality-control cameras, use Integrated Gradients instead.
func (o GoogleCloudAiplatformV1beta1ExplanationParametersResponseOutput) XraiAttribution() GoogleCloudAiplatformV1beta1XraiAttributionResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ExplanationParametersResponse) GoogleCloudAiplatformV1beta1XraiAttributionResponse {
		return v.XraiAttribution
	}).(GoogleCloudAiplatformV1beta1XraiAttributionResponseOutput)
}

// Specification of Model explanation.
type GoogleCloudAiplatformV1beta1ExplanationSpec struct {
	// Optional. Metadata describing the Model's input and output for explanation.
	Metadata *GoogleCloudAiplatformV1beta1ExplanationMetadata `pulumi:"metadata"`
	// Parameters that configure explaining of the Model's predictions.
	Parameters GoogleCloudAiplatformV1beta1ExplanationParameters `pulumi:"parameters"`
}

// GoogleCloudAiplatformV1beta1ExplanationSpecInput is an input type that accepts GoogleCloudAiplatformV1beta1ExplanationSpecArgs and GoogleCloudAiplatformV1beta1ExplanationSpecOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1ExplanationSpecInput` via:
//
//	GoogleCloudAiplatformV1beta1ExplanationSpecArgs{...}
type GoogleCloudAiplatformV1beta1ExplanationSpecInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1ExplanationSpecOutput() GoogleCloudAiplatformV1beta1ExplanationSpecOutput
	ToGoogleCloudAiplatformV1beta1ExplanationSpecOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1ExplanationSpecOutput
}

// Specification of Model explanation.
type GoogleCloudAiplatformV1beta1ExplanationSpecArgs struct {
	// Optional. Metadata describing the Model's input and output for explanation.
	Metadata GoogleCloudAiplatformV1beta1ExplanationMetadataPtrInput `pulumi:"metadata"`
	// Parameters that configure explaining of the Model's predictions.
	Parameters GoogleCloudAiplatformV1beta1ExplanationParametersInput `pulumi:"parameters"`
}

func (GoogleCloudAiplatformV1beta1ExplanationSpecArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ExplanationSpec)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1ExplanationSpecArgs) ToGoogleCloudAiplatformV1beta1ExplanationSpecOutput() GoogleCloudAiplatformV1beta1ExplanationSpecOutput {
	return i.ToGoogleCloudAiplatformV1beta1ExplanationSpecOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1ExplanationSpecArgs) ToGoogleCloudAiplatformV1beta1ExplanationSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ExplanationSpecOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ExplanationSpecOutput)
}

func (i GoogleCloudAiplatformV1beta1ExplanationSpecArgs) ToGoogleCloudAiplatformV1beta1ExplanationSpecPtrOutput() GoogleCloudAiplatformV1beta1ExplanationSpecPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1ExplanationSpecPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1ExplanationSpecArgs) ToGoogleCloudAiplatformV1beta1ExplanationSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ExplanationSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ExplanationSpecOutput).ToGoogleCloudAiplatformV1beta1ExplanationSpecPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1ExplanationSpecPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1ExplanationSpecArgs, GoogleCloudAiplatformV1beta1ExplanationSpecPtr and GoogleCloudAiplatformV1beta1ExplanationSpecPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1ExplanationSpecPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1ExplanationSpecArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1ExplanationSpecPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1ExplanationSpecPtrOutput() GoogleCloudAiplatformV1beta1ExplanationSpecPtrOutput
	ToGoogleCloudAiplatformV1beta1ExplanationSpecPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1ExplanationSpecPtrOutput
}

type googleCloudAiplatformV1beta1ExplanationSpecPtrType GoogleCloudAiplatformV1beta1ExplanationSpecArgs

func GoogleCloudAiplatformV1beta1ExplanationSpecPtr(v *GoogleCloudAiplatformV1beta1ExplanationSpecArgs) GoogleCloudAiplatformV1beta1ExplanationSpecPtrInput {
	return (*googleCloudAiplatformV1beta1ExplanationSpecPtrType)(v)
}

func (*googleCloudAiplatformV1beta1ExplanationSpecPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1ExplanationSpec)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1ExplanationSpecPtrType) ToGoogleCloudAiplatformV1beta1ExplanationSpecPtrOutput() GoogleCloudAiplatformV1beta1ExplanationSpecPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1ExplanationSpecPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1ExplanationSpecPtrType) ToGoogleCloudAiplatformV1beta1ExplanationSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ExplanationSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ExplanationSpecPtrOutput)
}

// Specification of Model explanation.
type GoogleCloudAiplatformV1beta1ExplanationSpecOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ExplanationSpecOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ExplanationSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ExplanationSpecOutput) ToGoogleCloudAiplatformV1beta1ExplanationSpecOutput() GoogleCloudAiplatformV1beta1ExplanationSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ExplanationSpecOutput) ToGoogleCloudAiplatformV1beta1ExplanationSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ExplanationSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ExplanationSpecOutput) ToGoogleCloudAiplatformV1beta1ExplanationSpecPtrOutput() GoogleCloudAiplatformV1beta1ExplanationSpecPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1ExplanationSpecPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1ExplanationSpecOutput) ToGoogleCloudAiplatformV1beta1ExplanationSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ExplanationSpecPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1ExplanationSpec) *GoogleCloudAiplatformV1beta1ExplanationSpec {
		return &v
	}).(GoogleCloudAiplatformV1beta1ExplanationSpecPtrOutput)
}

// Optional. Metadata describing the Model's input and output for explanation.
func (o GoogleCloudAiplatformV1beta1ExplanationSpecOutput) Metadata() GoogleCloudAiplatformV1beta1ExplanationMetadataPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ExplanationSpec) *GoogleCloudAiplatformV1beta1ExplanationMetadata {
		return v.Metadata
	}).(GoogleCloudAiplatformV1beta1ExplanationMetadataPtrOutput)
}

// Parameters that configure explaining of the Model's predictions.
func (o GoogleCloudAiplatformV1beta1ExplanationSpecOutput) Parameters() GoogleCloudAiplatformV1beta1ExplanationParametersOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ExplanationSpec) GoogleCloudAiplatformV1beta1ExplanationParameters {
		return v.Parameters
	}).(GoogleCloudAiplatformV1beta1ExplanationParametersOutput)
}

type GoogleCloudAiplatformV1beta1ExplanationSpecPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ExplanationSpecPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1ExplanationSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ExplanationSpecPtrOutput) ToGoogleCloudAiplatformV1beta1ExplanationSpecPtrOutput() GoogleCloudAiplatformV1beta1ExplanationSpecPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ExplanationSpecPtrOutput) ToGoogleCloudAiplatformV1beta1ExplanationSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ExplanationSpecPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ExplanationSpecPtrOutput) Elem() GoogleCloudAiplatformV1beta1ExplanationSpecOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ExplanationSpec) GoogleCloudAiplatformV1beta1ExplanationSpec {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1ExplanationSpec
		return ret
	}).(GoogleCloudAiplatformV1beta1ExplanationSpecOutput)
}

// Optional. Metadata describing the Model's input and output for explanation.
func (o GoogleCloudAiplatformV1beta1ExplanationSpecPtrOutput) Metadata() GoogleCloudAiplatformV1beta1ExplanationMetadataPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ExplanationSpec) *GoogleCloudAiplatformV1beta1ExplanationMetadata {
		if v == nil {
			return nil
		}
		return v.Metadata
	}).(GoogleCloudAiplatformV1beta1ExplanationMetadataPtrOutput)
}

// Parameters that configure explaining of the Model's predictions.
func (o GoogleCloudAiplatformV1beta1ExplanationSpecPtrOutput) Parameters() GoogleCloudAiplatformV1beta1ExplanationParametersPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ExplanationSpec) *GoogleCloudAiplatformV1beta1ExplanationParameters {
		if v == nil {
			return nil
		}
		return &v.Parameters
	}).(GoogleCloudAiplatformV1beta1ExplanationParametersPtrOutput)
}

// Specification of Model explanation.
type GoogleCloudAiplatformV1beta1ExplanationSpecResponse struct {
	// Optional. Metadata describing the Model's input and output for explanation.
	Metadata GoogleCloudAiplatformV1beta1ExplanationMetadataResponse `pulumi:"metadata"`
	// Parameters that configure explaining of the Model's predictions.
	Parameters GoogleCloudAiplatformV1beta1ExplanationParametersResponse `pulumi:"parameters"`
}

// Specification of Model explanation.
type GoogleCloudAiplatformV1beta1ExplanationSpecResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ExplanationSpecResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ExplanationSpecResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ExplanationSpecResponseOutput) ToGoogleCloudAiplatformV1beta1ExplanationSpecResponseOutput() GoogleCloudAiplatformV1beta1ExplanationSpecResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ExplanationSpecResponseOutput) ToGoogleCloudAiplatformV1beta1ExplanationSpecResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ExplanationSpecResponseOutput {
	return o
}

// Optional. Metadata describing the Model's input and output for explanation.
func (o GoogleCloudAiplatformV1beta1ExplanationSpecResponseOutput) Metadata() GoogleCloudAiplatformV1beta1ExplanationMetadataResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ExplanationSpecResponse) GoogleCloudAiplatformV1beta1ExplanationMetadataResponse {
		return v.Metadata
	}).(GoogleCloudAiplatformV1beta1ExplanationMetadataResponseOutput)
}

// Parameters that configure explaining of the Model's predictions.
func (o GoogleCloudAiplatformV1beta1ExplanationSpecResponseOutput) Parameters() GoogleCloudAiplatformV1beta1ExplanationParametersResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ExplanationSpecResponse) GoogleCloudAiplatformV1beta1ExplanationParametersResponse {
		return v.Parameters
	}).(GoogleCloudAiplatformV1beta1ExplanationParametersResponseOutput)
}

// Input source type for BigQuery Tables and Views.
type GoogleCloudAiplatformV1beta1FeatureGroupBigQuery struct {
	// Immutable. The BigQuery source URI that points to either a BigQuery Table or View.
	BigQuerySource GoogleCloudAiplatformV1beta1BigQuerySource `pulumi:"bigQuerySource"`
	// Optional. Columns to construct entity_id / row keys. Currently only supports 1 entity_id_column. If not provided defaults to `entity_id`.
	EntityIdColumns []string `pulumi:"entityIdColumns"`
}

// GoogleCloudAiplatformV1beta1FeatureGroupBigQueryInput is an input type that accepts GoogleCloudAiplatformV1beta1FeatureGroupBigQueryArgs and GoogleCloudAiplatformV1beta1FeatureGroupBigQueryOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1FeatureGroupBigQueryInput` via:
//
//	GoogleCloudAiplatformV1beta1FeatureGroupBigQueryArgs{...}
type GoogleCloudAiplatformV1beta1FeatureGroupBigQueryInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1FeatureGroupBigQueryOutput() GoogleCloudAiplatformV1beta1FeatureGroupBigQueryOutput
	ToGoogleCloudAiplatformV1beta1FeatureGroupBigQueryOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1FeatureGroupBigQueryOutput
}

// Input source type for BigQuery Tables and Views.
type GoogleCloudAiplatformV1beta1FeatureGroupBigQueryArgs struct {
	// Immutable. The BigQuery source URI that points to either a BigQuery Table or View.
	BigQuerySource GoogleCloudAiplatformV1beta1BigQuerySourceInput `pulumi:"bigQuerySource"`
	// Optional. Columns to construct entity_id / row keys. Currently only supports 1 entity_id_column. If not provided defaults to `entity_id`.
	EntityIdColumns pulumi.StringArrayInput `pulumi:"entityIdColumns"`
}

func (GoogleCloudAiplatformV1beta1FeatureGroupBigQueryArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeatureGroupBigQuery)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1FeatureGroupBigQueryArgs) ToGoogleCloudAiplatformV1beta1FeatureGroupBigQueryOutput() GoogleCloudAiplatformV1beta1FeatureGroupBigQueryOutput {
	return i.ToGoogleCloudAiplatformV1beta1FeatureGroupBigQueryOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1FeatureGroupBigQueryArgs) ToGoogleCloudAiplatformV1beta1FeatureGroupBigQueryOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureGroupBigQueryOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1FeatureGroupBigQueryOutput)
}

func (i GoogleCloudAiplatformV1beta1FeatureGroupBigQueryArgs) ToGoogleCloudAiplatformV1beta1FeatureGroupBigQueryPtrOutput() GoogleCloudAiplatformV1beta1FeatureGroupBigQueryPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1FeatureGroupBigQueryPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1FeatureGroupBigQueryArgs) ToGoogleCloudAiplatformV1beta1FeatureGroupBigQueryPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureGroupBigQueryPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1FeatureGroupBigQueryOutput).ToGoogleCloudAiplatformV1beta1FeatureGroupBigQueryPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1FeatureGroupBigQueryPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1FeatureGroupBigQueryArgs, GoogleCloudAiplatformV1beta1FeatureGroupBigQueryPtr and GoogleCloudAiplatformV1beta1FeatureGroupBigQueryPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1FeatureGroupBigQueryPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1FeatureGroupBigQueryArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1FeatureGroupBigQueryPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1FeatureGroupBigQueryPtrOutput() GoogleCloudAiplatformV1beta1FeatureGroupBigQueryPtrOutput
	ToGoogleCloudAiplatformV1beta1FeatureGroupBigQueryPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1FeatureGroupBigQueryPtrOutput
}

type googleCloudAiplatformV1beta1FeatureGroupBigQueryPtrType GoogleCloudAiplatformV1beta1FeatureGroupBigQueryArgs

func GoogleCloudAiplatformV1beta1FeatureGroupBigQueryPtr(v *GoogleCloudAiplatformV1beta1FeatureGroupBigQueryArgs) GoogleCloudAiplatformV1beta1FeatureGroupBigQueryPtrInput {
	return (*googleCloudAiplatformV1beta1FeatureGroupBigQueryPtrType)(v)
}

func (*googleCloudAiplatformV1beta1FeatureGroupBigQueryPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1FeatureGroupBigQuery)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1FeatureGroupBigQueryPtrType) ToGoogleCloudAiplatformV1beta1FeatureGroupBigQueryPtrOutput() GoogleCloudAiplatformV1beta1FeatureGroupBigQueryPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1FeatureGroupBigQueryPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1FeatureGroupBigQueryPtrType) ToGoogleCloudAiplatformV1beta1FeatureGroupBigQueryPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureGroupBigQueryPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1FeatureGroupBigQueryPtrOutput)
}

// Input source type for BigQuery Tables and Views.
type GoogleCloudAiplatformV1beta1FeatureGroupBigQueryOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1FeatureGroupBigQueryOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeatureGroupBigQuery)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1FeatureGroupBigQueryOutput) ToGoogleCloudAiplatformV1beta1FeatureGroupBigQueryOutput() GoogleCloudAiplatformV1beta1FeatureGroupBigQueryOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeatureGroupBigQueryOutput) ToGoogleCloudAiplatformV1beta1FeatureGroupBigQueryOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureGroupBigQueryOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeatureGroupBigQueryOutput) ToGoogleCloudAiplatformV1beta1FeatureGroupBigQueryPtrOutput() GoogleCloudAiplatformV1beta1FeatureGroupBigQueryPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1FeatureGroupBigQueryPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1FeatureGroupBigQueryOutput) ToGoogleCloudAiplatformV1beta1FeatureGroupBigQueryPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureGroupBigQueryPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1FeatureGroupBigQuery) *GoogleCloudAiplatformV1beta1FeatureGroupBigQuery {
		return &v
	}).(GoogleCloudAiplatformV1beta1FeatureGroupBigQueryPtrOutput)
}

// Immutable. The BigQuery source URI that points to either a BigQuery Table or View.
func (o GoogleCloudAiplatformV1beta1FeatureGroupBigQueryOutput) BigQuerySource() GoogleCloudAiplatformV1beta1BigQuerySourceOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeatureGroupBigQuery) GoogleCloudAiplatformV1beta1BigQuerySource {
		return v.BigQuerySource
	}).(GoogleCloudAiplatformV1beta1BigQuerySourceOutput)
}

// Optional. Columns to construct entity_id / row keys. Currently only supports 1 entity_id_column. If not provided defaults to `entity_id`.
func (o GoogleCloudAiplatformV1beta1FeatureGroupBigQueryOutput) EntityIdColumns() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeatureGroupBigQuery) []string { return v.EntityIdColumns }).(pulumi.StringArrayOutput)
}

type GoogleCloudAiplatformV1beta1FeatureGroupBigQueryPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1FeatureGroupBigQueryPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1FeatureGroupBigQuery)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1FeatureGroupBigQueryPtrOutput) ToGoogleCloudAiplatformV1beta1FeatureGroupBigQueryPtrOutput() GoogleCloudAiplatformV1beta1FeatureGroupBigQueryPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeatureGroupBigQueryPtrOutput) ToGoogleCloudAiplatformV1beta1FeatureGroupBigQueryPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureGroupBigQueryPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeatureGroupBigQueryPtrOutput) Elem() GoogleCloudAiplatformV1beta1FeatureGroupBigQueryOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1FeatureGroupBigQuery) GoogleCloudAiplatformV1beta1FeatureGroupBigQuery {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1FeatureGroupBigQuery
		return ret
	}).(GoogleCloudAiplatformV1beta1FeatureGroupBigQueryOutput)
}

// Immutable. The BigQuery source URI that points to either a BigQuery Table or View.
func (o GoogleCloudAiplatformV1beta1FeatureGroupBigQueryPtrOutput) BigQuerySource() GoogleCloudAiplatformV1beta1BigQuerySourcePtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1FeatureGroupBigQuery) *GoogleCloudAiplatformV1beta1BigQuerySource {
		if v == nil {
			return nil
		}
		return &v.BigQuerySource
	}).(GoogleCloudAiplatformV1beta1BigQuerySourcePtrOutput)
}

// Optional. Columns to construct entity_id / row keys. Currently only supports 1 entity_id_column. If not provided defaults to `entity_id`.
func (o GoogleCloudAiplatformV1beta1FeatureGroupBigQueryPtrOutput) EntityIdColumns() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1FeatureGroupBigQuery) []string {
		if v == nil {
			return nil
		}
		return v.EntityIdColumns
	}).(pulumi.StringArrayOutput)
}

// Input source type for BigQuery Tables and Views.
type GoogleCloudAiplatformV1beta1FeatureGroupBigQueryResponse struct {
	// Immutable. The BigQuery source URI that points to either a BigQuery Table or View.
	BigQuerySource GoogleCloudAiplatformV1beta1BigQuerySourceResponse `pulumi:"bigQuerySource"`
	// Optional. Columns to construct entity_id / row keys. Currently only supports 1 entity_id_column. If not provided defaults to `entity_id`.
	EntityIdColumns []string `pulumi:"entityIdColumns"`
}

// Input source type for BigQuery Tables and Views.
type GoogleCloudAiplatformV1beta1FeatureGroupBigQueryResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1FeatureGroupBigQueryResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeatureGroupBigQueryResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1FeatureGroupBigQueryResponseOutput) ToGoogleCloudAiplatformV1beta1FeatureGroupBigQueryResponseOutput() GoogleCloudAiplatformV1beta1FeatureGroupBigQueryResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeatureGroupBigQueryResponseOutput) ToGoogleCloudAiplatformV1beta1FeatureGroupBigQueryResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureGroupBigQueryResponseOutput {
	return o
}

// Immutable. The BigQuery source URI that points to either a BigQuery Table or View.
func (o GoogleCloudAiplatformV1beta1FeatureGroupBigQueryResponseOutput) BigQuerySource() GoogleCloudAiplatformV1beta1BigQuerySourceResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeatureGroupBigQueryResponse) GoogleCloudAiplatformV1beta1BigQuerySourceResponse {
		return v.BigQuerySource
	}).(GoogleCloudAiplatformV1beta1BigQuerySourceResponseOutput)
}

// Optional. Columns to construct entity_id / row keys. Currently only supports 1 entity_id_column. If not provided defaults to `entity_id`.
func (o GoogleCloudAiplatformV1beta1FeatureGroupBigQueryResponseOutput) EntityIdColumns() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeatureGroupBigQueryResponse) []string { return v.EntityIdColumns }).(pulumi.StringArrayOutput)
}

// A list of historical SnapshotAnalysis or ImportFeaturesAnalysis stats requested by user, sorted by FeatureStatsAnomaly.start_time descending.
type GoogleCloudAiplatformV1beta1FeatureMonitoringStatsAnomalyResponse struct {
	// The stats and anomalies generated at specific timestamp.
	FeatureStatsAnomaly GoogleCloudAiplatformV1beta1FeatureStatsAnomalyResponse `pulumi:"featureStatsAnomaly"`
	// The objective for each stats.
	Objective string `pulumi:"objective"`
}

// A list of historical SnapshotAnalysis or ImportFeaturesAnalysis stats requested by user, sorted by FeatureStatsAnomaly.start_time descending.
type GoogleCloudAiplatformV1beta1FeatureMonitoringStatsAnomalyResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1FeatureMonitoringStatsAnomalyResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeatureMonitoringStatsAnomalyResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1FeatureMonitoringStatsAnomalyResponseOutput) ToGoogleCloudAiplatformV1beta1FeatureMonitoringStatsAnomalyResponseOutput() GoogleCloudAiplatformV1beta1FeatureMonitoringStatsAnomalyResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeatureMonitoringStatsAnomalyResponseOutput) ToGoogleCloudAiplatformV1beta1FeatureMonitoringStatsAnomalyResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureMonitoringStatsAnomalyResponseOutput {
	return o
}

// The stats and anomalies generated at specific timestamp.
func (o GoogleCloudAiplatformV1beta1FeatureMonitoringStatsAnomalyResponseOutput) FeatureStatsAnomaly() GoogleCloudAiplatformV1beta1FeatureStatsAnomalyResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeatureMonitoringStatsAnomalyResponse) GoogleCloudAiplatformV1beta1FeatureStatsAnomalyResponse {
		return v.FeatureStatsAnomaly
	}).(GoogleCloudAiplatformV1beta1FeatureStatsAnomalyResponseOutput)
}

// The objective for each stats.
func (o GoogleCloudAiplatformV1beta1FeatureMonitoringStatsAnomalyResponseOutput) Objective() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeatureMonitoringStatsAnomalyResponse) string { return v.Objective }).(pulumi.StringOutput)
}

type GoogleCloudAiplatformV1beta1FeatureMonitoringStatsAnomalyResponseArrayOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1FeatureMonitoringStatsAnomalyResponseArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1beta1FeatureMonitoringStatsAnomalyResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1FeatureMonitoringStatsAnomalyResponseArrayOutput) ToGoogleCloudAiplatformV1beta1FeatureMonitoringStatsAnomalyResponseArrayOutput() GoogleCloudAiplatformV1beta1FeatureMonitoringStatsAnomalyResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeatureMonitoringStatsAnomalyResponseArrayOutput) ToGoogleCloudAiplatformV1beta1FeatureMonitoringStatsAnomalyResponseArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureMonitoringStatsAnomalyResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeatureMonitoringStatsAnomalyResponseArrayOutput) Index(i pulumi.IntInput) GoogleCloudAiplatformV1beta1FeatureMonitoringStatsAnomalyResponseOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GoogleCloudAiplatformV1beta1FeatureMonitoringStatsAnomalyResponse {
		return vs[0].([]GoogleCloudAiplatformV1beta1FeatureMonitoringStatsAnomalyResponse)[vs[1].(int)]
	}).(GoogleCloudAiplatformV1beta1FeatureMonitoringStatsAnomalyResponseOutput)
}

// Noise sigma by features. Noise sigma represents the standard deviation of the gaussian kernel that will be used to add noise to interpolated inputs prior to computing gradients.
type GoogleCloudAiplatformV1beta1FeatureNoiseSigma struct {
	// Noise sigma per feature. No noise is added to features that are not set.
	NoiseSigma []GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeature `pulumi:"noiseSigma"`
}

// GoogleCloudAiplatformV1beta1FeatureNoiseSigmaInput is an input type that accepts GoogleCloudAiplatformV1beta1FeatureNoiseSigmaArgs and GoogleCloudAiplatformV1beta1FeatureNoiseSigmaOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1FeatureNoiseSigmaInput` via:
//
//	GoogleCloudAiplatformV1beta1FeatureNoiseSigmaArgs{...}
type GoogleCloudAiplatformV1beta1FeatureNoiseSigmaInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1FeatureNoiseSigmaOutput() GoogleCloudAiplatformV1beta1FeatureNoiseSigmaOutput
	ToGoogleCloudAiplatformV1beta1FeatureNoiseSigmaOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1FeatureNoiseSigmaOutput
}

// Noise sigma by features. Noise sigma represents the standard deviation of the gaussian kernel that will be used to add noise to interpolated inputs prior to computing gradients.
type GoogleCloudAiplatformV1beta1FeatureNoiseSigmaArgs struct {
	// Noise sigma per feature. No noise is added to features that are not set.
	NoiseSigma GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureArrayInput `pulumi:"noiseSigma"`
}

func (GoogleCloudAiplatformV1beta1FeatureNoiseSigmaArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeatureNoiseSigma)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1FeatureNoiseSigmaArgs) ToGoogleCloudAiplatformV1beta1FeatureNoiseSigmaOutput() GoogleCloudAiplatformV1beta1FeatureNoiseSigmaOutput {
	return i.ToGoogleCloudAiplatformV1beta1FeatureNoiseSigmaOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1FeatureNoiseSigmaArgs) ToGoogleCloudAiplatformV1beta1FeatureNoiseSigmaOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureNoiseSigmaOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1FeatureNoiseSigmaOutput)
}

func (i GoogleCloudAiplatformV1beta1FeatureNoiseSigmaArgs) ToGoogleCloudAiplatformV1beta1FeatureNoiseSigmaPtrOutput() GoogleCloudAiplatformV1beta1FeatureNoiseSigmaPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1FeatureNoiseSigmaPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1FeatureNoiseSigmaArgs) ToGoogleCloudAiplatformV1beta1FeatureNoiseSigmaPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureNoiseSigmaPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1FeatureNoiseSigmaOutput).ToGoogleCloudAiplatformV1beta1FeatureNoiseSigmaPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1FeatureNoiseSigmaPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1FeatureNoiseSigmaArgs, GoogleCloudAiplatformV1beta1FeatureNoiseSigmaPtr and GoogleCloudAiplatformV1beta1FeatureNoiseSigmaPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1FeatureNoiseSigmaPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1FeatureNoiseSigmaArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1FeatureNoiseSigmaPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1FeatureNoiseSigmaPtrOutput() GoogleCloudAiplatformV1beta1FeatureNoiseSigmaPtrOutput
	ToGoogleCloudAiplatformV1beta1FeatureNoiseSigmaPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1FeatureNoiseSigmaPtrOutput
}

type googleCloudAiplatformV1beta1FeatureNoiseSigmaPtrType GoogleCloudAiplatformV1beta1FeatureNoiseSigmaArgs

func GoogleCloudAiplatformV1beta1FeatureNoiseSigmaPtr(v *GoogleCloudAiplatformV1beta1FeatureNoiseSigmaArgs) GoogleCloudAiplatformV1beta1FeatureNoiseSigmaPtrInput {
	return (*googleCloudAiplatformV1beta1FeatureNoiseSigmaPtrType)(v)
}

func (*googleCloudAiplatformV1beta1FeatureNoiseSigmaPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1FeatureNoiseSigma)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1FeatureNoiseSigmaPtrType) ToGoogleCloudAiplatformV1beta1FeatureNoiseSigmaPtrOutput() GoogleCloudAiplatformV1beta1FeatureNoiseSigmaPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1FeatureNoiseSigmaPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1FeatureNoiseSigmaPtrType) ToGoogleCloudAiplatformV1beta1FeatureNoiseSigmaPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureNoiseSigmaPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1FeatureNoiseSigmaPtrOutput)
}

// Noise sigma by features. Noise sigma represents the standard deviation of the gaussian kernel that will be used to add noise to interpolated inputs prior to computing gradients.
type GoogleCloudAiplatformV1beta1FeatureNoiseSigmaOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1FeatureNoiseSigmaOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeatureNoiseSigma)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1FeatureNoiseSigmaOutput) ToGoogleCloudAiplatformV1beta1FeatureNoiseSigmaOutput() GoogleCloudAiplatformV1beta1FeatureNoiseSigmaOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeatureNoiseSigmaOutput) ToGoogleCloudAiplatformV1beta1FeatureNoiseSigmaOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureNoiseSigmaOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeatureNoiseSigmaOutput) ToGoogleCloudAiplatformV1beta1FeatureNoiseSigmaPtrOutput() GoogleCloudAiplatformV1beta1FeatureNoiseSigmaPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1FeatureNoiseSigmaPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1FeatureNoiseSigmaOutput) ToGoogleCloudAiplatformV1beta1FeatureNoiseSigmaPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureNoiseSigmaPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1FeatureNoiseSigma) *GoogleCloudAiplatformV1beta1FeatureNoiseSigma {
		return &v
	}).(GoogleCloudAiplatformV1beta1FeatureNoiseSigmaPtrOutput)
}

// Noise sigma per feature. No noise is added to features that are not set.
func (o GoogleCloudAiplatformV1beta1FeatureNoiseSigmaOutput) NoiseSigma() GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeatureNoiseSigma) []GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeature {
		return v.NoiseSigma
	}).(GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureArrayOutput)
}

type GoogleCloudAiplatformV1beta1FeatureNoiseSigmaPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1FeatureNoiseSigmaPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1FeatureNoiseSigma)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1FeatureNoiseSigmaPtrOutput) ToGoogleCloudAiplatformV1beta1FeatureNoiseSigmaPtrOutput() GoogleCloudAiplatformV1beta1FeatureNoiseSigmaPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeatureNoiseSigmaPtrOutput) ToGoogleCloudAiplatformV1beta1FeatureNoiseSigmaPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureNoiseSigmaPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeatureNoiseSigmaPtrOutput) Elem() GoogleCloudAiplatformV1beta1FeatureNoiseSigmaOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1FeatureNoiseSigma) GoogleCloudAiplatformV1beta1FeatureNoiseSigma {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1FeatureNoiseSigma
		return ret
	}).(GoogleCloudAiplatformV1beta1FeatureNoiseSigmaOutput)
}

// Noise sigma per feature. No noise is added to features that are not set.
func (o GoogleCloudAiplatformV1beta1FeatureNoiseSigmaPtrOutput) NoiseSigma() GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureArrayOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1FeatureNoiseSigma) []GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeature {
		if v == nil {
			return nil
		}
		return v.NoiseSigma
	}).(GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureArrayOutput)
}

// Noise sigma for a single feature.
type GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeature struct {
	// The name of the input feature for which noise sigma is provided. The features are defined in explanation metadata inputs.
	Name *string `pulumi:"name"`
	// This represents the standard deviation of the Gaussian kernel that will be used to add noise to the feature prior to computing gradients. Similar to noise_sigma but represents the noise added to the current feature. Defaults to 0.1.
	Sigma *float64 `pulumi:"sigma"`
}

// GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureInput is an input type that accepts GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureArgs and GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureInput` via:
//
//	GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureArgs{...}
type GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureOutput() GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureOutput
	ToGoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureOutput
}

// Noise sigma for a single feature.
type GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureArgs struct {
	// The name of the input feature for which noise sigma is provided. The features are defined in explanation metadata inputs.
	Name pulumi.StringPtrInput `pulumi:"name"`
	// This represents the standard deviation of the Gaussian kernel that will be used to add noise to the feature prior to computing gradients. Similar to noise_sigma but represents the noise added to the current feature. Defaults to 0.1.
	Sigma pulumi.Float64PtrInput `pulumi:"sigma"`
}

func (GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeature)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureArgs) ToGoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureOutput() GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureOutput {
	return i.ToGoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureArgs) ToGoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureOutput)
}

// GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureArrayInput is an input type that accepts GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureArray and GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureArrayOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureArrayInput` via:
//
//	GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureArray{ GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureArgs{...} }
type GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureArrayInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureArrayOutput() GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureArrayOutput
	ToGoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureArrayOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureArrayOutput
}

type GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureArray []GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureInput

func (GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeature)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureArray) ToGoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureArrayOutput() GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureArrayOutput {
	return i.ToGoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureArrayOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureArray) ToGoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureArrayOutput)
}

// Noise sigma for a single feature.
type GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeature)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureOutput) ToGoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureOutput() GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureOutput) ToGoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureOutput {
	return o
}

// The name of the input feature for which noise sigma is provided. The features are defined in explanation metadata inputs.
func (o GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureOutput) Name() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeature) *string { return v.Name }).(pulumi.StringPtrOutput)
}

// This represents the standard deviation of the Gaussian kernel that will be used to add noise to the feature prior to computing gradients. Similar to noise_sigma but represents the noise added to the current feature. Defaults to 0.1.
func (o GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureOutput) Sigma() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeature) *float64 { return v.Sigma }).(pulumi.Float64PtrOutput)
}

type GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureArrayOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeature)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureArrayOutput) ToGoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureArrayOutput() GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureArrayOutput) ToGoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureArrayOutput) Index(i pulumi.IntInput) GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeature {
		return vs[0].([]GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeature)[vs[1].(int)]
	}).(GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureOutput)
}

// Noise sigma for a single feature.
type GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureResponse struct {
	// The name of the input feature for which noise sigma is provided. The features are defined in explanation metadata inputs.
	Name string `pulumi:"name"`
	// This represents the standard deviation of the Gaussian kernel that will be used to add noise to the feature prior to computing gradients. Similar to noise_sigma but represents the noise added to the current feature. Defaults to 0.1.
	Sigma float64 `pulumi:"sigma"`
}

// Noise sigma for a single feature.
type GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureResponseOutput) ToGoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureResponseOutput() GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureResponseOutput) ToGoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureResponseOutput {
	return o
}

// The name of the input feature for which noise sigma is provided. The features are defined in explanation metadata inputs.
func (o GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureResponseOutput) Name() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureResponse) string {
		return v.Name
	}).(pulumi.StringOutput)
}

// This represents the standard deviation of the Gaussian kernel that will be used to add noise to the feature prior to computing gradients. Similar to noise_sigma but represents the noise added to the current feature. Defaults to 0.1.
func (o GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureResponseOutput) Sigma() pulumi.Float64Output {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureResponse) float64 {
		return v.Sigma
	}).(pulumi.Float64Output)
}

type GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureResponseArrayOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureResponseArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureResponseArrayOutput) ToGoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureResponseArrayOutput() GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureResponseArrayOutput) ToGoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureResponseArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureResponseArrayOutput) Index(i pulumi.IntInput) GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureResponseOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureResponse {
		return vs[0].([]GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureResponse)[vs[1].(int)]
	}).(GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureResponseOutput)
}

// Noise sigma by features. Noise sigma represents the standard deviation of the gaussian kernel that will be used to add noise to interpolated inputs prior to computing gradients.
type GoogleCloudAiplatformV1beta1FeatureNoiseSigmaResponse struct {
	// Noise sigma per feature. No noise is added to features that are not set.
	NoiseSigma []GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureResponse `pulumi:"noiseSigma"`
}

// Noise sigma by features. Noise sigma represents the standard deviation of the gaussian kernel that will be used to add noise to interpolated inputs prior to computing gradients.
type GoogleCloudAiplatformV1beta1FeatureNoiseSigmaResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1FeatureNoiseSigmaResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeatureNoiseSigmaResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1FeatureNoiseSigmaResponseOutput) ToGoogleCloudAiplatformV1beta1FeatureNoiseSigmaResponseOutput() GoogleCloudAiplatformV1beta1FeatureNoiseSigmaResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeatureNoiseSigmaResponseOutput) ToGoogleCloudAiplatformV1beta1FeatureNoiseSigmaResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureNoiseSigmaResponseOutput {
	return o
}

// Noise sigma per feature. No noise is added to features that are not set.
func (o GoogleCloudAiplatformV1beta1FeatureNoiseSigmaResponseOutput) NoiseSigma() GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureResponseArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeatureNoiseSigmaResponse) []GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureResponse {
		return v.NoiseSigma
	}).(GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureResponseArrayOutput)
}

type GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtable struct {
	// Autoscaling config applied to Bigtable Instance.
	AutoScaling GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScaling `pulumi:"autoScaling"`
}

// GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableInput is an input type that accepts GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableArgs and GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableInput` via:
//
//	GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableArgs{...}
type GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableOutput() GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableOutput
	ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableOutput
}

type GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableArgs struct {
	// Autoscaling config applied to Bigtable Instance.
	AutoScaling GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingInput `pulumi:"autoScaling"`
}

func (GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtable)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableArgs) ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableOutput() GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableOutput {
	return i.ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableArgs) ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableOutput)
}

func (i GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableArgs) ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtablePtrOutput() GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtablePtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtablePtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableArgs) ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtablePtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtablePtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableOutput).ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtablePtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtablePtrInput is an input type that accepts GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableArgs, GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtablePtr and GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtablePtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtablePtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtablePtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtablePtrOutput() GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtablePtrOutput
	ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtablePtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtablePtrOutput
}

type googleCloudAiplatformV1beta1FeatureOnlineStoreBigtablePtrType GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableArgs

func GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtablePtr(v *GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableArgs) GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtablePtrInput {
	return (*googleCloudAiplatformV1beta1FeatureOnlineStoreBigtablePtrType)(v)
}

func (*googleCloudAiplatformV1beta1FeatureOnlineStoreBigtablePtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtable)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1FeatureOnlineStoreBigtablePtrType) ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtablePtrOutput() GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtablePtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtablePtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1FeatureOnlineStoreBigtablePtrType) ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtablePtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtablePtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtablePtrOutput)
}

type GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtable)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableOutput) ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableOutput() GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableOutput) ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableOutput) ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtablePtrOutput() GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtablePtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtablePtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableOutput) ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtablePtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtablePtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtable) *GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtable {
		return &v
	}).(GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtablePtrOutput)
}

// Autoscaling config applied to Bigtable Instance.
func (o GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableOutput) AutoScaling() GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtable) GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScaling {
		return v.AutoScaling
	}).(GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingOutput)
}

type GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtablePtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtablePtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtable)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtablePtrOutput) ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtablePtrOutput() GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtablePtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtablePtrOutput) ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtablePtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtablePtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtablePtrOutput) Elem() GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtable) GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtable {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtable
		return ret
	}).(GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableOutput)
}

// Autoscaling config applied to Bigtable Instance.
func (o GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtablePtrOutput) AutoScaling() GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtable) *GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScaling {
		if v == nil {
			return nil
		}
		return &v.AutoScaling
	}).(GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingPtrOutput)
}

type GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScaling struct {
	// Optional. A percentage of the cluster's CPU capacity. Can be from 10% to 80%. When a cluster's CPU utilization exceeds the target that you have set, Bigtable immediately adds nodes to the cluster. When CPU utilization is substantially lower than the target, Bigtable removes nodes. If not set will default to 50%.
	CpuUtilizationTarget *int `pulumi:"cpuUtilizationTarget"`
	// The maximum number of nodes to scale up to. Must be greater than or equal to min_node_count, and less than or equal to 10 times of 'min_node_count'.
	MaxNodeCount int `pulumi:"maxNodeCount"`
	// The minimum number of nodes to scale down to. Must be greater than or equal to 1.
	MinNodeCount int `pulumi:"minNodeCount"`
}

// GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingInput is an input type that accepts GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingArgs and GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingInput` via:
//
//	GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingArgs{...}
type GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingOutput() GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingOutput
	ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingOutput
}

type GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingArgs struct {
	// Optional. A percentage of the cluster's CPU capacity. Can be from 10% to 80%. When a cluster's CPU utilization exceeds the target that you have set, Bigtable immediately adds nodes to the cluster. When CPU utilization is substantially lower than the target, Bigtable removes nodes. If not set will default to 50%.
	CpuUtilizationTarget pulumi.IntPtrInput `pulumi:"cpuUtilizationTarget"`
	// The maximum number of nodes to scale up to. Must be greater than or equal to min_node_count, and less than or equal to 10 times of 'min_node_count'.
	MaxNodeCount pulumi.IntInput `pulumi:"maxNodeCount"`
	// The minimum number of nodes to scale down to. Must be greater than or equal to 1.
	MinNodeCount pulumi.IntInput `pulumi:"minNodeCount"`
}

func (GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScaling)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingArgs) ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingOutput() GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingOutput {
	return i.ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingArgs) ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingOutput)
}

func (i GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingArgs) ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingPtrOutput() GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingArgs) ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingOutput).ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingArgs, GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingPtr and GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingPtrOutput() GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingPtrOutput
	ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingPtrOutput
}

type googleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingPtrType GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingArgs

func GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingPtr(v *GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingArgs) GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingPtrInput {
	return (*googleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingPtrType)(v)
}

func (*googleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScaling)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingPtrType) ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingPtrOutput() GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingPtrType) ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingPtrOutput)
}

type GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScaling)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingOutput) ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingOutput() GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingOutput) ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingOutput) ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingPtrOutput() GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingOutput) ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScaling) *GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScaling {
		return &v
	}).(GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingPtrOutput)
}

// Optional. A percentage of the cluster's CPU capacity. Can be from 10% to 80%. When a cluster's CPU utilization exceeds the target that you have set, Bigtable immediately adds nodes to the cluster. When CPU utilization is substantially lower than the target, Bigtable removes nodes. If not set will default to 50%.
func (o GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingOutput) CpuUtilizationTarget() pulumi.IntPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScaling) *int {
		return v.CpuUtilizationTarget
	}).(pulumi.IntPtrOutput)
}

// The maximum number of nodes to scale up to. Must be greater than or equal to min_node_count, and less than or equal to 10 times of 'min_node_count'.
func (o GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingOutput) MaxNodeCount() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScaling) int { return v.MaxNodeCount }).(pulumi.IntOutput)
}

// The minimum number of nodes to scale down to. Must be greater than or equal to 1.
func (o GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingOutput) MinNodeCount() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScaling) int { return v.MinNodeCount }).(pulumi.IntOutput)
}

type GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScaling)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingPtrOutput) ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingPtrOutput() GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingPtrOutput) ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingPtrOutput) Elem() GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScaling) GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScaling {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScaling
		return ret
	}).(GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingOutput)
}

// Optional. A percentage of the cluster's CPU capacity. Can be from 10% to 80%. When a cluster's CPU utilization exceeds the target that you have set, Bigtable immediately adds nodes to the cluster. When CPU utilization is substantially lower than the target, Bigtable removes nodes. If not set will default to 50%.
func (o GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingPtrOutput) CpuUtilizationTarget() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScaling) *int {
		if v == nil {
			return nil
		}
		return v.CpuUtilizationTarget
	}).(pulumi.IntPtrOutput)
}

// The maximum number of nodes to scale up to. Must be greater than or equal to min_node_count, and less than or equal to 10 times of 'min_node_count'.
func (o GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingPtrOutput) MaxNodeCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScaling) *int {
		if v == nil {
			return nil
		}
		return &v.MaxNodeCount
	}).(pulumi.IntPtrOutput)
}

// The minimum number of nodes to scale down to. Must be greater than or equal to 1.
func (o GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingPtrOutput) MinNodeCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScaling) *int {
		if v == nil {
			return nil
		}
		return &v.MinNodeCount
	}).(pulumi.IntPtrOutput)
}

type GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingResponse struct {
	// Optional. A percentage of the cluster's CPU capacity. Can be from 10% to 80%. When a cluster's CPU utilization exceeds the target that you have set, Bigtable immediately adds nodes to the cluster. When CPU utilization is substantially lower than the target, Bigtable removes nodes. If not set will default to 50%.
	CpuUtilizationTarget int `pulumi:"cpuUtilizationTarget"`
	// The maximum number of nodes to scale up to. Must be greater than or equal to min_node_count, and less than or equal to 10 times of 'min_node_count'.
	MaxNodeCount int `pulumi:"maxNodeCount"`
	// The minimum number of nodes to scale down to. Must be greater than or equal to 1.
	MinNodeCount int `pulumi:"minNodeCount"`
}

type GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingResponseOutput) ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingResponseOutput() GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingResponseOutput) ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingResponseOutput {
	return o
}

// Optional. A percentage of the cluster's CPU capacity. Can be from 10% to 80%. When a cluster's CPU utilization exceeds the target that you have set, Bigtable immediately adds nodes to the cluster. When CPU utilization is substantially lower than the target, Bigtable removes nodes. If not set will default to 50%.
func (o GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingResponseOutput) CpuUtilizationTarget() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingResponse) int {
		return v.CpuUtilizationTarget
	}).(pulumi.IntOutput)
}

// The maximum number of nodes to scale up to. Must be greater than or equal to min_node_count, and less than or equal to 10 times of 'min_node_count'.
func (o GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingResponseOutput) MaxNodeCount() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingResponse) int {
		return v.MaxNodeCount
	}).(pulumi.IntOutput)
}

// The minimum number of nodes to scale down to. Must be greater than or equal to 1.
func (o GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingResponseOutput) MinNodeCount() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingResponse) int {
		return v.MinNodeCount
	}).(pulumi.IntOutput)
}

type GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableResponse struct {
	// Autoscaling config applied to Bigtable Instance.
	AutoScaling GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingResponse `pulumi:"autoScaling"`
}

type GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableResponseOutput) ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableResponseOutput() GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableResponseOutput) ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableResponseOutput {
	return o
}

// Autoscaling config applied to Bigtable Instance.
func (o GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableResponseOutput) AutoScaling() GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableResponse) GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingResponse {
		return v.AutoScaling
	}).(GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingResponseOutput)
}

// The dedicated serving endpoint for this FeatureOnlineStore. Only need to set when you choose Optimized storage type or enable EmbeddingManagement. Will use public endpoint by default.
type GoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpoint struct {
	// Optional. Private service connect config. If PrivateServiceConnectConfig.enable_private_service_connect set to true, customers will use private service connection to send request. Otherwise, the connection will set to public endpoint.
	PrivateServiceConnectConfig *GoogleCloudAiplatformV1beta1PrivateServiceConnectConfig `pulumi:"privateServiceConnectConfig"`
}

// GoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointInput is an input type that accepts GoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointArgs and GoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointInput` via:
//
//	GoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointArgs{...}
type GoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointOutput() GoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointOutput
	ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointOutput
}

// The dedicated serving endpoint for this FeatureOnlineStore. Only need to set when you choose Optimized storage type or enable EmbeddingManagement. Will use public endpoint by default.
type GoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointArgs struct {
	// Optional. Private service connect config. If PrivateServiceConnectConfig.enable_private_service_connect set to true, customers will use private service connection to send request. Otherwise, the connection will set to public endpoint.
	PrivateServiceConnectConfig GoogleCloudAiplatformV1beta1PrivateServiceConnectConfigPtrInput `pulumi:"privateServiceConnectConfig"`
}

func (GoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpoint)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointArgs) ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointOutput() GoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointOutput {
	return i.ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointArgs) ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointOutput)
}

func (i GoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointArgs) ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointPtrOutput() GoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointArgs) ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointOutput).ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointArgs, GoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointPtr and GoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointPtrOutput() GoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointPtrOutput
	ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointPtrOutput
}

type googleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointPtrType GoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointArgs

func GoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointPtr(v *GoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointArgs) GoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointPtrInput {
	return (*googleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointPtrType)(v)
}

func (*googleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpoint)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointPtrType) ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointPtrOutput() GoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointPtrType) ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointPtrOutput)
}

// The dedicated serving endpoint for this FeatureOnlineStore. Only need to set when you choose Optimized storage type or enable EmbeddingManagement. Will use public endpoint by default.
type GoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpoint)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointOutput) ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointOutput() GoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointOutput) ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointOutput) ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointPtrOutput() GoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointOutput) ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpoint) *GoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpoint {
		return &v
	}).(GoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointPtrOutput)
}

// Optional. Private service connect config. If PrivateServiceConnectConfig.enable_private_service_connect set to true, customers will use private service connection to send request. Otherwise, the connection will set to public endpoint.
func (o GoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointOutput) PrivateServiceConnectConfig() GoogleCloudAiplatformV1beta1PrivateServiceConnectConfigPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpoint) *GoogleCloudAiplatformV1beta1PrivateServiceConnectConfig {
		return v.PrivateServiceConnectConfig
	}).(GoogleCloudAiplatformV1beta1PrivateServiceConnectConfigPtrOutput)
}

type GoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpoint)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointPtrOutput) ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointPtrOutput() GoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointPtrOutput) ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointPtrOutput) Elem() GoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpoint) GoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpoint {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpoint
		return ret
	}).(GoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointOutput)
}

// Optional. Private service connect config. If PrivateServiceConnectConfig.enable_private_service_connect set to true, customers will use private service connection to send request. Otherwise, the connection will set to public endpoint.
func (o GoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointPtrOutput) PrivateServiceConnectConfig() GoogleCloudAiplatformV1beta1PrivateServiceConnectConfigPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpoint) *GoogleCloudAiplatformV1beta1PrivateServiceConnectConfig {
		if v == nil {
			return nil
		}
		return v.PrivateServiceConnectConfig
	}).(GoogleCloudAiplatformV1beta1PrivateServiceConnectConfigPtrOutput)
}

// The dedicated serving endpoint for this FeatureOnlineStore. Only need to set when you choose Optimized storage type or enable EmbeddingManagement. Will use public endpoint by default.
type GoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointResponse struct {
	// Optional. Private service connect config. If PrivateServiceConnectConfig.enable_private_service_connect set to true, customers will use private service connection to send request. Otherwise, the connection will set to public endpoint.
	PrivateServiceConnectConfig GoogleCloudAiplatformV1beta1PrivateServiceConnectConfigResponse `pulumi:"privateServiceConnectConfig"`
	// This field will be populated with the domain name to use for this FeatureOnlineStore
	PublicEndpointDomainName string `pulumi:"publicEndpointDomainName"`
	// The name of the service attachment resource. Populated if private service connect is enabled and after FeatureViewSync is created.
	ServiceAttachment string `pulumi:"serviceAttachment"`
}

// The dedicated serving endpoint for this FeatureOnlineStore. Only need to set when you choose Optimized storage type or enable EmbeddingManagement. Will use public endpoint by default.
type GoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointResponseOutput) ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointResponseOutput() GoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointResponseOutput) ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointResponseOutput {
	return o
}

// Optional. Private service connect config. If PrivateServiceConnectConfig.enable_private_service_connect set to true, customers will use private service connection to send request. Otherwise, the connection will set to public endpoint.
func (o GoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointResponseOutput) PrivateServiceConnectConfig() GoogleCloudAiplatformV1beta1PrivateServiceConnectConfigResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointResponse) GoogleCloudAiplatformV1beta1PrivateServiceConnectConfigResponse {
		return v.PrivateServiceConnectConfig
	}).(GoogleCloudAiplatformV1beta1PrivateServiceConnectConfigResponseOutput)
}

// This field will be populated with the domain name to use for this FeatureOnlineStore
func (o GoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointResponseOutput) PublicEndpointDomainName() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointResponse) string {
		return v.PublicEndpointDomainName
	}).(pulumi.StringOutput)
}

// The name of the service attachment resource. Populated if private service connect is enabled and after FeatureViewSync is created.
func (o GoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointResponseOutput) ServiceAttachment() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointResponse) string {
		return v.ServiceAttachment
	}).(pulumi.StringOutput)
}

// Contains settings for embedding management.
type GoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagement struct {
	// Optional. Immutable. Whether to enable embedding management in this FeatureOnlineStore. It's immutable after creation to ensure the FeatureOnlineStore availability.
	Enabled *bool `pulumi:"enabled"`
}

// GoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementInput is an input type that accepts GoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementArgs and GoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementInput` via:
//
//	GoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementArgs{...}
type GoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementOutput() GoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementOutput
	ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementOutput
}

// Contains settings for embedding management.
type GoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementArgs struct {
	// Optional. Immutable. Whether to enable embedding management in this FeatureOnlineStore. It's immutable after creation to ensure the FeatureOnlineStore availability.
	Enabled pulumi.BoolPtrInput `pulumi:"enabled"`
}

func (GoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagement)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementArgs) ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementOutput() GoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementOutput {
	return i.ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementArgs) ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementOutput)
}

func (i GoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementArgs) ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementPtrOutput() GoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementArgs) ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementOutput).ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementArgs, GoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementPtr and GoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementPtrOutput() GoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementPtrOutput
	ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementPtrOutput
}

type googleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementPtrType GoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementArgs

func GoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementPtr(v *GoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementArgs) GoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementPtrInput {
	return (*googleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementPtrType)(v)
}

func (*googleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagement)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementPtrType) ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementPtrOutput() GoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementPtrType) ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementPtrOutput)
}

// Contains settings for embedding management.
type GoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagement)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementOutput) ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementOutput() GoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementOutput) ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementOutput) ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementPtrOutput() GoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementOutput) ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagement) *GoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagement {
		return &v
	}).(GoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementPtrOutput)
}

// Optional. Immutable. Whether to enable embedding management in this FeatureOnlineStore. It's immutable after creation to ensure the FeatureOnlineStore availability.
func (o GoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementOutput) Enabled() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagement) *bool { return v.Enabled }).(pulumi.BoolPtrOutput)
}

type GoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagement)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementPtrOutput) ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementPtrOutput() GoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementPtrOutput) ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementPtrOutput) Elem() GoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagement) GoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagement {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagement
		return ret
	}).(GoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementOutput)
}

// Optional. Immutable. Whether to enable embedding management in this FeatureOnlineStore. It's immutable after creation to ensure the FeatureOnlineStore availability.
func (o GoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementPtrOutput) Enabled() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagement) *bool {
		if v == nil {
			return nil
		}
		return v.Enabled
	}).(pulumi.BoolPtrOutput)
}

// Contains settings for embedding management.
type GoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementResponse struct {
	// Optional. Immutable. Whether to enable embedding management in this FeatureOnlineStore. It's immutable after creation to ensure the FeatureOnlineStore availability.
	Enabled bool `pulumi:"enabled"`
}

// Contains settings for embedding management.
type GoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementResponseOutput) ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementResponseOutput() GoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementResponseOutput) ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementResponseOutput {
	return o
}

// Optional. Immutable. Whether to enable embedding management in this FeatureOnlineStore. It's immutable after creation to ensure the FeatureOnlineStore availability.
func (o GoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementResponseOutput) Enabled() pulumi.BoolOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementResponse) bool {
		return v.Enabled
	}).(pulumi.BoolOutput)
}

// Optimized storage type
type GoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimized struct {
}

// GoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimizedInput is an input type that accepts GoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimizedArgs and GoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimizedOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimizedInput` via:
//
//	GoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimizedArgs{...}
type GoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimizedInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimizedOutput() GoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimizedOutput
	ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimizedOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimizedOutput
}

// Optimized storage type
type GoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimizedArgs struct {
}

func (GoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimizedArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimized)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimizedArgs) ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimizedOutput() GoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimizedOutput {
	return i.ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimizedOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimizedArgs) ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimizedOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimizedOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimizedOutput)
}

func (i GoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimizedArgs) ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimizedPtrOutput() GoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimizedPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimizedPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimizedArgs) ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimizedPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimizedPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimizedOutput).ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimizedPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimizedPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimizedArgs, GoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimizedPtr and GoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimizedPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimizedPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimizedArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimizedPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimizedPtrOutput() GoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimizedPtrOutput
	ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimizedPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimizedPtrOutput
}

type googleCloudAiplatformV1beta1FeatureOnlineStoreOptimizedPtrType GoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimizedArgs

func GoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimizedPtr(v *GoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimizedArgs) GoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimizedPtrInput {
	return (*googleCloudAiplatformV1beta1FeatureOnlineStoreOptimizedPtrType)(v)
}

func (*googleCloudAiplatformV1beta1FeatureOnlineStoreOptimizedPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimized)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1FeatureOnlineStoreOptimizedPtrType) ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimizedPtrOutput() GoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimizedPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimizedPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1FeatureOnlineStoreOptimizedPtrType) ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimizedPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimizedPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimizedPtrOutput)
}

// Optimized storage type
type GoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimizedOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimizedOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimized)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimizedOutput) ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimizedOutput() GoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimizedOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimizedOutput) ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimizedOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimizedOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimizedOutput) ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimizedPtrOutput() GoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimizedPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimizedPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimizedOutput) ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimizedPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimizedPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimized) *GoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimized {
		return &v
	}).(GoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimizedPtrOutput)
}

type GoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimizedPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimizedPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimized)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimizedPtrOutput) ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimizedPtrOutput() GoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimizedPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimizedPtrOutput) ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimizedPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimizedPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimizedPtrOutput) Elem() GoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimizedOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimized) GoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimized {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimized
		return ret
	}).(GoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimizedOutput)
}

// Optimized storage type
type GoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimizedResponse struct {
}

// Optimized storage type
type GoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimizedResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimizedResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimizedResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimizedResponseOutput) ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimizedResponseOutput() GoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimizedResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimizedResponseOutput) ToGoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimizedResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimizedResponseOutput {
	return o
}

// Stats and Anomaly generated at specific timestamp for specific Feature. The start_time and end_time are used to define the time range of the dataset that current stats belongs to, e.g. prediction traffic is bucketed into prediction datasets by time window. If the Dataset is not defined by time window, start_time = end_time. Timestamp of the stats and anomalies always refers to end_time. Raw stats and anomalies are stored in stats_uri or anomaly_uri in the tensorflow defined protos. Field data_stats contains almost identical information with the raw stats in Vertex AI defined proto, for UI to display.
type GoogleCloudAiplatformV1beta1FeatureStatsAnomaly struct {
	// This is the threshold used when detecting anomalies. The threshold can be changed by user, so this one might be different from ThresholdConfig.value.
	AnomalyDetectionThreshold *float64 `pulumi:"anomalyDetectionThreshold"`
	// Path of the anomaly file for current feature values in Cloud Storage bucket. Format: gs:////anomalies. Example: gs://monitoring_bucket/feature_name/anomalies. Stats are stored as binary format with Protobuf message Anoamlies are stored as binary format with Protobuf message [tensorflow.metadata.v0.AnomalyInfo] (https://github.com/tensorflow/metadata/blob/master/tensorflow_metadata/proto/v0/anomalies.proto).
	AnomalyUri *string `pulumi:"anomalyUri"`
	// Deviation from the current stats to baseline stats. 1. For categorical feature, the distribution distance is calculated by L-inifinity norm. 2. For numerical feature, the distribution distance is calculated by Jensen–Shannon divergence.
	DistributionDeviation *float64 `pulumi:"distributionDeviation"`
	// The end timestamp of window where stats were generated. For objectives where time window doesn't make sense (e.g. Featurestore Snapshot Monitoring), end_time indicates the timestamp of the data used to generate stats (e.g. timestamp we take snapshots for feature values).
	EndTime *string `pulumi:"endTime"`
	// Feature importance score, only populated when cross-feature monitoring is enabled. For now only used to represent feature attribution score within range [0, 1] for ModelDeploymentMonitoringObjectiveType.FEATURE_ATTRIBUTION_SKEW and ModelDeploymentMonitoringObjectiveType.FEATURE_ATTRIBUTION_DRIFT.
	Score *float64 `pulumi:"score"`
	// The start timestamp of window where stats were generated. For objectives where time window doesn't make sense (e.g. Featurestore Snapshot Monitoring), start_time is only used to indicate the monitoring intervals, so it always equals to (end_time - monitoring_interval).
	StartTime *string `pulumi:"startTime"`
	// Path of the stats file for current feature values in Cloud Storage bucket. Format: gs:////stats. Example: gs://monitoring_bucket/feature_name/stats. Stats are stored as binary format with Protobuf message [tensorflow.metadata.v0.FeatureNameStatistics](https://github.com/tensorflow/metadata/blob/master/tensorflow_metadata/proto/v0/statistics.proto).
	StatsUri *string `pulumi:"statsUri"`
}

// GoogleCloudAiplatformV1beta1FeatureStatsAnomalyInput is an input type that accepts GoogleCloudAiplatformV1beta1FeatureStatsAnomalyArgs and GoogleCloudAiplatformV1beta1FeatureStatsAnomalyOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1FeatureStatsAnomalyInput` via:
//
//	GoogleCloudAiplatformV1beta1FeatureStatsAnomalyArgs{...}
type GoogleCloudAiplatformV1beta1FeatureStatsAnomalyInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1FeatureStatsAnomalyOutput() GoogleCloudAiplatformV1beta1FeatureStatsAnomalyOutput
	ToGoogleCloudAiplatformV1beta1FeatureStatsAnomalyOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1FeatureStatsAnomalyOutput
}

// Stats and Anomaly generated at specific timestamp for specific Feature. The start_time and end_time are used to define the time range of the dataset that current stats belongs to, e.g. prediction traffic is bucketed into prediction datasets by time window. If the Dataset is not defined by time window, start_time = end_time. Timestamp of the stats and anomalies always refers to end_time. Raw stats and anomalies are stored in stats_uri or anomaly_uri in the tensorflow defined protos. Field data_stats contains almost identical information with the raw stats in Vertex AI defined proto, for UI to display.
type GoogleCloudAiplatformV1beta1FeatureStatsAnomalyArgs struct {
	// This is the threshold used when detecting anomalies. The threshold can be changed by user, so this one might be different from ThresholdConfig.value.
	AnomalyDetectionThreshold pulumi.Float64PtrInput `pulumi:"anomalyDetectionThreshold"`
	// Path of the anomaly file for current feature values in Cloud Storage bucket. Format: gs:////anomalies. Example: gs://monitoring_bucket/feature_name/anomalies. Stats are stored as binary format with Protobuf message Anoamlies are stored as binary format with Protobuf message [tensorflow.metadata.v0.AnomalyInfo] (https://github.com/tensorflow/metadata/blob/master/tensorflow_metadata/proto/v0/anomalies.proto).
	AnomalyUri pulumi.StringPtrInput `pulumi:"anomalyUri"`
	// Deviation from the current stats to baseline stats. 1. For categorical feature, the distribution distance is calculated by L-inifinity norm. 2. For numerical feature, the distribution distance is calculated by Jensen–Shannon divergence.
	DistributionDeviation pulumi.Float64PtrInput `pulumi:"distributionDeviation"`
	// The end timestamp of window where stats were generated. For objectives where time window doesn't make sense (e.g. Featurestore Snapshot Monitoring), end_time indicates the timestamp of the data used to generate stats (e.g. timestamp we take snapshots for feature values).
	EndTime pulumi.StringPtrInput `pulumi:"endTime"`
	// Feature importance score, only populated when cross-feature monitoring is enabled. For now only used to represent feature attribution score within range [0, 1] for ModelDeploymentMonitoringObjectiveType.FEATURE_ATTRIBUTION_SKEW and ModelDeploymentMonitoringObjectiveType.FEATURE_ATTRIBUTION_DRIFT.
	Score pulumi.Float64PtrInput `pulumi:"score"`
	// The start timestamp of window where stats were generated. For objectives where time window doesn't make sense (e.g. Featurestore Snapshot Monitoring), start_time is only used to indicate the monitoring intervals, so it always equals to (end_time - monitoring_interval).
	StartTime pulumi.StringPtrInput `pulumi:"startTime"`
	// Path of the stats file for current feature values in Cloud Storage bucket. Format: gs:////stats. Example: gs://monitoring_bucket/feature_name/stats. Stats are stored as binary format with Protobuf message [tensorflow.metadata.v0.FeatureNameStatistics](https://github.com/tensorflow/metadata/blob/master/tensorflow_metadata/proto/v0/statistics.proto).
	StatsUri pulumi.StringPtrInput `pulumi:"statsUri"`
}

func (GoogleCloudAiplatformV1beta1FeatureStatsAnomalyArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeatureStatsAnomaly)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1FeatureStatsAnomalyArgs) ToGoogleCloudAiplatformV1beta1FeatureStatsAnomalyOutput() GoogleCloudAiplatformV1beta1FeatureStatsAnomalyOutput {
	return i.ToGoogleCloudAiplatformV1beta1FeatureStatsAnomalyOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1FeatureStatsAnomalyArgs) ToGoogleCloudAiplatformV1beta1FeatureStatsAnomalyOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureStatsAnomalyOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1FeatureStatsAnomalyOutput)
}

func (i GoogleCloudAiplatformV1beta1FeatureStatsAnomalyArgs) ToGoogleCloudAiplatformV1beta1FeatureStatsAnomalyPtrOutput() GoogleCloudAiplatformV1beta1FeatureStatsAnomalyPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1FeatureStatsAnomalyPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1FeatureStatsAnomalyArgs) ToGoogleCloudAiplatformV1beta1FeatureStatsAnomalyPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureStatsAnomalyPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1FeatureStatsAnomalyOutput).ToGoogleCloudAiplatformV1beta1FeatureStatsAnomalyPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1FeatureStatsAnomalyPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1FeatureStatsAnomalyArgs, GoogleCloudAiplatformV1beta1FeatureStatsAnomalyPtr and GoogleCloudAiplatformV1beta1FeatureStatsAnomalyPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1FeatureStatsAnomalyPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1FeatureStatsAnomalyArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1FeatureStatsAnomalyPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1FeatureStatsAnomalyPtrOutput() GoogleCloudAiplatformV1beta1FeatureStatsAnomalyPtrOutput
	ToGoogleCloudAiplatformV1beta1FeatureStatsAnomalyPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1FeatureStatsAnomalyPtrOutput
}

type googleCloudAiplatformV1beta1FeatureStatsAnomalyPtrType GoogleCloudAiplatformV1beta1FeatureStatsAnomalyArgs

func GoogleCloudAiplatformV1beta1FeatureStatsAnomalyPtr(v *GoogleCloudAiplatformV1beta1FeatureStatsAnomalyArgs) GoogleCloudAiplatformV1beta1FeatureStatsAnomalyPtrInput {
	return (*googleCloudAiplatformV1beta1FeatureStatsAnomalyPtrType)(v)
}

func (*googleCloudAiplatformV1beta1FeatureStatsAnomalyPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1FeatureStatsAnomaly)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1FeatureStatsAnomalyPtrType) ToGoogleCloudAiplatformV1beta1FeatureStatsAnomalyPtrOutput() GoogleCloudAiplatformV1beta1FeatureStatsAnomalyPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1FeatureStatsAnomalyPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1FeatureStatsAnomalyPtrType) ToGoogleCloudAiplatformV1beta1FeatureStatsAnomalyPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureStatsAnomalyPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1FeatureStatsAnomalyPtrOutput)
}

// GoogleCloudAiplatformV1beta1FeatureStatsAnomalyArrayInput is an input type that accepts GoogleCloudAiplatformV1beta1FeatureStatsAnomalyArray and GoogleCloudAiplatformV1beta1FeatureStatsAnomalyArrayOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1FeatureStatsAnomalyArrayInput` via:
//
//	GoogleCloudAiplatformV1beta1FeatureStatsAnomalyArray{ GoogleCloudAiplatformV1beta1FeatureStatsAnomalyArgs{...} }
type GoogleCloudAiplatformV1beta1FeatureStatsAnomalyArrayInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1FeatureStatsAnomalyArrayOutput() GoogleCloudAiplatformV1beta1FeatureStatsAnomalyArrayOutput
	ToGoogleCloudAiplatformV1beta1FeatureStatsAnomalyArrayOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1FeatureStatsAnomalyArrayOutput
}

type GoogleCloudAiplatformV1beta1FeatureStatsAnomalyArray []GoogleCloudAiplatformV1beta1FeatureStatsAnomalyInput

func (GoogleCloudAiplatformV1beta1FeatureStatsAnomalyArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1beta1FeatureStatsAnomaly)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1FeatureStatsAnomalyArray) ToGoogleCloudAiplatformV1beta1FeatureStatsAnomalyArrayOutput() GoogleCloudAiplatformV1beta1FeatureStatsAnomalyArrayOutput {
	return i.ToGoogleCloudAiplatformV1beta1FeatureStatsAnomalyArrayOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1FeatureStatsAnomalyArray) ToGoogleCloudAiplatformV1beta1FeatureStatsAnomalyArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureStatsAnomalyArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1FeatureStatsAnomalyArrayOutput)
}

// Stats and Anomaly generated at specific timestamp for specific Feature. The start_time and end_time are used to define the time range of the dataset that current stats belongs to, e.g. prediction traffic is bucketed into prediction datasets by time window. If the Dataset is not defined by time window, start_time = end_time. Timestamp of the stats and anomalies always refers to end_time. Raw stats and anomalies are stored in stats_uri or anomaly_uri in the tensorflow defined protos. Field data_stats contains almost identical information with the raw stats in Vertex AI defined proto, for UI to display.
type GoogleCloudAiplatformV1beta1FeatureStatsAnomalyOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1FeatureStatsAnomalyOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeatureStatsAnomaly)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1FeatureStatsAnomalyOutput) ToGoogleCloudAiplatformV1beta1FeatureStatsAnomalyOutput() GoogleCloudAiplatformV1beta1FeatureStatsAnomalyOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeatureStatsAnomalyOutput) ToGoogleCloudAiplatformV1beta1FeatureStatsAnomalyOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureStatsAnomalyOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeatureStatsAnomalyOutput) ToGoogleCloudAiplatformV1beta1FeatureStatsAnomalyPtrOutput() GoogleCloudAiplatformV1beta1FeatureStatsAnomalyPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1FeatureStatsAnomalyPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1FeatureStatsAnomalyOutput) ToGoogleCloudAiplatformV1beta1FeatureStatsAnomalyPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureStatsAnomalyPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1FeatureStatsAnomaly) *GoogleCloudAiplatformV1beta1FeatureStatsAnomaly {
		return &v
	}).(GoogleCloudAiplatformV1beta1FeatureStatsAnomalyPtrOutput)
}

// This is the threshold used when detecting anomalies. The threshold can be changed by user, so this one might be different from ThresholdConfig.value.
func (o GoogleCloudAiplatformV1beta1FeatureStatsAnomalyOutput) AnomalyDetectionThreshold() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeatureStatsAnomaly) *float64 { return v.AnomalyDetectionThreshold }).(pulumi.Float64PtrOutput)
}

// Path of the anomaly file for current feature values in Cloud Storage bucket. Format: gs:////anomalies. Example: gs://monitoring_bucket/feature_name/anomalies. Stats are stored as binary format with Protobuf message Anoamlies are stored as binary format with Protobuf message [tensorflow.metadata.v0.AnomalyInfo] (https://github.com/tensorflow/metadata/blob/master/tensorflow_metadata/proto/v0/anomalies.proto).
func (o GoogleCloudAiplatformV1beta1FeatureStatsAnomalyOutput) AnomalyUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeatureStatsAnomaly) *string { return v.AnomalyUri }).(pulumi.StringPtrOutput)
}

// Deviation from the current stats to baseline stats. 1. For categorical feature, the distribution distance is calculated by L-inifinity norm. 2. For numerical feature, the distribution distance is calculated by Jensen–Shannon divergence.
func (o GoogleCloudAiplatformV1beta1FeatureStatsAnomalyOutput) DistributionDeviation() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeatureStatsAnomaly) *float64 { return v.DistributionDeviation }).(pulumi.Float64PtrOutput)
}

// The end timestamp of window where stats were generated. For objectives where time window doesn't make sense (e.g. Featurestore Snapshot Monitoring), end_time indicates the timestamp of the data used to generate stats (e.g. timestamp we take snapshots for feature values).
func (o GoogleCloudAiplatformV1beta1FeatureStatsAnomalyOutput) EndTime() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeatureStatsAnomaly) *string { return v.EndTime }).(pulumi.StringPtrOutput)
}

// Feature importance score, only populated when cross-feature monitoring is enabled. For now only used to represent feature attribution score within range [0, 1] for ModelDeploymentMonitoringObjectiveType.FEATURE_ATTRIBUTION_SKEW and ModelDeploymentMonitoringObjectiveType.FEATURE_ATTRIBUTION_DRIFT.
func (o GoogleCloudAiplatformV1beta1FeatureStatsAnomalyOutput) Score() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeatureStatsAnomaly) *float64 { return v.Score }).(pulumi.Float64PtrOutput)
}

// The start timestamp of window where stats were generated. For objectives where time window doesn't make sense (e.g. Featurestore Snapshot Monitoring), start_time is only used to indicate the monitoring intervals, so it always equals to (end_time - monitoring_interval).
func (o GoogleCloudAiplatformV1beta1FeatureStatsAnomalyOutput) StartTime() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeatureStatsAnomaly) *string { return v.StartTime }).(pulumi.StringPtrOutput)
}

// Path of the stats file for current feature values in Cloud Storage bucket. Format: gs:////stats. Example: gs://monitoring_bucket/feature_name/stats. Stats are stored as binary format with Protobuf message [tensorflow.metadata.v0.FeatureNameStatistics](https://github.com/tensorflow/metadata/blob/master/tensorflow_metadata/proto/v0/statistics.proto).
func (o GoogleCloudAiplatformV1beta1FeatureStatsAnomalyOutput) StatsUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeatureStatsAnomaly) *string { return v.StatsUri }).(pulumi.StringPtrOutput)
}

type GoogleCloudAiplatformV1beta1FeatureStatsAnomalyPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1FeatureStatsAnomalyPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1FeatureStatsAnomaly)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1FeatureStatsAnomalyPtrOutput) ToGoogleCloudAiplatformV1beta1FeatureStatsAnomalyPtrOutput() GoogleCloudAiplatformV1beta1FeatureStatsAnomalyPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeatureStatsAnomalyPtrOutput) ToGoogleCloudAiplatformV1beta1FeatureStatsAnomalyPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureStatsAnomalyPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeatureStatsAnomalyPtrOutput) Elem() GoogleCloudAiplatformV1beta1FeatureStatsAnomalyOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1FeatureStatsAnomaly) GoogleCloudAiplatformV1beta1FeatureStatsAnomaly {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1FeatureStatsAnomaly
		return ret
	}).(GoogleCloudAiplatformV1beta1FeatureStatsAnomalyOutput)
}

// This is the threshold used when detecting anomalies. The threshold can be changed by user, so this one might be different from ThresholdConfig.value.
func (o GoogleCloudAiplatformV1beta1FeatureStatsAnomalyPtrOutput) AnomalyDetectionThreshold() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1FeatureStatsAnomaly) *float64 {
		if v == nil {
			return nil
		}
		return v.AnomalyDetectionThreshold
	}).(pulumi.Float64PtrOutput)
}

// Path of the anomaly file for current feature values in Cloud Storage bucket. Format: gs:////anomalies. Example: gs://monitoring_bucket/feature_name/anomalies. Stats are stored as binary format with Protobuf message Anoamlies are stored as binary format with Protobuf message [tensorflow.metadata.v0.AnomalyInfo] (https://github.com/tensorflow/metadata/blob/master/tensorflow_metadata/proto/v0/anomalies.proto).
func (o GoogleCloudAiplatformV1beta1FeatureStatsAnomalyPtrOutput) AnomalyUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1FeatureStatsAnomaly) *string {
		if v == nil {
			return nil
		}
		return v.AnomalyUri
	}).(pulumi.StringPtrOutput)
}

// Deviation from the current stats to baseline stats. 1. For categorical feature, the distribution distance is calculated by L-inifinity norm. 2. For numerical feature, the distribution distance is calculated by Jensen–Shannon divergence.
func (o GoogleCloudAiplatformV1beta1FeatureStatsAnomalyPtrOutput) DistributionDeviation() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1FeatureStatsAnomaly) *float64 {
		if v == nil {
			return nil
		}
		return v.DistributionDeviation
	}).(pulumi.Float64PtrOutput)
}

// The end timestamp of window where stats were generated. For objectives where time window doesn't make sense (e.g. Featurestore Snapshot Monitoring), end_time indicates the timestamp of the data used to generate stats (e.g. timestamp we take snapshots for feature values).
func (o GoogleCloudAiplatformV1beta1FeatureStatsAnomalyPtrOutput) EndTime() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1FeatureStatsAnomaly) *string {
		if v == nil {
			return nil
		}
		return v.EndTime
	}).(pulumi.StringPtrOutput)
}

// Feature importance score, only populated when cross-feature monitoring is enabled. For now only used to represent feature attribution score within range [0, 1] for ModelDeploymentMonitoringObjectiveType.FEATURE_ATTRIBUTION_SKEW and ModelDeploymentMonitoringObjectiveType.FEATURE_ATTRIBUTION_DRIFT.
func (o GoogleCloudAiplatformV1beta1FeatureStatsAnomalyPtrOutput) Score() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1FeatureStatsAnomaly) *float64 {
		if v == nil {
			return nil
		}
		return v.Score
	}).(pulumi.Float64PtrOutput)
}

// The start timestamp of window where stats were generated. For objectives where time window doesn't make sense (e.g. Featurestore Snapshot Monitoring), start_time is only used to indicate the monitoring intervals, so it always equals to (end_time - monitoring_interval).
func (o GoogleCloudAiplatformV1beta1FeatureStatsAnomalyPtrOutput) StartTime() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1FeatureStatsAnomaly) *string {
		if v == nil {
			return nil
		}
		return v.StartTime
	}).(pulumi.StringPtrOutput)
}

// Path of the stats file for current feature values in Cloud Storage bucket. Format: gs:////stats. Example: gs://monitoring_bucket/feature_name/stats. Stats are stored as binary format with Protobuf message [tensorflow.metadata.v0.FeatureNameStatistics](https://github.com/tensorflow/metadata/blob/master/tensorflow_metadata/proto/v0/statistics.proto).
func (o GoogleCloudAiplatformV1beta1FeatureStatsAnomalyPtrOutput) StatsUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1FeatureStatsAnomaly) *string {
		if v == nil {
			return nil
		}
		return v.StatsUri
	}).(pulumi.StringPtrOutput)
}

type GoogleCloudAiplatformV1beta1FeatureStatsAnomalyArrayOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1FeatureStatsAnomalyArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1beta1FeatureStatsAnomaly)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1FeatureStatsAnomalyArrayOutput) ToGoogleCloudAiplatformV1beta1FeatureStatsAnomalyArrayOutput() GoogleCloudAiplatformV1beta1FeatureStatsAnomalyArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeatureStatsAnomalyArrayOutput) ToGoogleCloudAiplatformV1beta1FeatureStatsAnomalyArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureStatsAnomalyArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeatureStatsAnomalyArrayOutput) Index(i pulumi.IntInput) GoogleCloudAiplatformV1beta1FeatureStatsAnomalyOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GoogleCloudAiplatformV1beta1FeatureStatsAnomaly {
		return vs[0].([]GoogleCloudAiplatformV1beta1FeatureStatsAnomaly)[vs[1].(int)]
	}).(GoogleCloudAiplatformV1beta1FeatureStatsAnomalyOutput)
}

// Stats and Anomaly generated at specific timestamp for specific Feature. The start_time and end_time are used to define the time range of the dataset that current stats belongs to, e.g. prediction traffic is bucketed into prediction datasets by time window. If the Dataset is not defined by time window, start_time = end_time. Timestamp of the stats and anomalies always refers to end_time. Raw stats and anomalies are stored in stats_uri or anomaly_uri in the tensorflow defined protos. Field data_stats contains almost identical information with the raw stats in Vertex AI defined proto, for UI to display.
type GoogleCloudAiplatformV1beta1FeatureStatsAnomalyResponse struct {
	// This is the threshold used when detecting anomalies. The threshold can be changed by user, so this one might be different from ThresholdConfig.value.
	AnomalyDetectionThreshold float64 `pulumi:"anomalyDetectionThreshold"`
	// Path of the anomaly file for current feature values in Cloud Storage bucket. Format: gs:////anomalies. Example: gs://monitoring_bucket/feature_name/anomalies. Stats are stored as binary format with Protobuf message Anoamlies are stored as binary format with Protobuf message [tensorflow.metadata.v0.AnomalyInfo] (https://github.com/tensorflow/metadata/blob/master/tensorflow_metadata/proto/v0/anomalies.proto).
	AnomalyUri string `pulumi:"anomalyUri"`
	// Deviation from the current stats to baseline stats. 1. For categorical feature, the distribution distance is calculated by L-inifinity norm. 2. For numerical feature, the distribution distance is calculated by Jensen–Shannon divergence.
	DistributionDeviation float64 `pulumi:"distributionDeviation"`
	// The end timestamp of window where stats were generated. For objectives where time window doesn't make sense (e.g. Featurestore Snapshot Monitoring), end_time indicates the timestamp of the data used to generate stats (e.g. timestamp we take snapshots for feature values).
	EndTime string `pulumi:"endTime"`
	// Feature importance score, only populated when cross-feature monitoring is enabled. For now only used to represent feature attribution score within range [0, 1] for ModelDeploymentMonitoringObjectiveType.FEATURE_ATTRIBUTION_SKEW and ModelDeploymentMonitoringObjectiveType.FEATURE_ATTRIBUTION_DRIFT.
	Score float64 `pulumi:"score"`
	// The start timestamp of window where stats were generated. For objectives where time window doesn't make sense (e.g. Featurestore Snapshot Monitoring), start_time is only used to indicate the monitoring intervals, so it always equals to (end_time - monitoring_interval).
	StartTime string `pulumi:"startTime"`
	// Path of the stats file for current feature values in Cloud Storage bucket. Format: gs:////stats. Example: gs://monitoring_bucket/feature_name/stats. Stats are stored as binary format with Protobuf message [tensorflow.metadata.v0.FeatureNameStatistics](https://github.com/tensorflow/metadata/blob/master/tensorflow_metadata/proto/v0/statistics.proto).
	StatsUri string `pulumi:"statsUri"`
}

// Stats and Anomaly generated at specific timestamp for specific Feature. The start_time and end_time are used to define the time range of the dataset that current stats belongs to, e.g. prediction traffic is bucketed into prediction datasets by time window. If the Dataset is not defined by time window, start_time = end_time. Timestamp of the stats and anomalies always refers to end_time. Raw stats and anomalies are stored in stats_uri or anomaly_uri in the tensorflow defined protos. Field data_stats contains almost identical information with the raw stats in Vertex AI defined proto, for UI to display.
type GoogleCloudAiplatformV1beta1FeatureStatsAnomalyResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1FeatureStatsAnomalyResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeatureStatsAnomalyResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1FeatureStatsAnomalyResponseOutput) ToGoogleCloudAiplatformV1beta1FeatureStatsAnomalyResponseOutput() GoogleCloudAiplatformV1beta1FeatureStatsAnomalyResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeatureStatsAnomalyResponseOutput) ToGoogleCloudAiplatformV1beta1FeatureStatsAnomalyResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureStatsAnomalyResponseOutput {
	return o
}

// This is the threshold used when detecting anomalies. The threshold can be changed by user, so this one might be different from ThresholdConfig.value.
func (o GoogleCloudAiplatformV1beta1FeatureStatsAnomalyResponseOutput) AnomalyDetectionThreshold() pulumi.Float64Output {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeatureStatsAnomalyResponse) float64 {
		return v.AnomalyDetectionThreshold
	}).(pulumi.Float64Output)
}

// Path of the anomaly file for current feature values in Cloud Storage bucket. Format: gs:////anomalies. Example: gs://monitoring_bucket/feature_name/anomalies. Stats are stored as binary format with Protobuf message Anoamlies are stored as binary format with Protobuf message [tensorflow.metadata.v0.AnomalyInfo] (https://github.com/tensorflow/metadata/blob/master/tensorflow_metadata/proto/v0/anomalies.proto).
func (o GoogleCloudAiplatformV1beta1FeatureStatsAnomalyResponseOutput) AnomalyUri() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeatureStatsAnomalyResponse) string { return v.AnomalyUri }).(pulumi.StringOutput)
}

// Deviation from the current stats to baseline stats. 1. For categorical feature, the distribution distance is calculated by L-inifinity norm. 2. For numerical feature, the distribution distance is calculated by Jensen–Shannon divergence.
func (o GoogleCloudAiplatformV1beta1FeatureStatsAnomalyResponseOutput) DistributionDeviation() pulumi.Float64Output {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeatureStatsAnomalyResponse) float64 {
		return v.DistributionDeviation
	}).(pulumi.Float64Output)
}

// The end timestamp of window where stats were generated. For objectives where time window doesn't make sense (e.g. Featurestore Snapshot Monitoring), end_time indicates the timestamp of the data used to generate stats (e.g. timestamp we take snapshots for feature values).
func (o GoogleCloudAiplatformV1beta1FeatureStatsAnomalyResponseOutput) EndTime() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeatureStatsAnomalyResponse) string { return v.EndTime }).(pulumi.StringOutput)
}

// Feature importance score, only populated when cross-feature monitoring is enabled. For now only used to represent feature attribution score within range [0, 1] for ModelDeploymentMonitoringObjectiveType.FEATURE_ATTRIBUTION_SKEW and ModelDeploymentMonitoringObjectiveType.FEATURE_ATTRIBUTION_DRIFT.
func (o GoogleCloudAiplatformV1beta1FeatureStatsAnomalyResponseOutput) Score() pulumi.Float64Output {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeatureStatsAnomalyResponse) float64 { return v.Score }).(pulumi.Float64Output)
}

// The start timestamp of window where stats were generated. For objectives where time window doesn't make sense (e.g. Featurestore Snapshot Monitoring), start_time is only used to indicate the monitoring intervals, so it always equals to (end_time - monitoring_interval).
func (o GoogleCloudAiplatformV1beta1FeatureStatsAnomalyResponseOutput) StartTime() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeatureStatsAnomalyResponse) string { return v.StartTime }).(pulumi.StringOutput)
}

// Path of the stats file for current feature values in Cloud Storage bucket. Format: gs:////stats. Example: gs://monitoring_bucket/feature_name/stats. Stats are stored as binary format with Protobuf message [tensorflow.metadata.v0.FeatureNameStatistics](https://github.com/tensorflow/metadata/blob/master/tensorflow_metadata/proto/v0/statistics.proto).
func (o GoogleCloudAiplatformV1beta1FeatureStatsAnomalyResponseOutput) StatsUri() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeatureStatsAnomalyResponse) string { return v.StatsUri }).(pulumi.StringOutput)
}

type GoogleCloudAiplatformV1beta1FeatureStatsAnomalyResponseArrayOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1FeatureStatsAnomalyResponseArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1beta1FeatureStatsAnomalyResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1FeatureStatsAnomalyResponseArrayOutput) ToGoogleCloudAiplatformV1beta1FeatureStatsAnomalyResponseArrayOutput() GoogleCloudAiplatformV1beta1FeatureStatsAnomalyResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeatureStatsAnomalyResponseArrayOutput) ToGoogleCloudAiplatformV1beta1FeatureStatsAnomalyResponseArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureStatsAnomalyResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeatureStatsAnomalyResponseArrayOutput) Index(i pulumi.IntInput) GoogleCloudAiplatformV1beta1FeatureStatsAnomalyResponseOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GoogleCloudAiplatformV1beta1FeatureStatsAnomalyResponse {
		return vs[0].([]GoogleCloudAiplatformV1beta1FeatureStatsAnomalyResponse)[vs[1].(int)]
	}).(GoogleCloudAiplatformV1beta1FeatureStatsAnomalyResponseOutput)
}

type GoogleCloudAiplatformV1beta1FeatureViewBigQuerySource struct {
	// Columns to construct entity_id / row keys. Start by supporting 1 only.
	EntityIdColumns []string `pulumi:"entityIdColumns"`
	// The BigQuery view URI that will be materialized on each sync trigger based on FeatureView.SyncConfig.
	Uri string `pulumi:"uri"`
}

// GoogleCloudAiplatformV1beta1FeatureViewBigQuerySourceInput is an input type that accepts GoogleCloudAiplatformV1beta1FeatureViewBigQuerySourceArgs and GoogleCloudAiplatformV1beta1FeatureViewBigQuerySourceOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1FeatureViewBigQuerySourceInput` via:
//
//	GoogleCloudAiplatformV1beta1FeatureViewBigQuerySourceArgs{...}
type GoogleCloudAiplatformV1beta1FeatureViewBigQuerySourceInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1FeatureViewBigQuerySourceOutput() GoogleCloudAiplatformV1beta1FeatureViewBigQuerySourceOutput
	ToGoogleCloudAiplatformV1beta1FeatureViewBigQuerySourceOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1FeatureViewBigQuerySourceOutput
}

type GoogleCloudAiplatformV1beta1FeatureViewBigQuerySourceArgs struct {
	// Columns to construct entity_id / row keys. Start by supporting 1 only.
	EntityIdColumns pulumi.StringArrayInput `pulumi:"entityIdColumns"`
	// The BigQuery view URI that will be materialized on each sync trigger based on FeatureView.SyncConfig.
	Uri pulumi.StringInput `pulumi:"uri"`
}

func (GoogleCloudAiplatformV1beta1FeatureViewBigQuerySourceArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeatureViewBigQuerySource)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1FeatureViewBigQuerySourceArgs) ToGoogleCloudAiplatformV1beta1FeatureViewBigQuerySourceOutput() GoogleCloudAiplatformV1beta1FeatureViewBigQuerySourceOutput {
	return i.ToGoogleCloudAiplatformV1beta1FeatureViewBigQuerySourceOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1FeatureViewBigQuerySourceArgs) ToGoogleCloudAiplatformV1beta1FeatureViewBigQuerySourceOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureViewBigQuerySourceOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1FeatureViewBigQuerySourceOutput)
}

func (i GoogleCloudAiplatformV1beta1FeatureViewBigQuerySourceArgs) ToGoogleCloudAiplatformV1beta1FeatureViewBigQuerySourcePtrOutput() GoogleCloudAiplatformV1beta1FeatureViewBigQuerySourcePtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1FeatureViewBigQuerySourcePtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1FeatureViewBigQuerySourceArgs) ToGoogleCloudAiplatformV1beta1FeatureViewBigQuerySourcePtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureViewBigQuerySourcePtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1FeatureViewBigQuerySourceOutput).ToGoogleCloudAiplatformV1beta1FeatureViewBigQuerySourcePtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1FeatureViewBigQuerySourcePtrInput is an input type that accepts GoogleCloudAiplatformV1beta1FeatureViewBigQuerySourceArgs, GoogleCloudAiplatformV1beta1FeatureViewBigQuerySourcePtr and GoogleCloudAiplatformV1beta1FeatureViewBigQuerySourcePtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1FeatureViewBigQuerySourcePtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1FeatureViewBigQuerySourceArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1FeatureViewBigQuerySourcePtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1FeatureViewBigQuerySourcePtrOutput() GoogleCloudAiplatformV1beta1FeatureViewBigQuerySourcePtrOutput
	ToGoogleCloudAiplatformV1beta1FeatureViewBigQuerySourcePtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1FeatureViewBigQuerySourcePtrOutput
}

type googleCloudAiplatformV1beta1FeatureViewBigQuerySourcePtrType GoogleCloudAiplatformV1beta1FeatureViewBigQuerySourceArgs

func GoogleCloudAiplatformV1beta1FeatureViewBigQuerySourcePtr(v *GoogleCloudAiplatformV1beta1FeatureViewBigQuerySourceArgs) GoogleCloudAiplatformV1beta1FeatureViewBigQuerySourcePtrInput {
	return (*googleCloudAiplatformV1beta1FeatureViewBigQuerySourcePtrType)(v)
}

func (*googleCloudAiplatformV1beta1FeatureViewBigQuerySourcePtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1FeatureViewBigQuerySource)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1FeatureViewBigQuerySourcePtrType) ToGoogleCloudAiplatformV1beta1FeatureViewBigQuerySourcePtrOutput() GoogleCloudAiplatformV1beta1FeatureViewBigQuerySourcePtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1FeatureViewBigQuerySourcePtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1FeatureViewBigQuerySourcePtrType) ToGoogleCloudAiplatformV1beta1FeatureViewBigQuerySourcePtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureViewBigQuerySourcePtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1FeatureViewBigQuerySourcePtrOutput)
}

type GoogleCloudAiplatformV1beta1FeatureViewBigQuerySourceOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1FeatureViewBigQuerySourceOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeatureViewBigQuerySource)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1FeatureViewBigQuerySourceOutput) ToGoogleCloudAiplatformV1beta1FeatureViewBigQuerySourceOutput() GoogleCloudAiplatformV1beta1FeatureViewBigQuerySourceOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeatureViewBigQuerySourceOutput) ToGoogleCloudAiplatformV1beta1FeatureViewBigQuerySourceOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureViewBigQuerySourceOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeatureViewBigQuerySourceOutput) ToGoogleCloudAiplatformV1beta1FeatureViewBigQuerySourcePtrOutput() GoogleCloudAiplatformV1beta1FeatureViewBigQuerySourcePtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1FeatureViewBigQuerySourcePtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1FeatureViewBigQuerySourceOutput) ToGoogleCloudAiplatformV1beta1FeatureViewBigQuerySourcePtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureViewBigQuerySourcePtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1FeatureViewBigQuerySource) *GoogleCloudAiplatformV1beta1FeatureViewBigQuerySource {
		return &v
	}).(GoogleCloudAiplatformV1beta1FeatureViewBigQuerySourcePtrOutput)
}

// Columns to construct entity_id / row keys. Start by supporting 1 only.
func (o GoogleCloudAiplatformV1beta1FeatureViewBigQuerySourceOutput) EntityIdColumns() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeatureViewBigQuerySource) []string { return v.EntityIdColumns }).(pulumi.StringArrayOutput)
}

// The BigQuery view URI that will be materialized on each sync trigger based on FeatureView.SyncConfig.
func (o GoogleCloudAiplatformV1beta1FeatureViewBigQuerySourceOutput) Uri() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeatureViewBigQuerySource) string { return v.Uri }).(pulumi.StringOutput)
}

type GoogleCloudAiplatformV1beta1FeatureViewBigQuerySourcePtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1FeatureViewBigQuerySourcePtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1FeatureViewBigQuerySource)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1FeatureViewBigQuerySourcePtrOutput) ToGoogleCloudAiplatformV1beta1FeatureViewBigQuerySourcePtrOutput() GoogleCloudAiplatformV1beta1FeatureViewBigQuerySourcePtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeatureViewBigQuerySourcePtrOutput) ToGoogleCloudAiplatformV1beta1FeatureViewBigQuerySourcePtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureViewBigQuerySourcePtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeatureViewBigQuerySourcePtrOutput) Elem() GoogleCloudAiplatformV1beta1FeatureViewBigQuerySourceOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1FeatureViewBigQuerySource) GoogleCloudAiplatformV1beta1FeatureViewBigQuerySource {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1FeatureViewBigQuerySource
		return ret
	}).(GoogleCloudAiplatformV1beta1FeatureViewBigQuerySourceOutput)
}

// Columns to construct entity_id / row keys. Start by supporting 1 only.
func (o GoogleCloudAiplatformV1beta1FeatureViewBigQuerySourcePtrOutput) EntityIdColumns() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1FeatureViewBigQuerySource) []string {
		if v == nil {
			return nil
		}
		return v.EntityIdColumns
	}).(pulumi.StringArrayOutput)
}

// The BigQuery view URI that will be materialized on each sync trigger based on FeatureView.SyncConfig.
func (o GoogleCloudAiplatformV1beta1FeatureViewBigQuerySourcePtrOutput) Uri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1FeatureViewBigQuerySource) *string {
		if v == nil {
			return nil
		}
		return &v.Uri
	}).(pulumi.StringPtrOutput)
}

type GoogleCloudAiplatformV1beta1FeatureViewBigQuerySourceResponse struct {
	// Columns to construct entity_id / row keys. Start by supporting 1 only.
	EntityIdColumns []string `pulumi:"entityIdColumns"`
	// The BigQuery view URI that will be materialized on each sync trigger based on FeatureView.SyncConfig.
	Uri string `pulumi:"uri"`
}

type GoogleCloudAiplatformV1beta1FeatureViewBigQuerySourceResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1FeatureViewBigQuerySourceResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeatureViewBigQuerySourceResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1FeatureViewBigQuerySourceResponseOutput) ToGoogleCloudAiplatformV1beta1FeatureViewBigQuerySourceResponseOutput() GoogleCloudAiplatformV1beta1FeatureViewBigQuerySourceResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeatureViewBigQuerySourceResponseOutput) ToGoogleCloudAiplatformV1beta1FeatureViewBigQuerySourceResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureViewBigQuerySourceResponseOutput {
	return o
}

// Columns to construct entity_id / row keys. Start by supporting 1 only.
func (o GoogleCloudAiplatformV1beta1FeatureViewBigQuerySourceResponseOutput) EntityIdColumns() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeatureViewBigQuerySourceResponse) []string {
		return v.EntityIdColumns
	}).(pulumi.StringArrayOutput)
}

// The BigQuery view URI that will be materialized on each sync trigger based on FeatureView.SyncConfig.
func (o GoogleCloudAiplatformV1beta1FeatureViewBigQuerySourceResponseOutput) Uri() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeatureViewBigQuerySourceResponse) string { return v.Uri }).(pulumi.StringOutput)
}

// A Feature Registry source for features that need to be synced to Online Store.
type GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySource struct {
	// List of features that need to be synced to Online Store.
	FeatureGroups []GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroup `pulumi:"featureGroups"`
}

// GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceInput is an input type that accepts GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceArgs and GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceInput` via:
//
//	GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceArgs{...}
type GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceOutput() GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceOutput
	ToGoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceOutput
}

// A Feature Registry source for features that need to be synced to Online Store.
type GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceArgs struct {
	// List of features that need to be synced to Online Store.
	FeatureGroups GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupArrayInput `pulumi:"featureGroups"`
}

func (GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySource)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceArgs) ToGoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceOutput() GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceOutput {
	return i.ToGoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceArgs) ToGoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceOutput)
}

func (i GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceArgs) ToGoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourcePtrOutput() GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourcePtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourcePtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceArgs) ToGoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourcePtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourcePtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceOutput).ToGoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourcePtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourcePtrInput is an input type that accepts GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceArgs, GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourcePtr and GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourcePtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourcePtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourcePtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourcePtrOutput() GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourcePtrOutput
	ToGoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourcePtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourcePtrOutput
}

type googleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourcePtrType GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceArgs

func GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourcePtr(v *GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceArgs) GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourcePtrInput {
	return (*googleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourcePtrType)(v)
}

func (*googleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourcePtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySource)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourcePtrType) ToGoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourcePtrOutput() GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourcePtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourcePtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourcePtrType) ToGoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourcePtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourcePtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourcePtrOutput)
}

// A Feature Registry source for features that need to be synced to Online Store.
type GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySource)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceOutput) ToGoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceOutput() GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceOutput) ToGoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceOutput) ToGoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourcePtrOutput() GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourcePtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourcePtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceOutput) ToGoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourcePtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourcePtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySource) *GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySource {
		return &v
	}).(GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourcePtrOutput)
}

// List of features that need to be synced to Online Store.
func (o GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceOutput) FeatureGroups() GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySource) []GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroup {
		return v.FeatureGroups
	}).(GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupArrayOutput)
}

type GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourcePtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourcePtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySource)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourcePtrOutput) ToGoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourcePtrOutput() GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourcePtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourcePtrOutput) ToGoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourcePtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourcePtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourcePtrOutput) Elem() GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySource) GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySource {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySource
		return ret
	}).(GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceOutput)
}

// List of features that need to be synced to Online Store.
func (o GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourcePtrOutput) FeatureGroups() GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupArrayOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySource) []GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroup {
		if v == nil {
			return nil
		}
		return v.FeatureGroups
	}).(GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupArrayOutput)
}

// Features belonging to a single feature group that will be synced to Online Store.
type GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroup struct {
	// Identifier of the feature group.
	FeatureGroupId string `pulumi:"featureGroupId"`
	// Identifiers of features under the feature group.
	FeatureIds []string `pulumi:"featureIds"`
}

// GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupInput is an input type that accepts GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupArgs and GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupInput` via:
//
//	GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupArgs{...}
type GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupOutput() GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupOutput
	ToGoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupOutput
}

// Features belonging to a single feature group that will be synced to Online Store.
type GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupArgs struct {
	// Identifier of the feature group.
	FeatureGroupId pulumi.StringInput `pulumi:"featureGroupId"`
	// Identifiers of features under the feature group.
	FeatureIds pulumi.StringArrayInput `pulumi:"featureIds"`
}

func (GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroup)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupArgs) ToGoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupOutput() GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupOutput {
	return i.ToGoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupArgs) ToGoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupOutput)
}

// GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupArrayInput is an input type that accepts GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupArray and GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupArrayOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupArrayInput` via:
//
//	GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupArray{ GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupArgs{...} }
type GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupArrayInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupArrayOutput() GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupArrayOutput
	ToGoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupArrayOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupArrayOutput
}

type GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupArray []GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupInput

func (GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroup)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupArray) ToGoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupArrayOutput() GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupArrayOutput {
	return i.ToGoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupArrayOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupArray) ToGoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupArrayOutput)
}

// Features belonging to a single feature group that will be synced to Online Store.
type GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroup)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupOutput) ToGoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupOutput() GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupOutput) ToGoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupOutput {
	return o
}

// Identifier of the feature group.
func (o GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupOutput) FeatureGroupId() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroup) string {
		return v.FeatureGroupId
	}).(pulumi.StringOutput)
}

// Identifiers of features under the feature group.
func (o GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupOutput) FeatureIds() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroup) []string {
		return v.FeatureIds
	}).(pulumi.StringArrayOutput)
}

type GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupArrayOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroup)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupArrayOutput) ToGoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupArrayOutput() GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupArrayOutput) ToGoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupArrayOutput) Index(i pulumi.IntInput) GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroup {
		return vs[0].([]GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroup)[vs[1].(int)]
	}).(GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupOutput)
}

// Features belonging to a single feature group that will be synced to Online Store.
type GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupResponse struct {
	// Identifier of the feature group.
	FeatureGroupId string `pulumi:"featureGroupId"`
	// Identifiers of features under the feature group.
	FeatureIds []string `pulumi:"featureIds"`
}

// Features belonging to a single feature group that will be synced to Online Store.
type GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupResponseOutput) ToGoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupResponseOutput() GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupResponseOutput) ToGoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupResponseOutput {
	return o
}

// Identifier of the feature group.
func (o GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupResponseOutput) FeatureGroupId() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupResponse) string {
		return v.FeatureGroupId
	}).(pulumi.StringOutput)
}

// Identifiers of features under the feature group.
func (o GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupResponseOutput) FeatureIds() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupResponse) []string {
		return v.FeatureIds
	}).(pulumi.StringArrayOutput)
}

type GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupResponseArrayOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupResponseArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupResponseArrayOutput) ToGoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupResponseArrayOutput() GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupResponseArrayOutput) ToGoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupResponseArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupResponseArrayOutput) Index(i pulumi.IntInput) GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupResponseOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupResponse {
		return vs[0].([]GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupResponse)[vs[1].(int)]
	}).(GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupResponseOutput)
}

// A Feature Registry source for features that need to be synced to Online Store.
type GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceResponse struct {
	// List of features that need to be synced to Online Store.
	FeatureGroups []GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupResponse `pulumi:"featureGroups"`
}

// A Feature Registry source for features that need to be synced to Online Store.
type GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceResponseOutput) ToGoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceResponseOutput() GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceResponseOutput) ToGoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceResponseOutput {
	return o
}

// List of features that need to be synced to Online Store.
func (o GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceResponseOutput) FeatureGroups() GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupResponseArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceResponse) []GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupResponse {
		return v.FeatureGroups
	}).(GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupResponseArrayOutput)
}

type GoogleCloudAiplatformV1beta1FeatureViewSyncConfig struct {
	// Cron schedule (https://en.wikipedia.org/wiki/Cron) to launch scheduled runs. To explicitly set a timezone to the cron tab, apply a prefix in the cron tab: "CRON_TZ=${IANA_TIME_ZONE}" or "TZ=${IANA_TIME_ZONE}". The ${IANA_TIME_ZONE} may only be a valid string from IANA time zone database. For example, "CRON_TZ=America/New_York 1 * * * *", or "TZ=America/New_York 1 * * * *".
	Cron *string `pulumi:"cron"`
}

// GoogleCloudAiplatformV1beta1FeatureViewSyncConfigInput is an input type that accepts GoogleCloudAiplatformV1beta1FeatureViewSyncConfigArgs and GoogleCloudAiplatformV1beta1FeatureViewSyncConfigOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1FeatureViewSyncConfigInput` via:
//
//	GoogleCloudAiplatformV1beta1FeatureViewSyncConfigArgs{...}
type GoogleCloudAiplatformV1beta1FeatureViewSyncConfigInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1FeatureViewSyncConfigOutput() GoogleCloudAiplatformV1beta1FeatureViewSyncConfigOutput
	ToGoogleCloudAiplatformV1beta1FeatureViewSyncConfigOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1FeatureViewSyncConfigOutput
}

type GoogleCloudAiplatformV1beta1FeatureViewSyncConfigArgs struct {
	// Cron schedule (https://en.wikipedia.org/wiki/Cron) to launch scheduled runs. To explicitly set a timezone to the cron tab, apply a prefix in the cron tab: "CRON_TZ=${IANA_TIME_ZONE}" or "TZ=${IANA_TIME_ZONE}". The ${IANA_TIME_ZONE} may only be a valid string from IANA time zone database. For example, "CRON_TZ=America/New_York 1 * * * *", or "TZ=America/New_York 1 * * * *".
	Cron pulumi.StringPtrInput `pulumi:"cron"`
}

func (GoogleCloudAiplatformV1beta1FeatureViewSyncConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeatureViewSyncConfig)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1FeatureViewSyncConfigArgs) ToGoogleCloudAiplatformV1beta1FeatureViewSyncConfigOutput() GoogleCloudAiplatformV1beta1FeatureViewSyncConfigOutput {
	return i.ToGoogleCloudAiplatformV1beta1FeatureViewSyncConfigOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1FeatureViewSyncConfigArgs) ToGoogleCloudAiplatformV1beta1FeatureViewSyncConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureViewSyncConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1FeatureViewSyncConfigOutput)
}

func (i GoogleCloudAiplatformV1beta1FeatureViewSyncConfigArgs) ToGoogleCloudAiplatformV1beta1FeatureViewSyncConfigPtrOutput() GoogleCloudAiplatformV1beta1FeatureViewSyncConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1FeatureViewSyncConfigPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1FeatureViewSyncConfigArgs) ToGoogleCloudAiplatformV1beta1FeatureViewSyncConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureViewSyncConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1FeatureViewSyncConfigOutput).ToGoogleCloudAiplatformV1beta1FeatureViewSyncConfigPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1FeatureViewSyncConfigPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1FeatureViewSyncConfigArgs, GoogleCloudAiplatformV1beta1FeatureViewSyncConfigPtr and GoogleCloudAiplatformV1beta1FeatureViewSyncConfigPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1FeatureViewSyncConfigPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1FeatureViewSyncConfigArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1FeatureViewSyncConfigPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1FeatureViewSyncConfigPtrOutput() GoogleCloudAiplatformV1beta1FeatureViewSyncConfigPtrOutput
	ToGoogleCloudAiplatformV1beta1FeatureViewSyncConfigPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1FeatureViewSyncConfigPtrOutput
}

type googleCloudAiplatformV1beta1FeatureViewSyncConfigPtrType GoogleCloudAiplatformV1beta1FeatureViewSyncConfigArgs

func GoogleCloudAiplatformV1beta1FeatureViewSyncConfigPtr(v *GoogleCloudAiplatformV1beta1FeatureViewSyncConfigArgs) GoogleCloudAiplatformV1beta1FeatureViewSyncConfigPtrInput {
	return (*googleCloudAiplatformV1beta1FeatureViewSyncConfigPtrType)(v)
}

func (*googleCloudAiplatformV1beta1FeatureViewSyncConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1FeatureViewSyncConfig)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1FeatureViewSyncConfigPtrType) ToGoogleCloudAiplatformV1beta1FeatureViewSyncConfigPtrOutput() GoogleCloudAiplatformV1beta1FeatureViewSyncConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1FeatureViewSyncConfigPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1FeatureViewSyncConfigPtrType) ToGoogleCloudAiplatformV1beta1FeatureViewSyncConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureViewSyncConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1FeatureViewSyncConfigPtrOutput)
}

type GoogleCloudAiplatformV1beta1FeatureViewSyncConfigOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1FeatureViewSyncConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeatureViewSyncConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1FeatureViewSyncConfigOutput) ToGoogleCloudAiplatformV1beta1FeatureViewSyncConfigOutput() GoogleCloudAiplatformV1beta1FeatureViewSyncConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeatureViewSyncConfigOutput) ToGoogleCloudAiplatformV1beta1FeatureViewSyncConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureViewSyncConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeatureViewSyncConfigOutput) ToGoogleCloudAiplatformV1beta1FeatureViewSyncConfigPtrOutput() GoogleCloudAiplatformV1beta1FeatureViewSyncConfigPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1FeatureViewSyncConfigPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1FeatureViewSyncConfigOutput) ToGoogleCloudAiplatformV1beta1FeatureViewSyncConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureViewSyncConfigPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1FeatureViewSyncConfig) *GoogleCloudAiplatformV1beta1FeatureViewSyncConfig {
		return &v
	}).(GoogleCloudAiplatformV1beta1FeatureViewSyncConfigPtrOutput)
}

// Cron schedule (https://en.wikipedia.org/wiki/Cron) to launch scheduled runs. To explicitly set a timezone to the cron tab, apply a prefix in the cron tab: "CRON_TZ=${IANA_TIME_ZONE}" or "TZ=${IANA_TIME_ZONE}". The ${IANA_TIME_ZONE} may only be a valid string from IANA time zone database. For example, "CRON_TZ=America/New_York 1 * * * *", or "TZ=America/New_York 1 * * * *".
func (o GoogleCloudAiplatformV1beta1FeatureViewSyncConfigOutput) Cron() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeatureViewSyncConfig) *string { return v.Cron }).(pulumi.StringPtrOutput)
}

type GoogleCloudAiplatformV1beta1FeatureViewSyncConfigPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1FeatureViewSyncConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1FeatureViewSyncConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1FeatureViewSyncConfigPtrOutput) ToGoogleCloudAiplatformV1beta1FeatureViewSyncConfigPtrOutput() GoogleCloudAiplatformV1beta1FeatureViewSyncConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeatureViewSyncConfigPtrOutput) ToGoogleCloudAiplatformV1beta1FeatureViewSyncConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureViewSyncConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeatureViewSyncConfigPtrOutput) Elem() GoogleCloudAiplatformV1beta1FeatureViewSyncConfigOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1FeatureViewSyncConfig) GoogleCloudAiplatformV1beta1FeatureViewSyncConfig {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1FeatureViewSyncConfig
		return ret
	}).(GoogleCloudAiplatformV1beta1FeatureViewSyncConfigOutput)
}

// Cron schedule (https://en.wikipedia.org/wiki/Cron) to launch scheduled runs. To explicitly set a timezone to the cron tab, apply a prefix in the cron tab: "CRON_TZ=${IANA_TIME_ZONE}" or "TZ=${IANA_TIME_ZONE}". The ${IANA_TIME_ZONE} may only be a valid string from IANA time zone database. For example, "CRON_TZ=America/New_York 1 * * * *", or "TZ=America/New_York 1 * * * *".
func (o GoogleCloudAiplatformV1beta1FeatureViewSyncConfigPtrOutput) Cron() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1FeatureViewSyncConfig) *string {
		if v == nil {
			return nil
		}
		return v.Cron
	}).(pulumi.StringPtrOutput)
}

type GoogleCloudAiplatformV1beta1FeatureViewSyncConfigResponse struct {
	// Cron schedule (https://en.wikipedia.org/wiki/Cron) to launch scheduled runs. To explicitly set a timezone to the cron tab, apply a prefix in the cron tab: "CRON_TZ=${IANA_TIME_ZONE}" or "TZ=${IANA_TIME_ZONE}". The ${IANA_TIME_ZONE} may only be a valid string from IANA time zone database. For example, "CRON_TZ=America/New_York 1 * * * *", or "TZ=America/New_York 1 * * * *".
	Cron string `pulumi:"cron"`
}

type GoogleCloudAiplatformV1beta1FeatureViewSyncConfigResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1FeatureViewSyncConfigResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeatureViewSyncConfigResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1FeatureViewSyncConfigResponseOutput) ToGoogleCloudAiplatformV1beta1FeatureViewSyncConfigResponseOutput() GoogleCloudAiplatformV1beta1FeatureViewSyncConfigResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeatureViewSyncConfigResponseOutput) ToGoogleCloudAiplatformV1beta1FeatureViewSyncConfigResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureViewSyncConfigResponseOutput {
	return o
}

// Cron schedule (https://en.wikipedia.org/wiki/Cron) to launch scheduled runs. To explicitly set a timezone to the cron tab, apply a prefix in the cron tab: "CRON_TZ=${IANA_TIME_ZONE}" or "TZ=${IANA_TIME_ZONE}". The ${IANA_TIME_ZONE} may only be a valid string from IANA time zone database. For example, "CRON_TZ=America/New_York 1 * * * *", or "TZ=America/New_York 1 * * * *".
func (o GoogleCloudAiplatformV1beta1FeatureViewSyncConfigResponseOutput) Cron() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeatureViewSyncConfigResponse) string { return v.Cron }).(pulumi.StringOutput)
}

// Configuration for vector search.
type GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfig struct {
	// Optional. Configuration options for using brute force search, which simply implements the standard linear search in the database for each query. It is primarily meant for benchmarking and to generate the ground truth for approximate search.
	BruteForceConfig *GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfig `pulumi:"bruteForceConfig"`
	// Optional. Column of crowding. This column contains crowding attribute which is a constraint on a neighbor list produced by nearest neighbor search requiring that no more than some value k' of the k neighbors returned have the same value of crowding_attribute.
	CrowdingColumn *string `pulumi:"crowdingColumn"`
	// Optional. The distance measure used in nearest neighbor search.
	DistanceMeasureType *GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigDistanceMeasureType `pulumi:"distanceMeasureType"`
	// Optional. Column of embedding. This column contains the source data to create index for vector search. embedding_column must be set when using vector search.
	EmbeddingColumn *string `pulumi:"embeddingColumn"`
	// Optional. The number of dimensions of the input embedding.
	EmbeddingDimension *int `pulumi:"embeddingDimension"`
	// Optional. Columns of features that're used to filter vector search results.
	FilterColumns []string `pulumi:"filterColumns"`
	// Optional. Configuration options for the tree-AH algorithm (Shallow tree + Asymmetric Hashing). Please refer to this paper for more details: https://arxiv.org/abs/1908.10396
	TreeAhConfig *GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfig `pulumi:"treeAhConfig"`
}

// GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigInput is an input type that accepts GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigArgs and GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigInput` via:
//
//	GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigArgs{...}
type GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigOutput() GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigOutput
	ToGoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigOutput
}

// Configuration for vector search.
type GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigArgs struct {
	// Optional. Configuration options for using brute force search, which simply implements the standard linear search in the database for each query. It is primarily meant for benchmarking and to generate the ground truth for approximate search.
	BruteForceConfig GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigPtrInput `pulumi:"bruteForceConfig"`
	// Optional. Column of crowding. This column contains crowding attribute which is a constraint on a neighbor list produced by nearest neighbor search requiring that no more than some value k' of the k neighbors returned have the same value of crowding_attribute.
	CrowdingColumn pulumi.StringPtrInput `pulumi:"crowdingColumn"`
	// Optional. The distance measure used in nearest neighbor search.
	DistanceMeasureType GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigDistanceMeasureTypePtrInput `pulumi:"distanceMeasureType"`
	// Optional. Column of embedding. This column contains the source data to create index for vector search. embedding_column must be set when using vector search.
	EmbeddingColumn pulumi.StringPtrInput `pulumi:"embeddingColumn"`
	// Optional. The number of dimensions of the input embedding.
	EmbeddingDimension pulumi.IntPtrInput `pulumi:"embeddingDimension"`
	// Optional. Columns of features that're used to filter vector search results.
	FilterColumns pulumi.StringArrayInput `pulumi:"filterColumns"`
	// Optional. Configuration options for the tree-AH algorithm (Shallow tree + Asymmetric Hashing). Please refer to this paper for more details: https://arxiv.org/abs/1908.10396
	TreeAhConfig GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigPtrInput `pulumi:"treeAhConfig"`
}

func (GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfig)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigArgs) ToGoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigOutput() GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigOutput {
	return i.ToGoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigArgs) ToGoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigOutput)
}

func (i GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigArgs) ToGoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigPtrOutput() GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigArgs) ToGoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigOutput).ToGoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigArgs, GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigPtr and GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigPtrOutput() GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigPtrOutput
	ToGoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigPtrOutput
}

type googleCloudAiplatformV1beta1FeatureViewVectorSearchConfigPtrType GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigArgs

func GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigPtr(v *GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigArgs) GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigPtrInput {
	return (*googleCloudAiplatformV1beta1FeatureViewVectorSearchConfigPtrType)(v)
}

func (*googleCloudAiplatformV1beta1FeatureViewVectorSearchConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfig)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1FeatureViewVectorSearchConfigPtrType) ToGoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigPtrOutput() GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1FeatureViewVectorSearchConfigPtrType) ToGoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigPtrOutput)
}

// Configuration for vector search.
type GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigOutput) ToGoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigOutput() GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigOutput) ToGoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigOutput) ToGoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigPtrOutput() GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigOutput) ToGoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfig) *GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfig {
		return &v
	}).(GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigPtrOutput)
}

// Optional. Configuration options for using brute force search, which simply implements the standard linear search in the database for each query. It is primarily meant for benchmarking and to generate the ground truth for approximate search.
func (o GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigOutput) BruteForceConfig() GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfig) *GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfig {
		return v.BruteForceConfig
	}).(GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigPtrOutput)
}

// Optional. Column of crowding. This column contains crowding attribute which is a constraint on a neighbor list produced by nearest neighbor search requiring that no more than some value k' of the k neighbors returned have the same value of crowding_attribute.
func (o GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigOutput) CrowdingColumn() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfig) *string { return v.CrowdingColumn }).(pulumi.StringPtrOutput)
}

// Optional. The distance measure used in nearest neighbor search.
func (o GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigOutput) DistanceMeasureType() GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigDistanceMeasureTypePtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfig) *GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigDistanceMeasureType {
		return v.DistanceMeasureType
	}).(GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigDistanceMeasureTypePtrOutput)
}

// Optional. Column of embedding. This column contains the source data to create index for vector search. embedding_column must be set when using vector search.
func (o GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigOutput) EmbeddingColumn() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfig) *string { return v.EmbeddingColumn }).(pulumi.StringPtrOutput)
}

// Optional. The number of dimensions of the input embedding.
func (o GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigOutput) EmbeddingDimension() pulumi.IntPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfig) *int { return v.EmbeddingDimension }).(pulumi.IntPtrOutput)
}

// Optional. Columns of features that're used to filter vector search results.
func (o GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigOutput) FilterColumns() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfig) []string { return v.FilterColumns }).(pulumi.StringArrayOutput)
}

// Optional. Configuration options for the tree-AH algorithm (Shallow tree + Asymmetric Hashing). Please refer to this paper for more details: https://arxiv.org/abs/1908.10396
func (o GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigOutput) TreeAhConfig() GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfig) *GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfig {
		return v.TreeAhConfig
	}).(GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigPtrOutput)
}

type GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigPtrOutput) ToGoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigPtrOutput() GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigPtrOutput) ToGoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigPtrOutput) Elem() GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfig) GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfig {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfig
		return ret
	}).(GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigOutput)
}

// Optional. Configuration options for using brute force search, which simply implements the standard linear search in the database for each query. It is primarily meant for benchmarking and to generate the ground truth for approximate search.
func (o GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigPtrOutput) BruteForceConfig() GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfig) *GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfig {
		if v == nil {
			return nil
		}
		return v.BruteForceConfig
	}).(GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigPtrOutput)
}

// Optional. Column of crowding. This column contains crowding attribute which is a constraint on a neighbor list produced by nearest neighbor search requiring that no more than some value k' of the k neighbors returned have the same value of crowding_attribute.
func (o GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigPtrOutput) CrowdingColumn() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfig) *string {
		if v == nil {
			return nil
		}
		return v.CrowdingColumn
	}).(pulumi.StringPtrOutput)
}

// Optional. The distance measure used in nearest neighbor search.
func (o GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigPtrOutput) DistanceMeasureType() GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigDistanceMeasureTypePtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfig) *GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigDistanceMeasureType {
		if v == nil {
			return nil
		}
		return v.DistanceMeasureType
	}).(GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigDistanceMeasureTypePtrOutput)
}

// Optional. Column of embedding. This column contains the source data to create index for vector search. embedding_column must be set when using vector search.
func (o GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigPtrOutput) EmbeddingColumn() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfig) *string {
		if v == nil {
			return nil
		}
		return v.EmbeddingColumn
	}).(pulumi.StringPtrOutput)
}

// Optional. The number of dimensions of the input embedding.
func (o GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigPtrOutput) EmbeddingDimension() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfig) *int {
		if v == nil {
			return nil
		}
		return v.EmbeddingDimension
	}).(pulumi.IntPtrOutput)
}

// Optional. Columns of features that're used to filter vector search results.
func (o GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigPtrOutput) FilterColumns() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfig) []string {
		if v == nil {
			return nil
		}
		return v.FilterColumns
	}).(pulumi.StringArrayOutput)
}

// Optional. Configuration options for the tree-AH algorithm (Shallow tree + Asymmetric Hashing). Please refer to this paper for more details: https://arxiv.org/abs/1908.10396
func (o GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigPtrOutput) TreeAhConfig() GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfig) *GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfig {
		if v == nil {
			return nil
		}
		return v.TreeAhConfig
	}).(GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigPtrOutput)
}

type GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfig struct {
}

// GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigInput is an input type that accepts GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigArgs and GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigInput` via:
//
//	GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigArgs{...}
type GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigOutput() GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigOutput
	ToGoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigOutput
}

type GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigArgs struct {
}

func (GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfig)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigArgs) ToGoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigOutput() GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigOutput {
	return i.ToGoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigArgs) ToGoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigOutput)
}

func (i GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigArgs) ToGoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigPtrOutput() GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigArgs) ToGoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigOutput).ToGoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigArgs, GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigPtr and GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigPtrOutput() GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigPtrOutput
	ToGoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigPtrOutput
}

type googleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigPtrType GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigArgs

func GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigPtr(v *GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigArgs) GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigPtrInput {
	return (*googleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigPtrType)(v)
}

func (*googleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfig)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigPtrType) ToGoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigPtrOutput() GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigPtrType) ToGoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigPtrOutput)
}

type GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigOutput) ToGoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigOutput() GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigOutput) ToGoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigOutput) ToGoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigPtrOutput() GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigOutput) ToGoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfig) *GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfig {
		return &v
	}).(GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigPtrOutput)
}

type GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigPtrOutput) ToGoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigPtrOutput() GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigPtrOutput) ToGoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigPtrOutput) Elem() GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfig) GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfig {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfig
		return ret
	}).(GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigOutput)
}

type GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigResponse struct {
}

type GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigResponseOutput) ToGoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigResponseOutput() GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigResponseOutput) ToGoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigResponseOutput {
	return o
}

// Configuration for vector search.
type GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigResponse struct {
	// Optional. Configuration options for using brute force search, which simply implements the standard linear search in the database for each query. It is primarily meant for benchmarking and to generate the ground truth for approximate search.
	BruteForceConfig GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigResponse `pulumi:"bruteForceConfig"`
	// Optional. Column of crowding. This column contains crowding attribute which is a constraint on a neighbor list produced by nearest neighbor search requiring that no more than some value k' of the k neighbors returned have the same value of crowding_attribute.
	CrowdingColumn string `pulumi:"crowdingColumn"`
	// Optional. The distance measure used in nearest neighbor search.
	DistanceMeasureType string `pulumi:"distanceMeasureType"`
	// Optional. Column of embedding. This column contains the source data to create index for vector search. embedding_column must be set when using vector search.
	EmbeddingColumn string `pulumi:"embeddingColumn"`
	// Optional. The number of dimensions of the input embedding.
	EmbeddingDimension int `pulumi:"embeddingDimension"`
	// Optional. Columns of features that're used to filter vector search results.
	FilterColumns []string `pulumi:"filterColumns"`
	// Optional. Configuration options for the tree-AH algorithm (Shallow tree + Asymmetric Hashing). Please refer to this paper for more details: https://arxiv.org/abs/1908.10396
	TreeAhConfig GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigResponse `pulumi:"treeAhConfig"`
}

// Configuration for vector search.
type GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigResponseOutput) ToGoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigResponseOutput() GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigResponseOutput) ToGoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigResponseOutput {
	return o
}

// Optional. Configuration options for using brute force search, which simply implements the standard linear search in the database for each query. It is primarily meant for benchmarking and to generate the ground truth for approximate search.
func (o GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigResponseOutput) BruteForceConfig() GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigResponse) GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigResponse {
		return v.BruteForceConfig
	}).(GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigResponseOutput)
}

// Optional. Column of crowding. This column contains crowding attribute which is a constraint on a neighbor list produced by nearest neighbor search requiring that no more than some value k' of the k neighbors returned have the same value of crowding_attribute.
func (o GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigResponseOutput) CrowdingColumn() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigResponse) string {
		return v.CrowdingColumn
	}).(pulumi.StringOutput)
}

// Optional. The distance measure used in nearest neighbor search.
func (o GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigResponseOutput) DistanceMeasureType() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigResponse) string {
		return v.DistanceMeasureType
	}).(pulumi.StringOutput)
}

// Optional. Column of embedding. This column contains the source data to create index for vector search. embedding_column must be set when using vector search.
func (o GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigResponseOutput) EmbeddingColumn() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigResponse) string {
		return v.EmbeddingColumn
	}).(pulumi.StringOutput)
}

// Optional. The number of dimensions of the input embedding.
func (o GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigResponseOutput) EmbeddingDimension() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigResponse) int {
		return v.EmbeddingDimension
	}).(pulumi.IntOutput)
}

// Optional. Columns of features that're used to filter vector search results.
func (o GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigResponseOutput) FilterColumns() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigResponse) []string {
		return v.FilterColumns
	}).(pulumi.StringArrayOutput)
}

// Optional. Configuration options for the tree-AH algorithm (Shallow tree + Asymmetric Hashing). Please refer to this paper for more details: https://arxiv.org/abs/1908.10396
func (o GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigResponseOutput) TreeAhConfig() GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigResponse) GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigResponse {
		return v.TreeAhConfig
	}).(GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigResponseOutput)
}

type GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfig struct {
	// Optional. Number of embeddings on each leaf node. The default value is 1000 if not set.
	LeafNodeEmbeddingCount *string `pulumi:"leafNodeEmbeddingCount"`
}

// GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigInput is an input type that accepts GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigArgs and GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigInput` via:
//
//	GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigArgs{...}
type GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigOutput() GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigOutput
	ToGoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigOutput
}

type GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigArgs struct {
	// Optional. Number of embeddings on each leaf node. The default value is 1000 if not set.
	LeafNodeEmbeddingCount pulumi.StringPtrInput `pulumi:"leafNodeEmbeddingCount"`
}

func (GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfig)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigArgs) ToGoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigOutput() GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigOutput {
	return i.ToGoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigArgs) ToGoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigOutput)
}

func (i GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigArgs) ToGoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigPtrOutput() GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigArgs) ToGoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigOutput).ToGoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigArgs, GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigPtr and GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigPtrOutput() GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigPtrOutput
	ToGoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigPtrOutput
}

type googleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigPtrType GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigArgs

func GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigPtr(v *GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigArgs) GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigPtrInput {
	return (*googleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigPtrType)(v)
}

func (*googleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfig)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigPtrType) ToGoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigPtrOutput() GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigPtrType) ToGoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigPtrOutput)
}

type GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigOutput) ToGoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigOutput() GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigOutput) ToGoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigOutput) ToGoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigPtrOutput() GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigOutput) ToGoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfig) *GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfig {
		return &v
	}).(GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigPtrOutput)
}

// Optional. Number of embeddings on each leaf node. The default value is 1000 if not set.
func (o GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigOutput) LeafNodeEmbeddingCount() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfig) *string {
		return v.LeafNodeEmbeddingCount
	}).(pulumi.StringPtrOutput)
}

type GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigPtrOutput) ToGoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigPtrOutput() GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigPtrOutput) ToGoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigPtrOutput) Elem() GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfig) GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfig {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfig
		return ret
	}).(GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigOutput)
}

// Optional. Number of embeddings on each leaf node. The default value is 1000 if not set.
func (o GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigPtrOutput) LeafNodeEmbeddingCount() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfig) *string {
		if v == nil {
			return nil
		}
		return v.LeafNodeEmbeddingCount
	}).(pulumi.StringPtrOutput)
}

type GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigResponse struct {
	// Optional. Number of embeddings on each leaf node. The default value is 1000 if not set.
	LeafNodeEmbeddingCount string `pulumi:"leafNodeEmbeddingCount"`
}

type GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigResponseOutput) ToGoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigResponseOutput() GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigResponseOutput) ToGoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigResponseOutput {
	return o
}

// Optional. Number of embeddings on each leaf node. The default value is 1000 if not set.
func (o GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigResponseOutput) LeafNodeEmbeddingCount() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigResponse) string {
		return v.LeafNodeEmbeddingCount
	}).(pulumi.StringOutput)
}

// Configuration of how features in Featurestore are monitored.
type GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfig struct {
	// Threshold for categorical features of anomaly detection. This is shared by all types of Featurestore Monitoring for categorical features (i.e. Features with type (Feature.ValueType) BOOL or STRING).
	CategoricalThresholdConfig *GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfig `pulumi:"categoricalThresholdConfig"`
	// The config for ImportFeatures Analysis Based Feature Monitoring.
	ImportFeaturesAnalysis *GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysis `pulumi:"importFeaturesAnalysis"`
	// Threshold for numerical features of anomaly detection. This is shared by all objectives of Featurestore Monitoring for numerical features (i.e. Features with type (Feature.ValueType) DOUBLE or INT64).
	NumericalThresholdConfig *GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfig `pulumi:"numericalThresholdConfig"`
	// The config for Snapshot Analysis Based Feature Monitoring.
	SnapshotAnalysis *GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysis `pulumi:"snapshotAnalysis"`
}

// GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigInput is an input type that accepts GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigArgs and GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigInput` via:
//
//	GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigArgs{...}
type GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigOutput() GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigOutput
	ToGoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigOutput
}

// Configuration of how features in Featurestore are monitored.
type GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigArgs struct {
	// Threshold for categorical features of anomaly detection. This is shared by all types of Featurestore Monitoring for categorical features (i.e. Features with type (Feature.ValueType) BOOL or STRING).
	CategoricalThresholdConfig GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigPtrInput `pulumi:"categoricalThresholdConfig"`
	// The config for ImportFeatures Analysis Based Feature Monitoring.
	ImportFeaturesAnalysis GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrInput `pulumi:"importFeaturesAnalysis"`
	// Threshold for numerical features of anomaly detection. This is shared by all objectives of Featurestore Monitoring for numerical features (i.e. Features with type (Feature.ValueType) DOUBLE or INT64).
	NumericalThresholdConfig GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigPtrInput `pulumi:"numericalThresholdConfig"`
	// The config for Snapshot Analysis Based Feature Monitoring.
	SnapshotAnalysis GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisPtrInput `pulumi:"snapshotAnalysis"`
}

func (GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfig)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigArgs) ToGoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigOutput() GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigOutput {
	return i.ToGoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigArgs) ToGoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigOutput)
}

func (i GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigArgs) ToGoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigPtrOutput() GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigArgs) ToGoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigOutput).ToGoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigArgs, GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigPtr and GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigPtrOutput() GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigPtrOutput
	ToGoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigPtrOutput
}

type googleCloudAiplatformV1beta1FeaturestoreMonitoringConfigPtrType GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigArgs

func GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigPtr(v *GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigArgs) GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigPtrInput {
	return (*googleCloudAiplatformV1beta1FeaturestoreMonitoringConfigPtrType)(v)
}

func (*googleCloudAiplatformV1beta1FeaturestoreMonitoringConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfig)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1FeaturestoreMonitoringConfigPtrType) ToGoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigPtrOutput() GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1FeaturestoreMonitoringConfigPtrType) ToGoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigPtrOutput)
}

// Configuration of how features in Featurestore are monitored.
type GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigOutput) ToGoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigOutput() GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigOutput) ToGoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigOutput) ToGoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigPtrOutput() GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigOutput) ToGoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfig) *GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfig {
		return &v
	}).(GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigPtrOutput)
}

// Threshold for categorical features of anomaly detection. This is shared by all types of Featurestore Monitoring for categorical features (i.e. Features with type (Feature.ValueType) BOOL or STRING).
func (o GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigOutput) CategoricalThresholdConfig() GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfig) *GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfig {
		return v.CategoricalThresholdConfig
	}).(GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigPtrOutput)
}

// The config for ImportFeatures Analysis Based Feature Monitoring.
func (o GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigOutput) ImportFeaturesAnalysis() GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfig) *GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysis {
		return v.ImportFeaturesAnalysis
	}).(GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrOutput)
}

// Threshold for numerical features of anomaly detection. This is shared by all objectives of Featurestore Monitoring for numerical features (i.e. Features with type (Feature.ValueType) DOUBLE or INT64).
func (o GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigOutput) NumericalThresholdConfig() GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfig) *GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfig {
		return v.NumericalThresholdConfig
	}).(GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigPtrOutput)
}

// The config for Snapshot Analysis Based Feature Monitoring.
func (o GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigOutput) SnapshotAnalysis() GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfig) *GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysis {
		return v.SnapshotAnalysis
	}).(GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisPtrOutput)
}

type GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigPtrOutput) ToGoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigPtrOutput() GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigPtrOutput) ToGoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigPtrOutput) Elem() GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfig) GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfig {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfig
		return ret
	}).(GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigOutput)
}

// Threshold for categorical features of anomaly detection. This is shared by all types of Featurestore Monitoring for categorical features (i.e. Features with type (Feature.ValueType) BOOL or STRING).
func (o GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigPtrOutput) CategoricalThresholdConfig() GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfig) *GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfig {
		if v == nil {
			return nil
		}
		return v.CategoricalThresholdConfig
	}).(GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigPtrOutput)
}

// The config for ImportFeatures Analysis Based Feature Monitoring.
func (o GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigPtrOutput) ImportFeaturesAnalysis() GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfig) *GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysis {
		if v == nil {
			return nil
		}
		return v.ImportFeaturesAnalysis
	}).(GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrOutput)
}

// Threshold for numerical features of anomaly detection. This is shared by all objectives of Featurestore Monitoring for numerical features (i.e. Features with type (Feature.ValueType) DOUBLE or INT64).
func (o GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigPtrOutput) NumericalThresholdConfig() GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfig) *GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfig {
		if v == nil {
			return nil
		}
		return v.NumericalThresholdConfig
	}).(GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigPtrOutput)
}

// The config for Snapshot Analysis Based Feature Monitoring.
func (o GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigPtrOutput) SnapshotAnalysis() GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfig) *GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysis {
		if v == nil {
			return nil
		}
		return v.SnapshotAnalysis
	}).(GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisPtrOutput)
}

// Configuration of the Featurestore's ImportFeature Analysis Based Monitoring. This type of analysis generates statistics for values of each Feature imported by every ImportFeatureValues operation.
type GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysis struct {
	// The baseline used to do anomaly detection for the statistics generated by import features analysis.
	AnomalyDetectionBaseline *GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisAnomalyDetectionBaseline `pulumi:"anomalyDetectionBaseline"`
	// Whether to enable / disable / inherite default hebavior for import features analysis.
	State *GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisState `pulumi:"state"`
}

// GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisInput is an input type that accepts GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisArgs and GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisInput` via:
//
//	GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisArgs{...}
type GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisOutput() GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisOutput
	ToGoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisOutput
}

// Configuration of the Featurestore's ImportFeature Analysis Based Monitoring. This type of analysis generates statistics for values of each Feature imported by every ImportFeatureValues operation.
type GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisArgs struct {
	// The baseline used to do anomaly detection for the statistics generated by import features analysis.
	AnomalyDetectionBaseline GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisAnomalyDetectionBaselinePtrInput `pulumi:"anomalyDetectionBaseline"`
	// Whether to enable / disable / inherite default hebavior for import features analysis.
	State GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisStatePtrInput `pulumi:"state"`
}

func (GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysis)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisArgs) ToGoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisOutput() GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisOutput {
	return i.ToGoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisArgs) ToGoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisOutput)
}

func (i GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisArgs) ToGoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrOutput() GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisArgs) ToGoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisOutput).ToGoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisArgs, GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtr and GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrOutput() GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrOutput
	ToGoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrOutput
}

type googleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrType GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisArgs

func GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtr(v *GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisArgs) GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrInput {
	return (*googleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrType)(v)
}

func (*googleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysis)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrType) ToGoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrOutput() GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrType) ToGoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrOutput)
}

// Configuration of the Featurestore's ImportFeature Analysis Based Monitoring. This type of analysis generates statistics for values of each Feature imported by every ImportFeatureValues operation.
type GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysis)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisOutput) ToGoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisOutput() GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisOutput) ToGoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisOutput) ToGoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrOutput() GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisOutput) ToGoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysis) *GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysis {
		return &v
	}).(GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrOutput)
}

// The baseline used to do anomaly detection for the statistics generated by import features analysis.
func (o GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisOutput) AnomalyDetectionBaseline() GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisAnomalyDetectionBaselinePtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysis) *GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisAnomalyDetectionBaseline {
		return v.AnomalyDetectionBaseline
	}).(GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisAnomalyDetectionBaselinePtrOutput)
}

// Whether to enable / disable / inherite default hebavior for import features analysis.
func (o GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisOutput) State() GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisStatePtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysis) *GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisState {
		return v.State
	}).(GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisStatePtrOutput)
}

type GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysis)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrOutput) ToGoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrOutput() GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrOutput) ToGoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrOutput) Elem() GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysis) GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysis {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysis
		return ret
	}).(GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisOutput)
}

// The baseline used to do anomaly detection for the statistics generated by import features analysis.
func (o GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrOutput) AnomalyDetectionBaseline() GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisAnomalyDetectionBaselinePtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysis) *GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisAnomalyDetectionBaseline {
		if v == nil {
			return nil
		}
		return v.AnomalyDetectionBaseline
	}).(GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisAnomalyDetectionBaselinePtrOutput)
}

// Whether to enable / disable / inherite default hebavior for import features analysis.
func (o GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrOutput) State() GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisStatePtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysis) *GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisState {
		if v == nil {
			return nil
		}
		return v.State
	}).(GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisStatePtrOutput)
}

// Configuration of the Featurestore's ImportFeature Analysis Based Monitoring. This type of analysis generates statistics for values of each Feature imported by every ImportFeatureValues operation.
type GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisResponse struct {
	// The baseline used to do anomaly detection for the statistics generated by import features analysis.
	AnomalyDetectionBaseline string `pulumi:"anomalyDetectionBaseline"`
	// Whether to enable / disable / inherite default hebavior for import features analysis.
	State string `pulumi:"state"`
}

// Configuration of the Featurestore's ImportFeature Analysis Based Monitoring. This type of analysis generates statistics for values of each Feature imported by every ImportFeatureValues operation.
type GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisResponseOutput) ToGoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisResponseOutput() GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisResponseOutput) ToGoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisResponseOutput {
	return o
}

// The baseline used to do anomaly detection for the statistics generated by import features analysis.
func (o GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisResponseOutput) AnomalyDetectionBaseline() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisResponse) string {
		return v.AnomalyDetectionBaseline
	}).(pulumi.StringOutput)
}

// Whether to enable / disable / inherite default hebavior for import features analysis.
func (o GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisResponseOutput) State() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisResponse) string {
		return v.State
	}).(pulumi.StringOutput)
}

// Configuration of how features in Featurestore are monitored.
type GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigResponse struct {
	// Threshold for categorical features of anomaly detection. This is shared by all types of Featurestore Monitoring for categorical features (i.e. Features with type (Feature.ValueType) BOOL or STRING).
	CategoricalThresholdConfig GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigResponse `pulumi:"categoricalThresholdConfig"`
	// The config for ImportFeatures Analysis Based Feature Monitoring.
	ImportFeaturesAnalysis GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisResponse `pulumi:"importFeaturesAnalysis"`
	// Threshold for numerical features of anomaly detection. This is shared by all objectives of Featurestore Monitoring for numerical features (i.e. Features with type (Feature.ValueType) DOUBLE or INT64).
	NumericalThresholdConfig GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigResponse `pulumi:"numericalThresholdConfig"`
	// The config for Snapshot Analysis Based Feature Monitoring.
	SnapshotAnalysis GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisResponse `pulumi:"snapshotAnalysis"`
}

// Configuration of how features in Featurestore are monitored.
type GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigResponseOutput) ToGoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigResponseOutput() GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigResponseOutput) ToGoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigResponseOutput {
	return o
}

// Threshold for categorical features of anomaly detection. This is shared by all types of Featurestore Monitoring for categorical features (i.e. Features with type (Feature.ValueType) BOOL or STRING).
func (o GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigResponseOutput) CategoricalThresholdConfig() GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigResponse) GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigResponse {
		return v.CategoricalThresholdConfig
	}).(GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigResponseOutput)
}

// The config for ImportFeatures Analysis Based Feature Monitoring.
func (o GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigResponseOutput) ImportFeaturesAnalysis() GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigResponse) GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisResponse {
		return v.ImportFeaturesAnalysis
	}).(GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisResponseOutput)
}

// Threshold for numerical features of anomaly detection. This is shared by all objectives of Featurestore Monitoring for numerical features (i.e. Features with type (Feature.ValueType) DOUBLE or INT64).
func (o GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigResponseOutput) NumericalThresholdConfig() GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigResponse) GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigResponse {
		return v.NumericalThresholdConfig
	}).(GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigResponseOutput)
}

// The config for Snapshot Analysis Based Feature Monitoring.
func (o GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigResponseOutput) SnapshotAnalysis() GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigResponse) GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisResponse {
		return v.SnapshotAnalysis
	}).(GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisResponseOutput)
}

// Configuration of the Featurestore's Snapshot Analysis Based Monitoring. This type of analysis generates statistics for each Feature based on a snapshot of the latest feature value of each entities every monitoring_interval.
type GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysis struct {
	// The monitoring schedule for snapshot analysis. For EntityType-level config: unset / disabled = true indicates disabled by default for Features under it; otherwise by default enable snapshot analysis monitoring with monitoring_interval for Features under it. Feature-level config: disabled = true indicates disabled regardless of the EntityType-level config; unset monitoring_interval indicates going with EntityType-level config; otherwise run snapshot analysis monitoring with monitoring_interval regardless of the EntityType-level config. Explicitly Disable the snapshot analysis based monitoring.
	Disabled *bool `pulumi:"disabled"`
	// Configuration of the snapshot analysis based monitoring pipeline running interval. The value is rolled up to full day. If both monitoring_interval_days and the deprecated `monitoring_interval` field are set when creating/updating EntityTypes/Features, monitoring_interval_days will be used.
	MonitoringInterval *string `pulumi:"monitoringInterval"`
	// Configuration of the snapshot analysis based monitoring pipeline running interval. The value indicates number of days.
	MonitoringIntervalDays *int `pulumi:"monitoringIntervalDays"`
	// Customized export features time window for snapshot analysis. Unit is one day. Default value is 3 weeks. Minimum value is 1 day. Maximum value is 4000 days.
	StalenessDays *int `pulumi:"stalenessDays"`
}

// GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisInput is an input type that accepts GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisArgs and GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisInput` via:
//
//	GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisArgs{...}
type GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisOutput() GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisOutput
	ToGoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisOutput
}

// Configuration of the Featurestore's Snapshot Analysis Based Monitoring. This type of analysis generates statistics for each Feature based on a snapshot of the latest feature value of each entities every monitoring_interval.
type GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisArgs struct {
	// The monitoring schedule for snapshot analysis. For EntityType-level config: unset / disabled = true indicates disabled by default for Features under it; otherwise by default enable snapshot analysis monitoring with monitoring_interval for Features under it. Feature-level config: disabled = true indicates disabled regardless of the EntityType-level config; unset monitoring_interval indicates going with EntityType-level config; otherwise run snapshot analysis monitoring with monitoring_interval regardless of the EntityType-level config. Explicitly Disable the snapshot analysis based monitoring.
	Disabled pulumi.BoolPtrInput `pulumi:"disabled"`
	// Configuration of the snapshot analysis based monitoring pipeline running interval. The value is rolled up to full day. If both monitoring_interval_days and the deprecated `monitoring_interval` field are set when creating/updating EntityTypes/Features, monitoring_interval_days will be used.
	MonitoringInterval pulumi.StringPtrInput `pulumi:"monitoringInterval"`
	// Configuration of the snapshot analysis based monitoring pipeline running interval. The value indicates number of days.
	MonitoringIntervalDays pulumi.IntPtrInput `pulumi:"monitoringIntervalDays"`
	// Customized export features time window for snapshot analysis. Unit is one day. Default value is 3 weeks. Minimum value is 1 day. Maximum value is 4000 days.
	StalenessDays pulumi.IntPtrInput `pulumi:"stalenessDays"`
}

func (GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysis)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisArgs) ToGoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisOutput() GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisOutput {
	return i.ToGoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisArgs) ToGoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisOutput)
}

func (i GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisArgs) ToGoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisPtrOutput() GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisArgs) ToGoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisOutput).ToGoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisArgs, GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisPtr and GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisPtrOutput() GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisPtrOutput
	ToGoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisPtrOutput
}

type googleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisPtrType GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisArgs

func GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisPtr(v *GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisArgs) GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisPtrInput {
	return (*googleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisPtrType)(v)
}

func (*googleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysis)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisPtrType) ToGoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisPtrOutput() GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisPtrType) ToGoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisPtrOutput)
}

// Configuration of the Featurestore's Snapshot Analysis Based Monitoring. This type of analysis generates statistics for each Feature based on a snapshot of the latest feature value of each entities every monitoring_interval.
type GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysis)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisOutput) ToGoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisOutput() GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisOutput) ToGoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisOutput) ToGoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisPtrOutput() GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisOutput) ToGoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysis) *GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysis {
		return &v
	}).(GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisPtrOutput)
}

// The monitoring schedule for snapshot analysis. For EntityType-level config: unset / disabled = true indicates disabled by default for Features under it; otherwise by default enable snapshot analysis monitoring with monitoring_interval for Features under it. Feature-level config: disabled = true indicates disabled regardless of the EntityType-level config; unset monitoring_interval indicates going with EntityType-level config; otherwise run snapshot analysis monitoring with monitoring_interval regardless of the EntityType-level config. Explicitly Disable the snapshot analysis based monitoring.
func (o GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisOutput) Disabled() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysis) *bool {
		return v.Disabled
	}).(pulumi.BoolPtrOutput)
}

// Configuration of the snapshot analysis based monitoring pipeline running interval. The value is rolled up to full day. If both monitoring_interval_days and the deprecated `monitoring_interval` field are set when creating/updating EntityTypes/Features, monitoring_interval_days will be used.
func (o GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisOutput) MonitoringInterval() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysis) *string {
		return v.MonitoringInterval
	}).(pulumi.StringPtrOutput)
}

// Configuration of the snapshot analysis based monitoring pipeline running interval. The value indicates number of days.
func (o GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisOutput) MonitoringIntervalDays() pulumi.IntPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysis) *int {
		return v.MonitoringIntervalDays
	}).(pulumi.IntPtrOutput)
}

// Customized export features time window for snapshot analysis. Unit is one day. Default value is 3 weeks. Minimum value is 1 day. Maximum value is 4000 days.
func (o GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisOutput) StalenessDays() pulumi.IntPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysis) *int {
		return v.StalenessDays
	}).(pulumi.IntPtrOutput)
}

type GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysis)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisPtrOutput) ToGoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisPtrOutput() GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisPtrOutput) ToGoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisPtrOutput) Elem() GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysis) GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysis {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysis
		return ret
	}).(GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisOutput)
}

// The monitoring schedule for snapshot analysis. For EntityType-level config: unset / disabled = true indicates disabled by default for Features under it; otherwise by default enable snapshot analysis monitoring with monitoring_interval for Features under it. Feature-level config: disabled = true indicates disabled regardless of the EntityType-level config; unset monitoring_interval indicates going with EntityType-level config; otherwise run snapshot analysis monitoring with monitoring_interval regardless of the EntityType-level config. Explicitly Disable the snapshot analysis based monitoring.
func (o GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisPtrOutput) Disabled() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysis) *bool {
		if v == nil {
			return nil
		}
		return v.Disabled
	}).(pulumi.BoolPtrOutput)
}

// Configuration of the snapshot analysis based monitoring pipeline running interval. The value is rolled up to full day. If both monitoring_interval_days and the deprecated `monitoring_interval` field are set when creating/updating EntityTypes/Features, monitoring_interval_days will be used.
func (o GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisPtrOutput) MonitoringInterval() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysis) *string {
		if v == nil {
			return nil
		}
		return v.MonitoringInterval
	}).(pulumi.StringPtrOutput)
}

// Configuration of the snapshot analysis based monitoring pipeline running interval. The value indicates number of days.
func (o GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisPtrOutput) MonitoringIntervalDays() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysis) *int {
		if v == nil {
			return nil
		}
		return v.MonitoringIntervalDays
	}).(pulumi.IntPtrOutput)
}

// Customized export features time window for snapshot analysis. Unit is one day. Default value is 3 weeks. Minimum value is 1 day. Maximum value is 4000 days.
func (o GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisPtrOutput) StalenessDays() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysis) *int {
		if v == nil {
			return nil
		}
		return v.StalenessDays
	}).(pulumi.IntPtrOutput)
}

// Configuration of the Featurestore's Snapshot Analysis Based Monitoring. This type of analysis generates statistics for each Feature based on a snapshot of the latest feature value of each entities every monitoring_interval.
type GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisResponse struct {
	// The monitoring schedule for snapshot analysis. For EntityType-level config: unset / disabled = true indicates disabled by default for Features under it; otherwise by default enable snapshot analysis monitoring with monitoring_interval for Features under it. Feature-level config: disabled = true indicates disabled regardless of the EntityType-level config; unset monitoring_interval indicates going with EntityType-level config; otherwise run snapshot analysis monitoring with monitoring_interval regardless of the EntityType-level config. Explicitly Disable the snapshot analysis based monitoring.
	Disabled bool `pulumi:"disabled"`
	// Configuration of the snapshot analysis based monitoring pipeline running interval. The value is rolled up to full day. If both monitoring_interval_days and the deprecated `monitoring_interval` field are set when creating/updating EntityTypes/Features, monitoring_interval_days will be used.
	MonitoringInterval string `pulumi:"monitoringInterval"`
	// Configuration of the snapshot analysis based monitoring pipeline running interval. The value indicates number of days.
	MonitoringIntervalDays int `pulumi:"monitoringIntervalDays"`
	// Customized export features time window for snapshot analysis. Unit is one day. Default value is 3 weeks. Minimum value is 1 day. Maximum value is 4000 days.
	StalenessDays int `pulumi:"stalenessDays"`
}

// Configuration of the Featurestore's Snapshot Analysis Based Monitoring. This type of analysis generates statistics for each Feature based on a snapshot of the latest feature value of each entities every monitoring_interval.
type GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisResponseOutput) ToGoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisResponseOutput() GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisResponseOutput) ToGoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisResponseOutput {
	return o
}

// The monitoring schedule for snapshot analysis. For EntityType-level config: unset / disabled = true indicates disabled by default for Features under it; otherwise by default enable snapshot analysis monitoring with monitoring_interval for Features under it. Feature-level config: disabled = true indicates disabled regardless of the EntityType-level config; unset monitoring_interval indicates going with EntityType-level config; otherwise run snapshot analysis monitoring with monitoring_interval regardless of the EntityType-level config. Explicitly Disable the snapshot analysis based monitoring.
func (o GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisResponseOutput) Disabled() pulumi.BoolOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisResponse) bool {
		return v.Disabled
	}).(pulumi.BoolOutput)
}

// Configuration of the snapshot analysis based monitoring pipeline running interval. The value is rolled up to full day. If both monitoring_interval_days and the deprecated `monitoring_interval` field are set when creating/updating EntityTypes/Features, monitoring_interval_days will be used.
func (o GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisResponseOutput) MonitoringInterval() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisResponse) string {
		return v.MonitoringInterval
	}).(pulumi.StringOutput)
}

// Configuration of the snapshot analysis based monitoring pipeline running interval. The value indicates number of days.
func (o GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisResponseOutput) MonitoringIntervalDays() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisResponse) int {
		return v.MonitoringIntervalDays
	}).(pulumi.IntOutput)
}

// Customized export features time window for snapshot analysis. Unit is one day. Default value is 3 weeks. Minimum value is 1 day. Maximum value is 4000 days.
func (o GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisResponseOutput) StalenessDays() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisResponse) int {
		return v.StalenessDays
	}).(pulumi.IntOutput)
}

// The config for Featurestore Monitoring threshold.
type GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfig struct {
	// Specify a threshold value that can trigger the alert. 1. For categorical feature, the distribution distance is calculated by L-inifinity norm. 2. For numerical feature, the distribution distance is calculated by Jensen–Shannon divergence. Each feature must have a non-zero threshold if they need to be monitored. Otherwise no alert will be triggered for that feature.
	Value *float64 `pulumi:"value"`
}

// GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigInput is an input type that accepts GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigArgs and GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigInput` via:
//
//	GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigArgs{...}
type GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigOutput() GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigOutput
	ToGoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigOutput
}

// The config for Featurestore Monitoring threshold.
type GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigArgs struct {
	// Specify a threshold value that can trigger the alert. 1. For categorical feature, the distribution distance is calculated by L-inifinity norm. 2. For numerical feature, the distribution distance is calculated by Jensen–Shannon divergence. Each feature must have a non-zero threshold if they need to be monitored. Otherwise no alert will be triggered for that feature.
	Value pulumi.Float64PtrInput `pulumi:"value"`
}

func (GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfig)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigArgs) ToGoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigOutput() GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigOutput {
	return i.ToGoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigArgs) ToGoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigOutput)
}

func (i GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigArgs) ToGoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigPtrOutput() GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigArgs) ToGoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigOutput).ToGoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigArgs, GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigPtr and GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigPtrOutput() GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigPtrOutput
	ToGoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigPtrOutput
}

type googleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigPtrType GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigArgs

func GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigPtr(v *GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigArgs) GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigPtrInput {
	return (*googleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigPtrType)(v)
}

func (*googleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfig)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigPtrType) ToGoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigPtrOutput() GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigPtrType) ToGoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigPtrOutput)
}

// The config for Featurestore Monitoring threshold.
type GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigOutput) ToGoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigOutput() GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigOutput) ToGoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigOutput) ToGoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigPtrOutput() GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigOutput) ToGoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfig) *GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfig {
		return &v
	}).(GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigPtrOutput)
}

// Specify a threshold value that can trigger the alert. 1. For categorical feature, the distribution distance is calculated by L-inifinity norm. 2. For numerical feature, the distribution distance is calculated by Jensen–Shannon divergence. Each feature must have a non-zero threshold if they need to be monitored. Otherwise no alert will be triggered for that feature.
func (o GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigOutput) Value() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfig) *float64 {
		return v.Value
	}).(pulumi.Float64PtrOutput)
}

type GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigPtrOutput) ToGoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigPtrOutput() GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigPtrOutput) ToGoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigPtrOutput) Elem() GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfig) GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfig {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfig
		return ret
	}).(GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigOutput)
}

// Specify a threshold value that can trigger the alert. 1. For categorical feature, the distribution distance is calculated by L-inifinity norm. 2. For numerical feature, the distribution distance is calculated by Jensen–Shannon divergence. Each feature must have a non-zero threshold if they need to be monitored. Otherwise no alert will be triggered for that feature.
func (o GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigPtrOutput) Value() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfig) *float64 {
		if v == nil {
			return nil
		}
		return v.Value
	}).(pulumi.Float64PtrOutput)
}

// The config for Featurestore Monitoring threshold.
type GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigResponse struct {
	// Specify a threshold value that can trigger the alert. 1. For categorical feature, the distribution distance is calculated by L-inifinity norm. 2. For numerical feature, the distribution distance is calculated by Jensen–Shannon divergence. Each feature must have a non-zero threshold if they need to be monitored. Otherwise no alert will be triggered for that feature.
	Value float64 `pulumi:"value"`
}

// The config for Featurestore Monitoring threshold.
type GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigResponseOutput) ToGoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigResponseOutput() GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigResponseOutput) ToGoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigResponseOutput {
	return o
}

// Specify a threshold value that can trigger the alert. 1. For categorical feature, the distribution distance is calculated by L-inifinity norm. 2. For numerical feature, the distribution distance is calculated by Jensen–Shannon divergence. Each feature must have a non-zero threshold if they need to be monitored. Otherwise no alert will be triggered for that feature.
func (o GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigResponseOutput) Value() pulumi.Float64Output {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigResponse) float64 {
		return v.Value
	}).(pulumi.Float64Output)
}

// OnlineServingConfig specifies the details for provisioning online serving resources.
type GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfig struct {
	// The number of nodes for the online store. The number of nodes doesn't scale automatically, but you can manually update the number of nodes. If set to 0, the featurestore will not have an online store and cannot be used for online serving.
	FixedNodeCount *int `pulumi:"fixedNodeCount"`
	// Online serving scaling configuration. Only one of `fixed_node_count` and `scaling` can be set. Setting one will reset the other.
	Scaling *GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScaling `pulumi:"scaling"`
}

// GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigInput is an input type that accepts GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigArgs and GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigInput` via:
//
//	GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigArgs{...}
type GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigOutput() GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigOutput
	ToGoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigOutput
}

// OnlineServingConfig specifies the details for provisioning online serving resources.
type GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigArgs struct {
	// The number of nodes for the online store. The number of nodes doesn't scale automatically, but you can manually update the number of nodes. If set to 0, the featurestore will not have an online store and cannot be used for online serving.
	FixedNodeCount pulumi.IntPtrInput `pulumi:"fixedNodeCount"`
	// Online serving scaling configuration. Only one of `fixed_node_count` and `scaling` can be set. Setting one will reset the other.
	Scaling GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingPtrInput `pulumi:"scaling"`
}

func (GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfig)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigArgs) ToGoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigOutput() GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigOutput {
	return i.ToGoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigArgs) ToGoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigOutput)
}

func (i GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigArgs) ToGoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigPtrOutput() GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigArgs) ToGoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigOutput).ToGoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigArgs, GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigPtr and GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigPtrOutput() GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigPtrOutput
	ToGoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigPtrOutput
}

type googleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigPtrType GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigArgs

func GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigPtr(v *GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigArgs) GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigPtrInput {
	return (*googleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigPtrType)(v)
}

func (*googleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfig)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigPtrType) ToGoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigPtrOutput() GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigPtrType) ToGoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigPtrOutput)
}

// OnlineServingConfig specifies the details for provisioning online serving resources.
type GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigOutput) ToGoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigOutput() GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigOutput) ToGoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigOutput) ToGoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigPtrOutput() GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigOutput) ToGoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfig) *GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfig {
		return &v
	}).(GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigPtrOutput)
}

// The number of nodes for the online store. The number of nodes doesn't scale automatically, but you can manually update the number of nodes. If set to 0, the featurestore will not have an online store and cannot be used for online serving.
func (o GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigOutput) FixedNodeCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfig) *int { return v.FixedNodeCount }).(pulumi.IntPtrOutput)
}

// Online serving scaling configuration. Only one of `fixed_node_count` and `scaling` can be set. Setting one will reset the other.
func (o GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigOutput) Scaling() GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfig) *GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScaling {
		return v.Scaling
	}).(GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingPtrOutput)
}

type GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigPtrOutput) ToGoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigPtrOutput() GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigPtrOutput) ToGoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigPtrOutput) Elem() GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfig) GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfig {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfig
		return ret
	}).(GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigOutput)
}

// The number of nodes for the online store. The number of nodes doesn't scale automatically, but you can manually update the number of nodes. If set to 0, the featurestore will not have an online store and cannot be used for online serving.
func (o GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigPtrOutput) FixedNodeCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfig) *int {
		if v == nil {
			return nil
		}
		return v.FixedNodeCount
	}).(pulumi.IntPtrOutput)
}

// Online serving scaling configuration. Only one of `fixed_node_count` and `scaling` can be set. Setting one will reset the other.
func (o GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigPtrOutput) Scaling() GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfig) *GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScaling {
		if v == nil {
			return nil
		}
		return v.Scaling
	}).(GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingPtrOutput)
}

// OnlineServingConfig specifies the details for provisioning online serving resources.
type GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigResponse struct {
	// The number of nodes for the online store. The number of nodes doesn't scale automatically, but you can manually update the number of nodes. If set to 0, the featurestore will not have an online store and cannot be used for online serving.
	FixedNodeCount int `pulumi:"fixedNodeCount"`
	// Online serving scaling configuration. Only one of `fixed_node_count` and `scaling` can be set. Setting one will reset the other.
	Scaling GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingResponse `pulumi:"scaling"`
}

// OnlineServingConfig specifies the details for provisioning online serving resources.
type GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigResponseOutput) ToGoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigResponseOutput() GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigResponseOutput) ToGoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigResponseOutput {
	return o
}

// The number of nodes for the online store. The number of nodes doesn't scale automatically, but you can manually update the number of nodes. If set to 0, the featurestore will not have an online store and cannot be used for online serving.
func (o GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigResponseOutput) FixedNodeCount() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigResponse) int {
		return v.FixedNodeCount
	}).(pulumi.IntOutput)
}

// Online serving scaling configuration. Only one of `fixed_node_count` and `scaling` can be set. Setting one will reset the other.
func (o GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigResponseOutput) Scaling() GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigResponse) GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingResponse {
		return v.Scaling
	}).(GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingResponseOutput)
}

// Online serving scaling configuration. If min_node_count and max_node_count are set to the same value, the cluster will be configured with the fixed number of node (no auto-scaling).
type GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScaling struct {
	// Optional. The cpu utilization that the Autoscaler should be trying to achieve. This number is on a scale from 0 (no utilization) to 100 (total utilization), and is limited between 10 and 80. When a cluster's CPU utilization exceeds the target that you have set, Bigtable immediately adds nodes to the cluster. When CPU utilization is substantially lower than the target, Bigtable removes nodes. If not set or set to 0, default to 50.
	CpuUtilizationTarget *int `pulumi:"cpuUtilizationTarget"`
	// The maximum number of nodes to scale up to. Must be greater than min_node_count, and less than or equal to 10 times of 'min_node_count'.
	MaxNodeCount *int `pulumi:"maxNodeCount"`
	// The minimum number of nodes to scale down to. Must be greater than or equal to 1.
	MinNodeCount int `pulumi:"minNodeCount"`
}

// GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingInput is an input type that accepts GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingArgs and GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingInput` via:
//
//	GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingArgs{...}
type GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingOutput() GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingOutput
	ToGoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingOutput
}

// Online serving scaling configuration. If min_node_count and max_node_count are set to the same value, the cluster will be configured with the fixed number of node (no auto-scaling).
type GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingArgs struct {
	// Optional. The cpu utilization that the Autoscaler should be trying to achieve. This number is on a scale from 0 (no utilization) to 100 (total utilization), and is limited between 10 and 80. When a cluster's CPU utilization exceeds the target that you have set, Bigtable immediately adds nodes to the cluster. When CPU utilization is substantially lower than the target, Bigtable removes nodes. If not set or set to 0, default to 50.
	CpuUtilizationTarget pulumi.IntPtrInput `pulumi:"cpuUtilizationTarget"`
	// The maximum number of nodes to scale up to. Must be greater than min_node_count, and less than or equal to 10 times of 'min_node_count'.
	MaxNodeCount pulumi.IntPtrInput `pulumi:"maxNodeCount"`
	// The minimum number of nodes to scale down to. Must be greater than or equal to 1.
	MinNodeCount pulumi.IntInput `pulumi:"minNodeCount"`
}

func (GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScaling)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingArgs) ToGoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingOutput() GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingOutput {
	return i.ToGoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingArgs) ToGoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingOutput)
}

func (i GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingArgs) ToGoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingPtrOutput() GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingArgs) ToGoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingOutput).ToGoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingArgs, GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingPtr and GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingPtrOutput() GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingPtrOutput
	ToGoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingPtrOutput
}

type googleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingPtrType GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingArgs

func GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingPtr(v *GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingArgs) GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingPtrInput {
	return (*googleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingPtrType)(v)
}

func (*googleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScaling)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingPtrType) ToGoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingPtrOutput() GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingPtrType) ToGoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingPtrOutput)
}

// Online serving scaling configuration. If min_node_count and max_node_count are set to the same value, the cluster will be configured with the fixed number of node (no auto-scaling).
type GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScaling)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingOutput) ToGoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingOutput() GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingOutput) ToGoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingOutput) ToGoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingPtrOutput() GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingOutput) ToGoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScaling) *GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScaling {
		return &v
	}).(GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingPtrOutput)
}

// Optional. The cpu utilization that the Autoscaler should be trying to achieve. This number is on a scale from 0 (no utilization) to 100 (total utilization), and is limited between 10 and 80. When a cluster's CPU utilization exceeds the target that you have set, Bigtable immediately adds nodes to the cluster. When CPU utilization is substantially lower than the target, Bigtable removes nodes. If not set or set to 0, default to 50.
func (o GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingOutput) CpuUtilizationTarget() pulumi.IntPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScaling) *int {
		return v.CpuUtilizationTarget
	}).(pulumi.IntPtrOutput)
}

// The maximum number of nodes to scale up to. Must be greater than min_node_count, and less than or equal to 10 times of 'min_node_count'.
func (o GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingOutput) MaxNodeCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScaling) *int { return v.MaxNodeCount }).(pulumi.IntPtrOutput)
}

// The minimum number of nodes to scale down to. Must be greater than or equal to 1.
func (o GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingOutput) MinNodeCount() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScaling) int { return v.MinNodeCount }).(pulumi.IntOutput)
}

type GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScaling)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingPtrOutput) ToGoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingPtrOutput() GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingPtrOutput) ToGoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingPtrOutput) Elem() GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScaling) GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScaling {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScaling
		return ret
	}).(GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingOutput)
}

// Optional. The cpu utilization that the Autoscaler should be trying to achieve. This number is on a scale from 0 (no utilization) to 100 (total utilization), and is limited between 10 and 80. When a cluster's CPU utilization exceeds the target that you have set, Bigtable immediately adds nodes to the cluster. When CPU utilization is substantially lower than the target, Bigtable removes nodes. If not set or set to 0, default to 50.
func (o GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingPtrOutput) CpuUtilizationTarget() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScaling) *int {
		if v == nil {
			return nil
		}
		return v.CpuUtilizationTarget
	}).(pulumi.IntPtrOutput)
}

// The maximum number of nodes to scale up to. Must be greater than min_node_count, and less than or equal to 10 times of 'min_node_count'.
func (o GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingPtrOutput) MaxNodeCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScaling) *int {
		if v == nil {
			return nil
		}
		return v.MaxNodeCount
	}).(pulumi.IntPtrOutput)
}

// The minimum number of nodes to scale down to. Must be greater than or equal to 1.
func (o GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingPtrOutput) MinNodeCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScaling) *int {
		if v == nil {
			return nil
		}
		return &v.MinNodeCount
	}).(pulumi.IntPtrOutput)
}

// Online serving scaling configuration. If min_node_count and max_node_count are set to the same value, the cluster will be configured with the fixed number of node (no auto-scaling).
type GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingResponse struct {
	// Optional. The cpu utilization that the Autoscaler should be trying to achieve. This number is on a scale from 0 (no utilization) to 100 (total utilization), and is limited between 10 and 80. When a cluster's CPU utilization exceeds the target that you have set, Bigtable immediately adds nodes to the cluster. When CPU utilization is substantially lower than the target, Bigtable removes nodes. If not set or set to 0, default to 50.
	CpuUtilizationTarget int `pulumi:"cpuUtilizationTarget"`
	// The maximum number of nodes to scale up to. Must be greater than min_node_count, and less than or equal to 10 times of 'min_node_count'.
	MaxNodeCount int `pulumi:"maxNodeCount"`
	// The minimum number of nodes to scale down to. Must be greater than or equal to 1.
	MinNodeCount int `pulumi:"minNodeCount"`
}

// Online serving scaling configuration. If min_node_count and max_node_count are set to the same value, the cluster will be configured with the fixed number of node (no auto-scaling).
type GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingResponseOutput) ToGoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingResponseOutput() GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingResponseOutput) ToGoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingResponseOutput {
	return o
}

// Optional. The cpu utilization that the Autoscaler should be trying to achieve. This number is on a scale from 0 (no utilization) to 100 (total utilization), and is limited between 10 and 80. When a cluster's CPU utilization exceeds the target that you have set, Bigtable immediately adds nodes to the cluster. When CPU utilization is substantially lower than the target, Bigtable removes nodes. If not set or set to 0, default to 50.
func (o GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingResponseOutput) CpuUtilizationTarget() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingResponse) int {
		return v.CpuUtilizationTarget
	}).(pulumi.IntOutput)
}

// The maximum number of nodes to scale up to. Must be greater than min_node_count, and less than or equal to 10 times of 'min_node_count'.
func (o GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingResponseOutput) MaxNodeCount() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingResponse) int {
		return v.MaxNodeCount
	}).(pulumi.IntOutput)
}

// The minimum number of nodes to scale down to. Must be greater than or equal to 1.
func (o GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingResponseOutput) MinNodeCount() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingResponse) int {
		return v.MinNodeCount
	}).(pulumi.IntOutput)
}

// Assigns input data to training, validation, and test sets based on the given filters, data pieces not matched by any filter are ignored. Currently only supported for Datasets containing DataItems. If any of the filters in this message are to match nothing, then they can be set as '-' (the minus sign). Supported only for unstructured Datasets.
type GoogleCloudAiplatformV1beta1FilterSplit struct {
	// A filter on DataItems of the Dataset. DataItems that match this filter are used to test the Model. A filter with same syntax as the one used in DatasetService.ListDataItems may be used. If a single DataItem is matched by more than one of the FilterSplit filters, then it is assigned to the first set that applies to it in the training, validation, test order.
	TestFilter string `pulumi:"testFilter"`
	// A filter on DataItems of the Dataset. DataItems that match this filter are used to train the Model. A filter with same syntax as the one used in DatasetService.ListDataItems may be used. If a single DataItem is matched by more than one of the FilterSplit filters, then it is assigned to the first set that applies to it in the training, validation, test order.
	TrainingFilter string `pulumi:"trainingFilter"`
	// A filter on DataItems of the Dataset. DataItems that match this filter are used to validate the Model. A filter with same syntax as the one used in DatasetService.ListDataItems may be used. If a single DataItem is matched by more than one of the FilterSplit filters, then it is assigned to the first set that applies to it in the training, validation, test order.
	ValidationFilter string `pulumi:"validationFilter"`
}

// GoogleCloudAiplatformV1beta1FilterSplitInput is an input type that accepts GoogleCloudAiplatformV1beta1FilterSplitArgs and GoogleCloudAiplatformV1beta1FilterSplitOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1FilterSplitInput` via:
//
//	GoogleCloudAiplatformV1beta1FilterSplitArgs{...}
type GoogleCloudAiplatformV1beta1FilterSplitInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1FilterSplitOutput() GoogleCloudAiplatformV1beta1FilterSplitOutput
	ToGoogleCloudAiplatformV1beta1FilterSplitOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1FilterSplitOutput
}

// Assigns input data to training, validation, and test sets based on the given filters, data pieces not matched by any filter are ignored. Currently only supported for Datasets containing DataItems. If any of the filters in this message are to match nothing, then they can be set as '-' (the minus sign). Supported only for unstructured Datasets.
type GoogleCloudAiplatformV1beta1FilterSplitArgs struct {
	// A filter on DataItems of the Dataset. DataItems that match this filter are used to test the Model. A filter with same syntax as the one used in DatasetService.ListDataItems may be used. If a single DataItem is matched by more than one of the FilterSplit filters, then it is assigned to the first set that applies to it in the training, validation, test order.
	TestFilter pulumi.StringInput `pulumi:"testFilter"`
	// A filter on DataItems of the Dataset. DataItems that match this filter are used to train the Model. A filter with same syntax as the one used in DatasetService.ListDataItems may be used. If a single DataItem is matched by more than one of the FilterSplit filters, then it is assigned to the first set that applies to it in the training, validation, test order.
	TrainingFilter pulumi.StringInput `pulumi:"trainingFilter"`
	// A filter on DataItems of the Dataset. DataItems that match this filter are used to validate the Model. A filter with same syntax as the one used in DatasetService.ListDataItems may be used. If a single DataItem is matched by more than one of the FilterSplit filters, then it is assigned to the first set that applies to it in the training, validation, test order.
	ValidationFilter pulumi.StringInput `pulumi:"validationFilter"`
}

func (GoogleCloudAiplatformV1beta1FilterSplitArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1FilterSplit)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1FilterSplitArgs) ToGoogleCloudAiplatformV1beta1FilterSplitOutput() GoogleCloudAiplatformV1beta1FilterSplitOutput {
	return i.ToGoogleCloudAiplatformV1beta1FilterSplitOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1FilterSplitArgs) ToGoogleCloudAiplatformV1beta1FilterSplitOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FilterSplitOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1FilterSplitOutput)
}

func (i GoogleCloudAiplatformV1beta1FilterSplitArgs) ToGoogleCloudAiplatformV1beta1FilterSplitPtrOutput() GoogleCloudAiplatformV1beta1FilterSplitPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1FilterSplitPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1FilterSplitArgs) ToGoogleCloudAiplatformV1beta1FilterSplitPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FilterSplitPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1FilterSplitOutput).ToGoogleCloudAiplatformV1beta1FilterSplitPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1FilterSplitPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1FilterSplitArgs, GoogleCloudAiplatformV1beta1FilterSplitPtr and GoogleCloudAiplatformV1beta1FilterSplitPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1FilterSplitPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1FilterSplitArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1FilterSplitPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1FilterSplitPtrOutput() GoogleCloudAiplatformV1beta1FilterSplitPtrOutput
	ToGoogleCloudAiplatformV1beta1FilterSplitPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1FilterSplitPtrOutput
}

type googleCloudAiplatformV1beta1FilterSplitPtrType GoogleCloudAiplatformV1beta1FilterSplitArgs

func GoogleCloudAiplatformV1beta1FilterSplitPtr(v *GoogleCloudAiplatformV1beta1FilterSplitArgs) GoogleCloudAiplatformV1beta1FilterSplitPtrInput {
	return (*googleCloudAiplatformV1beta1FilterSplitPtrType)(v)
}

func (*googleCloudAiplatformV1beta1FilterSplitPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1FilterSplit)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1FilterSplitPtrType) ToGoogleCloudAiplatformV1beta1FilterSplitPtrOutput() GoogleCloudAiplatformV1beta1FilterSplitPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1FilterSplitPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1FilterSplitPtrType) ToGoogleCloudAiplatformV1beta1FilterSplitPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FilterSplitPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1FilterSplitPtrOutput)
}

// Assigns input data to training, validation, and test sets based on the given filters, data pieces not matched by any filter are ignored. Currently only supported for Datasets containing DataItems. If any of the filters in this message are to match nothing, then they can be set as '-' (the minus sign). Supported only for unstructured Datasets.
type GoogleCloudAiplatformV1beta1FilterSplitOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1FilterSplitOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1FilterSplit)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1FilterSplitOutput) ToGoogleCloudAiplatformV1beta1FilterSplitOutput() GoogleCloudAiplatformV1beta1FilterSplitOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FilterSplitOutput) ToGoogleCloudAiplatformV1beta1FilterSplitOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FilterSplitOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FilterSplitOutput) ToGoogleCloudAiplatformV1beta1FilterSplitPtrOutput() GoogleCloudAiplatformV1beta1FilterSplitPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1FilterSplitPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1FilterSplitOutput) ToGoogleCloudAiplatformV1beta1FilterSplitPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FilterSplitPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1FilterSplit) *GoogleCloudAiplatformV1beta1FilterSplit {
		return &v
	}).(GoogleCloudAiplatformV1beta1FilterSplitPtrOutput)
}

// A filter on DataItems of the Dataset. DataItems that match this filter are used to test the Model. A filter with same syntax as the one used in DatasetService.ListDataItems may be used. If a single DataItem is matched by more than one of the FilterSplit filters, then it is assigned to the first set that applies to it in the training, validation, test order.
func (o GoogleCloudAiplatformV1beta1FilterSplitOutput) TestFilter() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FilterSplit) string { return v.TestFilter }).(pulumi.StringOutput)
}

// A filter on DataItems of the Dataset. DataItems that match this filter are used to train the Model. A filter with same syntax as the one used in DatasetService.ListDataItems may be used. If a single DataItem is matched by more than one of the FilterSplit filters, then it is assigned to the first set that applies to it in the training, validation, test order.
func (o GoogleCloudAiplatformV1beta1FilterSplitOutput) TrainingFilter() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FilterSplit) string { return v.TrainingFilter }).(pulumi.StringOutput)
}

// A filter on DataItems of the Dataset. DataItems that match this filter are used to validate the Model. A filter with same syntax as the one used in DatasetService.ListDataItems may be used. If a single DataItem is matched by more than one of the FilterSplit filters, then it is assigned to the first set that applies to it in the training, validation, test order.
func (o GoogleCloudAiplatformV1beta1FilterSplitOutput) ValidationFilter() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FilterSplit) string { return v.ValidationFilter }).(pulumi.StringOutput)
}

type GoogleCloudAiplatformV1beta1FilterSplitPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1FilterSplitPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1FilterSplit)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1FilterSplitPtrOutput) ToGoogleCloudAiplatformV1beta1FilterSplitPtrOutput() GoogleCloudAiplatformV1beta1FilterSplitPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FilterSplitPtrOutput) ToGoogleCloudAiplatformV1beta1FilterSplitPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FilterSplitPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FilterSplitPtrOutput) Elem() GoogleCloudAiplatformV1beta1FilterSplitOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1FilterSplit) GoogleCloudAiplatformV1beta1FilterSplit {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1FilterSplit
		return ret
	}).(GoogleCloudAiplatformV1beta1FilterSplitOutput)
}

// A filter on DataItems of the Dataset. DataItems that match this filter are used to test the Model. A filter with same syntax as the one used in DatasetService.ListDataItems may be used. If a single DataItem is matched by more than one of the FilterSplit filters, then it is assigned to the first set that applies to it in the training, validation, test order.
func (o GoogleCloudAiplatformV1beta1FilterSplitPtrOutput) TestFilter() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1FilterSplit) *string {
		if v == nil {
			return nil
		}
		return &v.TestFilter
	}).(pulumi.StringPtrOutput)
}

// A filter on DataItems of the Dataset. DataItems that match this filter are used to train the Model. A filter with same syntax as the one used in DatasetService.ListDataItems may be used. If a single DataItem is matched by more than one of the FilterSplit filters, then it is assigned to the first set that applies to it in the training, validation, test order.
func (o GoogleCloudAiplatformV1beta1FilterSplitPtrOutput) TrainingFilter() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1FilterSplit) *string {
		if v == nil {
			return nil
		}
		return &v.TrainingFilter
	}).(pulumi.StringPtrOutput)
}

// A filter on DataItems of the Dataset. DataItems that match this filter are used to validate the Model. A filter with same syntax as the one used in DatasetService.ListDataItems may be used. If a single DataItem is matched by more than one of the FilterSplit filters, then it is assigned to the first set that applies to it in the training, validation, test order.
func (o GoogleCloudAiplatformV1beta1FilterSplitPtrOutput) ValidationFilter() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1FilterSplit) *string {
		if v == nil {
			return nil
		}
		return &v.ValidationFilter
	}).(pulumi.StringPtrOutput)
}

// Assigns input data to training, validation, and test sets based on the given filters, data pieces not matched by any filter are ignored. Currently only supported for Datasets containing DataItems. If any of the filters in this message are to match nothing, then they can be set as '-' (the minus sign). Supported only for unstructured Datasets.
type GoogleCloudAiplatformV1beta1FilterSplitResponse struct {
	// A filter on DataItems of the Dataset. DataItems that match this filter are used to test the Model. A filter with same syntax as the one used in DatasetService.ListDataItems may be used. If a single DataItem is matched by more than one of the FilterSplit filters, then it is assigned to the first set that applies to it in the training, validation, test order.
	TestFilter string `pulumi:"testFilter"`
	// A filter on DataItems of the Dataset. DataItems that match this filter are used to train the Model. A filter with same syntax as the one used in DatasetService.ListDataItems may be used. If a single DataItem is matched by more than one of the FilterSplit filters, then it is assigned to the first set that applies to it in the training, validation, test order.
	TrainingFilter string `pulumi:"trainingFilter"`
	// A filter on DataItems of the Dataset. DataItems that match this filter are used to validate the Model. A filter with same syntax as the one used in DatasetService.ListDataItems may be used. If a single DataItem is matched by more than one of the FilterSplit filters, then it is assigned to the first set that applies to it in the training, validation, test order.
	ValidationFilter string `pulumi:"validationFilter"`
}

// Assigns input data to training, validation, and test sets based on the given filters, data pieces not matched by any filter are ignored. Currently only supported for Datasets containing DataItems. If any of the filters in this message are to match nothing, then they can be set as '-' (the minus sign). Supported only for unstructured Datasets.
type GoogleCloudAiplatformV1beta1FilterSplitResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1FilterSplitResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1FilterSplitResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1FilterSplitResponseOutput) ToGoogleCloudAiplatformV1beta1FilterSplitResponseOutput() GoogleCloudAiplatformV1beta1FilterSplitResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FilterSplitResponseOutput) ToGoogleCloudAiplatformV1beta1FilterSplitResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FilterSplitResponseOutput {
	return o
}

// A filter on DataItems of the Dataset. DataItems that match this filter are used to test the Model. A filter with same syntax as the one used in DatasetService.ListDataItems may be used. If a single DataItem is matched by more than one of the FilterSplit filters, then it is assigned to the first set that applies to it in the training, validation, test order.
func (o GoogleCloudAiplatformV1beta1FilterSplitResponseOutput) TestFilter() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FilterSplitResponse) string { return v.TestFilter }).(pulumi.StringOutput)
}

// A filter on DataItems of the Dataset. DataItems that match this filter are used to train the Model. A filter with same syntax as the one used in DatasetService.ListDataItems may be used. If a single DataItem is matched by more than one of the FilterSplit filters, then it is assigned to the first set that applies to it in the training, validation, test order.
func (o GoogleCloudAiplatformV1beta1FilterSplitResponseOutput) TrainingFilter() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FilterSplitResponse) string { return v.TrainingFilter }).(pulumi.StringOutput)
}

// A filter on DataItems of the Dataset. DataItems that match this filter are used to validate the Model. A filter with same syntax as the one used in DatasetService.ListDataItems may be used. If a single DataItem is matched by more than one of the FilterSplit filters, then it is assigned to the first set that applies to it in the training, validation, test order.
func (o GoogleCloudAiplatformV1beta1FilterSplitResponseOutput) ValidationFilter() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FilterSplitResponse) string { return v.ValidationFilter }).(pulumi.StringOutput)
}

// Assigns the input data to training, validation, and test sets as per the given fractions. Any of `training_fraction`, `validation_fraction` and `test_fraction` may optionally be provided, they must sum to up to 1. If the provided ones sum to less than 1, the remainder is assigned to sets as decided by Vertex AI. If none of the fractions are set, by default roughly 80% of data is used for training, 10% for validation, and 10% for test.
type GoogleCloudAiplatformV1beta1FractionSplit struct {
	// The fraction of the input data that is to be used to evaluate the Model.
	TestFraction *float64 `pulumi:"testFraction"`
	// The fraction of the input data that is to be used to train the Model.
	TrainingFraction *float64 `pulumi:"trainingFraction"`
	// The fraction of the input data that is to be used to validate the Model.
	ValidationFraction *float64 `pulumi:"validationFraction"`
}

// GoogleCloudAiplatformV1beta1FractionSplitInput is an input type that accepts GoogleCloudAiplatformV1beta1FractionSplitArgs and GoogleCloudAiplatformV1beta1FractionSplitOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1FractionSplitInput` via:
//
//	GoogleCloudAiplatformV1beta1FractionSplitArgs{...}
type GoogleCloudAiplatformV1beta1FractionSplitInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1FractionSplitOutput() GoogleCloudAiplatformV1beta1FractionSplitOutput
	ToGoogleCloudAiplatformV1beta1FractionSplitOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1FractionSplitOutput
}

// Assigns the input data to training, validation, and test sets as per the given fractions. Any of `training_fraction`, `validation_fraction` and `test_fraction` may optionally be provided, they must sum to up to 1. If the provided ones sum to less than 1, the remainder is assigned to sets as decided by Vertex AI. If none of the fractions are set, by default roughly 80% of data is used for training, 10% for validation, and 10% for test.
type GoogleCloudAiplatformV1beta1FractionSplitArgs struct {
	// The fraction of the input data that is to be used to evaluate the Model.
	TestFraction pulumi.Float64PtrInput `pulumi:"testFraction"`
	// The fraction of the input data that is to be used to train the Model.
	TrainingFraction pulumi.Float64PtrInput `pulumi:"trainingFraction"`
	// The fraction of the input data that is to be used to validate the Model.
	ValidationFraction pulumi.Float64PtrInput `pulumi:"validationFraction"`
}

func (GoogleCloudAiplatformV1beta1FractionSplitArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1FractionSplit)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1FractionSplitArgs) ToGoogleCloudAiplatformV1beta1FractionSplitOutput() GoogleCloudAiplatformV1beta1FractionSplitOutput {
	return i.ToGoogleCloudAiplatformV1beta1FractionSplitOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1FractionSplitArgs) ToGoogleCloudAiplatformV1beta1FractionSplitOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FractionSplitOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1FractionSplitOutput)
}

func (i GoogleCloudAiplatformV1beta1FractionSplitArgs) ToGoogleCloudAiplatformV1beta1FractionSplitPtrOutput() GoogleCloudAiplatformV1beta1FractionSplitPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1FractionSplitPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1FractionSplitArgs) ToGoogleCloudAiplatformV1beta1FractionSplitPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FractionSplitPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1FractionSplitOutput).ToGoogleCloudAiplatformV1beta1FractionSplitPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1FractionSplitPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1FractionSplitArgs, GoogleCloudAiplatformV1beta1FractionSplitPtr and GoogleCloudAiplatformV1beta1FractionSplitPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1FractionSplitPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1FractionSplitArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1FractionSplitPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1FractionSplitPtrOutput() GoogleCloudAiplatformV1beta1FractionSplitPtrOutput
	ToGoogleCloudAiplatformV1beta1FractionSplitPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1FractionSplitPtrOutput
}

type googleCloudAiplatformV1beta1FractionSplitPtrType GoogleCloudAiplatformV1beta1FractionSplitArgs

func GoogleCloudAiplatformV1beta1FractionSplitPtr(v *GoogleCloudAiplatformV1beta1FractionSplitArgs) GoogleCloudAiplatformV1beta1FractionSplitPtrInput {
	return (*googleCloudAiplatformV1beta1FractionSplitPtrType)(v)
}

func (*googleCloudAiplatformV1beta1FractionSplitPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1FractionSplit)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1FractionSplitPtrType) ToGoogleCloudAiplatformV1beta1FractionSplitPtrOutput() GoogleCloudAiplatformV1beta1FractionSplitPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1FractionSplitPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1FractionSplitPtrType) ToGoogleCloudAiplatformV1beta1FractionSplitPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FractionSplitPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1FractionSplitPtrOutput)
}

// Assigns the input data to training, validation, and test sets as per the given fractions. Any of `training_fraction`, `validation_fraction` and `test_fraction` may optionally be provided, they must sum to up to 1. If the provided ones sum to less than 1, the remainder is assigned to sets as decided by Vertex AI. If none of the fractions are set, by default roughly 80% of data is used for training, 10% for validation, and 10% for test.
type GoogleCloudAiplatformV1beta1FractionSplitOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1FractionSplitOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1FractionSplit)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1FractionSplitOutput) ToGoogleCloudAiplatformV1beta1FractionSplitOutput() GoogleCloudAiplatformV1beta1FractionSplitOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FractionSplitOutput) ToGoogleCloudAiplatformV1beta1FractionSplitOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FractionSplitOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FractionSplitOutput) ToGoogleCloudAiplatformV1beta1FractionSplitPtrOutput() GoogleCloudAiplatformV1beta1FractionSplitPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1FractionSplitPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1FractionSplitOutput) ToGoogleCloudAiplatformV1beta1FractionSplitPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FractionSplitPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1FractionSplit) *GoogleCloudAiplatformV1beta1FractionSplit {
		return &v
	}).(GoogleCloudAiplatformV1beta1FractionSplitPtrOutput)
}

// The fraction of the input data that is to be used to evaluate the Model.
func (o GoogleCloudAiplatformV1beta1FractionSplitOutput) TestFraction() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FractionSplit) *float64 { return v.TestFraction }).(pulumi.Float64PtrOutput)
}

// The fraction of the input data that is to be used to train the Model.
func (o GoogleCloudAiplatformV1beta1FractionSplitOutput) TrainingFraction() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FractionSplit) *float64 { return v.TrainingFraction }).(pulumi.Float64PtrOutput)
}

// The fraction of the input data that is to be used to validate the Model.
func (o GoogleCloudAiplatformV1beta1FractionSplitOutput) ValidationFraction() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FractionSplit) *float64 { return v.ValidationFraction }).(pulumi.Float64PtrOutput)
}

type GoogleCloudAiplatformV1beta1FractionSplitPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1FractionSplitPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1FractionSplit)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1FractionSplitPtrOutput) ToGoogleCloudAiplatformV1beta1FractionSplitPtrOutput() GoogleCloudAiplatformV1beta1FractionSplitPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FractionSplitPtrOutput) ToGoogleCloudAiplatformV1beta1FractionSplitPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FractionSplitPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FractionSplitPtrOutput) Elem() GoogleCloudAiplatformV1beta1FractionSplitOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1FractionSplit) GoogleCloudAiplatformV1beta1FractionSplit {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1FractionSplit
		return ret
	}).(GoogleCloudAiplatformV1beta1FractionSplitOutput)
}

// The fraction of the input data that is to be used to evaluate the Model.
func (o GoogleCloudAiplatformV1beta1FractionSplitPtrOutput) TestFraction() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1FractionSplit) *float64 {
		if v == nil {
			return nil
		}
		return v.TestFraction
	}).(pulumi.Float64PtrOutput)
}

// The fraction of the input data that is to be used to train the Model.
func (o GoogleCloudAiplatformV1beta1FractionSplitPtrOutput) TrainingFraction() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1FractionSplit) *float64 {
		if v == nil {
			return nil
		}
		return v.TrainingFraction
	}).(pulumi.Float64PtrOutput)
}

// The fraction of the input data that is to be used to validate the Model.
func (o GoogleCloudAiplatformV1beta1FractionSplitPtrOutput) ValidationFraction() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1FractionSplit) *float64 {
		if v == nil {
			return nil
		}
		return v.ValidationFraction
	}).(pulumi.Float64PtrOutput)
}

// Assigns the input data to training, validation, and test sets as per the given fractions. Any of `training_fraction`, `validation_fraction` and `test_fraction` may optionally be provided, they must sum to up to 1. If the provided ones sum to less than 1, the remainder is assigned to sets as decided by Vertex AI. If none of the fractions are set, by default roughly 80% of data is used for training, 10% for validation, and 10% for test.
type GoogleCloudAiplatformV1beta1FractionSplitResponse struct {
	// The fraction of the input data that is to be used to evaluate the Model.
	TestFraction float64 `pulumi:"testFraction"`
	// The fraction of the input data that is to be used to train the Model.
	TrainingFraction float64 `pulumi:"trainingFraction"`
	// The fraction of the input data that is to be used to validate the Model.
	ValidationFraction float64 `pulumi:"validationFraction"`
}

// Assigns the input data to training, validation, and test sets as per the given fractions. Any of `training_fraction`, `validation_fraction` and `test_fraction` may optionally be provided, they must sum to up to 1. If the provided ones sum to less than 1, the remainder is assigned to sets as decided by Vertex AI. If none of the fractions are set, by default roughly 80% of data is used for training, 10% for validation, and 10% for test.
type GoogleCloudAiplatformV1beta1FractionSplitResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1FractionSplitResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1FractionSplitResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1FractionSplitResponseOutput) ToGoogleCloudAiplatformV1beta1FractionSplitResponseOutput() GoogleCloudAiplatformV1beta1FractionSplitResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1FractionSplitResponseOutput) ToGoogleCloudAiplatformV1beta1FractionSplitResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1FractionSplitResponseOutput {
	return o
}

// The fraction of the input data that is to be used to evaluate the Model.
func (o GoogleCloudAiplatformV1beta1FractionSplitResponseOutput) TestFraction() pulumi.Float64Output {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FractionSplitResponse) float64 { return v.TestFraction }).(pulumi.Float64Output)
}

// The fraction of the input data that is to be used to train the Model.
func (o GoogleCloudAiplatformV1beta1FractionSplitResponseOutput) TrainingFraction() pulumi.Float64Output {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FractionSplitResponse) float64 { return v.TrainingFraction }).(pulumi.Float64Output)
}

// The fraction of the input data that is to be used to validate the Model.
func (o GoogleCloudAiplatformV1beta1FractionSplitResponseOutput) ValidationFraction() pulumi.Float64Output {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1FractionSplitResponse) float64 { return v.ValidationFraction }).(pulumi.Float64Output)
}

// The Google Cloud Storage location where the output is to be written to.
type GoogleCloudAiplatformV1beta1GcsDestination struct {
	// Google Cloud Storage URI to output directory. If the uri doesn't end with '/', a '/' will be automatically appended. The directory is created if it doesn't exist.
	OutputUriPrefix string `pulumi:"outputUriPrefix"`
}

// GoogleCloudAiplatformV1beta1GcsDestinationInput is an input type that accepts GoogleCloudAiplatformV1beta1GcsDestinationArgs and GoogleCloudAiplatformV1beta1GcsDestinationOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1GcsDestinationInput` via:
//
//	GoogleCloudAiplatformV1beta1GcsDestinationArgs{...}
type GoogleCloudAiplatformV1beta1GcsDestinationInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1GcsDestinationOutput() GoogleCloudAiplatformV1beta1GcsDestinationOutput
	ToGoogleCloudAiplatformV1beta1GcsDestinationOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1GcsDestinationOutput
}

// The Google Cloud Storage location where the output is to be written to.
type GoogleCloudAiplatformV1beta1GcsDestinationArgs struct {
	// Google Cloud Storage URI to output directory. If the uri doesn't end with '/', a '/' will be automatically appended. The directory is created if it doesn't exist.
	OutputUriPrefix pulumi.StringInput `pulumi:"outputUriPrefix"`
}

func (GoogleCloudAiplatformV1beta1GcsDestinationArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1GcsDestination)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1GcsDestinationArgs) ToGoogleCloudAiplatformV1beta1GcsDestinationOutput() GoogleCloudAiplatformV1beta1GcsDestinationOutput {
	return i.ToGoogleCloudAiplatformV1beta1GcsDestinationOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1GcsDestinationArgs) ToGoogleCloudAiplatformV1beta1GcsDestinationOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1GcsDestinationOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1GcsDestinationOutput)
}

func (i GoogleCloudAiplatformV1beta1GcsDestinationArgs) ToGoogleCloudAiplatformV1beta1GcsDestinationPtrOutput() GoogleCloudAiplatformV1beta1GcsDestinationPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1GcsDestinationPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1GcsDestinationArgs) ToGoogleCloudAiplatformV1beta1GcsDestinationPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1GcsDestinationPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1GcsDestinationOutput).ToGoogleCloudAiplatformV1beta1GcsDestinationPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1GcsDestinationPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1GcsDestinationArgs, GoogleCloudAiplatformV1beta1GcsDestinationPtr and GoogleCloudAiplatformV1beta1GcsDestinationPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1GcsDestinationPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1GcsDestinationArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1GcsDestinationPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1GcsDestinationPtrOutput() GoogleCloudAiplatformV1beta1GcsDestinationPtrOutput
	ToGoogleCloudAiplatformV1beta1GcsDestinationPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1GcsDestinationPtrOutput
}

type googleCloudAiplatformV1beta1GcsDestinationPtrType GoogleCloudAiplatformV1beta1GcsDestinationArgs

func GoogleCloudAiplatformV1beta1GcsDestinationPtr(v *GoogleCloudAiplatformV1beta1GcsDestinationArgs) GoogleCloudAiplatformV1beta1GcsDestinationPtrInput {
	return (*googleCloudAiplatformV1beta1GcsDestinationPtrType)(v)
}

func (*googleCloudAiplatformV1beta1GcsDestinationPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1GcsDestination)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1GcsDestinationPtrType) ToGoogleCloudAiplatformV1beta1GcsDestinationPtrOutput() GoogleCloudAiplatformV1beta1GcsDestinationPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1GcsDestinationPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1GcsDestinationPtrType) ToGoogleCloudAiplatformV1beta1GcsDestinationPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1GcsDestinationPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1GcsDestinationPtrOutput)
}

// The Google Cloud Storage location where the output is to be written to.
type GoogleCloudAiplatformV1beta1GcsDestinationOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1GcsDestinationOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1GcsDestination)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1GcsDestinationOutput) ToGoogleCloudAiplatformV1beta1GcsDestinationOutput() GoogleCloudAiplatformV1beta1GcsDestinationOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1GcsDestinationOutput) ToGoogleCloudAiplatformV1beta1GcsDestinationOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1GcsDestinationOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1GcsDestinationOutput) ToGoogleCloudAiplatformV1beta1GcsDestinationPtrOutput() GoogleCloudAiplatformV1beta1GcsDestinationPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1GcsDestinationPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1GcsDestinationOutput) ToGoogleCloudAiplatformV1beta1GcsDestinationPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1GcsDestinationPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1GcsDestination) *GoogleCloudAiplatformV1beta1GcsDestination {
		return &v
	}).(GoogleCloudAiplatformV1beta1GcsDestinationPtrOutput)
}

// Google Cloud Storage URI to output directory. If the uri doesn't end with '/', a '/' will be automatically appended. The directory is created if it doesn't exist.
func (o GoogleCloudAiplatformV1beta1GcsDestinationOutput) OutputUriPrefix() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1GcsDestination) string { return v.OutputUriPrefix }).(pulumi.StringOutput)
}

type GoogleCloudAiplatformV1beta1GcsDestinationPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1GcsDestinationPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1GcsDestination)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1GcsDestinationPtrOutput) ToGoogleCloudAiplatformV1beta1GcsDestinationPtrOutput() GoogleCloudAiplatformV1beta1GcsDestinationPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1GcsDestinationPtrOutput) ToGoogleCloudAiplatformV1beta1GcsDestinationPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1GcsDestinationPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1GcsDestinationPtrOutput) Elem() GoogleCloudAiplatformV1beta1GcsDestinationOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1GcsDestination) GoogleCloudAiplatformV1beta1GcsDestination {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1GcsDestination
		return ret
	}).(GoogleCloudAiplatformV1beta1GcsDestinationOutput)
}

// Google Cloud Storage URI to output directory. If the uri doesn't end with '/', a '/' will be automatically appended. The directory is created if it doesn't exist.
func (o GoogleCloudAiplatformV1beta1GcsDestinationPtrOutput) OutputUriPrefix() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1GcsDestination) *string {
		if v == nil {
			return nil
		}
		return &v.OutputUriPrefix
	}).(pulumi.StringPtrOutput)
}

// The Google Cloud Storage location where the output is to be written to.
type GoogleCloudAiplatformV1beta1GcsDestinationResponse struct {
	// Google Cloud Storage URI to output directory. If the uri doesn't end with '/', a '/' will be automatically appended. The directory is created if it doesn't exist.
	OutputUriPrefix string `pulumi:"outputUriPrefix"`
}

// The Google Cloud Storage location where the output is to be written to.
type GoogleCloudAiplatformV1beta1GcsDestinationResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1GcsDestinationResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1GcsDestinationResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1GcsDestinationResponseOutput) ToGoogleCloudAiplatformV1beta1GcsDestinationResponseOutput() GoogleCloudAiplatformV1beta1GcsDestinationResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1GcsDestinationResponseOutput) ToGoogleCloudAiplatformV1beta1GcsDestinationResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1GcsDestinationResponseOutput {
	return o
}

// Google Cloud Storage URI to output directory. If the uri doesn't end with '/', a '/' will be automatically appended. The directory is created if it doesn't exist.
func (o GoogleCloudAiplatformV1beta1GcsDestinationResponseOutput) OutputUriPrefix() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1GcsDestinationResponse) string { return v.OutputUriPrefix }).(pulumi.StringOutput)
}

// The Google Cloud Storage location for the input content.
type GoogleCloudAiplatformV1beta1GcsSource struct {
	// Google Cloud Storage URI(-s) to the input file(s). May contain wildcards. For more information on wildcards, see https://cloud.google.com/storage/docs/gsutil/addlhelp/WildcardNames.
	Uris []string `pulumi:"uris"`
}

// GoogleCloudAiplatformV1beta1GcsSourceInput is an input type that accepts GoogleCloudAiplatformV1beta1GcsSourceArgs and GoogleCloudAiplatformV1beta1GcsSourceOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1GcsSourceInput` via:
//
//	GoogleCloudAiplatformV1beta1GcsSourceArgs{...}
type GoogleCloudAiplatformV1beta1GcsSourceInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1GcsSourceOutput() GoogleCloudAiplatformV1beta1GcsSourceOutput
	ToGoogleCloudAiplatformV1beta1GcsSourceOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1GcsSourceOutput
}

// The Google Cloud Storage location for the input content.
type GoogleCloudAiplatformV1beta1GcsSourceArgs struct {
	// Google Cloud Storage URI(-s) to the input file(s). May contain wildcards. For more information on wildcards, see https://cloud.google.com/storage/docs/gsutil/addlhelp/WildcardNames.
	Uris pulumi.StringArrayInput `pulumi:"uris"`
}

func (GoogleCloudAiplatformV1beta1GcsSourceArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1GcsSource)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1GcsSourceArgs) ToGoogleCloudAiplatformV1beta1GcsSourceOutput() GoogleCloudAiplatformV1beta1GcsSourceOutput {
	return i.ToGoogleCloudAiplatformV1beta1GcsSourceOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1GcsSourceArgs) ToGoogleCloudAiplatformV1beta1GcsSourceOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1GcsSourceOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1GcsSourceOutput)
}

func (i GoogleCloudAiplatformV1beta1GcsSourceArgs) ToGoogleCloudAiplatformV1beta1GcsSourcePtrOutput() GoogleCloudAiplatformV1beta1GcsSourcePtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1GcsSourcePtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1GcsSourceArgs) ToGoogleCloudAiplatformV1beta1GcsSourcePtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1GcsSourcePtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1GcsSourceOutput).ToGoogleCloudAiplatformV1beta1GcsSourcePtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1GcsSourcePtrInput is an input type that accepts GoogleCloudAiplatformV1beta1GcsSourceArgs, GoogleCloudAiplatformV1beta1GcsSourcePtr and GoogleCloudAiplatformV1beta1GcsSourcePtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1GcsSourcePtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1GcsSourceArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1GcsSourcePtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1GcsSourcePtrOutput() GoogleCloudAiplatformV1beta1GcsSourcePtrOutput
	ToGoogleCloudAiplatformV1beta1GcsSourcePtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1GcsSourcePtrOutput
}

type googleCloudAiplatformV1beta1GcsSourcePtrType GoogleCloudAiplatformV1beta1GcsSourceArgs

func GoogleCloudAiplatformV1beta1GcsSourcePtr(v *GoogleCloudAiplatformV1beta1GcsSourceArgs) GoogleCloudAiplatformV1beta1GcsSourcePtrInput {
	return (*googleCloudAiplatformV1beta1GcsSourcePtrType)(v)
}

func (*googleCloudAiplatformV1beta1GcsSourcePtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1GcsSource)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1GcsSourcePtrType) ToGoogleCloudAiplatformV1beta1GcsSourcePtrOutput() GoogleCloudAiplatformV1beta1GcsSourcePtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1GcsSourcePtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1GcsSourcePtrType) ToGoogleCloudAiplatformV1beta1GcsSourcePtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1GcsSourcePtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1GcsSourcePtrOutput)
}

// The Google Cloud Storage location for the input content.
type GoogleCloudAiplatformV1beta1GcsSourceOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1GcsSourceOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1GcsSource)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1GcsSourceOutput) ToGoogleCloudAiplatformV1beta1GcsSourceOutput() GoogleCloudAiplatformV1beta1GcsSourceOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1GcsSourceOutput) ToGoogleCloudAiplatformV1beta1GcsSourceOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1GcsSourceOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1GcsSourceOutput) ToGoogleCloudAiplatformV1beta1GcsSourcePtrOutput() GoogleCloudAiplatformV1beta1GcsSourcePtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1GcsSourcePtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1GcsSourceOutput) ToGoogleCloudAiplatformV1beta1GcsSourcePtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1GcsSourcePtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1GcsSource) *GoogleCloudAiplatformV1beta1GcsSource {
		return &v
	}).(GoogleCloudAiplatformV1beta1GcsSourcePtrOutput)
}

// Google Cloud Storage URI(-s) to the input file(s). May contain wildcards. For more information on wildcards, see https://cloud.google.com/storage/docs/gsutil/addlhelp/WildcardNames.
func (o GoogleCloudAiplatformV1beta1GcsSourceOutput) Uris() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1GcsSource) []string { return v.Uris }).(pulumi.StringArrayOutput)
}

type GoogleCloudAiplatformV1beta1GcsSourcePtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1GcsSourcePtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1GcsSource)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1GcsSourcePtrOutput) ToGoogleCloudAiplatformV1beta1GcsSourcePtrOutput() GoogleCloudAiplatformV1beta1GcsSourcePtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1GcsSourcePtrOutput) ToGoogleCloudAiplatformV1beta1GcsSourcePtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1GcsSourcePtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1GcsSourcePtrOutput) Elem() GoogleCloudAiplatformV1beta1GcsSourceOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1GcsSource) GoogleCloudAiplatformV1beta1GcsSource {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1GcsSource
		return ret
	}).(GoogleCloudAiplatformV1beta1GcsSourceOutput)
}

// Google Cloud Storage URI(-s) to the input file(s). May contain wildcards. For more information on wildcards, see https://cloud.google.com/storage/docs/gsutil/addlhelp/WildcardNames.
func (o GoogleCloudAiplatformV1beta1GcsSourcePtrOutput) Uris() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1GcsSource) []string {
		if v == nil {
			return nil
		}
		return v.Uris
	}).(pulumi.StringArrayOutput)
}

// The Google Cloud Storage location for the input content.
type GoogleCloudAiplatformV1beta1GcsSourceResponse struct {
	// Google Cloud Storage URI(-s) to the input file(s). May contain wildcards. For more information on wildcards, see https://cloud.google.com/storage/docs/gsutil/addlhelp/WildcardNames.
	Uris []string `pulumi:"uris"`
}

// The Google Cloud Storage location for the input content.
type GoogleCloudAiplatformV1beta1GcsSourceResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1GcsSourceResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1GcsSourceResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1GcsSourceResponseOutput) ToGoogleCloudAiplatformV1beta1GcsSourceResponseOutput() GoogleCloudAiplatformV1beta1GcsSourceResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1GcsSourceResponseOutput) ToGoogleCloudAiplatformV1beta1GcsSourceResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1GcsSourceResponseOutput {
	return o
}

// Google Cloud Storage URI(-s) to the input file(s). May contain wildcards. For more information on wildcards, see https://cloud.google.com/storage/docs/gsutil/addlhelp/WildcardNames.
func (o GoogleCloudAiplatformV1beta1GcsSourceResponseOutput) Uris() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1GcsSourceResponse) []string { return v.Uris }).(pulumi.StringArrayOutput)
}

// IndexPrivateEndpoints proto is used to provide paths for users to send requests via private endpoints (e.g. private service access, private service connect). To send request via private service access, use match_grpc_address. To send request via private service connect, use service_attachment.
type GoogleCloudAiplatformV1beta1IndexPrivateEndpointsResponse struct {
	// The ip address used to send match gRPC requests.
	MatchGrpcAddress string `pulumi:"matchGrpcAddress"`
	// The name of the service attachment resource. Populated if private service connect is enabled.
	ServiceAttachment string `pulumi:"serviceAttachment"`
}

// IndexPrivateEndpoints proto is used to provide paths for users to send requests via private endpoints (e.g. private service access, private service connect). To send request via private service access, use match_grpc_address. To send request via private service connect, use service_attachment.
type GoogleCloudAiplatformV1beta1IndexPrivateEndpointsResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1IndexPrivateEndpointsResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1IndexPrivateEndpointsResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1IndexPrivateEndpointsResponseOutput) ToGoogleCloudAiplatformV1beta1IndexPrivateEndpointsResponseOutput() GoogleCloudAiplatformV1beta1IndexPrivateEndpointsResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1IndexPrivateEndpointsResponseOutput) ToGoogleCloudAiplatformV1beta1IndexPrivateEndpointsResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1IndexPrivateEndpointsResponseOutput {
	return o
}

// The ip address used to send match gRPC requests.
func (o GoogleCloudAiplatformV1beta1IndexPrivateEndpointsResponseOutput) MatchGrpcAddress() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1IndexPrivateEndpointsResponse) string { return v.MatchGrpcAddress }).(pulumi.StringOutput)
}

// The name of the service attachment resource. Populated if private service connect is enabled.
func (o GoogleCloudAiplatformV1beta1IndexPrivateEndpointsResponseOutput) ServiceAttachment() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1IndexPrivateEndpointsResponse) string { return v.ServiceAttachment }).(pulumi.StringOutput)
}

// Stats of the Index.
type GoogleCloudAiplatformV1beta1IndexStatsResponse struct {
	// The number of shards in the Index.
	ShardsCount int `pulumi:"shardsCount"`
	// The number of vectors in the Index.
	VectorsCount string `pulumi:"vectorsCount"`
}

// Stats of the Index.
type GoogleCloudAiplatformV1beta1IndexStatsResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1IndexStatsResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1IndexStatsResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1IndexStatsResponseOutput) ToGoogleCloudAiplatformV1beta1IndexStatsResponseOutput() GoogleCloudAiplatformV1beta1IndexStatsResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1IndexStatsResponseOutput) ToGoogleCloudAiplatformV1beta1IndexStatsResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1IndexStatsResponseOutput {
	return o
}

// The number of shards in the Index.
func (o GoogleCloudAiplatformV1beta1IndexStatsResponseOutput) ShardsCount() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1IndexStatsResponse) int { return v.ShardsCount }).(pulumi.IntOutput)
}

// The number of vectors in the Index.
func (o GoogleCloudAiplatformV1beta1IndexStatsResponseOutput) VectorsCount() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1IndexStatsResponse) string { return v.VectorsCount }).(pulumi.StringOutput)
}

// Specifies Vertex AI owned input data to be used for training, and possibly evaluating, the Model.
type GoogleCloudAiplatformV1beta1InputDataConfig struct {
	// Applicable only to custom training with Datasets that have DataItems and Annotations. Cloud Storage URI that points to a YAML file describing the annotation schema. The schema is defined as an OpenAPI 3.0.2 [Schema Object](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject). The schema files that can be used here are found in gs://google-cloud-aiplatform/schema/dataset/annotation/ , note that the chosen schema must be consistent with metadata of the Dataset specified by dataset_id. Only Annotations that both match this schema and belong to DataItems not ignored by the split method are used in respectively training, validation or test role, depending on the role of the DataItem they are on. When used in conjunction with annotations_filter, the Annotations used for training are filtered by both annotations_filter and annotation_schema_uri.
	AnnotationSchemaUri *string `pulumi:"annotationSchemaUri"`
	// Applicable only to Datasets that have DataItems and Annotations. A filter on Annotations of the Dataset. Only Annotations that both match this filter and belong to DataItems not ignored by the split method are used in respectively training, validation or test role, depending on the role of the DataItem they are on (for the auto-assigned that role is decided by Vertex AI). A filter with same syntax as the one used in ListAnnotations may be used, but note here it filters across all Annotations of the Dataset, and not just within a single DataItem.
	AnnotationsFilter *string `pulumi:"annotationsFilter"`
	// Only applicable to custom training with tabular Dataset with BigQuery source. The BigQuery project location where the training data is to be written to. In the given project a new dataset is created with name `dataset___` where timestamp is in YYYY_MM_DDThh_mm_ss_sssZ format. All training input data is written into that dataset. In the dataset three tables are created, `training`, `validation` and `test`. * AIP_DATA_FORMAT = "bigquery". * AIP_TRAINING_DATA_URI = "bigquery_destination.dataset___.training" * AIP_VALIDATION_DATA_URI = "bigquery_destination.dataset___.validation" * AIP_TEST_DATA_URI = "bigquery_destination.dataset___.test"
	BigqueryDestination *GoogleCloudAiplatformV1beta1BigQueryDestination `pulumi:"bigqueryDestination"`
	// The ID of the Dataset in the same Project and Location which data will be used to train the Model. The Dataset must use schema compatible with Model being trained, and what is compatible should be described in the used TrainingPipeline's training_task_definition. For tabular Datasets, all their data is exported to training, to pick and choose from.
	DatasetId string `pulumi:"datasetId"`
	// Split based on the provided filters for each set.
	FilterSplit *GoogleCloudAiplatformV1beta1FilterSplit `pulumi:"filterSplit"`
	// Split based on fractions defining the size of each set.
	FractionSplit *GoogleCloudAiplatformV1beta1FractionSplit `pulumi:"fractionSplit"`
	// The Cloud Storage location where the training data is to be written to. In the given directory a new directory is created with name: `dataset---` where timestamp is in YYYY-MM-DDThh:mm:ss.sssZ ISO-8601 format. All training input data is written into that directory. The Vertex AI environment variables representing Cloud Storage data URIs are represented in the Cloud Storage wildcard format to support sharded data. e.g.: "gs://.../training-*.jsonl" * AIP_DATA_FORMAT = "jsonl" for non-tabular data, "csv" for tabular data * AIP_TRAINING_DATA_URI = "gcs_destination/dataset---/training-*.${AIP_DATA_FORMAT}" * AIP_VALIDATION_DATA_URI = "gcs_destination/dataset---/validation-*.${AIP_DATA_FORMAT}" * AIP_TEST_DATA_URI = "gcs_destination/dataset---/test-*.${AIP_DATA_FORMAT}"
	GcsDestination *GoogleCloudAiplatformV1beta1GcsDestination `pulumi:"gcsDestination"`
	// Whether to persist the ML use assignment to data item system labels.
	PersistMlUseAssignment *bool `pulumi:"persistMlUseAssignment"`
	// Supported only for tabular Datasets. Split based on a predefined key.
	PredefinedSplit *GoogleCloudAiplatformV1beta1PredefinedSplit `pulumi:"predefinedSplit"`
	// Only applicable to Datasets that have SavedQueries. The ID of a SavedQuery (annotation set) under the Dataset specified by dataset_id used for filtering Annotations for training. Only Annotations that are associated with this SavedQuery are used in respectively training. When used in conjunction with annotations_filter, the Annotations used for training are filtered by both saved_query_id and annotations_filter. Only one of saved_query_id and annotation_schema_uri should be specified as both of them represent the same thing: problem type.
	SavedQueryId *string `pulumi:"savedQueryId"`
	// Supported only for tabular Datasets. Split based on the distribution of the specified column.
	StratifiedSplit *GoogleCloudAiplatformV1beta1StratifiedSplit `pulumi:"stratifiedSplit"`
	// Supported only for tabular Datasets. Split based on the timestamp of the input data pieces.
	TimestampSplit *GoogleCloudAiplatformV1beta1TimestampSplit `pulumi:"timestampSplit"`
}

// GoogleCloudAiplatformV1beta1InputDataConfigInput is an input type that accepts GoogleCloudAiplatformV1beta1InputDataConfigArgs and GoogleCloudAiplatformV1beta1InputDataConfigOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1InputDataConfigInput` via:
//
//	GoogleCloudAiplatformV1beta1InputDataConfigArgs{...}
type GoogleCloudAiplatformV1beta1InputDataConfigInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1InputDataConfigOutput() GoogleCloudAiplatformV1beta1InputDataConfigOutput
	ToGoogleCloudAiplatformV1beta1InputDataConfigOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1InputDataConfigOutput
}

// Specifies Vertex AI owned input data to be used for training, and possibly evaluating, the Model.
type GoogleCloudAiplatformV1beta1InputDataConfigArgs struct {
	// Applicable only to custom training with Datasets that have DataItems and Annotations. Cloud Storage URI that points to a YAML file describing the annotation schema. The schema is defined as an OpenAPI 3.0.2 [Schema Object](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject). The schema files that can be used here are found in gs://google-cloud-aiplatform/schema/dataset/annotation/ , note that the chosen schema must be consistent with metadata of the Dataset specified by dataset_id. Only Annotations that both match this schema and belong to DataItems not ignored by the split method are used in respectively training, validation or test role, depending on the role of the DataItem they are on. When used in conjunction with annotations_filter, the Annotations used for training are filtered by both annotations_filter and annotation_schema_uri.
	AnnotationSchemaUri pulumi.StringPtrInput `pulumi:"annotationSchemaUri"`
	// Applicable only to Datasets that have DataItems and Annotations. A filter on Annotations of the Dataset. Only Annotations that both match this filter and belong to DataItems not ignored by the split method are used in respectively training, validation or test role, depending on the role of the DataItem they are on (for the auto-assigned that role is decided by Vertex AI). A filter with same syntax as the one used in ListAnnotations may be used, but note here it filters across all Annotations of the Dataset, and not just within a single DataItem.
	AnnotationsFilter pulumi.StringPtrInput `pulumi:"annotationsFilter"`
	// Only applicable to custom training with tabular Dataset with BigQuery source. The BigQuery project location where the training data is to be written to. In the given project a new dataset is created with name `dataset___` where timestamp is in YYYY_MM_DDThh_mm_ss_sssZ format. All training input data is written into that dataset. In the dataset three tables are created, `training`, `validation` and `test`. * AIP_DATA_FORMAT = "bigquery". * AIP_TRAINING_DATA_URI = "bigquery_destination.dataset___.training" * AIP_VALIDATION_DATA_URI = "bigquery_destination.dataset___.validation" * AIP_TEST_DATA_URI = "bigquery_destination.dataset___.test"
	BigqueryDestination GoogleCloudAiplatformV1beta1BigQueryDestinationPtrInput `pulumi:"bigqueryDestination"`
	// The ID of the Dataset in the same Project and Location which data will be used to train the Model. The Dataset must use schema compatible with Model being trained, and what is compatible should be described in the used TrainingPipeline's training_task_definition. For tabular Datasets, all their data is exported to training, to pick and choose from.
	DatasetId pulumi.StringInput `pulumi:"datasetId"`
	// Split based on the provided filters for each set.
	FilterSplit GoogleCloudAiplatformV1beta1FilterSplitPtrInput `pulumi:"filterSplit"`
	// Split based on fractions defining the size of each set.
	FractionSplit GoogleCloudAiplatformV1beta1FractionSplitPtrInput `pulumi:"fractionSplit"`
	// The Cloud Storage location where the training data is to be written to. In the given directory a new directory is created with name: `dataset---` where timestamp is in YYYY-MM-DDThh:mm:ss.sssZ ISO-8601 format. All training input data is written into that directory. The Vertex AI environment variables representing Cloud Storage data URIs are represented in the Cloud Storage wildcard format to support sharded data. e.g.: "gs://.../training-*.jsonl" * AIP_DATA_FORMAT = "jsonl" for non-tabular data, "csv" for tabular data * AIP_TRAINING_DATA_URI = "gcs_destination/dataset---/training-*.${AIP_DATA_FORMAT}" * AIP_VALIDATION_DATA_URI = "gcs_destination/dataset---/validation-*.${AIP_DATA_FORMAT}" * AIP_TEST_DATA_URI = "gcs_destination/dataset---/test-*.${AIP_DATA_FORMAT}"
	GcsDestination GoogleCloudAiplatformV1beta1GcsDestinationPtrInput `pulumi:"gcsDestination"`
	// Whether to persist the ML use assignment to data item system labels.
	PersistMlUseAssignment pulumi.BoolPtrInput `pulumi:"persistMlUseAssignment"`
	// Supported only for tabular Datasets. Split based on a predefined key.
	PredefinedSplit GoogleCloudAiplatformV1beta1PredefinedSplitPtrInput `pulumi:"predefinedSplit"`
	// Only applicable to Datasets that have SavedQueries. The ID of a SavedQuery (annotation set) under the Dataset specified by dataset_id used for filtering Annotations for training. Only Annotations that are associated with this SavedQuery are used in respectively training. When used in conjunction with annotations_filter, the Annotations used for training are filtered by both saved_query_id and annotations_filter. Only one of saved_query_id and annotation_schema_uri should be specified as both of them represent the same thing: problem type.
	SavedQueryId pulumi.StringPtrInput `pulumi:"savedQueryId"`
	// Supported only for tabular Datasets. Split based on the distribution of the specified column.
	StratifiedSplit GoogleCloudAiplatformV1beta1StratifiedSplitPtrInput `pulumi:"stratifiedSplit"`
	// Supported only for tabular Datasets. Split based on the timestamp of the input data pieces.
	TimestampSplit GoogleCloudAiplatformV1beta1TimestampSplitPtrInput `pulumi:"timestampSplit"`
}

func (GoogleCloudAiplatformV1beta1InputDataConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1InputDataConfig)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1InputDataConfigArgs) ToGoogleCloudAiplatformV1beta1InputDataConfigOutput() GoogleCloudAiplatformV1beta1InputDataConfigOutput {
	return i.ToGoogleCloudAiplatformV1beta1InputDataConfigOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1InputDataConfigArgs) ToGoogleCloudAiplatformV1beta1InputDataConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1InputDataConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1InputDataConfigOutput)
}

func (i GoogleCloudAiplatformV1beta1InputDataConfigArgs) ToGoogleCloudAiplatformV1beta1InputDataConfigPtrOutput() GoogleCloudAiplatformV1beta1InputDataConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1InputDataConfigPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1InputDataConfigArgs) ToGoogleCloudAiplatformV1beta1InputDataConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1InputDataConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1InputDataConfigOutput).ToGoogleCloudAiplatformV1beta1InputDataConfigPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1InputDataConfigPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1InputDataConfigArgs, GoogleCloudAiplatformV1beta1InputDataConfigPtr and GoogleCloudAiplatformV1beta1InputDataConfigPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1InputDataConfigPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1InputDataConfigArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1InputDataConfigPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1InputDataConfigPtrOutput() GoogleCloudAiplatformV1beta1InputDataConfigPtrOutput
	ToGoogleCloudAiplatformV1beta1InputDataConfigPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1InputDataConfigPtrOutput
}

type googleCloudAiplatformV1beta1InputDataConfigPtrType GoogleCloudAiplatformV1beta1InputDataConfigArgs

func GoogleCloudAiplatformV1beta1InputDataConfigPtr(v *GoogleCloudAiplatformV1beta1InputDataConfigArgs) GoogleCloudAiplatformV1beta1InputDataConfigPtrInput {
	return (*googleCloudAiplatformV1beta1InputDataConfigPtrType)(v)
}

func (*googleCloudAiplatformV1beta1InputDataConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1InputDataConfig)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1InputDataConfigPtrType) ToGoogleCloudAiplatformV1beta1InputDataConfigPtrOutput() GoogleCloudAiplatformV1beta1InputDataConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1InputDataConfigPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1InputDataConfigPtrType) ToGoogleCloudAiplatformV1beta1InputDataConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1InputDataConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1InputDataConfigPtrOutput)
}

// Specifies Vertex AI owned input data to be used for training, and possibly evaluating, the Model.
type GoogleCloudAiplatformV1beta1InputDataConfigOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1InputDataConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1InputDataConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1InputDataConfigOutput) ToGoogleCloudAiplatformV1beta1InputDataConfigOutput() GoogleCloudAiplatformV1beta1InputDataConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1InputDataConfigOutput) ToGoogleCloudAiplatformV1beta1InputDataConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1InputDataConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1InputDataConfigOutput) ToGoogleCloudAiplatformV1beta1InputDataConfigPtrOutput() GoogleCloudAiplatformV1beta1InputDataConfigPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1InputDataConfigPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1InputDataConfigOutput) ToGoogleCloudAiplatformV1beta1InputDataConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1InputDataConfigPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1InputDataConfig) *GoogleCloudAiplatformV1beta1InputDataConfig {
		return &v
	}).(GoogleCloudAiplatformV1beta1InputDataConfigPtrOutput)
}

// Applicable only to custom training with Datasets that have DataItems and Annotations. Cloud Storage URI that points to a YAML file describing the annotation schema. The schema is defined as an OpenAPI 3.0.2 [Schema Object](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject). The schema files that can be used here are found in gs://google-cloud-aiplatform/schema/dataset/annotation/ , note that the chosen schema must be consistent with metadata of the Dataset specified by dataset_id. Only Annotations that both match this schema and belong to DataItems not ignored by the split method are used in respectively training, validation or test role, depending on the role of the DataItem they are on. When used in conjunction with annotations_filter, the Annotations used for training are filtered by both annotations_filter and annotation_schema_uri.
func (o GoogleCloudAiplatformV1beta1InputDataConfigOutput) AnnotationSchemaUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1InputDataConfig) *string { return v.AnnotationSchemaUri }).(pulumi.StringPtrOutput)
}

// Applicable only to Datasets that have DataItems and Annotations. A filter on Annotations of the Dataset. Only Annotations that both match this filter and belong to DataItems not ignored by the split method are used in respectively training, validation or test role, depending on the role of the DataItem they are on (for the auto-assigned that role is decided by Vertex AI). A filter with same syntax as the one used in ListAnnotations may be used, but note here it filters across all Annotations of the Dataset, and not just within a single DataItem.
func (o GoogleCloudAiplatformV1beta1InputDataConfigOutput) AnnotationsFilter() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1InputDataConfig) *string { return v.AnnotationsFilter }).(pulumi.StringPtrOutput)
}

// Only applicable to custom training with tabular Dataset with BigQuery source. The BigQuery project location where the training data is to be written to. In the given project a new dataset is created with name `dataset___` where timestamp is in YYYY_MM_DDThh_mm_ss_sssZ format. All training input data is written into that dataset. In the dataset three tables are created, `training`, `validation` and `test`. * AIP_DATA_FORMAT = "bigquery". * AIP_TRAINING_DATA_URI = "bigquery_destination.dataset___.training" * AIP_VALIDATION_DATA_URI = "bigquery_destination.dataset___.validation" * AIP_TEST_DATA_URI = "bigquery_destination.dataset___.test"
func (o GoogleCloudAiplatformV1beta1InputDataConfigOutput) BigqueryDestination() GoogleCloudAiplatformV1beta1BigQueryDestinationPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1InputDataConfig) *GoogleCloudAiplatformV1beta1BigQueryDestination {
		return v.BigqueryDestination
	}).(GoogleCloudAiplatformV1beta1BigQueryDestinationPtrOutput)
}

// The ID of the Dataset in the same Project and Location which data will be used to train the Model. The Dataset must use schema compatible with Model being trained, and what is compatible should be described in the used TrainingPipeline's training_task_definition. For tabular Datasets, all their data is exported to training, to pick and choose from.
func (o GoogleCloudAiplatformV1beta1InputDataConfigOutput) DatasetId() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1InputDataConfig) string { return v.DatasetId }).(pulumi.StringOutput)
}

// Split based on the provided filters for each set.
func (o GoogleCloudAiplatformV1beta1InputDataConfigOutput) FilterSplit() GoogleCloudAiplatformV1beta1FilterSplitPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1InputDataConfig) *GoogleCloudAiplatformV1beta1FilterSplit {
		return v.FilterSplit
	}).(GoogleCloudAiplatformV1beta1FilterSplitPtrOutput)
}

// Split based on fractions defining the size of each set.
func (o GoogleCloudAiplatformV1beta1InputDataConfigOutput) FractionSplit() GoogleCloudAiplatformV1beta1FractionSplitPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1InputDataConfig) *GoogleCloudAiplatformV1beta1FractionSplit {
		return v.FractionSplit
	}).(GoogleCloudAiplatformV1beta1FractionSplitPtrOutput)
}

// The Cloud Storage location where the training data is to be written to. In the given directory a new directory is created with name: `dataset---` where timestamp is in YYYY-MM-DDThh:mm:ss.sssZ ISO-8601 format. All training input data is written into that directory. The Vertex AI environment variables representing Cloud Storage data URIs are represented in the Cloud Storage wildcard format to support sharded data. e.g.: "gs://.../training-*.jsonl" * AIP_DATA_FORMAT = "jsonl" for non-tabular data, "csv" for tabular data * AIP_TRAINING_DATA_URI = "gcs_destination/dataset---/training-*.${AIP_DATA_FORMAT}" * AIP_VALIDATION_DATA_URI = "gcs_destination/dataset---/validation-*.${AIP_DATA_FORMAT}" * AIP_TEST_DATA_URI = "gcs_destination/dataset---/test-*.${AIP_DATA_FORMAT}"
func (o GoogleCloudAiplatformV1beta1InputDataConfigOutput) GcsDestination() GoogleCloudAiplatformV1beta1GcsDestinationPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1InputDataConfig) *GoogleCloudAiplatformV1beta1GcsDestination {
		return v.GcsDestination
	}).(GoogleCloudAiplatformV1beta1GcsDestinationPtrOutput)
}

// Whether to persist the ML use assignment to data item system labels.
func (o GoogleCloudAiplatformV1beta1InputDataConfigOutput) PersistMlUseAssignment() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1InputDataConfig) *bool { return v.PersistMlUseAssignment }).(pulumi.BoolPtrOutput)
}

// Supported only for tabular Datasets. Split based on a predefined key.
func (o GoogleCloudAiplatformV1beta1InputDataConfigOutput) PredefinedSplit() GoogleCloudAiplatformV1beta1PredefinedSplitPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1InputDataConfig) *GoogleCloudAiplatformV1beta1PredefinedSplit {
		return v.PredefinedSplit
	}).(GoogleCloudAiplatformV1beta1PredefinedSplitPtrOutput)
}

// Only applicable to Datasets that have SavedQueries. The ID of a SavedQuery (annotation set) under the Dataset specified by dataset_id used for filtering Annotations for training. Only Annotations that are associated with this SavedQuery are used in respectively training. When used in conjunction with annotations_filter, the Annotations used for training are filtered by both saved_query_id and annotations_filter. Only one of saved_query_id and annotation_schema_uri should be specified as both of them represent the same thing: problem type.
func (o GoogleCloudAiplatformV1beta1InputDataConfigOutput) SavedQueryId() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1InputDataConfig) *string { return v.SavedQueryId }).(pulumi.StringPtrOutput)
}

// Supported only for tabular Datasets. Split based on the distribution of the specified column.
func (o GoogleCloudAiplatformV1beta1InputDataConfigOutput) StratifiedSplit() GoogleCloudAiplatformV1beta1StratifiedSplitPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1InputDataConfig) *GoogleCloudAiplatformV1beta1StratifiedSplit {
		return v.StratifiedSplit
	}).(GoogleCloudAiplatformV1beta1StratifiedSplitPtrOutput)
}

// Supported only for tabular Datasets. Split based on the timestamp of the input data pieces.
func (o GoogleCloudAiplatformV1beta1InputDataConfigOutput) TimestampSplit() GoogleCloudAiplatformV1beta1TimestampSplitPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1InputDataConfig) *GoogleCloudAiplatformV1beta1TimestampSplit {
		return v.TimestampSplit
	}).(GoogleCloudAiplatformV1beta1TimestampSplitPtrOutput)
}

type GoogleCloudAiplatformV1beta1InputDataConfigPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1InputDataConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1InputDataConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1InputDataConfigPtrOutput) ToGoogleCloudAiplatformV1beta1InputDataConfigPtrOutput() GoogleCloudAiplatformV1beta1InputDataConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1InputDataConfigPtrOutput) ToGoogleCloudAiplatformV1beta1InputDataConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1InputDataConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1InputDataConfigPtrOutput) Elem() GoogleCloudAiplatformV1beta1InputDataConfigOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1InputDataConfig) GoogleCloudAiplatformV1beta1InputDataConfig {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1InputDataConfig
		return ret
	}).(GoogleCloudAiplatformV1beta1InputDataConfigOutput)
}

// Applicable only to custom training with Datasets that have DataItems and Annotations. Cloud Storage URI that points to a YAML file describing the annotation schema. The schema is defined as an OpenAPI 3.0.2 [Schema Object](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject). The schema files that can be used here are found in gs://google-cloud-aiplatform/schema/dataset/annotation/ , note that the chosen schema must be consistent with metadata of the Dataset specified by dataset_id. Only Annotations that both match this schema and belong to DataItems not ignored by the split method are used in respectively training, validation or test role, depending on the role of the DataItem they are on. When used in conjunction with annotations_filter, the Annotations used for training are filtered by both annotations_filter and annotation_schema_uri.
func (o GoogleCloudAiplatformV1beta1InputDataConfigPtrOutput) AnnotationSchemaUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1InputDataConfig) *string {
		if v == nil {
			return nil
		}
		return v.AnnotationSchemaUri
	}).(pulumi.StringPtrOutput)
}

// Applicable only to Datasets that have DataItems and Annotations. A filter on Annotations of the Dataset. Only Annotations that both match this filter and belong to DataItems not ignored by the split method are used in respectively training, validation or test role, depending on the role of the DataItem they are on (for the auto-assigned that role is decided by Vertex AI). A filter with same syntax as the one used in ListAnnotations may be used, but note here it filters across all Annotations of the Dataset, and not just within a single DataItem.
func (o GoogleCloudAiplatformV1beta1InputDataConfigPtrOutput) AnnotationsFilter() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1InputDataConfig) *string {
		if v == nil {
			return nil
		}
		return v.AnnotationsFilter
	}).(pulumi.StringPtrOutput)
}

// Only applicable to custom training with tabular Dataset with BigQuery source. The BigQuery project location where the training data is to be written to. In the given project a new dataset is created with name `dataset___` where timestamp is in YYYY_MM_DDThh_mm_ss_sssZ format. All training input data is written into that dataset. In the dataset three tables are created, `training`, `validation` and `test`. * AIP_DATA_FORMAT = "bigquery". * AIP_TRAINING_DATA_URI = "bigquery_destination.dataset___.training" * AIP_VALIDATION_DATA_URI = "bigquery_destination.dataset___.validation" * AIP_TEST_DATA_URI = "bigquery_destination.dataset___.test"
func (o GoogleCloudAiplatformV1beta1InputDataConfigPtrOutput) BigqueryDestination() GoogleCloudAiplatformV1beta1BigQueryDestinationPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1InputDataConfig) *GoogleCloudAiplatformV1beta1BigQueryDestination {
		if v == nil {
			return nil
		}
		return v.BigqueryDestination
	}).(GoogleCloudAiplatformV1beta1BigQueryDestinationPtrOutput)
}

// The ID of the Dataset in the same Project and Location which data will be used to train the Model. The Dataset must use schema compatible with Model being trained, and what is compatible should be described in the used TrainingPipeline's training_task_definition. For tabular Datasets, all their data is exported to training, to pick and choose from.
func (o GoogleCloudAiplatformV1beta1InputDataConfigPtrOutput) DatasetId() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1InputDataConfig) *string {
		if v == nil {
			return nil
		}
		return &v.DatasetId
	}).(pulumi.StringPtrOutput)
}

// Split based on the provided filters for each set.
func (o GoogleCloudAiplatformV1beta1InputDataConfigPtrOutput) FilterSplit() GoogleCloudAiplatformV1beta1FilterSplitPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1InputDataConfig) *GoogleCloudAiplatformV1beta1FilterSplit {
		if v == nil {
			return nil
		}
		return v.FilterSplit
	}).(GoogleCloudAiplatformV1beta1FilterSplitPtrOutput)
}

// Split based on fractions defining the size of each set.
func (o GoogleCloudAiplatformV1beta1InputDataConfigPtrOutput) FractionSplit() GoogleCloudAiplatformV1beta1FractionSplitPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1InputDataConfig) *GoogleCloudAiplatformV1beta1FractionSplit {
		if v == nil {
			return nil
		}
		return v.FractionSplit
	}).(GoogleCloudAiplatformV1beta1FractionSplitPtrOutput)
}

// The Cloud Storage location where the training data is to be written to. In the given directory a new directory is created with name: `dataset---` where timestamp is in YYYY-MM-DDThh:mm:ss.sssZ ISO-8601 format. All training input data is written into that directory. The Vertex AI environment variables representing Cloud Storage data URIs are represented in the Cloud Storage wildcard format to support sharded data. e.g.: "gs://.../training-*.jsonl" * AIP_DATA_FORMAT = "jsonl" for non-tabular data, "csv" for tabular data * AIP_TRAINING_DATA_URI = "gcs_destination/dataset---/training-*.${AIP_DATA_FORMAT}" * AIP_VALIDATION_DATA_URI = "gcs_destination/dataset---/validation-*.${AIP_DATA_FORMAT}" * AIP_TEST_DATA_URI = "gcs_destination/dataset---/test-*.${AIP_DATA_FORMAT}"
func (o GoogleCloudAiplatformV1beta1InputDataConfigPtrOutput) GcsDestination() GoogleCloudAiplatformV1beta1GcsDestinationPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1InputDataConfig) *GoogleCloudAiplatformV1beta1GcsDestination {
		if v == nil {
			return nil
		}
		return v.GcsDestination
	}).(GoogleCloudAiplatformV1beta1GcsDestinationPtrOutput)
}

// Whether to persist the ML use assignment to data item system labels.
func (o GoogleCloudAiplatformV1beta1InputDataConfigPtrOutput) PersistMlUseAssignment() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1InputDataConfig) *bool {
		if v == nil {
			return nil
		}
		return v.PersistMlUseAssignment
	}).(pulumi.BoolPtrOutput)
}

// Supported only for tabular Datasets. Split based on a predefined key.
func (o GoogleCloudAiplatformV1beta1InputDataConfigPtrOutput) PredefinedSplit() GoogleCloudAiplatformV1beta1PredefinedSplitPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1InputDataConfig) *GoogleCloudAiplatformV1beta1PredefinedSplit {
		if v == nil {
			return nil
		}
		return v.PredefinedSplit
	}).(GoogleCloudAiplatformV1beta1PredefinedSplitPtrOutput)
}

// Only applicable to Datasets that have SavedQueries. The ID of a SavedQuery (annotation set) under the Dataset specified by dataset_id used for filtering Annotations for training. Only Annotations that are associated with this SavedQuery are used in respectively training. When used in conjunction with annotations_filter, the Annotations used for training are filtered by both saved_query_id and annotations_filter. Only one of saved_query_id and annotation_schema_uri should be specified as both of them represent the same thing: problem type.
func (o GoogleCloudAiplatformV1beta1InputDataConfigPtrOutput) SavedQueryId() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1InputDataConfig) *string {
		if v == nil {
			return nil
		}
		return v.SavedQueryId
	}).(pulumi.StringPtrOutput)
}

// Supported only for tabular Datasets. Split based on the distribution of the specified column.
func (o GoogleCloudAiplatformV1beta1InputDataConfigPtrOutput) StratifiedSplit() GoogleCloudAiplatformV1beta1StratifiedSplitPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1InputDataConfig) *GoogleCloudAiplatformV1beta1StratifiedSplit {
		if v == nil {
			return nil
		}
		return v.StratifiedSplit
	}).(GoogleCloudAiplatformV1beta1StratifiedSplitPtrOutput)
}

// Supported only for tabular Datasets. Split based on the timestamp of the input data pieces.
func (o GoogleCloudAiplatformV1beta1InputDataConfigPtrOutput) TimestampSplit() GoogleCloudAiplatformV1beta1TimestampSplitPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1InputDataConfig) *GoogleCloudAiplatformV1beta1TimestampSplit {
		if v == nil {
			return nil
		}
		return v.TimestampSplit
	}).(GoogleCloudAiplatformV1beta1TimestampSplitPtrOutput)
}

// Specifies Vertex AI owned input data to be used for training, and possibly evaluating, the Model.
type GoogleCloudAiplatformV1beta1InputDataConfigResponse struct {
	// Applicable only to custom training with Datasets that have DataItems and Annotations. Cloud Storage URI that points to a YAML file describing the annotation schema. The schema is defined as an OpenAPI 3.0.2 [Schema Object](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject). The schema files that can be used here are found in gs://google-cloud-aiplatform/schema/dataset/annotation/ , note that the chosen schema must be consistent with metadata of the Dataset specified by dataset_id. Only Annotations that both match this schema and belong to DataItems not ignored by the split method are used in respectively training, validation or test role, depending on the role of the DataItem they are on. When used in conjunction with annotations_filter, the Annotations used for training are filtered by both annotations_filter and annotation_schema_uri.
	AnnotationSchemaUri string `pulumi:"annotationSchemaUri"`
	// Applicable only to Datasets that have DataItems and Annotations. A filter on Annotations of the Dataset. Only Annotations that both match this filter and belong to DataItems not ignored by the split method are used in respectively training, validation or test role, depending on the role of the DataItem they are on (for the auto-assigned that role is decided by Vertex AI). A filter with same syntax as the one used in ListAnnotations may be used, but note here it filters across all Annotations of the Dataset, and not just within a single DataItem.
	AnnotationsFilter string `pulumi:"annotationsFilter"`
	// Only applicable to custom training with tabular Dataset with BigQuery source. The BigQuery project location where the training data is to be written to. In the given project a new dataset is created with name `dataset___` where timestamp is in YYYY_MM_DDThh_mm_ss_sssZ format. All training input data is written into that dataset. In the dataset three tables are created, `training`, `validation` and `test`. * AIP_DATA_FORMAT = "bigquery". * AIP_TRAINING_DATA_URI = "bigquery_destination.dataset___.training" * AIP_VALIDATION_DATA_URI = "bigquery_destination.dataset___.validation" * AIP_TEST_DATA_URI = "bigquery_destination.dataset___.test"
	BigqueryDestination GoogleCloudAiplatformV1beta1BigQueryDestinationResponse `pulumi:"bigqueryDestination"`
	// The ID of the Dataset in the same Project and Location which data will be used to train the Model. The Dataset must use schema compatible with Model being trained, and what is compatible should be described in the used TrainingPipeline's training_task_definition. For tabular Datasets, all their data is exported to training, to pick and choose from.
	DatasetId string `pulumi:"datasetId"`
	// Split based on the provided filters for each set.
	FilterSplit GoogleCloudAiplatformV1beta1FilterSplitResponse `pulumi:"filterSplit"`
	// Split based on fractions defining the size of each set.
	FractionSplit GoogleCloudAiplatformV1beta1FractionSplitResponse `pulumi:"fractionSplit"`
	// The Cloud Storage location where the training data is to be written to. In the given directory a new directory is created with name: `dataset---` where timestamp is in YYYY-MM-DDThh:mm:ss.sssZ ISO-8601 format. All training input data is written into that directory. The Vertex AI environment variables representing Cloud Storage data URIs are represented in the Cloud Storage wildcard format to support sharded data. e.g.: "gs://.../training-*.jsonl" * AIP_DATA_FORMAT = "jsonl" for non-tabular data, "csv" for tabular data * AIP_TRAINING_DATA_URI = "gcs_destination/dataset---/training-*.${AIP_DATA_FORMAT}" * AIP_VALIDATION_DATA_URI = "gcs_destination/dataset---/validation-*.${AIP_DATA_FORMAT}" * AIP_TEST_DATA_URI = "gcs_destination/dataset---/test-*.${AIP_DATA_FORMAT}"
	GcsDestination GoogleCloudAiplatformV1beta1GcsDestinationResponse `pulumi:"gcsDestination"`
	// Whether to persist the ML use assignment to data item system labels.
	PersistMlUseAssignment bool `pulumi:"persistMlUseAssignment"`
	// Supported only for tabular Datasets. Split based on a predefined key.
	PredefinedSplit GoogleCloudAiplatformV1beta1PredefinedSplitResponse `pulumi:"predefinedSplit"`
	// Only applicable to Datasets that have SavedQueries. The ID of a SavedQuery (annotation set) under the Dataset specified by dataset_id used for filtering Annotations for training. Only Annotations that are associated with this SavedQuery are used in respectively training. When used in conjunction with annotations_filter, the Annotations used for training are filtered by both saved_query_id and annotations_filter. Only one of saved_query_id and annotation_schema_uri should be specified as both of them represent the same thing: problem type.
	SavedQueryId string `pulumi:"savedQueryId"`
	// Supported only for tabular Datasets. Split based on the distribution of the specified column.
	StratifiedSplit GoogleCloudAiplatformV1beta1StratifiedSplitResponse `pulumi:"stratifiedSplit"`
	// Supported only for tabular Datasets. Split based on the timestamp of the input data pieces.
	TimestampSplit GoogleCloudAiplatformV1beta1TimestampSplitResponse `pulumi:"timestampSplit"`
}

// Specifies Vertex AI owned input data to be used for training, and possibly evaluating, the Model.
type GoogleCloudAiplatformV1beta1InputDataConfigResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1InputDataConfigResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1InputDataConfigResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1InputDataConfigResponseOutput) ToGoogleCloudAiplatformV1beta1InputDataConfigResponseOutput() GoogleCloudAiplatformV1beta1InputDataConfigResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1InputDataConfigResponseOutput) ToGoogleCloudAiplatformV1beta1InputDataConfigResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1InputDataConfigResponseOutput {
	return o
}

// Applicable only to custom training with Datasets that have DataItems and Annotations. Cloud Storage URI that points to a YAML file describing the annotation schema. The schema is defined as an OpenAPI 3.0.2 [Schema Object](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject). The schema files that can be used here are found in gs://google-cloud-aiplatform/schema/dataset/annotation/ , note that the chosen schema must be consistent with metadata of the Dataset specified by dataset_id. Only Annotations that both match this schema and belong to DataItems not ignored by the split method are used in respectively training, validation or test role, depending on the role of the DataItem they are on. When used in conjunction with annotations_filter, the Annotations used for training are filtered by both annotations_filter and annotation_schema_uri.
func (o GoogleCloudAiplatformV1beta1InputDataConfigResponseOutput) AnnotationSchemaUri() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1InputDataConfigResponse) string { return v.AnnotationSchemaUri }).(pulumi.StringOutput)
}

// Applicable only to Datasets that have DataItems and Annotations. A filter on Annotations of the Dataset. Only Annotations that both match this filter and belong to DataItems not ignored by the split method are used in respectively training, validation or test role, depending on the role of the DataItem they are on (for the auto-assigned that role is decided by Vertex AI). A filter with same syntax as the one used in ListAnnotations may be used, but note here it filters across all Annotations of the Dataset, and not just within a single DataItem.
func (o GoogleCloudAiplatformV1beta1InputDataConfigResponseOutput) AnnotationsFilter() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1InputDataConfigResponse) string { return v.AnnotationsFilter }).(pulumi.StringOutput)
}

// Only applicable to custom training with tabular Dataset with BigQuery source. The BigQuery project location where the training data is to be written to. In the given project a new dataset is created with name `dataset___` where timestamp is in YYYY_MM_DDThh_mm_ss_sssZ format. All training input data is written into that dataset. In the dataset three tables are created, `training`, `validation` and `test`. * AIP_DATA_FORMAT = "bigquery". * AIP_TRAINING_DATA_URI = "bigquery_destination.dataset___.training" * AIP_VALIDATION_DATA_URI = "bigquery_destination.dataset___.validation" * AIP_TEST_DATA_URI = "bigquery_destination.dataset___.test"
func (o GoogleCloudAiplatformV1beta1InputDataConfigResponseOutput) BigqueryDestination() GoogleCloudAiplatformV1beta1BigQueryDestinationResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1InputDataConfigResponse) GoogleCloudAiplatformV1beta1BigQueryDestinationResponse {
		return v.BigqueryDestination
	}).(GoogleCloudAiplatformV1beta1BigQueryDestinationResponseOutput)
}

// The ID of the Dataset in the same Project and Location which data will be used to train the Model. The Dataset must use schema compatible with Model being trained, and what is compatible should be described in the used TrainingPipeline's training_task_definition. For tabular Datasets, all their data is exported to training, to pick and choose from.
func (o GoogleCloudAiplatformV1beta1InputDataConfigResponseOutput) DatasetId() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1InputDataConfigResponse) string { return v.DatasetId }).(pulumi.StringOutput)
}

// Split based on the provided filters for each set.
func (o GoogleCloudAiplatformV1beta1InputDataConfigResponseOutput) FilterSplit() GoogleCloudAiplatformV1beta1FilterSplitResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1InputDataConfigResponse) GoogleCloudAiplatformV1beta1FilterSplitResponse {
		return v.FilterSplit
	}).(GoogleCloudAiplatformV1beta1FilterSplitResponseOutput)
}

// Split based on fractions defining the size of each set.
func (o GoogleCloudAiplatformV1beta1InputDataConfigResponseOutput) FractionSplit() GoogleCloudAiplatformV1beta1FractionSplitResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1InputDataConfigResponse) GoogleCloudAiplatformV1beta1FractionSplitResponse {
		return v.FractionSplit
	}).(GoogleCloudAiplatformV1beta1FractionSplitResponseOutput)
}

// The Cloud Storage location where the training data is to be written to. In the given directory a new directory is created with name: `dataset---` where timestamp is in YYYY-MM-DDThh:mm:ss.sssZ ISO-8601 format. All training input data is written into that directory. The Vertex AI environment variables representing Cloud Storage data URIs are represented in the Cloud Storage wildcard format to support sharded data. e.g.: "gs://.../training-*.jsonl" * AIP_DATA_FORMAT = "jsonl" for non-tabular data, "csv" for tabular data * AIP_TRAINING_DATA_URI = "gcs_destination/dataset---/training-*.${AIP_DATA_FORMAT}" * AIP_VALIDATION_DATA_URI = "gcs_destination/dataset---/validation-*.${AIP_DATA_FORMAT}" * AIP_TEST_DATA_URI = "gcs_destination/dataset---/test-*.${AIP_DATA_FORMAT}"
func (o GoogleCloudAiplatformV1beta1InputDataConfigResponseOutput) GcsDestination() GoogleCloudAiplatformV1beta1GcsDestinationResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1InputDataConfigResponse) GoogleCloudAiplatformV1beta1GcsDestinationResponse {
		return v.GcsDestination
	}).(GoogleCloudAiplatformV1beta1GcsDestinationResponseOutput)
}

// Whether to persist the ML use assignment to data item system labels.
func (o GoogleCloudAiplatformV1beta1InputDataConfigResponseOutput) PersistMlUseAssignment() pulumi.BoolOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1InputDataConfigResponse) bool { return v.PersistMlUseAssignment }).(pulumi.BoolOutput)
}

// Supported only for tabular Datasets. Split based on a predefined key.
func (o GoogleCloudAiplatformV1beta1InputDataConfigResponseOutput) PredefinedSplit() GoogleCloudAiplatformV1beta1PredefinedSplitResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1InputDataConfigResponse) GoogleCloudAiplatformV1beta1PredefinedSplitResponse {
		return v.PredefinedSplit
	}).(GoogleCloudAiplatformV1beta1PredefinedSplitResponseOutput)
}

// Only applicable to Datasets that have SavedQueries. The ID of a SavedQuery (annotation set) under the Dataset specified by dataset_id used for filtering Annotations for training. Only Annotations that are associated with this SavedQuery are used in respectively training. When used in conjunction with annotations_filter, the Annotations used for training are filtered by both saved_query_id and annotations_filter. Only one of saved_query_id and annotation_schema_uri should be specified as both of them represent the same thing: problem type.
func (o GoogleCloudAiplatformV1beta1InputDataConfigResponseOutput) SavedQueryId() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1InputDataConfigResponse) string { return v.SavedQueryId }).(pulumi.StringOutput)
}

// Supported only for tabular Datasets. Split based on the distribution of the specified column.
func (o GoogleCloudAiplatformV1beta1InputDataConfigResponseOutput) StratifiedSplit() GoogleCloudAiplatformV1beta1StratifiedSplitResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1InputDataConfigResponse) GoogleCloudAiplatformV1beta1StratifiedSplitResponse {
		return v.StratifiedSplit
	}).(GoogleCloudAiplatformV1beta1StratifiedSplitResponseOutput)
}

// Supported only for tabular Datasets. Split based on the timestamp of the input data pieces.
func (o GoogleCloudAiplatformV1beta1InputDataConfigResponseOutput) TimestampSplit() GoogleCloudAiplatformV1beta1TimestampSplitResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1InputDataConfigResponse) GoogleCloudAiplatformV1beta1TimestampSplitResponse {
		return v.TimestampSplit
	}).(GoogleCloudAiplatformV1beta1TimestampSplitResponseOutput)
}

// An attribution method that computes the Aumann-Shapley value taking advantage of the model's fully differentiable structure. Refer to this paper for more details: https://arxiv.org/abs/1703.01365
type GoogleCloudAiplatformV1beta1IntegratedGradientsAttribution struct {
	// Config for IG with blur baseline. When enabled, a linear path from the maximally blurred image to the input image is created. Using a blurred baseline instead of zero (black image) is motivated by the BlurIG approach explained here: https://arxiv.org/abs/2004.03383
	BlurBaselineConfig *GoogleCloudAiplatformV1beta1BlurBaselineConfig `pulumi:"blurBaselineConfig"`
	// Config for SmoothGrad approximation of gradients. When enabled, the gradients are approximated by averaging the gradients from noisy samples in the vicinity of the inputs. Adding noise can help improve the computed gradients. Refer to this paper for more details: https://arxiv.org/pdf/1706.03825.pdf
	SmoothGradConfig *GoogleCloudAiplatformV1beta1SmoothGradConfig `pulumi:"smoothGradConfig"`
	// The number of steps for approximating the path integral. A good value to start is 50 and gradually increase until the sum to diff property is within the desired error range. Valid range of its value is [1, 100], inclusively.
	StepCount int `pulumi:"stepCount"`
}

// GoogleCloudAiplatformV1beta1IntegratedGradientsAttributionInput is an input type that accepts GoogleCloudAiplatformV1beta1IntegratedGradientsAttributionArgs and GoogleCloudAiplatformV1beta1IntegratedGradientsAttributionOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1IntegratedGradientsAttributionInput` via:
//
//	GoogleCloudAiplatformV1beta1IntegratedGradientsAttributionArgs{...}
type GoogleCloudAiplatformV1beta1IntegratedGradientsAttributionInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1IntegratedGradientsAttributionOutput() GoogleCloudAiplatformV1beta1IntegratedGradientsAttributionOutput
	ToGoogleCloudAiplatformV1beta1IntegratedGradientsAttributionOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1IntegratedGradientsAttributionOutput
}

// An attribution method that computes the Aumann-Shapley value taking advantage of the model's fully differentiable structure. Refer to this paper for more details: https://arxiv.org/abs/1703.01365
type GoogleCloudAiplatformV1beta1IntegratedGradientsAttributionArgs struct {
	// Config for IG with blur baseline. When enabled, a linear path from the maximally blurred image to the input image is created. Using a blurred baseline instead of zero (black image) is motivated by the BlurIG approach explained here: https://arxiv.org/abs/2004.03383
	BlurBaselineConfig GoogleCloudAiplatformV1beta1BlurBaselineConfigPtrInput `pulumi:"blurBaselineConfig"`
	// Config for SmoothGrad approximation of gradients. When enabled, the gradients are approximated by averaging the gradients from noisy samples in the vicinity of the inputs. Adding noise can help improve the computed gradients. Refer to this paper for more details: https://arxiv.org/pdf/1706.03825.pdf
	SmoothGradConfig GoogleCloudAiplatformV1beta1SmoothGradConfigPtrInput `pulumi:"smoothGradConfig"`
	// The number of steps for approximating the path integral. A good value to start is 50 and gradually increase until the sum to diff property is within the desired error range. Valid range of its value is [1, 100], inclusively.
	StepCount pulumi.IntInput `pulumi:"stepCount"`
}

func (GoogleCloudAiplatformV1beta1IntegratedGradientsAttributionArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1IntegratedGradientsAttribution)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1IntegratedGradientsAttributionArgs) ToGoogleCloudAiplatformV1beta1IntegratedGradientsAttributionOutput() GoogleCloudAiplatformV1beta1IntegratedGradientsAttributionOutput {
	return i.ToGoogleCloudAiplatformV1beta1IntegratedGradientsAttributionOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1IntegratedGradientsAttributionArgs) ToGoogleCloudAiplatformV1beta1IntegratedGradientsAttributionOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1IntegratedGradientsAttributionOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1IntegratedGradientsAttributionOutput)
}

func (i GoogleCloudAiplatformV1beta1IntegratedGradientsAttributionArgs) ToGoogleCloudAiplatformV1beta1IntegratedGradientsAttributionPtrOutput() GoogleCloudAiplatformV1beta1IntegratedGradientsAttributionPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1IntegratedGradientsAttributionPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1IntegratedGradientsAttributionArgs) ToGoogleCloudAiplatformV1beta1IntegratedGradientsAttributionPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1IntegratedGradientsAttributionPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1IntegratedGradientsAttributionOutput).ToGoogleCloudAiplatformV1beta1IntegratedGradientsAttributionPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1IntegratedGradientsAttributionPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1IntegratedGradientsAttributionArgs, GoogleCloudAiplatformV1beta1IntegratedGradientsAttributionPtr and GoogleCloudAiplatformV1beta1IntegratedGradientsAttributionPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1IntegratedGradientsAttributionPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1IntegratedGradientsAttributionArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1IntegratedGradientsAttributionPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1IntegratedGradientsAttributionPtrOutput() GoogleCloudAiplatformV1beta1IntegratedGradientsAttributionPtrOutput
	ToGoogleCloudAiplatformV1beta1IntegratedGradientsAttributionPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1IntegratedGradientsAttributionPtrOutput
}

type googleCloudAiplatformV1beta1IntegratedGradientsAttributionPtrType GoogleCloudAiplatformV1beta1IntegratedGradientsAttributionArgs

func GoogleCloudAiplatformV1beta1IntegratedGradientsAttributionPtr(v *GoogleCloudAiplatformV1beta1IntegratedGradientsAttributionArgs) GoogleCloudAiplatformV1beta1IntegratedGradientsAttributionPtrInput {
	return (*googleCloudAiplatformV1beta1IntegratedGradientsAttributionPtrType)(v)
}

func (*googleCloudAiplatformV1beta1IntegratedGradientsAttributionPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1IntegratedGradientsAttribution)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1IntegratedGradientsAttributionPtrType) ToGoogleCloudAiplatformV1beta1IntegratedGradientsAttributionPtrOutput() GoogleCloudAiplatformV1beta1IntegratedGradientsAttributionPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1IntegratedGradientsAttributionPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1IntegratedGradientsAttributionPtrType) ToGoogleCloudAiplatformV1beta1IntegratedGradientsAttributionPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1IntegratedGradientsAttributionPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1IntegratedGradientsAttributionPtrOutput)
}

// An attribution method that computes the Aumann-Shapley value taking advantage of the model's fully differentiable structure. Refer to this paper for more details: https://arxiv.org/abs/1703.01365
type GoogleCloudAiplatformV1beta1IntegratedGradientsAttributionOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1IntegratedGradientsAttributionOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1IntegratedGradientsAttribution)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1IntegratedGradientsAttributionOutput) ToGoogleCloudAiplatformV1beta1IntegratedGradientsAttributionOutput() GoogleCloudAiplatformV1beta1IntegratedGradientsAttributionOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1IntegratedGradientsAttributionOutput) ToGoogleCloudAiplatformV1beta1IntegratedGradientsAttributionOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1IntegratedGradientsAttributionOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1IntegratedGradientsAttributionOutput) ToGoogleCloudAiplatformV1beta1IntegratedGradientsAttributionPtrOutput() GoogleCloudAiplatformV1beta1IntegratedGradientsAttributionPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1IntegratedGradientsAttributionPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1IntegratedGradientsAttributionOutput) ToGoogleCloudAiplatformV1beta1IntegratedGradientsAttributionPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1IntegratedGradientsAttributionPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1IntegratedGradientsAttribution) *GoogleCloudAiplatformV1beta1IntegratedGradientsAttribution {
		return &v
	}).(GoogleCloudAiplatformV1beta1IntegratedGradientsAttributionPtrOutput)
}

// Config for IG with blur baseline. When enabled, a linear path from the maximally blurred image to the input image is created. Using a blurred baseline instead of zero (black image) is motivated by the BlurIG approach explained here: https://arxiv.org/abs/2004.03383
func (o GoogleCloudAiplatformV1beta1IntegratedGradientsAttributionOutput) BlurBaselineConfig() GoogleCloudAiplatformV1beta1BlurBaselineConfigPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1IntegratedGradientsAttribution) *GoogleCloudAiplatformV1beta1BlurBaselineConfig {
		return v.BlurBaselineConfig
	}).(GoogleCloudAiplatformV1beta1BlurBaselineConfigPtrOutput)
}

// Config for SmoothGrad approximation of gradients. When enabled, the gradients are approximated by averaging the gradients from noisy samples in the vicinity of the inputs. Adding noise can help improve the computed gradients. Refer to this paper for more details: https://arxiv.org/pdf/1706.03825.pdf
func (o GoogleCloudAiplatformV1beta1IntegratedGradientsAttributionOutput) SmoothGradConfig() GoogleCloudAiplatformV1beta1SmoothGradConfigPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1IntegratedGradientsAttribution) *GoogleCloudAiplatformV1beta1SmoothGradConfig {
		return v.SmoothGradConfig
	}).(GoogleCloudAiplatformV1beta1SmoothGradConfigPtrOutput)
}

// The number of steps for approximating the path integral. A good value to start is 50 and gradually increase until the sum to diff property is within the desired error range. Valid range of its value is [1, 100], inclusively.
func (o GoogleCloudAiplatformV1beta1IntegratedGradientsAttributionOutput) StepCount() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1IntegratedGradientsAttribution) int { return v.StepCount }).(pulumi.IntOutput)
}

type GoogleCloudAiplatformV1beta1IntegratedGradientsAttributionPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1IntegratedGradientsAttributionPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1IntegratedGradientsAttribution)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1IntegratedGradientsAttributionPtrOutput) ToGoogleCloudAiplatformV1beta1IntegratedGradientsAttributionPtrOutput() GoogleCloudAiplatformV1beta1IntegratedGradientsAttributionPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1IntegratedGradientsAttributionPtrOutput) ToGoogleCloudAiplatformV1beta1IntegratedGradientsAttributionPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1IntegratedGradientsAttributionPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1IntegratedGradientsAttributionPtrOutput) Elem() GoogleCloudAiplatformV1beta1IntegratedGradientsAttributionOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1IntegratedGradientsAttribution) GoogleCloudAiplatformV1beta1IntegratedGradientsAttribution {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1IntegratedGradientsAttribution
		return ret
	}).(GoogleCloudAiplatformV1beta1IntegratedGradientsAttributionOutput)
}

// Config for IG with blur baseline. When enabled, a linear path from the maximally blurred image to the input image is created. Using a blurred baseline instead of zero (black image) is motivated by the BlurIG approach explained here: https://arxiv.org/abs/2004.03383
func (o GoogleCloudAiplatformV1beta1IntegratedGradientsAttributionPtrOutput) BlurBaselineConfig() GoogleCloudAiplatformV1beta1BlurBaselineConfigPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1IntegratedGradientsAttribution) *GoogleCloudAiplatformV1beta1BlurBaselineConfig {
		if v == nil {
			return nil
		}
		return v.BlurBaselineConfig
	}).(GoogleCloudAiplatformV1beta1BlurBaselineConfigPtrOutput)
}

// Config for SmoothGrad approximation of gradients. When enabled, the gradients are approximated by averaging the gradients from noisy samples in the vicinity of the inputs. Adding noise can help improve the computed gradients. Refer to this paper for more details: https://arxiv.org/pdf/1706.03825.pdf
func (o GoogleCloudAiplatformV1beta1IntegratedGradientsAttributionPtrOutput) SmoothGradConfig() GoogleCloudAiplatformV1beta1SmoothGradConfigPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1IntegratedGradientsAttribution) *GoogleCloudAiplatformV1beta1SmoothGradConfig {
		if v == nil {
			return nil
		}
		return v.SmoothGradConfig
	}).(GoogleCloudAiplatformV1beta1SmoothGradConfigPtrOutput)
}

// The number of steps for approximating the path integral. A good value to start is 50 and gradually increase until the sum to diff property is within the desired error range. Valid range of its value is [1, 100], inclusively.
func (o GoogleCloudAiplatformV1beta1IntegratedGradientsAttributionPtrOutput) StepCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1IntegratedGradientsAttribution) *int {
		if v == nil {
			return nil
		}
		return &v.StepCount
	}).(pulumi.IntPtrOutput)
}

// An attribution method that computes the Aumann-Shapley value taking advantage of the model's fully differentiable structure. Refer to this paper for more details: https://arxiv.org/abs/1703.01365
type GoogleCloudAiplatformV1beta1IntegratedGradientsAttributionResponse struct {
	// Config for IG with blur baseline. When enabled, a linear path from the maximally blurred image to the input image is created. Using a blurred baseline instead of zero (black image) is motivated by the BlurIG approach explained here: https://arxiv.org/abs/2004.03383
	BlurBaselineConfig GoogleCloudAiplatformV1beta1BlurBaselineConfigResponse `pulumi:"blurBaselineConfig"`
	// Config for SmoothGrad approximation of gradients. When enabled, the gradients are approximated by averaging the gradients from noisy samples in the vicinity of the inputs. Adding noise can help improve the computed gradients. Refer to this paper for more details: https://arxiv.org/pdf/1706.03825.pdf
	SmoothGradConfig GoogleCloudAiplatformV1beta1SmoothGradConfigResponse `pulumi:"smoothGradConfig"`
	// The number of steps for approximating the path integral. A good value to start is 50 and gradually increase until the sum to diff property is within the desired error range. Valid range of its value is [1, 100], inclusively.
	StepCount int `pulumi:"stepCount"`
}

// An attribution method that computes the Aumann-Shapley value taking advantage of the model's fully differentiable structure. Refer to this paper for more details: https://arxiv.org/abs/1703.01365
type GoogleCloudAiplatformV1beta1IntegratedGradientsAttributionResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1IntegratedGradientsAttributionResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1IntegratedGradientsAttributionResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1IntegratedGradientsAttributionResponseOutput) ToGoogleCloudAiplatformV1beta1IntegratedGradientsAttributionResponseOutput() GoogleCloudAiplatformV1beta1IntegratedGradientsAttributionResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1IntegratedGradientsAttributionResponseOutput) ToGoogleCloudAiplatformV1beta1IntegratedGradientsAttributionResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1IntegratedGradientsAttributionResponseOutput {
	return o
}

// Config for IG with blur baseline. When enabled, a linear path from the maximally blurred image to the input image is created. Using a blurred baseline instead of zero (black image) is motivated by the BlurIG approach explained here: https://arxiv.org/abs/2004.03383
func (o GoogleCloudAiplatformV1beta1IntegratedGradientsAttributionResponseOutput) BlurBaselineConfig() GoogleCloudAiplatformV1beta1BlurBaselineConfigResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1IntegratedGradientsAttributionResponse) GoogleCloudAiplatformV1beta1BlurBaselineConfigResponse {
		return v.BlurBaselineConfig
	}).(GoogleCloudAiplatformV1beta1BlurBaselineConfigResponseOutput)
}

// Config for SmoothGrad approximation of gradients. When enabled, the gradients are approximated by averaging the gradients from noisy samples in the vicinity of the inputs. Adding noise can help improve the computed gradients. Refer to this paper for more details: https://arxiv.org/pdf/1706.03825.pdf
func (o GoogleCloudAiplatformV1beta1IntegratedGradientsAttributionResponseOutput) SmoothGradConfig() GoogleCloudAiplatformV1beta1SmoothGradConfigResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1IntegratedGradientsAttributionResponse) GoogleCloudAiplatformV1beta1SmoothGradConfigResponse {
		return v.SmoothGradConfig
	}).(GoogleCloudAiplatformV1beta1SmoothGradConfigResponseOutput)
}

// The number of steps for approximating the path integral. A good value to start is 50 and gradually increase until the sum to diff property is within the desired error range. Valid range of its value is [1, 100], inclusively.
func (o GoogleCloudAiplatformV1beta1IntegratedGradientsAttributionResponseOutput) StepCount() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1IntegratedGradientsAttributionResponse) int { return v.StepCount }).(pulumi.IntOutput)
}

// Specification of a single machine.
type GoogleCloudAiplatformV1beta1MachineSpec struct {
	// The number of accelerators to attach to the machine.
	AcceleratorCount *int `pulumi:"acceleratorCount"`
	// Immutable. The type of accelerator(s) that may be attached to the machine as per accelerator_count.
	AcceleratorType *GoogleCloudAiplatformV1beta1MachineSpecAcceleratorType `pulumi:"acceleratorType"`
	// Immutable. The type of the machine. See the [list of machine types supported for prediction](https://cloud.google.com/vertex-ai/docs/predictions/configure-compute#machine-types) See the [list of machine types supported for custom training](https://cloud.google.com/vertex-ai/docs/training/configure-compute#machine-types). For DeployedModel this field is optional, and the default value is `n1-standard-2`. For BatchPredictionJob or as part of WorkerPoolSpec this field is required.
	MachineType *string `pulumi:"machineType"`
	// Immutable. The topology of the TPUs. Corresponds to the TPU topologies available from GKE. (Example: tpu_topology: "2x2x1").
	TpuTopology *string `pulumi:"tpuTopology"`
}

// GoogleCloudAiplatformV1beta1MachineSpecInput is an input type that accepts GoogleCloudAiplatformV1beta1MachineSpecArgs and GoogleCloudAiplatformV1beta1MachineSpecOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1MachineSpecInput` via:
//
//	GoogleCloudAiplatformV1beta1MachineSpecArgs{...}
type GoogleCloudAiplatformV1beta1MachineSpecInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1MachineSpecOutput() GoogleCloudAiplatformV1beta1MachineSpecOutput
	ToGoogleCloudAiplatformV1beta1MachineSpecOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1MachineSpecOutput
}

// Specification of a single machine.
type GoogleCloudAiplatformV1beta1MachineSpecArgs struct {
	// The number of accelerators to attach to the machine.
	AcceleratorCount pulumi.IntPtrInput `pulumi:"acceleratorCount"`
	// Immutable. The type of accelerator(s) that may be attached to the machine as per accelerator_count.
	AcceleratorType GoogleCloudAiplatformV1beta1MachineSpecAcceleratorTypePtrInput `pulumi:"acceleratorType"`
	// Immutable. The type of the machine. See the [list of machine types supported for prediction](https://cloud.google.com/vertex-ai/docs/predictions/configure-compute#machine-types) See the [list of machine types supported for custom training](https://cloud.google.com/vertex-ai/docs/training/configure-compute#machine-types). For DeployedModel this field is optional, and the default value is `n1-standard-2`. For BatchPredictionJob or as part of WorkerPoolSpec this field is required.
	MachineType pulumi.StringPtrInput `pulumi:"machineType"`
	// Immutable. The topology of the TPUs. Corresponds to the TPU topologies available from GKE. (Example: tpu_topology: "2x2x1").
	TpuTopology pulumi.StringPtrInput `pulumi:"tpuTopology"`
}

func (GoogleCloudAiplatformV1beta1MachineSpecArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1MachineSpec)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1MachineSpecArgs) ToGoogleCloudAiplatformV1beta1MachineSpecOutput() GoogleCloudAiplatformV1beta1MachineSpecOutput {
	return i.ToGoogleCloudAiplatformV1beta1MachineSpecOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1MachineSpecArgs) ToGoogleCloudAiplatformV1beta1MachineSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1MachineSpecOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1MachineSpecOutput)
}

func (i GoogleCloudAiplatformV1beta1MachineSpecArgs) ToGoogleCloudAiplatformV1beta1MachineSpecPtrOutput() GoogleCloudAiplatformV1beta1MachineSpecPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1MachineSpecPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1MachineSpecArgs) ToGoogleCloudAiplatformV1beta1MachineSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1MachineSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1MachineSpecOutput).ToGoogleCloudAiplatformV1beta1MachineSpecPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1MachineSpecPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1MachineSpecArgs, GoogleCloudAiplatformV1beta1MachineSpecPtr and GoogleCloudAiplatformV1beta1MachineSpecPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1MachineSpecPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1MachineSpecArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1MachineSpecPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1MachineSpecPtrOutput() GoogleCloudAiplatformV1beta1MachineSpecPtrOutput
	ToGoogleCloudAiplatformV1beta1MachineSpecPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1MachineSpecPtrOutput
}

type googleCloudAiplatformV1beta1MachineSpecPtrType GoogleCloudAiplatformV1beta1MachineSpecArgs

func GoogleCloudAiplatformV1beta1MachineSpecPtr(v *GoogleCloudAiplatformV1beta1MachineSpecArgs) GoogleCloudAiplatformV1beta1MachineSpecPtrInput {
	return (*googleCloudAiplatformV1beta1MachineSpecPtrType)(v)
}

func (*googleCloudAiplatformV1beta1MachineSpecPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1MachineSpec)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1MachineSpecPtrType) ToGoogleCloudAiplatformV1beta1MachineSpecPtrOutput() GoogleCloudAiplatformV1beta1MachineSpecPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1MachineSpecPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1MachineSpecPtrType) ToGoogleCloudAiplatformV1beta1MachineSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1MachineSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1MachineSpecPtrOutput)
}

// Specification of a single machine.
type GoogleCloudAiplatformV1beta1MachineSpecOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1MachineSpecOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1MachineSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1MachineSpecOutput) ToGoogleCloudAiplatformV1beta1MachineSpecOutput() GoogleCloudAiplatformV1beta1MachineSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1MachineSpecOutput) ToGoogleCloudAiplatformV1beta1MachineSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1MachineSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1MachineSpecOutput) ToGoogleCloudAiplatformV1beta1MachineSpecPtrOutput() GoogleCloudAiplatformV1beta1MachineSpecPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1MachineSpecPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1MachineSpecOutput) ToGoogleCloudAiplatformV1beta1MachineSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1MachineSpecPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1MachineSpec) *GoogleCloudAiplatformV1beta1MachineSpec {
		return &v
	}).(GoogleCloudAiplatformV1beta1MachineSpecPtrOutput)
}

// The number of accelerators to attach to the machine.
func (o GoogleCloudAiplatformV1beta1MachineSpecOutput) AcceleratorCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1MachineSpec) *int { return v.AcceleratorCount }).(pulumi.IntPtrOutput)
}

// Immutable. The type of accelerator(s) that may be attached to the machine as per accelerator_count.
func (o GoogleCloudAiplatformV1beta1MachineSpecOutput) AcceleratorType() GoogleCloudAiplatformV1beta1MachineSpecAcceleratorTypePtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1MachineSpec) *GoogleCloudAiplatformV1beta1MachineSpecAcceleratorType {
		return v.AcceleratorType
	}).(GoogleCloudAiplatformV1beta1MachineSpecAcceleratorTypePtrOutput)
}

// Immutable. The type of the machine. See the [list of machine types supported for prediction](https://cloud.google.com/vertex-ai/docs/predictions/configure-compute#machine-types) See the [list of machine types supported for custom training](https://cloud.google.com/vertex-ai/docs/training/configure-compute#machine-types). For DeployedModel this field is optional, and the default value is `n1-standard-2`. For BatchPredictionJob or as part of WorkerPoolSpec this field is required.
func (o GoogleCloudAiplatformV1beta1MachineSpecOutput) MachineType() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1MachineSpec) *string { return v.MachineType }).(pulumi.StringPtrOutput)
}

// Immutable. The topology of the TPUs. Corresponds to the TPU topologies available from GKE. (Example: tpu_topology: "2x2x1").
func (o GoogleCloudAiplatformV1beta1MachineSpecOutput) TpuTopology() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1MachineSpec) *string { return v.TpuTopology }).(pulumi.StringPtrOutput)
}

type GoogleCloudAiplatformV1beta1MachineSpecPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1MachineSpecPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1MachineSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1MachineSpecPtrOutput) ToGoogleCloudAiplatformV1beta1MachineSpecPtrOutput() GoogleCloudAiplatformV1beta1MachineSpecPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1MachineSpecPtrOutput) ToGoogleCloudAiplatformV1beta1MachineSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1MachineSpecPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1MachineSpecPtrOutput) Elem() GoogleCloudAiplatformV1beta1MachineSpecOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1MachineSpec) GoogleCloudAiplatformV1beta1MachineSpec {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1MachineSpec
		return ret
	}).(GoogleCloudAiplatformV1beta1MachineSpecOutput)
}

// The number of accelerators to attach to the machine.
func (o GoogleCloudAiplatformV1beta1MachineSpecPtrOutput) AcceleratorCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1MachineSpec) *int {
		if v == nil {
			return nil
		}
		return v.AcceleratorCount
	}).(pulumi.IntPtrOutput)
}

// Immutable. The type of accelerator(s) that may be attached to the machine as per accelerator_count.
func (o GoogleCloudAiplatformV1beta1MachineSpecPtrOutput) AcceleratorType() GoogleCloudAiplatformV1beta1MachineSpecAcceleratorTypePtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1MachineSpec) *GoogleCloudAiplatformV1beta1MachineSpecAcceleratorType {
		if v == nil {
			return nil
		}
		return v.AcceleratorType
	}).(GoogleCloudAiplatformV1beta1MachineSpecAcceleratorTypePtrOutput)
}

// Immutable. The type of the machine. See the [list of machine types supported for prediction](https://cloud.google.com/vertex-ai/docs/predictions/configure-compute#machine-types) See the [list of machine types supported for custom training](https://cloud.google.com/vertex-ai/docs/training/configure-compute#machine-types). For DeployedModel this field is optional, and the default value is `n1-standard-2`. For BatchPredictionJob or as part of WorkerPoolSpec this field is required.
func (o GoogleCloudAiplatformV1beta1MachineSpecPtrOutput) MachineType() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1MachineSpec) *string {
		if v == nil {
			return nil
		}
		return v.MachineType
	}).(pulumi.StringPtrOutput)
}

// Immutable. The topology of the TPUs. Corresponds to the TPU topologies available from GKE. (Example: tpu_topology: "2x2x1").
func (o GoogleCloudAiplatformV1beta1MachineSpecPtrOutput) TpuTopology() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1MachineSpec) *string {
		if v == nil {
			return nil
		}
		return v.TpuTopology
	}).(pulumi.StringPtrOutput)
}

// Specification of a single machine.
type GoogleCloudAiplatformV1beta1MachineSpecResponse struct {
	// The number of accelerators to attach to the machine.
	AcceleratorCount int `pulumi:"acceleratorCount"`
	// Immutable. The type of accelerator(s) that may be attached to the machine as per accelerator_count.
	AcceleratorType string `pulumi:"acceleratorType"`
	// Immutable. The type of the machine. See the [list of machine types supported for prediction](https://cloud.google.com/vertex-ai/docs/predictions/configure-compute#machine-types) See the [list of machine types supported for custom training](https://cloud.google.com/vertex-ai/docs/training/configure-compute#machine-types). For DeployedModel this field is optional, and the default value is `n1-standard-2`. For BatchPredictionJob or as part of WorkerPoolSpec this field is required.
	MachineType string `pulumi:"machineType"`
	// Immutable. The topology of the TPUs. Corresponds to the TPU topologies available from GKE. (Example: tpu_topology: "2x2x1").
	TpuTopology string `pulumi:"tpuTopology"`
}

// Specification of a single machine.
type GoogleCloudAiplatformV1beta1MachineSpecResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1MachineSpecResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1MachineSpecResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1MachineSpecResponseOutput) ToGoogleCloudAiplatformV1beta1MachineSpecResponseOutput() GoogleCloudAiplatformV1beta1MachineSpecResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1MachineSpecResponseOutput) ToGoogleCloudAiplatformV1beta1MachineSpecResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1MachineSpecResponseOutput {
	return o
}

// The number of accelerators to attach to the machine.
func (o GoogleCloudAiplatformV1beta1MachineSpecResponseOutput) AcceleratorCount() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1MachineSpecResponse) int { return v.AcceleratorCount }).(pulumi.IntOutput)
}

// Immutable. The type of accelerator(s) that may be attached to the machine as per accelerator_count.
func (o GoogleCloudAiplatformV1beta1MachineSpecResponseOutput) AcceleratorType() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1MachineSpecResponse) string { return v.AcceleratorType }).(pulumi.StringOutput)
}

// Immutable. The type of the machine. See the [list of machine types supported for prediction](https://cloud.google.com/vertex-ai/docs/predictions/configure-compute#machine-types) See the [list of machine types supported for custom training](https://cloud.google.com/vertex-ai/docs/training/configure-compute#machine-types). For DeployedModel this field is optional, and the default value is `n1-standard-2`. For BatchPredictionJob or as part of WorkerPoolSpec this field is required.
func (o GoogleCloudAiplatformV1beta1MachineSpecResponseOutput) MachineType() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1MachineSpecResponse) string { return v.MachineType }).(pulumi.StringOutput)
}

// Immutable. The topology of the TPUs. Corresponds to the TPU topologies available from GKE. (Example: tpu_topology: "2x2x1").
func (o GoogleCloudAiplatformV1beta1MachineSpecResponseOutput) TpuTopology() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1MachineSpecResponse) string { return v.TpuTopology }).(pulumi.StringOutput)
}

// Manual batch tuning parameters.
type GoogleCloudAiplatformV1beta1ManualBatchTuningParameters struct {
	// Immutable. The number of the records (e.g. instances) of the operation given in each batch to a machine replica. Machine type, and size of a single record should be considered when setting this parameter, higher value speeds up the batch operation's execution, but too high value will result in a whole batch not fitting in a machine's memory, and the whole operation will fail. The default value is 64.
	BatchSize *int `pulumi:"batchSize"`
}

// GoogleCloudAiplatformV1beta1ManualBatchTuningParametersInput is an input type that accepts GoogleCloudAiplatformV1beta1ManualBatchTuningParametersArgs and GoogleCloudAiplatformV1beta1ManualBatchTuningParametersOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1ManualBatchTuningParametersInput` via:
//
//	GoogleCloudAiplatformV1beta1ManualBatchTuningParametersArgs{...}
type GoogleCloudAiplatformV1beta1ManualBatchTuningParametersInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1ManualBatchTuningParametersOutput() GoogleCloudAiplatformV1beta1ManualBatchTuningParametersOutput
	ToGoogleCloudAiplatformV1beta1ManualBatchTuningParametersOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1ManualBatchTuningParametersOutput
}

// Manual batch tuning parameters.
type GoogleCloudAiplatformV1beta1ManualBatchTuningParametersArgs struct {
	// Immutable. The number of the records (e.g. instances) of the operation given in each batch to a machine replica. Machine type, and size of a single record should be considered when setting this parameter, higher value speeds up the batch operation's execution, but too high value will result in a whole batch not fitting in a machine's memory, and the whole operation will fail. The default value is 64.
	BatchSize pulumi.IntPtrInput `pulumi:"batchSize"`
}

func (GoogleCloudAiplatformV1beta1ManualBatchTuningParametersArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ManualBatchTuningParameters)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1ManualBatchTuningParametersArgs) ToGoogleCloudAiplatformV1beta1ManualBatchTuningParametersOutput() GoogleCloudAiplatformV1beta1ManualBatchTuningParametersOutput {
	return i.ToGoogleCloudAiplatformV1beta1ManualBatchTuningParametersOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1ManualBatchTuningParametersArgs) ToGoogleCloudAiplatformV1beta1ManualBatchTuningParametersOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ManualBatchTuningParametersOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ManualBatchTuningParametersOutput)
}

func (i GoogleCloudAiplatformV1beta1ManualBatchTuningParametersArgs) ToGoogleCloudAiplatformV1beta1ManualBatchTuningParametersPtrOutput() GoogleCloudAiplatformV1beta1ManualBatchTuningParametersPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1ManualBatchTuningParametersPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1ManualBatchTuningParametersArgs) ToGoogleCloudAiplatformV1beta1ManualBatchTuningParametersPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ManualBatchTuningParametersPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ManualBatchTuningParametersOutput).ToGoogleCloudAiplatformV1beta1ManualBatchTuningParametersPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1ManualBatchTuningParametersPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1ManualBatchTuningParametersArgs, GoogleCloudAiplatformV1beta1ManualBatchTuningParametersPtr and GoogleCloudAiplatformV1beta1ManualBatchTuningParametersPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1ManualBatchTuningParametersPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1ManualBatchTuningParametersArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1ManualBatchTuningParametersPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1ManualBatchTuningParametersPtrOutput() GoogleCloudAiplatformV1beta1ManualBatchTuningParametersPtrOutput
	ToGoogleCloudAiplatformV1beta1ManualBatchTuningParametersPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1ManualBatchTuningParametersPtrOutput
}

type googleCloudAiplatformV1beta1ManualBatchTuningParametersPtrType GoogleCloudAiplatformV1beta1ManualBatchTuningParametersArgs

func GoogleCloudAiplatformV1beta1ManualBatchTuningParametersPtr(v *GoogleCloudAiplatformV1beta1ManualBatchTuningParametersArgs) GoogleCloudAiplatformV1beta1ManualBatchTuningParametersPtrInput {
	return (*googleCloudAiplatformV1beta1ManualBatchTuningParametersPtrType)(v)
}

func (*googleCloudAiplatformV1beta1ManualBatchTuningParametersPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1ManualBatchTuningParameters)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1ManualBatchTuningParametersPtrType) ToGoogleCloudAiplatformV1beta1ManualBatchTuningParametersPtrOutput() GoogleCloudAiplatformV1beta1ManualBatchTuningParametersPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1ManualBatchTuningParametersPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1ManualBatchTuningParametersPtrType) ToGoogleCloudAiplatformV1beta1ManualBatchTuningParametersPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ManualBatchTuningParametersPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ManualBatchTuningParametersPtrOutput)
}

// Manual batch tuning parameters.
type GoogleCloudAiplatformV1beta1ManualBatchTuningParametersOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ManualBatchTuningParametersOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ManualBatchTuningParameters)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ManualBatchTuningParametersOutput) ToGoogleCloudAiplatformV1beta1ManualBatchTuningParametersOutput() GoogleCloudAiplatformV1beta1ManualBatchTuningParametersOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ManualBatchTuningParametersOutput) ToGoogleCloudAiplatformV1beta1ManualBatchTuningParametersOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ManualBatchTuningParametersOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ManualBatchTuningParametersOutput) ToGoogleCloudAiplatformV1beta1ManualBatchTuningParametersPtrOutput() GoogleCloudAiplatformV1beta1ManualBatchTuningParametersPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1ManualBatchTuningParametersPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1ManualBatchTuningParametersOutput) ToGoogleCloudAiplatformV1beta1ManualBatchTuningParametersPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ManualBatchTuningParametersPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1ManualBatchTuningParameters) *GoogleCloudAiplatformV1beta1ManualBatchTuningParameters {
		return &v
	}).(GoogleCloudAiplatformV1beta1ManualBatchTuningParametersPtrOutput)
}

// Immutable. The number of the records (e.g. instances) of the operation given in each batch to a machine replica. Machine type, and size of a single record should be considered when setting this parameter, higher value speeds up the batch operation's execution, but too high value will result in a whole batch not fitting in a machine's memory, and the whole operation will fail. The default value is 64.
func (o GoogleCloudAiplatformV1beta1ManualBatchTuningParametersOutput) BatchSize() pulumi.IntPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ManualBatchTuningParameters) *int { return v.BatchSize }).(pulumi.IntPtrOutput)
}

type GoogleCloudAiplatformV1beta1ManualBatchTuningParametersPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ManualBatchTuningParametersPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1ManualBatchTuningParameters)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ManualBatchTuningParametersPtrOutput) ToGoogleCloudAiplatformV1beta1ManualBatchTuningParametersPtrOutput() GoogleCloudAiplatformV1beta1ManualBatchTuningParametersPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ManualBatchTuningParametersPtrOutput) ToGoogleCloudAiplatformV1beta1ManualBatchTuningParametersPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ManualBatchTuningParametersPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ManualBatchTuningParametersPtrOutput) Elem() GoogleCloudAiplatformV1beta1ManualBatchTuningParametersOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ManualBatchTuningParameters) GoogleCloudAiplatformV1beta1ManualBatchTuningParameters {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1ManualBatchTuningParameters
		return ret
	}).(GoogleCloudAiplatformV1beta1ManualBatchTuningParametersOutput)
}

// Immutable. The number of the records (e.g. instances) of the operation given in each batch to a machine replica. Machine type, and size of a single record should be considered when setting this parameter, higher value speeds up the batch operation's execution, but too high value will result in a whole batch not fitting in a machine's memory, and the whole operation will fail. The default value is 64.
func (o GoogleCloudAiplatformV1beta1ManualBatchTuningParametersPtrOutput) BatchSize() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ManualBatchTuningParameters) *int {
		if v == nil {
			return nil
		}
		return v.BatchSize
	}).(pulumi.IntPtrOutput)
}

// Manual batch tuning parameters.
type GoogleCloudAiplatformV1beta1ManualBatchTuningParametersResponse struct {
	// Immutable. The number of the records (e.g. instances) of the operation given in each batch to a machine replica. Machine type, and size of a single record should be considered when setting this parameter, higher value speeds up the batch operation's execution, but too high value will result in a whole batch not fitting in a machine's memory, and the whole operation will fail. The default value is 64.
	BatchSize int `pulumi:"batchSize"`
}

// Manual batch tuning parameters.
type GoogleCloudAiplatformV1beta1ManualBatchTuningParametersResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ManualBatchTuningParametersResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ManualBatchTuningParametersResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ManualBatchTuningParametersResponseOutput) ToGoogleCloudAiplatformV1beta1ManualBatchTuningParametersResponseOutput() GoogleCloudAiplatformV1beta1ManualBatchTuningParametersResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ManualBatchTuningParametersResponseOutput) ToGoogleCloudAiplatformV1beta1ManualBatchTuningParametersResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ManualBatchTuningParametersResponseOutput {
	return o
}

// Immutable. The number of the records (e.g. instances) of the operation given in each batch to a machine replica. Machine type, and size of a single record should be considered when setting this parameter, higher value speeds up the batch operation's execution, but too high value will result in a whole batch not fitting in a machine's memory, and the whole operation will fail. The default value is 64.
func (o GoogleCloudAiplatformV1beta1ManualBatchTuningParametersResponseOutput) BatchSize() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ManualBatchTuningParametersResponse) int { return v.BatchSize }).(pulumi.IntOutput)
}

// A message representing a metric in the measurement.
type GoogleCloudAiplatformV1beta1MeasurementMetricResponse struct {
	// The ID of the Metric. The Metric should be defined in StudySpec's Metrics.
	MetricId string `pulumi:"metricId"`
	// The value for this metric.
	Value float64 `pulumi:"value"`
}

// A message representing a metric in the measurement.
type GoogleCloudAiplatformV1beta1MeasurementMetricResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1MeasurementMetricResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1MeasurementMetricResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1MeasurementMetricResponseOutput) ToGoogleCloudAiplatformV1beta1MeasurementMetricResponseOutput() GoogleCloudAiplatformV1beta1MeasurementMetricResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1MeasurementMetricResponseOutput) ToGoogleCloudAiplatformV1beta1MeasurementMetricResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1MeasurementMetricResponseOutput {
	return o
}

// The ID of the Metric. The Metric should be defined in StudySpec's Metrics.
func (o GoogleCloudAiplatformV1beta1MeasurementMetricResponseOutput) MetricId() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1MeasurementMetricResponse) string { return v.MetricId }).(pulumi.StringOutput)
}

// The value for this metric.
func (o GoogleCloudAiplatformV1beta1MeasurementMetricResponseOutput) Value() pulumi.Float64Output {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1MeasurementMetricResponse) float64 { return v.Value }).(pulumi.Float64Output)
}

type GoogleCloudAiplatformV1beta1MeasurementMetricResponseArrayOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1MeasurementMetricResponseArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1beta1MeasurementMetricResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1MeasurementMetricResponseArrayOutput) ToGoogleCloudAiplatformV1beta1MeasurementMetricResponseArrayOutput() GoogleCloudAiplatformV1beta1MeasurementMetricResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1MeasurementMetricResponseArrayOutput) ToGoogleCloudAiplatformV1beta1MeasurementMetricResponseArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1MeasurementMetricResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1MeasurementMetricResponseArrayOutput) Index(i pulumi.IntInput) GoogleCloudAiplatformV1beta1MeasurementMetricResponseOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GoogleCloudAiplatformV1beta1MeasurementMetricResponse {
		return vs[0].([]GoogleCloudAiplatformV1beta1MeasurementMetricResponse)[vs[1].(int)]
	}).(GoogleCloudAiplatformV1beta1MeasurementMetricResponseOutput)
}

// A message representing a Measurement of a Trial. A Measurement contains the Metrics got by executing a Trial using suggested hyperparameter values.
type GoogleCloudAiplatformV1beta1MeasurementResponse struct {
	// Time that the Trial has been running at the point of this Measurement.
	ElapsedDuration string `pulumi:"elapsedDuration"`
	// A list of metrics got by evaluating the objective functions using suggested Parameter values.
	Metrics []GoogleCloudAiplatformV1beta1MeasurementMetricResponse `pulumi:"metrics"`
	// The number of steps the machine learning model has been trained for. Must be non-negative.
	StepCount string `pulumi:"stepCount"`
}

// A message representing a Measurement of a Trial. A Measurement contains the Metrics got by executing a Trial using suggested hyperparameter values.
type GoogleCloudAiplatformV1beta1MeasurementResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1MeasurementResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1MeasurementResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1MeasurementResponseOutput) ToGoogleCloudAiplatformV1beta1MeasurementResponseOutput() GoogleCloudAiplatformV1beta1MeasurementResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1MeasurementResponseOutput) ToGoogleCloudAiplatformV1beta1MeasurementResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1MeasurementResponseOutput {
	return o
}

// Time that the Trial has been running at the point of this Measurement.
func (o GoogleCloudAiplatformV1beta1MeasurementResponseOutput) ElapsedDuration() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1MeasurementResponse) string { return v.ElapsedDuration }).(pulumi.StringOutput)
}

// A list of metrics got by evaluating the objective functions using suggested Parameter values.
func (o GoogleCloudAiplatformV1beta1MeasurementResponseOutput) Metrics() GoogleCloudAiplatformV1beta1MeasurementMetricResponseArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1MeasurementResponse) []GoogleCloudAiplatformV1beta1MeasurementMetricResponse {
		return v.Metrics
	}).(GoogleCloudAiplatformV1beta1MeasurementMetricResponseArrayOutput)
}

// The number of steps the machine learning model has been trained for. Must be non-negative.
func (o GoogleCloudAiplatformV1beta1MeasurementResponseOutput) StepCount() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1MeasurementResponse) string { return v.StepCount }).(pulumi.StringOutput)
}

type GoogleCloudAiplatformV1beta1MeasurementResponseArrayOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1MeasurementResponseArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1beta1MeasurementResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1MeasurementResponseArrayOutput) ToGoogleCloudAiplatformV1beta1MeasurementResponseArrayOutput() GoogleCloudAiplatformV1beta1MeasurementResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1MeasurementResponseArrayOutput) ToGoogleCloudAiplatformV1beta1MeasurementResponseArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1MeasurementResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1MeasurementResponseArrayOutput) Index(i pulumi.IntInput) GoogleCloudAiplatformV1beta1MeasurementResponseOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GoogleCloudAiplatformV1beta1MeasurementResponse {
		return vs[0].([]GoogleCloudAiplatformV1beta1MeasurementResponse)[vs[1].(int)]
	}).(GoogleCloudAiplatformV1beta1MeasurementResponseOutput)
}

// Represents state information for a MetadataStore.
type GoogleCloudAiplatformV1beta1MetadataStoreMetadataStoreStateResponse struct {
	// The disk utilization of the MetadataStore in bytes.
	DiskUtilizationBytes string `pulumi:"diskUtilizationBytes"`
}

// Represents state information for a MetadataStore.
type GoogleCloudAiplatformV1beta1MetadataStoreMetadataStoreStateResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1MetadataStoreMetadataStoreStateResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1MetadataStoreMetadataStoreStateResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1MetadataStoreMetadataStoreStateResponseOutput) ToGoogleCloudAiplatformV1beta1MetadataStoreMetadataStoreStateResponseOutput() GoogleCloudAiplatformV1beta1MetadataStoreMetadataStoreStateResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1MetadataStoreMetadataStoreStateResponseOutput) ToGoogleCloudAiplatformV1beta1MetadataStoreMetadataStoreStateResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1MetadataStoreMetadataStoreStateResponseOutput {
	return o
}

// The disk utilization of the MetadataStore in bytes.
func (o GoogleCloudAiplatformV1beta1MetadataStoreMetadataStoreStateResponseOutput) DiskUtilizationBytes() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1MetadataStoreMetadataStoreStateResponse) string {
		return v.DiskUtilizationBytes
	}).(pulumi.StringOutput)
}

// A trained machine learning Model.
type GoogleCloudAiplatformV1beta1Model struct {
	// Immutable. The path to the directory containing the Model artifact and any of its supporting files. Not present for AutoML Models or Large Models.
	ArtifactUri *string `pulumi:"artifactUri"`
	// Input only. The specification of the container that is to be used when deploying this Model. The specification is ingested upon ModelService.UploadModel, and all binaries it contains are copied and stored internally by Vertex AI. Not present for AutoML Models or Large Models.
	ContainerSpec *GoogleCloudAiplatformV1beta1ModelContainerSpec `pulumi:"containerSpec"`
	// The description of the Model.
	Description *string `pulumi:"description"`
	// The display name of the Model. The name can be up to 128 characters long and can consist of any UTF-8 characters.
	DisplayName string `pulumi:"displayName"`
	// Customer-managed encryption key spec for a Model. If set, this Model and all sub-resources of this Model will be secured by this key.
	EncryptionSpec *GoogleCloudAiplatformV1beta1EncryptionSpec `pulumi:"encryptionSpec"`
	// Used to perform consistent read-modify-write updates. If not set, a blind "overwrite" update happens.
	Etag *string `pulumi:"etag"`
	// The default explanation specification for this Model. The Model can be used for requesting explanation after being deployed if it is populated. The Model can be used for batch explanation if it is populated. All fields of the explanation_spec can be overridden by explanation_spec of DeployModelRequest.deployed_model, or explanation_spec of BatchPredictionJob. If the default explanation specification is not set for this Model, this Model can still be used for requesting explanation by setting explanation_spec of DeployModelRequest.deployed_model and for batch explanation by setting explanation_spec of BatchPredictionJob.
	ExplanationSpec *GoogleCloudAiplatformV1beta1ExplanationSpec `pulumi:"explanationSpec"`
	// The labels with user-defined metadata to organize your Models. Label keys and values can be no longer than 64 characters (Unicode codepoints), can only contain lowercase letters, numeric characters, underscores and dashes. International characters are allowed. See https://goo.gl/xmQnxf for more information and examples of labels.
	Labels map[string]string `pulumi:"labels"`
	// Immutable. An additional information about the Model; the schema of the metadata can be found in metadata_schema. Unset if the Model does not have any additional information.
	Metadata interface{} `pulumi:"metadata"`
	// Immutable. Points to a YAML file stored on Google Cloud Storage describing additional information about the Model, that is specific to it. Unset if the Model does not have any additional information. The schema is defined as an OpenAPI 3.0.2 [Schema Object](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject). AutoML Models always have this field populated by Vertex AI, if no additional metadata is needed, this field is set to an empty string. Note: The URI given on output will be immutable and probably different, including the URI scheme, than the one given on input. The output URI will point to a location where the user only has a read access.
	MetadataSchemaUri *string `pulumi:"metadataSchemaUri"`
	// The resource name of the Model.
	Name *string `pulumi:"name"`
	// The schemata that describe formats of the Model's predictions and explanations as given and returned via PredictionService.Predict and PredictionService.Explain.
	PredictSchemata *GoogleCloudAiplatformV1beta1PredictSchemata `pulumi:"predictSchemata"`
	// User provided version aliases so that a model version can be referenced via alias (i.e. `projects/{project}/locations/{location}/models/{model_id}@{version_alias}` instead of auto-generated version id (i.e. `projects/{project}/locations/{location}/models/{model_id}@{version_id})`. The format is a-z{0,126}[a-z0-9] to distinguish from version_id. A default version alias will be created for the first version of the model, and there must be exactly one default version alias for a model.
	VersionAliases []string `pulumi:"versionAliases"`
	// The description of this version.
	VersionDescription *string `pulumi:"versionDescription"`
}

// GoogleCloudAiplatformV1beta1ModelInput is an input type that accepts GoogleCloudAiplatformV1beta1ModelArgs and GoogleCloudAiplatformV1beta1ModelOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1ModelInput` via:
//
//	GoogleCloudAiplatformV1beta1ModelArgs{...}
type GoogleCloudAiplatformV1beta1ModelInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1ModelOutput() GoogleCloudAiplatformV1beta1ModelOutput
	ToGoogleCloudAiplatformV1beta1ModelOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1ModelOutput
}

// A trained machine learning Model.
type GoogleCloudAiplatformV1beta1ModelArgs struct {
	// Immutable. The path to the directory containing the Model artifact and any of its supporting files. Not present for AutoML Models or Large Models.
	ArtifactUri pulumi.StringPtrInput `pulumi:"artifactUri"`
	// Input only. The specification of the container that is to be used when deploying this Model. The specification is ingested upon ModelService.UploadModel, and all binaries it contains are copied and stored internally by Vertex AI. Not present for AutoML Models or Large Models.
	ContainerSpec GoogleCloudAiplatformV1beta1ModelContainerSpecPtrInput `pulumi:"containerSpec"`
	// The description of the Model.
	Description pulumi.StringPtrInput `pulumi:"description"`
	// The display name of the Model. The name can be up to 128 characters long and can consist of any UTF-8 characters.
	DisplayName pulumi.StringInput `pulumi:"displayName"`
	// Customer-managed encryption key spec for a Model. If set, this Model and all sub-resources of this Model will be secured by this key.
	EncryptionSpec GoogleCloudAiplatformV1beta1EncryptionSpecPtrInput `pulumi:"encryptionSpec"`
	// Used to perform consistent read-modify-write updates. If not set, a blind "overwrite" update happens.
	Etag pulumi.StringPtrInput `pulumi:"etag"`
	// The default explanation specification for this Model. The Model can be used for requesting explanation after being deployed if it is populated. The Model can be used for batch explanation if it is populated. All fields of the explanation_spec can be overridden by explanation_spec of DeployModelRequest.deployed_model, or explanation_spec of BatchPredictionJob. If the default explanation specification is not set for this Model, this Model can still be used for requesting explanation by setting explanation_spec of DeployModelRequest.deployed_model and for batch explanation by setting explanation_spec of BatchPredictionJob.
	ExplanationSpec GoogleCloudAiplatformV1beta1ExplanationSpecPtrInput `pulumi:"explanationSpec"`
	// The labels with user-defined metadata to organize your Models. Label keys and values can be no longer than 64 characters (Unicode codepoints), can only contain lowercase letters, numeric characters, underscores and dashes. International characters are allowed. See https://goo.gl/xmQnxf for more information and examples of labels.
	Labels pulumi.StringMapInput `pulumi:"labels"`
	// Immutable. An additional information about the Model; the schema of the metadata can be found in metadata_schema. Unset if the Model does not have any additional information.
	Metadata pulumi.Input `pulumi:"metadata"`
	// Immutable. Points to a YAML file stored on Google Cloud Storage describing additional information about the Model, that is specific to it. Unset if the Model does not have any additional information. The schema is defined as an OpenAPI 3.0.2 [Schema Object](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject). AutoML Models always have this field populated by Vertex AI, if no additional metadata is needed, this field is set to an empty string. Note: The URI given on output will be immutable and probably different, including the URI scheme, than the one given on input. The output URI will point to a location where the user only has a read access.
	MetadataSchemaUri pulumi.StringPtrInput `pulumi:"metadataSchemaUri"`
	// The resource name of the Model.
	Name pulumi.StringPtrInput `pulumi:"name"`
	// The schemata that describe formats of the Model's predictions and explanations as given and returned via PredictionService.Predict and PredictionService.Explain.
	PredictSchemata GoogleCloudAiplatformV1beta1PredictSchemataPtrInput `pulumi:"predictSchemata"`
	// User provided version aliases so that a model version can be referenced via alias (i.e. `projects/{project}/locations/{location}/models/{model_id}@{version_alias}` instead of auto-generated version id (i.e. `projects/{project}/locations/{location}/models/{model_id}@{version_id})`. The format is a-z{0,126}[a-z0-9] to distinguish from version_id. A default version alias will be created for the first version of the model, and there must be exactly one default version alias for a model.
	VersionAliases pulumi.StringArrayInput `pulumi:"versionAliases"`
	// The description of this version.
	VersionDescription pulumi.StringPtrInput `pulumi:"versionDescription"`
}

func (GoogleCloudAiplatformV1beta1ModelArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1Model)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1ModelArgs) ToGoogleCloudAiplatformV1beta1ModelOutput() GoogleCloudAiplatformV1beta1ModelOutput {
	return i.ToGoogleCloudAiplatformV1beta1ModelOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1ModelArgs) ToGoogleCloudAiplatformV1beta1ModelOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ModelOutput)
}

func (i GoogleCloudAiplatformV1beta1ModelArgs) ToGoogleCloudAiplatformV1beta1ModelPtrOutput() GoogleCloudAiplatformV1beta1ModelPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1ModelPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1ModelArgs) ToGoogleCloudAiplatformV1beta1ModelPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ModelOutput).ToGoogleCloudAiplatformV1beta1ModelPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1ModelPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1ModelArgs, GoogleCloudAiplatformV1beta1ModelPtr and GoogleCloudAiplatformV1beta1ModelPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1ModelPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1ModelArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1ModelPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1ModelPtrOutput() GoogleCloudAiplatformV1beta1ModelPtrOutput
	ToGoogleCloudAiplatformV1beta1ModelPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1ModelPtrOutput
}

type googleCloudAiplatformV1beta1ModelPtrType GoogleCloudAiplatformV1beta1ModelArgs

func GoogleCloudAiplatformV1beta1ModelPtr(v *GoogleCloudAiplatformV1beta1ModelArgs) GoogleCloudAiplatformV1beta1ModelPtrInput {
	return (*googleCloudAiplatformV1beta1ModelPtrType)(v)
}

func (*googleCloudAiplatformV1beta1ModelPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1Model)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1ModelPtrType) ToGoogleCloudAiplatformV1beta1ModelPtrOutput() GoogleCloudAiplatformV1beta1ModelPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1ModelPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1ModelPtrType) ToGoogleCloudAiplatformV1beta1ModelPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ModelPtrOutput)
}

// A trained machine learning Model.
type GoogleCloudAiplatformV1beta1ModelOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ModelOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1Model)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ModelOutput) ToGoogleCloudAiplatformV1beta1ModelOutput() GoogleCloudAiplatformV1beta1ModelOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ModelOutput) ToGoogleCloudAiplatformV1beta1ModelOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ModelOutput) ToGoogleCloudAiplatformV1beta1ModelPtrOutput() GoogleCloudAiplatformV1beta1ModelPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1ModelPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1ModelOutput) ToGoogleCloudAiplatformV1beta1ModelPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1Model) *GoogleCloudAiplatformV1beta1Model {
		return &v
	}).(GoogleCloudAiplatformV1beta1ModelPtrOutput)
}

// Immutable. The path to the directory containing the Model artifact and any of its supporting files. Not present for AutoML Models or Large Models.
func (o GoogleCloudAiplatformV1beta1ModelOutput) ArtifactUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1Model) *string { return v.ArtifactUri }).(pulumi.StringPtrOutput)
}

// Input only. The specification of the container that is to be used when deploying this Model. The specification is ingested upon ModelService.UploadModel, and all binaries it contains are copied and stored internally by Vertex AI. Not present for AutoML Models or Large Models.
func (o GoogleCloudAiplatformV1beta1ModelOutput) ContainerSpec() GoogleCloudAiplatformV1beta1ModelContainerSpecPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1Model) *GoogleCloudAiplatformV1beta1ModelContainerSpec {
		return v.ContainerSpec
	}).(GoogleCloudAiplatformV1beta1ModelContainerSpecPtrOutput)
}

// The description of the Model.
func (o GoogleCloudAiplatformV1beta1ModelOutput) Description() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1Model) *string { return v.Description }).(pulumi.StringPtrOutput)
}

// The display name of the Model. The name can be up to 128 characters long and can consist of any UTF-8 characters.
func (o GoogleCloudAiplatformV1beta1ModelOutput) DisplayName() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1Model) string { return v.DisplayName }).(pulumi.StringOutput)
}

// Customer-managed encryption key spec for a Model. If set, this Model and all sub-resources of this Model will be secured by this key.
func (o GoogleCloudAiplatformV1beta1ModelOutput) EncryptionSpec() GoogleCloudAiplatformV1beta1EncryptionSpecPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1Model) *GoogleCloudAiplatformV1beta1EncryptionSpec {
		return v.EncryptionSpec
	}).(GoogleCloudAiplatformV1beta1EncryptionSpecPtrOutput)
}

// Used to perform consistent read-modify-write updates. If not set, a blind "overwrite" update happens.
func (o GoogleCloudAiplatformV1beta1ModelOutput) Etag() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1Model) *string { return v.Etag }).(pulumi.StringPtrOutput)
}

// The default explanation specification for this Model. The Model can be used for requesting explanation after being deployed if it is populated. The Model can be used for batch explanation if it is populated. All fields of the explanation_spec can be overridden by explanation_spec of DeployModelRequest.deployed_model, or explanation_spec of BatchPredictionJob. If the default explanation specification is not set for this Model, this Model can still be used for requesting explanation by setting explanation_spec of DeployModelRequest.deployed_model and for batch explanation by setting explanation_spec of BatchPredictionJob.
func (o GoogleCloudAiplatformV1beta1ModelOutput) ExplanationSpec() GoogleCloudAiplatformV1beta1ExplanationSpecPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1Model) *GoogleCloudAiplatformV1beta1ExplanationSpec {
		return v.ExplanationSpec
	}).(GoogleCloudAiplatformV1beta1ExplanationSpecPtrOutput)
}

// The labels with user-defined metadata to organize your Models. Label keys and values can be no longer than 64 characters (Unicode codepoints), can only contain lowercase letters, numeric characters, underscores and dashes. International characters are allowed. See https://goo.gl/xmQnxf for more information and examples of labels.
func (o GoogleCloudAiplatformV1beta1ModelOutput) Labels() pulumi.StringMapOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1Model) map[string]string { return v.Labels }).(pulumi.StringMapOutput)
}

// Immutable. An additional information about the Model; the schema of the metadata can be found in metadata_schema. Unset if the Model does not have any additional information.
func (o GoogleCloudAiplatformV1beta1ModelOutput) Metadata() pulumi.AnyOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1Model) interface{} { return v.Metadata }).(pulumi.AnyOutput)
}

// Immutable. Points to a YAML file stored on Google Cloud Storage describing additional information about the Model, that is specific to it. Unset if the Model does not have any additional information. The schema is defined as an OpenAPI 3.0.2 [Schema Object](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject). AutoML Models always have this field populated by Vertex AI, if no additional metadata is needed, this field is set to an empty string. Note: The URI given on output will be immutable and probably different, including the URI scheme, than the one given on input. The output URI will point to a location where the user only has a read access.
func (o GoogleCloudAiplatformV1beta1ModelOutput) MetadataSchemaUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1Model) *string { return v.MetadataSchemaUri }).(pulumi.StringPtrOutput)
}

// The resource name of the Model.
func (o GoogleCloudAiplatformV1beta1ModelOutput) Name() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1Model) *string { return v.Name }).(pulumi.StringPtrOutput)
}

// The schemata that describe formats of the Model's predictions and explanations as given and returned via PredictionService.Predict and PredictionService.Explain.
func (o GoogleCloudAiplatformV1beta1ModelOutput) PredictSchemata() GoogleCloudAiplatformV1beta1PredictSchemataPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1Model) *GoogleCloudAiplatformV1beta1PredictSchemata {
		return v.PredictSchemata
	}).(GoogleCloudAiplatformV1beta1PredictSchemataPtrOutput)
}

// User provided version aliases so that a model version can be referenced via alias (i.e. `projects/{project}/locations/{location}/models/{model_id}@{version_alias}` instead of auto-generated version id (i.e. `projects/{project}/locations/{location}/models/{model_id}@{version_id})`. The format is a-z{0,126}[a-z0-9] to distinguish from version_id. A default version alias will be created for the first version of the model, and there must be exactly one default version alias for a model.
func (o GoogleCloudAiplatformV1beta1ModelOutput) VersionAliases() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1Model) []string { return v.VersionAliases }).(pulumi.StringArrayOutput)
}

// The description of this version.
func (o GoogleCloudAiplatformV1beta1ModelOutput) VersionDescription() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1Model) *string { return v.VersionDescription }).(pulumi.StringPtrOutput)
}

type GoogleCloudAiplatformV1beta1ModelPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ModelPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1Model)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ModelPtrOutput) ToGoogleCloudAiplatformV1beta1ModelPtrOutput() GoogleCloudAiplatformV1beta1ModelPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ModelPtrOutput) ToGoogleCloudAiplatformV1beta1ModelPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ModelPtrOutput) Elem() GoogleCloudAiplatformV1beta1ModelOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1Model) GoogleCloudAiplatformV1beta1Model {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1Model
		return ret
	}).(GoogleCloudAiplatformV1beta1ModelOutput)
}

// Immutable. The path to the directory containing the Model artifact and any of its supporting files. Not present for AutoML Models or Large Models.
func (o GoogleCloudAiplatformV1beta1ModelPtrOutput) ArtifactUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1Model) *string {
		if v == nil {
			return nil
		}
		return v.ArtifactUri
	}).(pulumi.StringPtrOutput)
}

// Input only. The specification of the container that is to be used when deploying this Model. The specification is ingested upon ModelService.UploadModel, and all binaries it contains are copied and stored internally by Vertex AI. Not present for AutoML Models or Large Models.
func (o GoogleCloudAiplatformV1beta1ModelPtrOutput) ContainerSpec() GoogleCloudAiplatformV1beta1ModelContainerSpecPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1Model) *GoogleCloudAiplatformV1beta1ModelContainerSpec {
		if v == nil {
			return nil
		}
		return v.ContainerSpec
	}).(GoogleCloudAiplatformV1beta1ModelContainerSpecPtrOutput)
}

// The description of the Model.
func (o GoogleCloudAiplatformV1beta1ModelPtrOutput) Description() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1Model) *string {
		if v == nil {
			return nil
		}
		return v.Description
	}).(pulumi.StringPtrOutput)
}

// The display name of the Model. The name can be up to 128 characters long and can consist of any UTF-8 characters.
func (o GoogleCloudAiplatformV1beta1ModelPtrOutput) DisplayName() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1Model) *string {
		if v == nil {
			return nil
		}
		return &v.DisplayName
	}).(pulumi.StringPtrOutput)
}

// Customer-managed encryption key spec for a Model. If set, this Model and all sub-resources of this Model will be secured by this key.
func (o GoogleCloudAiplatformV1beta1ModelPtrOutput) EncryptionSpec() GoogleCloudAiplatformV1beta1EncryptionSpecPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1Model) *GoogleCloudAiplatformV1beta1EncryptionSpec {
		if v == nil {
			return nil
		}
		return v.EncryptionSpec
	}).(GoogleCloudAiplatformV1beta1EncryptionSpecPtrOutput)
}

// Used to perform consistent read-modify-write updates. If not set, a blind "overwrite" update happens.
func (o GoogleCloudAiplatformV1beta1ModelPtrOutput) Etag() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1Model) *string {
		if v == nil {
			return nil
		}
		return v.Etag
	}).(pulumi.StringPtrOutput)
}

// The default explanation specification for this Model. The Model can be used for requesting explanation after being deployed if it is populated. The Model can be used for batch explanation if it is populated. All fields of the explanation_spec can be overridden by explanation_spec of DeployModelRequest.deployed_model, or explanation_spec of BatchPredictionJob. If the default explanation specification is not set for this Model, this Model can still be used for requesting explanation by setting explanation_spec of DeployModelRequest.deployed_model and for batch explanation by setting explanation_spec of BatchPredictionJob.
func (o GoogleCloudAiplatformV1beta1ModelPtrOutput) ExplanationSpec() GoogleCloudAiplatformV1beta1ExplanationSpecPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1Model) *GoogleCloudAiplatformV1beta1ExplanationSpec {
		if v == nil {
			return nil
		}
		return v.ExplanationSpec
	}).(GoogleCloudAiplatformV1beta1ExplanationSpecPtrOutput)
}

// The labels with user-defined metadata to organize your Models. Label keys and values can be no longer than 64 characters (Unicode codepoints), can only contain lowercase letters, numeric characters, underscores and dashes. International characters are allowed. See https://goo.gl/xmQnxf for more information and examples of labels.
func (o GoogleCloudAiplatformV1beta1ModelPtrOutput) Labels() pulumi.StringMapOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1Model) map[string]string {
		if v == nil {
			return nil
		}
		return v.Labels
	}).(pulumi.StringMapOutput)
}

// Immutable. An additional information about the Model; the schema of the metadata can be found in metadata_schema. Unset if the Model does not have any additional information.
func (o GoogleCloudAiplatformV1beta1ModelPtrOutput) Metadata() pulumi.AnyOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1Model) interface{} {
		if v == nil {
			return nil
		}
		return v.Metadata
	}).(pulumi.AnyOutput)
}

// Immutable. Points to a YAML file stored on Google Cloud Storage describing additional information about the Model, that is specific to it. Unset if the Model does not have any additional information. The schema is defined as an OpenAPI 3.0.2 [Schema Object](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject). AutoML Models always have this field populated by Vertex AI, if no additional metadata is needed, this field is set to an empty string. Note: The URI given on output will be immutable and probably different, including the URI scheme, than the one given on input. The output URI will point to a location where the user only has a read access.
func (o GoogleCloudAiplatformV1beta1ModelPtrOutput) MetadataSchemaUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1Model) *string {
		if v == nil {
			return nil
		}
		return v.MetadataSchemaUri
	}).(pulumi.StringPtrOutput)
}

// The resource name of the Model.
func (o GoogleCloudAiplatformV1beta1ModelPtrOutput) Name() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1Model) *string {
		if v == nil {
			return nil
		}
		return v.Name
	}).(pulumi.StringPtrOutput)
}

// The schemata that describe formats of the Model's predictions and explanations as given and returned via PredictionService.Predict and PredictionService.Explain.
func (o GoogleCloudAiplatformV1beta1ModelPtrOutput) PredictSchemata() GoogleCloudAiplatformV1beta1PredictSchemataPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1Model) *GoogleCloudAiplatformV1beta1PredictSchemata {
		if v == nil {
			return nil
		}
		return v.PredictSchemata
	}).(GoogleCloudAiplatformV1beta1PredictSchemataPtrOutput)
}

// User provided version aliases so that a model version can be referenced via alias (i.e. `projects/{project}/locations/{location}/models/{model_id}@{version_alias}` instead of auto-generated version id (i.e. `projects/{project}/locations/{location}/models/{model_id}@{version_id})`. The format is a-z{0,126}[a-z0-9] to distinguish from version_id. A default version alias will be created for the first version of the model, and there must be exactly one default version alias for a model.
func (o GoogleCloudAiplatformV1beta1ModelPtrOutput) VersionAliases() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1Model) []string {
		if v == nil {
			return nil
		}
		return v.VersionAliases
	}).(pulumi.StringArrayOutput)
}

// The description of this version.
func (o GoogleCloudAiplatformV1beta1ModelPtrOutput) VersionDescription() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1Model) *string {
		if v == nil {
			return nil
		}
		return v.VersionDescription
	}).(pulumi.StringPtrOutput)
}

// Specification of a container for serving predictions. Some fields in this message correspond to fields in the [Kubernetes Container v1 core specification](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
type GoogleCloudAiplatformV1beta1ModelContainerSpec struct {
	// Immutable. Specifies arguments for the command that runs when the container starts. This overrides the container's [`CMD`](https://docs.docker.com/engine/reference/builder/#cmd). Specify this field as an array of executable and arguments, similar to a Docker `CMD`'s "default parameters" form. If you don't specify this field but do specify the command field, then the command from the `command` field runs without any additional arguments. See the [Kubernetes documentation about how the `command` and `args` fields interact with a container's `ENTRYPOINT` and `CMD`](https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#notes). If you don't specify this field and don't specify the `command` field, then the container's [`ENTRYPOINT`](https://docs.docker.com/engine/reference/builder/#cmd) and `CMD` determine what runs based on their default behavior. See the Docker documentation about [how `CMD` and `ENTRYPOINT` interact](https://docs.docker.com/engine/reference/builder/#understand-how-cmd-and-entrypoint-interact). In this field, you can reference [environment variables set by Vertex AI](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables) and environment variables set in the env field. You cannot reference environment variables set in the Docker image. In order for environment variables to be expanded, reference them by using the following syntax: $( VARIABLE_NAME) Note that this differs from Bash variable expansion, which does not use parentheses. If a variable cannot be resolved, the reference in the input string is used unchanged. To avoid variable expansion, you can escape this syntax with `$$`; for example: $$(VARIABLE_NAME) This field corresponds to the `args` field of the Kubernetes Containers [v1 core API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
	Args []string `pulumi:"args"`
	// Immutable. Specifies the command that runs when the container starts. This overrides the container's [ENTRYPOINT](https://docs.docker.com/engine/reference/builder/#entrypoint). Specify this field as an array of executable and arguments, similar to a Docker `ENTRYPOINT`'s "exec" form, not its "shell" form. If you do not specify this field, then the container's `ENTRYPOINT` runs, in conjunction with the args field or the container's [`CMD`](https://docs.docker.com/engine/reference/builder/#cmd), if either exists. If this field is not specified and the container does not have an `ENTRYPOINT`, then refer to the Docker documentation about [how `CMD` and `ENTRYPOINT` interact](https://docs.docker.com/engine/reference/builder/#understand-how-cmd-and-entrypoint-interact). If you specify this field, then you can also specify the `args` field to provide additional arguments for this command. However, if you specify this field, then the container's `CMD` is ignored. See the [Kubernetes documentation about how the `command` and `args` fields interact with a container's `ENTRYPOINT` and `CMD`](https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#notes). In this field, you can reference [environment variables set by Vertex AI](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables) and environment variables set in the env field. You cannot reference environment variables set in the Docker image. In order for environment variables to be expanded, reference them by using the following syntax: $( VARIABLE_NAME) Note that this differs from Bash variable expansion, which does not use parentheses. If a variable cannot be resolved, the reference in the input string is used unchanged. To avoid variable expansion, you can escape this syntax with `$$`; for example: $$(VARIABLE_NAME) This field corresponds to the `command` field of the Kubernetes Containers [v1 core API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
	Command []string `pulumi:"command"`
	// Immutable. Deployment timeout. TODO (b/306244185): Revise documentation before exposing.
	DeploymentTimeout *string `pulumi:"deploymentTimeout"`
	// Immutable. List of environment variables to set in the container. After the container starts running, code running in the container can read these environment variables. Additionally, the command and args fields can reference these variables. Later entries in this list can also reference earlier entries. For example, the following example sets the variable `VAR_2` to have the value `foo bar`: ``` json [ { "name": "VAR_1", "value": "foo" }, { "name": "VAR_2", "value": "$(VAR_1) bar" } ]  ``` If you switch the order of the variables in the example, then the expansion does not occur. This field corresponds to the `env` field of the Kubernetes Containers [v1 core API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
	Env []GoogleCloudAiplatformV1beta1EnvVar `pulumi:"env"`
	// Immutable. Specification for Kubernetes readiness probe. TODO (b/306244185): Revise documentation before exposing.
	HealthProbe *GoogleCloudAiplatformV1beta1Probe `pulumi:"healthProbe"`
	// Immutable. HTTP path on the container to send health checks to. Vertex AI intermittently sends GET requests to this path on the container's IP address and port to check that the container is healthy. Read more about [health checks](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#health). For example, if you set this field to `/bar`, then Vertex AI intermittently sends a GET request to the `/bar` path on the port of your container specified by the first value of this `ModelContainerSpec`'s ports field. If you don't specify this field, it defaults to the following value when you deploy this Model to an Endpoint: /v1/endpoints/ENDPOINT/deployedModels/ DEPLOYED_MODEL:predict The placeholders in this value are replaced as follows: * ENDPOINT: The last segment (following `endpoints/`)of the Endpoint.name][] field of the Endpoint where this Model has been deployed. (Vertex AI makes this value available to your container code as the [`AIP_ENDPOINT_ID` environment variable](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables).) * DEPLOYED_MODEL: DeployedModel.id of the `DeployedModel`. (Vertex AI makes this value available to your container code as the [`AIP_DEPLOYED_MODEL_ID` environment variable](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables).)
	HealthRoute *string `pulumi:"healthRoute"`
	// Immutable. URI of the Docker image to be used as the custom container for serving predictions. This URI must identify an image in Artifact Registry or Container Registry. Learn more about the [container publishing requirements](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#publishing), including permissions requirements for the Vertex AI Service Agent. The container image is ingested upon ModelService.UploadModel, stored internally, and this original path is afterwards not used. To learn about the requirements for the Docker image itself, see [Custom container requirements](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#). You can use the URI to one of Vertex AI's [pre-built container images for prediction](https://cloud.google.com/vertex-ai/docs/predictions/pre-built-containers) in this field.
	ImageUri string `pulumi:"imageUri"`
	// Immutable. List of ports to expose from the container. Vertex AI sends any prediction requests that it receives to the first port on this list. Vertex AI also sends [liveness and health checks](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#liveness) to this port. If you do not specify this field, it defaults to following value: ``` json [ { "containerPort": 8080 } ]  ``` Vertex AI does not use ports other than the first one listed. This field corresponds to the `ports` field of the Kubernetes Containers [v1 core API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
	Ports []GoogleCloudAiplatformV1beta1Port `pulumi:"ports"`
	// Immutable. HTTP path on the container to send prediction requests to. Vertex AI forwards requests sent using projects.locations.endpoints.predict to this path on the container's IP address and port. Vertex AI then returns the container's response in the API response. For example, if you set this field to `/foo`, then when Vertex AI receives a prediction request, it forwards the request body in a POST request to the `/foo` path on the port of your container specified by the first value of this `ModelContainerSpec`'s ports field. If you don't specify this field, it defaults to the following value when you deploy this Model to an Endpoint: /v1/endpoints/ENDPOINT/deployedModels/DEPLOYED_MODEL:predict The placeholders in this value are replaced as follows: * ENDPOINT: The last segment (following `endpoints/`)of the Endpoint.name][] field of the Endpoint where this Model has been deployed. (Vertex AI makes this value available to your container code as the [`AIP_ENDPOINT_ID` environment variable](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables).) * DEPLOYED_MODEL: DeployedModel.id of the `DeployedModel`. (Vertex AI makes this value available to your container code as the [`AIP_DEPLOYED_MODEL_ID` environment variable](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables).)
	PredictRoute *string `pulumi:"predictRoute"`
	// Immutable. The amount of the VM memory to reserve as the shared memory for the model in megabytes. TODO (b/306244185): Revise documentation before exposing.
	SharedMemorySizeMb *string `pulumi:"sharedMemorySizeMb"`
	// Immutable. Specification for Kubernetes startup probe. TODO (b/306244185): Revise documentation before exposing.
	StartupProbe *GoogleCloudAiplatformV1beta1Probe `pulumi:"startupProbe"`
}

// GoogleCloudAiplatformV1beta1ModelContainerSpecInput is an input type that accepts GoogleCloudAiplatformV1beta1ModelContainerSpecArgs and GoogleCloudAiplatformV1beta1ModelContainerSpecOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1ModelContainerSpecInput` via:
//
//	GoogleCloudAiplatformV1beta1ModelContainerSpecArgs{...}
type GoogleCloudAiplatformV1beta1ModelContainerSpecInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1ModelContainerSpecOutput() GoogleCloudAiplatformV1beta1ModelContainerSpecOutput
	ToGoogleCloudAiplatformV1beta1ModelContainerSpecOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1ModelContainerSpecOutput
}

// Specification of a container for serving predictions. Some fields in this message correspond to fields in the [Kubernetes Container v1 core specification](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
type GoogleCloudAiplatformV1beta1ModelContainerSpecArgs struct {
	// Immutable. Specifies arguments for the command that runs when the container starts. This overrides the container's [`CMD`](https://docs.docker.com/engine/reference/builder/#cmd). Specify this field as an array of executable and arguments, similar to a Docker `CMD`'s "default parameters" form. If you don't specify this field but do specify the command field, then the command from the `command` field runs without any additional arguments. See the [Kubernetes documentation about how the `command` and `args` fields interact with a container's `ENTRYPOINT` and `CMD`](https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#notes). If you don't specify this field and don't specify the `command` field, then the container's [`ENTRYPOINT`](https://docs.docker.com/engine/reference/builder/#cmd) and `CMD` determine what runs based on their default behavior. See the Docker documentation about [how `CMD` and `ENTRYPOINT` interact](https://docs.docker.com/engine/reference/builder/#understand-how-cmd-and-entrypoint-interact). In this field, you can reference [environment variables set by Vertex AI](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables) and environment variables set in the env field. You cannot reference environment variables set in the Docker image. In order for environment variables to be expanded, reference them by using the following syntax: $( VARIABLE_NAME) Note that this differs from Bash variable expansion, which does not use parentheses. If a variable cannot be resolved, the reference in the input string is used unchanged. To avoid variable expansion, you can escape this syntax with `$$`; for example: $$(VARIABLE_NAME) This field corresponds to the `args` field of the Kubernetes Containers [v1 core API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
	Args pulumi.StringArrayInput `pulumi:"args"`
	// Immutable. Specifies the command that runs when the container starts. This overrides the container's [ENTRYPOINT](https://docs.docker.com/engine/reference/builder/#entrypoint). Specify this field as an array of executable and arguments, similar to a Docker `ENTRYPOINT`'s "exec" form, not its "shell" form. If you do not specify this field, then the container's `ENTRYPOINT` runs, in conjunction with the args field or the container's [`CMD`](https://docs.docker.com/engine/reference/builder/#cmd), if either exists. If this field is not specified and the container does not have an `ENTRYPOINT`, then refer to the Docker documentation about [how `CMD` and `ENTRYPOINT` interact](https://docs.docker.com/engine/reference/builder/#understand-how-cmd-and-entrypoint-interact). If you specify this field, then you can also specify the `args` field to provide additional arguments for this command. However, if you specify this field, then the container's `CMD` is ignored. See the [Kubernetes documentation about how the `command` and `args` fields interact with a container's `ENTRYPOINT` and `CMD`](https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#notes). In this field, you can reference [environment variables set by Vertex AI](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables) and environment variables set in the env field. You cannot reference environment variables set in the Docker image. In order for environment variables to be expanded, reference them by using the following syntax: $( VARIABLE_NAME) Note that this differs from Bash variable expansion, which does not use parentheses. If a variable cannot be resolved, the reference in the input string is used unchanged. To avoid variable expansion, you can escape this syntax with `$$`; for example: $$(VARIABLE_NAME) This field corresponds to the `command` field of the Kubernetes Containers [v1 core API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
	Command pulumi.StringArrayInput `pulumi:"command"`
	// Immutable. Deployment timeout. TODO (b/306244185): Revise documentation before exposing.
	DeploymentTimeout pulumi.StringPtrInput `pulumi:"deploymentTimeout"`
	// Immutable. List of environment variables to set in the container. After the container starts running, code running in the container can read these environment variables. Additionally, the command and args fields can reference these variables. Later entries in this list can also reference earlier entries. For example, the following example sets the variable `VAR_2` to have the value `foo bar`: ``` json [ { "name": "VAR_1", "value": "foo" }, { "name": "VAR_2", "value": "$(VAR_1) bar" } ]  ``` If you switch the order of the variables in the example, then the expansion does not occur. This field corresponds to the `env` field of the Kubernetes Containers [v1 core API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
	Env GoogleCloudAiplatformV1beta1EnvVarArrayInput `pulumi:"env"`
	// Immutable. Specification for Kubernetes readiness probe. TODO (b/306244185): Revise documentation before exposing.
	HealthProbe GoogleCloudAiplatformV1beta1ProbePtrInput `pulumi:"healthProbe"`
	// Immutable. HTTP path on the container to send health checks to. Vertex AI intermittently sends GET requests to this path on the container's IP address and port to check that the container is healthy. Read more about [health checks](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#health). For example, if you set this field to `/bar`, then Vertex AI intermittently sends a GET request to the `/bar` path on the port of your container specified by the first value of this `ModelContainerSpec`'s ports field. If you don't specify this field, it defaults to the following value when you deploy this Model to an Endpoint: /v1/endpoints/ENDPOINT/deployedModels/ DEPLOYED_MODEL:predict The placeholders in this value are replaced as follows: * ENDPOINT: The last segment (following `endpoints/`)of the Endpoint.name][] field of the Endpoint where this Model has been deployed. (Vertex AI makes this value available to your container code as the [`AIP_ENDPOINT_ID` environment variable](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables).) * DEPLOYED_MODEL: DeployedModel.id of the `DeployedModel`. (Vertex AI makes this value available to your container code as the [`AIP_DEPLOYED_MODEL_ID` environment variable](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables).)
	HealthRoute pulumi.StringPtrInput `pulumi:"healthRoute"`
	// Immutable. URI of the Docker image to be used as the custom container for serving predictions. This URI must identify an image in Artifact Registry or Container Registry. Learn more about the [container publishing requirements](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#publishing), including permissions requirements for the Vertex AI Service Agent. The container image is ingested upon ModelService.UploadModel, stored internally, and this original path is afterwards not used. To learn about the requirements for the Docker image itself, see [Custom container requirements](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#). You can use the URI to one of Vertex AI's [pre-built container images for prediction](https://cloud.google.com/vertex-ai/docs/predictions/pre-built-containers) in this field.
	ImageUri pulumi.StringInput `pulumi:"imageUri"`
	// Immutable. List of ports to expose from the container. Vertex AI sends any prediction requests that it receives to the first port on this list. Vertex AI also sends [liveness and health checks](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#liveness) to this port. If you do not specify this field, it defaults to following value: ``` json [ { "containerPort": 8080 } ]  ``` Vertex AI does not use ports other than the first one listed. This field corresponds to the `ports` field of the Kubernetes Containers [v1 core API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
	Ports GoogleCloudAiplatformV1beta1PortArrayInput `pulumi:"ports"`
	// Immutable. HTTP path on the container to send prediction requests to. Vertex AI forwards requests sent using projects.locations.endpoints.predict to this path on the container's IP address and port. Vertex AI then returns the container's response in the API response. For example, if you set this field to `/foo`, then when Vertex AI receives a prediction request, it forwards the request body in a POST request to the `/foo` path on the port of your container specified by the first value of this `ModelContainerSpec`'s ports field. If you don't specify this field, it defaults to the following value when you deploy this Model to an Endpoint: /v1/endpoints/ENDPOINT/deployedModels/DEPLOYED_MODEL:predict The placeholders in this value are replaced as follows: * ENDPOINT: The last segment (following `endpoints/`)of the Endpoint.name][] field of the Endpoint where this Model has been deployed. (Vertex AI makes this value available to your container code as the [`AIP_ENDPOINT_ID` environment variable](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables).) * DEPLOYED_MODEL: DeployedModel.id of the `DeployedModel`. (Vertex AI makes this value available to your container code as the [`AIP_DEPLOYED_MODEL_ID` environment variable](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables).)
	PredictRoute pulumi.StringPtrInput `pulumi:"predictRoute"`
	// Immutable. The amount of the VM memory to reserve as the shared memory for the model in megabytes. TODO (b/306244185): Revise documentation before exposing.
	SharedMemorySizeMb pulumi.StringPtrInput `pulumi:"sharedMemorySizeMb"`
	// Immutable. Specification for Kubernetes startup probe. TODO (b/306244185): Revise documentation before exposing.
	StartupProbe GoogleCloudAiplatformV1beta1ProbePtrInput `pulumi:"startupProbe"`
}

func (GoogleCloudAiplatformV1beta1ModelContainerSpecArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ModelContainerSpec)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1ModelContainerSpecArgs) ToGoogleCloudAiplatformV1beta1ModelContainerSpecOutput() GoogleCloudAiplatformV1beta1ModelContainerSpecOutput {
	return i.ToGoogleCloudAiplatformV1beta1ModelContainerSpecOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1ModelContainerSpecArgs) ToGoogleCloudAiplatformV1beta1ModelContainerSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelContainerSpecOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ModelContainerSpecOutput)
}

func (i GoogleCloudAiplatformV1beta1ModelContainerSpecArgs) ToGoogleCloudAiplatformV1beta1ModelContainerSpecPtrOutput() GoogleCloudAiplatformV1beta1ModelContainerSpecPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1ModelContainerSpecPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1ModelContainerSpecArgs) ToGoogleCloudAiplatformV1beta1ModelContainerSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelContainerSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ModelContainerSpecOutput).ToGoogleCloudAiplatformV1beta1ModelContainerSpecPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1ModelContainerSpecPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1ModelContainerSpecArgs, GoogleCloudAiplatformV1beta1ModelContainerSpecPtr and GoogleCloudAiplatformV1beta1ModelContainerSpecPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1ModelContainerSpecPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1ModelContainerSpecArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1ModelContainerSpecPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1ModelContainerSpecPtrOutput() GoogleCloudAiplatformV1beta1ModelContainerSpecPtrOutput
	ToGoogleCloudAiplatformV1beta1ModelContainerSpecPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1ModelContainerSpecPtrOutput
}

type googleCloudAiplatformV1beta1ModelContainerSpecPtrType GoogleCloudAiplatformV1beta1ModelContainerSpecArgs

func GoogleCloudAiplatformV1beta1ModelContainerSpecPtr(v *GoogleCloudAiplatformV1beta1ModelContainerSpecArgs) GoogleCloudAiplatformV1beta1ModelContainerSpecPtrInput {
	return (*googleCloudAiplatformV1beta1ModelContainerSpecPtrType)(v)
}

func (*googleCloudAiplatformV1beta1ModelContainerSpecPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1ModelContainerSpec)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1ModelContainerSpecPtrType) ToGoogleCloudAiplatformV1beta1ModelContainerSpecPtrOutput() GoogleCloudAiplatformV1beta1ModelContainerSpecPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1ModelContainerSpecPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1ModelContainerSpecPtrType) ToGoogleCloudAiplatformV1beta1ModelContainerSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelContainerSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ModelContainerSpecPtrOutput)
}

// Specification of a container for serving predictions. Some fields in this message correspond to fields in the [Kubernetes Container v1 core specification](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
type GoogleCloudAiplatformV1beta1ModelContainerSpecOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ModelContainerSpecOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ModelContainerSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ModelContainerSpecOutput) ToGoogleCloudAiplatformV1beta1ModelContainerSpecOutput() GoogleCloudAiplatformV1beta1ModelContainerSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ModelContainerSpecOutput) ToGoogleCloudAiplatformV1beta1ModelContainerSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelContainerSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ModelContainerSpecOutput) ToGoogleCloudAiplatformV1beta1ModelContainerSpecPtrOutput() GoogleCloudAiplatformV1beta1ModelContainerSpecPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1ModelContainerSpecPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1ModelContainerSpecOutput) ToGoogleCloudAiplatformV1beta1ModelContainerSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelContainerSpecPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1ModelContainerSpec) *GoogleCloudAiplatformV1beta1ModelContainerSpec {
		return &v
	}).(GoogleCloudAiplatformV1beta1ModelContainerSpecPtrOutput)
}

// Immutable. Specifies arguments for the command that runs when the container starts. This overrides the container's [`CMD`](https://docs.docker.com/engine/reference/builder/#cmd). Specify this field as an array of executable and arguments, similar to a Docker `CMD`'s "default parameters" form. If you don't specify this field but do specify the command field, then the command from the `command` field runs without any additional arguments. See the [Kubernetes documentation about how the `command` and `args` fields interact with a container's `ENTRYPOINT` and `CMD`](https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#notes). If you don't specify this field and don't specify the `command` field, then the container's [`ENTRYPOINT`](https://docs.docker.com/engine/reference/builder/#cmd) and `CMD` determine what runs based on their default behavior. See the Docker documentation about [how `CMD` and `ENTRYPOINT` interact](https://docs.docker.com/engine/reference/builder/#understand-how-cmd-and-entrypoint-interact). In this field, you can reference [environment variables set by Vertex AI](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables) and environment variables set in the env field. You cannot reference environment variables set in the Docker image. In order for environment variables to be expanded, reference them by using the following syntax: $( VARIABLE_NAME) Note that this differs from Bash variable expansion, which does not use parentheses. If a variable cannot be resolved, the reference in the input string is used unchanged. To avoid variable expansion, you can escape this syntax with `$$`; for example: $$(VARIABLE_NAME) This field corresponds to the `args` field of the Kubernetes Containers [v1 core API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
func (o GoogleCloudAiplatformV1beta1ModelContainerSpecOutput) Args() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelContainerSpec) []string { return v.Args }).(pulumi.StringArrayOutput)
}

// Immutable. Specifies the command that runs when the container starts. This overrides the container's [ENTRYPOINT](https://docs.docker.com/engine/reference/builder/#entrypoint). Specify this field as an array of executable and arguments, similar to a Docker `ENTRYPOINT`'s "exec" form, not its "shell" form. If you do not specify this field, then the container's `ENTRYPOINT` runs, in conjunction with the args field or the container's [`CMD`](https://docs.docker.com/engine/reference/builder/#cmd), if either exists. If this field is not specified and the container does not have an `ENTRYPOINT`, then refer to the Docker documentation about [how `CMD` and `ENTRYPOINT` interact](https://docs.docker.com/engine/reference/builder/#understand-how-cmd-and-entrypoint-interact). If you specify this field, then you can also specify the `args` field to provide additional arguments for this command. However, if you specify this field, then the container's `CMD` is ignored. See the [Kubernetes documentation about how the `command` and `args` fields interact with a container's `ENTRYPOINT` and `CMD`](https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#notes). In this field, you can reference [environment variables set by Vertex AI](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables) and environment variables set in the env field. You cannot reference environment variables set in the Docker image. In order for environment variables to be expanded, reference them by using the following syntax: $( VARIABLE_NAME) Note that this differs from Bash variable expansion, which does not use parentheses. If a variable cannot be resolved, the reference in the input string is used unchanged. To avoid variable expansion, you can escape this syntax with `$$`; for example: $$(VARIABLE_NAME) This field corresponds to the `command` field of the Kubernetes Containers [v1 core API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
func (o GoogleCloudAiplatformV1beta1ModelContainerSpecOutput) Command() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelContainerSpec) []string { return v.Command }).(pulumi.StringArrayOutput)
}

// Immutable. Deployment timeout. TODO (b/306244185): Revise documentation before exposing.
func (o GoogleCloudAiplatformV1beta1ModelContainerSpecOutput) DeploymentTimeout() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelContainerSpec) *string { return v.DeploymentTimeout }).(pulumi.StringPtrOutput)
}

// Immutable. List of environment variables to set in the container. After the container starts running, code running in the container can read these environment variables. Additionally, the command and args fields can reference these variables. Later entries in this list can also reference earlier entries. For example, the following example sets the variable `VAR_2` to have the value `foo bar`: ``` json [ { "name": "VAR_1", "value": "foo" }, { "name": "VAR_2", "value": "$(VAR_1) bar" } ]  ``` If you switch the order of the variables in the example, then the expansion does not occur. This field corresponds to the `env` field of the Kubernetes Containers [v1 core API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
func (o GoogleCloudAiplatformV1beta1ModelContainerSpecOutput) Env() GoogleCloudAiplatformV1beta1EnvVarArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelContainerSpec) []GoogleCloudAiplatformV1beta1EnvVar {
		return v.Env
	}).(GoogleCloudAiplatformV1beta1EnvVarArrayOutput)
}

// Immutable. Specification for Kubernetes readiness probe. TODO (b/306244185): Revise documentation before exposing.
func (o GoogleCloudAiplatformV1beta1ModelContainerSpecOutput) HealthProbe() GoogleCloudAiplatformV1beta1ProbePtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelContainerSpec) *GoogleCloudAiplatformV1beta1Probe {
		return v.HealthProbe
	}).(GoogleCloudAiplatformV1beta1ProbePtrOutput)
}

// Immutable. HTTP path on the container to send health checks to. Vertex AI intermittently sends GET requests to this path on the container's IP address and port to check that the container is healthy. Read more about [health checks](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#health). For example, if you set this field to `/bar`, then Vertex AI intermittently sends a GET request to the `/bar` path on the port of your container specified by the first value of this `ModelContainerSpec`'s ports field. If you don't specify this field, it defaults to the following value when you deploy this Model to an Endpoint: /v1/endpoints/ENDPOINT/deployedModels/ DEPLOYED_MODEL:predict The placeholders in this value are replaced as follows: * ENDPOINT: The last segment (following `endpoints/`)of the Endpoint.name][] field of the Endpoint where this Model has been deployed. (Vertex AI makes this value available to your container code as the [`AIP_ENDPOINT_ID` environment variable](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables).) * DEPLOYED_MODEL: DeployedModel.id of the `DeployedModel`. (Vertex AI makes this value available to your container code as the [`AIP_DEPLOYED_MODEL_ID` environment variable](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables).)
func (o GoogleCloudAiplatformV1beta1ModelContainerSpecOutput) HealthRoute() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelContainerSpec) *string { return v.HealthRoute }).(pulumi.StringPtrOutput)
}

// Immutable. URI of the Docker image to be used as the custom container for serving predictions. This URI must identify an image in Artifact Registry or Container Registry. Learn more about the [container publishing requirements](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#publishing), including permissions requirements for the Vertex AI Service Agent. The container image is ingested upon ModelService.UploadModel, stored internally, and this original path is afterwards not used. To learn about the requirements for the Docker image itself, see [Custom container requirements](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#). You can use the URI to one of Vertex AI's [pre-built container images for prediction](https://cloud.google.com/vertex-ai/docs/predictions/pre-built-containers) in this field.
func (o GoogleCloudAiplatformV1beta1ModelContainerSpecOutput) ImageUri() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelContainerSpec) string { return v.ImageUri }).(pulumi.StringOutput)
}

// Immutable. List of ports to expose from the container. Vertex AI sends any prediction requests that it receives to the first port on this list. Vertex AI also sends [liveness and health checks](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#liveness) to this port. If you do not specify this field, it defaults to following value: ``` json [ { "containerPort": 8080 } ]  ``` Vertex AI does not use ports other than the first one listed. This field corresponds to the `ports` field of the Kubernetes Containers [v1 core API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
func (o GoogleCloudAiplatformV1beta1ModelContainerSpecOutput) Ports() GoogleCloudAiplatformV1beta1PortArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelContainerSpec) []GoogleCloudAiplatformV1beta1Port {
		return v.Ports
	}).(GoogleCloudAiplatformV1beta1PortArrayOutput)
}

// Immutable. HTTP path on the container to send prediction requests to. Vertex AI forwards requests sent using projects.locations.endpoints.predict to this path on the container's IP address and port. Vertex AI then returns the container's response in the API response. For example, if you set this field to `/foo`, then when Vertex AI receives a prediction request, it forwards the request body in a POST request to the `/foo` path on the port of your container specified by the first value of this `ModelContainerSpec`'s ports field. If you don't specify this field, it defaults to the following value when you deploy this Model to an Endpoint: /v1/endpoints/ENDPOINT/deployedModels/DEPLOYED_MODEL:predict The placeholders in this value are replaced as follows: * ENDPOINT: The last segment (following `endpoints/`)of the Endpoint.name][] field of the Endpoint where this Model has been deployed. (Vertex AI makes this value available to your container code as the [`AIP_ENDPOINT_ID` environment variable](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables).) * DEPLOYED_MODEL: DeployedModel.id of the `DeployedModel`. (Vertex AI makes this value available to your container code as the [`AIP_DEPLOYED_MODEL_ID` environment variable](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables).)
func (o GoogleCloudAiplatformV1beta1ModelContainerSpecOutput) PredictRoute() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelContainerSpec) *string { return v.PredictRoute }).(pulumi.StringPtrOutput)
}

// Immutable. The amount of the VM memory to reserve as the shared memory for the model in megabytes. TODO (b/306244185): Revise documentation before exposing.
func (o GoogleCloudAiplatformV1beta1ModelContainerSpecOutput) SharedMemorySizeMb() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelContainerSpec) *string { return v.SharedMemorySizeMb }).(pulumi.StringPtrOutput)
}

// Immutable. Specification for Kubernetes startup probe. TODO (b/306244185): Revise documentation before exposing.
func (o GoogleCloudAiplatformV1beta1ModelContainerSpecOutput) StartupProbe() GoogleCloudAiplatformV1beta1ProbePtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelContainerSpec) *GoogleCloudAiplatformV1beta1Probe {
		return v.StartupProbe
	}).(GoogleCloudAiplatformV1beta1ProbePtrOutput)
}

type GoogleCloudAiplatformV1beta1ModelContainerSpecPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ModelContainerSpecPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1ModelContainerSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ModelContainerSpecPtrOutput) ToGoogleCloudAiplatformV1beta1ModelContainerSpecPtrOutput() GoogleCloudAiplatformV1beta1ModelContainerSpecPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ModelContainerSpecPtrOutput) ToGoogleCloudAiplatformV1beta1ModelContainerSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelContainerSpecPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ModelContainerSpecPtrOutput) Elem() GoogleCloudAiplatformV1beta1ModelContainerSpecOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ModelContainerSpec) GoogleCloudAiplatformV1beta1ModelContainerSpec {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1ModelContainerSpec
		return ret
	}).(GoogleCloudAiplatformV1beta1ModelContainerSpecOutput)
}

// Immutable. Specifies arguments for the command that runs when the container starts. This overrides the container's [`CMD`](https://docs.docker.com/engine/reference/builder/#cmd). Specify this field as an array of executable and arguments, similar to a Docker `CMD`'s "default parameters" form. If you don't specify this field but do specify the command field, then the command from the `command` field runs without any additional arguments. See the [Kubernetes documentation about how the `command` and `args` fields interact with a container's `ENTRYPOINT` and `CMD`](https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#notes). If you don't specify this field and don't specify the `command` field, then the container's [`ENTRYPOINT`](https://docs.docker.com/engine/reference/builder/#cmd) and `CMD` determine what runs based on their default behavior. See the Docker documentation about [how `CMD` and `ENTRYPOINT` interact](https://docs.docker.com/engine/reference/builder/#understand-how-cmd-and-entrypoint-interact). In this field, you can reference [environment variables set by Vertex AI](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables) and environment variables set in the env field. You cannot reference environment variables set in the Docker image. In order for environment variables to be expanded, reference them by using the following syntax: $( VARIABLE_NAME) Note that this differs from Bash variable expansion, which does not use parentheses. If a variable cannot be resolved, the reference in the input string is used unchanged. To avoid variable expansion, you can escape this syntax with `$$`; for example: $$(VARIABLE_NAME) This field corresponds to the `args` field of the Kubernetes Containers [v1 core API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
func (o GoogleCloudAiplatformV1beta1ModelContainerSpecPtrOutput) Args() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ModelContainerSpec) []string {
		if v == nil {
			return nil
		}
		return v.Args
	}).(pulumi.StringArrayOutput)
}

// Immutable. Specifies the command that runs when the container starts. This overrides the container's [ENTRYPOINT](https://docs.docker.com/engine/reference/builder/#entrypoint). Specify this field as an array of executable and arguments, similar to a Docker `ENTRYPOINT`'s "exec" form, not its "shell" form. If you do not specify this field, then the container's `ENTRYPOINT` runs, in conjunction with the args field or the container's [`CMD`](https://docs.docker.com/engine/reference/builder/#cmd), if either exists. If this field is not specified and the container does not have an `ENTRYPOINT`, then refer to the Docker documentation about [how `CMD` and `ENTRYPOINT` interact](https://docs.docker.com/engine/reference/builder/#understand-how-cmd-and-entrypoint-interact). If you specify this field, then you can also specify the `args` field to provide additional arguments for this command. However, if you specify this field, then the container's `CMD` is ignored. See the [Kubernetes documentation about how the `command` and `args` fields interact with a container's `ENTRYPOINT` and `CMD`](https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#notes). In this field, you can reference [environment variables set by Vertex AI](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables) and environment variables set in the env field. You cannot reference environment variables set in the Docker image. In order for environment variables to be expanded, reference them by using the following syntax: $( VARIABLE_NAME) Note that this differs from Bash variable expansion, which does not use parentheses. If a variable cannot be resolved, the reference in the input string is used unchanged. To avoid variable expansion, you can escape this syntax with `$$`; for example: $$(VARIABLE_NAME) This field corresponds to the `command` field of the Kubernetes Containers [v1 core API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
func (o GoogleCloudAiplatformV1beta1ModelContainerSpecPtrOutput) Command() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ModelContainerSpec) []string {
		if v == nil {
			return nil
		}
		return v.Command
	}).(pulumi.StringArrayOutput)
}

// Immutable. Deployment timeout. TODO (b/306244185): Revise documentation before exposing.
func (o GoogleCloudAiplatformV1beta1ModelContainerSpecPtrOutput) DeploymentTimeout() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ModelContainerSpec) *string {
		if v == nil {
			return nil
		}
		return v.DeploymentTimeout
	}).(pulumi.StringPtrOutput)
}

// Immutable. List of environment variables to set in the container. After the container starts running, code running in the container can read these environment variables. Additionally, the command and args fields can reference these variables. Later entries in this list can also reference earlier entries. For example, the following example sets the variable `VAR_2` to have the value `foo bar`: ``` json [ { "name": "VAR_1", "value": "foo" }, { "name": "VAR_2", "value": "$(VAR_1) bar" } ]  ``` If you switch the order of the variables in the example, then the expansion does not occur. This field corresponds to the `env` field of the Kubernetes Containers [v1 core API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
func (o GoogleCloudAiplatformV1beta1ModelContainerSpecPtrOutput) Env() GoogleCloudAiplatformV1beta1EnvVarArrayOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ModelContainerSpec) []GoogleCloudAiplatformV1beta1EnvVar {
		if v == nil {
			return nil
		}
		return v.Env
	}).(GoogleCloudAiplatformV1beta1EnvVarArrayOutput)
}

// Immutable. Specification for Kubernetes readiness probe. TODO (b/306244185): Revise documentation before exposing.
func (o GoogleCloudAiplatformV1beta1ModelContainerSpecPtrOutput) HealthProbe() GoogleCloudAiplatformV1beta1ProbePtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ModelContainerSpec) *GoogleCloudAiplatformV1beta1Probe {
		if v == nil {
			return nil
		}
		return v.HealthProbe
	}).(GoogleCloudAiplatformV1beta1ProbePtrOutput)
}

// Immutable. HTTP path on the container to send health checks to. Vertex AI intermittently sends GET requests to this path on the container's IP address and port to check that the container is healthy. Read more about [health checks](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#health). For example, if you set this field to `/bar`, then Vertex AI intermittently sends a GET request to the `/bar` path on the port of your container specified by the first value of this `ModelContainerSpec`'s ports field. If you don't specify this field, it defaults to the following value when you deploy this Model to an Endpoint: /v1/endpoints/ENDPOINT/deployedModels/ DEPLOYED_MODEL:predict The placeholders in this value are replaced as follows: * ENDPOINT: The last segment (following `endpoints/`)of the Endpoint.name][] field of the Endpoint where this Model has been deployed. (Vertex AI makes this value available to your container code as the [`AIP_ENDPOINT_ID` environment variable](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables).) * DEPLOYED_MODEL: DeployedModel.id of the `DeployedModel`. (Vertex AI makes this value available to your container code as the [`AIP_DEPLOYED_MODEL_ID` environment variable](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables).)
func (o GoogleCloudAiplatformV1beta1ModelContainerSpecPtrOutput) HealthRoute() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ModelContainerSpec) *string {
		if v == nil {
			return nil
		}
		return v.HealthRoute
	}).(pulumi.StringPtrOutput)
}

// Immutable. URI of the Docker image to be used as the custom container for serving predictions. This URI must identify an image in Artifact Registry or Container Registry. Learn more about the [container publishing requirements](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#publishing), including permissions requirements for the Vertex AI Service Agent. The container image is ingested upon ModelService.UploadModel, stored internally, and this original path is afterwards not used. To learn about the requirements for the Docker image itself, see [Custom container requirements](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#). You can use the URI to one of Vertex AI's [pre-built container images for prediction](https://cloud.google.com/vertex-ai/docs/predictions/pre-built-containers) in this field.
func (o GoogleCloudAiplatformV1beta1ModelContainerSpecPtrOutput) ImageUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ModelContainerSpec) *string {
		if v == nil {
			return nil
		}
		return &v.ImageUri
	}).(pulumi.StringPtrOutput)
}

// Immutable. List of ports to expose from the container. Vertex AI sends any prediction requests that it receives to the first port on this list. Vertex AI also sends [liveness and health checks](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#liveness) to this port. If you do not specify this field, it defaults to following value: ``` json [ { "containerPort": 8080 } ]  ``` Vertex AI does not use ports other than the first one listed. This field corresponds to the `ports` field of the Kubernetes Containers [v1 core API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
func (o GoogleCloudAiplatformV1beta1ModelContainerSpecPtrOutput) Ports() GoogleCloudAiplatformV1beta1PortArrayOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ModelContainerSpec) []GoogleCloudAiplatformV1beta1Port {
		if v == nil {
			return nil
		}
		return v.Ports
	}).(GoogleCloudAiplatformV1beta1PortArrayOutput)
}

// Immutable. HTTP path on the container to send prediction requests to. Vertex AI forwards requests sent using projects.locations.endpoints.predict to this path on the container's IP address and port. Vertex AI then returns the container's response in the API response. For example, if you set this field to `/foo`, then when Vertex AI receives a prediction request, it forwards the request body in a POST request to the `/foo` path on the port of your container specified by the first value of this `ModelContainerSpec`'s ports field. If you don't specify this field, it defaults to the following value when you deploy this Model to an Endpoint: /v1/endpoints/ENDPOINT/deployedModels/DEPLOYED_MODEL:predict The placeholders in this value are replaced as follows: * ENDPOINT: The last segment (following `endpoints/`)of the Endpoint.name][] field of the Endpoint where this Model has been deployed. (Vertex AI makes this value available to your container code as the [`AIP_ENDPOINT_ID` environment variable](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables).) * DEPLOYED_MODEL: DeployedModel.id of the `DeployedModel`. (Vertex AI makes this value available to your container code as the [`AIP_DEPLOYED_MODEL_ID` environment variable](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables).)
func (o GoogleCloudAiplatformV1beta1ModelContainerSpecPtrOutput) PredictRoute() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ModelContainerSpec) *string {
		if v == nil {
			return nil
		}
		return v.PredictRoute
	}).(pulumi.StringPtrOutput)
}

// Immutable. The amount of the VM memory to reserve as the shared memory for the model in megabytes. TODO (b/306244185): Revise documentation before exposing.
func (o GoogleCloudAiplatformV1beta1ModelContainerSpecPtrOutput) SharedMemorySizeMb() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ModelContainerSpec) *string {
		if v == nil {
			return nil
		}
		return v.SharedMemorySizeMb
	}).(pulumi.StringPtrOutput)
}

// Immutable. Specification for Kubernetes startup probe. TODO (b/306244185): Revise documentation before exposing.
func (o GoogleCloudAiplatformV1beta1ModelContainerSpecPtrOutput) StartupProbe() GoogleCloudAiplatformV1beta1ProbePtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ModelContainerSpec) *GoogleCloudAiplatformV1beta1Probe {
		if v == nil {
			return nil
		}
		return v.StartupProbe
	}).(GoogleCloudAiplatformV1beta1ProbePtrOutput)
}

// Specification of a container for serving predictions. Some fields in this message correspond to fields in the [Kubernetes Container v1 core specification](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
type GoogleCloudAiplatformV1beta1ModelContainerSpecResponse struct {
	// Immutable. Specifies arguments for the command that runs when the container starts. This overrides the container's [`CMD`](https://docs.docker.com/engine/reference/builder/#cmd). Specify this field as an array of executable and arguments, similar to a Docker `CMD`'s "default parameters" form. If you don't specify this field but do specify the command field, then the command from the `command` field runs without any additional arguments. See the [Kubernetes documentation about how the `command` and `args` fields interact with a container's `ENTRYPOINT` and `CMD`](https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#notes). If you don't specify this field and don't specify the `command` field, then the container's [`ENTRYPOINT`](https://docs.docker.com/engine/reference/builder/#cmd) and `CMD` determine what runs based on their default behavior. See the Docker documentation about [how `CMD` and `ENTRYPOINT` interact](https://docs.docker.com/engine/reference/builder/#understand-how-cmd-and-entrypoint-interact). In this field, you can reference [environment variables set by Vertex AI](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables) and environment variables set in the env field. You cannot reference environment variables set in the Docker image. In order for environment variables to be expanded, reference them by using the following syntax: $( VARIABLE_NAME) Note that this differs from Bash variable expansion, which does not use parentheses. If a variable cannot be resolved, the reference in the input string is used unchanged. To avoid variable expansion, you can escape this syntax with `$$`; for example: $$(VARIABLE_NAME) This field corresponds to the `args` field of the Kubernetes Containers [v1 core API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
	Args []string `pulumi:"args"`
	// Immutable. Specifies the command that runs when the container starts. This overrides the container's [ENTRYPOINT](https://docs.docker.com/engine/reference/builder/#entrypoint). Specify this field as an array of executable and arguments, similar to a Docker `ENTRYPOINT`'s "exec" form, not its "shell" form. If you do not specify this field, then the container's `ENTRYPOINT` runs, in conjunction with the args field or the container's [`CMD`](https://docs.docker.com/engine/reference/builder/#cmd), if either exists. If this field is not specified and the container does not have an `ENTRYPOINT`, then refer to the Docker documentation about [how `CMD` and `ENTRYPOINT` interact](https://docs.docker.com/engine/reference/builder/#understand-how-cmd-and-entrypoint-interact). If you specify this field, then you can also specify the `args` field to provide additional arguments for this command. However, if you specify this field, then the container's `CMD` is ignored. See the [Kubernetes documentation about how the `command` and `args` fields interact with a container's `ENTRYPOINT` and `CMD`](https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#notes). In this field, you can reference [environment variables set by Vertex AI](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables) and environment variables set in the env field. You cannot reference environment variables set in the Docker image. In order for environment variables to be expanded, reference them by using the following syntax: $( VARIABLE_NAME) Note that this differs from Bash variable expansion, which does not use parentheses. If a variable cannot be resolved, the reference in the input string is used unchanged. To avoid variable expansion, you can escape this syntax with `$$`; for example: $$(VARIABLE_NAME) This field corresponds to the `command` field of the Kubernetes Containers [v1 core API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
	Command []string `pulumi:"command"`
	// Immutable. Deployment timeout. TODO (b/306244185): Revise documentation before exposing.
	DeploymentTimeout string `pulumi:"deploymentTimeout"`
	// Immutable. List of environment variables to set in the container. After the container starts running, code running in the container can read these environment variables. Additionally, the command and args fields can reference these variables. Later entries in this list can also reference earlier entries. For example, the following example sets the variable `VAR_2` to have the value `foo bar`: ``` json [ { "name": "VAR_1", "value": "foo" }, { "name": "VAR_2", "value": "$(VAR_1) bar" } ]  ``` If you switch the order of the variables in the example, then the expansion does not occur. This field corresponds to the `env` field of the Kubernetes Containers [v1 core API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
	Env []GoogleCloudAiplatformV1beta1EnvVarResponse `pulumi:"env"`
	// Immutable. Specification for Kubernetes readiness probe. TODO (b/306244185): Revise documentation before exposing.
	HealthProbe GoogleCloudAiplatformV1beta1ProbeResponse `pulumi:"healthProbe"`
	// Immutable. HTTP path on the container to send health checks to. Vertex AI intermittently sends GET requests to this path on the container's IP address and port to check that the container is healthy. Read more about [health checks](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#health). For example, if you set this field to `/bar`, then Vertex AI intermittently sends a GET request to the `/bar` path on the port of your container specified by the first value of this `ModelContainerSpec`'s ports field. If you don't specify this field, it defaults to the following value when you deploy this Model to an Endpoint: /v1/endpoints/ENDPOINT/deployedModels/ DEPLOYED_MODEL:predict The placeholders in this value are replaced as follows: * ENDPOINT: The last segment (following `endpoints/`)of the Endpoint.name][] field of the Endpoint where this Model has been deployed. (Vertex AI makes this value available to your container code as the [`AIP_ENDPOINT_ID` environment variable](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables).) * DEPLOYED_MODEL: DeployedModel.id of the `DeployedModel`. (Vertex AI makes this value available to your container code as the [`AIP_DEPLOYED_MODEL_ID` environment variable](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables).)
	HealthRoute string `pulumi:"healthRoute"`
	// Immutable. URI of the Docker image to be used as the custom container for serving predictions. This URI must identify an image in Artifact Registry or Container Registry. Learn more about the [container publishing requirements](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#publishing), including permissions requirements for the Vertex AI Service Agent. The container image is ingested upon ModelService.UploadModel, stored internally, and this original path is afterwards not used. To learn about the requirements for the Docker image itself, see [Custom container requirements](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#). You can use the URI to one of Vertex AI's [pre-built container images for prediction](https://cloud.google.com/vertex-ai/docs/predictions/pre-built-containers) in this field.
	ImageUri string `pulumi:"imageUri"`
	// Immutable. List of ports to expose from the container. Vertex AI sends any prediction requests that it receives to the first port on this list. Vertex AI also sends [liveness and health checks](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#liveness) to this port. If you do not specify this field, it defaults to following value: ``` json [ { "containerPort": 8080 } ]  ``` Vertex AI does not use ports other than the first one listed. This field corresponds to the `ports` field of the Kubernetes Containers [v1 core API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
	Ports []GoogleCloudAiplatformV1beta1PortResponse `pulumi:"ports"`
	// Immutable. HTTP path on the container to send prediction requests to. Vertex AI forwards requests sent using projects.locations.endpoints.predict to this path on the container's IP address and port. Vertex AI then returns the container's response in the API response. For example, if you set this field to `/foo`, then when Vertex AI receives a prediction request, it forwards the request body in a POST request to the `/foo` path on the port of your container specified by the first value of this `ModelContainerSpec`'s ports field. If you don't specify this field, it defaults to the following value when you deploy this Model to an Endpoint: /v1/endpoints/ENDPOINT/deployedModels/DEPLOYED_MODEL:predict The placeholders in this value are replaced as follows: * ENDPOINT: The last segment (following `endpoints/`)of the Endpoint.name][] field of the Endpoint where this Model has been deployed. (Vertex AI makes this value available to your container code as the [`AIP_ENDPOINT_ID` environment variable](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables).) * DEPLOYED_MODEL: DeployedModel.id of the `DeployedModel`. (Vertex AI makes this value available to your container code as the [`AIP_DEPLOYED_MODEL_ID` environment variable](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables).)
	PredictRoute string `pulumi:"predictRoute"`
	// Immutable. The amount of the VM memory to reserve as the shared memory for the model in megabytes. TODO (b/306244185): Revise documentation before exposing.
	SharedMemorySizeMb string `pulumi:"sharedMemorySizeMb"`
	// Immutable. Specification for Kubernetes startup probe. TODO (b/306244185): Revise documentation before exposing.
	StartupProbe GoogleCloudAiplatformV1beta1ProbeResponse `pulumi:"startupProbe"`
}

// Specification of a container for serving predictions. Some fields in this message correspond to fields in the [Kubernetes Container v1 core specification](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
type GoogleCloudAiplatformV1beta1ModelContainerSpecResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ModelContainerSpecResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ModelContainerSpecResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ModelContainerSpecResponseOutput) ToGoogleCloudAiplatformV1beta1ModelContainerSpecResponseOutput() GoogleCloudAiplatformV1beta1ModelContainerSpecResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ModelContainerSpecResponseOutput) ToGoogleCloudAiplatformV1beta1ModelContainerSpecResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelContainerSpecResponseOutput {
	return o
}

// Immutable. Specifies arguments for the command that runs when the container starts. This overrides the container's [`CMD`](https://docs.docker.com/engine/reference/builder/#cmd). Specify this field as an array of executable and arguments, similar to a Docker `CMD`'s "default parameters" form. If you don't specify this field but do specify the command field, then the command from the `command` field runs without any additional arguments. See the [Kubernetes documentation about how the `command` and `args` fields interact with a container's `ENTRYPOINT` and `CMD`](https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#notes). If you don't specify this field and don't specify the `command` field, then the container's [`ENTRYPOINT`](https://docs.docker.com/engine/reference/builder/#cmd) and `CMD` determine what runs based on their default behavior. See the Docker documentation about [how `CMD` and `ENTRYPOINT` interact](https://docs.docker.com/engine/reference/builder/#understand-how-cmd-and-entrypoint-interact). In this field, you can reference [environment variables set by Vertex AI](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables) and environment variables set in the env field. You cannot reference environment variables set in the Docker image. In order for environment variables to be expanded, reference them by using the following syntax: $( VARIABLE_NAME) Note that this differs from Bash variable expansion, which does not use parentheses. If a variable cannot be resolved, the reference in the input string is used unchanged. To avoid variable expansion, you can escape this syntax with `$$`; for example: $$(VARIABLE_NAME) This field corresponds to the `args` field of the Kubernetes Containers [v1 core API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
func (o GoogleCloudAiplatformV1beta1ModelContainerSpecResponseOutput) Args() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelContainerSpecResponse) []string { return v.Args }).(pulumi.StringArrayOutput)
}

// Immutable. Specifies the command that runs when the container starts. This overrides the container's [ENTRYPOINT](https://docs.docker.com/engine/reference/builder/#entrypoint). Specify this field as an array of executable and arguments, similar to a Docker `ENTRYPOINT`'s "exec" form, not its "shell" form. If you do not specify this field, then the container's `ENTRYPOINT` runs, in conjunction with the args field or the container's [`CMD`](https://docs.docker.com/engine/reference/builder/#cmd), if either exists. If this field is not specified and the container does not have an `ENTRYPOINT`, then refer to the Docker documentation about [how `CMD` and `ENTRYPOINT` interact](https://docs.docker.com/engine/reference/builder/#understand-how-cmd-and-entrypoint-interact). If you specify this field, then you can also specify the `args` field to provide additional arguments for this command. However, if you specify this field, then the container's `CMD` is ignored. See the [Kubernetes documentation about how the `command` and `args` fields interact with a container's `ENTRYPOINT` and `CMD`](https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#notes). In this field, you can reference [environment variables set by Vertex AI](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables) and environment variables set in the env field. You cannot reference environment variables set in the Docker image. In order for environment variables to be expanded, reference them by using the following syntax: $( VARIABLE_NAME) Note that this differs from Bash variable expansion, which does not use parentheses. If a variable cannot be resolved, the reference in the input string is used unchanged. To avoid variable expansion, you can escape this syntax with `$$`; for example: $$(VARIABLE_NAME) This field corresponds to the `command` field of the Kubernetes Containers [v1 core API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
func (o GoogleCloudAiplatformV1beta1ModelContainerSpecResponseOutput) Command() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelContainerSpecResponse) []string { return v.Command }).(pulumi.StringArrayOutput)
}

// Immutable. Deployment timeout. TODO (b/306244185): Revise documentation before exposing.
func (o GoogleCloudAiplatformV1beta1ModelContainerSpecResponseOutput) DeploymentTimeout() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelContainerSpecResponse) string { return v.DeploymentTimeout }).(pulumi.StringOutput)
}

// Immutable. List of environment variables to set in the container. After the container starts running, code running in the container can read these environment variables. Additionally, the command and args fields can reference these variables. Later entries in this list can also reference earlier entries. For example, the following example sets the variable `VAR_2` to have the value `foo bar`: ``` json [ { "name": "VAR_1", "value": "foo" }, { "name": "VAR_2", "value": "$(VAR_1) bar" } ]  ``` If you switch the order of the variables in the example, then the expansion does not occur. This field corresponds to the `env` field of the Kubernetes Containers [v1 core API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
func (o GoogleCloudAiplatformV1beta1ModelContainerSpecResponseOutput) Env() GoogleCloudAiplatformV1beta1EnvVarResponseArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelContainerSpecResponse) []GoogleCloudAiplatformV1beta1EnvVarResponse {
		return v.Env
	}).(GoogleCloudAiplatformV1beta1EnvVarResponseArrayOutput)
}

// Immutable. Specification for Kubernetes readiness probe. TODO (b/306244185): Revise documentation before exposing.
func (o GoogleCloudAiplatformV1beta1ModelContainerSpecResponseOutput) HealthProbe() GoogleCloudAiplatformV1beta1ProbeResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelContainerSpecResponse) GoogleCloudAiplatformV1beta1ProbeResponse {
		return v.HealthProbe
	}).(GoogleCloudAiplatformV1beta1ProbeResponseOutput)
}

// Immutable. HTTP path on the container to send health checks to. Vertex AI intermittently sends GET requests to this path on the container's IP address and port to check that the container is healthy. Read more about [health checks](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#health). For example, if you set this field to `/bar`, then Vertex AI intermittently sends a GET request to the `/bar` path on the port of your container specified by the first value of this `ModelContainerSpec`'s ports field. If you don't specify this field, it defaults to the following value when you deploy this Model to an Endpoint: /v1/endpoints/ENDPOINT/deployedModels/ DEPLOYED_MODEL:predict The placeholders in this value are replaced as follows: * ENDPOINT: The last segment (following `endpoints/`)of the Endpoint.name][] field of the Endpoint where this Model has been deployed. (Vertex AI makes this value available to your container code as the [`AIP_ENDPOINT_ID` environment variable](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables).) * DEPLOYED_MODEL: DeployedModel.id of the `DeployedModel`. (Vertex AI makes this value available to your container code as the [`AIP_DEPLOYED_MODEL_ID` environment variable](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables).)
func (o GoogleCloudAiplatformV1beta1ModelContainerSpecResponseOutput) HealthRoute() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelContainerSpecResponse) string { return v.HealthRoute }).(pulumi.StringOutput)
}

// Immutable. URI of the Docker image to be used as the custom container for serving predictions. This URI must identify an image in Artifact Registry or Container Registry. Learn more about the [container publishing requirements](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#publishing), including permissions requirements for the Vertex AI Service Agent. The container image is ingested upon ModelService.UploadModel, stored internally, and this original path is afterwards not used. To learn about the requirements for the Docker image itself, see [Custom container requirements](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#). You can use the URI to one of Vertex AI's [pre-built container images for prediction](https://cloud.google.com/vertex-ai/docs/predictions/pre-built-containers) in this field.
func (o GoogleCloudAiplatformV1beta1ModelContainerSpecResponseOutput) ImageUri() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelContainerSpecResponse) string { return v.ImageUri }).(pulumi.StringOutput)
}

// Immutable. List of ports to expose from the container. Vertex AI sends any prediction requests that it receives to the first port on this list. Vertex AI also sends [liveness and health checks](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#liveness) to this port. If you do not specify this field, it defaults to following value: ``` json [ { "containerPort": 8080 } ]  ``` Vertex AI does not use ports other than the first one listed. This field corresponds to the `ports` field of the Kubernetes Containers [v1 core API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
func (o GoogleCloudAiplatformV1beta1ModelContainerSpecResponseOutput) Ports() GoogleCloudAiplatformV1beta1PortResponseArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelContainerSpecResponse) []GoogleCloudAiplatformV1beta1PortResponse {
		return v.Ports
	}).(GoogleCloudAiplatformV1beta1PortResponseArrayOutput)
}

// Immutable. HTTP path on the container to send prediction requests to. Vertex AI forwards requests sent using projects.locations.endpoints.predict to this path on the container's IP address and port. Vertex AI then returns the container's response in the API response. For example, if you set this field to `/foo`, then when Vertex AI receives a prediction request, it forwards the request body in a POST request to the `/foo` path on the port of your container specified by the first value of this `ModelContainerSpec`'s ports field. If you don't specify this field, it defaults to the following value when you deploy this Model to an Endpoint: /v1/endpoints/ENDPOINT/deployedModels/DEPLOYED_MODEL:predict The placeholders in this value are replaced as follows: * ENDPOINT: The last segment (following `endpoints/`)of the Endpoint.name][] field of the Endpoint where this Model has been deployed. (Vertex AI makes this value available to your container code as the [`AIP_ENDPOINT_ID` environment variable](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables).) * DEPLOYED_MODEL: DeployedModel.id of the `DeployedModel`. (Vertex AI makes this value available to your container code as the [`AIP_DEPLOYED_MODEL_ID` environment variable](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables).)
func (o GoogleCloudAiplatformV1beta1ModelContainerSpecResponseOutput) PredictRoute() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelContainerSpecResponse) string { return v.PredictRoute }).(pulumi.StringOutput)
}

// Immutable. The amount of the VM memory to reserve as the shared memory for the model in megabytes. TODO (b/306244185): Revise documentation before exposing.
func (o GoogleCloudAiplatformV1beta1ModelContainerSpecResponseOutput) SharedMemorySizeMb() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelContainerSpecResponse) string { return v.SharedMemorySizeMb }).(pulumi.StringOutput)
}

// Immutable. Specification for Kubernetes startup probe. TODO (b/306244185): Revise documentation before exposing.
func (o GoogleCloudAiplatformV1beta1ModelContainerSpecResponseOutput) StartupProbe() GoogleCloudAiplatformV1beta1ProbeResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelContainerSpecResponse) GoogleCloudAiplatformV1beta1ProbeResponse {
		return v.StartupProbe
	}).(GoogleCloudAiplatformV1beta1ProbeResponseOutput)
}

// ModelDeploymentMonitoringBigQueryTable specifies the BigQuery table name as well as some information of the logs stored in this table.
type GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringBigQueryTableResponse struct {
	// The created BigQuery table to store logs. Customer could do their own query & analysis. Format: `bq://.model_deployment_monitoring_._`
	BigqueryTablePath string `pulumi:"bigqueryTablePath"`
	// The source of log.
	LogSource string `pulumi:"logSource"`
	// The type of log.
	LogType string `pulumi:"logType"`
}

// ModelDeploymentMonitoringBigQueryTable specifies the BigQuery table name as well as some information of the logs stored in this table.
type GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringBigQueryTableResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringBigQueryTableResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringBigQueryTableResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringBigQueryTableResponseOutput) ToGoogleCloudAiplatformV1beta1ModelDeploymentMonitoringBigQueryTableResponseOutput() GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringBigQueryTableResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringBigQueryTableResponseOutput) ToGoogleCloudAiplatformV1beta1ModelDeploymentMonitoringBigQueryTableResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringBigQueryTableResponseOutput {
	return o
}

// The created BigQuery table to store logs. Customer could do their own query & analysis. Format: `bq://.model_deployment_monitoring_._`
func (o GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringBigQueryTableResponseOutput) BigqueryTablePath() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringBigQueryTableResponse) string {
		return v.BigqueryTablePath
	}).(pulumi.StringOutput)
}

// The source of log.
func (o GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringBigQueryTableResponseOutput) LogSource() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringBigQueryTableResponse) string {
		return v.LogSource
	}).(pulumi.StringOutput)
}

// The type of log.
func (o GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringBigQueryTableResponseOutput) LogType() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringBigQueryTableResponse) string {
		return v.LogType
	}).(pulumi.StringOutput)
}

type GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringBigQueryTableResponseArrayOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringBigQueryTableResponseArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringBigQueryTableResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringBigQueryTableResponseArrayOutput) ToGoogleCloudAiplatformV1beta1ModelDeploymentMonitoringBigQueryTableResponseArrayOutput() GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringBigQueryTableResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringBigQueryTableResponseArrayOutput) ToGoogleCloudAiplatformV1beta1ModelDeploymentMonitoringBigQueryTableResponseArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringBigQueryTableResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringBigQueryTableResponseArrayOutput) Index(i pulumi.IntInput) GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringBigQueryTableResponseOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringBigQueryTableResponse {
		return vs[0].([]GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringBigQueryTableResponse)[vs[1].(int)]
	}).(GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringBigQueryTableResponseOutput)
}

// All metadata of most recent monitoring pipelines.
type GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringJobLatestMonitoringPipelineMetadataResponse struct {
	// The time that most recent monitoring pipelines that is related to this run.
	RunTime string `pulumi:"runTime"`
	// The status of the most recent monitoring pipeline.
	Status GoogleRpcStatusResponse `pulumi:"status"`
}

// All metadata of most recent monitoring pipelines.
type GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringJobLatestMonitoringPipelineMetadataResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringJobLatestMonitoringPipelineMetadataResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringJobLatestMonitoringPipelineMetadataResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringJobLatestMonitoringPipelineMetadataResponseOutput) ToGoogleCloudAiplatformV1beta1ModelDeploymentMonitoringJobLatestMonitoringPipelineMetadataResponseOutput() GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringJobLatestMonitoringPipelineMetadataResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringJobLatestMonitoringPipelineMetadataResponseOutput) ToGoogleCloudAiplatformV1beta1ModelDeploymentMonitoringJobLatestMonitoringPipelineMetadataResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringJobLatestMonitoringPipelineMetadataResponseOutput {
	return o
}

// The time that most recent monitoring pipelines that is related to this run.
func (o GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringJobLatestMonitoringPipelineMetadataResponseOutput) RunTime() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringJobLatestMonitoringPipelineMetadataResponse) string {
		return v.RunTime
	}).(pulumi.StringOutput)
}

// The status of the most recent monitoring pipeline.
func (o GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringJobLatestMonitoringPipelineMetadataResponseOutput) Status() GoogleRpcStatusResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringJobLatestMonitoringPipelineMetadataResponse) GoogleRpcStatusResponse {
		return v.Status
	}).(GoogleRpcStatusResponseOutput)
}

// ModelDeploymentMonitoringObjectiveConfig contains the pair of deployed_model_id to ModelMonitoringObjectiveConfig.
type GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfig struct {
	// The DeployedModel ID of the objective config.
	DeployedModelId *string `pulumi:"deployedModelId"`
	// The objective config of for the modelmonitoring job of this deployed model.
	ObjectiveConfig *GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfig `pulumi:"objectiveConfig"`
}

// GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigInput is an input type that accepts GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigArgs and GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigInput` via:
//
//	GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigArgs{...}
type GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigOutput() GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigOutput
	ToGoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigOutput
}

// ModelDeploymentMonitoringObjectiveConfig contains the pair of deployed_model_id to ModelMonitoringObjectiveConfig.
type GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigArgs struct {
	// The DeployedModel ID of the objective config.
	DeployedModelId pulumi.StringPtrInput `pulumi:"deployedModelId"`
	// The objective config of for the modelmonitoring job of this deployed model.
	ObjectiveConfig GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPtrInput `pulumi:"objectiveConfig"`
}

func (GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfig)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigArgs) ToGoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigOutput() GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigOutput {
	return i.ToGoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigArgs) ToGoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigOutput)
}

// GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigArrayInput is an input type that accepts GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigArray and GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigArrayOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigArrayInput` via:
//
//	GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigArray{ GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigArgs{...} }
type GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigArrayInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigArrayOutput() GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigArrayOutput
	ToGoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigArrayOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigArrayOutput
}

type GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigArray []GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigInput

func (GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfig)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigArray) ToGoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigArrayOutput() GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigArrayOutput {
	return i.ToGoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigArrayOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigArray) ToGoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigArrayOutput)
}

// ModelDeploymentMonitoringObjectiveConfig contains the pair of deployed_model_id to ModelMonitoringObjectiveConfig.
type GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigOutput) ToGoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigOutput() GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigOutput) ToGoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigOutput {
	return o
}

// The DeployedModel ID of the objective config.
func (o GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigOutput) DeployedModelId() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfig) *string {
		return v.DeployedModelId
	}).(pulumi.StringPtrOutput)
}

// The objective config of for the modelmonitoring job of this deployed model.
func (o GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigOutput) ObjectiveConfig() GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfig) *GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfig {
		return v.ObjectiveConfig
	}).(GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPtrOutput)
}

type GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigArrayOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigArrayOutput) ToGoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigArrayOutput() GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigArrayOutput) ToGoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigArrayOutput) Index(i pulumi.IntInput) GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfig {
		return vs[0].([]GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfig)[vs[1].(int)]
	}).(GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigOutput)
}

// ModelDeploymentMonitoringObjectiveConfig contains the pair of deployed_model_id to ModelMonitoringObjectiveConfig.
type GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigResponse struct {
	// The DeployedModel ID of the objective config.
	DeployedModelId string `pulumi:"deployedModelId"`
	// The objective config of for the modelmonitoring job of this deployed model.
	ObjectiveConfig GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigResponse `pulumi:"objectiveConfig"`
}

// ModelDeploymentMonitoringObjectiveConfig contains the pair of deployed_model_id to ModelMonitoringObjectiveConfig.
type GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigResponseOutput) ToGoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigResponseOutput() GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigResponseOutput) ToGoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigResponseOutput {
	return o
}

// The DeployedModel ID of the objective config.
func (o GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigResponseOutput) DeployedModelId() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigResponse) string {
		return v.DeployedModelId
	}).(pulumi.StringOutput)
}

// The objective config of for the modelmonitoring job of this deployed model.
func (o GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigResponseOutput) ObjectiveConfig() GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigResponse) GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigResponse {
		return v.ObjectiveConfig
	}).(GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigResponseOutput)
}

type GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigResponseArrayOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigResponseArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigResponseArrayOutput) ToGoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigResponseArrayOutput() GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigResponseArrayOutput) ToGoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigResponseArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigResponseArrayOutput) Index(i pulumi.IntInput) GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigResponseOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigResponse {
		return vs[0].([]GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigResponse)[vs[1].(int)]
	}).(GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigResponseOutput)
}

// The config for scheduling monitoring job.
type GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringScheduleConfig struct {
	// The model monitoring job scheduling interval. It will be rounded up to next full hour. This defines how often the monitoring jobs are triggered.
	MonitorInterval string `pulumi:"monitorInterval"`
	// The time window of the prediction data being included in each prediction dataset. This window specifies how long the data should be collected from historical model results for each run. If not set, ModelDeploymentMonitoringScheduleConfig.monitor_interval will be used. e.g. If currently the cutoff time is 2022-01-08 14:30:00 and the monitor_window is set to be 3600, then data from 2022-01-08 13:30:00 to 2022-01-08 14:30:00 will be retrieved and aggregated to calculate the monitoring statistics.
	MonitorWindow *string `pulumi:"monitorWindow"`
}

// GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringScheduleConfigInput is an input type that accepts GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringScheduleConfigArgs and GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringScheduleConfigOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringScheduleConfigInput` via:
//
//	GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringScheduleConfigArgs{...}
type GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringScheduleConfigInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1ModelDeploymentMonitoringScheduleConfigOutput() GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringScheduleConfigOutput
	ToGoogleCloudAiplatformV1beta1ModelDeploymentMonitoringScheduleConfigOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringScheduleConfigOutput
}

// The config for scheduling monitoring job.
type GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringScheduleConfigArgs struct {
	// The model monitoring job scheduling interval. It will be rounded up to next full hour. This defines how often the monitoring jobs are triggered.
	MonitorInterval pulumi.StringInput `pulumi:"monitorInterval"`
	// The time window of the prediction data being included in each prediction dataset. This window specifies how long the data should be collected from historical model results for each run. If not set, ModelDeploymentMonitoringScheduleConfig.monitor_interval will be used. e.g. If currently the cutoff time is 2022-01-08 14:30:00 and the monitor_window is set to be 3600, then data from 2022-01-08 13:30:00 to 2022-01-08 14:30:00 will be retrieved and aggregated to calculate the monitoring statistics.
	MonitorWindow pulumi.StringPtrInput `pulumi:"monitorWindow"`
}

func (GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringScheduleConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringScheduleConfig)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringScheduleConfigArgs) ToGoogleCloudAiplatformV1beta1ModelDeploymentMonitoringScheduleConfigOutput() GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringScheduleConfigOutput {
	return i.ToGoogleCloudAiplatformV1beta1ModelDeploymentMonitoringScheduleConfigOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringScheduleConfigArgs) ToGoogleCloudAiplatformV1beta1ModelDeploymentMonitoringScheduleConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringScheduleConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringScheduleConfigOutput)
}

// The config for scheduling monitoring job.
type GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringScheduleConfigOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringScheduleConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringScheduleConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringScheduleConfigOutput) ToGoogleCloudAiplatformV1beta1ModelDeploymentMonitoringScheduleConfigOutput() GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringScheduleConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringScheduleConfigOutput) ToGoogleCloudAiplatformV1beta1ModelDeploymentMonitoringScheduleConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringScheduleConfigOutput {
	return o
}

// The model monitoring job scheduling interval. It will be rounded up to next full hour. This defines how often the monitoring jobs are triggered.
func (o GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringScheduleConfigOutput) MonitorInterval() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringScheduleConfig) string {
		return v.MonitorInterval
	}).(pulumi.StringOutput)
}

// The time window of the prediction data being included in each prediction dataset. This window specifies how long the data should be collected from historical model results for each run. If not set, ModelDeploymentMonitoringScheduleConfig.monitor_interval will be used. e.g. If currently the cutoff time is 2022-01-08 14:30:00 and the monitor_window is set to be 3600, then data from 2022-01-08 13:30:00 to 2022-01-08 14:30:00 will be retrieved and aggregated to calculate the monitoring statistics.
func (o GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringScheduleConfigOutput) MonitorWindow() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringScheduleConfig) *string {
		return v.MonitorWindow
	}).(pulumi.StringPtrOutput)
}

// The config for scheduling monitoring job.
type GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringScheduleConfigResponse struct {
	// The model monitoring job scheduling interval. It will be rounded up to next full hour. This defines how often the monitoring jobs are triggered.
	MonitorInterval string `pulumi:"monitorInterval"`
	// The time window of the prediction data being included in each prediction dataset. This window specifies how long the data should be collected from historical model results for each run. If not set, ModelDeploymentMonitoringScheduleConfig.monitor_interval will be used. e.g. If currently the cutoff time is 2022-01-08 14:30:00 and the monitor_window is set to be 3600, then data from 2022-01-08 13:30:00 to 2022-01-08 14:30:00 will be retrieved and aggregated to calculate the monitoring statistics.
	MonitorWindow string `pulumi:"monitorWindow"`
}

// The config for scheduling monitoring job.
type GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringScheduleConfigResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringScheduleConfigResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringScheduleConfigResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringScheduleConfigResponseOutput) ToGoogleCloudAiplatformV1beta1ModelDeploymentMonitoringScheduleConfigResponseOutput() GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringScheduleConfigResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringScheduleConfigResponseOutput) ToGoogleCloudAiplatformV1beta1ModelDeploymentMonitoringScheduleConfigResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringScheduleConfigResponseOutput {
	return o
}

// The model monitoring job scheduling interval. It will be rounded up to next full hour. This defines how often the monitoring jobs are triggered.
func (o GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringScheduleConfigResponseOutput) MonitorInterval() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringScheduleConfigResponse) string {
		return v.MonitorInterval
	}).(pulumi.StringOutput)
}

// The time window of the prediction data being included in each prediction dataset. This window specifies how long the data should be collected from historical model results for each run. If not set, ModelDeploymentMonitoringScheduleConfig.monitor_interval will be used. e.g. If currently the cutoff time is 2022-01-08 14:30:00 and the monitor_window is set to be 3600, then data from 2022-01-08 13:30:00 to 2022-01-08 14:30:00 will be retrieved and aggregated to calculate the monitoring statistics.
func (o GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringScheduleConfigResponseOutput) MonitorWindow() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringScheduleConfigResponse) string {
		return v.MonitorWindow
	}).(pulumi.StringOutput)
}

// Represents export format supported by the Model. All formats export to Google Cloud Storage.
type GoogleCloudAiplatformV1beta1ModelExportFormatResponse struct {
	// The content of this Model that may be exported.
	ExportableContents []string `pulumi:"exportableContents"`
}

// Represents export format supported by the Model. All formats export to Google Cloud Storage.
type GoogleCloudAiplatformV1beta1ModelExportFormatResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ModelExportFormatResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ModelExportFormatResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ModelExportFormatResponseOutput) ToGoogleCloudAiplatformV1beta1ModelExportFormatResponseOutput() GoogleCloudAiplatformV1beta1ModelExportFormatResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ModelExportFormatResponseOutput) ToGoogleCloudAiplatformV1beta1ModelExportFormatResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelExportFormatResponseOutput {
	return o
}

// The content of this Model that may be exported.
func (o GoogleCloudAiplatformV1beta1ModelExportFormatResponseOutput) ExportableContents() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelExportFormatResponse) []string { return v.ExportableContents }).(pulumi.StringArrayOutput)
}

type GoogleCloudAiplatformV1beta1ModelExportFormatResponseArrayOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ModelExportFormatResponseArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1beta1ModelExportFormatResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ModelExportFormatResponseArrayOutput) ToGoogleCloudAiplatformV1beta1ModelExportFormatResponseArrayOutput() GoogleCloudAiplatformV1beta1ModelExportFormatResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ModelExportFormatResponseArrayOutput) ToGoogleCloudAiplatformV1beta1ModelExportFormatResponseArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelExportFormatResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ModelExportFormatResponseArrayOutput) Index(i pulumi.IntInput) GoogleCloudAiplatformV1beta1ModelExportFormatResponseOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GoogleCloudAiplatformV1beta1ModelExportFormatResponse {
		return vs[0].([]GoogleCloudAiplatformV1beta1ModelExportFormatResponse)[vs[1].(int)]
	}).(GoogleCloudAiplatformV1beta1ModelExportFormatResponseOutput)
}

type GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfig struct {
	// Email alert config.
	EmailAlertConfig *GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfig `pulumi:"emailAlertConfig"`
	// Dump the anomalies to Cloud Logging. The anomalies will be put to json payload encoded from proto google.cloud.aiplatform.logging.ModelMonitoringAnomaliesLogEntry. This can be further sinked to Pub/Sub or any other services supported by Cloud Logging.
	EnableLogging *bool `pulumi:"enableLogging"`
	// Resource names of the NotificationChannels to send alert. Must be of the format `projects//notificationChannels/`
	NotificationChannels []string `pulumi:"notificationChannels"`
}

// GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigInput is an input type that accepts GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigArgs and GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigInput` via:
//
//	GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigArgs{...}
type GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigOutput() GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigOutput
	ToGoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigOutput
}

type GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigArgs struct {
	// Email alert config.
	EmailAlertConfig GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigPtrInput `pulumi:"emailAlertConfig"`
	// Dump the anomalies to Cloud Logging. The anomalies will be put to json payload encoded from proto google.cloud.aiplatform.logging.ModelMonitoringAnomaliesLogEntry. This can be further sinked to Pub/Sub or any other services supported by Cloud Logging.
	EnableLogging pulumi.BoolPtrInput `pulumi:"enableLogging"`
	// Resource names of the NotificationChannels to send alert. Must be of the format `projects//notificationChannels/`
	NotificationChannels pulumi.StringArrayInput `pulumi:"notificationChannels"`
}

func (GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfig)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigArgs) ToGoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigOutput() GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigOutput {
	return i.ToGoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigArgs) ToGoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigOutput)
}

func (i GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigArgs) ToGoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigPtrOutput() GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigArgs) ToGoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigOutput).ToGoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigArgs, GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigPtr and GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigPtrOutput() GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigPtrOutput
	ToGoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigPtrOutput
}

type googleCloudAiplatformV1beta1ModelMonitoringAlertConfigPtrType GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigArgs

func GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigPtr(v *GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigArgs) GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigPtrInput {
	return (*googleCloudAiplatformV1beta1ModelMonitoringAlertConfigPtrType)(v)
}

func (*googleCloudAiplatformV1beta1ModelMonitoringAlertConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfig)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1ModelMonitoringAlertConfigPtrType) ToGoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigPtrOutput() GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1ModelMonitoringAlertConfigPtrType) ToGoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigPtrOutput)
}

type GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigOutput) ToGoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigOutput() GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigOutput) ToGoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigOutput) ToGoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigPtrOutput() GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigOutput) ToGoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfig) *GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfig {
		return &v
	}).(GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigPtrOutput)
}

// Email alert config.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigOutput) EmailAlertConfig() GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfig) *GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfig {
		return v.EmailAlertConfig
	}).(GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigPtrOutput)
}

// Dump the anomalies to Cloud Logging. The anomalies will be put to json payload encoded from proto google.cloud.aiplatform.logging.ModelMonitoringAnomaliesLogEntry. This can be further sinked to Pub/Sub or any other services supported by Cloud Logging.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigOutput) EnableLogging() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfig) *bool { return v.EnableLogging }).(pulumi.BoolPtrOutput)
}

// Resource names of the NotificationChannels to send alert. Must be of the format `projects//notificationChannels/`
func (o GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigOutput) NotificationChannels() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfig) []string { return v.NotificationChannels }).(pulumi.StringArrayOutput)
}

type GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigPtrOutput) ToGoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigPtrOutput() GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigPtrOutput) ToGoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigPtrOutput) Elem() GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfig) GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfig {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfig
		return ret
	}).(GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigOutput)
}

// Email alert config.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigPtrOutput) EmailAlertConfig() GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfig) *GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfig {
		if v == nil {
			return nil
		}
		return v.EmailAlertConfig
	}).(GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigPtrOutput)
}

// Dump the anomalies to Cloud Logging. The anomalies will be put to json payload encoded from proto google.cloud.aiplatform.logging.ModelMonitoringAnomaliesLogEntry. This can be further sinked to Pub/Sub or any other services supported by Cloud Logging.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigPtrOutput) EnableLogging() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfig) *bool {
		if v == nil {
			return nil
		}
		return v.EnableLogging
	}).(pulumi.BoolPtrOutput)
}

// Resource names of the NotificationChannels to send alert. Must be of the format `projects//notificationChannels/`
func (o GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigPtrOutput) NotificationChannels() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfig) []string {
		if v == nil {
			return nil
		}
		return v.NotificationChannels
	}).(pulumi.StringArrayOutput)
}

// The config for email alert.
type GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfig struct {
	// The email addresses to send the alert.
	UserEmails []string `pulumi:"userEmails"`
}

// GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigInput is an input type that accepts GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigArgs and GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigInput` via:
//
//	GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigArgs{...}
type GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigOutput() GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigOutput
	ToGoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigOutput
}

// The config for email alert.
type GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigArgs struct {
	// The email addresses to send the alert.
	UserEmails pulumi.StringArrayInput `pulumi:"userEmails"`
}

func (GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfig)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigArgs) ToGoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigOutput() GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigOutput {
	return i.ToGoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigArgs) ToGoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigOutput)
}

func (i GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigArgs) ToGoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigPtrOutput() GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigArgs) ToGoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigOutput).ToGoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigArgs, GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigPtr and GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigPtrOutput() GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigPtrOutput
	ToGoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigPtrOutput
}

type googleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigPtrType GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigArgs

func GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigPtr(v *GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigArgs) GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigPtrInput {
	return (*googleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigPtrType)(v)
}

func (*googleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfig)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigPtrType) ToGoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigPtrOutput() GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigPtrType) ToGoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigPtrOutput)
}

// The config for email alert.
type GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigOutput) ToGoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigOutput() GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigOutput) ToGoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigOutput) ToGoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigPtrOutput() GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigOutput) ToGoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfig) *GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfig {
		return &v
	}).(GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigPtrOutput)
}

// The email addresses to send the alert.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigOutput) UserEmails() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfig) []string {
		return v.UserEmails
	}).(pulumi.StringArrayOutput)
}

type GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigPtrOutput) ToGoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigPtrOutput() GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigPtrOutput) ToGoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigPtrOutput) Elem() GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfig) GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfig {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfig
		return ret
	}).(GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigOutput)
}

// The email addresses to send the alert.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigPtrOutput) UserEmails() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfig) []string {
		if v == nil {
			return nil
		}
		return v.UserEmails
	}).(pulumi.StringArrayOutput)
}

// The config for email alert.
type GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigResponse struct {
	// The email addresses to send the alert.
	UserEmails []string `pulumi:"userEmails"`
}

// The config for email alert.
type GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigResponseOutput) ToGoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigResponseOutput() GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigResponseOutput) ToGoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigResponseOutput {
	return o
}

// The email addresses to send the alert.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigResponseOutput) UserEmails() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigResponse) []string {
		return v.UserEmails
	}).(pulumi.StringArrayOutput)
}

type GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigResponse struct {
	// Email alert config.
	EmailAlertConfig GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigResponse `pulumi:"emailAlertConfig"`
	// Dump the anomalies to Cloud Logging. The anomalies will be put to json payload encoded from proto google.cloud.aiplatform.logging.ModelMonitoringAnomaliesLogEntry. This can be further sinked to Pub/Sub or any other services supported by Cloud Logging.
	EnableLogging bool `pulumi:"enableLogging"`
	// Resource names of the NotificationChannels to send alert. Must be of the format `projects//notificationChannels/`
	NotificationChannels []string `pulumi:"notificationChannels"`
}

type GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigResponseOutput) ToGoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigResponseOutput() GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigResponseOutput) ToGoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigResponseOutput {
	return o
}

// Email alert config.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigResponseOutput) EmailAlertConfig() GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigResponse) GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigResponse {
		return v.EmailAlertConfig
	}).(GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigResponseOutput)
}

// Dump the anomalies to Cloud Logging. The anomalies will be put to json payload encoded from proto google.cloud.aiplatform.logging.ModelMonitoringAnomaliesLogEntry. This can be further sinked to Pub/Sub or any other services supported by Cloud Logging.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigResponseOutput) EnableLogging() pulumi.BoolOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigResponse) bool { return v.EnableLogging }).(pulumi.BoolOutput)
}

// Resource names of the NotificationChannels to send alert. Must be of the format `projects//notificationChannels/`
func (o GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigResponseOutput) NotificationChannels() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigResponse) []string {
		return v.NotificationChannels
	}).(pulumi.StringArrayOutput)
}

// The model monitoring configuration used for Batch Prediction Job.
type GoogleCloudAiplatformV1beta1ModelMonitoringConfig struct {
	// Model monitoring alert config.
	AlertConfig *GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfig `pulumi:"alertConfig"`
	// YAML schema file uri in Cloud Storage describing the format of a single instance that you want Tensorflow Data Validation (TFDV) to analyze. If there are any data type differences between predict instance and TFDV instance, this field can be used to override the schema. For models trained with Vertex AI, this field must be set as all the fields in predict instance formatted as string.
	AnalysisInstanceSchemaUri *string `pulumi:"analysisInstanceSchemaUri"`
	// Model monitoring objective config.
	ObjectiveConfigs []GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfig `pulumi:"objectiveConfigs"`
	// A Google Cloud Storage location for batch prediction model monitoring to dump statistics and anomalies. If not provided, a folder will be created in customer project to hold statistics and anomalies.
	StatsAnomaliesBaseDirectory *GoogleCloudAiplatformV1beta1GcsDestination `pulumi:"statsAnomaliesBaseDirectory"`
}

// GoogleCloudAiplatformV1beta1ModelMonitoringConfigInput is an input type that accepts GoogleCloudAiplatformV1beta1ModelMonitoringConfigArgs and GoogleCloudAiplatformV1beta1ModelMonitoringConfigOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1ModelMonitoringConfigInput` via:
//
//	GoogleCloudAiplatformV1beta1ModelMonitoringConfigArgs{...}
type GoogleCloudAiplatformV1beta1ModelMonitoringConfigInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1ModelMonitoringConfigOutput() GoogleCloudAiplatformV1beta1ModelMonitoringConfigOutput
	ToGoogleCloudAiplatformV1beta1ModelMonitoringConfigOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringConfigOutput
}

// The model monitoring configuration used for Batch Prediction Job.
type GoogleCloudAiplatformV1beta1ModelMonitoringConfigArgs struct {
	// Model monitoring alert config.
	AlertConfig GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigPtrInput `pulumi:"alertConfig"`
	// YAML schema file uri in Cloud Storage describing the format of a single instance that you want Tensorflow Data Validation (TFDV) to analyze. If there are any data type differences between predict instance and TFDV instance, this field can be used to override the schema. For models trained with Vertex AI, this field must be set as all the fields in predict instance formatted as string.
	AnalysisInstanceSchemaUri pulumi.StringPtrInput `pulumi:"analysisInstanceSchemaUri"`
	// Model monitoring objective config.
	ObjectiveConfigs GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigArrayInput `pulumi:"objectiveConfigs"`
	// A Google Cloud Storage location for batch prediction model monitoring to dump statistics and anomalies. If not provided, a folder will be created in customer project to hold statistics and anomalies.
	StatsAnomaliesBaseDirectory GoogleCloudAiplatformV1beta1GcsDestinationPtrInput `pulumi:"statsAnomaliesBaseDirectory"`
}

func (GoogleCloudAiplatformV1beta1ModelMonitoringConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ModelMonitoringConfig)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1ModelMonitoringConfigArgs) ToGoogleCloudAiplatformV1beta1ModelMonitoringConfigOutput() GoogleCloudAiplatformV1beta1ModelMonitoringConfigOutput {
	return i.ToGoogleCloudAiplatformV1beta1ModelMonitoringConfigOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1ModelMonitoringConfigArgs) ToGoogleCloudAiplatformV1beta1ModelMonitoringConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ModelMonitoringConfigOutput)
}

func (i GoogleCloudAiplatformV1beta1ModelMonitoringConfigArgs) ToGoogleCloudAiplatformV1beta1ModelMonitoringConfigPtrOutput() GoogleCloudAiplatformV1beta1ModelMonitoringConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1ModelMonitoringConfigPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1ModelMonitoringConfigArgs) ToGoogleCloudAiplatformV1beta1ModelMonitoringConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ModelMonitoringConfigOutput).ToGoogleCloudAiplatformV1beta1ModelMonitoringConfigPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1ModelMonitoringConfigPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1ModelMonitoringConfigArgs, GoogleCloudAiplatformV1beta1ModelMonitoringConfigPtr and GoogleCloudAiplatformV1beta1ModelMonitoringConfigPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1ModelMonitoringConfigPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1ModelMonitoringConfigArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1ModelMonitoringConfigPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1ModelMonitoringConfigPtrOutput() GoogleCloudAiplatformV1beta1ModelMonitoringConfigPtrOutput
	ToGoogleCloudAiplatformV1beta1ModelMonitoringConfigPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringConfigPtrOutput
}

type googleCloudAiplatformV1beta1ModelMonitoringConfigPtrType GoogleCloudAiplatformV1beta1ModelMonitoringConfigArgs

func GoogleCloudAiplatformV1beta1ModelMonitoringConfigPtr(v *GoogleCloudAiplatformV1beta1ModelMonitoringConfigArgs) GoogleCloudAiplatformV1beta1ModelMonitoringConfigPtrInput {
	return (*googleCloudAiplatformV1beta1ModelMonitoringConfigPtrType)(v)
}

func (*googleCloudAiplatformV1beta1ModelMonitoringConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1ModelMonitoringConfig)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1ModelMonitoringConfigPtrType) ToGoogleCloudAiplatformV1beta1ModelMonitoringConfigPtrOutput() GoogleCloudAiplatformV1beta1ModelMonitoringConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1ModelMonitoringConfigPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1ModelMonitoringConfigPtrType) ToGoogleCloudAiplatformV1beta1ModelMonitoringConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ModelMonitoringConfigPtrOutput)
}

// The model monitoring configuration used for Batch Prediction Job.
type GoogleCloudAiplatformV1beta1ModelMonitoringConfigOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ModelMonitoringConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ModelMonitoringConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringConfigOutput) ToGoogleCloudAiplatformV1beta1ModelMonitoringConfigOutput() GoogleCloudAiplatformV1beta1ModelMonitoringConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringConfigOutput) ToGoogleCloudAiplatformV1beta1ModelMonitoringConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringConfigOutput) ToGoogleCloudAiplatformV1beta1ModelMonitoringConfigPtrOutput() GoogleCloudAiplatformV1beta1ModelMonitoringConfigPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1ModelMonitoringConfigPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringConfigOutput) ToGoogleCloudAiplatformV1beta1ModelMonitoringConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringConfigPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1ModelMonitoringConfig) *GoogleCloudAiplatformV1beta1ModelMonitoringConfig {
		return &v
	}).(GoogleCloudAiplatformV1beta1ModelMonitoringConfigPtrOutput)
}

// Model monitoring alert config.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringConfigOutput) AlertConfig() GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelMonitoringConfig) *GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfig {
		return v.AlertConfig
	}).(GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigPtrOutput)
}

// YAML schema file uri in Cloud Storage describing the format of a single instance that you want Tensorflow Data Validation (TFDV) to analyze. If there are any data type differences between predict instance and TFDV instance, this field can be used to override the schema. For models trained with Vertex AI, this field must be set as all the fields in predict instance formatted as string.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringConfigOutput) AnalysisInstanceSchemaUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelMonitoringConfig) *string { return v.AnalysisInstanceSchemaUri }).(pulumi.StringPtrOutput)
}

// Model monitoring objective config.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringConfigOutput) ObjectiveConfigs() GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelMonitoringConfig) []GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfig {
		return v.ObjectiveConfigs
	}).(GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigArrayOutput)
}

// A Google Cloud Storage location for batch prediction model monitoring to dump statistics and anomalies. If not provided, a folder will be created in customer project to hold statistics and anomalies.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringConfigOutput) StatsAnomaliesBaseDirectory() GoogleCloudAiplatformV1beta1GcsDestinationPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelMonitoringConfig) *GoogleCloudAiplatformV1beta1GcsDestination {
		return v.StatsAnomaliesBaseDirectory
	}).(GoogleCloudAiplatformV1beta1GcsDestinationPtrOutput)
}

type GoogleCloudAiplatformV1beta1ModelMonitoringConfigPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ModelMonitoringConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1ModelMonitoringConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringConfigPtrOutput) ToGoogleCloudAiplatformV1beta1ModelMonitoringConfigPtrOutput() GoogleCloudAiplatformV1beta1ModelMonitoringConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringConfigPtrOutput) ToGoogleCloudAiplatformV1beta1ModelMonitoringConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringConfigPtrOutput) Elem() GoogleCloudAiplatformV1beta1ModelMonitoringConfigOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ModelMonitoringConfig) GoogleCloudAiplatformV1beta1ModelMonitoringConfig {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1ModelMonitoringConfig
		return ret
	}).(GoogleCloudAiplatformV1beta1ModelMonitoringConfigOutput)
}

// Model monitoring alert config.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringConfigPtrOutput) AlertConfig() GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ModelMonitoringConfig) *GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfig {
		if v == nil {
			return nil
		}
		return v.AlertConfig
	}).(GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigPtrOutput)
}

// YAML schema file uri in Cloud Storage describing the format of a single instance that you want Tensorflow Data Validation (TFDV) to analyze. If there are any data type differences between predict instance and TFDV instance, this field can be used to override the schema. For models trained with Vertex AI, this field must be set as all the fields in predict instance formatted as string.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringConfigPtrOutput) AnalysisInstanceSchemaUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ModelMonitoringConfig) *string {
		if v == nil {
			return nil
		}
		return v.AnalysisInstanceSchemaUri
	}).(pulumi.StringPtrOutput)
}

// Model monitoring objective config.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringConfigPtrOutput) ObjectiveConfigs() GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigArrayOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ModelMonitoringConfig) []GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfig {
		if v == nil {
			return nil
		}
		return v.ObjectiveConfigs
	}).(GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigArrayOutput)
}

// A Google Cloud Storage location for batch prediction model monitoring to dump statistics and anomalies. If not provided, a folder will be created in customer project to hold statistics and anomalies.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringConfigPtrOutput) StatsAnomaliesBaseDirectory() GoogleCloudAiplatformV1beta1GcsDestinationPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ModelMonitoringConfig) *GoogleCloudAiplatformV1beta1GcsDestination {
		if v == nil {
			return nil
		}
		return v.StatsAnomaliesBaseDirectory
	}).(GoogleCloudAiplatformV1beta1GcsDestinationPtrOutput)
}

// The model monitoring configuration used for Batch Prediction Job.
type GoogleCloudAiplatformV1beta1ModelMonitoringConfigResponse struct {
	// Model monitoring alert config.
	AlertConfig GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigResponse `pulumi:"alertConfig"`
	// YAML schema file uri in Cloud Storage describing the format of a single instance that you want Tensorflow Data Validation (TFDV) to analyze. If there are any data type differences between predict instance and TFDV instance, this field can be used to override the schema. For models trained with Vertex AI, this field must be set as all the fields in predict instance formatted as string.
	AnalysisInstanceSchemaUri string `pulumi:"analysisInstanceSchemaUri"`
	// Model monitoring objective config.
	ObjectiveConfigs []GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigResponse `pulumi:"objectiveConfigs"`
	// A Google Cloud Storage location for batch prediction model monitoring to dump statistics and anomalies. If not provided, a folder will be created in customer project to hold statistics and anomalies.
	StatsAnomaliesBaseDirectory GoogleCloudAiplatformV1beta1GcsDestinationResponse `pulumi:"statsAnomaliesBaseDirectory"`
}

// The model monitoring configuration used for Batch Prediction Job.
type GoogleCloudAiplatformV1beta1ModelMonitoringConfigResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ModelMonitoringConfigResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ModelMonitoringConfigResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringConfigResponseOutput) ToGoogleCloudAiplatformV1beta1ModelMonitoringConfigResponseOutput() GoogleCloudAiplatformV1beta1ModelMonitoringConfigResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringConfigResponseOutput) ToGoogleCloudAiplatformV1beta1ModelMonitoringConfigResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringConfigResponseOutput {
	return o
}

// Model monitoring alert config.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringConfigResponseOutput) AlertConfig() GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelMonitoringConfigResponse) GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigResponse {
		return v.AlertConfig
	}).(GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigResponseOutput)
}

// YAML schema file uri in Cloud Storage describing the format of a single instance that you want Tensorflow Data Validation (TFDV) to analyze. If there are any data type differences between predict instance and TFDV instance, this field can be used to override the schema. For models trained with Vertex AI, this field must be set as all the fields in predict instance formatted as string.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringConfigResponseOutput) AnalysisInstanceSchemaUri() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelMonitoringConfigResponse) string {
		return v.AnalysisInstanceSchemaUri
	}).(pulumi.StringOutput)
}

// Model monitoring objective config.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringConfigResponseOutput) ObjectiveConfigs() GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigResponseArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelMonitoringConfigResponse) []GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigResponse {
		return v.ObjectiveConfigs
	}).(GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigResponseArrayOutput)
}

// A Google Cloud Storage location for batch prediction model monitoring to dump statistics and anomalies. If not provided, a folder will be created in customer project to hold statistics and anomalies.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringConfigResponseOutput) StatsAnomaliesBaseDirectory() GoogleCloudAiplatformV1beta1GcsDestinationResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelMonitoringConfigResponse) GoogleCloudAiplatformV1beta1GcsDestinationResponse {
		return v.StatsAnomaliesBaseDirectory
	}).(GoogleCloudAiplatformV1beta1GcsDestinationResponseOutput)
}

// The objective configuration for model monitoring, including the information needed to detect anomalies for one particular model.
type GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfig struct {
	// The config for integrating with Vertex Explainable AI.
	ExplanationConfig *GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfig `pulumi:"explanationConfig"`
	// The config for drift of prediction data.
	PredictionDriftDetectionConfig *GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfig `pulumi:"predictionDriftDetectionConfig"`
	// Training dataset for models. This field has to be set only if TrainingPredictionSkewDetectionConfig is specified.
	TrainingDataset *GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDataset `pulumi:"trainingDataset"`
	// The config for skew between training data and prediction data.
	TrainingPredictionSkewDetectionConfig *GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfig `pulumi:"trainingPredictionSkewDetectionConfig"`
}

// GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigInput is an input type that accepts GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigArgs and GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigInput` via:
//
//	GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigArgs{...}
type GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigOutput() GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigOutput
	ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigOutput
}

// The objective configuration for model monitoring, including the information needed to detect anomalies for one particular model.
type GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigArgs struct {
	// The config for integrating with Vertex Explainable AI.
	ExplanationConfig GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigPtrInput `pulumi:"explanationConfig"`
	// The config for drift of prediction data.
	PredictionDriftDetectionConfig GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrInput `pulumi:"predictionDriftDetectionConfig"`
	// Training dataset for models. This field has to be set only if TrainingPredictionSkewDetectionConfig is specified.
	TrainingDataset GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetPtrInput `pulumi:"trainingDataset"`
	// The config for skew between training data and prediction data.
	TrainingPredictionSkewDetectionConfig GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrInput `pulumi:"trainingPredictionSkewDetectionConfig"`
}

func (GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfig)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigArgs) ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigOutput() GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigOutput {
	return i.ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigArgs) ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigOutput)
}

func (i GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigArgs) ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPtrOutput() GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigArgs) ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigOutput).ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigArgs, GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPtr and GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPtrOutput() GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPtrOutput
	ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPtrOutput
}

type googleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPtrType GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigArgs

func GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPtr(v *GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigArgs) GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPtrInput {
	return (*googleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPtrType)(v)
}

func (*googleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfig)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPtrType) ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPtrOutput() GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPtrType) ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPtrOutput)
}

// GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigArrayInput is an input type that accepts GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigArray and GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigArrayOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigArrayInput` via:
//
//	GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigArray{ GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigArgs{...} }
type GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigArrayInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigArrayOutput() GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigArrayOutput
	ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigArrayOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigArrayOutput
}

type GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigArray []GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigInput

func (GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfig)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigArray) ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigArrayOutput() GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigArrayOutput {
	return i.ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigArrayOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigArray) ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigArrayOutput)
}

// The objective configuration for model monitoring, including the information needed to detect anomalies for one particular model.
type GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigOutput) ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigOutput() GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigOutput) ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigOutput) ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPtrOutput() GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigOutput) ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfig) *GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfig {
		return &v
	}).(GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPtrOutput)
}

// The config for integrating with Vertex Explainable AI.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigOutput) ExplanationConfig() GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfig) *GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfig {
		return v.ExplanationConfig
	}).(GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigPtrOutput)
}

// The config for drift of prediction data.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigOutput) PredictionDriftDetectionConfig() GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfig) *GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfig {
		return v.PredictionDriftDetectionConfig
	}).(GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrOutput)
}

// Training dataset for models. This field has to be set only if TrainingPredictionSkewDetectionConfig is specified.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigOutput) TrainingDataset() GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfig) *GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDataset {
		return v.TrainingDataset
	}).(GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetPtrOutput)
}

// The config for skew between training data and prediction data.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigOutput) TrainingPredictionSkewDetectionConfig() GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfig) *GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfig {
		return v.TrainingPredictionSkewDetectionConfig
	}).(GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrOutput)
}

type GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPtrOutput) ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPtrOutput() GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPtrOutput) ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPtrOutput) Elem() GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfig) GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfig {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfig
		return ret
	}).(GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigOutput)
}

// The config for integrating with Vertex Explainable AI.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPtrOutput) ExplanationConfig() GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfig) *GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfig {
		if v == nil {
			return nil
		}
		return v.ExplanationConfig
	}).(GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigPtrOutput)
}

// The config for drift of prediction data.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPtrOutput) PredictionDriftDetectionConfig() GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfig) *GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfig {
		if v == nil {
			return nil
		}
		return v.PredictionDriftDetectionConfig
	}).(GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrOutput)
}

// Training dataset for models. This field has to be set only if TrainingPredictionSkewDetectionConfig is specified.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPtrOutput) TrainingDataset() GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfig) *GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDataset {
		if v == nil {
			return nil
		}
		return v.TrainingDataset
	}).(GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetPtrOutput)
}

// The config for skew between training data and prediction data.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPtrOutput) TrainingPredictionSkewDetectionConfig() GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfig) *GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfig {
		if v == nil {
			return nil
		}
		return v.TrainingPredictionSkewDetectionConfig
	}).(GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrOutput)
}

type GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigArrayOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigArrayOutput) ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigArrayOutput() GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigArrayOutput) ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigArrayOutput) Index(i pulumi.IntInput) GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfig {
		return vs[0].([]GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfig)[vs[1].(int)]
	}).(GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigOutput)
}

// The config for integrating with Vertex Explainable AI. Only applicable if the Model has explanation_spec populated.
type GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfig struct {
	// If want to analyze the Vertex Explainable AI feature attribute scores or not. If set to true, Vertex AI will log the feature attributions from explain response and do the skew/drift detection for them.
	EnableFeatureAttributes *bool `pulumi:"enableFeatureAttributes"`
	// Predictions generated by the BatchPredictionJob using baseline dataset.
	ExplanationBaseline *GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaseline `pulumi:"explanationBaseline"`
}

// GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigInput is an input type that accepts GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigArgs and GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigInput` via:
//
//	GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigArgs{...}
type GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigOutput() GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigOutput
	ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigOutput
}

// The config for integrating with Vertex Explainable AI. Only applicable if the Model has explanation_spec populated.
type GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigArgs struct {
	// If want to analyze the Vertex Explainable AI feature attribute scores or not. If set to true, Vertex AI will log the feature attributions from explain response and do the skew/drift detection for them.
	EnableFeatureAttributes pulumi.BoolPtrInput `pulumi:"enableFeatureAttributes"`
	// Predictions generated by the BatchPredictionJob using baseline dataset.
	ExplanationBaseline GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrInput `pulumi:"explanationBaseline"`
}

func (GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfig)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigArgs) ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigOutput() GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigOutput {
	return i.ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigArgs) ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigOutput)
}

func (i GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigArgs) ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigPtrOutput() GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigArgs) ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigOutput).ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigArgs, GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigPtr and GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigPtrOutput() GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigPtrOutput
	ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigPtrOutput
}

type googleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigPtrType GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigArgs

func GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigPtr(v *GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigArgs) GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigPtrInput {
	return (*googleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigPtrType)(v)
}

func (*googleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfig)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigPtrType) ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigPtrOutput() GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigPtrType) ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigPtrOutput)
}

// The config for integrating with Vertex Explainable AI. Only applicable if the Model has explanation_spec populated.
type GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigOutput) ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigOutput() GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigOutput) ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigOutput) ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigPtrOutput() GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigOutput) ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfig) *GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfig {
		return &v
	}).(GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigPtrOutput)
}

// If want to analyze the Vertex Explainable AI feature attribute scores or not. If set to true, Vertex AI will log the feature attributions from explain response and do the skew/drift detection for them.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigOutput) EnableFeatureAttributes() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfig) *bool {
		return v.EnableFeatureAttributes
	}).(pulumi.BoolPtrOutput)
}

// Predictions generated by the BatchPredictionJob using baseline dataset.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigOutput) ExplanationBaseline() GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfig) *GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaseline {
		return v.ExplanationBaseline
	}).(GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrOutput)
}

type GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigPtrOutput) ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigPtrOutput() GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigPtrOutput) ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigPtrOutput) Elem() GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfig) GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfig {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfig
		return ret
	}).(GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigOutput)
}

// If want to analyze the Vertex Explainable AI feature attribute scores or not. If set to true, Vertex AI will log the feature attributions from explain response and do the skew/drift detection for them.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigPtrOutput) EnableFeatureAttributes() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfig) *bool {
		if v == nil {
			return nil
		}
		return v.EnableFeatureAttributes
	}).(pulumi.BoolPtrOutput)
}

// Predictions generated by the BatchPredictionJob using baseline dataset.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigPtrOutput) ExplanationBaseline() GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfig) *GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaseline {
		if v == nil {
			return nil
		}
		return v.ExplanationBaseline
	}).(GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrOutput)
}

// Output from BatchPredictionJob for Model Monitoring baseline dataset, which can be used to generate baseline attribution scores.
type GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaseline struct {
	// BigQuery location for BatchExplain output.
	Bigquery *GoogleCloudAiplatformV1beta1BigQueryDestination `pulumi:"bigquery"`
	// Cloud Storage location for BatchExplain output.
	Gcs *GoogleCloudAiplatformV1beta1GcsDestination `pulumi:"gcs"`
	// The storage format of the predictions generated BatchPrediction job.
	PredictionFormat *GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePredictionFormat `pulumi:"predictionFormat"`
}

// GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineInput is an input type that accepts GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineArgs and GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineInput` via:
//
//	GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineArgs{...}
type GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineOutput() GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineOutput
	ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineOutput
}

// Output from BatchPredictionJob for Model Monitoring baseline dataset, which can be used to generate baseline attribution scores.
type GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineArgs struct {
	// BigQuery location for BatchExplain output.
	Bigquery GoogleCloudAiplatformV1beta1BigQueryDestinationPtrInput `pulumi:"bigquery"`
	// Cloud Storage location for BatchExplain output.
	Gcs GoogleCloudAiplatformV1beta1GcsDestinationPtrInput `pulumi:"gcs"`
	// The storage format of the predictions generated BatchPrediction job.
	PredictionFormat GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePredictionFormatPtrInput `pulumi:"predictionFormat"`
}

func (GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaseline)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineArgs) ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineOutput() GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineOutput {
	return i.ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineArgs) ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineOutput)
}

func (i GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineArgs) ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrOutput() GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineArgs) ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineOutput).ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrInput is an input type that accepts GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineArgs, GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtr and GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrOutput() GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrOutput
	ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrOutput
}

type googleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrType GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineArgs

func GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtr(v *GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineArgs) GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrInput {
	return (*googleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrType)(v)
}

func (*googleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaseline)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrType) ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrOutput() GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrType) ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrOutput)
}

// Output from BatchPredictionJob for Model Monitoring baseline dataset, which can be used to generate baseline attribution scores.
type GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaseline)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineOutput) ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineOutput() GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineOutput) ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineOutput) ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrOutput() GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineOutput) ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaseline) *GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaseline {
		return &v
	}).(GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrOutput)
}

// BigQuery location for BatchExplain output.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineOutput) Bigquery() GoogleCloudAiplatformV1beta1BigQueryDestinationPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaseline) *GoogleCloudAiplatformV1beta1BigQueryDestination {
		return v.Bigquery
	}).(GoogleCloudAiplatformV1beta1BigQueryDestinationPtrOutput)
}

// Cloud Storage location for BatchExplain output.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineOutput) Gcs() GoogleCloudAiplatformV1beta1GcsDestinationPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaseline) *GoogleCloudAiplatformV1beta1GcsDestination {
		return v.Gcs
	}).(GoogleCloudAiplatformV1beta1GcsDestinationPtrOutput)
}

// The storage format of the predictions generated BatchPrediction job.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineOutput) PredictionFormat() GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePredictionFormatPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaseline) *GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePredictionFormat {
		return v.PredictionFormat
	}).(GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePredictionFormatPtrOutput)
}

type GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaseline)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrOutput) ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrOutput() GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrOutput) ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrOutput) Elem() GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaseline) GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaseline {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaseline
		return ret
	}).(GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineOutput)
}

// BigQuery location for BatchExplain output.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrOutput) Bigquery() GoogleCloudAiplatformV1beta1BigQueryDestinationPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaseline) *GoogleCloudAiplatformV1beta1BigQueryDestination {
		if v == nil {
			return nil
		}
		return v.Bigquery
	}).(GoogleCloudAiplatformV1beta1BigQueryDestinationPtrOutput)
}

// Cloud Storage location for BatchExplain output.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrOutput) Gcs() GoogleCloudAiplatformV1beta1GcsDestinationPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaseline) *GoogleCloudAiplatformV1beta1GcsDestination {
		if v == nil {
			return nil
		}
		return v.Gcs
	}).(GoogleCloudAiplatformV1beta1GcsDestinationPtrOutput)
}

// The storage format of the predictions generated BatchPrediction job.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrOutput) PredictionFormat() GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePredictionFormatPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaseline) *GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePredictionFormat {
		if v == nil {
			return nil
		}
		return v.PredictionFormat
	}).(GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePredictionFormatPtrOutput)
}

// Output from BatchPredictionJob for Model Monitoring baseline dataset, which can be used to generate baseline attribution scores.
type GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineResponse struct {
	// BigQuery location for BatchExplain output.
	Bigquery GoogleCloudAiplatformV1beta1BigQueryDestinationResponse `pulumi:"bigquery"`
	// Cloud Storage location for BatchExplain output.
	Gcs GoogleCloudAiplatformV1beta1GcsDestinationResponse `pulumi:"gcs"`
	// The storage format of the predictions generated BatchPrediction job.
	PredictionFormat string `pulumi:"predictionFormat"`
}

// Output from BatchPredictionJob for Model Monitoring baseline dataset, which can be used to generate baseline attribution scores.
type GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineResponseOutput) ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineResponseOutput() GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineResponseOutput) ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineResponseOutput {
	return o
}

// BigQuery location for BatchExplain output.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineResponseOutput) Bigquery() GoogleCloudAiplatformV1beta1BigQueryDestinationResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineResponse) GoogleCloudAiplatformV1beta1BigQueryDestinationResponse {
		return v.Bigquery
	}).(GoogleCloudAiplatformV1beta1BigQueryDestinationResponseOutput)
}

// Cloud Storage location for BatchExplain output.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineResponseOutput) Gcs() GoogleCloudAiplatformV1beta1GcsDestinationResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineResponse) GoogleCloudAiplatformV1beta1GcsDestinationResponse {
		return v.Gcs
	}).(GoogleCloudAiplatformV1beta1GcsDestinationResponseOutput)
}

// The storage format of the predictions generated BatchPrediction job.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineResponseOutput) PredictionFormat() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineResponse) string {
		return v.PredictionFormat
	}).(pulumi.StringOutput)
}

// The config for integrating with Vertex Explainable AI. Only applicable if the Model has explanation_spec populated.
type GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigResponse struct {
	// If want to analyze the Vertex Explainable AI feature attribute scores or not. If set to true, Vertex AI will log the feature attributions from explain response and do the skew/drift detection for them.
	EnableFeatureAttributes bool `pulumi:"enableFeatureAttributes"`
	// Predictions generated by the BatchPredictionJob using baseline dataset.
	ExplanationBaseline GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineResponse `pulumi:"explanationBaseline"`
}

// The config for integrating with Vertex Explainable AI. Only applicable if the Model has explanation_spec populated.
type GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigResponseOutput) ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigResponseOutput() GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigResponseOutput) ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigResponseOutput {
	return o
}

// If want to analyze the Vertex Explainable AI feature attribute scores or not. If set to true, Vertex AI will log the feature attributions from explain response and do the skew/drift detection for them.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigResponseOutput) EnableFeatureAttributes() pulumi.BoolOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigResponse) bool {
		return v.EnableFeatureAttributes
	}).(pulumi.BoolOutput)
}

// Predictions generated by the BatchPredictionJob using baseline dataset.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigResponseOutput) ExplanationBaseline() GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigResponse) GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineResponse {
		return v.ExplanationBaseline
	}).(GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineResponseOutput)
}

// The config for Prediction data drift detection.
type GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfig struct {
	// Key is the feature name and value is the threshold. The threshold here is against attribution score distance between different time windows.
	AttributionScoreDriftThresholds *GoogleCloudAiplatformV1beta1ThresholdConfig `pulumi:"attributionScoreDriftThresholds"`
	// Drift anomaly detection threshold used by all features. When the per-feature thresholds are not set, this field can be used to specify a threshold for all features.
	DefaultDriftThreshold *GoogleCloudAiplatformV1beta1ThresholdConfig `pulumi:"defaultDriftThreshold"`
	// Key is the feature name and value is the threshold. If a feature needs to be monitored for drift, a value threshold must be configured for that feature. The threshold here is against feature distribution distance between different time windws.
	DriftThresholds *GoogleCloudAiplatformV1beta1ThresholdConfig `pulumi:"driftThresholds"`
}

// GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigInput is an input type that accepts GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigArgs and GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigInput` via:
//
//	GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigArgs{...}
type GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigOutput() GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigOutput
	ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigOutput
}

// The config for Prediction data drift detection.
type GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigArgs struct {
	// Key is the feature name and value is the threshold. The threshold here is against attribution score distance between different time windows.
	AttributionScoreDriftThresholds GoogleCloudAiplatformV1beta1ThresholdConfigPtrInput `pulumi:"attributionScoreDriftThresholds"`
	// Drift anomaly detection threshold used by all features. When the per-feature thresholds are not set, this field can be used to specify a threshold for all features.
	DefaultDriftThreshold GoogleCloudAiplatformV1beta1ThresholdConfigPtrInput `pulumi:"defaultDriftThreshold"`
	// Key is the feature name and value is the threshold. If a feature needs to be monitored for drift, a value threshold must be configured for that feature. The threshold here is against feature distribution distance between different time windws.
	DriftThresholds GoogleCloudAiplatformV1beta1ThresholdConfigPtrInput `pulumi:"driftThresholds"`
}

func (GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfig)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigArgs) ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigOutput() GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigOutput {
	return i.ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigArgs) ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigOutput)
}

func (i GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigArgs) ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrOutput() GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigArgs) ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigOutput).ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigArgs, GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtr and GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrOutput() GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrOutput
	ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrOutput
}

type googleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrType GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigArgs

func GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtr(v *GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigArgs) GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrInput {
	return (*googleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrType)(v)
}

func (*googleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfig)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrType) ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrOutput() GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrType) ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrOutput)
}

// The config for Prediction data drift detection.
type GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigOutput) ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigOutput() GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigOutput) ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigOutput) ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrOutput() GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigOutput) ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfig) *GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfig {
		return &v
	}).(GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrOutput)
}

// Key is the feature name and value is the threshold. The threshold here is against attribution score distance between different time windows.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigOutput) AttributionScoreDriftThresholds() GoogleCloudAiplatformV1beta1ThresholdConfigPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfig) *GoogleCloudAiplatformV1beta1ThresholdConfig {
		return v.AttributionScoreDriftThresholds
	}).(GoogleCloudAiplatformV1beta1ThresholdConfigPtrOutput)
}

// Drift anomaly detection threshold used by all features. When the per-feature thresholds are not set, this field can be used to specify a threshold for all features.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigOutput) DefaultDriftThreshold() GoogleCloudAiplatformV1beta1ThresholdConfigPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfig) *GoogleCloudAiplatformV1beta1ThresholdConfig {
		return v.DefaultDriftThreshold
	}).(GoogleCloudAiplatformV1beta1ThresholdConfigPtrOutput)
}

// Key is the feature name and value is the threshold. If a feature needs to be monitored for drift, a value threshold must be configured for that feature. The threshold here is against feature distribution distance between different time windws.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigOutput) DriftThresholds() GoogleCloudAiplatformV1beta1ThresholdConfigPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfig) *GoogleCloudAiplatformV1beta1ThresholdConfig {
		return v.DriftThresholds
	}).(GoogleCloudAiplatformV1beta1ThresholdConfigPtrOutput)
}

type GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrOutput) ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrOutput() GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrOutput) ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrOutput) Elem() GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfig) GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfig {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfig
		return ret
	}).(GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigOutput)
}

// Key is the feature name and value is the threshold. The threshold here is against attribution score distance between different time windows.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrOutput) AttributionScoreDriftThresholds() GoogleCloudAiplatformV1beta1ThresholdConfigPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfig) *GoogleCloudAiplatformV1beta1ThresholdConfig {
		if v == nil {
			return nil
		}
		return v.AttributionScoreDriftThresholds
	}).(GoogleCloudAiplatformV1beta1ThresholdConfigPtrOutput)
}

// Drift anomaly detection threshold used by all features. When the per-feature thresholds are not set, this field can be used to specify a threshold for all features.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrOutput) DefaultDriftThreshold() GoogleCloudAiplatformV1beta1ThresholdConfigPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfig) *GoogleCloudAiplatformV1beta1ThresholdConfig {
		if v == nil {
			return nil
		}
		return v.DefaultDriftThreshold
	}).(GoogleCloudAiplatformV1beta1ThresholdConfigPtrOutput)
}

// Key is the feature name and value is the threshold. If a feature needs to be monitored for drift, a value threshold must be configured for that feature. The threshold here is against feature distribution distance between different time windws.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrOutput) DriftThresholds() GoogleCloudAiplatformV1beta1ThresholdConfigPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfig) *GoogleCloudAiplatformV1beta1ThresholdConfig {
		if v == nil {
			return nil
		}
		return v.DriftThresholds
	}).(GoogleCloudAiplatformV1beta1ThresholdConfigPtrOutput)
}

// The config for Prediction data drift detection.
type GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigResponse struct {
	// Key is the feature name and value is the threshold. The threshold here is against attribution score distance between different time windows.
	AttributionScoreDriftThresholds GoogleCloudAiplatformV1beta1ThresholdConfigResponse `pulumi:"attributionScoreDriftThresholds"`
	// Drift anomaly detection threshold used by all features. When the per-feature thresholds are not set, this field can be used to specify a threshold for all features.
	DefaultDriftThreshold GoogleCloudAiplatformV1beta1ThresholdConfigResponse `pulumi:"defaultDriftThreshold"`
	// Key is the feature name and value is the threshold. If a feature needs to be monitored for drift, a value threshold must be configured for that feature. The threshold here is against feature distribution distance between different time windws.
	DriftThresholds GoogleCloudAiplatformV1beta1ThresholdConfigResponse `pulumi:"driftThresholds"`
}

// The config for Prediction data drift detection.
type GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigResponseOutput) ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigResponseOutput() GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigResponseOutput) ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigResponseOutput {
	return o
}

// Key is the feature name and value is the threshold. The threshold here is against attribution score distance between different time windows.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigResponseOutput) AttributionScoreDriftThresholds() GoogleCloudAiplatformV1beta1ThresholdConfigResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigResponse) GoogleCloudAiplatformV1beta1ThresholdConfigResponse {
		return v.AttributionScoreDriftThresholds
	}).(GoogleCloudAiplatformV1beta1ThresholdConfigResponseOutput)
}

// Drift anomaly detection threshold used by all features. When the per-feature thresholds are not set, this field can be used to specify a threshold for all features.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigResponseOutput) DefaultDriftThreshold() GoogleCloudAiplatformV1beta1ThresholdConfigResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigResponse) GoogleCloudAiplatformV1beta1ThresholdConfigResponse {
		return v.DefaultDriftThreshold
	}).(GoogleCloudAiplatformV1beta1ThresholdConfigResponseOutput)
}

// Key is the feature name and value is the threshold. If a feature needs to be monitored for drift, a value threshold must be configured for that feature. The threshold here is against feature distribution distance between different time windws.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigResponseOutput) DriftThresholds() GoogleCloudAiplatformV1beta1ThresholdConfigResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigResponse) GoogleCloudAiplatformV1beta1ThresholdConfigResponse {
		return v.DriftThresholds
	}).(GoogleCloudAiplatformV1beta1ThresholdConfigResponseOutput)
}

// The objective configuration for model monitoring, including the information needed to detect anomalies for one particular model.
type GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigResponse struct {
	// The config for integrating with Vertex Explainable AI.
	ExplanationConfig GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigResponse `pulumi:"explanationConfig"`
	// The config for drift of prediction data.
	PredictionDriftDetectionConfig GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigResponse `pulumi:"predictionDriftDetectionConfig"`
	// Training dataset for models. This field has to be set only if TrainingPredictionSkewDetectionConfig is specified.
	TrainingDataset GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetResponse `pulumi:"trainingDataset"`
	// The config for skew between training data and prediction data.
	TrainingPredictionSkewDetectionConfig GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigResponse `pulumi:"trainingPredictionSkewDetectionConfig"`
}

// The objective configuration for model monitoring, including the information needed to detect anomalies for one particular model.
type GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigResponseOutput) ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigResponseOutput() GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigResponseOutput) ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigResponseOutput {
	return o
}

// The config for integrating with Vertex Explainable AI.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigResponseOutput) ExplanationConfig() GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigResponse) GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigResponse {
		return v.ExplanationConfig
	}).(GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigResponseOutput)
}

// The config for drift of prediction data.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigResponseOutput) PredictionDriftDetectionConfig() GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigResponse) GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigResponse {
		return v.PredictionDriftDetectionConfig
	}).(GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigResponseOutput)
}

// Training dataset for models. This field has to be set only if TrainingPredictionSkewDetectionConfig is specified.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigResponseOutput) TrainingDataset() GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigResponse) GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetResponse {
		return v.TrainingDataset
	}).(GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetResponseOutput)
}

// The config for skew between training data and prediction data.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigResponseOutput) TrainingPredictionSkewDetectionConfig() GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigResponse) GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigResponse {
		return v.TrainingPredictionSkewDetectionConfig
	}).(GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigResponseOutput)
}

type GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigResponseArrayOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigResponseArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigResponseArrayOutput) ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigResponseArrayOutput() GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigResponseArrayOutput) ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigResponseArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigResponseArrayOutput) Index(i pulumi.IntInput) GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigResponseOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigResponse {
		return vs[0].([]GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigResponse)[vs[1].(int)]
	}).(GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigResponseOutput)
}

// Training Dataset information.
type GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDataset struct {
	// The BigQuery table of the unmanaged Dataset used to train this Model.
	BigquerySource *GoogleCloudAiplatformV1beta1BigQuerySource `pulumi:"bigquerySource"`
	// Data format of the dataset, only applicable if the input is from Google Cloud Storage. The possible formats are: "tf-record" The source file is a TFRecord file. "csv" The source file is a CSV file. "jsonl" The source file is a JSONL file.
	DataFormat *string `pulumi:"dataFormat"`
	// The resource name of the Dataset used to train this Model.
	Dataset *string `pulumi:"dataset"`
	// The Google Cloud Storage uri of the unmanaged Dataset used to train this Model.
	GcsSource *GoogleCloudAiplatformV1beta1GcsSource `pulumi:"gcsSource"`
	// Strategy to sample data from Training Dataset. If not set, we process the whole dataset.
	LoggingSamplingStrategy *GoogleCloudAiplatformV1beta1SamplingStrategy `pulumi:"loggingSamplingStrategy"`
	// The target field name the model is to predict. This field will be excluded when doing Predict and (or) Explain for the training data.
	TargetField *string `pulumi:"targetField"`
}

// GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetInput is an input type that accepts GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetArgs and GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetInput` via:
//
//	GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetArgs{...}
type GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetOutput() GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetOutput
	ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetOutput
}

// Training Dataset information.
type GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetArgs struct {
	// The BigQuery table of the unmanaged Dataset used to train this Model.
	BigquerySource GoogleCloudAiplatformV1beta1BigQuerySourcePtrInput `pulumi:"bigquerySource"`
	// Data format of the dataset, only applicable if the input is from Google Cloud Storage. The possible formats are: "tf-record" The source file is a TFRecord file. "csv" The source file is a CSV file. "jsonl" The source file is a JSONL file.
	DataFormat pulumi.StringPtrInput `pulumi:"dataFormat"`
	// The resource name of the Dataset used to train this Model.
	Dataset pulumi.StringPtrInput `pulumi:"dataset"`
	// The Google Cloud Storage uri of the unmanaged Dataset used to train this Model.
	GcsSource GoogleCloudAiplatformV1beta1GcsSourcePtrInput `pulumi:"gcsSource"`
	// Strategy to sample data from Training Dataset. If not set, we process the whole dataset.
	LoggingSamplingStrategy GoogleCloudAiplatformV1beta1SamplingStrategyPtrInput `pulumi:"loggingSamplingStrategy"`
	// The target field name the model is to predict. This field will be excluded when doing Predict and (or) Explain for the training data.
	TargetField pulumi.StringPtrInput `pulumi:"targetField"`
}

func (GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDataset)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetArgs) ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetOutput() GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetOutput {
	return i.ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetArgs) ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetOutput)
}

func (i GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetArgs) ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetPtrOutput() GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetArgs) ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetOutput).ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetArgs, GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetPtr and GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetPtrOutput() GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetPtrOutput
	ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetPtrOutput
}

type googleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetPtrType GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetArgs

func GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetPtr(v *GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetArgs) GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetPtrInput {
	return (*googleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetPtrType)(v)
}

func (*googleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDataset)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetPtrType) ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetPtrOutput() GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetPtrType) ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetPtrOutput)
}

// Training Dataset information.
type GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDataset)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetOutput) ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetOutput() GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetOutput) ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetOutput) ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetPtrOutput() GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetOutput) ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDataset) *GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDataset {
		return &v
	}).(GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetPtrOutput)
}

// The BigQuery table of the unmanaged Dataset used to train this Model.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetOutput) BigquerySource() GoogleCloudAiplatformV1beta1BigQuerySourcePtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDataset) *GoogleCloudAiplatformV1beta1BigQuerySource {
		return v.BigquerySource
	}).(GoogleCloudAiplatformV1beta1BigQuerySourcePtrOutput)
}

// Data format of the dataset, only applicable if the input is from Google Cloud Storage. The possible formats are: "tf-record" The source file is a TFRecord file. "csv" The source file is a CSV file. "jsonl" The source file is a JSONL file.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetOutput) DataFormat() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDataset) *string {
		return v.DataFormat
	}).(pulumi.StringPtrOutput)
}

// The resource name of the Dataset used to train this Model.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetOutput) Dataset() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDataset) *string {
		return v.Dataset
	}).(pulumi.StringPtrOutput)
}

// The Google Cloud Storage uri of the unmanaged Dataset used to train this Model.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetOutput) GcsSource() GoogleCloudAiplatformV1beta1GcsSourcePtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDataset) *GoogleCloudAiplatformV1beta1GcsSource {
		return v.GcsSource
	}).(GoogleCloudAiplatformV1beta1GcsSourcePtrOutput)
}

// Strategy to sample data from Training Dataset. If not set, we process the whole dataset.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetOutput) LoggingSamplingStrategy() GoogleCloudAiplatformV1beta1SamplingStrategyPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDataset) *GoogleCloudAiplatformV1beta1SamplingStrategy {
		return v.LoggingSamplingStrategy
	}).(GoogleCloudAiplatformV1beta1SamplingStrategyPtrOutput)
}

// The target field name the model is to predict. This field will be excluded when doing Predict and (or) Explain for the training data.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetOutput) TargetField() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDataset) *string {
		return v.TargetField
	}).(pulumi.StringPtrOutput)
}

type GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDataset)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetPtrOutput) ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetPtrOutput() GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetPtrOutput) ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetPtrOutput) Elem() GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDataset) GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDataset {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDataset
		return ret
	}).(GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetOutput)
}

// The BigQuery table of the unmanaged Dataset used to train this Model.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetPtrOutput) BigquerySource() GoogleCloudAiplatformV1beta1BigQuerySourcePtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDataset) *GoogleCloudAiplatformV1beta1BigQuerySource {
		if v == nil {
			return nil
		}
		return v.BigquerySource
	}).(GoogleCloudAiplatformV1beta1BigQuerySourcePtrOutput)
}

// Data format of the dataset, only applicable if the input is from Google Cloud Storage. The possible formats are: "tf-record" The source file is a TFRecord file. "csv" The source file is a CSV file. "jsonl" The source file is a JSONL file.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetPtrOutput) DataFormat() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDataset) *string {
		if v == nil {
			return nil
		}
		return v.DataFormat
	}).(pulumi.StringPtrOutput)
}

// The resource name of the Dataset used to train this Model.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetPtrOutput) Dataset() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDataset) *string {
		if v == nil {
			return nil
		}
		return v.Dataset
	}).(pulumi.StringPtrOutput)
}

// The Google Cloud Storage uri of the unmanaged Dataset used to train this Model.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetPtrOutput) GcsSource() GoogleCloudAiplatformV1beta1GcsSourcePtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDataset) *GoogleCloudAiplatformV1beta1GcsSource {
		if v == nil {
			return nil
		}
		return v.GcsSource
	}).(GoogleCloudAiplatformV1beta1GcsSourcePtrOutput)
}

// Strategy to sample data from Training Dataset. If not set, we process the whole dataset.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetPtrOutput) LoggingSamplingStrategy() GoogleCloudAiplatformV1beta1SamplingStrategyPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDataset) *GoogleCloudAiplatformV1beta1SamplingStrategy {
		if v == nil {
			return nil
		}
		return v.LoggingSamplingStrategy
	}).(GoogleCloudAiplatformV1beta1SamplingStrategyPtrOutput)
}

// The target field name the model is to predict. This field will be excluded when doing Predict and (or) Explain for the training data.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetPtrOutput) TargetField() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDataset) *string {
		if v == nil {
			return nil
		}
		return v.TargetField
	}).(pulumi.StringPtrOutput)
}

// Training Dataset information.
type GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetResponse struct {
	// The BigQuery table of the unmanaged Dataset used to train this Model.
	BigquerySource GoogleCloudAiplatformV1beta1BigQuerySourceResponse `pulumi:"bigquerySource"`
	// Data format of the dataset, only applicable if the input is from Google Cloud Storage. The possible formats are: "tf-record" The source file is a TFRecord file. "csv" The source file is a CSV file. "jsonl" The source file is a JSONL file.
	DataFormat string `pulumi:"dataFormat"`
	// The resource name of the Dataset used to train this Model.
	Dataset string `pulumi:"dataset"`
	// The Google Cloud Storage uri of the unmanaged Dataset used to train this Model.
	GcsSource GoogleCloudAiplatformV1beta1GcsSourceResponse `pulumi:"gcsSource"`
	// Strategy to sample data from Training Dataset. If not set, we process the whole dataset.
	LoggingSamplingStrategy GoogleCloudAiplatformV1beta1SamplingStrategyResponse `pulumi:"loggingSamplingStrategy"`
	// The target field name the model is to predict. This field will be excluded when doing Predict and (or) Explain for the training data.
	TargetField string `pulumi:"targetField"`
}

// Training Dataset information.
type GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetResponseOutput) ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetResponseOutput() GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetResponseOutput) ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetResponseOutput {
	return o
}

// The BigQuery table of the unmanaged Dataset used to train this Model.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetResponseOutput) BigquerySource() GoogleCloudAiplatformV1beta1BigQuerySourceResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetResponse) GoogleCloudAiplatformV1beta1BigQuerySourceResponse {
		return v.BigquerySource
	}).(GoogleCloudAiplatformV1beta1BigQuerySourceResponseOutput)
}

// Data format of the dataset, only applicable if the input is from Google Cloud Storage. The possible formats are: "tf-record" The source file is a TFRecord file. "csv" The source file is a CSV file. "jsonl" The source file is a JSONL file.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetResponseOutput) DataFormat() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetResponse) string {
		return v.DataFormat
	}).(pulumi.StringOutput)
}

// The resource name of the Dataset used to train this Model.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetResponseOutput) Dataset() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetResponse) string {
		return v.Dataset
	}).(pulumi.StringOutput)
}

// The Google Cloud Storage uri of the unmanaged Dataset used to train this Model.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetResponseOutput) GcsSource() GoogleCloudAiplatformV1beta1GcsSourceResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetResponse) GoogleCloudAiplatformV1beta1GcsSourceResponse {
		return v.GcsSource
	}).(GoogleCloudAiplatformV1beta1GcsSourceResponseOutput)
}

// Strategy to sample data from Training Dataset. If not set, we process the whole dataset.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetResponseOutput) LoggingSamplingStrategy() GoogleCloudAiplatformV1beta1SamplingStrategyResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetResponse) GoogleCloudAiplatformV1beta1SamplingStrategyResponse {
		return v.LoggingSamplingStrategy
	}).(GoogleCloudAiplatformV1beta1SamplingStrategyResponseOutput)
}

// The target field name the model is to predict. This field will be excluded when doing Predict and (or) Explain for the training data.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetResponseOutput) TargetField() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetResponse) string {
		return v.TargetField
	}).(pulumi.StringOutput)
}

// The config for Training & Prediction data skew detection. It specifies the training dataset sources and the skew detection parameters.
type GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfig struct {
	// Key is the feature name and value is the threshold. The threshold here is against attribution score distance between the training and prediction feature.
	AttributionScoreSkewThresholds *GoogleCloudAiplatformV1beta1ThresholdConfig `pulumi:"attributionScoreSkewThresholds"`
	// Skew anomaly detection threshold used by all features. When the per-feature thresholds are not set, this field can be used to specify a threshold for all features.
	DefaultSkewThreshold *GoogleCloudAiplatformV1beta1ThresholdConfig `pulumi:"defaultSkewThreshold"`
	// Key is the feature name and value is the threshold. If a feature needs to be monitored for skew, a value threshold must be configured for that feature. The threshold here is against feature distribution distance between the training and prediction feature.
	SkewThresholds *GoogleCloudAiplatformV1beta1ThresholdConfig `pulumi:"skewThresholds"`
}

// GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigInput is an input type that accepts GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigArgs and GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigInput` via:
//
//	GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigArgs{...}
type GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigOutput() GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigOutput
	ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigOutput
}

// The config for Training & Prediction data skew detection. It specifies the training dataset sources and the skew detection parameters.
type GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigArgs struct {
	// Key is the feature name and value is the threshold. The threshold here is against attribution score distance between the training and prediction feature.
	AttributionScoreSkewThresholds GoogleCloudAiplatformV1beta1ThresholdConfigPtrInput `pulumi:"attributionScoreSkewThresholds"`
	// Skew anomaly detection threshold used by all features. When the per-feature thresholds are not set, this field can be used to specify a threshold for all features.
	DefaultSkewThreshold GoogleCloudAiplatformV1beta1ThresholdConfigPtrInput `pulumi:"defaultSkewThreshold"`
	// Key is the feature name and value is the threshold. If a feature needs to be monitored for skew, a value threshold must be configured for that feature. The threshold here is against feature distribution distance between the training and prediction feature.
	SkewThresholds GoogleCloudAiplatformV1beta1ThresholdConfigPtrInput `pulumi:"skewThresholds"`
}

func (GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfig)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigArgs) ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigOutput() GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigOutput {
	return i.ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigArgs) ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigOutput)
}

func (i GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigArgs) ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrOutput() GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigArgs) ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigOutput).ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigArgs, GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtr and GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrOutput() GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrOutput
	ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrOutput
}

type googleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrType GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigArgs

func GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtr(v *GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigArgs) GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrInput {
	return (*googleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrType)(v)
}

func (*googleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfig)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrType) ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrOutput() GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrType) ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrOutput)
}

// The config for Training & Prediction data skew detection. It specifies the training dataset sources and the skew detection parameters.
type GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigOutput) ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigOutput() GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigOutput) ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigOutput) ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrOutput() GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigOutput) ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfig) *GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfig {
		return &v
	}).(GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrOutput)
}

// Key is the feature name and value is the threshold. The threshold here is against attribution score distance between the training and prediction feature.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigOutput) AttributionScoreSkewThresholds() GoogleCloudAiplatformV1beta1ThresholdConfigPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfig) *GoogleCloudAiplatformV1beta1ThresholdConfig {
		return v.AttributionScoreSkewThresholds
	}).(GoogleCloudAiplatformV1beta1ThresholdConfigPtrOutput)
}

// Skew anomaly detection threshold used by all features. When the per-feature thresholds are not set, this field can be used to specify a threshold for all features.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigOutput) DefaultSkewThreshold() GoogleCloudAiplatformV1beta1ThresholdConfigPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfig) *GoogleCloudAiplatformV1beta1ThresholdConfig {
		return v.DefaultSkewThreshold
	}).(GoogleCloudAiplatformV1beta1ThresholdConfigPtrOutput)
}

// Key is the feature name and value is the threshold. If a feature needs to be monitored for skew, a value threshold must be configured for that feature. The threshold here is against feature distribution distance between the training and prediction feature.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigOutput) SkewThresholds() GoogleCloudAiplatformV1beta1ThresholdConfigPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfig) *GoogleCloudAiplatformV1beta1ThresholdConfig {
		return v.SkewThresholds
	}).(GoogleCloudAiplatformV1beta1ThresholdConfigPtrOutput)
}

type GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrOutput) ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrOutput() GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrOutput) ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrOutput) Elem() GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfig) GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfig {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfig
		return ret
	}).(GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigOutput)
}

// Key is the feature name and value is the threshold. The threshold here is against attribution score distance between the training and prediction feature.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrOutput) AttributionScoreSkewThresholds() GoogleCloudAiplatformV1beta1ThresholdConfigPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfig) *GoogleCloudAiplatformV1beta1ThresholdConfig {
		if v == nil {
			return nil
		}
		return v.AttributionScoreSkewThresholds
	}).(GoogleCloudAiplatformV1beta1ThresholdConfigPtrOutput)
}

// Skew anomaly detection threshold used by all features. When the per-feature thresholds are not set, this field can be used to specify a threshold for all features.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrOutput) DefaultSkewThreshold() GoogleCloudAiplatformV1beta1ThresholdConfigPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfig) *GoogleCloudAiplatformV1beta1ThresholdConfig {
		if v == nil {
			return nil
		}
		return v.DefaultSkewThreshold
	}).(GoogleCloudAiplatformV1beta1ThresholdConfigPtrOutput)
}

// Key is the feature name and value is the threshold. If a feature needs to be monitored for skew, a value threshold must be configured for that feature. The threshold here is against feature distribution distance between the training and prediction feature.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrOutput) SkewThresholds() GoogleCloudAiplatformV1beta1ThresholdConfigPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfig) *GoogleCloudAiplatformV1beta1ThresholdConfig {
		if v == nil {
			return nil
		}
		return v.SkewThresholds
	}).(GoogleCloudAiplatformV1beta1ThresholdConfigPtrOutput)
}

// The config for Training & Prediction data skew detection. It specifies the training dataset sources and the skew detection parameters.
type GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigResponse struct {
	// Key is the feature name and value is the threshold. The threshold here is against attribution score distance between the training and prediction feature.
	AttributionScoreSkewThresholds GoogleCloudAiplatformV1beta1ThresholdConfigResponse `pulumi:"attributionScoreSkewThresholds"`
	// Skew anomaly detection threshold used by all features. When the per-feature thresholds are not set, this field can be used to specify a threshold for all features.
	DefaultSkewThreshold GoogleCloudAiplatformV1beta1ThresholdConfigResponse `pulumi:"defaultSkewThreshold"`
	// Key is the feature name and value is the threshold. If a feature needs to be monitored for skew, a value threshold must be configured for that feature. The threshold here is against feature distribution distance between the training and prediction feature.
	SkewThresholds GoogleCloudAiplatformV1beta1ThresholdConfigResponse `pulumi:"skewThresholds"`
}

// The config for Training & Prediction data skew detection. It specifies the training dataset sources and the skew detection parameters.
type GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigResponseOutput) ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigResponseOutput() GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigResponseOutput) ToGoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigResponseOutput {
	return o
}

// Key is the feature name and value is the threshold. The threshold here is against attribution score distance between the training and prediction feature.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigResponseOutput) AttributionScoreSkewThresholds() GoogleCloudAiplatformV1beta1ThresholdConfigResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigResponse) GoogleCloudAiplatformV1beta1ThresholdConfigResponse {
		return v.AttributionScoreSkewThresholds
	}).(GoogleCloudAiplatformV1beta1ThresholdConfigResponseOutput)
}

// Skew anomaly detection threshold used by all features. When the per-feature thresholds are not set, this field can be used to specify a threshold for all features.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigResponseOutput) DefaultSkewThreshold() GoogleCloudAiplatformV1beta1ThresholdConfigResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigResponse) GoogleCloudAiplatformV1beta1ThresholdConfigResponse {
		return v.DefaultSkewThreshold
	}).(GoogleCloudAiplatformV1beta1ThresholdConfigResponseOutput)
}

// Key is the feature name and value is the threshold. If a feature needs to be monitored for skew, a value threshold must be configured for that feature. The threshold here is against feature distribution distance between the training and prediction feature.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigResponseOutput) SkewThresholds() GoogleCloudAiplatformV1beta1ThresholdConfigResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigResponse) GoogleCloudAiplatformV1beta1ThresholdConfigResponse {
		return v.SkewThresholds
	}).(GoogleCloudAiplatformV1beta1ThresholdConfigResponseOutput)
}

// Statistics and anomalies generated by Model Monitoring.
type GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomalies struct {
	// Number of anomalies within all stats.
	AnomalyCount *int `pulumi:"anomalyCount"`
	// Deployed Model ID.
	DeployedModelId *string `pulumi:"deployedModelId"`
	// A list of historical Stats and Anomalies generated for all Features.
	FeatureStats []GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomalies `pulumi:"featureStats"`
	// Model Monitoring Objective those stats and anomalies belonging to.
	Objective *GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesObjective `pulumi:"objective"`
}

// GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesInput is an input type that accepts GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesArgs and GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesInput` via:
//
//	GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesArgs{...}
type GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesOutput() GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesOutput
	ToGoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesOutput
}

// Statistics and anomalies generated by Model Monitoring.
type GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesArgs struct {
	// Number of anomalies within all stats.
	AnomalyCount pulumi.IntPtrInput `pulumi:"anomalyCount"`
	// Deployed Model ID.
	DeployedModelId pulumi.StringPtrInput `pulumi:"deployedModelId"`
	// A list of historical Stats and Anomalies generated for all Features.
	FeatureStats GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesArrayInput `pulumi:"featureStats"`
	// Model Monitoring Objective those stats and anomalies belonging to.
	Objective GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesObjectivePtrInput `pulumi:"objective"`
}

func (GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomalies)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesArgs) ToGoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesOutput() GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesOutput {
	return i.ToGoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesArgs) ToGoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesOutput)
}

// GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesArrayInput is an input type that accepts GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesArray and GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesArrayOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesArrayInput` via:
//
//	GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesArray{ GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesArgs{...} }
type GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesArrayInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesArrayOutput() GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesArrayOutput
	ToGoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesArrayOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesArrayOutput
}

type GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesArray []GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesInput

func (GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomalies)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesArray) ToGoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesArrayOutput() GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesArrayOutput {
	return i.ToGoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesArrayOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesArray) ToGoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesArrayOutput)
}

// Statistics and anomalies generated by Model Monitoring.
type GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomalies)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesOutput) ToGoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesOutput() GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesOutput) ToGoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesOutput {
	return o
}

// Number of anomalies within all stats.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesOutput) AnomalyCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomalies) *int { return v.AnomalyCount }).(pulumi.IntPtrOutput)
}

// Deployed Model ID.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesOutput) DeployedModelId() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomalies) *string { return v.DeployedModelId }).(pulumi.StringPtrOutput)
}

// A list of historical Stats and Anomalies generated for all Features.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesOutput) FeatureStats() GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomalies) []GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomalies {
		return v.FeatureStats
	}).(GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesArrayOutput)
}

// Model Monitoring Objective those stats and anomalies belonging to.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesOutput) Objective() GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesObjectivePtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomalies) *GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesObjective {
		return v.Objective
	}).(GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesObjectivePtrOutput)
}

type GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesArrayOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomalies)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesArrayOutput) ToGoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesArrayOutput() GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesArrayOutput) ToGoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesArrayOutput) Index(i pulumi.IntInput) GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomalies {
		return vs[0].([]GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomalies)[vs[1].(int)]
	}).(GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesOutput)
}

// Historical Stats (and Anomalies) for a specific Feature.
type GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomalies struct {
	// Display Name of the Feature.
	FeatureDisplayName *string `pulumi:"featureDisplayName"`
	// A list of historical stats generated by different time window's Prediction Dataset.
	PredictionStats []GoogleCloudAiplatformV1beta1FeatureStatsAnomaly `pulumi:"predictionStats"`
	// Threshold for anomaly detection.
	Threshold *GoogleCloudAiplatformV1beta1ThresholdConfig `pulumi:"threshold"`
	// Stats calculated for the Training Dataset.
	TrainingStats *GoogleCloudAiplatformV1beta1FeatureStatsAnomaly `pulumi:"trainingStats"`
}

// GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesInput is an input type that accepts GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesArgs and GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesInput` via:
//
//	GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesArgs{...}
type GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesOutput() GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesOutput
	ToGoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesOutput
}

// Historical Stats (and Anomalies) for a specific Feature.
type GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesArgs struct {
	// Display Name of the Feature.
	FeatureDisplayName pulumi.StringPtrInput `pulumi:"featureDisplayName"`
	// A list of historical stats generated by different time window's Prediction Dataset.
	PredictionStats GoogleCloudAiplatformV1beta1FeatureStatsAnomalyArrayInput `pulumi:"predictionStats"`
	// Threshold for anomaly detection.
	Threshold GoogleCloudAiplatformV1beta1ThresholdConfigPtrInput `pulumi:"threshold"`
	// Stats calculated for the Training Dataset.
	TrainingStats GoogleCloudAiplatformV1beta1FeatureStatsAnomalyPtrInput `pulumi:"trainingStats"`
}

func (GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomalies)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesArgs) ToGoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesOutput() GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesOutput {
	return i.ToGoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesArgs) ToGoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesOutput)
}

// GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesArrayInput is an input type that accepts GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesArray and GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesArrayOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesArrayInput` via:
//
//	GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesArray{ GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesArgs{...} }
type GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesArrayInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesArrayOutput() GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesArrayOutput
	ToGoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesArrayOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesArrayOutput
}

type GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesArray []GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesInput

func (GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomalies)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesArray) ToGoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesArrayOutput() GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesArrayOutput {
	return i.ToGoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesArrayOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesArray) ToGoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesArrayOutput)
}

// Historical Stats (and Anomalies) for a specific Feature.
type GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomalies)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesOutput) ToGoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesOutput() GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesOutput) ToGoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesOutput {
	return o
}

// Display Name of the Feature.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesOutput) FeatureDisplayName() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomalies) *string {
		return v.FeatureDisplayName
	}).(pulumi.StringPtrOutput)
}

// A list of historical stats generated by different time window's Prediction Dataset.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesOutput) PredictionStats() GoogleCloudAiplatformV1beta1FeatureStatsAnomalyArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomalies) []GoogleCloudAiplatformV1beta1FeatureStatsAnomaly {
		return v.PredictionStats
	}).(GoogleCloudAiplatformV1beta1FeatureStatsAnomalyArrayOutput)
}

// Threshold for anomaly detection.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesOutput) Threshold() GoogleCloudAiplatformV1beta1ThresholdConfigPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomalies) *GoogleCloudAiplatformV1beta1ThresholdConfig {
		return v.Threshold
	}).(GoogleCloudAiplatformV1beta1ThresholdConfigPtrOutput)
}

// Stats calculated for the Training Dataset.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesOutput) TrainingStats() GoogleCloudAiplatformV1beta1FeatureStatsAnomalyPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomalies) *GoogleCloudAiplatformV1beta1FeatureStatsAnomaly {
		return v.TrainingStats
	}).(GoogleCloudAiplatformV1beta1FeatureStatsAnomalyPtrOutput)
}

type GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesArrayOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomalies)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesArrayOutput) ToGoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesArrayOutput() GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesArrayOutput) ToGoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesArrayOutput) Index(i pulumi.IntInput) GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomalies {
		return vs[0].([]GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomalies)[vs[1].(int)]
	}).(GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesOutput)
}

// Historical Stats (and Anomalies) for a specific Feature.
type GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesResponse struct {
	// Display Name of the Feature.
	FeatureDisplayName string `pulumi:"featureDisplayName"`
	// A list of historical stats generated by different time window's Prediction Dataset.
	PredictionStats []GoogleCloudAiplatformV1beta1FeatureStatsAnomalyResponse `pulumi:"predictionStats"`
	// Threshold for anomaly detection.
	Threshold GoogleCloudAiplatformV1beta1ThresholdConfigResponse `pulumi:"threshold"`
	// Stats calculated for the Training Dataset.
	TrainingStats GoogleCloudAiplatformV1beta1FeatureStatsAnomalyResponse `pulumi:"trainingStats"`
}

// Historical Stats (and Anomalies) for a specific Feature.
type GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesResponseOutput) ToGoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesResponseOutput() GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesResponseOutput) ToGoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesResponseOutput {
	return o
}

// Display Name of the Feature.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesResponseOutput) FeatureDisplayName() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesResponse) string {
		return v.FeatureDisplayName
	}).(pulumi.StringOutput)
}

// A list of historical stats generated by different time window's Prediction Dataset.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesResponseOutput) PredictionStats() GoogleCloudAiplatformV1beta1FeatureStatsAnomalyResponseArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesResponse) []GoogleCloudAiplatformV1beta1FeatureStatsAnomalyResponse {
		return v.PredictionStats
	}).(GoogleCloudAiplatformV1beta1FeatureStatsAnomalyResponseArrayOutput)
}

// Threshold for anomaly detection.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesResponseOutput) Threshold() GoogleCloudAiplatformV1beta1ThresholdConfigResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesResponse) GoogleCloudAiplatformV1beta1ThresholdConfigResponse {
		return v.Threshold
	}).(GoogleCloudAiplatformV1beta1ThresholdConfigResponseOutput)
}

// Stats calculated for the Training Dataset.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesResponseOutput) TrainingStats() GoogleCloudAiplatformV1beta1FeatureStatsAnomalyResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesResponse) GoogleCloudAiplatformV1beta1FeatureStatsAnomalyResponse {
		return v.TrainingStats
	}).(GoogleCloudAiplatformV1beta1FeatureStatsAnomalyResponseOutput)
}

type GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesResponseArrayOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesResponseArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesResponseArrayOutput) ToGoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesResponseArrayOutput() GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesResponseArrayOutput) ToGoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesResponseArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesResponseArrayOutput) Index(i pulumi.IntInput) GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesResponseOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesResponse {
		return vs[0].([]GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesResponse)[vs[1].(int)]
	}).(GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesResponseOutput)
}

// Statistics and anomalies generated by Model Monitoring.
type GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesResponse struct {
	// Number of anomalies within all stats.
	AnomalyCount int `pulumi:"anomalyCount"`
	// Deployed Model ID.
	DeployedModelId string `pulumi:"deployedModelId"`
	// A list of historical Stats and Anomalies generated for all Features.
	FeatureStats []GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesResponse `pulumi:"featureStats"`
	// Model Monitoring Objective those stats and anomalies belonging to.
	Objective string `pulumi:"objective"`
}

// Statistics and anomalies generated by Model Monitoring.
type GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesResponseOutput) ToGoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesResponseOutput() GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesResponseOutput) ToGoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesResponseOutput {
	return o
}

// Number of anomalies within all stats.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesResponseOutput) AnomalyCount() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesResponse) int { return v.AnomalyCount }).(pulumi.IntOutput)
}

// Deployed Model ID.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesResponseOutput) DeployedModelId() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesResponse) string {
		return v.DeployedModelId
	}).(pulumi.StringOutput)
}

// A list of historical Stats and Anomalies generated for all Features.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesResponseOutput) FeatureStats() GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesResponseArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesResponse) []GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesResponse {
		return v.FeatureStats
	}).(GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesResponseArrayOutput)
}

// Model Monitoring Objective those stats and anomalies belonging to.
func (o GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesResponseOutput) Objective() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesResponse) string { return v.Objective }).(pulumi.StringOutput)
}

type GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesResponseArrayOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesResponseArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesResponseArrayOutput) ToGoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesResponseArrayOutput() GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesResponseArrayOutput) ToGoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesResponseArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesResponseArrayOutput) Index(i pulumi.IntInput) GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesResponseOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesResponse {
		return vs[0].([]GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesResponse)[vs[1].(int)]
	}).(GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesResponseOutput)
}

// Contains information about the original Model if this Model is a copy.
type GoogleCloudAiplatformV1beta1ModelOriginalModelInfoResponse struct {
	// The resource name of the Model this Model is a copy of, including the revision. Format: `projects/{project}/locations/{location}/models/{model_id}@{version_id}`
	Model string `pulumi:"model"`
}

// Contains information about the original Model if this Model is a copy.
type GoogleCloudAiplatformV1beta1ModelOriginalModelInfoResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ModelOriginalModelInfoResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ModelOriginalModelInfoResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ModelOriginalModelInfoResponseOutput) ToGoogleCloudAiplatformV1beta1ModelOriginalModelInfoResponseOutput() GoogleCloudAiplatformV1beta1ModelOriginalModelInfoResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ModelOriginalModelInfoResponseOutput) ToGoogleCloudAiplatformV1beta1ModelOriginalModelInfoResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelOriginalModelInfoResponseOutput {
	return o
}

// The resource name of the Model this Model is a copy of, including the revision. Format: `projects/{project}/locations/{location}/models/{model_id}@{version_id}`
func (o GoogleCloudAiplatformV1beta1ModelOriginalModelInfoResponseOutput) Model() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelOriginalModelInfoResponse) string { return v.Model }).(pulumi.StringOutput)
}

// A trained machine learning Model.
type GoogleCloudAiplatformV1beta1ModelResponse struct {
	// Immutable. The path to the directory containing the Model artifact and any of its supporting files. Not present for AutoML Models or Large Models.
	ArtifactUri string `pulumi:"artifactUri"`
	// Input only. The specification of the container that is to be used when deploying this Model. The specification is ingested upon ModelService.UploadModel, and all binaries it contains are copied and stored internally by Vertex AI. Not present for AutoML Models or Large Models.
	ContainerSpec GoogleCloudAiplatformV1beta1ModelContainerSpecResponse `pulumi:"containerSpec"`
	// Timestamp when this Model was uploaded into Vertex AI.
	CreateTime string `pulumi:"createTime"`
	// The pointers to DeployedModels created from this Model. Note that Model could have been deployed to Endpoints in different Locations.
	DeployedModels []GoogleCloudAiplatformV1beta1DeployedModelRefResponse `pulumi:"deployedModels"`
	// The description of the Model.
	Description string `pulumi:"description"`
	// The display name of the Model. The name can be up to 128 characters long and can consist of any UTF-8 characters.
	DisplayName string `pulumi:"displayName"`
	// Customer-managed encryption key spec for a Model. If set, this Model and all sub-resources of this Model will be secured by this key.
	EncryptionSpec GoogleCloudAiplatformV1beta1EncryptionSpecResponse `pulumi:"encryptionSpec"`
	// Used to perform consistent read-modify-write updates. If not set, a blind "overwrite" update happens.
	Etag string `pulumi:"etag"`
	// The default explanation specification for this Model. The Model can be used for requesting explanation after being deployed if it is populated. The Model can be used for batch explanation if it is populated. All fields of the explanation_spec can be overridden by explanation_spec of DeployModelRequest.deployed_model, or explanation_spec of BatchPredictionJob. If the default explanation specification is not set for this Model, this Model can still be used for requesting explanation by setting explanation_spec of DeployModelRequest.deployed_model and for batch explanation by setting explanation_spec of BatchPredictionJob.
	ExplanationSpec GoogleCloudAiplatformV1beta1ExplanationSpecResponse `pulumi:"explanationSpec"`
	// The labels with user-defined metadata to organize your Models. Label keys and values can be no longer than 64 characters (Unicode codepoints), can only contain lowercase letters, numeric characters, underscores and dashes. International characters are allowed. See https://goo.gl/xmQnxf for more information and examples of labels.
	Labels map[string]string `pulumi:"labels"`
	// Immutable. An additional information about the Model; the schema of the metadata can be found in metadata_schema. Unset if the Model does not have any additional information.
	Metadata interface{} `pulumi:"metadata"`
	// The resource name of the Artifact that was created in MetadataStore when creating the Model. The Artifact resource name pattern is `projects/{project}/locations/{location}/metadataStores/{metadata_store}/artifacts/{artifact}`.
	MetadataArtifact string `pulumi:"metadataArtifact"`
	// Immutable. Points to a YAML file stored on Google Cloud Storage describing additional information about the Model, that is specific to it. Unset if the Model does not have any additional information. The schema is defined as an OpenAPI 3.0.2 [Schema Object](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject). AutoML Models always have this field populated by Vertex AI, if no additional metadata is needed, this field is set to an empty string. Note: The URI given on output will be immutable and probably different, including the URI scheme, than the one given on input. The output URI will point to a location where the user only has a read access.
	MetadataSchemaUri string `pulumi:"metadataSchemaUri"`
	// Source of a model. It can either be automl training pipeline, custom training pipeline, BigQuery ML, or existing Vertex AI Model.
	ModelSourceInfo GoogleCloudAiplatformV1beta1ModelSourceInfoResponse `pulumi:"modelSourceInfo"`
	// The resource name of the Model.
	Name string `pulumi:"name"`
	// If this Model is a copy of another Model, this contains info about the original.
	OriginalModelInfo GoogleCloudAiplatformV1beta1ModelOriginalModelInfoResponse `pulumi:"originalModelInfo"`
	// The schemata that describe formats of the Model's predictions and explanations as given and returned via PredictionService.Predict and PredictionService.Explain.
	PredictSchemata GoogleCloudAiplatformV1beta1PredictSchemataResponse `pulumi:"predictSchemata"`
	// When this Model is deployed, its prediction resources are described by the `prediction_resources` field of the Endpoint.deployed_models object. Because not all Models support all resource configuration types, the configuration types this Model supports are listed here. If no configuration types are listed, the Model cannot be deployed to an Endpoint and does not support online predictions (PredictionService.Predict or PredictionService.Explain). Such a Model can serve predictions by using a BatchPredictionJob, if it has at least one entry each in supported_input_storage_formats and supported_output_storage_formats.
	SupportedDeploymentResourcesTypes []string `pulumi:"supportedDeploymentResourcesTypes"`
	// The formats in which this Model may be exported. If empty, this Model is not available for export.
	SupportedExportFormats []GoogleCloudAiplatformV1beta1ModelExportFormatResponse `pulumi:"supportedExportFormats"`
	// The formats this Model supports in BatchPredictionJob.input_config. If PredictSchemata.instance_schema_uri exists, the instances should be given as per that schema. The possible formats are: * `jsonl` The JSON Lines format, where each instance is a single line. Uses GcsSource. * `csv` The CSV format, where each instance is a single comma-separated line. The first line in the file is the header, containing comma-separated field names. Uses GcsSource. * `tf-record` The TFRecord format, where each instance is a single record in tfrecord syntax. Uses GcsSource. * `tf-record-gzip` Similar to `tf-record`, but the file is gzipped. Uses GcsSource. * `bigquery` Each instance is a single row in BigQuery. Uses BigQuerySource. * `file-list` Each line of the file is the location of an instance to process, uses `gcs_source` field of the InputConfig object. If this Model doesn't support any of these formats it means it cannot be used with a BatchPredictionJob. However, if it has supported_deployment_resources_types, it could serve online predictions by using PredictionService.Predict or PredictionService.Explain.
	SupportedInputStorageFormats []string `pulumi:"supportedInputStorageFormats"`
	// The formats this Model supports in BatchPredictionJob.output_config. If both PredictSchemata.instance_schema_uri and PredictSchemata.prediction_schema_uri exist, the predictions are returned together with their instances. In other words, the prediction has the original instance data first, followed by the actual prediction content (as per the schema). The possible formats are: * `jsonl` The JSON Lines format, where each prediction is a single line. Uses GcsDestination. * `csv` The CSV format, where each prediction is a single comma-separated line. The first line in the file is the header, containing comma-separated field names. Uses GcsDestination. * `bigquery` Each prediction is a single row in a BigQuery table, uses BigQueryDestination . If this Model doesn't support any of these formats it means it cannot be used with a BatchPredictionJob. However, if it has supported_deployment_resources_types, it could serve online predictions by using PredictionService.Predict or PredictionService.Explain.
	SupportedOutputStorageFormats []string `pulumi:"supportedOutputStorageFormats"`
	// The resource name of the TrainingPipeline that uploaded this Model, if any.
	TrainingPipeline string `pulumi:"trainingPipeline"`
	// Timestamp when this Model was most recently updated.
	UpdateTime string `pulumi:"updateTime"`
	// User provided version aliases so that a model version can be referenced via alias (i.e. `projects/{project}/locations/{location}/models/{model_id}@{version_alias}` instead of auto-generated version id (i.e. `projects/{project}/locations/{location}/models/{model_id}@{version_id})`. The format is a-z{0,126}[a-z0-9] to distinguish from version_id. A default version alias will be created for the first version of the model, and there must be exactly one default version alias for a model.
	VersionAliases []string `pulumi:"versionAliases"`
	// Timestamp when this version was created.
	VersionCreateTime string `pulumi:"versionCreateTime"`
	// The description of this version.
	VersionDescription string `pulumi:"versionDescription"`
	// Immutable. The version ID of the model. A new version is committed when a new model version is uploaded or trained under an existing model id. It is an auto-incrementing decimal number in string representation.
	VersionId string `pulumi:"versionId"`
	// Timestamp when this version was most recently updated.
	VersionUpdateTime string `pulumi:"versionUpdateTime"`
}

// A trained machine learning Model.
type GoogleCloudAiplatformV1beta1ModelResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ModelResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ModelResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ModelResponseOutput) ToGoogleCloudAiplatformV1beta1ModelResponseOutput() GoogleCloudAiplatformV1beta1ModelResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ModelResponseOutput) ToGoogleCloudAiplatformV1beta1ModelResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelResponseOutput {
	return o
}

// Immutable. The path to the directory containing the Model artifact and any of its supporting files. Not present for AutoML Models or Large Models.
func (o GoogleCloudAiplatformV1beta1ModelResponseOutput) ArtifactUri() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelResponse) string { return v.ArtifactUri }).(pulumi.StringOutput)
}

// Input only. The specification of the container that is to be used when deploying this Model. The specification is ingested upon ModelService.UploadModel, and all binaries it contains are copied and stored internally by Vertex AI. Not present for AutoML Models or Large Models.
func (o GoogleCloudAiplatformV1beta1ModelResponseOutput) ContainerSpec() GoogleCloudAiplatformV1beta1ModelContainerSpecResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelResponse) GoogleCloudAiplatformV1beta1ModelContainerSpecResponse {
		return v.ContainerSpec
	}).(GoogleCloudAiplatformV1beta1ModelContainerSpecResponseOutput)
}

// Timestamp when this Model was uploaded into Vertex AI.
func (o GoogleCloudAiplatformV1beta1ModelResponseOutput) CreateTime() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelResponse) string { return v.CreateTime }).(pulumi.StringOutput)
}

// The pointers to DeployedModels created from this Model. Note that Model could have been deployed to Endpoints in different Locations.
func (o GoogleCloudAiplatformV1beta1ModelResponseOutput) DeployedModels() GoogleCloudAiplatformV1beta1DeployedModelRefResponseArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelResponse) []GoogleCloudAiplatformV1beta1DeployedModelRefResponse {
		return v.DeployedModels
	}).(GoogleCloudAiplatformV1beta1DeployedModelRefResponseArrayOutput)
}

// The description of the Model.
func (o GoogleCloudAiplatformV1beta1ModelResponseOutput) Description() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelResponse) string { return v.Description }).(pulumi.StringOutput)
}

// The display name of the Model. The name can be up to 128 characters long and can consist of any UTF-8 characters.
func (o GoogleCloudAiplatformV1beta1ModelResponseOutput) DisplayName() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelResponse) string { return v.DisplayName }).(pulumi.StringOutput)
}

// Customer-managed encryption key spec for a Model. If set, this Model and all sub-resources of this Model will be secured by this key.
func (o GoogleCloudAiplatformV1beta1ModelResponseOutput) EncryptionSpec() GoogleCloudAiplatformV1beta1EncryptionSpecResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelResponse) GoogleCloudAiplatformV1beta1EncryptionSpecResponse {
		return v.EncryptionSpec
	}).(GoogleCloudAiplatformV1beta1EncryptionSpecResponseOutput)
}

// Used to perform consistent read-modify-write updates. If not set, a blind "overwrite" update happens.
func (o GoogleCloudAiplatformV1beta1ModelResponseOutput) Etag() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelResponse) string { return v.Etag }).(pulumi.StringOutput)
}

// The default explanation specification for this Model. The Model can be used for requesting explanation after being deployed if it is populated. The Model can be used for batch explanation if it is populated. All fields of the explanation_spec can be overridden by explanation_spec of DeployModelRequest.deployed_model, or explanation_spec of BatchPredictionJob. If the default explanation specification is not set for this Model, this Model can still be used for requesting explanation by setting explanation_spec of DeployModelRequest.deployed_model and for batch explanation by setting explanation_spec of BatchPredictionJob.
func (o GoogleCloudAiplatformV1beta1ModelResponseOutput) ExplanationSpec() GoogleCloudAiplatformV1beta1ExplanationSpecResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelResponse) GoogleCloudAiplatformV1beta1ExplanationSpecResponse {
		return v.ExplanationSpec
	}).(GoogleCloudAiplatformV1beta1ExplanationSpecResponseOutput)
}

// The labels with user-defined metadata to organize your Models. Label keys and values can be no longer than 64 characters (Unicode codepoints), can only contain lowercase letters, numeric characters, underscores and dashes. International characters are allowed. See https://goo.gl/xmQnxf for more information and examples of labels.
func (o GoogleCloudAiplatformV1beta1ModelResponseOutput) Labels() pulumi.StringMapOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelResponse) map[string]string { return v.Labels }).(pulumi.StringMapOutput)
}

// Immutable. An additional information about the Model; the schema of the metadata can be found in metadata_schema. Unset if the Model does not have any additional information.
func (o GoogleCloudAiplatformV1beta1ModelResponseOutput) Metadata() pulumi.AnyOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelResponse) interface{} { return v.Metadata }).(pulumi.AnyOutput)
}

// The resource name of the Artifact that was created in MetadataStore when creating the Model. The Artifact resource name pattern is `projects/{project}/locations/{location}/metadataStores/{metadata_store}/artifacts/{artifact}`.
func (o GoogleCloudAiplatformV1beta1ModelResponseOutput) MetadataArtifact() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelResponse) string { return v.MetadataArtifact }).(pulumi.StringOutput)
}

// Immutable. Points to a YAML file stored on Google Cloud Storage describing additional information about the Model, that is specific to it. Unset if the Model does not have any additional information. The schema is defined as an OpenAPI 3.0.2 [Schema Object](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject). AutoML Models always have this field populated by Vertex AI, if no additional metadata is needed, this field is set to an empty string. Note: The URI given on output will be immutable and probably different, including the URI scheme, than the one given on input. The output URI will point to a location where the user only has a read access.
func (o GoogleCloudAiplatformV1beta1ModelResponseOutput) MetadataSchemaUri() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelResponse) string { return v.MetadataSchemaUri }).(pulumi.StringOutput)
}

// Source of a model. It can either be automl training pipeline, custom training pipeline, BigQuery ML, or existing Vertex AI Model.
func (o GoogleCloudAiplatformV1beta1ModelResponseOutput) ModelSourceInfo() GoogleCloudAiplatformV1beta1ModelSourceInfoResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelResponse) GoogleCloudAiplatformV1beta1ModelSourceInfoResponse {
		return v.ModelSourceInfo
	}).(GoogleCloudAiplatformV1beta1ModelSourceInfoResponseOutput)
}

// The resource name of the Model.
func (o GoogleCloudAiplatformV1beta1ModelResponseOutput) Name() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelResponse) string { return v.Name }).(pulumi.StringOutput)
}

// If this Model is a copy of another Model, this contains info about the original.
func (o GoogleCloudAiplatformV1beta1ModelResponseOutput) OriginalModelInfo() GoogleCloudAiplatformV1beta1ModelOriginalModelInfoResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelResponse) GoogleCloudAiplatformV1beta1ModelOriginalModelInfoResponse {
		return v.OriginalModelInfo
	}).(GoogleCloudAiplatformV1beta1ModelOriginalModelInfoResponseOutput)
}

// The schemata that describe formats of the Model's predictions and explanations as given and returned via PredictionService.Predict and PredictionService.Explain.
func (o GoogleCloudAiplatformV1beta1ModelResponseOutput) PredictSchemata() GoogleCloudAiplatformV1beta1PredictSchemataResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelResponse) GoogleCloudAiplatformV1beta1PredictSchemataResponse {
		return v.PredictSchemata
	}).(GoogleCloudAiplatformV1beta1PredictSchemataResponseOutput)
}

// When this Model is deployed, its prediction resources are described by the `prediction_resources` field of the Endpoint.deployed_models object. Because not all Models support all resource configuration types, the configuration types this Model supports are listed here. If no configuration types are listed, the Model cannot be deployed to an Endpoint and does not support online predictions (PredictionService.Predict or PredictionService.Explain). Such a Model can serve predictions by using a BatchPredictionJob, if it has at least one entry each in supported_input_storage_formats and supported_output_storage_formats.
func (o GoogleCloudAiplatformV1beta1ModelResponseOutput) SupportedDeploymentResourcesTypes() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelResponse) []string { return v.SupportedDeploymentResourcesTypes }).(pulumi.StringArrayOutput)
}

// The formats in which this Model may be exported. If empty, this Model is not available for export.
func (o GoogleCloudAiplatformV1beta1ModelResponseOutput) SupportedExportFormats() GoogleCloudAiplatformV1beta1ModelExportFormatResponseArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelResponse) []GoogleCloudAiplatformV1beta1ModelExportFormatResponse {
		return v.SupportedExportFormats
	}).(GoogleCloudAiplatformV1beta1ModelExportFormatResponseArrayOutput)
}

// The formats this Model supports in BatchPredictionJob.input_config. If PredictSchemata.instance_schema_uri exists, the instances should be given as per that schema. The possible formats are: * `jsonl` The JSON Lines format, where each instance is a single line. Uses GcsSource. * `csv` The CSV format, where each instance is a single comma-separated line. The first line in the file is the header, containing comma-separated field names. Uses GcsSource. * `tf-record` The TFRecord format, where each instance is a single record in tfrecord syntax. Uses GcsSource. * `tf-record-gzip` Similar to `tf-record`, but the file is gzipped. Uses GcsSource. * `bigquery` Each instance is a single row in BigQuery. Uses BigQuerySource. * `file-list` Each line of the file is the location of an instance to process, uses `gcs_source` field of the InputConfig object. If this Model doesn't support any of these formats it means it cannot be used with a BatchPredictionJob. However, if it has supported_deployment_resources_types, it could serve online predictions by using PredictionService.Predict or PredictionService.Explain.
func (o GoogleCloudAiplatformV1beta1ModelResponseOutput) SupportedInputStorageFormats() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelResponse) []string { return v.SupportedInputStorageFormats }).(pulumi.StringArrayOutput)
}

// The formats this Model supports in BatchPredictionJob.output_config. If both PredictSchemata.instance_schema_uri and PredictSchemata.prediction_schema_uri exist, the predictions are returned together with their instances. In other words, the prediction has the original instance data first, followed by the actual prediction content (as per the schema). The possible formats are: * `jsonl` The JSON Lines format, where each prediction is a single line. Uses GcsDestination. * `csv` The CSV format, where each prediction is a single comma-separated line. The first line in the file is the header, containing comma-separated field names. Uses GcsDestination. * `bigquery` Each prediction is a single row in a BigQuery table, uses BigQueryDestination . If this Model doesn't support any of these formats it means it cannot be used with a BatchPredictionJob. However, if it has supported_deployment_resources_types, it could serve online predictions by using PredictionService.Predict or PredictionService.Explain.
func (o GoogleCloudAiplatformV1beta1ModelResponseOutput) SupportedOutputStorageFormats() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelResponse) []string { return v.SupportedOutputStorageFormats }).(pulumi.StringArrayOutput)
}

// The resource name of the TrainingPipeline that uploaded this Model, if any.
func (o GoogleCloudAiplatformV1beta1ModelResponseOutput) TrainingPipeline() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelResponse) string { return v.TrainingPipeline }).(pulumi.StringOutput)
}

// Timestamp when this Model was most recently updated.
func (o GoogleCloudAiplatformV1beta1ModelResponseOutput) UpdateTime() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelResponse) string { return v.UpdateTime }).(pulumi.StringOutput)
}

// User provided version aliases so that a model version can be referenced via alias (i.e. `projects/{project}/locations/{location}/models/{model_id}@{version_alias}` instead of auto-generated version id (i.e. `projects/{project}/locations/{location}/models/{model_id}@{version_id})`. The format is a-z{0,126}[a-z0-9] to distinguish from version_id. A default version alias will be created for the first version of the model, and there must be exactly one default version alias for a model.
func (o GoogleCloudAiplatformV1beta1ModelResponseOutput) VersionAliases() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelResponse) []string { return v.VersionAliases }).(pulumi.StringArrayOutput)
}

// Timestamp when this version was created.
func (o GoogleCloudAiplatformV1beta1ModelResponseOutput) VersionCreateTime() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelResponse) string { return v.VersionCreateTime }).(pulumi.StringOutput)
}

// The description of this version.
func (o GoogleCloudAiplatformV1beta1ModelResponseOutput) VersionDescription() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelResponse) string { return v.VersionDescription }).(pulumi.StringOutput)
}

// Immutable. The version ID of the model. A new version is committed when a new model version is uploaded or trained under an existing model id. It is an auto-incrementing decimal number in string representation.
func (o GoogleCloudAiplatformV1beta1ModelResponseOutput) VersionId() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelResponse) string { return v.VersionId }).(pulumi.StringOutput)
}

// Timestamp when this version was most recently updated.
func (o GoogleCloudAiplatformV1beta1ModelResponseOutput) VersionUpdateTime() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelResponse) string { return v.VersionUpdateTime }).(pulumi.StringOutput)
}

// Detail description of the source information of the model.
type GoogleCloudAiplatformV1beta1ModelSourceInfoResponse struct {
	// If this Model is copy of another Model. If true then source_type pertains to the original.
	Copy bool `pulumi:"copy"`
	// Type of the model source.
	SourceType string `pulumi:"sourceType"`
}

// Detail description of the source information of the model.
type GoogleCloudAiplatformV1beta1ModelSourceInfoResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ModelSourceInfoResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ModelSourceInfoResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ModelSourceInfoResponseOutput) ToGoogleCloudAiplatformV1beta1ModelSourceInfoResponseOutput() GoogleCloudAiplatformV1beta1ModelSourceInfoResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ModelSourceInfoResponseOutput) ToGoogleCloudAiplatformV1beta1ModelSourceInfoResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ModelSourceInfoResponseOutput {
	return o
}

// If this Model is copy of another Model. If true then source_type pertains to the original.
func (o GoogleCloudAiplatformV1beta1ModelSourceInfoResponseOutput) Copy() pulumi.BoolOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelSourceInfoResponse) bool { return v.Copy }).(pulumi.BoolOutput)
}

// Type of the model source.
func (o GoogleCloudAiplatformV1beta1ModelSourceInfoResponseOutput) SourceType() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ModelSourceInfoResponse) string { return v.SourceType }).(pulumi.StringOutput)
}

// The output of a multi-trial Neural Architecture Search (NAS) jobs.
type GoogleCloudAiplatformV1beta1NasJobOutputMultiTrialJobOutputResponse struct {
	// List of NasTrials that were started as part of search stage.
	SearchTrials []GoogleCloudAiplatformV1beta1NasTrialResponse `pulumi:"searchTrials"`
	// List of NasTrials that were started as part of train stage.
	TrainTrials []GoogleCloudAiplatformV1beta1NasTrialResponse `pulumi:"trainTrials"`
}

// The output of a multi-trial Neural Architecture Search (NAS) jobs.
type GoogleCloudAiplatformV1beta1NasJobOutputMultiTrialJobOutputResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1NasJobOutputMultiTrialJobOutputResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1NasJobOutputMultiTrialJobOutputResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1NasJobOutputMultiTrialJobOutputResponseOutput) ToGoogleCloudAiplatformV1beta1NasJobOutputMultiTrialJobOutputResponseOutput() GoogleCloudAiplatformV1beta1NasJobOutputMultiTrialJobOutputResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1NasJobOutputMultiTrialJobOutputResponseOutput) ToGoogleCloudAiplatformV1beta1NasJobOutputMultiTrialJobOutputResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1NasJobOutputMultiTrialJobOutputResponseOutput {
	return o
}

// List of NasTrials that were started as part of search stage.
func (o GoogleCloudAiplatformV1beta1NasJobOutputMultiTrialJobOutputResponseOutput) SearchTrials() GoogleCloudAiplatformV1beta1NasTrialResponseArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1NasJobOutputMultiTrialJobOutputResponse) []GoogleCloudAiplatformV1beta1NasTrialResponse {
		return v.SearchTrials
	}).(GoogleCloudAiplatformV1beta1NasTrialResponseArrayOutput)
}

// List of NasTrials that were started as part of train stage.
func (o GoogleCloudAiplatformV1beta1NasJobOutputMultiTrialJobOutputResponseOutput) TrainTrials() GoogleCloudAiplatformV1beta1NasTrialResponseArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1NasJobOutputMultiTrialJobOutputResponse) []GoogleCloudAiplatformV1beta1NasTrialResponse {
		return v.TrainTrials
	}).(GoogleCloudAiplatformV1beta1NasTrialResponseArrayOutput)
}

// Represents a uCAIP NasJob output.
type GoogleCloudAiplatformV1beta1NasJobOutputResponse struct {
	// The output of this multi-trial Neural Architecture Search (NAS) job.
	MultiTrialJobOutput GoogleCloudAiplatformV1beta1NasJobOutputMultiTrialJobOutputResponse `pulumi:"multiTrialJobOutput"`
}

// Represents a uCAIP NasJob output.
type GoogleCloudAiplatformV1beta1NasJobOutputResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1NasJobOutputResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1NasJobOutputResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1NasJobOutputResponseOutput) ToGoogleCloudAiplatformV1beta1NasJobOutputResponseOutput() GoogleCloudAiplatformV1beta1NasJobOutputResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1NasJobOutputResponseOutput) ToGoogleCloudAiplatformV1beta1NasJobOutputResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1NasJobOutputResponseOutput {
	return o
}

// The output of this multi-trial Neural Architecture Search (NAS) job.
func (o GoogleCloudAiplatformV1beta1NasJobOutputResponseOutput) MultiTrialJobOutput() GoogleCloudAiplatformV1beta1NasJobOutputMultiTrialJobOutputResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1NasJobOutputResponse) GoogleCloudAiplatformV1beta1NasJobOutputMultiTrialJobOutputResponse {
		return v.MultiTrialJobOutput
	}).(GoogleCloudAiplatformV1beta1NasJobOutputMultiTrialJobOutputResponseOutput)
}

// Represents the spec of a NasJob.
type GoogleCloudAiplatformV1beta1NasJobSpec struct {
	// The spec of multi-trial algorithms.
	MultiTrialAlgorithmSpec *GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpec `pulumi:"multiTrialAlgorithmSpec"`
	// The ID of the existing NasJob in the same Project and Location which will be used to resume search. search_space_spec and nas_algorithm_spec are obtained from previous NasJob hence should not provide them again for this NasJob.
	ResumeNasJobId *string `pulumi:"resumeNasJobId"`
	// It defines the search space for Neural Architecture Search (NAS).
	SearchSpaceSpec *string `pulumi:"searchSpaceSpec"`
}

// GoogleCloudAiplatformV1beta1NasJobSpecInput is an input type that accepts GoogleCloudAiplatformV1beta1NasJobSpecArgs and GoogleCloudAiplatformV1beta1NasJobSpecOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1NasJobSpecInput` via:
//
//	GoogleCloudAiplatformV1beta1NasJobSpecArgs{...}
type GoogleCloudAiplatformV1beta1NasJobSpecInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1NasJobSpecOutput() GoogleCloudAiplatformV1beta1NasJobSpecOutput
	ToGoogleCloudAiplatformV1beta1NasJobSpecOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1NasJobSpecOutput
}

// Represents the spec of a NasJob.
type GoogleCloudAiplatformV1beta1NasJobSpecArgs struct {
	// The spec of multi-trial algorithms.
	MultiTrialAlgorithmSpec GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecPtrInput `pulumi:"multiTrialAlgorithmSpec"`
	// The ID of the existing NasJob in the same Project and Location which will be used to resume search. search_space_spec and nas_algorithm_spec are obtained from previous NasJob hence should not provide them again for this NasJob.
	ResumeNasJobId pulumi.StringPtrInput `pulumi:"resumeNasJobId"`
	// It defines the search space for Neural Architecture Search (NAS).
	SearchSpaceSpec pulumi.StringPtrInput `pulumi:"searchSpaceSpec"`
}

func (GoogleCloudAiplatformV1beta1NasJobSpecArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1NasJobSpec)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1NasJobSpecArgs) ToGoogleCloudAiplatformV1beta1NasJobSpecOutput() GoogleCloudAiplatformV1beta1NasJobSpecOutput {
	return i.ToGoogleCloudAiplatformV1beta1NasJobSpecOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1NasJobSpecArgs) ToGoogleCloudAiplatformV1beta1NasJobSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1NasJobSpecOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1NasJobSpecOutput)
}

// Represents the spec of a NasJob.
type GoogleCloudAiplatformV1beta1NasJobSpecOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1NasJobSpecOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1NasJobSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1NasJobSpecOutput) ToGoogleCloudAiplatformV1beta1NasJobSpecOutput() GoogleCloudAiplatformV1beta1NasJobSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1NasJobSpecOutput) ToGoogleCloudAiplatformV1beta1NasJobSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1NasJobSpecOutput {
	return o
}

// The spec of multi-trial algorithms.
func (o GoogleCloudAiplatformV1beta1NasJobSpecOutput) MultiTrialAlgorithmSpec() GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1NasJobSpec) *GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpec {
		return v.MultiTrialAlgorithmSpec
	}).(GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecPtrOutput)
}

// The ID of the existing NasJob in the same Project and Location which will be used to resume search. search_space_spec and nas_algorithm_spec are obtained from previous NasJob hence should not provide them again for this NasJob.
func (o GoogleCloudAiplatformV1beta1NasJobSpecOutput) ResumeNasJobId() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1NasJobSpec) *string { return v.ResumeNasJobId }).(pulumi.StringPtrOutput)
}

// It defines the search space for Neural Architecture Search (NAS).
func (o GoogleCloudAiplatformV1beta1NasJobSpecOutput) SearchSpaceSpec() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1NasJobSpec) *string { return v.SearchSpaceSpec }).(pulumi.StringPtrOutput)
}

// The spec of multi-trial Neural Architecture Search (NAS).
type GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpec struct {
	// Metric specs for the NAS job. Validation for this field is done at `multi_trial_algorithm_spec` field.
	Metric *GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpec `pulumi:"metric"`
	// The multi-trial Neural Architecture Search (NAS) algorithm type. Defaults to `REINFORCEMENT_LEARNING`.
	MultiTrialAlgorithm *GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMultiTrialAlgorithm `pulumi:"multiTrialAlgorithm"`
	// Spec for search trials.
	SearchTrialSpec GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpec `pulumi:"searchTrialSpec"`
	// Spec for train trials. Top N [TrainTrialSpec.max_parallel_trial_count] search trials will be trained for every M [TrainTrialSpec.frequency] trials searched.
	TrainTrialSpec *GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpec `pulumi:"trainTrialSpec"`
}

// GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecInput is an input type that accepts GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecArgs and GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecInput` via:
//
//	GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecArgs{...}
type GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecOutput() GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecOutput
	ToGoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecOutput
}

// The spec of multi-trial Neural Architecture Search (NAS).
type GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecArgs struct {
	// Metric specs for the NAS job. Validation for this field is done at `multi_trial_algorithm_spec` field.
	Metric GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrInput `pulumi:"metric"`
	// The multi-trial Neural Architecture Search (NAS) algorithm type. Defaults to `REINFORCEMENT_LEARNING`.
	MultiTrialAlgorithm GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMultiTrialAlgorithmPtrInput `pulumi:"multiTrialAlgorithm"`
	// Spec for search trials.
	SearchTrialSpec GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecInput `pulumi:"searchTrialSpec"`
	// Spec for train trials. Top N [TrainTrialSpec.max_parallel_trial_count] search trials will be trained for every M [TrainTrialSpec.frequency] trials searched.
	TrainTrialSpec GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrInput `pulumi:"trainTrialSpec"`
}

func (GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpec)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecArgs) ToGoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecOutput() GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecOutput {
	return i.ToGoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecArgs) ToGoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecOutput)
}

func (i GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecArgs) ToGoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecPtrOutput() GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecArgs) ToGoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecOutput).ToGoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecArgs, GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecPtr and GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecPtrOutput() GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecPtrOutput
	ToGoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecPtrOutput
}

type googleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecPtrType GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecArgs

func GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecPtr(v *GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecArgs) GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecPtrInput {
	return (*googleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecPtrType)(v)
}

func (*googleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpec)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecPtrType) ToGoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecPtrOutput() GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecPtrType) ToGoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecPtrOutput)
}

// The spec of multi-trial Neural Architecture Search (NAS).
type GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecOutput) ToGoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecOutput() GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecOutput) ToGoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecOutput) ToGoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecPtrOutput() GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecOutput) ToGoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpec) *GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpec {
		return &v
	}).(GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecPtrOutput)
}

// Metric specs for the NAS job. Validation for this field is done at `multi_trial_algorithm_spec` field.
func (o GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecOutput) Metric() GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpec) *GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpec {
		return v.Metric
	}).(GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrOutput)
}

// The multi-trial Neural Architecture Search (NAS) algorithm type. Defaults to `REINFORCEMENT_LEARNING`.
func (o GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecOutput) MultiTrialAlgorithm() GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMultiTrialAlgorithmPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpec) *GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMultiTrialAlgorithm {
		return v.MultiTrialAlgorithm
	}).(GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMultiTrialAlgorithmPtrOutput)
}

// Spec for search trials.
func (o GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecOutput) SearchTrialSpec() GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpec) GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpec {
		return v.SearchTrialSpec
	}).(GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecOutput)
}

// Spec for train trials. Top N [TrainTrialSpec.max_parallel_trial_count] search trials will be trained for every M [TrainTrialSpec.frequency] trials searched.
func (o GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecOutput) TrainTrialSpec() GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpec) *GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpec {
		return v.TrainTrialSpec
	}).(GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrOutput)
}

type GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecPtrOutput) ToGoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecPtrOutput() GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecPtrOutput) ToGoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecPtrOutput) Elem() GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpec) GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpec {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpec
		return ret
	}).(GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecOutput)
}

// Metric specs for the NAS job. Validation for this field is done at `multi_trial_algorithm_spec` field.
func (o GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecPtrOutput) Metric() GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpec) *GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpec {
		if v == nil {
			return nil
		}
		return v.Metric
	}).(GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrOutput)
}

// The multi-trial Neural Architecture Search (NAS) algorithm type. Defaults to `REINFORCEMENT_LEARNING`.
func (o GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecPtrOutput) MultiTrialAlgorithm() GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMultiTrialAlgorithmPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpec) *GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMultiTrialAlgorithm {
		if v == nil {
			return nil
		}
		return v.MultiTrialAlgorithm
	}).(GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMultiTrialAlgorithmPtrOutput)
}

// Spec for search trials.
func (o GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecPtrOutput) SearchTrialSpec() GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpec) *GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpec {
		if v == nil {
			return nil
		}
		return &v.SearchTrialSpec
	}).(GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtrOutput)
}

// Spec for train trials. Top N [TrainTrialSpec.max_parallel_trial_count] search trials will be trained for every M [TrainTrialSpec.frequency] trials searched.
func (o GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecPtrOutput) TrainTrialSpec() GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpec) *GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpec {
		if v == nil {
			return nil
		}
		return v.TrainTrialSpec
	}).(GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrOutput)
}

// Represents a metric to optimize.
type GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpec struct {
	// The optimization goal of the metric.
	Goal GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecGoal `pulumi:"goal"`
	// The ID of the metric. Must not contain whitespaces.
	MetricId string `pulumi:"metricId"`
}

// GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecInput is an input type that accepts GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecArgs and GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecInput` via:
//
//	GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecArgs{...}
type GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecOutput() GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecOutput
	ToGoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecOutput
}

// Represents a metric to optimize.
type GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecArgs struct {
	// The optimization goal of the metric.
	Goal GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecGoalInput `pulumi:"goal"`
	// The ID of the metric. Must not contain whitespaces.
	MetricId pulumi.StringInput `pulumi:"metricId"`
}

func (GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpec)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecArgs) ToGoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecOutput() GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecOutput {
	return i.ToGoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecArgs) ToGoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecOutput)
}

func (i GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecArgs) ToGoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrOutput() GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecArgs) ToGoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecOutput).ToGoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecArgs, GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtr and GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrOutput() GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrOutput
	ToGoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrOutput
}

type googleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrType GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecArgs

func GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtr(v *GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecArgs) GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrInput {
	return (*googleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrType)(v)
}

func (*googleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpec)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrType) ToGoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrOutput() GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrType) ToGoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrOutput)
}

// Represents a metric to optimize.
type GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecOutput) ToGoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecOutput() GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecOutput) ToGoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecOutput) ToGoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrOutput() GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecOutput) ToGoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpec) *GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpec {
		return &v
	}).(GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrOutput)
}

// The optimization goal of the metric.
func (o GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecOutput) Goal() GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecGoalOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpec) GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecGoal {
		return v.Goal
	}).(GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecGoalOutput)
}

// The ID of the metric. Must not contain whitespaces.
func (o GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecOutput) MetricId() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpec) string {
		return v.MetricId
	}).(pulumi.StringOutput)
}

type GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrOutput) ToGoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrOutput() GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrOutput) ToGoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrOutput) Elem() GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpec) GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpec {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpec
		return ret
	}).(GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecOutput)
}

// The optimization goal of the metric.
func (o GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrOutput) Goal() GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecGoalPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpec) *GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecGoal {
		if v == nil {
			return nil
		}
		return &v.Goal
	}).(GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecGoalPtrOutput)
}

// The ID of the metric. Must not contain whitespaces.
func (o GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrOutput) MetricId() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpec) *string {
		if v == nil {
			return nil
		}
		return &v.MetricId
	}).(pulumi.StringPtrOutput)
}

// Represents a metric to optimize.
type GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecResponse struct {
	// The optimization goal of the metric.
	Goal string `pulumi:"goal"`
	// The ID of the metric. Must not contain whitespaces.
	MetricId string `pulumi:"metricId"`
}

// Represents a metric to optimize.
type GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecResponseOutput) ToGoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecResponseOutput() GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecResponseOutput) ToGoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecResponseOutput {
	return o
}

// The optimization goal of the metric.
func (o GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecResponseOutput) Goal() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecResponse) string {
		return v.Goal
	}).(pulumi.StringOutput)
}

// The ID of the metric. Must not contain whitespaces.
func (o GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecResponseOutput) MetricId() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecResponse) string {
		return v.MetricId
	}).(pulumi.StringOutput)
}

// The spec of multi-trial Neural Architecture Search (NAS).
type GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecResponse struct {
	// Metric specs for the NAS job. Validation for this field is done at `multi_trial_algorithm_spec` field.
	Metric GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecResponse `pulumi:"metric"`
	// The multi-trial Neural Architecture Search (NAS) algorithm type. Defaults to `REINFORCEMENT_LEARNING`.
	MultiTrialAlgorithm string `pulumi:"multiTrialAlgorithm"`
	// Spec for search trials.
	SearchTrialSpec GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecResponse `pulumi:"searchTrialSpec"`
	// Spec for train trials. Top N [TrainTrialSpec.max_parallel_trial_count] search trials will be trained for every M [TrainTrialSpec.frequency] trials searched.
	TrainTrialSpec GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecResponse `pulumi:"trainTrialSpec"`
}

// The spec of multi-trial Neural Architecture Search (NAS).
type GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecResponseOutput) ToGoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecResponseOutput() GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecResponseOutput) ToGoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecResponseOutput {
	return o
}

// Metric specs for the NAS job. Validation for this field is done at `multi_trial_algorithm_spec` field.
func (o GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecResponseOutput) Metric() GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecResponse) GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecResponse {
		return v.Metric
	}).(GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecResponseOutput)
}

// The multi-trial Neural Architecture Search (NAS) algorithm type. Defaults to `REINFORCEMENT_LEARNING`.
func (o GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecResponseOutput) MultiTrialAlgorithm() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecResponse) string {
		return v.MultiTrialAlgorithm
	}).(pulumi.StringOutput)
}

// Spec for search trials.
func (o GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecResponseOutput) SearchTrialSpec() GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecResponse) GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecResponse {
		return v.SearchTrialSpec
	}).(GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecResponseOutput)
}

// Spec for train trials. Top N [TrainTrialSpec.max_parallel_trial_count] search trials will be trained for every M [TrainTrialSpec.frequency] trials searched.
func (o GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecResponseOutput) TrainTrialSpec() GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecResponse) GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecResponse {
		return v.TrainTrialSpec
	}).(GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecResponseOutput)
}

// Represent spec for search trials.
type GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpec struct {
	// The number of failed trials that need to be seen before failing the NasJob. If set to 0, Vertex AI decides how many trials must fail before the whole job fails.
	MaxFailedTrialCount *int `pulumi:"maxFailedTrialCount"`
	// The maximum number of trials to run in parallel.
	MaxParallelTrialCount int `pulumi:"maxParallelTrialCount"`
	// The maximum number of Neural Architecture Search (NAS) trials to run.
	MaxTrialCount int `pulumi:"maxTrialCount"`
	// The spec of a search trial job. The same spec applies to all search trials.
	SearchTrialJobSpec GoogleCloudAiplatformV1beta1CustomJobSpec `pulumi:"searchTrialJobSpec"`
}

// GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecInput is an input type that accepts GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecArgs and GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecInput` via:
//
//	GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecArgs{...}
type GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecOutput() GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecOutput
	ToGoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecOutput
}

// Represent spec for search trials.
type GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecArgs struct {
	// The number of failed trials that need to be seen before failing the NasJob. If set to 0, Vertex AI decides how many trials must fail before the whole job fails.
	MaxFailedTrialCount pulumi.IntPtrInput `pulumi:"maxFailedTrialCount"`
	// The maximum number of trials to run in parallel.
	MaxParallelTrialCount pulumi.IntInput `pulumi:"maxParallelTrialCount"`
	// The maximum number of Neural Architecture Search (NAS) trials to run.
	MaxTrialCount pulumi.IntInput `pulumi:"maxTrialCount"`
	// The spec of a search trial job. The same spec applies to all search trials.
	SearchTrialJobSpec GoogleCloudAiplatformV1beta1CustomJobSpecInput `pulumi:"searchTrialJobSpec"`
}

func (GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpec)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecArgs) ToGoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecOutput() GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecOutput {
	return i.ToGoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecArgs) ToGoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecOutput)
}

func (i GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecArgs) ToGoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtrOutput() GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecArgs) ToGoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecOutput).ToGoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecArgs, GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtr and GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtrOutput() GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtrOutput
	ToGoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtrOutput
}

type googleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtrType GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecArgs

func GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtr(v *GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecArgs) GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtrInput {
	return (*googleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtrType)(v)
}

func (*googleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpec)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtrType) ToGoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtrOutput() GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtrType) ToGoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtrOutput)
}

// Represent spec for search trials.
type GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecOutput) ToGoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecOutput() GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecOutput) ToGoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecOutput) ToGoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtrOutput() GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecOutput) ToGoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpec) *GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpec {
		return &v
	}).(GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtrOutput)
}

// The number of failed trials that need to be seen before failing the NasJob. If set to 0, Vertex AI decides how many trials must fail before the whole job fails.
func (o GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecOutput) MaxFailedTrialCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpec) *int {
		return v.MaxFailedTrialCount
	}).(pulumi.IntPtrOutput)
}

// The maximum number of trials to run in parallel.
func (o GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecOutput) MaxParallelTrialCount() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpec) int {
		return v.MaxParallelTrialCount
	}).(pulumi.IntOutput)
}

// The maximum number of Neural Architecture Search (NAS) trials to run.
func (o GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecOutput) MaxTrialCount() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpec) int {
		return v.MaxTrialCount
	}).(pulumi.IntOutput)
}

// The spec of a search trial job. The same spec applies to all search trials.
func (o GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecOutput) SearchTrialJobSpec() GoogleCloudAiplatformV1beta1CustomJobSpecOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpec) GoogleCloudAiplatformV1beta1CustomJobSpec {
		return v.SearchTrialJobSpec
	}).(GoogleCloudAiplatformV1beta1CustomJobSpecOutput)
}

type GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtrOutput) ToGoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtrOutput() GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtrOutput) ToGoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtrOutput) Elem() GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpec) GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpec {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpec
		return ret
	}).(GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecOutput)
}

// The number of failed trials that need to be seen before failing the NasJob. If set to 0, Vertex AI decides how many trials must fail before the whole job fails.
func (o GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtrOutput) MaxFailedTrialCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpec) *int {
		if v == nil {
			return nil
		}
		return v.MaxFailedTrialCount
	}).(pulumi.IntPtrOutput)
}

// The maximum number of trials to run in parallel.
func (o GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtrOutput) MaxParallelTrialCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpec) *int {
		if v == nil {
			return nil
		}
		return &v.MaxParallelTrialCount
	}).(pulumi.IntPtrOutput)
}

// The maximum number of Neural Architecture Search (NAS) trials to run.
func (o GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtrOutput) MaxTrialCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpec) *int {
		if v == nil {
			return nil
		}
		return &v.MaxTrialCount
	}).(pulumi.IntPtrOutput)
}

// The spec of a search trial job. The same spec applies to all search trials.
func (o GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtrOutput) SearchTrialJobSpec() GoogleCloudAiplatformV1beta1CustomJobSpecPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpec) *GoogleCloudAiplatformV1beta1CustomJobSpec {
		if v == nil {
			return nil
		}
		return &v.SearchTrialJobSpec
	}).(GoogleCloudAiplatformV1beta1CustomJobSpecPtrOutput)
}

// Represent spec for search trials.
type GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecResponse struct {
	// The number of failed trials that need to be seen before failing the NasJob. If set to 0, Vertex AI decides how many trials must fail before the whole job fails.
	MaxFailedTrialCount int `pulumi:"maxFailedTrialCount"`
	// The maximum number of trials to run in parallel.
	MaxParallelTrialCount int `pulumi:"maxParallelTrialCount"`
	// The maximum number of Neural Architecture Search (NAS) trials to run.
	MaxTrialCount int `pulumi:"maxTrialCount"`
	// The spec of a search trial job. The same spec applies to all search trials.
	SearchTrialJobSpec GoogleCloudAiplatformV1beta1CustomJobSpecResponse `pulumi:"searchTrialJobSpec"`
}

// Represent spec for search trials.
type GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecResponseOutput) ToGoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecResponseOutput() GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecResponseOutput) ToGoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecResponseOutput {
	return o
}

// The number of failed trials that need to be seen before failing the NasJob. If set to 0, Vertex AI decides how many trials must fail before the whole job fails.
func (o GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecResponseOutput) MaxFailedTrialCount() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecResponse) int {
		return v.MaxFailedTrialCount
	}).(pulumi.IntOutput)
}

// The maximum number of trials to run in parallel.
func (o GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecResponseOutput) MaxParallelTrialCount() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecResponse) int {
		return v.MaxParallelTrialCount
	}).(pulumi.IntOutput)
}

// The maximum number of Neural Architecture Search (NAS) trials to run.
func (o GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecResponseOutput) MaxTrialCount() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecResponse) int {
		return v.MaxTrialCount
	}).(pulumi.IntOutput)
}

// The spec of a search trial job. The same spec applies to all search trials.
func (o GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecResponseOutput) SearchTrialJobSpec() GoogleCloudAiplatformV1beta1CustomJobSpecResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecResponse) GoogleCloudAiplatformV1beta1CustomJobSpecResponse {
		return v.SearchTrialJobSpec
	}).(GoogleCloudAiplatformV1beta1CustomJobSpecResponseOutput)
}

// Represent spec for train trials.
type GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpec struct {
	// Frequency of search trials to start train stage. Top N [TrainTrialSpec.max_parallel_trial_count] search trials will be trained for every M [TrainTrialSpec.frequency] trials searched.
	Frequency int `pulumi:"frequency"`
	// The maximum number of trials to run in parallel.
	MaxParallelTrialCount int `pulumi:"maxParallelTrialCount"`
	// The spec of a train trial job. The same spec applies to all train trials.
	TrainTrialJobSpec GoogleCloudAiplatformV1beta1CustomJobSpec `pulumi:"trainTrialJobSpec"`
}

// GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecInput is an input type that accepts GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecArgs and GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecInput` via:
//
//	GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecArgs{...}
type GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecOutput() GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecOutput
	ToGoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecOutput
}

// Represent spec for train trials.
type GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecArgs struct {
	// Frequency of search trials to start train stage. Top N [TrainTrialSpec.max_parallel_trial_count] search trials will be trained for every M [TrainTrialSpec.frequency] trials searched.
	Frequency pulumi.IntInput `pulumi:"frequency"`
	// The maximum number of trials to run in parallel.
	MaxParallelTrialCount pulumi.IntInput `pulumi:"maxParallelTrialCount"`
	// The spec of a train trial job. The same spec applies to all train trials.
	TrainTrialJobSpec GoogleCloudAiplatformV1beta1CustomJobSpecInput `pulumi:"trainTrialJobSpec"`
}

func (GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpec)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecArgs) ToGoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecOutput() GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecOutput {
	return i.ToGoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecArgs) ToGoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecOutput)
}

func (i GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecArgs) ToGoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrOutput() GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecArgs) ToGoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecOutput).ToGoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecArgs, GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtr and GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrOutput() GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrOutput
	ToGoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrOutput
}

type googleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrType GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecArgs

func GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtr(v *GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecArgs) GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrInput {
	return (*googleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrType)(v)
}

func (*googleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpec)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrType) ToGoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrOutput() GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrType) ToGoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrOutput)
}

// Represent spec for train trials.
type GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecOutput) ToGoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecOutput() GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecOutput) ToGoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecOutput) ToGoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrOutput() GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecOutput) ToGoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpec) *GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpec {
		return &v
	}).(GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrOutput)
}

// Frequency of search trials to start train stage. Top N [TrainTrialSpec.max_parallel_trial_count] search trials will be trained for every M [TrainTrialSpec.frequency] trials searched.
func (o GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecOutput) Frequency() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpec) int {
		return v.Frequency
	}).(pulumi.IntOutput)
}

// The maximum number of trials to run in parallel.
func (o GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecOutput) MaxParallelTrialCount() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpec) int {
		return v.MaxParallelTrialCount
	}).(pulumi.IntOutput)
}

// The spec of a train trial job. The same spec applies to all train trials.
func (o GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecOutput) TrainTrialJobSpec() GoogleCloudAiplatformV1beta1CustomJobSpecOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpec) GoogleCloudAiplatformV1beta1CustomJobSpec {
		return v.TrainTrialJobSpec
	}).(GoogleCloudAiplatformV1beta1CustomJobSpecOutput)
}

type GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrOutput) ToGoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrOutput() GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrOutput) ToGoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrOutput) Elem() GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpec) GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpec {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpec
		return ret
	}).(GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecOutput)
}

// Frequency of search trials to start train stage. Top N [TrainTrialSpec.max_parallel_trial_count] search trials will be trained for every M [TrainTrialSpec.frequency] trials searched.
func (o GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrOutput) Frequency() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpec) *int {
		if v == nil {
			return nil
		}
		return &v.Frequency
	}).(pulumi.IntPtrOutput)
}

// The maximum number of trials to run in parallel.
func (o GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrOutput) MaxParallelTrialCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpec) *int {
		if v == nil {
			return nil
		}
		return &v.MaxParallelTrialCount
	}).(pulumi.IntPtrOutput)
}

// The spec of a train trial job. The same spec applies to all train trials.
func (o GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrOutput) TrainTrialJobSpec() GoogleCloudAiplatformV1beta1CustomJobSpecPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpec) *GoogleCloudAiplatformV1beta1CustomJobSpec {
		if v == nil {
			return nil
		}
		return &v.TrainTrialJobSpec
	}).(GoogleCloudAiplatformV1beta1CustomJobSpecPtrOutput)
}

// Represent spec for train trials.
type GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecResponse struct {
	// Frequency of search trials to start train stage. Top N [TrainTrialSpec.max_parallel_trial_count] search trials will be trained for every M [TrainTrialSpec.frequency] trials searched.
	Frequency int `pulumi:"frequency"`
	// The maximum number of trials to run in parallel.
	MaxParallelTrialCount int `pulumi:"maxParallelTrialCount"`
	// The spec of a train trial job. The same spec applies to all train trials.
	TrainTrialJobSpec GoogleCloudAiplatformV1beta1CustomJobSpecResponse `pulumi:"trainTrialJobSpec"`
}

// Represent spec for train trials.
type GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecResponseOutput) ToGoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecResponseOutput() GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecResponseOutput) ToGoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecResponseOutput {
	return o
}

// Frequency of search trials to start train stage. Top N [TrainTrialSpec.max_parallel_trial_count] search trials will be trained for every M [TrainTrialSpec.frequency] trials searched.
func (o GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecResponseOutput) Frequency() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecResponse) int {
		return v.Frequency
	}).(pulumi.IntOutput)
}

// The maximum number of trials to run in parallel.
func (o GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecResponseOutput) MaxParallelTrialCount() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecResponse) int {
		return v.MaxParallelTrialCount
	}).(pulumi.IntOutput)
}

// The spec of a train trial job. The same spec applies to all train trials.
func (o GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecResponseOutput) TrainTrialJobSpec() GoogleCloudAiplatformV1beta1CustomJobSpecResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecResponse) GoogleCloudAiplatformV1beta1CustomJobSpecResponse {
		return v.TrainTrialJobSpec
	}).(GoogleCloudAiplatformV1beta1CustomJobSpecResponseOutput)
}

// Represents the spec of a NasJob.
type GoogleCloudAiplatformV1beta1NasJobSpecResponse struct {
	// The spec of multi-trial algorithms.
	MultiTrialAlgorithmSpec GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecResponse `pulumi:"multiTrialAlgorithmSpec"`
	// The ID of the existing NasJob in the same Project and Location which will be used to resume search. search_space_spec and nas_algorithm_spec are obtained from previous NasJob hence should not provide them again for this NasJob.
	ResumeNasJobId string `pulumi:"resumeNasJobId"`
	// It defines the search space for Neural Architecture Search (NAS).
	SearchSpaceSpec string `pulumi:"searchSpaceSpec"`
}

// Represents the spec of a NasJob.
type GoogleCloudAiplatformV1beta1NasJobSpecResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1NasJobSpecResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1NasJobSpecResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1NasJobSpecResponseOutput) ToGoogleCloudAiplatformV1beta1NasJobSpecResponseOutput() GoogleCloudAiplatformV1beta1NasJobSpecResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1NasJobSpecResponseOutput) ToGoogleCloudAiplatformV1beta1NasJobSpecResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1NasJobSpecResponseOutput {
	return o
}

// The spec of multi-trial algorithms.
func (o GoogleCloudAiplatformV1beta1NasJobSpecResponseOutput) MultiTrialAlgorithmSpec() GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1NasJobSpecResponse) GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecResponse {
		return v.MultiTrialAlgorithmSpec
	}).(GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecResponseOutput)
}

// The ID of the existing NasJob in the same Project and Location which will be used to resume search. search_space_spec and nas_algorithm_spec are obtained from previous NasJob hence should not provide them again for this NasJob.
func (o GoogleCloudAiplatformV1beta1NasJobSpecResponseOutput) ResumeNasJobId() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1NasJobSpecResponse) string { return v.ResumeNasJobId }).(pulumi.StringOutput)
}

// It defines the search space for Neural Architecture Search (NAS).
func (o GoogleCloudAiplatformV1beta1NasJobSpecResponseOutput) SearchSpaceSpec() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1NasJobSpecResponse) string { return v.SearchSpaceSpec }).(pulumi.StringOutput)
}

// Represents a uCAIP NasJob trial.
type GoogleCloudAiplatformV1beta1NasTrialResponse struct {
	// Time when the NasTrial's status changed to `SUCCEEDED` or `INFEASIBLE`.
	EndTime string `pulumi:"endTime"`
	// The final measurement containing the objective value.
	FinalMeasurement GoogleCloudAiplatformV1beta1MeasurementResponse `pulumi:"finalMeasurement"`
	// Time when the NasTrial was started.
	StartTime string `pulumi:"startTime"`
	// The detailed state of the NasTrial.
	State string `pulumi:"state"`
}

// Represents a uCAIP NasJob trial.
type GoogleCloudAiplatformV1beta1NasTrialResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1NasTrialResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1NasTrialResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1NasTrialResponseOutput) ToGoogleCloudAiplatformV1beta1NasTrialResponseOutput() GoogleCloudAiplatformV1beta1NasTrialResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1NasTrialResponseOutput) ToGoogleCloudAiplatformV1beta1NasTrialResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1NasTrialResponseOutput {
	return o
}

// Time when the NasTrial's status changed to `SUCCEEDED` or `INFEASIBLE`.
func (o GoogleCloudAiplatformV1beta1NasTrialResponseOutput) EndTime() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1NasTrialResponse) string { return v.EndTime }).(pulumi.StringOutput)
}

// The final measurement containing the objective value.
func (o GoogleCloudAiplatformV1beta1NasTrialResponseOutput) FinalMeasurement() GoogleCloudAiplatformV1beta1MeasurementResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1NasTrialResponse) GoogleCloudAiplatformV1beta1MeasurementResponse {
		return v.FinalMeasurement
	}).(GoogleCloudAiplatformV1beta1MeasurementResponseOutput)
}

// Time when the NasTrial was started.
func (o GoogleCloudAiplatformV1beta1NasTrialResponseOutput) StartTime() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1NasTrialResponse) string { return v.StartTime }).(pulumi.StringOutput)
}

// The detailed state of the NasTrial.
func (o GoogleCloudAiplatformV1beta1NasTrialResponseOutput) State() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1NasTrialResponse) string { return v.State }).(pulumi.StringOutput)
}

type GoogleCloudAiplatformV1beta1NasTrialResponseArrayOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1NasTrialResponseArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1beta1NasTrialResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1NasTrialResponseArrayOutput) ToGoogleCloudAiplatformV1beta1NasTrialResponseArrayOutput() GoogleCloudAiplatformV1beta1NasTrialResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1NasTrialResponseArrayOutput) ToGoogleCloudAiplatformV1beta1NasTrialResponseArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1NasTrialResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1NasTrialResponseArrayOutput) Index(i pulumi.IntInput) GoogleCloudAiplatformV1beta1NasTrialResponseOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GoogleCloudAiplatformV1beta1NasTrialResponse {
		return vs[0].([]GoogleCloudAiplatformV1beta1NasTrialResponse)[vs[1].(int)]
	}).(GoogleCloudAiplatformV1beta1NasTrialResponseOutput)
}

// Network spec.
type GoogleCloudAiplatformV1beta1NetworkSpec struct {
	// Whether to enable public internet access. Default false.
	EnableInternetAccess *bool `pulumi:"enableInternetAccess"`
	// The full name of the Google Compute Engine [network](https://cloud.google.com//compute/docs/networks-and-firewalls#networks)
	Network *string `pulumi:"network"`
	// The name of the subnet that this instance is in. Format: `projects/{project_id_or_number}/regions/{region}/subnetworks/{subnetwork_id}`
	Subnetwork *string `pulumi:"subnetwork"`
}

// GoogleCloudAiplatformV1beta1NetworkSpecInput is an input type that accepts GoogleCloudAiplatformV1beta1NetworkSpecArgs and GoogleCloudAiplatformV1beta1NetworkSpecOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1NetworkSpecInput` via:
//
//	GoogleCloudAiplatformV1beta1NetworkSpecArgs{...}
type GoogleCloudAiplatformV1beta1NetworkSpecInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1NetworkSpecOutput() GoogleCloudAiplatformV1beta1NetworkSpecOutput
	ToGoogleCloudAiplatformV1beta1NetworkSpecOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1NetworkSpecOutput
}

// Network spec.
type GoogleCloudAiplatformV1beta1NetworkSpecArgs struct {
	// Whether to enable public internet access. Default false.
	EnableInternetAccess pulumi.BoolPtrInput `pulumi:"enableInternetAccess"`
	// The full name of the Google Compute Engine [network](https://cloud.google.com//compute/docs/networks-and-firewalls#networks)
	Network pulumi.StringPtrInput `pulumi:"network"`
	// The name of the subnet that this instance is in. Format: `projects/{project_id_or_number}/regions/{region}/subnetworks/{subnetwork_id}`
	Subnetwork pulumi.StringPtrInput `pulumi:"subnetwork"`
}

func (GoogleCloudAiplatformV1beta1NetworkSpecArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1NetworkSpec)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1NetworkSpecArgs) ToGoogleCloudAiplatformV1beta1NetworkSpecOutput() GoogleCloudAiplatformV1beta1NetworkSpecOutput {
	return i.ToGoogleCloudAiplatformV1beta1NetworkSpecOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1NetworkSpecArgs) ToGoogleCloudAiplatformV1beta1NetworkSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1NetworkSpecOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1NetworkSpecOutput)
}

func (i GoogleCloudAiplatformV1beta1NetworkSpecArgs) ToGoogleCloudAiplatformV1beta1NetworkSpecPtrOutput() GoogleCloudAiplatformV1beta1NetworkSpecPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1NetworkSpecPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1NetworkSpecArgs) ToGoogleCloudAiplatformV1beta1NetworkSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1NetworkSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1NetworkSpecOutput).ToGoogleCloudAiplatformV1beta1NetworkSpecPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1NetworkSpecPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1NetworkSpecArgs, GoogleCloudAiplatformV1beta1NetworkSpecPtr and GoogleCloudAiplatformV1beta1NetworkSpecPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1NetworkSpecPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1NetworkSpecArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1NetworkSpecPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1NetworkSpecPtrOutput() GoogleCloudAiplatformV1beta1NetworkSpecPtrOutput
	ToGoogleCloudAiplatformV1beta1NetworkSpecPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1NetworkSpecPtrOutput
}

type googleCloudAiplatformV1beta1NetworkSpecPtrType GoogleCloudAiplatformV1beta1NetworkSpecArgs

func GoogleCloudAiplatformV1beta1NetworkSpecPtr(v *GoogleCloudAiplatformV1beta1NetworkSpecArgs) GoogleCloudAiplatformV1beta1NetworkSpecPtrInput {
	return (*googleCloudAiplatformV1beta1NetworkSpecPtrType)(v)
}

func (*googleCloudAiplatformV1beta1NetworkSpecPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1NetworkSpec)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1NetworkSpecPtrType) ToGoogleCloudAiplatformV1beta1NetworkSpecPtrOutput() GoogleCloudAiplatformV1beta1NetworkSpecPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1NetworkSpecPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1NetworkSpecPtrType) ToGoogleCloudAiplatformV1beta1NetworkSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1NetworkSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1NetworkSpecPtrOutput)
}

// Network spec.
type GoogleCloudAiplatformV1beta1NetworkSpecOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1NetworkSpecOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1NetworkSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1NetworkSpecOutput) ToGoogleCloudAiplatformV1beta1NetworkSpecOutput() GoogleCloudAiplatformV1beta1NetworkSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1NetworkSpecOutput) ToGoogleCloudAiplatformV1beta1NetworkSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1NetworkSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1NetworkSpecOutput) ToGoogleCloudAiplatformV1beta1NetworkSpecPtrOutput() GoogleCloudAiplatformV1beta1NetworkSpecPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1NetworkSpecPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1NetworkSpecOutput) ToGoogleCloudAiplatformV1beta1NetworkSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1NetworkSpecPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1NetworkSpec) *GoogleCloudAiplatformV1beta1NetworkSpec {
		return &v
	}).(GoogleCloudAiplatformV1beta1NetworkSpecPtrOutput)
}

// Whether to enable public internet access. Default false.
func (o GoogleCloudAiplatformV1beta1NetworkSpecOutput) EnableInternetAccess() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1NetworkSpec) *bool { return v.EnableInternetAccess }).(pulumi.BoolPtrOutput)
}

// The full name of the Google Compute Engine [network](https://cloud.google.com//compute/docs/networks-and-firewalls#networks)
func (o GoogleCloudAiplatformV1beta1NetworkSpecOutput) Network() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1NetworkSpec) *string { return v.Network }).(pulumi.StringPtrOutput)
}

// The name of the subnet that this instance is in. Format: `projects/{project_id_or_number}/regions/{region}/subnetworks/{subnetwork_id}`
func (o GoogleCloudAiplatformV1beta1NetworkSpecOutput) Subnetwork() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1NetworkSpec) *string { return v.Subnetwork }).(pulumi.StringPtrOutput)
}

type GoogleCloudAiplatformV1beta1NetworkSpecPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1NetworkSpecPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1NetworkSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1NetworkSpecPtrOutput) ToGoogleCloudAiplatformV1beta1NetworkSpecPtrOutput() GoogleCloudAiplatformV1beta1NetworkSpecPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1NetworkSpecPtrOutput) ToGoogleCloudAiplatformV1beta1NetworkSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1NetworkSpecPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1NetworkSpecPtrOutput) Elem() GoogleCloudAiplatformV1beta1NetworkSpecOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1NetworkSpec) GoogleCloudAiplatformV1beta1NetworkSpec {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1NetworkSpec
		return ret
	}).(GoogleCloudAiplatformV1beta1NetworkSpecOutput)
}

// Whether to enable public internet access. Default false.
func (o GoogleCloudAiplatformV1beta1NetworkSpecPtrOutput) EnableInternetAccess() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1NetworkSpec) *bool {
		if v == nil {
			return nil
		}
		return v.EnableInternetAccess
	}).(pulumi.BoolPtrOutput)
}

// The full name of the Google Compute Engine [network](https://cloud.google.com//compute/docs/networks-and-firewalls#networks)
func (o GoogleCloudAiplatformV1beta1NetworkSpecPtrOutput) Network() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1NetworkSpec) *string {
		if v == nil {
			return nil
		}
		return v.Network
	}).(pulumi.StringPtrOutput)
}

// The name of the subnet that this instance is in. Format: `projects/{project_id_or_number}/regions/{region}/subnetworks/{subnetwork_id}`
func (o GoogleCloudAiplatformV1beta1NetworkSpecPtrOutput) Subnetwork() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1NetworkSpec) *string {
		if v == nil {
			return nil
		}
		return v.Subnetwork
	}).(pulumi.StringPtrOutput)
}

// Network spec.
type GoogleCloudAiplatformV1beta1NetworkSpecResponse struct {
	// Whether to enable public internet access. Default false.
	EnableInternetAccess bool `pulumi:"enableInternetAccess"`
	// The full name of the Google Compute Engine [network](https://cloud.google.com//compute/docs/networks-and-firewalls#networks)
	Network string `pulumi:"network"`
	// The name of the subnet that this instance is in. Format: `projects/{project_id_or_number}/regions/{region}/subnetworks/{subnetwork_id}`
	Subnetwork string `pulumi:"subnetwork"`
}

// Network spec.
type GoogleCloudAiplatformV1beta1NetworkSpecResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1NetworkSpecResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1NetworkSpecResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1NetworkSpecResponseOutput) ToGoogleCloudAiplatformV1beta1NetworkSpecResponseOutput() GoogleCloudAiplatformV1beta1NetworkSpecResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1NetworkSpecResponseOutput) ToGoogleCloudAiplatformV1beta1NetworkSpecResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1NetworkSpecResponseOutput {
	return o
}

// Whether to enable public internet access. Default false.
func (o GoogleCloudAiplatformV1beta1NetworkSpecResponseOutput) EnableInternetAccess() pulumi.BoolOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1NetworkSpecResponse) bool { return v.EnableInternetAccess }).(pulumi.BoolOutput)
}

// The full name of the Google Compute Engine [network](https://cloud.google.com//compute/docs/networks-and-firewalls#networks)
func (o GoogleCloudAiplatformV1beta1NetworkSpecResponseOutput) Network() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1NetworkSpecResponse) string { return v.Network }).(pulumi.StringOutput)
}

// The name of the subnet that this instance is in. Format: `projects/{project_id_or_number}/regions/{region}/subnetworks/{subnetwork_id}`
func (o GoogleCloudAiplatformV1beta1NetworkSpecResponseOutput) Subnetwork() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1NetworkSpecResponse) string { return v.Subnetwork }).(pulumi.StringOutput)
}

// Represents a mount configuration for Network File System (NFS) to mount.
type GoogleCloudAiplatformV1beta1NfsMount struct {
	// Destination mount path. The NFS will be mounted for the user under /mnt/nfs/
	MountPoint string `pulumi:"mountPoint"`
	// Source path exported from NFS server. Has to start with '/', and combined with the ip address, it indicates the source mount path in the form of `server:path`
	Path string `pulumi:"path"`
	// IP address of the NFS server.
	Server string `pulumi:"server"`
}

// GoogleCloudAiplatformV1beta1NfsMountInput is an input type that accepts GoogleCloudAiplatformV1beta1NfsMountArgs and GoogleCloudAiplatformV1beta1NfsMountOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1NfsMountInput` via:
//
//	GoogleCloudAiplatformV1beta1NfsMountArgs{...}
type GoogleCloudAiplatformV1beta1NfsMountInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1NfsMountOutput() GoogleCloudAiplatformV1beta1NfsMountOutput
	ToGoogleCloudAiplatformV1beta1NfsMountOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1NfsMountOutput
}

// Represents a mount configuration for Network File System (NFS) to mount.
type GoogleCloudAiplatformV1beta1NfsMountArgs struct {
	// Destination mount path. The NFS will be mounted for the user under /mnt/nfs/
	MountPoint pulumi.StringInput `pulumi:"mountPoint"`
	// Source path exported from NFS server. Has to start with '/', and combined with the ip address, it indicates the source mount path in the form of `server:path`
	Path pulumi.StringInput `pulumi:"path"`
	// IP address of the NFS server.
	Server pulumi.StringInput `pulumi:"server"`
}

func (GoogleCloudAiplatformV1beta1NfsMountArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1NfsMount)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1NfsMountArgs) ToGoogleCloudAiplatformV1beta1NfsMountOutput() GoogleCloudAiplatformV1beta1NfsMountOutput {
	return i.ToGoogleCloudAiplatformV1beta1NfsMountOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1NfsMountArgs) ToGoogleCloudAiplatformV1beta1NfsMountOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1NfsMountOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1NfsMountOutput)
}

// GoogleCloudAiplatformV1beta1NfsMountArrayInput is an input type that accepts GoogleCloudAiplatformV1beta1NfsMountArray and GoogleCloudAiplatformV1beta1NfsMountArrayOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1NfsMountArrayInput` via:
//
//	GoogleCloudAiplatformV1beta1NfsMountArray{ GoogleCloudAiplatformV1beta1NfsMountArgs{...} }
type GoogleCloudAiplatformV1beta1NfsMountArrayInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1NfsMountArrayOutput() GoogleCloudAiplatformV1beta1NfsMountArrayOutput
	ToGoogleCloudAiplatformV1beta1NfsMountArrayOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1NfsMountArrayOutput
}

type GoogleCloudAiplatformV1beta1NfsMountArray []GoogleCloudAiplatformV1beta1NfsMountInput

func (GoogleCloudAiplatformV1beta1NfsMountArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1beta1NfsMount)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1NfsMountArray) ToGoogleCloudAiplatformV1beta1NfsMountArrayOutput() GoogleCloudAiplatformV1beta1NfsMountArrayOutput {
	return i.ToGoogleCloudAiplatformV1beta1NfsMountArrayOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1NfsMountArray) ToGoogleCloudAiplatformV1beta1NfsMountArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1NfsMountArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1NfsMountArrayOutput)
}

// Represents a mount configuration for Network File System (NFS) to mount.
type GoogleCloudAiplatformV1beta1NfsMountOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1NfsMountOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1NfsMount)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1NfsMountOutput) ToGoogleCloudAiplatformV1beta1NfsMountOutput() GoogleCloudAiplatformV1beta1NfsMountOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1NfsMountOutput) ToGoogleCloudAiplatformV1beta1NfsMountOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1NfsMountOutput {
	return o
}

// Destination mount path. The NFS will be mounted for the user under /mnt/nfs/
func (o GoogleCloudAiplatformV1beta1NfsMountOutput) MountPoint() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1NfsMount) string { return v.MountPoint }).(pulumi.StringOutput)
}

// Source path exported from NFS server. Has to start with '/', and combined with the ip address, it indicates the source mount path in the form of `server:path`
func (o GoogleCloudAiplatformV1beta1NfsMountOutput) Path() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1NfsMount) string { return v.Path }).(pulumi.StringOutput)
}

// IP address of the NFS server.
func (o GoogleCloudAiplatformV1beta1NfsMountOutput) Server() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1NfsMount) string { return v.Server }).(pulumi.StringOutput)
}

type GoogleCloudAiplatformV1beta1NfsMountArrayOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1NfsMountArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1beta1NfsMount)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1NfsMountArrayOutput) ToGoogleCloudAiplatformV1beta1NfsMountArrayOutput() GoogleCloudAiplatformV1beta1NfsMountArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1NfsMountArrayOutput) ToGoogleCloudAiplatformV1beta1NfsMountArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1NfsMountArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1NfsMountArrayOutput) Index(i pulumi.IntInput) GoogleCloudAiplatformV1beta1NfsMountOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GoogleCloudAiplatformV1beta1NfsMount {
		return vs[0].([]GoogleCloudAiplatformV1beta1NfsMount)[vs[1].(int)]
	}).(GoogleCloudAiplatformV1beta1NfsMountOutput)
}

// Represents a mount configuration for Network File System (NFS) to mount.
type GoogleCloudAiplatformV1beta1NfsMountResponse struct {
	// Destination mount path. The NFS will be mounted for the user under /mnt/nfs/
	MountPoint string `pulumi:"mountPoint"`
	// Source path exported from NFS server. Has to start with '/', and combined with the ip address, it indicates the source mount path in the form of `server:path`
	Path string `pulumi:"path"`
	// IP address of the NFS server.
	Server string `pulumi:"server"`
}

// Represents a mount configuration for Network File System (NFS) to mount.
type GoogleCloudAiplatformV1beta1NfsMountResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1NfsMountResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1NfsMountResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1NfsMountResponseOutput) ToGoogleCloudAiplatformV1beta1NfsMountResponseOutput() GoogleCloudAiplatformV1beta1NfsMountResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1NfsMountResponseOutput) ToGoogleCloudAiplatformV1beta1NfsMountResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1NfsMountResponseOutput {
	return o
}

// Destination mount path. The NFS will be mounted for the user under /mnt/nfs/
func (o GoogleCloudAiplatformV1beta1NfsMountResponseOutput) MountPoint() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1NfsMountResponse) string { return v.MountPoint }).(pulumi.StringOutput)
}

// Source path exported from NFS server. Has to start with '/', and combined with the ip address, it indicates the source mount path in the form of `server:path`
func (o GoogleCloudAiplatformV1beta1NfsMountResponseOutput) Path() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1NfsMountResponse) string { return v.Path }).(pulumi.StringOutput)
}

// IP address of the NFS server.
func (o GoogleCloudAiplatformV1beta1NfsMountResponseOutput) Server() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1NfsMountResponse) string { return v.Server }).(pulumi.StringOutput)
}

type GoogleCloudAiplatformV1beta1NfsMountResponseArrayOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1NfsMountResponseArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1beta1NfsMountResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1NfsMountResponseArrayOutput) ToGoogleCloudAiplatformV1beta1NfsMountResponseArrayOutput() GoogleCloudAiplatformV1beta1NfsMountResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1NfsMountResponseArrayOutput) ToGoogleCloudAiplatformV1beta1NfsMountResponseArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1NfsMountResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1NfsMountResponseArrayOutput) Index(i pulumi.IntInput) GoogleCloudAiplatformV1beta1NfsMountResponseOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GoogleCloudAiplatformV1beta1NfsMountResponse {
		return vs[0].([]GoogleCloudAiplatformV1beta1NfsMountResponse)[vs[1].(int)]
	}).(GoogleCloudAiplatformV1beta1NfsMountResponseOutput)
}

// The euc configuration of NotebookRuntimeTemplate.
type GoogleCloudAiplatformV1beta1NotebookEucConfig struct {
	// Input only. Whether EUC is disabled in this NotebookRuntimeTemplate. In proto3, the default value of a boolean is false. In this way, by default EUC will be enabled for NotebookRuntimeTemplate.
	EucDisabled *bool `pulumi:"eucDisabled"`
}

// GoogleCloudAiplatformV1beta1NotebookEucConfigInput is an input type that accepts GoogleCloudAiplatformV1beta1NotebookEucConfigArgs and GoogleCloudAiplatformV1beta1NotebookEucConfigOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1NotebookEucConfigInput` via:
//
//	GoogleCloudAiplatformV1beta1NotebookEucConfigArgs{...}
type GoogleCloudAiplatformV1beta1NotebookEucConfigInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1NotebookEucConfigOutput() GoogleCloudAiplatformV1beta1NotebookEucConfigOutput
	ToGoogleCloudAiplatformV1beta1NotebookEucConfigOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1NotebookEucConfigOutput
}

// The euc configuration of NotebookRuntimeTemplate.
type GoogleCloudAiplatformV1beta1NotebookEucConfigArgs struct {
	// Input only. Whether EUC is disabled in this NotebookRuntimeTemplate. In proto3, the default value of a boolean is false. In this way, by default EUC will be enabled for NotebookRuntimeTemplate.
	EucDisabled pulumi.BoolPtrInput `pulumi:"eucDisabled"`
}

func (GoogleCloudAiplatformV1beta1NotebookEucConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1NotebookEucConfig)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1NotebookEucConfigArgs) ToGoogleCloudAiplatformV1beta1NotebookEucConfigOutput() GoogleCloudAiplatformV1beta1NotebookEucConfigOutput {
	return i.ToGoogleCloudAiplatformV1beta1NotebookEucConfigOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1NotebookEucConfigArgs) ToGoogleCloudAiplatformV1beta1NotebookEucConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1NotebookEucConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1NotebookEucConfigOutput)
}

func (i GoogleCloudAiplatformV1beta1NotebookEucConfigArgs) ToGoogleCloudAiplatformV1beta1NotebookEucConfigPtrOutput() GoogleCloudAiplatformV1beta1NotebookEucConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1NotebookEucConfigPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1NotebookEucConfigArgs) ToGoogleCloudAiplatformV1beta1NotebookEucConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1NotebookEucConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1NotebookEucConfigOutput).ToGoogleCloudAiplatformV1beta1NotebookEucConfigPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1NotebookEucConfigPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1NotebookEucConfigArgs, GoogleCloudAiplatformV1beta1NotebookEucConfigPtr and GoogleCloudAiplatformV1beta1NotebookEucConfigPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1NotebookEucConfigPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1NotebookEucConfigArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1NotebookEucConfigPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1NotebookEucConfigPtrOutput() GoogleCloudAiplatformV1beta1NotebookEucConfigPtrOutput
	ToGoogleCloudAiplatformV1beta1NotebookEucConfigPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1NotebookEucConfigPtrOutput
}

type googleCloudAiplatformV1beta1NotebookEucConfigPtrType GoogleCloudAiplatformV1beta1NotebookEucConfigArgs

func GoogleCloudAiplatformV1beta1NotebookEucConfigPtr(v *GoogleCloudAiplatformV1beta1NotebookEucConfigArgs) GoogleCloudAiplatformV1beta1NotebookEucConfigPtrInput {
	return (*googleCloudAiplatformV1beta1NotebookEucConfigPtrType)(v)
}

func (*googleCloudAiplatformV1beta1NotebookEucConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1NotebookEucConfig)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1NotebookEucConfigPtrType) ToGoogleCloudAiplatformV1beta1NotebookEucConfigPtrOutput() GoogleCloudAiplatformV1beta1NotebookEucConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1NotebookEucConfigPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1NotebookEucConfigPtrType) ToGoogleCloudAiplatformV1beta1NotebookEucConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1NotebookEucConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1NotebookEucConfigPtrOutput)
}

// The euc configuration of NotebookRuntimeTemplate.
type GoogleCloudAiplatformV1beta1NotebookEucConfigOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1NotebookEucConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1NotebookEucConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1NotebookEucConfigOutput) ToGoogleCloudAiplatformV1beta1NotebookEucConfigOutput() GoogleCloudAiplatformV1beta1NotebookEucConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1NotebookEucConfigOutput) ToGoogleCloudAiplatformV1beta1NotebookEucConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1NotebookEucConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1NotebookEucConfigOutput) ToGoogleCloudAiplatformV1beta1NotebookEucConfigPtrOutput() GoogleCloudAiplatformV1beta1NotebookEucConfigPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1NotebookEucConfigPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1NotebookEucConfigOutput) ToGoogleCloudAiplatformV1beta1NotebookEucConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1NotebookEucConfigPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1NotebookEucConfig) *GoogleCloudAiplatformV1beta1NotebookEucConfig {
		return &v
	}).(GoogleCloudAiplatformV1beta1NotebookEucConfigPtrOutput)
}

// Input only. Whether EUC is disabled in this NotebookRuntimeTemplate. In proto3, the default value of a boolean is false. In this way, by default EUC will be enabled for NotebookRuntimeTemplate.
func (o GoogleCloudAiplatformV1beta1NotebookEucConfigOutput) EucDisabled() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1NotebookEucConfig) *bool { return v.EucDisabled }).(pulumi.BoolPtrOutput)
}

type GoogleCloudAiplatformV1beta1NotebookEucConfigPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1NotebookEucConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1NotebookEucConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1NotebookEucConfigPtrOutput) ToGoogleCloudAiplatformV1beta1NotebookEucConfigPtrOutput() GoogleCloudAiplatformV1beta1NotebookEucConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1NotebookEucConfigPtrOutput) ToGoogleCloudAiplatformV1beta1NotebookEucConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1NotebookEucConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1NotebookEucConfigPtrOutput) Elem() GoogleCloudAiplatformV1beta1NotebookEucConfigOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1NotebookEucConfig) GoogleCloudAiplatformV1beta1NotebookEucConfig {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1NotebookEucConfig
		return ret
	}).(GoogleCloudAiplatformV1beta1NotebookEucConfigOutput)
}

// Input only. Whether EUC is disabled in this NotebookRuntimeTemplate. In proto3, the default value of a boolean is false. In this way, by default EUC will be enabled for NotebookRuntimeTemplate.
func (o GoogleCloudAiplatformV1beta1NotebookEucConfigPtrOutput) EucDisabled() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1NotebookEucConfig) *bool {
		if v == nil {
			return nil
		}
		return v.EucDisabled
	}).(pulumi.BoolPtrOutput)
}

// The euc configuration of NotebookRuntimeTemplate.
type GoogleCloudAiplatformV1beta1NotebookEucConfigResponse struct {
	// Whether ActAs check is bypassed for service account attached to the VM. If false, we need ActAs check for the default Compute Engine Service account. When a Runtime is created, a VM is allocated using Default Compute Engine Service Account. Any user requesting to use this Runtime requires Service Account User (ActAs) permission over this SA. If true, Runtime owner is using EUC and does not require the above permission as VM no longer use default Compute Engine SA, but a P4SA.
	BypassActasCheck bool `pulumi:"bypassActasCheck"`
	// Input only. Whether EUC is disabled in this NotebookRuntimeTemplate. In proto3, the default value of a boolean is false. In this way, by default EUC will be enabled for NotebookRuntimeTemplate.
	EucDisabled bool `pulumi:"eucDisabled"`
}

// The euc configuration of NotebookRuntimeTemplate.
type GoogleCloudAiplatformV1beta1NotebookEucConfigResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1NotebookEucConfigResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1NotebookEucConfigResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1NotebookEucConfigResponseOutput) ToGoogleCloudAiplatformV1beta1NotebookEucConfigResponseOutput() GoogleCloudAiplatformV1beta1NotebookEucConfigResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1NotebookEucConfigResponseOutput) ToGoogleCloudAiplatformV1beta1NotebookEucConfigResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1NotebookEucConfigResponseOutput {
	return o
}

// Whether ActAs check is bypassed for service account attached to the VM. If false, we need ActAs check for the default Compute Engine Service account. When a Runtime is created, a VM is allocated using Default Compute Engine Service Account. Any user requesting to use this Runtime requires Service Account User (ActAs) permission over this SA. If true, Runtime owner is using EUC and does not require the above permission as VM no longer use default Compute Engine SA, but a P4SA.
func (o GoogleCloudAiplatformV1beta1NotebookEucConfigResponseOutput) BypassActasCheck() pulumi.BoolOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1NotebookEucConfigResponse) bool { return v.BypassActasCheck }).(pulumi.BoolOutput)
}

// Input only. Whether EUC is disabled in this NotebookRuntimeTemplate. In proto3, the default value of a boolean is false. In this way, by default EUC will be enabled for NotebookRuntimeTemplate.
func (o GoogleCloudAiplatformV1beta1NotebookEucConfigResponseOutput) EucDisabled() pulumi.BoolOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1NotebookEucConfigResponse) bool { return v.EucDisabled }).(pulumi.BoolOutput)
}

// The idle shutdown configuration of NotebookRuntimeTemplate, which contains the idle_timeout as required field.
type GoogleCloudAiplatformV1beta1NotebookIdleShutdownConfig struct {
	// Whether Idle Shutdown is disabled in this NotebookRuntimeTemplate.
	IdleShutdownDisabled *bool `pulumi:"idleShutdownDisabled"`
	// Duration is accurate to the second. In Notebook, Idle Timeout is accurate to minute so the range of idle_timeout (second) is: 10 * 60 ~ 1440 * 60.
	IdleTimeout string `pulumi:"idleTimeout"`
}

// GoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigInput is an input type that accepts GoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigArgs and GoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigInput` via:
//
//	GoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigArgs{...}
type GoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigOutput() GoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigOutput
	ToGoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigOutput
}

// The idle shutdown configuration of NotebookRuntimeTemplate, which contains the idle_timeout as required field.
type GoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigArgs struct {
	// Whether Idle Shutdown is disabled in this NotebookRuntimeTemplate.
	IdleShutdownDisabled pulumi.BoolPtrInput `pulumi:"idleShutdownDisabled"`
	// Duration is accurate to the second. In Notebook, Idle Timeout is accurate to minute so the range of idle_timeout (second) is: 10 * 60 ~ 1440 * 60.
	IdleTimeout pulumi.StringInput `pulumi:"idleTimeout"`
}

func (GoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1NotebookIdleShutdownConfig)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigArgs) ToGoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigOutput() GoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigOutput {
	return i.ToGoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigArgs) ToGoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigOutput)
}

func (i GoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigArgs) ToGoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigPtrOutput() GoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigArgs) ToGoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigOutput).ToGoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigArgs, GoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigPtr and GoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigPtrOutput() GoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigPtrOutput
	ToGoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigPtrOutput
}

type googleCloudAiplatformV1beta1NotebookIdleShutdownConfigPtrType GoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigArgs

func GoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigPtr(v *GoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigArgs) GoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigPtrInput {
	return (*googleCloudAiplatformV1beta1NotebookIdleShutdownConfigPtrType)(v)
}

func (*googleCloudAiplatformV1beta1NotebookIdleShutdownConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1NotebookIdleShutdownConfig)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1NotebookIdleShutdownConfigPtrType) ToGoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigPtrOutput() GoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1NotebookIdleShutdownConfigPtrType) ToGoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigPtrOutput)
}

// The idle shutdown configuration of NotebookRuntimeTemplate, which contains the idle_timeout as required field.
type GoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1NotebookIdleShutdownConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigOutput) ToGoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigOutput() GoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigOutput) ToGoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigOutput) ToGoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigPtrOutput() GoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigOutput) ToGoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1NotebookIdleShutdownConfig) *GoogleCloudAiplatformV1beta1NotebookIdleShutdownConfig {
		return &v
	}).(GoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigPtrOutput)
}

// Whether Idle Shutdown is disabled in this NotebookRuntimeTemplate.
func (o GoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigOutput) IdleShutdownDisabled() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1NotebookIdleShutdownConfig) *bool { return v.IdleShutdownDisabled }).(pulumi.BoolPtrOutput)
}

// Duration is accurate to the second. In Notebook, Idle Timeout is accurate to minute so the range of idle_timeout (second) is: 10 * 60 ~ 1440 * 60.
func (o GoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigOutput) IdleTimeout() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1NotebookIdleShutdownConfig) string { return v.IdleTimeout }).(pulumi.StringOutput)
}

type GoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1NotebookIdleShutdownConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigPtrOutput) ToGoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigPtrOutput() GoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigPtrOutput) ToGoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigPtrOutput) Elem() GoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1NotebookIdleShutdownConfig) GoogleCloudAiplatformV1beta1NotebookIdleShutdownConfig {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1NotebookIdleShutdownConfig
		return ret
	}).(GoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigOutput)
}

// Whether Idle Shutdown is disabled in this NotebookRuntimeTemplate.
func (o GoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigPtrOutput) IdleShutdownDisabled() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1NotebookIdleShutdownConfig) *bool {
		if v == nil {
			return nil
		}
		return v.IdleShutdownDisabled
	}).(pulumi.BoolPtrOutput)
}

// Duration is accurate to the second. In Notebook, Idle Timeout is accurate to minute so the range of idle_timeout (second) is: 10 * 60 ~ 1440 * 60.
func (o GoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigPtrOutput) IdleTimeout() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1NotebookIdleShutdownConfig) *string {
		if v == nil {
			return nil
		}
		return &v.IdleTimeout
	}).(pulumi.StringPtrOutput)
}

// The idle shutdown configuration of NotebookRuntimeTemplate, which contains the idle_timeout as required field.
type GoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigResponse struct {
	// Whether Idle Shutdown is disabled in this NotebookRuntimeTemplate.
	IdleShutdownDisabled bool `pulumi:"idleShutdownDisabled"`
	// Duration is accurate to the second. In Notebook, Idle Timeout is accurate to minute so the range of idle_timeout (second) is: 10 * 60 ~ 1440 * 60.
	IdleTimeout string `pulumi:"idleTimeout"`
}

// The idle shutdown configuration of NotebookRuntimeTemplate, which contains the idle_timeout as required field.
type GoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigResponseOutput) ToGoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigResponseOutput() GoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigResponseOutput) ToGoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigResponseOutput {
	return o
}

// Whether Idle Shutdown is disabled in this NotebookRuntimeTemplate.
func (o GoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigResponseOutput) IdleShutdownDisabled() pulumi.BoolOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigResponse) bool {
		return v.IdleShutdownDisabled
	}).(pulumi.BoolOutput)
}

// Duration is accurate to the second. In Notebook, Idle Timeout is accurate to minute so the range of idle_timeout (second) is: 10 * 60 ~ 1440 * 60.
func (o GoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigResponseOutput) IdleTimeout() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigResponse) string { return v.IdleTimeout }).(pulumi.StringOutput)
}

// Represents the spec of persistent disk options.
type GoogleCloudAiplatformV1beta1PersistentDiskSpec struct {
	// Size in GB of the disk (default is 100GB).
	DiskSizeGb *string `pulumi:"diskSizeGb"`
	// Type of the disk (default is "pd-standard"). Valid values: "pd-ssd" (Persistent Disk Solid State Drive) "pd-standard" (Persistent Disk Hard Disk Drive) "pd-balanced" (Balanced Persistent Disk) "pd-extreme" (Extreme Persistent Disk)
	DiskType *string `pulumi:"diskType"`
}

// GoogleCloudAiplatformV1beta1PersistentDiskSpecInput is an input type that accepts GoogleCloudAiplatformV1beta1PersistentDiskSpecArgs and GoogleCloudAiplatformV1beta1PersistentDiskSpecOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1PersistentDiskSpecInput` via:
//
//	GoogleCloudAiplatformV1beta1PersistentDiskSpecArgs{...}
type GoogleCloudAiplatformV1beta1PersistentDiskSpecInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1PersistentDiskSpecOutput() GoogleCloudAiplatformV1beta1PersistentDiskSpecOutput
	ToGoogleCloudAiplatformV1beta1PersistentDiskSpecOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1PersistentDiskSpecOutput
}

// Represents the spec of persistent disk options.
type GoogleCloudAiplatformV1beta1PersistentDiskSpecArgs struct {
	// Size in GB of the disk (default is 100GB).
	DiskSizeGb pulumi.StringPtrInput `pulumi:"diskSizeGb"`
	// Type of the disk (default is "pd-standard"). Valid values: "pd-ssd" (Persistent Disk Solid State Drive) "pd-standard" (Persistent Disk Hard Disk Drive) "pd-balanced" (Balanced Persistent Disk) "pd-extreme" (Extreme Persistent Disk)
	DiskType pulumi.StringPtrInput `pulumi:"diskType"`
}

func (GoogleCloudAiplatformV1beta1PersistentDiskSpecArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1PersistentDiskSpec)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1PersistentDiskSpecArgs) ToGoogleCloudAiplatformV1beta1PersistentDiskSpecOutput() GoogleCloudAiplatformV1beta1PersistentDiskSpecOutput {
	return i.ToGoogleCloudAiplatformV1beta1PersistentDiskSpecOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1PersistentDiskSpecArgs) ToGoogleCloudAiplatformV1beta1PersistentDiskSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1PersistentDiskSpecOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1PersistentDiskSpecOutput)
}

func (i GoogleCloudAiplatformV1beta1PersistentDiskSpecArgs) ToGoogleCloudAiplatformV1beta1PersistentDiskSpecPtrOutput() GoogleCloudAiplatformV1beta1PersistentDiskSpecPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1PersistentDiskSpecPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1PersistentDiskSpecArgs) ToGoogleCloudAiplatformV1beta1PersistentDiskSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1PersistentDiskSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1PersistentDiskSpecOutput).ToGoogleCloudAiplatformV1beta1PersistentDiskSpecPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1PersistentDiskSpecPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1PersistentDiskSpecArgs, GoogleCloudAiplatformV1beta1PersistentDiskSpecPtr and GoogleCloudAiplatformV1beta1PersistentDiskSpecPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1PersistentDiskSpecPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1PersistentDiskSpecArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1PersistentDiskSpecPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1PersistentDiskSpecPtrOutput() GoogleCloudAiplatformV1beta1PersistentDiskSpecPtrOutput
	ToGoogleCloudAiplatformV1beta1PersistentDiskSpecPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1PersistentDiskSpecPtrOutput
}

type googleCloudAiplatformV1beta1PersistentDiskSpecPtrType GoogleCloudAiplatformV1beta1PersistentDiskSpecArgs

func GoogleCloudAiplatformV1beta1PersistentDiskSpecPtr(v *GoogleCloudAiplatformV1beta1PersistentDiskSpecArgs) GoogleCloudAiplatformV1beta1PersistentDiskSpecPtrInput {
	return (*googleCloudAiplatformV1beta1PersistentDiskSpecPtrType)(v)
}

func (*googleCloudAiplatformV1beta1PersistentDiskSpecPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1PersistentDiskSpec)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1PersistentDiskSpecPtrType) ToGoogleCloudAiplatformV1beta1PersistentDiskSpecPtrOutput() GoogleCloudAiplatformV1beta1PersistentDiskSpecPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1PersistentDiskSpecPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1PersistentDiskSpecPtrType) ToGoogleCloudAiplatformV1beta1PersistentDiskSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1PersistentDiskSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1PersistentDiskSpecPtrOutput)
}

// Represents the spec of persistent disk options.
type GoogleCloudAiplatformV1beta1PersistentDiskSpecOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1PersistentDiskSpecOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1PersistentDiskSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1PersistentDiskSpecOutput) ToGoogleCloudAiplatformV1beta1PersistentDiskSpecOutput() GoogleCloudAiplatformV1beta1PersistentDiskSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1PersistentDiskSpecOutput) ToGoogleCloudAiplatformV1beta1PersistentDiskSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1PersistentDiskSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1PersistentDiskSpecOutput) ToGoogleCloudAiplatformV1beta1PersistentDiskSpecPtrOutput() GoogleCloudAiplatformV1beta1PersistentDiskSpecPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1PersistentDiskSpecPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1PersistentDiskSpecOutput) ToGoogleCloudAiplatformV1beta1PersistentDiskSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1PersistentDiskSpecPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1PersistentDiskSpec) *GoogleCloudAiplatformV1beta1PersistentDiskSpec {
		return &v
	}).(GoogleCloudAiplatformV1beta1PersistentDiskSpecPtrOutput)
}

// Size in GB of the disk (default is 100GB).
func (o GoogleCloudAiplatformV1beta1PersistentDiskSpecOutput) DiskSizeGb() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PersistentDiskSpec) *string { return v.DiskSizeGb }).(pulumi.StringPtrOutput)
}

// Type of the disk (default is "pd-standard"). Valid values: "pd-ssd" (Persistent Disk Solid State Drive) "pd-standard" (Persistent Disk Hard Disk Drive) "pd-balanced" (Balanced Persistent Disk) "pd-extreme" (Extreme Persistent Disk)
func (o GoogleCloudAiplatformV1beta1PersistentDiskSpecOutput) DiskType() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PersistentDiskSpec) *string { return v.DiskType }).(pulumi.StringPtrOutput)
}

type GoogleCloudAiplatformV1beta1PersistentDiskSpecPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1PersistentDiskSpecPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1PersistentDiskSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1PersistentDiskSpecPtrOutput) ToGoogleCloudAiplatformV1beta1PersistentDiskSpecPtrOutput() GoogleCloudAiplatformV1beta1PersistentDiskSpecPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1PersistentDiskSpecPtrOutput) ToGoogleCloudAiplatformV1beta1PersistentDiskSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1PersistentDiskSpecPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1PersistentDiskSpecPtrOutput) Elem() GoogleCloudAiplatformV1beta1PersistentDiskSpecOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1PersistentDiskSpec) GoogleCloudAiplatformV1beta1PersistentDiskSpec {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1PersistentDiskSpec
		return ret
	}).(GoogleCloudAiplatformV1beta1PersistentDiskSpecOutput)
}

// Size in GB of the disk (default is 100GB).
func (o GoogleCloudAiplatformV1beta1PersistentDiskSpecPtrOutput) DiskSizeGb() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1PersistentDiskSpec) *string {
		if v == nil {
			return nil
		}
		return v.DiskSizeGb
	}).(pulumi.StringPtrOutput)
}

// Type of the disk (default is "pd-standard"). Valid values: "pd-ssd" (Persistent Disk Solid State Drive) "pd-standard" (Persistent Disk Hard Disk Drive) "pd-balanced" (Balanced Persistent Disk) "pd-extreme" (Extreme Persistent Disk)
func (o GoogleCloudAiplatformV1beta1PersistentDiskSpecPtrOutput) DiskType() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1PersistentDiskSpec) *string {
		if v == nil {
			return nil
		}
		return v.DiskType
	}).(pulumi.StringPtrOutput)
}

// Represents the spec of persistent disk options.
type GoogleCloudAiplatformV1beta1PersistentDiskSpecResponse struct {
	// Size in GB of the disk (default is 100GB).
	DiskSizeGb string `pulumi:"diskSizeGb"`
	// Type of the disk (default is "pd-standard"). Valid values: "pd-ssd" (Persistent Disk Solid State Drive) "pd-standard" (Persistent Disk Hard Disk Drive) "pd-balanced" (Balanced Persistent Disk) "pd-extreme" (Extreme Persistent Disk)
	DiskType string `pulumi:"diskType"`
}

// Represents the spec of persistent disk options.
type GoogleCloudAiplatformV1beta1PersistentDiskSpecResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1PersistentDiskSpecResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1PersistentDiskSpecResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1PersistentDiskSpecResponseOutput) ToGoogleCloudAiplatformV1beta1PersistentDiskSpecResponseOutput() GoogleCloudAiplatformV1beta1PersistentDiskSpecResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1PersistentDiskSpecResponseOutput) ToGoogleCloudAiplatformV1beta1PersistentDiskSpecResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1PersistentDiskSpecResponseOutput {
	return o
}

// Size in GB of the disk (default is 100GB).
func (o GoogleCloudAiplatformV1beta1PersistentDiskSpecResponseOutput) DiskSizeGb() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PersistentDiskSpecResponse) string { return v.DiskSizeGb }).(pulumi.StringOutput)
}

// Type of the disk (default is "pd-standard"). Valid values: "pd-ssd" (Persistent Disk Solid State Drive) "pd-standard" (Persistent Disk Hard Disk Drive) "pd-balanced" (Balanced Persistent Disk) "pd-extreme" (Extreme Persistent Disk)
func (o GoogleCloudAiplatformV1beta1PersistentDiskSpecResponseOutput) DiskType() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PersistentDiskSpecResponse) string { return v.DiskType }).(pulumi.StringOutput)
}

// An instance of a machine learning PipelineJob.
type GoogleCloudAiplatformV1beta1PipelineJob struct {
	// The display name of the Pipeline. The name can be up to 128 characters long and can consist of any UTF-8 characters.
	DisplayName *string `pulumi:"displayName"`
	// Customer-managed encryption key spec for a pipelineJob. If set, this PipelineJob and all of its sub-resources will be secured by this key.
	EncryptionSpec *GoogleCloudAiplatformV1beta1EncryptionSpec `pulumi:"encryptionSpec"`
	// The labels with user-defined metadata to organize PipelineJob. Label keys and values can be no longer than 64 characters (Unicode codepoints), can only contain lowercase letters, numeric characters, underscores and dashes. International characters are allowed. See https://goo.gl/xmQnxf for more information and examples of labels. Note there is some reserved label key for Vertex AI Pipelines. - `vertex-ai-pipelines-run-billing-id`, user set value will get overrided.
	Labels map[string]string `pulumi:"labels"`
	// The full name of the Compute Engine [network](/compute/docs/networks-and-firewalls#networks) to which the Pipeline Job's workload should be peered. For example, `projects/12345/global/networks/myVPC`. [Format](/compute/docs/reference/rest/v1/networks/insert) is of the form `projects/{project}/global/networks/{network}`. Where {project} is a project number, as in `12345`, and {network} is a network name. Private services access must already be configured for the network. Pipeline job will apply the network configuration to the Google Cloud resources being launched, if applied, such as Vertex AI Training or Dataflow job. If left unspecified, the workload is not peered with any network.
	Network *string `pulumi:"network"`
	// The spec of the pipeline.
	PipelineSpec map[string]interface{} `pulumi:"pipelineSpec"`
	// A list of names for the reserved ip ranges under the VPC network that can be used for this Pipeline Job's workload. If set, we will deploy the Pipeline Job's workload within the provided ip ranges. Otherwise, the job will be deployed to any ip ranges under the provided VPC network. Example: ['vertex-ai-ip-range'].
	ReservedIpRanges []string `pulumi:"reservedIpRanges"`
	// Runtime config of the pipeline.
	RuntimeConfig *GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfig `pulumi:"runtimeConfig"`
	// The service account that the pipeline workload runs as. If not specified, the Compute Engine default service account in the project will be used. See https://cloud.google.com/compute/docs/access/service-accounts#default_service_account Users starting the pipeline must have the `iam.serviceAccounts.actAs` permission on this service account.
	ServiceAccount *string `pulumi:"serviceAccount"`
	// A template uri from where the PipelineJob.pipeline_spec, if empty, will be downloaded. Currently, only uri from Vertex Template Registry & Gallery is supported. Reference to https://cloud.google.com/vertex-ai/docs/pipelines/create-pipeline-template.
	TemplateUri *string `pulumi:"templateUri"`
}

// GoogleCloudAiplatformV1beta1PipelineJobInput is an input type that accepts GoogleCloudAiplatformV1beta1PipelineJobArgs and GoogleCloudAiplatformV1beta1PipelineJobOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1PipelineJobInput` via:
//
//	GoogleCloudAiplatformV1beta1PipelineJobArgs{...}
type GoogleCloudAiplatformV1beta1PipelineJobInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1PipelineJobOutput() GoogleCloudAiplatformV1beta1PipelineJobOutput
	ToGoogleCloudAiplatformV1beta1PipelineJobOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1PipelineJobOutput
}

// An instance of a machine learning PipelineJob.
type GoogleCloudAiplatformV1beta1PipelineJobArgs struct {
	// The display name of the Pipeline. The name can be up to 128 characters long and can consist of any UTF-8 characters.
	DisplayName pulumi.StringPtrInput `pulumi:"displayName"`
	// Customer-managed encryption key spec for a pipelineJob. If set, this PipelineJob and all of its sub-resources will be secured by this key.
	EncryptionSpec GoogleCloudAiplatformV1beta1EncryptionSpecPtrInput `pulumi:"encryptionSpec"`
	// The labels with user-defined metadata to organize PipelineJob. Label keys and values can be no longer than 64 characters (Unicode codepoints), can only contain lowercase letters, numeric characters, underscores and dashes. International characters are allowed. See https://goo.gl/xmQnxf for more information and examples of labels. Note there is some reserved label key for Vertex AI Pipelines. - `vertex-ai-pipelines-run-billing-id`, user set value will get overrided.
	Labels pulumi.StringMapInput `pulumi:"labels"`
	// The full name of the Compute Engine [network](/compute/docs/networks-and-firewalls#networks) to which the Pipeline Job's workload should be peered. For example, `projects/12345/global/networks/myVPC`. [Format](/compute/docs/reference/rest/v1/networks/insert) is of the form `projects/{project}/global/networks/{network}`. Where {project} is a project number, as in `12345`, and {network} is a network name. Private services access must already be configured for the network. Pipeline job will apply the network configuration to the Google Cloud resources being launched, if applied, such as Vertex AI Training or Dataflow job. If left unspecified, the workload is not peered with any network.
	Network pulumi.StringPtrInput `pulumi:"network"`
	// The spec of the pipeline.
	PipelineSpec pulumi.MapInput `pulumi:"pipelineSpec"`
	// A list of names for the reserved ip ranges under the VPC network that can be used for this Pipeline Job's workload. If set, we will deploy the Pipeline Job's workload within the provided ip ranges. Otherwise, the job will be deployed to any ip ranges under the provided VPC network. Example: ['vertex-ai-ip-range'].
	ReservedIpRanges pulumi.StringArrayInput `pulumi:"reservedIpRanges"`
	// Runtime config of the pipeline.
	RuntimeConfig GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigPtrInput `pulumi:"runtimeConfig"`
	// The service account that the pipeline workload runs as. If not specified, the Compute Engine default service account in the project will be used. See https://cloud.google.com/compute/docs/access/service-accounts#default_service_account Users starting the pipeline must have the `iam.serviceAccounts.actAs` permission on this service account.
	ServiceAccount pulumi.StringPtrInput `pulumi:"serviceAccount"`
	// A template uri from where the PipelineJob.pipeline_spec, if empty, will be downloaded. Currently, only uri from Vertex Template Registry & Gallery is supported. Reference to https://cloud.google.com/vertex-ai/docs/pipelines/create-pipeline-template.
	TemplateUri pulumi.StringPtrInput `pulumi:"templateUri"`
}

func (GoogleCloudAiplatformV1beta1PipelineJobArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1PipelineJob)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1PipelineJobArgs) ToGoogleCloudAiplatformV1beta1PipelineJobOutput() GoogleCloudAiplatformV1beta1PipelineJobOutput {
	return i.ToGoogleCloudAiplatformV1beta1PipelineJobOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1PipelineJobArgs) ToGoogleCloudAiplatformV1beta1PipelineJobOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1PipelineJobOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1PipelineJobOutput)
}

func (i GoogleCloudAiplatformV1beta1PipelineJobArgs) ToGoogleCloudAiplatformV1beta1PipelineJobPtrOutput() GoogleCloudAiplatformV1beta1PipelineJobPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1PipelineJobPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1PipelineJobArgs) ToGoogleCloudAiplatformV1beta1PipelineJobPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1PipelineJobPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1PipelineJobOutput).ToGoogleCloudAiplatformV1beta1PipelineJobPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1PipelineJobPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1PipelineJobArgs, GoogleCloudAiplatformV1beta1PipelineJobPtr and GoogleCloudAiplatformV1beta1PipelineJobPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1PipelineJobPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1PipelineJobArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1PipelineJobPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1PipelineJobPtrOutput() GoogleCloudAiplatformV1beta1PipelineJobPtrOutput
	ToGoogleCloudAiplatformV1beta1PipelineJobPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1PipelineJobPtrOutput
}

type googleCloudAiplatformV1beta1PipelineJobPtrType GoogleCloudAiplatformV1beta1PipelineJobArgs

func GoogleCloudAiplatformV1beta1PipelineJobPtr(v *GoogleCloudAiplatformV1beta1PipelineJobArgs) GoogleCloudAiplatformV1beta1PipelineJobPtrInput {
	return (*googleCloudAiplatformV1beta1PipelineJobPtrType)(v)
}

func (*googleCloudAiplatformV1beta1PipelineJobPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1PipelineJob)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1PipelineJobPtrType) ToGoogleCloudAiplatformV1beta1PipelineJobPtrOutput() GoogleCloudAiplatformV1beta1PipelineJobPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1PipelineJobPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1PipelineJobPtrType) ToGoogleCloudAiplatformV1beta1PipelineJobPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1PipelineJobPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1PipelineJobPtrOutput)
}

// An instance of a machine learning PipelineJob.
type GoogleCloudAiplatformV1beta1PipelineJobOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1PipelineJobOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1PipelineJob)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1PipelineJobOutput) ToGoogleCloudAiplatformV1beta1PipelineJobOutput() GoogleCloudAiplatformV1beta1PipelineJobOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1PipelineJobOutput) ToGoogleCloudAiplatformV1beta1PipelineJobOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1PipelineJobOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1PipelineJobOutput) ToGoogleCloudAiplatformV1beta1PipelineJobPtrOutput() GoogleCloudAiplatformV1beta1PipelineJobPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1PipelineJobPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1PipelineJobOutput) ToGoogleCloudAiplatformV1beta1PipelineJobPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1PipelineJobPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1PipelineJob) *GoogleCloudAiplatformV1beta1PipelineJob {
		return &v
	}).(GoogleCloudAiplatformV1beta1PipelineJobPtrOutput)
}

// The display name of the Pipeline. The name can be up to 128 characters long and can consist of any UTF-8 characters.
func (o GoogleCloudAiplatformV1beta1PipelineJobOutput) DisplayName() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PipelineJob) *string { return v.DisplayName }).(pulumi.StringPtrOutput)
}

// Customer-managed encryption key spec for a pipelineJob. If set, this PipelineJob and all of its sub-resources will be secured by this key.
func (o GoogleCloudAiplatformV1beta1PipelineJobOutput) EncryptionSpec() GoogleCloudAiplatformV1beta1EncryptionSpecPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PipelineJob) *GoogleCloudAiplatformV1beta1EncryptionSpec {
		return v.EncryptionSpec
	}).(GoogleCloudAiplatformV1beta1EncryptionSpecPtrOutput)
}

// The labels with user-defined metadata to organize PipelineJob. Label keys and values can be no longer than 64 characters (Unicode codepoints), can only contain lowercase letters, numeric characters, underscores and dashes. International characters are allowed. See https://goo.gl/xmQnxf for more information and examples of labels. Note there is some reserved label key for Vertex AI Pipelines. - `vertex-ai-pipelines-run-billing-id`, user set value will get overrided.
func (o GoogleCloudAiplatformV1beta1PipelineJobOutput) Labels() pulumi.StringMapOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PipelineJob) map[string]string { return v.Labels }).(pulumi.StringMapOutput)
}

// The full name of the Compute Engine [network](/compute/docs/networks-and-firewalls#networks) to which the Pipeline Job's workload should be peered. For example, `projects/12345/global/networks/myVPC`. [Format](/compute/docs/reference/rest/v1/networks/insert) is of the form `projects/{project}/global/networks/{network}`. Where {project} is a project number, as in `12345`, and {network} is a network name. Private services access must already be configured for the network. Pipeline job will apply the network configuration to the Google Cloud resources being launched, if applied, such as Vertex AI Training or Dataflow job. If left unspecified, the workload is not peered with any network.
func (o GoogleCloudAiplatformV1beta1PipelineJobOutput) Network() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PipelineJob) *string { return v.Network }).(pulumi.StringPtrOutput)
}

// The spec of the pipeline.
func (o GoogleCloudAiplatformV1beta1PipelineJobOutput) PipelineSpec() pulumi.MapOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PipelineJob) map[string]interface{} { return v.PipelineSpec }).(pulumi.MapOutput)
}

// A list of names for the reserved ip ranges under the VPC network that can be used for this Pipeline Job's workload. If set, we will deploy the Pipeline Job's workload within the provided ip ranges. Otherwise, the job will be deployed to any ip ranges under the provided VPC network. Example: ['vertex-ai-ip-range'].
func (o GoogleCloudAiplatformV1beta1PipelineJobOutput) ReservedIpRanges() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PipelineJob) []string { return v.ReservedIpRanges }).(pulumi.StringArrayOutput)
}

// Runtime config of the pipeline.
func (o GoogleCloudAiplatformV1beta1PipelineJobOutput) RuntimeConfig() GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PipelineJob) *GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfig {
		return v.RuntimeConfig
	}).(GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigPtrOutput)
}

// The service account that the pipeline workload runs as. If not specified, the Compute Engine default service account in the project will be used. See https://cloud.google.com/compute/docs/access/service-accounts#default_service_account Users starting the pipeline must have the `iam.serviceAccounts.actAs` permission on this service account.
func (o GoogleCloudAiplatformV1beta1PipelineJobOutput) ServiceAccount() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PipelineJob) *string { return v.ServiceAccount }).(pulumi.StringPtrOutput)
}

// A template uri from where the PipelineJob.pipeline_spec, if empty, will be downloaded. Currently, only uri from Vertex Template Registry & Gallery is supported. Reference to https://cloud.google.com/vertex-ai/docs/pipelines/create-pipeline-template.
func (o GoogleCloudAiplatformV1beta1PipelineJobOutput) TemplateUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PipelineJob) *string { return v.TemplateUri }).(pulumi.StringPtrOutput)
}

type GoogleCloudAiplatformV1beta1PipelineJobPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1PipelineJobPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1PipelineJob)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1PipelineJobPtrOutput) ToGoogleCloudAiplatformV1beta1PipelineJobPtrOutput() GoogleCloudAiplatformV1beta1PipelineJobPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1PipelineJobPtrOutput) ToGoogleCloudAiplatformV1beta1PipelineJobPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1PipelineJobPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1PipelineJobPtrOutput) Elem() GoogleCloudAiplatformV1beta1PipelineJobOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1PipelineJob) GoogleCloudAiplatformV1beta1PipelineJob {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1PipelineJob
		return ret
	}).(GoogleCloudAiplatformV1beta1PipelineJobOutput)
}

// The display name of the Pipeline. The name can be up to 128 characters long and can consist of any UTF-8 characters.
func (o GoogleCloudAiplatformV1beta1PipelineJobPtrOutput) DisplayName() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1PipelineJob) *string {
		if v == nil {
			return nil
		}
		return v.DisplayName
	}).(pulumi.StringPtrOutput)
}

// Customer-managed encryption key spec for a pipelineJob. If set, this PipelineJob and all of its sub-resources will be secured by this key.
func (o GoogleCloudAiplatformV1beta1PipelineJobPtrOutput) EncryptionSpec() GoogleCloudAiplatformV1beta1EncryptionSpecPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1PipelineJob) *GoogleCloudAiplatformV1beta1EncryptionSpec {
		if v == nil {
			return nil
		}
		return v.EncryptionSpec
	}).(GoogleCloudAiplatformV1beta1EncryptionSpecPtrOutput)
}

// The labels with user-defined metadata to organize PipelineJob. Label keys and values can be no longer than 64 characters (Unicode codepoints), can only contain lowercase letters, numeric characters, underscores and dashes. International characters are allowed. See https://goo.gl/xmQnxf for more information and examples of labels. Note there is some reserved label key for Vertex AI Pipelines. - `vertex-ai-pipelines-run-billing-id`, user set value will get overrided.
func (o GoogleCloudAiplatformV1beta1PipelineJobPtrOutput) Labels() pulumi.StringMapOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1PipelineJob) map[string]string {
		if v == nil {
			return nil
		}
		return v.Labels
	}).(pulumi.StringMapOutput)
}

// The full name of the Compute Engine [network](/compute/docs/networks-and-firewalls#networks) to which the Pipeline Job's workload should be peered. For example, `projects/12345/global/networks/myVPC`. [Format](/compute/docs/reference/rest/v1/networks/insert) is of the form `projects/{project}/global/networks/{network}`. Where {project} is a project number, as in `12345`, and {network} is a network name. Private services access must already be configured for the network. Pipeline job will apply the network configuration to the Google Cloud resources being launched, if applied, such as Vertex AI Training or Dataflow job. If left unspecified, the workload is not peered with any network.
func (o GoogleCloudAiplatformV1beta1PipelineJobPtrOutput) Network() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1PipelineJob) *string {
		if v == nil {
			return nil
		}
		return v.Network
	}).(pulumi.StringPtrOutput)
}

// The spec of the pipeline.
func (o GoogleCloudAiplatformV1beta1PipelineJobPtrOutput) PipelineSpec() pulumi.MapOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1PipelineJob) map[string]interface{} {
		if v == nil {
			return nil
		}
		return v.PipelineSpec
	}).(pulumi.MapOutput)
}

// A list of names for the reserved ip ranges under the VPC network that can be used for this Pipeline Job's workload. If set, we will deploy the Pipeline Job's workload within the provided ip ranges. Otherwise, the job will be deployed to any ip ranges under the provided VPC network. Example: ['vertex-ai-ip-range'].
func (o GoogleCloudAiplatformV1beta1PipelineJobPtrOutput) ReservedIpRanges() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1PipelineJob) []string {
		if v == nil {
			return nil
		}
		return v.ReservedIpRanges
	}).(pulumi.StringArrayOutput)
}

// Runtime config of the pipeline.
func (o GoogleCloudAiplatformV1beta1PipelineJobPtrOutput) RuntimeConfig() GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1PipelineJob) *GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfig {
		if v == nil {
			return nil
		}
		return v.RuntimeConfig
	}).(GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigPtrOutput)
}

// The service account that the pipeline workload runs as. If not specified, the Compute Engine default service account in the project will be used. See https://cloud.google.com/compute/docs/access/service-accounts#default_service_account Users starting the pipeline must have the `iam.serviceAccounts.actAs` permission on this service account.
func (o GoogleCloudAiplatformV1beta1PipelineJobPtrOutput) ServiceAccount() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1PipelineJob) *string {
		if v == nil {
			return nil
		}
		return v.ServiceAccount
	}).(pulumi.StringPtrOutput)
}

// A template uri from where the PipelineJob.pipeline_spec, if empty, will be downloaded. Currently, only uri from Vertex Template Registry & Gallery is supported. Reference to https://cloud.google.com/vertex-ai/docs/pipelines/create-pipeline-template.
func (o GoogleCloudAiplatformV1beta1PipelineJobPtrOutput) TemplateUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1PipelineJob) *string {
		if v == nil {
			return nil
		}
		return v.TemplateUri
	}).(pulumi.StringPtrOutput)
}

// The runtime detail of PipelineJob.
type GoogleCloudAiplatformV1beta1PipelineJobDetailResponse struct {
	// The context of the pipeline.
	PipelineContext GoogleCloudAiplatformV1beta1ContextResponse `pulumi:"pipelineContext"`
	// The context of the current pipeline run.
	PipelineRunContext GoogleCloudAiplatformV1beta1ContextResponse `pulumi:"pipelineRunContext"`
	// The runtime details of the tasks under the pipeline.
	TaskDetails []GoogleCloudAiplatformV1beta1PipelineTaskDetailResponse `pulumi:"taskDetails"`
}

// The runtime detail of PipelineJob.
type GoogleCloudAiplatformV1beta1PipelineJobDetailResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1PipelineJobDetailResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1PipelineJobDetailResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1PipelineJobDetailResponseOutput) ToGoogleCloudAiplatformV1beta1PipelineJobDetailResponseOutput() GoogleCloudAiplatformV1beta1PipelineJobDetailResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1PipelineJobDetailResponseOutput) ToGoogleCloudAiplatformV1beta1PipelineJobDetailResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1PipelineJobDetailResponseOutput {
	return o
}

// The context of the pipeline.
func (o GoogleCloudAiplatformV1beta1PipelineJobDetailResponseOutput) PipelineContext() GoogleCloudAiplatformV1beta1ContextResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PipelineJobDetailResponse) GoogleCloudAiplatformV1beta1ContextResponse {
		return v.PipelineContext
	}).(GoogleCloudAiplatformV1beta1ContextResponseOutput)
}

// The context of the current pipeline run.
func (o GoogleCloudAiplatformV1beta1PipelineJobDetailResponseOutput) PipelineRunContext() GoogleCloudAiplatformV1beta1ContextResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PipelineJobDetailResponse) GoogleCloudAiplatformV1beta1ContextResponse {
		return v.PipelineRunContext
	}).(GoogleCloudAiplatformV1beta1ContextResponseOutput)
}

// The runtime details of the tasks under the pipeline.
func (o GoogleCloudAiplatformV1beta1PipelineJobDetailResponseOutput) TaskDetails() GoogleCloudAiplatformV1beta1PipelineTaskDetailResponseArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PipelineJobDetailResponse) []GoogleCloudAiplatformV1beta1PipelineTaskDetailResponse {
		return v.TaskDetails
	}).(GoogleCloudAiplatformV1beta1PipelineTaskDetailResponseArrayOutput)
}

// An instance of a machine learning PipelineJob.
type GoogleCloudAiplatformV1beta1PipelineJobResponse struct {
	// Pipeline creation time.
	CreateTime string `pulumi:"createTime"`
	// The display name of the Pipeline. The name can be up to 128 characters long and can consist of any UTF-8 characters.
	DisplayName string `pulumi:"displayName"`
	// Customer-managed encryption key spec for a pipelineJob. If set, this PipelineJob and all of its sub-resources will be secured by this key.
	EncryptionSpec GoogleCloudAiplatformV1beta1EncryptionSpecResponse `pulumi:"encryptionSpec"`
	// Pipeline end time.
	EndTime string `pulumi:"endTime"`
	// The error that occurred during pipeline execution. Only populated when the pipeline's state is FAILED or CANCELLED.
	Error GoogleRpcStatusResponse `pulumi:"error"`
	// The details of pipeline run. Not available in the list view.
	JobDetail GoogleCloudAiplatformV1beta1PipelineJobDetailResponse `pulumi:"jobDetail"`
	// The labels with user-defined metadata to organize PipelineJob. Label keys and values can be no longer than 64 characters (Unicode codepoints), can only contain lowercase letters, numeric characters, underscores and dashes. International characters are allowed. See https://goo.gl/xmQnxf for more information and examples of labels. Note there is some reserved label key for Vertex AI Pipelines. - `vertex-ai-pipelines-run-billing-id`, user set value will get overrided.
	Labels map[string]string `pulumi:"labels"`
	// The resource name of the PipelineJob.
	Name string `pulumi:"name"`
	// The full name of the Compute Engine [network](/compute/docs/networks-and-firewalls#networks) to which the Pipeline Job's workload should be peered. For example, `projects/12345/global/networks/myVPC`. [Format](/compute/docs/reference/rest/v1/networks/insert) is of the form `projects/{project}/global/networks/{network}`. Where {project} is a project number, as in `12345`, and {network} is a network name. Private services access must already be configured for the network. Pipeline job will apply the network configuration to the Google Cloud resources being launched, if applied, such as Vertex AI Training or Dataflow job. If left unspecified, the workload is not peered with any network.
	Network string `pulumi:"network"`
	// The spec of the pipeline.
	PipelineSpec map[string]interface{} `pulumi:"pipelineSpec"`
	// A list of names for the reserved ip ranges under the VPC network that can be used for this Pipeline Job's workload. If set, we will deploy the Pipeline Job's workload within the provided ip ranges. Otherwise, the job will be deployed to any ip ranges under the provided VPC network. Example: ['vertex-ai-ip-range'].
	ReservedIpRanges []string `pulumi:"reservedIpRanges"`
	// Runtime config of the pipeline.
	RuntimeConfig GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigResponse `pulumi:"runtimeConfig"`
	// The schedule resource name. Only returned if the Pipeline is created by Schedule API.
	ScheduleName string `pulumi:"scheduleName"`
	// The service account that the pipeline workload runs as. If not specified, the Compute Engine default service account in the project will be used. See https://cloud.google.com/compute/docs/access/service-accounts#default_service_account Users starting the pipeline must have the `iam.serviceAccounts.actAs` permission on this service account.
	ServiceAccount string `pulumi:"serviceAccount"`
	// Pipeline start time.
	StartTime string `pulumi:"startTime"`
	// The detailed state of the job.
	State string `pulumi:"state"`
	// Pipeline template metadata. Will fill up fields if PipelineJob.template_uri is from supported template registry.
	TemplateMetadata GoogleCloudAiplatformV1beta1PipelineTemplateMetadataResponse `pulumi:"templateMetadata"`
	// A template uri from where the PipelineJob.pipeline_spec, if empty, will be downloaded. Currently, only uri from Vertex Template Registry & Gallery is supported. Reference to https://cloud.google.com/vertex-ai/docs/pipelines/create-pipeline-template.
	TemplateUri string `pulumi:"templateUri"`
	// Timestamp when this PipelineJob was most recently updated.
	UpdateTime string `pulumi:"updateTime"`
}

// An instance of a machine learning PipelineJob.
type GoogleCloudAiplatformV1beta1PipelineJobResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1PipelineJobResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1PipelineJobResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1PipelineJobResponseOutput) ToGoogleCloudAiplatformV1beta1PipelineJobResponseOutput() GoogleCloudAiplatformV1beta1PipelineJobResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1PipelineJobResponseOutput) ToGoogleCloudAiplatformV1beta1PipelineJobResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1PipelineJobResponseOutput {
	return o
}

// Pipeline creation time.
func (o GoogleCloudAiplatformV1beta1PipelineJobResponseOutput) CreateTime() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PipelineJobResponse) string { return v.CreateTime }).(pulumi.StringOutput)
}

// The display name of the Pipeline. The name can be up to 128 characters long and can consist of any UTF-8 characters.
func (o GoogleCloudAiplatformV1beta1PipelineJobResponseOutput) DisplayName() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PipelineJobResponse) string { return v.DisplayName }).(pulumi.StringOutput)
}

// Customer-managed encryption key spec for a pipelineJob. If set, this PipelineJob and all of its sub-resources will be secured by this key.
func (o GoogleCloudAiplatformV1beta1PipelineJobResponseOutput) EncryptionSpec() GoogleCloudAiplatformV1beta1EncryptionSpecResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PipelineJobResponse) GoogleCloudAiplatformV1beta1EncryptionSpecResponse {
		return v.EncryptionSpec
	}).(GoogleCloudAiplatformV1beta1EncryptionSpecResponseOutput)
}

// Pipeline end time.
func (o GoogleCloudAiplatformV1beta1PipelineJobResponseOutput) EndTime() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PipelineJobResponse) string { return v.EndTime }).(pulumi.StringOutput)
}

// The error that occurred during pipeline execution. Only populated when the pipeline's state is FAILED or CANCELLED.
func (o GoogleCloudAiplatformV1beta1PipelineJobResponseOutput) Error() GoogleRpcStatusResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PipelineJobResponse) GoogleRpcStatusResponse { return v.Error }).(GoogleRpcStatusResponseOutput)
}

// The details of pipeline run. Not available in the list view.
func (o GoogleCloudAiplatformV1beta1PipelineJobResponseOutput) JobDetail() GoogleCloudAiplatformV1beta1PipelineJobDetailResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PipelineJobResponse) GoogleCloudAiplatformV1beta1PipelineJobDetailResponse {
		return v.JobDetail
	}).(GoogleCloudAiplatformV1beta1PipelineJobDetailResponseOutput)
}

// The labels with user-defined metadata to organize PipelineJob. Label keys and values can be no longer than 64 characters (Unicode codepoints), can only contain lowercase letters, numeric characters, underscores and dashes. International characters are allowed. See https://goo.gl/xmQnxf for more information and examples of labels. Note there is some reserved label key for Vertex AI Pipelines. - `vertex-ai-pipelines-run-billing-id`, user set value will get overrided.
func (o GoogleCloudAiplatformV1beta1PipelineJobResponseOutput) Labels() pulumi.StringMapOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PipelineJobResponse) map[string]string { return v.Labels }).(pulumi.StringMapOutput)
}

// The resource name of the PipelineJob.
func (o GoogleCloudAiplatformV1beta1PipelineJobResponseOutput) Name() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PipelineJobResponse) string { return v.Name }).(pulumi.StringOutput)
}

// The full name of the Compute Engine [network](/compute/docs/networks-and-firewalls#networks) to which the Pipeline Job's workload should be peered. For example, `projects/12345/global/networks/myVPC`. [Format](/compute/docs/reference/rest/v1/networks/insert) is of the form `projects/{project}/global/networks/{network}`. Where {project} is a project number, as in `12345`, and {network} is a network name. Private services access must already be configured for the network. Pipeline job will apply the network configuration to the Google Cloud resources being launched, if applied, such as Vertex AI Training or Dataflow job. If left unspecified, the workload is not peered with any network.
func (o GoogleCloudAiplatformV1beta1PipelineJobResponseOutput) Network() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PipelineJobResponse) string { return v.Network }).(pulumi.StringOutput)
}

// The spec of the pipeline.
func (o GoogleCloudAiplatformV1beta1PipelineJobResponseOutput) PipelineSpec() pulumi.MapOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PipelineJobResponse) map[string]interface{} { return v.PipelineSpec }).(pulumi.MapOutput)
}

// A list of names for the reserved ip ranges under the VPC network that can be used for this Pipeline Job's workload. If set, we will deploy the Pipeline Job's workload within the provided ip ranges. Otherwise, the job will be deployed to any ip ranges under the provided VPC network. Example: ['vertex-ai-ip-range'].
func (o GoogleCloudAiplatformV1beta1PipelineJobResponseOutput) ReservedIpRanges() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PipelineJobResponse) []string { return v.ReservedIpRanges }).(pulumi.StringArrayOutput)
}

// Runtime config of the pipeline.
func (o GoogleCloudAiplatformV1beta1PipelineJobResponseOutput) RuntimeConfig() GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PipelineJobResponse) GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigResponse {
		return v.RuntimeConfig
	}).(GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigResponseOutput)
}

// The schedule resource name. Only returned if the Pipeline is created by Schedule API.
func (o GoogleCloudAiplatformV1beta1PipelineJobResponseOutput) ScheduleName() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PipelineJobResponse) string { return v.ScheduleName }).(pulumi.StringOutput)
}

// The service account that the pipeline workload runs as. If not specified, the Compute Engine default service account in the project will be used. See https://cloud.google.com/compute/docs/access/service-accounts#default_service_account Users starting the pipeline must have the `iam.serviceAccounts.actAs` permission on this service account.
func (o GoogleCloudAiplatformV1beta1PipelineJobResponseOutput) ServiceAccount() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PipelineJobResponse) string { return v.ServiceAccount }).(pulumi.StringOutput)
}

// Pipeline start time.
func (o GoogleCloudAiplatformV1beta1PipelineJobResponseOutput) StartTime() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PipelineJobResponse) string { return v.StartTime }).(pulumi.StringOutput)
}

// The detailed state of the job.
func (o GoogleCloudAiplatformV1beta1PipelineJobResponseOutput) State() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PipelineJobResponse) string { return v.State }).(pulumi.StringOutput)
}

// Pipeline template metadata. Will fill up fields if PipelineJob.template_uri is from supported template registry.
func (o GoogleCloudAiplatformV1beta1PipelineJobResponseOutput) TemplateMetadata() GoogleCloudAiplatformV1beta1PipelineTemplateMetadataResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PipelineJobResponse) GoogleCloudAiplatformV1beta1PipelineTemplateMetadataResponse {
		return v.TemplateMetadata
	}).(GoogleCloudAiplatformV1beta1PipelineTemplateMetadataResponseOutput)
}

// A template uri from where the PipelineJob.pipeline_spec, if empty, will be downloaded. Currently, only uri from Vertex Template Registry & Gallery is supported. Reference to https://cloud.google.com/vertex-ai/docs/pipelines/create-pipeline-template.
func (o GoogleCloudAiplatformV1beta1PipelineJobResponseOutput) TemplateUri() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PipelineJobResponse) string { return v.TemplateUri }).(pulumi.StringOutput)
}

// Timestamp when this PipelineJob was most recently updated.
func (o GoogleCloudAiplatformV1beta1PipelineJobResponseOutput) UpdateTime() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PipelineJobResponse) string { return v.UpdateTime }).(pulumi.StringOutput)
}

// The runtime config of a PipelineJob.
type GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfig struct {
	// Represents the failure policy of a pipeline. Currently, the default of a pipeline is that the pipeline will continue to run until no more tasks can be executed, also known as PIPELINE_FAILURE_POLICY_FAIL_SLOW. However, if a pipeline is set to PIPELINE_FAILURE_POLICY_FAIL_FAST, it will stop scheduling any new tasks when a task has failed. Any scheduled tasks will continue to completion.
	FailurePolicy *GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigFailurePolicy `pulumi:"failurePolicy"`
	// A path in a Cloud Storage bucket, which will be treated as the root output directory of the pipeline. It is used by the system to generate the paths of output artifacts. The artifact paths are generated with a sub-path pattern `{job_id}/{task_id}/{output_key}` under the specified output directory. The service account specified in this pipeline must have the `storage.objects.get` and `storage.objects.create` permissions for this bucket.
	GcsOutputDirectory string `pulumi:"gcsOutputDirectory"`
	// The runtime artifacts of the PipelineJob. The key will be the input artifact name and the value would be one of the InputArtifact.
	InputArtifacts *GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifact `pulumi:"inputArtifacts"`
	// The runtime parameters of the PipelineJob. The parameters will be passed into PipelineJob.pipeline_spec to replace the placeholders at runtime. This field is used by pipelines built using `PipelineJob.pipeline_spec.schema_version` 2.1.0, such as pipelines built using Kubeflow Pipelines SDK 1.9 or higher and the v2 DSL.
	ParameterValues map[string]interface{} `pulumi:"parameterValues"`
	// Deprecated. Use RuntimeConfig.parameter_values instead. The runtime parameters of the PipelineJob. The parameters will be passed into PipelineJob.pipeline_spec to replace the placeholders at runtime. This field is used by pipelines built using `PipelineJob.pipeline_spec.schema_version` 2.0.0 or lower, such as pipelines built using Kubeflow Pipelines SDK 1.8 or lower.
	//
	// Deprecated: Deprecated. Use RuntimeConfig.parameter_values instead. The runtime parameters of the PipelineJob. The parameters will be passed into PipelineJob.pipeline_spec to replace the placeholders at runtime. This field is used by pipelines built using `PipelineJob.pipeline_spec.schema_version` 2.0.0 or lower, such as pipelines built using Kubeflow Pipelines SDK 1.8 or lower.
	Parameters *GoogleCloudAiplatformV1beta1Value `pulumi:"parameters"`
}

// GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInput is an input type that accepts GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigArgs and GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInput` via:
//
//	GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigArgs{...}
type GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigOutput() GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigOutput
	ToGoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigOutput
}

// The runtime config of a PipelineJob.
type GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigArgs struct {
	// Represents the failure policy of a pipeline. Currently, the default of a pipeline is that the pipeline will continue to run until no more tasks can be executed, also known as PIPELINE_FAILURE_POLICY_FAIL_SLOW. However, if a pipeline is set to PIPELINE_FAILURE_POLICY_FAIL_FAST, it will stop scheduling any new tasks when a task has failed. Any scheduled tasks will continue to completion.
	FailurePolicy GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigFailurePolicyPtrInput `pulumi:"failurePolicy"`
	// A path in a Cloud Storage bucket, which will be treated as the root output directory of the pipeline. It is used by the system to generate the paths of output artifacts. The artifact paths are generated with a sub-path pattern `{job_id}/{task_id}/{output_key}` under the specified output directory. The service account specified in this pipeline must have the `storage.objects.get` and `storage.objects.create` permissions for this bucket.
	GcsOutputDirectory pulumi.StringInput `pulumi:"gcsOutputDirectory"`
	// The runtime artifacts of the PipelineJob. The key will be the input artifact name and the value would be one of the InputArtifact.
	InputArtifacts GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactPtrInput `pulumi:"inputArtifacts"`
	// The runtime parameters of the PipelineJob. The parameters will be passed into PipelineJob.pipeline_spec to replace the placeholders at runtime. This field is used by pipelines built using `PipelineJob.pipeline_spec.schema_version` 2.1.0, such as pipelines built using Kubeflow Pipelines SDK 1.9 or higher and the v2 DSL.
	ParameterValues pulumi.MapInput `pulumi:"parameterValues"`
	// Deprecated. Use RuntimeConfig.parameter_values instead. The runtime parameters of the PipelineJob. The parameters will be passed into PipelineJob.pipeline_spec to replace the placeholders at runtime. This field is used by pipelines built using `PipelineJob.pipeline_spec.schema_version` 2.0.0 or lower, such as pipelines built using Kubeflow Pipelines SDK 1.8 or lower.
	//
	// Deprecated: Deprecated. Use RuntimeConfig.parameter_values instead. The runtime parameters of the PipelineJob. The parameters will be passed into PipelineJob.pipeline_spec to replace the placeholders at runtime. This field is used by pipelines built using `PipelineJob.pipeline_spec.schema_version` 2.0.0 or lower, such as pipelines built using Kubeflow Pipelines SDK 1.8 or lower.
	Parameters GoogleCloudAiplatformV1beta1ValuePtrInput `pulumi:"parameters"`
}

func (GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfig)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigArgs) ToGoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigOutput() GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigOutput {
	return i.ToGoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigArgs) ToGoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigOutput)
}

func (i GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigArgs) ToGoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigPtrOutput() GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigArgs) ToGoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigOutput).ToGoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigArgs, GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigPtr and GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigPtrOutput() GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigPtrOutput
	ToGoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigPtrOutput
}

type googleCloudAiplatformV1beta1PipelineJobRuntimeConfigPtrType GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigArgs

func GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigPtr(v *GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigArgs) GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigPtrInput {
	return (*googleCloudAiplatformV1beta1PipelineJobRuntimeConfigPtrType)(v)
}

func (*googleCloudAiplatformV1beta1PipelineJobRuntimeConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfig)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1PipelineJobRuntimeConfigPtrType) ToGoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigPtrOutput() GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1PipelineJobRuntimeConfigPtrType) ToGoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigPtrOutput)
}

// The runtime config of a PipelineJob.
type GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigOutput) ToGoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigOutput() GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigOutput) ToGoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigOutput) ToGoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigPtrOutput() GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigOutput) ToGoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfig) *GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfig {
		return &v
	}).(GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigPtrOutput)
}

// Represents the failure policy of a pipeline. Currently, the default of a pipeline is that the pipeline will continue to run until no more tasks can be executed, also known as PIPELINE_FAILURE_POLICY_FAIL_SLOW. However, if a pipeline is set to PIPELINE_FAILURE_POLICY_FAIL_FAST, it will stop scheduling any new tasks when a task has failed. Any scheduled tasks will continue to completion.
func (o GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigOutput) FailurePolicy() GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigFailurePolicyPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfig) *GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigFailurePolicy {
		return v.FailurePolicy
	}).(GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigFailurePolicyPtrOutput)
}

// A path in a Cloud Storage bucket, which will be treated as the root output directory of the pipeline. It is used by the system to generate the paths of output artifacts. The artifact paths are generated with a sub-path pattern `{job_id}/{task_id}/{output_key}` under the specified output directory. The service account specified in this pipeline must have the `storage.objects.get` and `storage.objects.create` permissions for this bucket.
func (o GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigOutput) GcsOutputDirectory() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfig) string { return v.GcsOutputDirectory }).(pulumi.StringOutput)
}

// The runtime artifacts of the PipelineJob. The key will be the input artifact name and the value would be one of the InputArtifact.
func (o GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigOutput) InputArtifacts() GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfig) *GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifact {
		return v.InputArtifacts
	}).(GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactPtrOutput)
}

// The runtime parameters of the PipelineJob. The parameters will be passed into PipelineJob.pipeline_spec to replace the placeholders at runtime. This field is used by pipelines built using `PipelineJob.pipeline_spec.schema_version` 2.1.0, such as pipelines built using Kubeflow Pipelines SDK 1.9 or higher and the v2 DSL.
func (o GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigOutput) ParameterValues() pulumi.MapOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfig) map[string]interface{} {
		return v.ParameterValues
	}).(pulumi.MapOutput)
}

// Deprecated. Use RuntimeConfig.parameter_values instead. The runtime parameters of the PipelineJob. The parameters will be passed into PipelineJob.pipeline_spec to replace the placeholders at runtime. This field is used by pipelines built using `PipelineJob.pipeline_spec.schema_version` 2.0.0 or lower, such as pipelines built using Kubeflow Pipelines SDK 1.8 or lower.
//
// Deprecated: Deprecated. Use RuntimeConfig.parameter_values instead. The runtime parameters of the PipelineJob. The parameters will be passed into PipelineJob.pipeline_spec to replace the placeholders at runtime. This field is used by pipelines built using `PipelineJob.pipeline_spec.schema_version` 2.0.0 or lower, such as pipelines built using Kubeflow Pipelines SDK 1.8 or lower.
func (o GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigOutput) Parameters() GoogleCloudAiplatformV1beta1ValuePtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfig) *GoogleCloudAiplatformV1beta1Value {
		return v.Parameters
	}).(GoogleCloudAiplatformV1beta1ValuePtrOutput)
}

type GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigPtrOutput) ToGoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigPtrOutput() GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigPtrOutput) ToGoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigPtrOutput) Elem() GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfig) GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfig {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfig
		return ret
	}).(GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigOutput)
}

// Represents the failure policy of a pipeline. Currently, the default of a pipeline is that the pipeline will continue to run until no more tasks can be executed, also known as PIPELINE_FAILURE_POLICY_FAIL_SLOW. However, if a pipeline is set to PIPELINE_FAILURE_POLICY_FAIL_FAST, it will stop scheduling any new tasks when a task has failed. Any scheduled tasks will continue to completion.
func (o GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigPtrOutput) FailurePolicy() GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigFailurePolicyPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfig) *GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigFailurePolicy {
		if v == nil {
			return nil
		}
		return v.FailurePolicy
	}).(GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigFailurePolicyPtrOutput)
}

// A path in a Cloud Storage bucket, which will be treated as the root output directory of the pipeline. It is used by the system to generate the paths of output artifacts. The artifact paths are generated with a sub-path pattern `{job_id}/{task_id}/{output_key}` under the specified output directory. The service account specified in this pipeline must have the `storage.objects.get` and `storage.objects.create` permissions for this bucket.
func (o GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigPtrOutput) GcsOutputDirectory() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfig) *string {
		if v == nil {
			return nil
		}
		return &v.GcsOutputDirectory
	}).(pulumi.StringPtrOutput)
}

// The runtime artifacts of the PipelineJob. The key will be the input artifact name and the value would be one of the InputArtifact.
func (o GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigPtrOutput) InputArtifacts() GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfig) *GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifact {
		if v == nil {
			return nil
		}
		return v.InputArtifacts
	}).(GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactPtrOutput)
}

// The runtime parameters of the PipelineJob. The parameters will be passed into PipelineJob.pipeline_spec to replace the placeholders at runtime. This field is used by pipelines built using `PipelineJob.pipeline_spec.schema_version` 2.1.0, such as pipelines built using Kubeflow Pipelines SDK 1.9 or higher and the v2 DSL.
func (o GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigPtrOutput) ParameterValues() pulumi.MapOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfig) map[string]interface{} {
		if v == nil {
			return nil
		}
		return v.ParameterValues
	}).(pulumi.MapOutput)
}

// Deprecated. Use RuntimeConfig.parameter_values instead. The runtime parameters of the PipelineJob. The parameters will be passed into PipelineJob.pipeline_spec to replace the placeholders at runtime. This field is used by pipelines built using `PipelineJob.pipeline_spec.schema_version` 2.0.0 or lower, such as pipelines built using Kubeflow Pipelines SDK 1.8 or lower.
//
// Deprecated: Deprecated. Use RuntimeConfig.parameter_values instead. The runtime parameters of the PipelineJob. The parameters will be passed into PipelineJob.pipeline_spec to replace the placeholders at runtime. This field is used by pipelines built using `PipelineJob.pipeline_spec.schema_version` 2.0.0 or lower, such as pipelines built using Kubeflow Pipelines SDK 1.8 or lower.
func (o GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigPtrOutput) Parameters() GoogleCloudAiplatformV1beta1ValuePtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfig) *GoogleCloudAiplatformV1beta1Value {
		if v == nil {
			return nil
		}
		return v.Parameters
	}).(GoogleCloudAiplatformV1beta1ValuePtrOutput)
}

// The type of an input artifact.
type GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifact struct {
	// Artifact resource id from MLMD. Which is the last portion of an artifact resource name: `projects/{project}/locations/{location}/metadataStores/default/artifacts/{artifact_id}`. The artifact must stay within the same project, location and default metadatastore as the pipeline.
	ArtifactId *string `pulumi:"artifactId"`
}

// GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactInput is an input type that accepts GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactArgs and GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactInput` via:
//
//	GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactArgs{...}
type GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactOutput() GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactOutput
	ToGoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactOutput
}

// The type of an input artifact.
type GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactArgs struct {
	// Artifact resource id from MLMD. Which is the last portion of an artifact resource name: `projects/{project}/locations/{location}/metadataStores/default/artifacts/{artifact_id}`. The artifact must stay within the same project, location and default metadatastore as the pipeline.
	ArtifactId pulumi.StringPtrInput `pulumi:"artifactId"`
}

func (GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifact)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactArgs) ToGoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactOutput() GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactOutput {
	return i.ToGoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactArgs) ToGoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactOutput)
}

func (i GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactArgs) ToGoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactPtrOutput() GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactArgs) ToGoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactOutput).ToGoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactArgs, GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactPtr and GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactPtrOutput() GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactPtrOutput
	ToGoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactPtrOutput
}

type googleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactPtrType GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactArgs

func GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactPtr(v *GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactArgs) GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactPtrInput {
	return (*googleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactPtrType)(v)
}

func (*googleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifact)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactPtrType) ToGoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactPtrOutput() GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactPtrType) ToGoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactPtrOutput)
}

// The type of an input artifact.
type GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifact)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactOutput) ToGoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactOutput() GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactOutput) ToGoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactOutput) ToGoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactPtrOutput() GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactOutput) ToGoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifact) *GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifact {
		return &v
	}).(GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactPtrOutput)
}

// Artifact resource id from MLMD. Which is the last portion of an artifact resource name: `projects/{project}/locations/{location}/metadataStores/default/artifacts/{artifact_id}`. The artifact must stay within the same project, location and default metadatastore as the pipeline.
func (o GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactOutput) ArtifactId() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifact) *string { return v.ArtifactId }).(pulumi.StringPtrOutput)
}

type GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifact)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactPtrOutput) ToGoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactPtrOutput() GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactPtrOutput) ToGoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactPtrOutput) Elem() GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifact) GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifact {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifact
		return ret
	}).(GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactOutput)
}

// Artifact resource id from MLMD. Which is the last portion of an artifact resource name: `projects/{project}/locations/{location}/metadataStores/default/artifacts/{artifact_id}`. The artifact must stay within the same project, location and default metadatastore as the pipeline.
func (o GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactPtrOutput) ArtifactId() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifact) *string {
		if v == nil {
			return nil
		}
		return v.ArtifactId
	}).(pulumi.StringPtrOutput)
}

// The type of an input artifact.
type GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactResponse struct {
	// Artifact resource id from MLMD. Which is the last portion of an artifact resource name: `projects/{project}/locations/{location}/metadataStores/default/artifacts/{artifact_id}`. The artifact must stay within the same project, location and default metadatastore as the pipeline.
	ArtifactId string `pulumi:"artifactId"`
}

// The type of an input artifact.
type GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactResponseOutput) ToGoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactResponseOutput() GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactResponseOutput) ToGoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactResponseOutput {
	return o
}

// Artifact resource id from MLMD. Which is the last portion of an artifact resource name: `projects/{project}/locations/{location}/metadataStores/default/artifacts/{artifact_id}`. The artifact must stay within the same project, location and default metadatastore as the pipeline.
func (o GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactResponseOutput) ArtifactId() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactResponse) string {
		return v.ArtifactId
	}).(pulumi.StringOutput)
}

// The runtime config of a PipelineJob.
type GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigResponse struct {
	// Represents the failure policy of a pipeline. Currently, the default of a pipeline is that the pipeline will continue to run until no more tasks can be executed, also known as PIPELINE_FAILURE_POLICY_FAIL_SLOW. However, if a pipeline is set to PIPELINE_FAILURE_POLICY_FAIL_FAST, it will stop scheduling any new tasks when a task has failed. Any scheduled tasks will continue to completion.
	FailurePolicy string `pulumi:"failurePolicy"`
	// A path in a Cloud Storage bucket, which will be treated as the root output directory of the pipeline. It is used by the system to generate the paths of output artifacts. The artifact paths are generated with a sub-path pattern `{job_id}/{task_id}/{output_key}` under the specified output directory. The service account specified in this pipeline must have the `storage.objects.get` and `storage.objects.create` permissions for this bucket.
	GcsOutputDirectory string `pulumi:"gcsOutputDirectory"`
	// The runtime artifacts of the PipelineJob. The key will be the input artifact name and the value would be one of the InputArtifact.
	InputArtifacts GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactResponse `pulumi:"inputArtifacts"`
	// The runtime parameters of the PipelineJob. The parameters will be passed into PipelineJob.pipeline_spec to replace the placeholders at runtime. This field is used by pipelines built using `PipelineJob.pipeline_spec.schema_version` 2.1.0, such as pipelines built using Kubeflow Pipelines SDK 1.9 or higher and the v2 DSL.
	ParameterValues map[string]interface{} `pulumi:"parameterValues"`
	// Deprecated. Use RuntimeConfig.parameter_values instead. The runtime parameters of the PipelineJob. The parameters will be passed into PipelineJob.pipeline_spec to replace the placeholders at runtime. This field is used by pipelines built using `PipelineJob.pipeline_spec.schema_version` 2.0.0 or lower, such as pipelines built using Kubeflow Pipelines SDK 1.8 or lower.
	//
	// Deprecated: Deprecated. Use RuntimeConfig.parameter_values instead. The runtime parameters of the PipelineJob. The parameters will be passed into PipelineJob.pipeline_spec to replace the placeholders at runtime. This field is used by pipelines built using `PipelineJob.pipeline_spec.schema_version` 2.0.0 or lower, such as pipelines built using Kubeflow Pipelines SDK 1.8 or lower.
	Parameters GoogleCloudAiplatformV1beta1ValueResponse `pulumi:"parameters"`
}

// The runtime config of a PipelineJob.
type GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigResponseOutput) ToGoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigResponseOutput() GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigResponseOutput) ToGoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigResponseOutput {
	return o
}

// Represents the failure policy of a pipeline. Currently, the default of a pipeline is that the pipeline will continue to run until no more tasks can be executed, also known as PIPELINE_FAILURE_POLICY_FAIL_SLOW. However, if a pipeline is set to PIPELINE_FAILURE_POLICY_FAIL_FAST, it will stop scheduling any new tasks when a task has failed. Any scheduled tasks will continue to completion.
func (o GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigResponseOutput) FailurePolicy() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigResponse) string { return v.FailurePolicy }).(pulumi.StringOutput)
}

// A path in a Cloud Storage bucket, which will be treated as the root output directory of the pipeline. It is used by the system to generate the paths of output artifacts. The artifact paths are generated with a sub-path pattern `{job_id}/{task_id}/{output_key}` under the specified output directory. The service account specified in this pipeline must have the `storage.objects.get` and `storage.objects.create` permissions for this bucket.
func (o GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigResponseOutput) GcsOutputDirectory() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigResponse) string {
		return v.GcsOutputDirectory
	}).(pulumi.StringOutput)
}

// The runtime artifacts of the PipelineJob. The key will be the input artifact name and the value would be one of the InputArtifact.
func (o GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigResponseOutput) InputArtifacts() GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigResponse) GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactResponse {
		return v.InputArtifacts
	}).(GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactResponseOutput)
}

// The runtime parameters of the PipelineJob. The parameters will be passed into PipelineJob.pipeline_spec to replace the placeholders at runtime. This field is used by pipelines built using `PipelineJob.pipeline_spec.schema_version` 2.1.0, such as pipelines built using Kubeflow Pipelines SDK 1.9 or higher and the v2 DSL.
func (o GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigResponseOutput) ParameterValues() pulumi.MapOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigResponse) map[string]interface{} {
		return v.ParameterValues
	}).(pulumi.MapOutput)
}

// Deprecated. Use RuntimeConfig.parameter_values instead. The runtime parameters of the PipelineJob. The parameters will be passed into PipelineJob.pipeline_spec to replace the placeholders at runtime. This field is used by pipelines built using `PipelineJob.pipeline_spec.schema_version` 2.0.0 or lower, such as pipelines built using Kubeflow Pipelines SDK 1.8 or lower.
//
// Deprecated: Deprecated. Use RuntimeConfig.parameter_values instead. The runtime parameters of the PipelineJob. The parameters will be passed into PipelineJob.pipeline_spec to replace the placeholders at runtime. This field is used by pipelines built using `PipelineJob.pipeline_spec.schema_version` 2.0.0 or lower, such as pipelines built using Kubeflow Pipelines SDK 1.8 or lower.
func (o GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigResponseOutput) Parameters() GoogleCloudAiplatformV1beta1ValueResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigResponse) GoogleCloudAiplatformV1beta1ValueResponse {
		return v.Parameters
	}).(GoogleCloudAiplatformV1beta1ValueResponseOutput)
}

// A list of artifact metadata.
type GoogleCloudAiplatformV1beta1PipelineTaskDetailArtifactListResponse struct {
	// A list of artifact metadata.
	Artifacts []GoogleCloudAiplatformV1beta1ArtifactResponse `pulumi:"artifacts"`
}

// A list of artifact metadata.
type GoogleCloudAiplatformV1beta1PipelineTaskDetailArtifactListResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1PipelineTaskDetailArtifactListResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1PipelineTaskDetailArtifactListResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1PipelineTaskDetailArtifactListResponseOutput) ToGoogleCloudAiplatformV1beta1PipelineTaskDetailArtifactListResponseOutput() GoogleCloudAiplatformV1beta1PipelineTaskDetailArtifactListResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1PipelineTaskDetailArtifactListResponseOutput) ToGoogleCloudAiplatformV1beta1PipelineTaskDetailArtifactListResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1PipelineTaskDetailArtifactListResponseOutput {
	return o
}

// A list of artifact metadata.
func (o GoogleCloudAiplatformV1beta1PipelineTaskDetailArtifactListResponseOutput) Artifacts() GoogleCloudAiplatformV1beta1ArtifactResponseArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PipelineTaskDetailArtifactListResponse) []GoogleCloudAiplatformV1beta1ArtifactResponse {
		return v.Artifacts
	}).(GoogleCloudAiplatformV1beta1ArtifactResponseArrayOutput)
}

// A single record of the task status.
type GoogleCloudAiplatformV1beta1PipelineTaskDetailPipelineTaskStatusResponse struct {
	// The error that occurred during the state. May be set when the state is any of the non-final state (PENDING/RUNNING/CANCELLING) or FAILED state. If the state is FAILED, the error here is final and not going to be retried. If the state is a non-final state, the error indicates a system-error being retried.
	Error GoogleRpcStatusResponse `pulumi:"error"`
	// The state of the task.
	State string `pulumi:"state"`
	// Update time of this status.
	UpdateTime string `pulumi:"updateTime"`
}

// A single record of the task status.
type GoogleCloudAiplatformV1beta1PipelineTaskDetailPipelineTaskStatusResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1PipelineTaskDetailPipelineTaskStatusResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1PipelineTaskDetailPipelineTaskStatusResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1PipelineTaskDetailPipelineTaskStatusResponseOutput) ToGoogleCloudAiplatformV1beta1PipelineTaskDetailPipelineTaskStatusResponseOutput() GoogleCloudAiplatformV1beta1PipelineTaskDetailPipelineTaskStatusResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1PipelineTaskDetailPipelineTaskStatusResponseOutput) ToGoogleCloudAiplatformV1beta1PipelineTaskDetailPipelineTaskStatusResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1PipelineTaskDetailPipelineTaskStatusResponseOutput {
	return o
}

// The error that occurred during the state. May be set when the state is any of the non-final state (PENDING/RUNNING/CANCELLING) or FAILED state. If the state is FAILED, the error here is final and not going to be retried. If the state is a non-final state, the error indicates a system-error being retried.
func (o GoogleCloudAiplatformV1beta1PipelineTaskDetailPipelineTaskStatusResponseOutput) Error() GoogleRpcStatusResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PipelineTaskDetailPipelineTaskStatusResponse) GoogleRpcStatusResponse {
		return v.Error
	}).(GoogleRpcStatusResponseOutput)
}

// The state of the task.
func (o GoogleCloudAiplatformV1beta1PipelineTaskDetailPipelineTaskStatusResponseOutput) State() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PipelineTaskDetailPipelineTaskStatusResponse) string {
		return v.State
	}).(pulumi.StringOutput)
}

// Update time of this status.
func (o GoogleCloudAiplatformV1beta1PipelineTaskDetailPipelineTaskStatusResponseOutput) UpdateTime() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PipelineTaskDetailPipelineTaskStatusResponse) string {
		return v.UpdateTime
	}).(pulumi.StringOutput)
}

type GoogleCloudAiplatformV1beta1PipelineTaskDetailPipelineTaskStatusResponseArrayOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1PipelineTaskDetailPipelineTaskStatusResponseArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1beta1PipelineTaskDetailPipelineTaskStatusResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1PipelineTaskDetailPipelineTaskStatusResponseArrayOutput) ToGoogleCloudAiplatformV1beta1PipelineTaskDetailPipelineTaskStatusResponseArrayOutput() GoogleCloudAiplatformV1beta1PipelineTaskDetailPipelineTaskStatusResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1PipelineTaskDetailPipelineTaskStatusResponseArrayOutput) ToGoogleCloudAiplatformV1beta1PipelineTaskDetailPipelineTaskStatusResponseArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1PipelineTaskDetailPipelineTaskStatusResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1PipelineTaskDetailPipelineTaskStatusResponseArrayOutput) Index(i pulumi.IntInput) GoogleCloudAiplatformV1beta1PipelineTaskDetailPipelineTaskStatusResponseOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GoogleCloudAiplatformV1beta1PipelineTaskDetailPipelineTaskStatusResponse {
		return vs[0].([]GoogleCloudAiplatformV1beta1PipelineTaskDetailPipelineTaskStatusResponse)[vs[1].(int)]
	}).(GoogleCloudAiplatformV1beta1PipelineTaskDetailPipelineTaskStatusResponseOutput)
}

// The runtime detail of a task execution.
type GoogleCloudAiplatformV1beta1PipelineTaskDetailResponse struct {
	// Task create time.
	CreateTime string `pulumi:"createTime"`
	// Task end time.
	EndTime string `pulumi:"endTime"`
	// The error that occurred during task execution. Only populated when the task's state is FAILED or CANCELLED.
	Error GoogleRpcStatusResponse `pulumi:"error"`
	// The execution metadata of the task.
	Execution GoogleCloudAiplatformV1beta1ExecutionResponse `pulumi:"execution"`
	// The detailed execution info.
	ExecutorDetail GoogleCloudAiplatformV1beta1PipelineTaskExecutorDetailResponse `pulumi:"executorDetail"`
	// The runtime input artifacts of the task.
	Inputs GoogleCloudAiplatformV1beta1PipelineTaskDetailArtifactListResponse `pulumi:"inputs"`
	// The runtime output artifacts of the task.
	Outputs GoogleCloudAiplatformV1beta1PipelineTaskDetailArtifactListResponse `pulumi:"outputs"`
	// The id of the parent task if the task is within a component scope. Empty if the task is at the root level.
	ParentTaskId string `pulumi:"parentTaskId"`
	// A list of task status. This field keeps a record of task status evolving over time.
	PipelineTaskStatus []GoogleCloudAiplatformV1beta1PipelineTaskDetailPipelineTaskStatusResponse `pulumi:"pipelineTaskStatus"`
	// Task start time.
	StartTime string `pulumi:"startTime"`
	// State of the task.
	State string `pulumi:"state"`
	// The system generated ID of the task.
	TaskId string `pulumi:"taskId"`
	// The user specified name of the task that is defined in pipeline_spec.
	TaskName string `pulumi:"taskName"`
}

// The runtime detail of a task execution.
type GoogleCloudAiplatformV1beta1PipelineTaskDetailResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1PipelineTaskDetailResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1PipelineTaskDetailResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1PipelineTaskDetailResponseOutput) ToGoogleCloudAiplatformV1beta1PipelineTaskDetailResponseOutput() GoogleCloudAiplatformV1beta1PipelineTaskDetailResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1PipelineTaskDetailResponseOutput) ToGoogleCloudAiplatformV1beta1PipelineTaskDetailResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1PipelineTaskDetailResponseOutput {
	return o
}

// Task create time.
func (o GoogleCloudAiplatformV1beta1PipelineTaskDetailResponseOutput) CreateTime() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PipelineTaskDetailResponse) string { return v.CreateTime }).(pulumi.StringOutput)
}

// Task end time.
func (o GoogleCloudAiplatformV1beta1PipelineTaskDetailResponseOutput) EndTime() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PipelineTaskDetailResponse) string { return v.EndTime }).(pulumi.StringOutput)
}

// The error that occurred during task execution. Only populated when the task's state is FAILED or CANCELLED.
func (o GoogleCloudAiplatformV1beta1PipelineTaskDetailResponseOutput) Error() GoogleRpcStatusResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PipelineTaskDetailResponse) GoogleRpcStatusResponse { return v.Error }).(GoogleRpcStatusResponseOutput)
}

// The execution metadata of the task.
func (o GoogleCloudAiplatformV1beta1PipelineTaskDetailResponseOutput) Execution() GoogleCloudAiplatformV1beta1ExecutionResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PipelineTaskDetailResponse) GoogleCloudAiplatformV1beta1ExecutionResponse {
		return v.Execution
	}).(GoogleCloudAiplatformV1beta1ExecutionResponseOutput)
}

// The detailed execution info.
func (o GoogleCloudAiplatformV1beta1PipelineTaskDetailResponseOutput) ExecutorDetail() GoogleCloudAiplatformV1beta1PipelineTaskExecutorDetailResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PipelineTaskDetailResponse) GoogleCloudAiplatformV1beta1PipelineTaskExecutorDetailResponse {
		return v.ExecutorDetail
	}).(GoogleCloudAiplatformV1beta1PipelineTaskExecutorDetailResponseOutput)
}

// The runtime input artifacts of the task.
func (o GoogleCloudAiplatformV1beta1PipelineTaskDetailResponseOutput) Inputs() GoogleCloudAiplatformV1beta1PipelineTaskDetailArtifactListResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PipelineTaskDetailResponse) GoogleCloudAiplatformV1beta1PipelineTaskDetailArtifactListResponse {
		return v.Inputs
	}).(GoogleCloudAiplatformV1beta1PipelineTaskDetailArtifactListResponseOutput)
}

// The runtime output artifacts of the task.
func (o GoogleCloudAiplatformV1beta1PipelineTaskDetailResponseOutput) Outputs() GoogleCloudAiplatformV1beta1PipelineTaskDetailArtifactListResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PipelineTaskDetailResponse) GoogleCloudAiplatformV1beta1PipelineTaskDetailArtifactListResponse {
		return v.Outputs
	}).(GoogleCloudAiplatformV1beta1PipelineTaskDetailArtifactListResponseOutput)
}

// The id of the parent task if the task is within a component scope. Empty if the task is at the root level.
func (o GoogleCloudAiplatformV1beta1PipelineTaskDetailResponseOutput) ParentTaskId() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PipelineTaskDetailResponse) string { return v.ParentTaskId }).(pulumi.StringOutput)
}

// A list of task status. This field keeps a record of task status evolving over time.
func (o GoogleCloudAiplatformV1beta1PipelineTaskDetailResponseOutput) PipelineTaskStatus() GoogleCloudAiplatformV1beta1PipelineTaskDetailPipelineTaskStatusResponseArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PipelineTaskDetailResponse) []GoogleCloudAiplatformV1beta1PipelineTaskDetailPipelineTaskStatusResponse {
		return v.PipelineTaskStatus
	}).(GoogleCloudAiplatformV1beta1PipelineTaskDetailPipelineTaskStatusResponseArrayOutput)
}

// Task start time.
func (o GoogleCloudAiplatformV1beta1PipelineTaskDetailResponseOutput) StartTime() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PipelineTaskDetailResponse) string { return v.StartTime }).(pulumi.StringOutput)
}

// State of the task.
func (o GoogleCloudAiplatformV1beta1PipelineTaskDetailResponseOutput) State() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PipelineTaskDetailResponse) string { return v.State }).(pulumi.StringOutput)
}

// The system generated ID of the task.
func (o GoogleCloudAiplatformV1beta1PipelineTaskDetailResponseOutput) TaskId() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PipelineTaskDetailResponse) string { return v.TaskId }).(pulumi.StringOutput)
}

// The user specified name of the task that is defined in pipeline_spec.
func (o GoogleCloudAiplatformV1beta1PipelineTaskDetailResponseOutput) TaskName() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PipelineTaskDetailResponse) string { return v.TaskName }).(pulumi.StringOutput)
}

type GoogleCloudAiplatformV1beta1PipelineTaskDetailResponseArrayOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1PipelineTaskDetailResponseArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1beta1PipelineTaskDetailResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1PipelineTaskDetailResponseArrayOutput) ToGoogleCloudAiplatformV1beta1PipelineTaskDetailResponseArrayOutput() GoogleCloudAiplatformV1beta1PipelineTaskDetailResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1PipelineTaskDetailResponseArrayOutput) ToGoogleCloudAiplatformV1beta1PipelineTaskDetailResponseArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1PipelineTaskDetailResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1PipelineTaskDetailResponseArrayOutput) Index(i pulumi.IntInput) GoogleCloudAiplatformV1beta1PipelineTaskDetailResponseOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GoogleCloudAiplatformV1beta1PipelineTaskDetailResponse {
		return vs[0].([]GoogleCloudAiplatformV1beta1PipelineTaskDetailResponse)[vs[1].(int)]
	}).(GoogleCloudAiplatformV1beta1PipelineTaskDetailResponseOutput)
}

// The detail of a container execution. It contains the job names of the lifecycle of a container execution.
type GoogleCloudAiplatformV1beta1PipelineTaskExecutorDetailContainerDetailResponse struct {
	// The names of the previously failed CustomJob for the main container executions. The list includes the all attempts in chronological order.
	FailedMainJobs []string `pulumi:"failedMainJobs"`
	// The names of the previously failed CustomJob for the pre-caching-check container executions. This job will be available if the PipelineJob.pipeline_spec specifies the `pre_caching_check` hook in the lifecycle events. The list includes the all attempts in chronological order.
	FailedPreCachingCheckJobs []string `pulumi:"failedPreCachingCheckJobs"`
	// The name of the CustomJob for the main container execution.
	MainJob string `pulumi:"mainJob"`
	// The name of the CustomJob for the pre-caching-check container execution. This job will be available if the PipelineJob.pipeline_spec specifies the `pre_caching_check` hook in the lifecycle events.
	PreCachingCheckJob string `pulumi:"preCachingCheckJob"`
}

// The detail of a container execution. It contains the job names of the lifecycle of a container execution.
type GoogleCloudAiplatformV1beta1PipelineTaskExecutorDetailContainerDetailResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1PipelineTaskExecutorDetailContainerDetailResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1PipelineTaskExecutorDetailContainerDetailResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1PipelineTaskExecutorDetailContainerDetailResponseOutput) ToGoogleCloudAiplatformV1beta1PipelineTaskExecutorDetailContainerDetailResponseOutput() GoogleCloudAiplatformV1beta1PipelineTaskExecutorDetailContainerDetailResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1PipelineTaskExecutorDetailContainerDetailResponseOutput) ToGoogleCloudAiplatformV1beta1PipelineTaskExecutorDetailContainerDetailResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1PipelineTaskExecutorDetailContainerDetailResponseOutput {
	return o
}

// The names of the previously failed CustomJob for the main container executions. The list includes the all attempts in chronological order.
func (o GoogleCloudAiplatformV1beta1PipelineTaskExecutorDetailContainerDetailResponseOutput) FailedMainJobs() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PipelineTaskExecutorDetailContainerDetailResponse) []string {
		return v.FailedMainJobs
	}).(pulumi.StringArrayOutput)
}

// The names of the previously failed CustomJob for the pre-caching-check container executions. This job will be available if the PipelineJob.pipeline_spec specifies the `pre_caching_check` hook in the lifecycle events. The list includes the all attempts in chronological order.
func (o GoogleCloudAiplatformV1beta1PipelineTaskExecutorDetailContainerDetailResponseOutput) FailedPreCachingCheckJobs() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PipelineTaskExecutorDetailContainerDetailResponse) []string {
		return v.FailedPreCachingCheckJobs
	}).(pulumi.StringArrayOutput)
}

// The name of the CustomJob for the main container execution.
func (o GoogleCloudAiplatformV1beta1PipelineTaskExecutorDetailContainerDetailResponseOutput) MainJob() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PipelineTaskExecutorDetailContainerDetailResponse) string {
		return v.MainJob
	}).(pulumi.StringOutput)
}

// The name of the CustomJob for the pre-caching-check container execution. This job will be available if the PipelineJob.pipeline_spec specifies the `pre_caching_check` hook in the lifecycle events.
func (o GoogleCloudAiplatformV1beta1PipelineTaskExecutorDetailContainerDetailResponseOutput) PreCachingCheckJob() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PipelineTaskExecutorDetailContainerDetailResponse) string {
		return v.PreCachingCheckJob
	}).(pulumi.StringOutput)
}

// The detailed info for a custom job executor.
type GoogleCloudAiplatformV1beta1PipelineTaskExecutorDetailCustomJobDetailResponse struct {
	// The names of the previously failed CustomJob. The list includes the all attempts in chronological order.
	FailedJobs []string `pulumi:"failedJobs"`
	// The name of the CustomJob.
	Job string `pulumi:"job"`
}

// The detailed info for a custom job executor.
type GoogleCloudAiplatformV1beta1PipelineTaskExecutorDetailCustomJobDetailResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1PipelineTaskExecutorDetailCustomJobDetailResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1PipelineTaskExecutorDetailCustomJobDetailResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1PipelineTaskExecutorDetailCustomJobDetailResponseOutput) ToGoogleCloudAiplatformV1beta1PipelineTaskExecutorDetailCustomJobDetailResponseOutput() GoogleCloudAiplatformV1beta1PipelineTaskExecutorDetailCustomJobDetailResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1PipelineTaskExecutorDetailCustomJobDetailResponseOutput) ToGoogleCloudAiplatformV1beta1PipelineTaskExecutorDetailCustomJobDetailResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1PipelineTaskExecutorDetailCustomJobDetailResponseOutput {
	return o
}

// The names of the previously failed CustomJob. The list includes the all attempts in chronological order.
func (o GoogleCloudAiplatformV1beta1PipelineTaskExecutorDetailCustomJobDetailResponseOutput) FailedJobs() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PipelineTaskExecutorDetailCustomJobDetailResponse) []string {
		return v.FailedJobs
	}).(pulumi.StringArrayOutput)
}

// The name of the CustomJob.
func (o GoogleCloudAiplatformV1beta1PipelineTaskExecutorDetailCustomJobDetailResponseOutput) Job() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PipelineTaskExecutorDetailCustomJobDetailResponse) string {
		return v.Job
	}).(pulumi.StringOutput)
}

// The runtime detail of a pipeline executor.
type GoogleCloudAiplatformV1beta1PipelineTaskExecutorDetailResponse struct {
	// The detailed info for a container executor.
	ContainerDetail GoogleCloudAiplatformV1beta1PipelineTaskExecutorDetailContainerDetailResponse `pulumi:"containerDetail"`
	// The detailed info for a custom job executor.
	CustomJobDetail GoogleCloudAiplatformV1beta1PipelineTaskExecutorDetailCustomJobDetailResponse `pulumi:"customJobDetail"`
}

// The runtime detail of a pipeline executor.
type GoogleCloudAiplatformV1beta1PipelineTaskExecutorDetailResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1PipelineTaskExecutorDetailResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1PipelineTaskExecutorDetailResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1PipelineTaskExecutorDetailResponseOutput) ToGoogleCloudAiplatformV1beta1PipelineTaskExecutorDetailResponseOutput() GoogleCloudAiplatformV1beta1PipelineTaskExecutorDetailResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1PipelineTaskExecutorDetailResponseOutput) ToGoogleCloudAiplatformV1beta1PipelineTaskExecutorDetailResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1PipelineTaskExecutorDetailResponseOutput {
	return o
}

// The detailed info for a container executor.
func (o GoogleCloudAiplatformV1beta1PipelineTaskExecutorDetailResponseOutput) ContainerDetail() GoogleCloudAiplatformV1beta1PipelineTaskExecutorDetailContainerDetailResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PipelineTaskExecutorDetailResponse) GoogleCloudAiplatformV1beta1PipelineTaskExecutorDetailContainerDetailResponse {
		return v.ContainerDetail
	}).(GoogleCloudAiplatformV1beta1PipelineTaskExecutorDetailContainerDetailResponseOutput)
}

// The detailed info for a custom job executor.
func (o GoogleCloudAiplatformV1beta1PipelineTaskExecutorDetailResponseOutput) CustomJobDetail() GoogleCloudAiplatformV1beta1PipelineTaskExecutorDetailCustomJobDetailResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PipelineTaskExecutorDetailResponse) GoogleCloudAiplatformV1beta1PipelineTaskExecutorDetailCustomJobDetailResponse {
		return v.CustomJobDetail
	}).(GoogleCloudAiplatformV1beta1PipelineTaskExecutorDetailCustomJobDetailResponseOutput)
}

// Pipeline template metadata if PipelineJob.template_uri is from supported template registry. Currently, the only supported registry is Artifact Registry.
type GoogleCloudAiplatformV1beta1PipelineTemplateMetadataResponse struct {
	// The version_name in artifact registry. Will always be presented in output if the PipelineJob.template_uri is from supported template registry. Format is "sha256:abcdef123456...".
	Version string `pulumi:"version"`
}

// Pipeline template metadata if PipelineJob.template_uri is from supported template registry. Currently, the only supported registry is Artifact Registry.
type GoogleCloudAiplatformV1beta1PipelineTemplateMetadataResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1PipelineTemplateMetadataResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1PipelineTemplateMetadataResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1PipelineTemplateMetadataResponseOutput) ToGoogleCloudAiplatformV1beta1PipelineTemplateMetadataResponseOutput() GoogleCloudAiplatformV1beta1PipelineTemplateMetadataResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1PipelineTemplateMetadataResponseOutput) ToGoogleCloudAiplatformV1beta1PipelineTemplateMetadataResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1PipelineTemplateMetadataResponseOutput {
	return o
}

// The version_name in artifact registry. Will always be presented in output if the PipelineJob.template_uri is from supported template registry. Format is "sha256:abcdef123456...".
func (o GoogleCloudAiplatformV1beta1PipelineTemplateMetadataResponseOutput) Version() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PipelineTemplateMetadataResponse) string { return v.Version }).(pulumi.StringOutput)
}

// Represents a network port in a container.
type GoogleCloudAiplatformV1beta1Port struct {
	// The number of the port to expose on the pod's IP address. Must be a valid port number, between 1 and 65535 inclusive.
	ContainerPort *int `pulumi:"containerPort"`
}

// GoogleCloudAiplatformV1beta1PortInput is an input type that accepts GoogleCloudAiplatformV1beta1PortArgs and GoogleCloudAiplatformV1beta1PortOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1PortInput` via:
//
//	GoogleCloudAiplatformV1beta1PortArgs{...}
type GoogleCloudAiplatformV1beta1PortInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1PortOutput() GoogleCloudAiplatformV1beta1PortOutput
	ToGoogleCloudAiplatformV1beta1PortOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1PortOutput
}

// Represents a network port in a container.
type GoogleCloudAiplatformV1beta1PortArgs struct {
	// The number of the port to expose on the pod's IP address. Must be a valid port number, between 1 and 65535 inclusive.
	ContainerPort pulumi.IntPtrInput `pulumi:"containerPort"`
}

func (GoogleCloudAiplatformV1beta1PortArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1Port)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1PortArgs) ToGoogleCloudAiplatformV1beta1PortOutput() GoogleCloudAiplatformV1beta1PortOutput {
	return i.ToGoogleCloudAiplatformV1beta1PortOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1PortArgs) ToGoogleCloudAiplatformV1beta1PortOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1PortOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1PortOutput)
}

// GoogleCloudAiplatformV1beta1PortArrayInput is an input type that accepts GoogleCloudAiplatformV1beta1PortArray and GoogleCloudAiplatformV1beta1PortArrayOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1PortArrayInput` via:
//
//	GoogleCloudAiplatformV1beta1PortArray{ GoogleCloudAiplatformV1beta1PortArgs{...} }
type GoogleCloudAiplatformV1beta1PortArrayInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1PortArrayOutput() GoogleCloudAiplatformV1beta1PortArrayOutput
	ToGoogleCloudAiplatformV1beta1PortArrayOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1PortArrayOutput
}

type GoogleCloudAiplatformV1beta1PortArray []GoogleCloudAiplatformV1beta1PortInput

func (GoogleCloudAiplatformV1beta1PortArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1beta1Port)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1PortArray) ToGoogleCloudAiplatformV1beta1PortArrayOutput() GoogleCloudAiplatformV1beta1PortArrayOutput {
	return i.ToGoogleCloudAiplatformV1beta1PortArrayOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1PortArray) ToGoogleCloudAiplatformV1beta1PortArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1PortArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1PortArrayOutput)
}

// Represents a network port in a container.
type GoogleCloudAiplatformV1beta1PortOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1PortOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1Port)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1PortOutput) ToGoogleCloudAiplatformV1beta1PortOutput() GoogleCloudAiplatformV1beta1PortOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1PortOutput) ToGoogleCloudAiplatformV1beta1PortOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1PortOutput {
	return o
}

// The number of the port to expose on the pod's IP address. Must be a valid port number, between 1 and 65535 inclusive.
func (o GoogleCloudAiplatformV1beta1PortOutput) ContainerPort() pulumi.IntPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1Port) *int { return v.ContainerPort }).(pulumi.IntPtrOutput)
}

type GoogleCloudAiplatformV1beta1PortArrayOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1PortArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1beta1Port)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1PortArrayOutput) ToGoogleCloudAiplatformV1beta1PortArrayOutput() GoogleCloudAiplatformV1beta1PortArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1PortArrayOutput) ToGoogleCloudAiplatformV1beta1PortArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1PortArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1PortArrayOutput) Index(i pulumi.IntInput) GoogleCloudAiplatformV1beta1PortOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GoogleCloudAiplatformV1beta1Port {
		return vs[0].([]GoogleCloudAiplatformV1beta1Port)[vs[1].(int)]
	}).(GoogleCloudAiplatformV1beta1PortOutput)
}

// Represents a network port in a container.
type GoogleCloudAiplatformV1beta1PortResponse struct {
	// The number of the port to expose on the pod's IP address. Must be a valid port number, between 1 and 65535 inclusive.
	ContainerPort int `pulumi:"containerPort"`
}

// Represents a network port in a container.
type GoogleCloudAiplatformV1beta1PortResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1PortResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1PortResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1PortResponseOutput) ToGoogleCloudAiplatformV1beta1PortResponseOutput() GoogleCloudAiplatformV1beta1PortResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1PortResponseOutput) ToGoogleCloudAiplatformV1beta1PortResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1PortResponseOutput {
	return o
}

// The number of the port to expose on the pod's IP address. Must be a valid port number, between 1 and 65535 inclusive.
func (o GoogleCloudAiplatformV1beta1PortResponseOutput) ContainerPort() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PortResponse) int { return v.ContainerPort }).(pulumi.IntOutput)
}

type GoogleCloudAiplatformV1beta1PortResponseArrayOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1PortResponseArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1beta1PortResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1PortResponseArrayOutput) ToGoogleCloudAiplatformV1beta1PortResponseArrayOutput() GoogleCloudAiplatformV1beta1PortResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1PortResponseArrayOutput) ToGoogleCloudAiplatformV1beta1PortResponseArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1PortResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1PortResponseArrayOutput) Index(i pulumi.IntInput) GoogleCloudAiplatformV1beta1PortResponseOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GoogleCloudAiplatformV1beta1PortResponse {
		return vs[0].([]GoogleCloudAiplatformV1beta1PortResponse)[vs[1].(int)]
	}).(GoogleCloudAiplatformV1beta1PortResponseOutput)
}

// Assigns input data to training, validation, and test sets based on the value of a provided key. Supported only for tabular Datasets.
type GoogleCloudAiplatformV1beta1PredefinedSplit struct {
	// The key is a name of one of the Dataset's data columns. The value of the key (either the label's value or value in the column) must be one of {`training`, `validation`, `test`}, and it defines to which set the given piece of data is assigned. If for a piece of data the key is not present or has an invalid value, that piece is ignored by the pipeline.
	Key string `pulumi:"key"`
}

// GoogleCloudAiplatformV1beta1PredefinedSplitInput is an input type that accepts GoogleCloudAiplatformV1beta1PredefinedSplitArgs and GoogleCloudAiplatformV1beta1PredefinedSplitOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1PredefinedSplitInput` via:
//
//	GoogleCloudAiplatformV1beta1PredefinedSplitArgs{...}
type GoogleCloudAiplatformV1beta1PredefinedSplitInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1PredefinedSplitOutput() GoogleCloudAiplatformV1beta1PredefinedSplitOutput
	ToGoogleCloudAiplatformV1beta1PredefinedSplitOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1PredefinedSplitOutput
}

// Assigns input data to training, validation, and test sets based on the value of a provided key. Supported only for tabular Datasets.
type GoogleCloudAiplatformV1beta1PredefinedSplitArgs struct {
	// The key is a name of one of the Dataset's data columns. The value of the key (either the label's value or value in the column) must be one of {`training`, `validation`, `test`}, and it defines to which set the given piece of data is assigned. If for a piece of data the key is not present or has an invalid value, that piece is ignored by the pipeline.
	Key pulumi.StringInput `pulumi:"key"`
}

func (GoogleCloudAiplatformV1beta1PredefinedSplitArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1PredefinedSplit)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1PredefinedSplitArgs) ToGoogleCloudAiplatformV1beta1PredefinedSplitOutput() GoogleCloudAiplatformV1beta1PredefinedSplitOutput {
	return i.ToGoogleCloudAiplatformV1beta1PredefinedSplitOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1PredefinedSplitArgs) ToGoogleCloudAiplatformV1beta1PredefinedSplitOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1PredefinedSplitOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1PredefinedSplitOutput)
}

func (i GoogleCloudAiplatformV1beta1PredefinedSplitArgs) ToGoogleCloudAiplatformV1beta1PredefinedSplitPtrOutput() GoogleCloudAiplatformV1beta1PredefinedSplitPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1PredefinedSplitPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1PredefinedSplitArgs) ToGoogleCloudAiplatformV1beta1PredefinedSplitPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1PredefinedSplitPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1PredefinedSplitOutput).ToGoogleCloudAiplatformV1beta1PredefinedSplitPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1PredefinedSplitPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1PredefinedSplitArgs, GoogleCloudAiplatformV1beta1PredefinedSplitPtr and GoogleCloudAiplatformV1beta1PredefinedSplitPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1PredefinedSplitPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1PredefinedSplitArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1PredefinedSplitPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1PredefinedSplitPtrOutput() GoogleCloudAiplatformV1beta1PredefinedSplitPtrOutput
	ToGoogleCloudAiplatformV1beta1PredefinedSplitPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1PredefinedSplitPtrOutput
}

type googleCloudAiplatformV1beta1PredefinedSplitPtrType GoogleCloudAiplatformV1beta1PredefinedSplitArgs

func GoogleCloudAiplatformV1beta1PredefinedSplitPtr(v *GoogleCloudAiplatformV1beta1PredefinedSplitArgs) GoogleCloudAiplatformV1beta1PredefinedSplitPtrInput {
	return (*googleCloudAiplatformV1beta1PredefinedSplitPtrType)(v)
}

func (*googleCloudAiplatformV1beta1PredefinedSplitPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1PredefinedSplit)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1PredefinedSplitPtrType) ToGoogleCloudAiplatformV1beta1PredefinedSplitPtrOutput() GoogleCloudAiplatformV1beta1PredefinedSplitPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1PredefinedSplitPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1PredefinedSplitPtrType) ToGoogleCloudAiplatformV1beta1PredefinedSplitPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1PredefinedSplitPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1PredefinedSplitPtrOutput)
}

// Assigns input data to training, validation, and test sets based on the value of a provided key. Supported only for tabular Datasets.
type GoogleCloudAiplatformV1beta1PredefinedSplitOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1PredefinedSplitOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1PredefinedSplit)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1PredefinedSplitOutput) ToGoogleCloudAiplatformV1beta1PredefinedSplitOutput() GoogleCloudAiplatformV1beta1PredefinedSplitOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1PredefinedSplitOutput) ToGoogleCloudAiplatformV1beta1PredefinedSplitOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1PredefinedSplitOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1PredefinedSplitOutput) ToGoogleCloudAiplatformV1beta1PredefinedSplitPtrOutput() GoogleCloudAiplatformV1beta1PredefinedSplitPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1PredefinedSplitPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1PredefinedSplitOutput) ToGoogleCloudAiplatformV1beta1PredefinedSplitPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1PredefinedSplitPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1PredefinedSplit) *GoogleCloudAiplatformV1beta1PredefinedSplit {
		return &v
	}).(GoogleCloudAiplatformV1beta1PredefinedSplitPtrOutput)
}

// The key is a name of one of the Dataset's data columns. The value of the key (either the label's value or value in the column) must be one of {`training`, `validation`, `test`}, and it defines to which set the given piece of data is assigned. If for a piece of data the key is not present or has an invalid value, that piece is ignored by the pipeline.
func (o GoogleCloudAiplatformV1beta1PredefinedSplitOutput) Key() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PredefinedSplit) string { return v.Key }).(pulumi.StringOutput)
}

type GoogleCloudAiplatformV1beta1PredefinedSplitPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1PredefinedSplitPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1PredefinedSplit)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1PredefinedSplitPtrOutput) ToGoogleCloudAiplatformV1beta1PredefinedSplitPtrOutput() GoogleCloudAiplatformV1beta1PredefinedSplitPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1PredefinedSplitPtrOutput) ToGoogleCloudAiplatformV1beta1PredefinedSplitPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1PredefinedSplitPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1PredefinedSplitPtrOutput) Elem() GoogleCloudAiplatformV1beta1PredefinedSplitOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1PredefinedSplit) GoogleCloudAiplatformV1beta1PredefinedSplit {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1PredefinedSplit
		return ret
	}).(GoogleCloudAiplatformV1beta1PredefinedSplitOutput)
}

// The key is a name of one of the Dataset's data columns. The value of the key (either the label's value or value in the column) must be one of {`training`, `validation`, `test`}, and it defines to which set the given piece of data is assigned. If for a piece of data the key is not present or has an invalid value, that piece is ignored by the pipeline.
func (o GoogleCloudAiplatformV1beta1PredefinedSplitPtrOutput) Key() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1PredefinedSplit) *string {
		if v == nil {
			return nil
		}
		return &v.Key
	}).(pulumi.StringPtrOutput)
}

// Assigns input data to training, validation, and test sets based on the value of a provided key. Supported only for tabular Datasets.
type GoogleCloudAiplatformV1beta1PredefinedSplitResponse struct {
	// The key is a name of one of the Dataset's data columns. The value of the key (either the label's value or value in the column) must be one of {`training`, `validation`, `test`}, and it defines to which set the given piece of data is assigned. If for a piece of data the key is not present or has an invalid value, that piece is ignored by the pipeline.
	Key string `pulumi:"key"`
}

// Assigns input data to training, validation, and test sets based on the value of a provided key. Supported only for tabular Datasets.
type GoogleCloudAiplatformV1beta1PredefinedSplitResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1PredefinedSplitResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1PredefinedSplitResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1PredefinedSplitResponseOutput) ToGoogleCloudAiplatformV1beta1PredefinedSplitResponseOutput() GoogleCloudAiplatformV1beta1PredefinedSplitResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1PredefinedSplitResponseOutput) ToGoogleCloudAiplatformV1beta1PredefinedSplitResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1PredefinedSplitResponseOutput {
	return o
}

// The key is a name of one of the Dataset's data columns. The value of the key (either the label's value or value in the column) must be one of {`training`, `validation`, `test`}, and it defines to which set the given piece of data is assigned. If for a piece of data the key is not present or has an invalid value, that piece is ignored by the pipeline.
func (o GoogleCloudAiplatformV1beta1PredefinedSplitResponseOutput) Key() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PredefinedSplitResponse) string { return v.Key }).(pulumi.StringOutput)
}

// Configuration for logging request-response to a BigQuery table.
type GoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfig struct {
	// BigQuery table for logging. If only given a project, a new dataset will be created with name `logging__` where will be made BigQuery-dataset-name compatible (e.g. most special characters will become underscores). If no table name is given, a new table will be created with name `request_response_logging`
	BigqueryDestination *GoogleCloudAiplatformV1beta1BigQueryDestination `pulumi:"bigqueryDestination"`
	// If logging is enabled or not.
	Enabled *bool `pulumi:"enabled"`
	// Percentage of requests to be logged, expressed as a fraction in range(0,1].
	SamplingRate *float64 `pulumi:"samplingRate"`
}

// GoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigInput is an input type that accepts GoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigArgs and GoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigInput` via:
//
//	GoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigArgs{...}
type GoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigOutput() GoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigOutput
	ToGoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigOutput
}

// Configuration for logging request-response to a BigQuery table.
type GoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigArgs struct {
	// BigQuery table for logging. If only given a project, a new dataset will be created with name `logging__` where will be made BigQuery-dataset-name compatible (e.g. most special characters will become underscores). If no table name is given, a new table will be created with name `request_response_logging`
	BigqueryDestination GoogleCloudAiplatformV1beta1BigQueryDestinationPtrInput `pulumi:"bigqueryDestination"`
	// If logging is enabled or not.
	Enabled pulumi.BoolPtrInput `pulumi:"enabled"`
	// Percentage of requests to be logged, expressed as a fraction in range(0,1].
	SamplingRate pulumi.Float64PtrInput `pulumi:"samplingRate"`
}

func (GoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfig)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigArgs) ToGoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigOutput() GoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigOutput {
	return i.ToGoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigArgs) ToGoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigOutput)
}

func (i GoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigArgs) ToGoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigPtrOutput() GoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigArgs) ToGoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigOutput).ToGoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigArgs, GoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigPtr and GoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigPtrOutput() GoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigPtrOutput
	ToGoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigPtrOutput
}

type googleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigPtrType GoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigArgs

func GoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigPtr(v *GoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigArgs) GoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigPtrInput {
	return (*googleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigPtrType)(v)
}

func (*googleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfig)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigPtrType) ToGoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigPtrOutput() GoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigPtrType) ToGoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigPtrOutput)
}

// Configuration for logging request-response to a BigQuery table.
type GoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigOutput) ToGoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigOutput() GoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigOutput) ToGoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigOutput) ToGoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigPtrOutput() GoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigOutput) ToGoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfig) *GoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfig {
		return &v
	}).(GoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigPtrOutput)
}

// BigQuery table for logging. If only given a project, a new dataset will be created with name `logging__` where will be made BigQuery-dataset-name compatible (e.g. most special characters will become underscores). If no table name is given, a new table will be created with name `request_response_logging`
func (o GoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigOutput) BigqueryDestination() GoogleCloudAiplatformV1beta1BigQueryDestinationPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfig) *GoogleCloudAiplatformV1beta1BigQueryDestination {
		return v.BigqueryDestination
	}).(GoogleCloudAiplatformV1beta1BigQueryDestinationPtrOutput)
}

// If logging is enabled or not.
func (o GoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigOutput) Enabled() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfig) *bool { return v.Enabled }).(pulumi.BoolPtrOutput)
}

// Percentage of requests to be logged, expressed as a fraction in range(0,1].
func (o GoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigOutput) SamplingRate() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfig) *float64 {
		return v.SamplingRate
	}).(pulumi.Float64PtrOutput)
}

type GoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigPtrOutput) ToGoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigPtrOutput() GoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigPtrOutput) ToGoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigPtrOutput) Elem() GoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfig) GoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfig {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfig
		return ret
	}).(GoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigOutput)
}

// BigQuery table for logging. If only given a project, a new dataset will be created with name `logging__` where will be made BigQuery-dataset-name compatible (e.g. most special characters will become underscores). If no table name is given, a new table will be created with name `request_response_logging`
func (o GoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigPtrOutput) BigqueryDestination() GoogleCloudAiplatformV1beta1BigQueryDestinationPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfig) *GoogleCloudAiplatformV1beta1BigQueryDestination {
		if v == nil {
			return nil
		}
		return v.BigqueryDestination
	}).(GoogleCloudAiplatformV1beta1BigQueryDestinationPtrOutput)
}

// If logging is enabled or not.
func (o GoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigPtrOutput) Enabled() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfig) *bool {
		if v == nil {
			return nil
		}
		return v.Enabled
	}).(pulumi.BoolPtrOutput)
}

// Percentage of requests to be logged, expressed as a fraction in range(0,1].
func (o GoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigPtrOutput) SamplingRate() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfig) *float64 {
		if v == nil {
			return nil
		}
		return v.SamplingRate
	}).(pulumi.Float64PtrOutput)
}

// Configuration for logging request-response to a BigQuery table.
type GoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigResponse struct {
	// BigQuery table for logging. If only given a project, a new dataset will be created with name `logging__` where will be made BigQuery-dataset-name compatible (e.g. most special characters will become underscores). If no table name is given, a new table will be created with name `request_response_logging`
	BigqueryDestination GoogleCloudAiplatformV1beta1BigQueryDestinationResponse `pulumi:"bigqueryDestination"`
	// If logging is enabled or not.
	Enabled bool `pulumi:"enabled"`
	// Percentage of requests to be logged, expressed as a fraction in range(0,1].
	SamplingRate float64 `pulumi:"samplingRate"`
}

// Configuration for logging request-response to a BigQuery table.
type GoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigResponseOutput) ToGoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigResponseOutput() GoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigResponseOutput) ToGoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigResponseOutput {
	return o
}

// BigQuery table for logging. If only given a project, a new dataset will be created with name `logging__` where will be made BigQuery-dataset-name compatible (e.g. most special characters will become underscores). If no table name is given, a new table will be created with name `request_response_logging`
func (o GoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigResponseOutput) BigqueryDestination() GoogleCloudAiplatformV1beta1BigQueryDestinationResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigResponse) GoogleCloudAiplatformV1beta1BigQueryDestinationResponse {
		return v.BigqueryDestination
	}).(GoogleCloudAiplatformV1beta1BigQueryDestinationResponseOutput)
}

// If logging is enabled or not.
func (o GoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigResponseOutput) Enabled() pulumi.BoolOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigResponse) bool { return v.Enabled }).(pulumi.BoolOutput)
}

// Percentage of requests to be logged, expressed as a fraction in range(0,1].
func (o GoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigResponseOutput) SamplingRate() pulumi.Float64Output {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigResponse) float64 {
		return v.SamplingRate
	}).(pulumi.Float64Output)
}

// Contains the schemata used in Model's predictions and explanations via PredictionService.Predict, PredictionService.Explain and BatchPredictionJob.
type GoogleCloudAiplatformV1beta1PredictSchemata struct {
	// Immutable. Points to a YAML file stored on Google Cloud Storage describing the format of a single instance, which are used in PredictRequest.instances, ExplainRequest.instances and BatchPredictionJob.input_config. The schema is defined as an OpenAPI 3.0.2 [Schema Object](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject). AutoML Models always have this field populated by Vertex AI. Note: The URI given on output will be immutable and probably different, including the URI scheme, than the one given on input. The output URI will point to a location where the user only has a read access.
	InstanceSchemaUri *string `pulumi:"instanceSchemaUri"`
	// Immutable. Points to a YAML file stored on Google Cloud Storage describing the parameters of prediction and explanation via PredictRequest.parameters, ExplainRequest.parameters and BatchPredictionJob.model_parameters. The schema is defined as an OpenAPI 3.0.2 [Schema Object](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject). AutoML Models always have this field populated by Vertex AI, if no parameters are supported, then it is set to an empty string. Note: The URI given on output will be immutable and probably different, including the URI scheme, than the one given on input. The output URI will point to a location where the user only has a read access.
	ParametersSchemaUri *string `pulumi:"parametersSchemaUri"`
	// Immutable. Points to a YAML file stored on Google Cloud Storage describing the format of a single prediction produced by this Model, which are returned via PredictResponse.predictions, ExplainResponse.explanations, and BatchPredictionJob.output_config. The schema is defined as an OpenAPI 3.0.2 [Schema Object](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject). AutoML Models always have this field populated by Vertex AI. Note: The URI given on output will be immutable and probably different, including the URI scheme, than the one given on input. The output URI will point to a location where the user only has a read access.
	PredictionSchemaUri *string `pulumi:"predictionSchemaUri"`
}

// GoogleCloudAiplatformV1beta1PredictSchemataInput is an input type that accepts GoogleCloudAiplatformV1beta1PredictSchemataArgs and GoogleCloudAiplatformV1beta1PredictSchemataOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1PredictSchemataInput` via:
//
//	GoogleCloudAiplatformV1beta1PredictSchemataArgs{...}
type GoogleCloudAiplatformV1beta1PredictSchemataInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1PredictSchemataOutput() GoogleCloudAiplatformV1beta1PredictSchemataOutput
	ToGoogleCloudAiplatformV1beta1PredictSchemataOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1PredictSchemataOutput
}

// Contains the schemata used in Model's predictions and explanations via PredictionService.Predict, PredictionService.Explain and BatchPredictionJob.
type GoogleCloudAiplatformV1beta1PredictSchemataArgs struct {
	// Immutable. Points to a YAML file stored on Google Cloud Storage describing the format of a single instance, which are used in PredictRequest.instances, ExplainRequest.instances and BatchPredictionJob.input_config. The schema is defined as an OpenAPI 3.0.2 [Schema Object](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject). AutoML Models always have this field populated by Vertex AI. Note: The URI given on output will be immutable and probably different, including the URI scheme, than the one given on input. The output URI will point to a location where the user only has a read access.
	InstanceSchemaUri pulumi.StringPtrInput `pulumi:"instanceSchemaUri"`
	// Immutable. Points to a YAML file stored on Google Cloud Storage describing the parameters of prediction and explanation via PredictRequest.parameters, ExplainRequest.parameters and BatchPredictionJob.model_parameters. The schema is defined as an OpenAPI 3.0.2 [Schema Object](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject). AutoML Models always have this field populated by Vertex AI, if no parameters are supported, then it is set to an empty string. Note: The URI given on output will be immutable and probably different, including the URI scheme, than the one given on input. The output URI will point to a location where the user only has a read access.
	ParametersSchemaUri pulumi.StringPtrInput `pulumi:"parametersSchemaUri"`
	// Immutable. Points to a YAML file stored on Google Cloud Storage describing the format of a single prediction produced by this Model, which are returned via PredictResponse.predictions, ExplainResponse.explanations, and BatchPredictionJob.output_config. The schema is defined as an OpenAPI 3.0.2 [Schema Object](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject). AutoML Models always have this field populated by Vertex AI. Note: The URI given on output will be immutable and probably different, including the URI scheme, than the one given on input. The output URI will point to a location where the user only has a read access.
	PredictionSchemaUri pulumi.StringPtrInput `pulumi:"predictionSchemaUri"`
}

func (GoogleCloudAiplatformV1beta1PredictSchemataArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1PredictSchemata)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1PredictSchemataArgs) ToGoogleCloudAiplatformV1beta1PredictSchemataOutput() GoogleCloudAiplatformV1beta1PredictSchemataOutput {
	return i.ToGoogleCloudAiplatformV1beta1PredictSchemataOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1PredictSchemataArgs) ToGoogleCloudAiplatformV1beta1PredictSchemataOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1PredictSchemataOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1PredictSchemataOutput)
}

func (i GoogleCloudAiplatformV1beta1PredictSchemataArgs) ToGoogleCloudAiplatformV1beta1PredictSchemataPtrOutput() GoogleCloudAiplatformV1beta1PredictSchemataPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1PredictSchemataPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1PredictSchemataArgs) ToGoogleCloudAiplatformV1beta1PredictSchemataPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1PredictSchemataPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1PredictSchemataOutput).ToGoogleCloudAiplatformV1beta1PredictSchemataPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1PredictSchemataPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1PredictSchemataArgs, GoogleCloudAiplatformV1beta1PredictSchemataPtr and GoogleCloudAiplatformV1beta1PredictSchemataPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1PredictSchemataPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1PredictSchemataArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1PredictSchemataPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1PredictSchemataPtrOutput() GoogleCloudAiplatformV1beta1PredictSchemataPtrOutput
	ToGoogleCloudAiplatformV1beta1PredictSchemataPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1PredictSchemataPtrOutput
}

type googleCloudAiplatformV1beta1PredictSchemataPtrType GoogleCloudAiplatformV1beta1PredictSchemataArgs

func GoogleCloudAiplatformV1beta1PredictSchemataPtr(v *GoogleCloudAiplatformV1beta1PredictSchemataArgs) GoogleCloudAiplatformV1beta1PredictSchemataPtrInput {
	return (*googleCloudAiplatformV1beta1PredictSchemataPtrType)(v)
}

func (*googleCloudAiplatformV1beta1PredictSchemataPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1PredictSchemata)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1PredictSchemataPtrType) ToGoogleCloudAiplatformV1beta1PredictSchemataPtrOutput() GoogleCloudAiplatformV1beta1PredictSchemataPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1PredictSchemataPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1PredictSchemataPtrType) ToGoogleCloudAiplatformV1beta1PredictSchemataPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1PredictSchemataPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1PredictSchemataPtrOutput)
}

// Contains the schemata used in Model's predictions and explanations via PredictionService.Predict, PredictionService.Explain and BatchPredictionJob.
type GoogleCloudAiplatformV1beta1PredictSchemataOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1PredictSchemataOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1PredictSchemata)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1PredictSchemataOutput) ToGoogleCloudAiplatformV1beta1PredictSchemataOutput() GoogleCloudAiplatformV1beta1PredictSchemataOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1PredictSchemataOutput) ToGoogleCloudAiplatformV1beta1PredictSchemataOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1PredictSchemataOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1PredictSchemataOutput) ToGoogleCloudAiplatformV1beta1PredictSchemataPtrOutput() GoogleCloudAiplatformV1beta1PredictSchemataPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1PredictSchemataPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1PredictSchemataOutput) ToGoogleCloudAiplatformV1beta1PredictSchemataPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1PredictSchemataPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1PredictSchemata) *GoogleCloudAiplatformV1beta1PredictSchemata {
		return &v
	}).(GoogleCloudAiplatformV1beta1PredictSchemataPtrOutput)
}

// Immutable. Points to a YAML file stored on Google Cloud Storage describing the format of a single instance, which are used in PredictRequest.instances, ExplainRequest.instances and BatchPredictionJob.input_config. The schema is defined as an OpenAPI 3.0.2 [Schema Object](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject). AutoML Models always have this field populated by Vertex AI. Note: The URI given on output will be immutable and probably different, including the URI scheme, than the one given on input. The output URI will point to a location where the user only has a read access.
func (o GoogleCloudAiplatformV1beta1PredictSchemataOutput) InstanceSchemaUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PredictSchemata) *string { return v.InstanceSchemaUri }).(pulumi.StringPtrOutput)
}

// Immutable. Points to a YAML file stored on Google Cloud Storage describing the parameters of prediction and explanation via PredictRequest.parameters, ExplainRequest.parameters and BatchPredictionJob.model_parameters. The schema is defined as an OpenAPI 3.0.2 [Schema Object](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject). AutoML Models always have this field populated by Vertex AI, if no parameters are supported, then it is set to an empty string. Note: The URI given on output will be immutable and probably different, including the URI scheme, than the one given on input. The output URI will point to a location where the user only has a read access.
func (o GoogleCloudAiplatformV1beta1PredictSchemataOutput) ParametersSchemaUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PredictSchemata) *string { return v.ParametersSchemaUri }).(pulumi.StringPtrOutput)
}

// Immutable. Points to a YAML file stored on Google Cloud Storage describing the format of a single prediction produced by this Model, which are returned via PredictResponse.predictions, ExplainResponse.explanations, and BatchPredictionJob.output_config. The schema is defined as an OpenAPI 3.0.2 [Schema Object](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject). AutoML Models always have this field populated by Vertex AI. Note: The URI given on output will be immutable and probably different, including the URI scheme, than the one given on input. The output URI will point to a location where the user only has a read access.
func (o GoogleCloudAiplatformV1beta1PredictSchemataOutput) PredictionSchemaUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PredictSchemata) *string { return v.PredictionSchemaUri }).(pulumi.StringPtrOutput)
}

type GoogleCloudAiplatformV1beta1PredictSchemataPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1PredictSchemataPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1PredictSchemata)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1PredictSchemataPtrOutput) ToGoogleCloudAiplatformV1beta1PredictSchemataPtrOutput() GoogleCloudAiplatformV1beta1PredictSchemataPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1PredictSchemataPtrOutput) ToGoogleCloudAiplatformV1beta1PredictSchemataPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1PredictSchemataPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1PredictSchemataPtrOutput) Elem() GoogleCloudAiplatformV1beta1PredictSchemataOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1PredictSchemata) GoogleCloudAiplatformV1beta1PredictSchemata {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1PredictSchemata
		return ret
	}).(GoogleCloudAiplatformV1beta1PredictSchemataOutput)
}

// Immutable. Points to a YAML file stored on Google Cloud Storage describing the format of a single instance, which are used in PredictRequest.instances, ExplainRequest.instances and BatchPredictionJob.input_config. The schema is defined as an OpenAPI 3.0.2 [Schema Object](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject). AutoML Models always have this field populated by Vertex AI. Note: The URI given on output will be immutable and probably different, including the URI scheme, than the one given on input. The output URI will point to a location where the user only has a read access.
func (o GoogleCloudAiplatformV1beta1PredictSchemataPtrOutput) InstanceSchemaUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1PredictSchemata) *string {
		if v == nil {
			return nil
		}
		return v.InstanceSchemaUri
	}).(pulumi.StringPtrOutput)
}

// Immutable. Points to a YAML file stored on Google Cloud Storage describing the parameters of prediction and explanation via PredictRequest.parameters, ExplainRequest.parameters and BatchPredictionJob.model_parameters. The schema is defined as an OpenAPI 3.0.2 [Schema Object](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject). AutoML Models always have this field populated by Vertex AI, if no parameters are supported, then it is set to an empty string. Note: The URI given on output will be immutable and probably different, including the URI scheme, than the one given on input. The output URI will point to a location where the user only has a read access.
func (o GoogleCloudAiplatformV1beta1PredictSchemataPtrOutput) ParametersSchemaUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1PredictSchemata) *string {
		if v == nil {
			return nil
		}
		return v.ParametersSchemaUri
	}).(pulumi.StringPtrOutput)
}

// Immutable. Points to a YAML file stored on Google Cloud Storage describing the format of a single prediction produced by this Model, which are returned via PredictResponse.predictions, ExplainResponse.explanations, and BatchPredictionJob.output_config. The schema is defined as an OpenAPI 3.0.2 [Schema Object](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject). AutoML Models always have this field populated by Vertex AI. Note: The URI given on output will be immutable and probably different, including the URI scheme, than the one given on input. The output URI will point to a location where the user only has a read access.
func (o GoogleCloudAiplatformV1beta1PredictSchemataPtrOutput) PredictionSchemaUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1PredictSchemata) *string {
		if v == nil {
			return nil
		}
		return v.PredictionSchemaUri
	}).(pulumi.StringPtrOutput)
}

// Contains the schemata used in Model's predictions and explanations via PredictionService.Predict, PredictionService.Explain and BatchPredictionJob.
type GoogleCloudAiplatformV1beta1PredictSchemataResponse struct {
	// Immutable. Points to a YAML file stored on Google Cloud Storage describing the format of a single instance, which are used in PredictRequest.instances, ExplainRequest.instances and BatchPredictionJob.input_config. The schema is defined as an OpenAPI 3.0.2 [Schema Object](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject). AutoML Models always have this field populated by Vertex AI. Note: The URI given on output will be immutable and probably different, including the URI scheme, than the one given on input. The output URI will point to a location where the user only has a read access.
	InstanceSchemaUri string `pulumi:"instanceSchemaUri"`
	// Immutable. Points to a YAML file stored on Google Cloud Storage describing the parameters of prediction and explanation via PredictRequest.parameters, ExplainRequest.parameters and BatchPredictionJob.model_parameters. The schema is defined as an OpenAPI 3.0.2 [Schema Object](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject). AutoML Models always have this field populated by Vertex AI, if no parameters are supported, then it is set to an empty string. Note: The URI given on output will be immutable and probably different, including the URI scheme, than the one given on input. The output URI will point to a location where the user only has a read access.
	ParametersSchemaUri string `pulumi:"parametersSchemaUri"`
	// Immutable. Points to a YAML file stored on Google Cloud Storage describing the format of a single prediction produced by this Model, which are returned via PredictResponse.predictions, ExplainResponse.explanations, and BatchPredictionJob.output_config. The schema is defined as an OpenAPI 3.0.2 [Schema Object](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject). AutoML Models always have this field populated by Vertex AI. Note: The URI given on output will be immutable and probably different, including the URI scheme, than the one given on input. The output URI will point to a location where the user only has a read access.
	PredictionSchemaUri string `pulumi:"predictionSchemaUri"`
}

// Contains the schemata used in Model's predictions and explanations via PredictionService.Predict, PredictionService.Explain and BatchPredictionJob.
type GoogleCloudAiplatformV1beta1PredictSchemataResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1PredictSchemataResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1PredictSchemataResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1PredictSchemataResponseOutput) ToGoogleCloudAiplatformV1beta1PredictSchemataResponseOutput() GoogleCloudAiplatformV1beta1PredictSchemataResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1PredictSchemataResponseOutput) ToGoogleCloudAiplatformV1beta1PredictSchemataResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1PredictSchemataResponseOutput {
	return o
}

// Immutable. Points to a YAML file stored on Google Cloud Storage describing the format of a single instance, which are used in PredictRequest.instances, ExplainRequest.instances and BatchPredictionJob.input_config. The schema is defined as an OpenAPI 3.0.2 [Schema Object](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject). AutoML Models always have this field populated by Vertex AI. Note: The URI given on output will be immutable and probably different, including the URI scheme, than the one given on input. The output URI will point to a location where the user only has a read access.
func (o GoogleCloudAiplatformV1beta1PredictSchemataResponseOutput) InstanceSchemaUri() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PredictSchemataResponse) string { return v.InstanceSchemaUri }).(pulumi.StringOutput)
}

// Immutable. Points to a YAML file stored on Google Cloud Storage describing the parameters of prediction and explanation via PredictRequest.parameters, ExplainRequest.parameters and BatchPredictionJob.model_parameters. The schema is defined as an OpenAPI 3.0.2 [Schema Object](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject). AutoML Models always have this field populated by Vertex AI, if no parameters are supported, then it is set to an empty string. Note: The URI given on output will be immutable and probably different, including the URI scheme, than the one given on input. The output URI will point to a location where the user only has a read access.
func (o GoogleCloudAiplatformV1beta1PredictSchemataResponseOutput) ParametersSchemaUri() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PredictSchemataResponse) string { return v.ParametersSchemaUri }).(pulumi.StringOutput)
}

// Immutable. Points to a YAML file stored on Google Cloud Storage describing the format of a single prediction produced by this Model, which are returned via PredictResponse.predictions, ExplainResponse.explanations, and BatchPredictionJob.output_config. The schema is defined as an OpenAPI 3.0.2 [Schema Object](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject). AutoML Models always have this field populated by Vertex AI. Note: The URI given on output will be immutable and probably different, including the URI scheme, than the one given on input. The output URI will point to a location where the user only has a read access.
func (o GoogleCloudAiplatformV1beta1PredictSchemataResponseOutput) PredictionSchemaUri() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PredictSchemataResponse) string { return v.PredictionSchemaUri }).(pulumi.StringOutput)
}

// Preset configuration for example-based explanations
type GoogleCloudAiplatformV1beta1Presets struct {
	// The modality of the uploaded model, which automatically configures the distance measurement and feature normalization for the underlying example index and queries. If your model does not precisely fit one of these types, it is okay to choose the closest type.
	Modality *GoogleCloudAiplatformV1beta1PresetsModality `pulumi:"modality"`
	// Preset option controlling parameters for speed-precision trade-off when querying for examples. If omitted, defaults to `PRECISE`.
	Query *GoogleCloudAiplatformV1beta1PresetsQuery `pulumi:"query"`
}

// GoogleCloudAiplatformV1beta1PresetsInput is an input type that accepts GoogleCloudAiplatformV1beta1PresetsArgs and GoogleCloudAiplatformV1beta1PresetsOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1PresetsInput` via:
//
//	GoogleCloudAiplatformV1beta1PresetsArgs{...}
type GoogleCloudAiplatformV1beta1PresetsInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1PresetsOutput() GoogleCloudAiplatformV1beta1PresetsOutput
	ToGoogleCloudAiplatformV1beta1PresetsOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1PresetsOutput
}

// Preset configuration for example-based explanations
type GoogleCloudAiplatformV1beta1PresetsArgs struct {
	// The modality of the uploaded model, which automatically configures the distance measurement and feature normalization for the underlying example index and queries. If your model does not precisely fit one of these types, it is okay to choose the closest type.
	Modality GoogleCloudAiplatformV1beta1PresetsModalityPtrInput `pulumi:"modality"`
	// Preset option controlling parameters for speed-precision trade-off when querying for examples. If omitted, defaults to `PRECISE`.
	Query GoogleCloudAiplatformV1beta1PresetsQueryPtrInput `pulumi:"query"`
}

func (GoogleCloudAiplatformV1beta1PresetsArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1Presets)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1PresetsArgs) ToGoogleCloudAiplatformV1beta1PresetsOutput() GoogleCloudAiplatformV1beta1PresetsOutput {
	return i.ToGoogleCloudAiplatformV1beta1PresetsOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1PresetsArgs) ToGoogleCloudAiplatformV1beta1PresetsOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1PresetsOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1PresetsOutput)
}

func (i GoogleCloudAiplatformV1beta1PresetsArgs) ToGoogleCloudAiplatformV1beta1PresetsPtrOutput() GoogleCloudAiplatformV1beta1PresetsPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1PresetsPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1PresetsArgs) ToGoogleCloudAiplatformV1beta1PresetsPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1PresetsPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1PresetsOutput).ToGoogleCloudAiplatformV1beta1PresetsPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1PresetsPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1PresetsArgs, GoogleCloudAiplatformV1beta1PresetsPtr and GoogleCloudAiplatformV1beta1PresetsPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1PresetsPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1PresetsArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1PresetsPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1PresetsPtrOutput() GoogleCloudAiplatformV1beta1PresetsPtrOutput
	ToGoogleCloudAiplatformV1beta1PresetsPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1PresetsPtrOutput
}

type googleCloudAiplatformV1beta1PresetsPtrType GoogleCloudAiplatformV1beta1PresetsArgs

func GoogleCloudAiplatformV1beta1PresetsPtr(v *GoogleCloudAiplatformV1beta1PresetsArgs) GoogleCloudAiplatformV1beta1PresetsPtrInput {
	return (*googleCloudAiplatformV1beta1PresetsPtrType)(v)
}

func (*googleCloudAiplatformV1beta1PresetsPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1Presets)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1PresetsPtrType) ToGoogleCloudAiplatformV1beta1PresetsPtrOutput() GoogleCloudAiplatformV1beta1PresetsPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1PresetsPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1PresetsPtrType) ToGoogleCloudAiplatformV1beta1PresetsPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1PresetsPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1PresetsPtrOutput)
}

// Preset configuration for example-based explanations
type GoogleCloudAiplatformV1beta1PresetsOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1PresetsOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1Presets)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1PresetsOutput) ToGoogleCloudAiplatformV1beta1PresetsOutput() GoogleCloudAiplatformV1beta1PresetsOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1PresetsOutput) ToGoogleCloudAiplatformV1beta1PresetsOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1PresetsOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1PresetsOutput) ToGoogleCloudAiplatformV1beta1PresetsPtrOutput() GoogleCloudAiplatformV1beta1PresetsPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1PresetsPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1PresetsOutput) ToGoogleCloudAiplatformV1beta1PresetsPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1PresetsPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1Presets) *GoogleCloudAiplatformV1beta1Presets {
		return &v
	}).(GoogleCloudAiplatformV1beta1PresetsPtrOutput)
}

// The modality of the uploaded model, which automatically configures the distance measurement and feature normalization for the underlying example index and queries. If your model does not precisely fit one of these types, it is okay to choose the closest type.
func (o GoogleCloudAiplatformV1beta1PresetsOutput) Modality() GoogleCloudAiplatformV1beta1PresetsModalityPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1Presets) *GoogleCloudAiplatformV1beta1PresetsModality {
		return v.Modality
	}).(GoogleCloudAiplatformV1beta1PresetsModalityPtrOutput)
}

// Preset option controlling parameters for speed-precision trade-off when querying for examples. If omitted, defaults to `PRECISE`.
func (o GoogleCloudAiplatformV1beta1PresetsOutput) Query() GoogleCloudAiplatformV1beta1PresetsQueryPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1Presets) *GoogleCloudAiplatformV1beta1PresetsQuery { return v.Query }).(GoogleCloudAiplatformV1beta1PresetsQueryPtrOutput)
}

type GoogleCloudAiplatformV1beta1PresetsPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1PresetsPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1Presets)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1PresetsPtrOutput) ToGoogleCloudAiplatformV1beta1PresetsPtrOutput() GoogleCloudAiplatformV1beta1PresetsPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1PresetsPtrOutput) ToGoogleCloudAiplatformV1beta1PresetsPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1PresetsPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1PresetsPtrOutput) Elem() GoogleCloudAiplatformV1beta1PresetsOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1Presets) GoogleCloudAiplatformV1beta1Presets {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1Presets
		return ret
	}).(GoogleCloudAiplatformV1beta1PresetsOutput)
}

// The modality of the uploaded model, which automatically configures the distance measurement and feature normalization for the underlying example index and queries. If your model does not precisely fit one of these types, it is okay to choose the closest type.
func (o GoogleCloudAiplatformV1beta1PresetsPtrOutput) Modality() GoogleCloudAiplatformV1beta1PresetsModalityPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1Presets) *GoogleCloudAiplatformV1beta1PresetsModality {
		if v == nil {
			return nil
		}
		return v.Modality
	}).(GoogleCloudAiplatformV1beta1PresetsModalityPtrOutput)
}

// Preset option controlling parameters for speed-precision trade-off when querying for examples. If omitted, defaults to `PRECISE`.
func (o GoogleCloudAiplatformV1beta1PresetsPtrOutput) Query() GoogleCloudAiplatformV1beta1PresetsQueryPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1Presets) *GoogleCloudAiplatformV1beta1PresetsQuery {
		if v == nil {
			return nil
		}
		return v.Query
	}).(GoogleCloudAiplatformV1beta1PresetsQueryPtrOutput)
}

// Preset configuration for example-based explanations
type GoogleCloudAiplatformV1beta1PresetsResponse struct {
	// The modality of the uploaded model, which automatically configures the distance measurement and feature normalization for the underlying example index and queries. If your model does not precisely fit one of these types, it is okay to choose the closest type.
	Modality string `pulumi:"modality"`
	// Preset option controlling parameters for speed-precision trade-off when querying for examples. If omitted, defaults to `PRECISE`.
	Query string `pulumi:"query"`
}

// Preset configuration for example-based explanations
type GoogleCloudAiplatformV1beta1PresetsResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1PresetsResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1PresetsResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1PresetsResponseOutput) ToGoogleCloudAiplatformV1beta1PresetsResponseOutput() GoogleCloudAiplatformV1beta1PresetsResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1PresetsResponseOutput) ToGoogleCloudAiplatformV1beta1PresetsResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1PresetsResponseOutput {
	return o
}

// The modality of the uploaded model, which automatically configures the distance measurement and feature normalization for the underlying example index and queries. If your model does not precisely fit one of these types, it is okay to choose the closest type.
func (o GoogleCloudAiplatformV1beta1PresetsResponseOutput) Modality() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PresetsResponse) string { return v.Modality }).(pulumi.StringOutput)
}

// Preset option controlling parameters for speed-precision trade-off when querying for examples. If omitted, defaults to `PRECISE`.
func (o GoogleCloudAiplatformV1beta1PresetsResponseOutput) Query() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PresetsResponse) string { return v.Query }).(pulumi.StringOutput)
}

// PrivateEndpoints proto is used to provide paths for users to send requests privately. To send request via private service access, use predict_http_uri, explain_http_uri or health_http_uri. To send request via private service connect, use service_attachment.
type GoogleCloudAiplatformV1beta1PrivateEndpointsResponse struct {
	// Http(s) path to send explain requests.
	ExplainHttpUri string `pulumi:"explainHttpUri"`
	// Http(s) path to send health check requests.
	HealthHttpUri string `pulumi:"healthHttpUri"`
	// Http(s) path to send prediction requests.
	PredictHttpUri string `pulumi:"predictHttpUri"`
	// The name of the service attachment resource. Populated if private service connect is enabled.
	ServiceAttachment string `pulumi:"serviceAttachment"`
}

// PrivateEndpoints proto is used to provide paths for users to send requests privately. To send request via private service access, use predict_http_uri, explain_http_uri or health_http_uri. To send request via private service connect, use service_attachment.
type GoogleCloudAiplatformV1beta1PrivateEndpointsResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1PrivateEndpointsResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1PrivateEndpointsResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1PrivateEndpointsResponseOutput) ToGoogleCloudAiplatformV1beta1PrivateEndpointsResponseOutput() GoogleCloudAiplatformV1beta1PrivateEndpointsResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1PrivateEndpointsResponseOutput) ToGoogleCloudAiplatformV1beta1PrivateEndpointsResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1PrivateEndpointsResponseOutput {
	return o
}

// Http(s) path to send explain requests.
func (o GoogleCloudAiplatformV1beta1PrivateEndpointsResponseOutput) ExplainHttpUri() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PrivateEndpointsResponse) string { return v.ExplainHttpUri }).(pulumi.StringOutput)
}

// Http(s) path to send health check requests.
func (o GoogleCloudAiplatformV1beta1PrivateEndpointsResponseOutput) HealthHttpUri() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PrivateEndpointsResponse) string { return v.HealthHttpUri }).(pulumi.StringOutput)
}

// Http(s) path to send prediction requests.
func (o GoogleCloudAiplatformV1beta1PrivateEndpointsResponseOutput) PredictHttpUri() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PrivateEndpointsResponse) string { return v.PredictHttpUri }).(pulumi.StringOutput)
}

// The name of the service attachment resource. Populated if private service connect is enabled.
func (o GoogleCloudAiplatformV1beta1PrivateEndpointsResponseOutput) ServiceAttachment() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PrivateEndpointsResponse) string { return v.ServiceAttachment }).(pulumi.StringOutput)
}

// Represents configuration for private service connect.
type GoogleCloudAiplatformV1beta1PrivateServiceConnectConfig struct {
	// If true, expose the IndexEndpoint via private service connect.
	EnablePrivateServiceConnect bool `pulumi:"enablePrivateServiceConnect"`
	// A list of Projects from which the forwarding rule will target the service attachment.
	ProjectAllowlist []string `pulumi:"projectAllowlist"`
}

// GoogleCloudAiplatformV1beta1PrivateServiceConnectConfigInput is an input type that accepts GoogleCloudAiplatformV1beta1PrivateServiceConnectConfigArgs and GoogleCloudAiplatformV1beta1PrivateServiceConnectConfigOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1PrivateServiceConnectConfigInput` via:
//
//	GoogleCloudAiplatformV1beta1PrivateServiceConnectConfigArgs{...}
type GoogleCloudAiplatformV1beta1PrivateServiceConnectConfigInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1PrivateServiceConnectConfigOutput() GoogleCloudAiplatformV1beta1PrivateServiceConnectConfigOutput
	ToGoogleCloudAiplatformV1beta1PrivateServiceConnectConfigOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1PrivateServiceConnectConfigOutput
}

// Represents configuration for private service connect.
type GoogleCloudAiplatformV1beta1PrivateServiceConnectConfigArgs struct {
	// If true, expose the IndexEndpoint via private service connect.
	EnablePrivateServiceConnect pulumi.BoolInput `pulumi:"enablePrivateServiceConnect"`
	// A list of Projects from which the forwarding rule will target the service attachment.
	ProjectAllowlist pulumi.StringArrayInput `pulumi:"projectAllowlist"`
}

func (GoogleCloudAiplatformV1beta1PrivateServiceConnectConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1PrivateServiceConnectConfig)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1PrivateServiceConnectConfigArgs) ToGoogleCloudAiplatformV1beta1PrivateServiceConnectConfigOutput() GoogleCloudAiplatformV1beta1PrivateServiceConnectConfigOutput {
	return i.ToGoogleCloudAiplatformV1beta1PrivateServiceConnectConfigOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1PrivateServiceConnectConfigArgs) ToGoogleCloudAiplatformV1beta1PrivateServiceConnectConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1PrivateServiceConnectConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1PrivateServiceConnectConfigOutput)
}

func (i GoogleCloudAiplatformV1beta1PrivateServiceConnectConfigArgs) ToGoogleCloudAiplatformV1beta1PrivateServiceConnectConfigPtrOutput() GoogleCloudAiplatformV1beta1PrivateServiceConnectConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1PrivateServiceConnectConfigPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1PrivateServiceConnectConfigArgs) ToGoogleCloudAiplatformV1beta1PrivateServiceConnectConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1PrivateServiceConnectConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1PrivateServiceConnectConfigOutput).ToGoogleCloudAiplatformV1beta1PrivateServiceConnectConfigPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1PrivateServiceConnectConfigPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1PrivateServiceConnectConfigArgs, GoogleCloudAiplatformV1beta1PrivateServiceConnectConfigPtr and GoogleCloudAiplatformV1beta1PrivateServiceConnectConfigPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1PrivateServiceConnectConfigPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1PrivateServiceConnectConfigArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1PrivateServiceConnectConfigPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1PrivateServiceConnectConfigPtrOutput() GoogleCloudAiplatformV1beta1PrivateServiceConnectConfigPtrOutput
	ToGoogleCloudAiplatformV1beta1PrivateServiceConnectConfigPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1PrivateServiceConnectConfigPtrOutput
}

type googleCloudAiplatformV1beta1PrivateServiceConnectConfigPtrType GoogleCloudAiplatformV1beta1PrivateServiceConnectConfigArgs

func GoogleCloudAiplatformV1beta1PrivateServiceConnectConfigPtr(v *GoogleCloudAiplatformV1beta1PrivateServiceConnectConfigArgs) GoogleCloudAiplatformV1beta1PrivateServiceConnectConfigPtrInput {
	return (*googleCloudAiplatformV1beta1PrivateServiceConnectConfigPtrType)(v)
}

func (*googleCloudAiplatformV1beta1PrivateServiceConnectConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1PrivateServiceConnectConfig)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1PrivateServiceConnectConfigPtrType) ToGoogleCloudAiplatformV1beta1PrivateServiceConnectConfigPtrOutput() GoogleCloudAiplatformV1beta1PrivateServiceConnectConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1PrivateServiceConnectConfigPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1PrivateServiceConnectConfigPtrType) ToGoogleCloudAiplatformV1beta1PrivateServiceConnectConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1PrivateServiceConnectConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1PrivateServiceConnectConfigPtrOutput)
}

// Represents configuration for private service connect.
type GoogleCloudAiplatformV1beta1PrivateServiceConnectConfigOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1PrivateServiceConnectConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1PrivateServiceConnectConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1PrivateServiceConnectConfigOutput) ToGoogleCloudAiplatformV1beta1PrivateServiceConnectConfigOutput() GoogleCloudAiplatformV1beta1PrivateServiceConnectConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1PrivateServiceConnectConfigOutput) ToGoogleCloudAiplatformV1beta1PrivateServiceConnectConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1PrivateServiceConnectConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1PrivateServiceConnectConfigOutput) ToGoogleCloudAiplatformV1beta1PrivateServiceConnectConfigPtrOutput() GoogleCloudAiplatformV1beta1PrivateServiceConnectConfigPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1PrivateServiceConnectConfigPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1PrivateServiceConnectConfigOutput) ToGoogleCloudAiplatformV1beta1PrivateServiceConnectConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1PrivateServiceConnectConfigPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1PrivateServiceConnectConfig) *GoogleCloudAiplatformV1beta1PrivateServiceConnectConfig {
		return &v
	}).(GoogleCloudAiplatformV1beta1PrivateServiceConnectConfigPtrOutput)
}

// If true, expose the IndexEndpoint via private service connect.
func (o GoogleCloudAiplatformV1beta1PrivateServiceConnectConfigOutput) EnablePrivateServiceConnect() pulumi.BoolOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PrivateServiceConnectConfig) bool {
		return v.EnablePrivateServiceConnect
	}).(pulumi.BoolOutput)
}

// A list of Projects from which the forwarding rule will target the service attachment.
func (o GoogleCloudAiplatformV1beta1PrivateServiceConnectConfigOutput) ProjectAllowlist() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PrivateServiceConnectConfig) []string { return v.ProjectAllowlist }).(pulumi.StringArrayOutput)
}

type GoogleCloudAiplatformV1beta1PrivateServiceConnectConfigPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1PrivateServiceConnectConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1PrivateServiceConnectConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1PrivateServiceConnectConfigPtrOutput) ToGoogleCloudAiplatformV1beta1PrivateServiceConnectConfigPtrOutput() GoogleCloudAiplatformV1beta1PrivateServiceConnectConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1PrivateServiceConnectConfigPtrOutput) ToGoogleCloudAiplatformV1beta1PrivateServiceConnectConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1PrivateServiceConnectConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1PrivateServiceConnectConfigPtrOutput) Elem() GoogleCloudAiplatformV1beta1PrivateServiceConnectConfigOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1PrivateServiceConnectConfig) GoogleCloudAiplatformV1beta1PrivateServiceConnectConfig {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1PrivateServiceConnectConfig
		return ret
	}).(GoogleCloudAiplatformV1beta1PrivateServiceConnectConfigOutput)
}

// If true, expose the IndexEndpoint via private service connect.
func (o GoogleCloudAiplatformV1beta1PrivateServiceConnectConfigPtrOutput) EnablePrivateServiceConnect() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1PrivateServiceConnectConfig) *bool {
		if v == nil {
			return nil
		}
		return &v.EnablePrivateServiceConnect
	}).(pulumi.BoolPtrOutput)
}

// A list of Projects from which the forwarding rule will target the service attachment.
func (o GoogleCloudAiplatformV1beta1PrivateServiceConnectConfigPtrOutput) ProjectAllowlist() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1PrivateServiceConnectConfig) []string {
		if v == nil {
			return nil
		}
		return v.ProjectAllowlist
	}).(pulumi.StringArrayOutput)
}

// Represents configuration for private service connect.
type GoogleCloudAiplatformV1beta1PrivateServiceConnectConfigResponse struct {
	// If true, expose the IndexEndpoint via private service connect.
	EnablePrivateServiceConnect bool `pulumi:"enablePrivateServiceConnect"`
	// A list of Projects from which the forwarding rule will target the service attachment.
	ProjectAllowlist []string `pulumi:"projectAllowlist"`
}

// Represents configuration for private service connect.
type GoogleCloudAiplatformV1beta1PrivateServiceConnectConfigResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1PrivateServiceConnectConfigResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1PrivateServiceConnectConfigResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1PrivateServiceConnectConfigResponseOutput) ToGoogleCloudAiplatformV1beta1PrivateServiceConnectConfigResponseOutput() GoogleCloudAiplatformV1beta1PrivateServiceConnectConfigResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1PrivateServiceConnectConfigResponseOutput) ToGoogleCloudAiplatformV1beta1PrivateServiceConnectConfigResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1PrivateServiceConnectConfigResponseOutput {
	return o
}

// If true, expose the IndexEndpoint via private service connect.
func (o GoogleCloudAiplatformV1beta1PrivateServiceConnectConfigResponseOutput) EnablePrivateServiceConnect() pulumi.BoolOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PrivateServiceConnectConfigResponse) bool {
		return v.EnablePrivateServiceConnect
	}).(pulumi.BoolOutput)
}

// A list of Projects from which the forwarding rule will target the service attachment.
func (o GoogleCloudAiplatformV1beta1PrivateServiceConnectConfigResponseOutput) ProjectAllowlist() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PrivateServiceConnectConfigResponse) []string {
		return v.ProjectAllowlist
	}).(pulumi.StringArrayOutput)
}

// Probe describes a health check to be performed against a container to determine whether it is alive or ready to receive traffic.
type GoogleCloudAiplatformV1beta1Probe struct {
	// Exec specifies the action to take.
	Exec *GoogleCloudAiplatformV1beta1ProbeExecAction `pulumi:"exec"`
	// How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1. Must be less than timeout_seconds. Maps to Kubernetes probe argument 'periodSeconds'.
	PeriodSeconds *int `pulumi:"periodSeconds"`
	// Number of seconds after which the probe times out. Defaults to 1 second. Minimum value is 1. Must be greater or equal to period_seconds. Maps to Kubernetes probe argument 'timeoutSeconds'.
	TimeoutSeconds *int `pulumi:"timeoutSeconds"`
}

// GoogleCloudAiplatformV1beta1ProbeInput is an input type that accepts GoogleCloudAiplatformV1beta1ProbeArgs and GoogleCloudAiplatformV1beta1ProbeOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1ProbeInput` via:
//
//	GoogleCloudAiplatformV1beta1ProbeArgs{...}
type GoogleCloudAiplatformV1beta1ProbeInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1ProbeOutput() GoogleCloudAiplatformV1beta1ProbeOutput
	ToGoogleCloudAiplatformV1beta1ProbeOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1ProbeOutput
}

// Probe describes a health check to be performed against a container to determine whether it is alive or ready to receive traffic.
type GoogleCloudAiplatformV1beta1ProbeArgs struct {
	// Exec specifies the action to take.
	Exec GoogleCloudAiplatformV1beta1ProbeExecActionPtrInput `pulumi:"exec"`
	// How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1. Must be less than timeout_seconds. Maps to Kubernetes probe argument 'periodSeconds'.
	PeriodSeconds pulumi.IntPtrInput `pulumi:"periodSeconds"`
	// Number of seconds after which the probe times out. Defaults to 1 second. Minimum value is 1. Must be greater or equal to period_seconds. Maps to Kubernetes probe argument 'timeoutSeconds'.
	TimeoutSeconds pulumi.IntPtrInput `pulumi:"timeoutSeconds"`
}

func (GoogleCloudAiplatformV1beta1ProbeArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1Probe)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1ProbeArgs) ToGoogleCloudAiplatformV1beta1ProbeOutput() GoogleCloudAiplatformV1beta1ProbeOutput {
	return i.ToGoogleCloudAiplatformV1beta1ProbeOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1ProbeArgs) ToGoogleCloudAiplatformV1beta1ProbeOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ProbeOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ProbeOutput)
}

func (i GoogleCloudAiplatformV1beta1ProbeArgs) ToGoogleCloudAiplatformV1beta1ProbePtrOutput() GoogleCloudAiplatformV1beta1ProbePtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1ProbePtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1ProbeArgs) ToGoogleCloudAiplatformV1beta1ProbePtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ProbePtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ProbeOutput).ToGoogleCloudAiplatformV1beta1ProbePtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1ProbePtrInput is an input type that accepts GoogleCloudAiplatformV1beta1ProbeArgs, GoogleCloudAiplatformV1beta1ProbePtr and GoogleCloudAiplatformV1beta1ProbePtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1ProbePtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1ProbeArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1ProbePtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1ProbePtrOutput() GoogleCloudAiplatformV1beta1ProbePtrOutput
	ToGoogleCloudAiplatformV1beta1ProbePtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1ProbePtrOutput
}

type googleCloudAiplatformV1beta1ProbePtrType GoogleCloudAiplatformV1beta1ProbeArgs

func GoogleCloudAiplatformV1beta1ProbePtr(v *GoogleCloudAiplatformV1beta1ProbeArgs) GoogleCloudAiplatformV1beta1ProbePtrInput {
	return (*googleCloudAiplatformV1beta1ProbePtrType)(v)
}

func (*googleCloudAiplatformV1beta1ProbePtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1Probe)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1ProbePtrType) ToGoogleCloudAiplatformV1beta1ProbePtrOutput() GoogleCloudAiplatformV1beta1ProbePtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1ProbePtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1ProbePtrType) ToGoogleCloudAiplatformV1beta1ProbePtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ProbePtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ProbePtrOutput)
}

// Probe describes a health check to be performed against a container to determine whether it is alive or ready to receive traffic.
type GoogleCloudAiplatformV1beta1ProbeOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ProbeOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1Probe)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ProbeOutput) ToGoogleCloudAiplatformV1beta1ProbeOutput() GoogleCloudAiplatformV1beta1ProbeOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ProbeOutput) ToGoogleCloudAiplatformV1beta1ProbeOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ProbeOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ProbeOutput) ToGoogleCloudAiplatformV1beta1ProbePtrOutput() GoogleCloudAiplatformV1beta1ProbePtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1ProbePtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1ProbeOutput) ToGoogleCloudAiplatformV1beta1ProbePtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ProbePtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1Probe) *GoogleCloudAiplatformV1beta1Probe {
		return &v
	}).(GoogleCloudAiplatformV1beta1ProbePtrOutput)
}

// Exec specifies the action to take.
func (o GoogleCloudAiplatformV1beta1ProbeOutput) Exec() GoogleCloudAiplatformV1beta1ProbeExecActionPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1Probe) *GoogleCloudAiplatformV1beta1ProbeExecAction { return v.Exec }).(GoogleCloudAiplatformV1beta1ProbeExecActionPtrOutput)
}

// How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1. Must be less than timeout_seconds. Maps to Kubernetes probe argument 'periodSeconds'.
func (o GoogleCloudAiplatformV1beta1ProbeOutput) PeriodSeconds() pulumi.IntPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1Probe) *int { return v.PeriodSeconds }).(pulumi.IntPtrOutput)
}

// Number of seconds after which the probe times out. Defaults to 1 second. Minimum value is 1. Must be greater or equal to period_seconds. Maps to Kubernetes probe argument 'timeoutSeconds'.
func (o GoogleCloudAiplatformV1beta1ProbeOutput) TimeoutSeconds() pulumi.IntPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1Probe) *int { return v.TimeoutSeconds }).(pulumi.IntPtrOutput)
}

type GoogleCloudAiplatformV1beta1ProbePtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ProbePtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1Probe)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ProbePtrOutput) ToGoogleCloudAiplatformV1beta1ProbePtrOutput() GoogleCloudAiplatformV1beta1ProbePtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ProbePtrOutput) ToGoogleCloudAiplatformV1beta1ProbePtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ProbePtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ProbePtrOutput) Elem() GoogleCloudAiplatformV1beta1ProbeOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1Probe) GoogleCloudAiplatformV1beta1Probe {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1Probe
		return ret
	}).(GoogleCloudAiplatformV1beta1ProbeOutput)
}

// Exec specifies the action to take.
func (o GoogleCloudAiplatformV1beta1ProbePtrOutput) Exec() GoogleCloudAiplatformV1beta1ProbeExecActionPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1Probe) *GoogleCloudAiplatformV1beta1ProbeExecAction {
		if v == nil {
			return nil
		}
		return v.Exec
	}).(GoogleCloudAiplatformV1beta1ProbeExecActionPtrOutput)
}

// How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1. Must be less than timeout_seconds. Maps to Kubernetes probe argument 'periodSeconds'.
func (o GoogleCloudAiplatformV1beta1ProbePtrOutput) PeriodSeconds() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1Probe) *int {
		if v == nil {
			return nil
		}
		return v.PeriodSeconds
	}).(pulumi.IntPtrOutput)
}

// Number of seconds after which the probe times out. Defaults to 1 second. Minimum value is 1. Must be greater or equal to period_seconds. Maps to Kubernetes probe argument 'timeoutSeconds'.
func (o GoogleCloudAiplatformV1beta1ProbePtrOutput) TimeoutSeconds() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1Probe) *int {
		if v == nil {
			return nil
		}
		return v.TimeoutSeconds
	}).(pulumi.IntPtrOutput)
}

// ExecAction specifies a command to execute.
type GoogleCloudAiplatformV1beta1ProbeExecAction struct {
	// Command is the command line to execute inside the container, the working directory for the command is root ('/') in the container's filesystem. The command is simply exec'd, it is not run inside a shell, so traditional shell instructions ('|', etc) won't work. To use a shell, you need to explicitly call out to that shell. Exit status of 0 is treated as live/healthy and non-zero is unhealthy.
	Command []string `pulumi:"command"`
}

// GoogleCloudAiplatformV1beta1ProbeExecActionInput is an input type that accepts GoogleCloudAiplatformV1beta1ProbeExecActionArgs and GoogleCloudAiplatformV1beta1ProbeExecActionOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1ProbeExecActionInput` via:
//
//	GoogleCloudAiplatformV1beta1ProbeExecActionArgs{...}
type GoogleCloudAiplatformV1beta1ProbeExecActionInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1ProbeExecActionOutput() GoogleCloudAiplatformV1beta1ProbeExecActionOutput
	ToGoogleCloudAiplatformV1beta1ProbeExecActionOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1ProbeExecActionOutput
}

// ExecAction specifies a command to execute.
type GoogleCloudAiplatformV1beta1ProbeExecActionArgs struct {
	// Command is the command line to execute inside the container, the working directory for the command is root ('/') in the container's filesystem. The command is simply exec'd, it is not run inside a shell, so traditional shell instructions ('|', etc) won't work. To use a shell, you need to explicitly call out to that shell. Exit status of 0 is treated as live/healthy and non-zero is unhealthy.
	Command pulumi.StringArrayInput `pulumi:"command"`
}

func (GoogleCloudAiplatformV1beta1ProbeExecActionArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ProbeExecAction)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1ProbeExecActionArgs) ToGoogleCloudAiplatformV1beta1ProbeExecActionOutput() GoogleCloudAiplatformV1beta1ProbeExecActionOutput {
	return i.ToGoogleCloudAiplatformV1beta1ProbeExecActionOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1ProbeExecActionArgs) ToGoogleCloudAiplatformV1beta1ProbeExecActionOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ProbeExecActionOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ProbeExecActionOutput)
}

func (i GoogleCloudAiplatformV1beta1ProbeExecActionArgs) ToGoogleCloudAiplatformV1beta1ProbeExecActionPtrOutput() GoogleCloudAiplatformV1beta1ProbeExecActionPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1ProbeExecActionPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1ProbeExecActionArgs) ToGoogleCloudAiplatformV1beta1ProbeExecActionPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ProbeExecActionPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ProbeExecActionOutput).ToGoogleCloudAiplatformV1beta1ProbeExecActionPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1ProbeExecActionPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1ProbeExecActionArgs, GoogleCloudAiplatformV1beta1ProbeExecActionPtr and GoogleCloudAiplatformV1beta1ProbeExecActionPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1ProbeExecActionPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1ProbeExecActionArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1ProbeExecActionPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1ProbeExecActionPtrOutput() GoogleCloudAiplatformV1beta1ProbeExecActionPtrOutput
	ToGoogleCloudAiplatformV1beta1ProbeExecActionPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1ProbeExecActionPtrOutput
}

type googleCloudAiplatformV1beta1ProbeExecActionPtrType GoogleCloudAiplatformV1beta1ProbeExecActionArgs

func GoogleCloudAiplatformV1beta1ProbeExecActionPtr(v *GoogleCloudAiplatformV1beta1ProbeExecActionArgs) GoogleCloudAiplatformV1beta1ProbeExecActionPtrInput {
	return (*googleCloudAiplatformV1beta1ProbeExecActionPtrType)(v)
}

func (*googleCloudAiplatformV1beta1ProbeExecActionPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1ProbeExecAction)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1ProbeExecActionPtrType) ToGoogleCloudAiplatformV1beta1ProbeExecActionPtrOutput() GoogleCloudAiplatformV1beta1ProbeExecActionPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1ProbeExecActionPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1ProbeExecActionPtrType) ToGoogleCloudAiplatformV1beta1ProbeExecActionPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ProbeExecActionPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ProbeExecActionPtrOutput)
}

// ExecAction specifies a command to execute.
type GoogleCloudAiplatformV1beta1ProbeExecActionOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ProbeExecActionOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ProbeExecAction)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ProbeExecActionOutput) ToGoogleCloudAiplatformV1beta1ProbeExecActionOutput() GoogleCloudAiplatformV1beta1ProbeExecActionOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ProbeExecActionOutput) ToGoogleCloudAiplatformV1beta1ProbeExecActionOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ProbeExecActionOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ProbeExecActionOutput) ToGoogleCloudAiplatformV1beta1ProbeExecActionPtrOutput() GoogleCloudAiplatformV1beta1ProbeExecActionPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1ProbeExecActionPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1ProbeExecActionOutput) ToGoogleCloudAiplatformV1beta1ProbeExecActionPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ProbeExecActionPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1ProbeExecAction) *GoogleCloudAiplatformV1beta1ProbeExecAction {
		return &v
	}).(GoogleCloudAiplatformV1beta1ProbeExecActionPtrOutput)
}

// Command is the command line to execute inside the container, the working directory for the command is root ('/') in the container's filesystem. The command is simply exec'd, it is not run inside a shell, so traditional shell instructions ('|', etc) won't work. To use a shell, you need to explicitly call out to that shell. Exit status of 0 is treated as live/healthy and non-zero is unhealthy.
func (o GoogleCloudAiplatformV1beta1ProbeExecActionOutput) Command() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ProbeExecAction) []string { return v.Command }).(pulumi.StringArrayOutput)
}

type GoogleCloudAiplatformV1beta1ProbeExecActionPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ProbeExecActionPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1ProbeExecAction)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ProbeExecActionPtrOutput) ToGoogleCloudAiplatformV1beta1ProbeExecActionPtrOutput() GoogleCloudAiplatformV1beta1ProbeExecActionPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ProbeExecActionPtrOutput) ToGoogleCloudAiplatformV1beta1ProbeExecActionPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ProbeExecActionPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ProbeExecActionPtrOutput) Elem() GoogleCloudAiplatformV1beta1ProbeExecActionOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ProbeExecAction) GoogleCloudAiplatformV1beta1ProbeExecAction {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1ProbeExecAction
		return ret
	}).(GoogleCloudAiplatformV1beta1ProbeExecActionOutput)
}

// Command is the command line to execute inside the container, the working directory for the command is root ('/') in the container's filesystem. The command is simply exec'd, it is not run inside a shell, so traditional shell instructions ('|', etc) won't work. To use a shell, you need to explicitly call out to that shell. Exit status of 0 is treated as live/healthy and non-zero is unhealthy.
func (o GoogleCloudAiplatformV1beta1ProbeExecActionPtrOutput) Command() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ProbeExecAction) []string {
		if v == nil {
			return nil
		}
		return v.Command
	}).(pulumi.StringArrayOutput)
}

// ExecAction specifies a command to execute.
type GoogleCloudAiplatformV1beta1ProbeExecActionResponse struct {
	// Command is the command line to execute inside the container, the working directory for the command is root ('/') in the container's filesystem. The command is simply exec'd, it is not run inside a shell, so traditional shell instructions ('|', etc) won't work. To use a shell, you need to explicitly call out to that shell. Exit status of 0 is treated as live/healthy and non-zero is unhealthy.
	Command []string `pulumi:"command"`
}

// ExecAction specifies a command to execute.
type GoogleCloudAiplatformV1beta1ProbeExecActionResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ProbeExecActionResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ProbeExecActionResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ProbeExecActionResponseOutput) ToGoogleCloudAiplatformV1beta1ProbeExecActionResponseOutput() GoogleCloudAiplatformV1beta1ProbeExecActionResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ProbeExecActionResponseOutput) ToGoogleCloudAiplatformV1beta1ProbeExecActionResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ProbeExecActionResponseOutput {
	return o
}

// Command is the command line to execute inside the container, the working directory for the command is root ('/') in the container's filesystem. The command is simply exec'd, it is not run inside a shell, so traditional shell instructions ('|', etc) won't work. To use a shell, you need to explicitly call out to that shell. Exit status of 0 is treated as live/healthy and non-zero is unhealthy.
func (o GoogleCloudAiplatformV1beta1ProbeExecActionResponseOutput) Command() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ProbeExecActionResponse) []string { return v.Command }).(pulumi.StringArrayOutput)
}

// Probe describes a health check to be performed against a container to determine whether it is alive or ready to receive traffic.
type GoogleCloudAiplatformV1beta1ProbeResponse struct {
	// Exec specifies the action to take.
	Exec GoogleCloudAiplatformV1beta1ProbeExecActionResponse `pulumi:"exec"`
	// How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1. Must be less than timeout_seconds. Maps to Kubernetes probe argument 'periodSeconds'.
	PeriodSeconds int `pulumi:"periodSeconds"`
	// Number of seconds after which the probe times out. Defaults to 1 second. Minimum value is 1. Must be greater or equal to period_seconds. Maps to Kubernetes probe argument 'timeoutSeconds'.
	TimeoutSeconds int `pulumi:"timeoutSeconds"`
}

// Probe describes a health check to be performed against a container to determine whether it is alive or ready to receive traffic.
type GoogleCloudAiplatformV1beta1ProbeResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ProbeResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ProbeResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ProbeResponseOutput) ToGoogleCloudAiplatformV1beta1ProbeResponseOutput() GoogleCloudAiplatformV1beta1ProbeResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ProbeResponseOutput) ToGoogleCloudAiplatformV1beta1ProbeResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ProbeResponseOutput {
	return o
}

// Exec specifies the action to take.
func (o GoogleCloudAiplatformV1beta1ProbeResponseOutput) Exec() GoogleCloudAiplatformV1beta1ProbeExecActionResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ProbeResponse) GoogleCloudAiplatformV1beta1ProbeExecActionResponse {
		return v.Exec
	}).(GoogleCloudAiplatformV1beta1ProbeExecActionResponseOutput)
}

// How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1. Must be less than timeout_seconds. Maps to Kubernetes probe argument 'periodSeconds'.
func (o GoogleCloudAiplatformV1beta1ProbeResponseOutput) PeriodSeconds() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ProbeResponse) int { return v.PeriodSeconds }).(pulumi.IntOutput)
}

// Number of seconds after which the probe times out. Defaults to 1 second. Minimum value is 1. Must be greater or equal to period_seconds. Maps to Kubernetes probe argument 'timeoutSeconds'.
func (o GoogleCloudAiplatformV1beta1ProbeResponseOutput) TimeoutSeconds() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ProbeResponse) int { return v.TimeoutSeconds }).(pulumi.IntOutput)
}

// The spec of a Python packaged code.
type GoogleCloudAiplatformV1beta1PythonPackageSpec struct {
	// Command line arguments to be passed to the Python task.
	Args []string `pulumi:"args"`
	// Environment variables to be passed to the python module. Maximum limit is 100.
	Env []GoogleCloudAiplatformV1beta1EnvVar `pulumi:"env"`
	// The URI of a container image in Artifact Registry that will run the provided Python package. Vertex AI provides a wide range of executor images with pre-installed packages to meet users' various use cases. See the list of [pre-built containers for training](https://cloud.google.com/vertex-ai/docs/training/pre-built-containers). You must use an image from this list.
	ExecutorImageUri string `pulumi:"executorImageUri"`
	// The Google Cloud Storage location of the Python package files which are the training program and its dependent packages. The maximum number of package URIs is 100.
	PackageUris []string `pulumi:"packageUris"`
	// The Python module name to run after installing the packages.
	PythonModule string `pulumi:"pythonModule"`
}

// GoogleCloudAiplatformV1beta1PythonPackageSpecInput is an input type that accepts GoogleCloudAiplatformV1beta1PythonPackageSpecArgs and GoogleCloudAiplatformV1beta1PythonPackageSpecOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1PythonPackageSpecInput` via:
//
//	GoogleCloudAiplatformV1beta1PythonPackageSpecArgs{...}
type GoogleCloudAiplatformV1beta1PythonPackageSpecInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1PythonPackageSpecOutput() GoogleCloudAiplatformV1beta1PythonPackageSpecOutput
	ToGoogleCloudAiplatformV1beta1PythonPackageSpecOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1PythonPackageSpecOutput
}

// The spec of a Python packaged code.
type GoogleCloudAiplatformV1beta1PythonPackageSpecArgs struct {
	// Command line arguments to be passed to the Python task.
	Args pulumi.StringArrayInput `pulumi:"args"`
	// Environment variables to be passed to the python module. Maximum limit is 100.
	Env GoogleCloudAiplatformV1beta1EnvVarArrayInput `pulumi:"env"`
	// The URI of a container image in Artifact Registry that will run the provided Python package. Vertex AI provides a wide range of executor images with pre-installed packages to meet users' various use cases. See the list of [pre-built containers for training](https://cloud.google.com/vertex-ai/docs/training/pre-built-containers). You must use an image from this list.
	ExecutorImageUri pulumi.StringInput `pulumi:"executorImageUri"`
	// The Google Cloud Storage location of the Python package files which are the training program and its dependent packages. The maximum number of package URIs is 100.
	PackageUris pulumi.StringArrayInput `pulumi:"packageUris"`
	// The Python module name to run after installing the packages.
	PythonModule pulumi.StringInput `pulumi:"pythonModule"`
}

func (GoogleCloudAiplatformV1beta1PythonPackageSpecArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1PythonPackageSpec)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1PythonPackageSpecArgs) ToGoogleCloudAiplatformV1beta1PythonPackageSpecOutput() GoogleCloudAiplatformV1beta1PythonPackageSpecOutput {
	return i.ToGoogleCloudAiplatformV1beta1PythonPackageSpecOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1PythonPackageSpecArgs) ToGoogleCloudAiplatformV1beta1PythonPackageSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1PythonPackageSpecOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1PythonPackageSpecOutput)
}

func (i GoogleCloudAiplatformV1beta1PythonPackageSpecArgs) ToGoogleCloudAiplatformV1beta1PythonPackageSpecPtrOutput() GoogleCloudAiplatformV1beta1PythonPackageSpecPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1PythonPackageSpecPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1PythonPackageSpecArgs) ToGoogleCloudAiplatformV1beta1PythonPackageSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1PythonPackageSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1PythonPackageSpecOutput).ToGoogleCloudAiplatformV1beta1PythonPackageSpecPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1PythonPackageSpecPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1PythonPackageSpecArgs, GoogleCloudAiplatformV1beta1PythonPackageSpecPtr and GoogleCloudAiplatformV1beta1PythonPackageSpecPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1PythonPackageSpecPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1PythonPackageSpecArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1PythonPackageSpecPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1PythonPackageSpecPtrOutput() GoogleCloudAiplatformV1beta1PythonPackageSpecPtrOutput
	ToGoogleCloudAiplatformV1beta1PythonPackageSpecPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1PythonPackageSpecPtrOutput
}

type googleCloudAiplatformV1beta1PythonPackageSpecPtrType GoogleCloudAiplatformV1beta1PythonPackageSpecArgs

func GoogleCloudAiplatformV1beta1PythonPackageSpecPtr(v *GoogleCloudAiplatformV1beta1PythonPackageSpecArgs) GoogleCloudAiplatformV1beta1PythonPackageSpecPtrInput {
	return (*googleCloudAiplatformV1beta1PythonPackageSpecPtrType)(v)
}

func (*googleCloudAiplatformV1beta1PythonPackageSpecPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1PythonPackageSpec)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1PythonPackageSpecPtrType) ToGoogleCloudAiplatformV1beta1PythonPackageSpecPtrOutput() GoogleCloudAiplatformV1beta1PythonPackageSpecPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1PythonPackageSpecPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1PythonPackageSpecPtrType) ToGoogleCloudAiplatformV1beta1PythonPackageSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1PythonPackageSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1PythonPackageSpecPtrOutput)
}

// The spec of a Python packaged code.
type GoogleCloudAiplatformV1beta1PythonPackageSpecOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1PythonPackageSpecOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1PythonPackageSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1PythonPackageSpecOutput) ToGoogleCloudAiplatformV1beta1PythonPackageSpecOutput() GoogleCloudAiplatformV1beta1PythonPackageSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1PythonPackageSpecOutput) ToGoogleCloudAiplatformV1beta1PythonPackageSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1PythonPackageSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1PythonPackageSpecOutput) ToGoogleCloudAiplatformV1beta1PythonPackageSpecPtrOutput() GoogleCloudAiplatformV1beta1PythonPackageSpecPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1PythonPackageSpecPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1PythonPackageSpecOutput) ToGoogleCloudAiplatformV1beta1PythonPackageSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1PythonPackageSpecPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1PythonPackageSpec) *GoogleCloudAiplatformV1beta1PythonPackageSpec {
		return &v
	}).(GoogleCloudAiplatformV1beta1PythonPackageSpecPtrOutput)
}

// Command line arguments to be passed to the Python task.
func (o GoogleCloudAiplatformV1beta1PythonPackageSpecOutput) Args() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PythonPackageSpec) []string { return v.Args }).(pulumi.StringArrayOutput)
}

// Environment variables to be passed to the python module. Maximum limit is 100.
func (o GoogleCloudAiplatformV1beta1PythonPackageSpecOutput) Env() GoogleCloudAiplatformV1beta1EnvVarArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PythonPackageSpec) []GoogleCloudAiplatformV1beta1EnvVar {
		return v.Env
	}).(GoogleCloudAiplatformV1beta1EnvVarArrayOutput)
}

// The URI of a container image in Artifact Registry that will run the provided Python package. Vertex AI provides a wide range of executor images with pre-installed packages to meet users' various use cases. See the list of [pre-built containers for training](https://cloud.google.com/vertex-ai/docs/training/pre-built-containers). You must use an image from this list.
func (o GoogleCloudAiplatformV1beta1PythonPackageSpecOutput) ExecutorImageUri() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PythonPackageSpec) string { return v.ExecutorImageUri }).(pulumi.StringOutput)
}

// The Google Cloud Storage location of the Python package files which are the training program and its dependent packages. The maximum number of package URIs is 100.
func (o GoogleCloudAiplatformV1beta1PythonPackageSpecOutput) PackageUris() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PythonPackageSpec) []string { return v.PackageUris }).(pulumi.StringArrayOutput)
}

// The Python module name to run after installing the packages.
func (o GoogleCloudAiplatformV1beta1PythonPackageSpecOutput) PythonModule() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PythonPackageSpec) string { return v.PythonModule }).(pulumi.StringOutput)
}

type GoogleCloudAiplatformV1beta1PythonPackageSpecPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1PythonPackageSpecPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1PythonPackageSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1PythonPackageSpecPtrOutput) ToGoogleCloudAiplatformV1beta1PythonPackageSpecPtrOutput() GoogleCloudAiplatformV1beta1PythonPackageSpecPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1PythonPackageSpecPtrOutput) ToGoogleCloudAiplatformV1beta1PythonPackageSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1PythonPackageSpecPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1PythonPackageSpecPtrOutput) Elem() GoogleCloudAiplatformV1beta1PythonPackageSpecOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1PythonPackageSpec) GoogleCloudAiplatformV1beta1PythonPackageSpec {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1PythonPackageSpec
		return ret
	}).(GoogleCloudAiplatformV1beta1PythonPackageSpecOutput)
}

// Command line arguments to be passed to the Python task.
func (o GoogleCloudAiplatformV1beta1PythonPackageSpecPtrOutput) Args() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1PythonPackageSpec) []string {
		if v == nil {
			return nil
		}
		return v.Args
	}).(pulumi.StringArrayOutput)
}

// Environment variables to be passed to the python module. Maximum limit is 100.
func (o GoogleCloudAiplatformV1beta1PythonPackageSpecPtrOutput) Env() GoogleCloudAiplatformV1beta1EnvVarArrayOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1PythonPackageSpec) []GoogleCloudAiplatformV1beta1EnvVar {
		if v == nil {
			return nil
		}
		return v.Env
	}).(GoogleCloudAiplatformV1beta1EnvVarArrayOutput)
}

// The URI of a container image in Artifact Registry that will run the provided Python package. Vertex AI provides a wide range of executor images with pre-installed packages to meet users' various use cases. See the list of [pre-built containers for training](https://cloud.google.com/vertex-ai/docs/training/pre-built-containers). You must use an image from this list.
func (o GoogleCloudAiplatformV1beta1PythonPackageSpecPtrOutput) ExecutorImageUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1PythonPackageSpec) *string {
		if v == nil {
			return nil
		}
		return &v.ExecutorImageUri
	}).(pulumi.StringPtrOutput)
}

// The Google Cloud Storage location of the Python package files which are the training program and its dependent packages. The maximum number of package URIs is 100.
func (o GoogleCloudAiplatformV1beta1PythonPackageSpecPtrOutput) PackageUris() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1PythonPackageSpec) []string {
		if v == nil {
			return nil
		}
		return v.PackageUris
	}).(pulumi.StringArrayOutput)
}

// The Python module name to run after installing the packages.
func (o GoogleCloudAiplatformV1beta1PythonPackageSpecPtrOutput) PythonModule() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1PythonPackageSpec) *string {
		if v == nil {
			return nil
		}
		return &v.PythonModule
	}).(pulumi.StringPtrOutput)
}

// The spec of a Python packaged code.
type GoogleCloudAiplatformV1beta1PythonPackageSpecResponse struct {
	// Command line arguments to be passed to the Python task.
	Args []string `pulumi:"args"`
	// Environment variables to be passed to the python module. Maximum limit is 100.
	Env []GoogleCloudAiplatformV1beta1EnvVarResponse `pulumi:"env"`
	// The URI of a container image in Artifact Registry that will run the provided Python package. Vertex AI provides a wide range of executor images with pre-installed packages to meet users' various use cases. See the list of [pre-built containers for training](https://cloud.google.com/vertex-ai/docs/training/pre-built-containers). You must use an image from this list.
	ExecutorImageUri string `pulumi:"executorImageUri"`
	// The Google Cloud Storage location of the Python package files which are the training program and its dependent packages. The maximum number of package URIs is 100.
	PackageUris []string `pulumi:"packageUris"`
	// The Python module name to run after installing the packages.
	PythonModule string `pulumi:"pythonModule"`
}

// The spec of a Python packaged code.
type GoogleCloudAiplatformV1beta1PythonPackageSpecResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1PythonPackageSpecResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1PythonPackageSpecResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1PythonPackageSpecResponseOutput) ToGoogleCloudAiplatformV1beta1PythonPackageSpecResponseOutput() GoogleCloudAiplatformV1beta1PythonPackageSpecResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1PythonPackageSpecResponseOutput) ToGoogleCloudAiplatformV1beta1PythonPackageSpecResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1PythonPackageSpecResponseOutput {
	return o
}

// Command line arguments to be passed to the Python task.
func (o GoogleCloudAiplatformV1beta1PythonPackageSpecResponseOutput) Args() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PythonPackageSpecResponse) []string { return v.Args }).(pulumi.StringArrayOutput)
}

// Environment variables to be passed to the python module. Maximum limit is 100.
func (o GoogleCloudAiplatformV1beta1PythonPackageSpecResponseOutput) Env() GoogleCloudAiplatformV1beta1EnvVarResponseArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PythonPackageSpecResponse) []GoogleCloudAiplatformV1beta1EnvVarResponse {
		return v.Env
	}).(GoogleCloudAiplatformV1beta1EnvVarResponseArrayOutput)
}

// The URI of a container image in Artifact Registry that will run the provided Python package. Vertex AI provides a wide range of executor images with pre-installed packages to meet users' various use cases. See the list of [pre-built containers for training](https://cloud.google.com/vertex-ai/docs/training/pre-built-containers). You must use an image from this list.
func (o GoogleCloudAiplatformV1beta1PythonPackageSpecResponseOutput) ExecutorImageUri() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PythonPackageSpecResponse) string { return v.ExecutorImageUri }).(pulumi.StringOutput)
}

// The Google Cloud Storage location of the Python package files which are the training program and its dependent packages. The maximum number of package URIs is 100.
func (o GoogleCloudAiplatformV1beta1PythonPackageSpecResponseOutput) PackageUris() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PythonPackageSpecResponse) []string { return v.PackageUris }).(pulumi.StringArrayOutput)
}

// The Python module name to run after installing the packages.
func (o GoogleCloudAiplatformV1beta1PythonPackageSpecResponseOutput) PythonModule() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1PythonPackageSpecResponse) string { return v.PythonModule }).(pulumi.StringOutput)
}

// Configuration information for the Ray cluster. For experimental launch, Ray cluster creation and Persistent cluster creation are 1:1 mapping: We will provision all the nodes within the Persistent cluster as Ray nodes.
type GoogleCloudAiplatformV1beta1RaySpec struct {
	// Optional. This will be used to indicate which resource pool will serve as the Ray head node(the first node within that pool). Will use the machine from the first workerpool as the head node by default if this field isn't set.
	HeadNodeResourcePoolId *string `pulumi:"headNodeResourcePoolId"`
	// Optional. Default image for user to choose a preferred ML framework (for example, TensorFlow or Pytorch) by choosing from [Vertex prebuilt images](https://cloud.google.com/vertex-ai/docs/training/pre-built-containers). Either this or the resource_pool_images is required. Use this field if you need all the resource pools to have the same Ray image. Otherwise, use the {@code resource_pool_images} field.
	ImageUri *string `pulumi:"imageUri"`
	// Optional. Required if image_uri isn't set. A map of resource_pool_id to prebuild Ray image if user need to use different images for different head/worker pools. This map needs to cover all the resource pool ids. Example: { "ray_head_node_pool": "head image" "ray_worker_node_pool1": "worker image" "ray_worker_node_pool2": "another worker image" }
	ResourcePoolImages map[string]string `pulumi:"resourcePoolImages"`
}

// GoogleCloudAiplatformV1beta1RaySpecInput is an input type that accepts GoogleCloudAiplatformV1beta1RaySpecArgs and GoogleCloudAiplatformV1beta1RaySpecOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1RaySpecInput` via:
//
//	GoogleCloudAiplatformV1beta1RaySpecArgs{...}
type GoogleCloudAiplatformV1beta1RaySpecInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1RaySpecOutput() GoogleCloudAiplatformV1beta1RaySpecOutput
	ToGoogleCloudAiplatformV1beta1RaySpecOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1RaySpecOutput
}

// Configuration information for the Ray cluster. For experimental launch, Ray cluster creation and Persistent cluster creation are 1:1 mapping: We will provision all the nodes within the Persistent cluster as Ray nodes.
type GoogleCloudAiplatformV1beta1RaySpecArgs struct {
	// Optional. This will be used to indicate which resource pool will serve as the Ray head node(the first node within that pool). Will use the machine from the first workerpool as the head node by default if this field isn't set.
	HeadNodeResourcePoolId pulumi.StringPtrInput `pulumi:"headNodeResourcePoolId"`
	// Optional. Default image for user to choose a preferred ML framework (for example, TensorFlow or Pytorch) by choosing from [Vertex prebuilt images](https://cloud.google.com/vertex-ai/docs/training/pre-built-containers). Either this or the resource_pool_images is required. Use this field if you need all the resource pools to have the same Ray image. Otherwise, use the {@code resource_pool_images} field.
	ImageUri pulumi.StringPtrInput `pulumi:"imageUri"`
	// Optional. Required if image_uri isn't set. A map of resource_pool_id to prebuild Ray image if user need to use different images for different head/worker pools. This map needs to cover all the resource pool ids. Example: { "ray_head_node_pool": "head image" "ray_worker_node_pool1": "worker image" "ray_worker_node_pool2": "another worker image" }
	ResourcePoolImages pulumi.StringMapInput `pulumi:"resourcePoolImages"`
}

func (GoogleCloudAiplatformV1beta1RaySpecArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1RaySpec)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1RaySpecArgs) ToGoogleCloudAiplatformV1beta1RaySpecOutput() GoogleCloudAiplatformV1beta1RaySpecOutput {
	return i.ToGoogleCloudAiplatformV1beta1RaySpecOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1RaySpecArgs) ToGoogleCloudAiplatformV1beta1RaySpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1RaySpecOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1RaySpecOutput)
}

func (i GoogleCloudAiplatformV1beta1RaySpecArgs) ToGoogleCloudAiplatformV1beta1RaySpecPtrOutput() GoogleCloudAiplatformV1beta1RaySpecPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1RaySpecPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1RaySpecArgs) ToGoogleCloudAiplatformV1beta1RaySpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1RaySpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1RaySpecOutput).ToGoogleCloudAiplatformV1beta1RaySpecPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1RaySpecPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1RaySpecArgs, GoogleCloudAiplatformV1beta1RaySpecPtr and GoogleCloudAiplatformV1beta1RaySpecPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1RaySpecPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1RaySpecArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1RaySpecPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1RaySpecPtrOutput() GoogleCloudAiplatformV1beta1RaySpecPtrOutput
	ToGoogleCloudAiplatformV1beta1RaySpecPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1RaySpecPtrOutput
}

type googleCloudAiplatformV1beta1RaySpecPtrType GoogleCloudAiplatformV1beta1RaySpecArgs

func GoogleCloudAiplatformV1beta1RaySpecPtr(v *GoogleCloudAiplatformV1beta1RaySpecArgs) GoogleCloudAiplatformV1beta1RaySpecPtrInput {
	return (*googleCloudAiplatformV1beta1RaySpecPtrType)(v)
}

func (*googleCloudAiplatformV1beta1RaySpecPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1RaySpec)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1RaySpecPtrType) ToGoogleCloudAiplatformV1beta1RaySpecPtrOutput() GoogleCloudAiplatformV1beta1RaySpecPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1RaySpecPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1RaySpecPtrType) ToGoogleCloudAiplatformV1beta1RaySpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1RaySpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1RaySpecPtrOutput)
}

// Configuration information for the Ray cluster. For experimental launch, Ray cluster creation and Persistent cluster creation are 1:1 mapping: We will provision all the nodes within the Persistent cluster as Ray nodes.
type GoogleCloudAiplatformV1beta1RaySpecOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1RaySpecOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1RaySpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1RaySpecOutput) ToGoogleCloudAiplatformV1beta1RaySpecOutput() GoogleCloudAiplatformV1beta1RaySpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1RaySpecOutput) ToGoogleCloudAiplatformV1beta1RaySpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1RaySpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1RaySpecOutput) ToGoogleCloudAiplatformV1beta1RaySpecPtrOutput() GoogleCloudAiplatformV1beta1RaySpecPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1RaySpecPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1RaySpecOutput) ToGoogleCloudAiplatformV1beta1RaySpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1RaySpecPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1RaySpec) *GoogleCloudAiplatformV1beta1RaySpec {
		return &v
	}).(GoogleCloudAiplatformV1beta1RaySpecPtrOutput)
}

// Optional. This will be used to indicate which resource pool will serve as the Ray head node(the first node within that pool). Will use the machine from the first workerpool as the head node by default if this field isn't set.
func (o GoogleCloudAiplatformV1beta1RaySpecOutput) HeadNodeResourcePoolId() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1RaySpec) *string { return v.HeadNodeResourcePoolId }).(pulumi.StringPtrOutput)
}

// Optional. Default image for user to choose a preferred ML framework (for example, TensorFlow or Pytorch) by choosing from [Vertex prebuilt images](https://cloud.google.com/vertex-ai/docs/training/pre-built-containers). Either this or the resource_pool_images is required. Use this field if you need all the resource pools to have the same Ray image. Otherwise, use the {@code resource_pool_images} field.
func (o GoogleCloudAiplatformV1beta1RaySpecOutput) ImageUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1RaySpec) *string { return v.ImageUri }).(pulumi.StringPtrOutput)
}

// Optional. Required if image_uri isn't set. A map of resource_pool_id to prebuild Ray image if user need to use different images for different head/worker pools. This map needs to cover all the resource pool ids. Example: { "ray_head_node_pool": "head image" "ray_worker_node_pool1": "worker image" "ray_worker_node_pool2": "another worker image" }
func (o GoogleCloudAiplatformV1beta1RaySpecOutput) ResourcePoolImages() pulumi.StringMapOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1RaySpec) map[string]string { return v.ResourcePoolImages }).(pulumi.StringMapOutput)
}

type GoogleCloudAiplatformV1beta1RaySpecPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1RaySpecPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1RaySpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1RaySpecPtrOutput) ToGoogleCloudAiplatformV1beta1RaySpecPtrOutput() GoogleCloudAiplatformV1beta1RaySpecPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1RaySpecPtrOutput) ToGoogleCloudAiplatformV1beta1RaySpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1RaySpecPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1RaySpecPtrOutput) Elem() GoogleCloudAiplatformV1beta1RaySpecOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1RaySpec) GoogleCloudAiplatformV1beta1RaySpec {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1RaySpec
		return ret
	}).(GoogleCloudAiplatformV1beta1RaySpecOutput)
}

// Optional. This will be used to indicate which resource pool will serve as the Ray head node(the first node within that pool). Will use the machine from the first workerpool as the head node by default if this field isn't set.
func (o GoogleCloudAiplatformV1beta1RaySpecPtrOutput) HeadNodeResourcePoolId() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1RaySpec) *string {
		if v == nil {
			return nil
		}
		return v.HeadNodeResourcePoolId
	}).(pulumi.StringPtrOutput)
}

// Optional. Default image for user to choose a preferred ML framework (for example, TensorFlow or Pytorch) by choosing from [Vertex prebuilt images](https://cloud.google.com/vertex-ai/docs/training/pre-built-containers). Either this or the resource_pool_images is required. Use this field if you need all the resource pools to have the same Ray image. Otherwise, use the {@code resource_pool_images} field.
func (o GoogleCloudAiplatformV1beta1RaySpecPtrOutput) ImageUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1RaySpec) *string {
		if v == nil {
			return nil
		}
		return v.ImageUri
	}).(pulumi.StringPtrOutput)
}

// Optional. Required if image_uri isn't set. A map of resource_pool_id to prebuild Ray image if user need to use different images for different head/worker pools. This map needs to cover all the resource pool ids. Example: { "ray_head_node_pool": "head image" "ray_worker_node_pool1": "worker image" "ray_worker_node_pool2": "another worker image" }
func (o GoogleCloudAiplatformV1beta1RaySpecPtrOutput) ResourcePoolImages() pulumi.StringMapOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1RaySpec) map[string]string {
		if v == nil {
			return nil
		}
		return v.ResourcePoolImages
	}).(pulumi.StringMapOutput)
}

// Configuration information for the Ray cluster. For experimental launch, Ray cluster creation and Persistent cluster creation are 1:1 mapping: We will provision all the nodes within the Persistent cluster as Ray nodes.
type GoogleCloudAiplatformV1beta1RaySpecResponse struct {
	// Optional. This will be used to indicate which resource pool will serve as the Ray head node(the first node within that pool). Will use the machine from the first workerpool as the head node by default if this field isn't set.
	HeadNodeResourcePoolId string `pulumi:"headNodeResourcePoolId"`
	// Optional. Default image for user to choose a preferred ML framework (for example, TensorFlow or Pytorch) by choosing from [Vertex prebuilt images](https://cloud.google.com/vertex-ai/docs/training/pre-built-containers). Either this or the resource_pool_images is required. Use this field if you need all the resource pools to have the same Ray image. Otherwise, use the {@code resource_pool_images} field.
	ImageUri string `pulumi:"imageUri"`
	// Optional. Required if image_uri isn't set. A map of resource_pool_id to prebuild Ray image if user need to use different images for different head/worker pools. This map needs to cover all the resource pool ids. Example: { "ray_head_node_pool": "head image" "ray_worker_node_pool1": "worker image" "ray_worker_node_pool2": "another worker image" }
	ResourcePoolImages map[string]string `pulumi:"resourcePoolImages"`
}

// Configuration information for the Ray cluster. For experimental launch, Ray cluster creation and Persistent cluster creation are 1:1 mapping: We will provision all the nodes within the Persistent cluster as Ray nodes.
type GoogleCloudAiplatformV1beta1RaySpecResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1RaySpecResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1RaySpecResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1RaySpecResponseOutput) ToGoogleCloudAiplatformV1beta1RaySpecResponseOutput() GoogleCloudAiplatformV1beta1RaySpecResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1RaySpecResponseOutput) ToGoogleCloudAiplatformV1beta1RaySpecResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1RaySpecResponseOutput {
	return o
}

// Optional. This will be used to indicate which resource pool will serve as the Ray head node(the first node within that pool). Will use the machine from the first workerpool as the head node by default if this field isn't set.
func (o GoogleCloudAiplatformV1beta1RaySpecResponseOutput) HeadNodeResourcePoolId() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1RaySpecResponse) string { return v.HeadNodeResourcePoolId }).(pulumi.StringOutput)
}

// Optional. Default image for user to choose a preferred ML framework (for example, TensorFlow or Pytorch) by choosing from [Vertex prebuilt images](https://cloud.google.com/vertex-ai/docs/training/pre-built-containers). Either this or the resource_pool_images is required. Use this field if you need all the resource pools to have the same Ray image. Otherwise, use the {@code resource_pool_images} field.
func (o GoogleCloudAiplatformV1beta1RaySpecResponseOutput) ImageUri() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1RaySpecResponse) string { return v.ImageUri }).(pulumi.StringOutput)
}

// Optional. Required if image_uri isn't set. A map of resource_pool_id to prebuild Ray image if user need to use different images for different head/worker pools. This map needs to cover all the resource pool ids. Example: { "ray_head_node_pool": "head image" "ray_worker_node_pool1": "worker image" "ray_worker_node_pool2": "another worker image" }
func (o GoogleCloudAiplatformV1beta1RaySpecResponseOutput) ResourcePoolImages() pulumi.StringMapOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1RaySpecResponse) map[string]string { return v.ResourcePoolImages }).(pulumi.StringMapOutput)
}

// Represents the spec of a group of resources of the same type, for example machine type, disk, and accelerators, in a PersistentResource.
type GoogleCloudAiplatformV1beta1ResourcePool struct {
	// Optional. Optional spec to configure GKE autoscaling
	AutoscalingSpec *GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpec `pulumi:"autoscalingSpec"`
	// Optional. Disk spec for the machine in this node pool.
	DiskSpec *GoogleCloudAiplatformV1beta1DiskSpec `pulumi:"diskSpec"`
	// Immutable. The unique ID in a PersistentResource for referring to this resource pool. User can specify it if necessary. Otherwise, it's generated automatically.
	Id *string `pulumi:"id"`
	// Immutable. The specification of a single machine.
	MachineSpec GoogleCloudAiplatformV1beta1MachineSpec `pulumi:"machineSpec"`
	// Optional. The total number of machines to use for this resource pool.
	ReplicaCount *string `pulumi:"replicaCount"`
}

// GoogleCloudAiplatformV1beta1ResourcePoolInput is an input type that accepts GoogleCloudAiplatformV1beta1ResourcePoolArgs and GoogleCloudAiplatformV1beta1ResourcePoolOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1ResourcePoolInput` via:
//
//	GoogleCloudAiplatformV1beta1ResourcePoolArgs{...}
type GoogleCloudAiplatformV1beta1ResourcePoolInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1ResourcePoolOutput() GoogleCloudAiplatformV1beta1ResourcePoolOutput
	ToGoogleCloudAiplatformV1beta1ResourcePoolOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1ResourcePoolOutput
}

// Represents the spec of a group of resources of the same type, for example machine type, disk, and accelerators, in a PersistentResource.
type GoogleCloudAiplatformV1beta1ResourcePoolArgs struct {
	// Optional. Optional spec to configure GKE autoscaling
	AutoscalingSpec GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecPtrInput `pulumi:"autoscalingSpec"`
	// Optional. Disk spec for the machine in this node pool.
	DiskSpec GoogleCloudAiplatformV1beta1DiskSpecPtrInput `pulumi:"diskSpec"`
	// Immutable. The unique ID in a PersistentResource for referring to this resource pool. User can specify it if necessary. Otherwise, it's generated automatically.
	Id pulumi.StringPtrInput `pulumi:"id"`
	// Immutable. The specification of a single machine.
	MachineSpec GoogleCloudAiplatformV1beta1MachineSpecInput `pulumi:"machineSpec"`
	// Optional. The total number of machines to use for this resource pool.
	ReplicaCount pulumi.StringPtrInput `pulumi:"replicaCount"`
}

func (GoogleCloudAiplatformV1beta1ResourcePoolArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ResourcePool)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1ResourcePoolArgs) ToGoogleCloudAiplatformV1beta1ResourcePoolOutput() GoogleCloudAiplatformV1beta1ResourcePoolOutput {
	return i.ToGoogleCloudAiplatformV1beta1ResourcePoolOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1ResourcePoolArgs) ToGoogleCloudAiplatformV1beta1ResourcePoolOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ResourcePoolOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ResourcePoolOutput)
}

// GoogleCloudAiplatformV1beta1ResourcePoolArrayInput is an input type that accepts GoogleCloudAiplatformV1beta1ResourcePoolArray and GoogleCloudAiplatformV1beta1ResourcePoolArrayOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1ResourcePoolArrayInput` via:
//
//	GoogleCloudAiplatformV1beta1ResourcePoolArray{ GoogleCloudAiplatformV1beta1ResourcePoolArgs{...} }
type GoogleCloudAiplatformV1beta1ResourcePoolArrayInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1ResourcePoolArrayOutput() GoogleCloudAiplatformV1beta1ResourcePoolArrayOutput
	ToGoogleCloudAiplatformV1beta1ResourcePoolArrayOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1ResourcePoolArrayOutput
}

type GoogleCloudAiplatformV1beta1ResourcePoolArray []GoogleCloudAiplatformV1beta1ResourcePoolInput

func (GoogleCloudAiplatformV1beta1ResourcePoolArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1beta1ResourcePool)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1ResourcePoolArray) ToGoogleCloudAiplatformV1beta1ResourcePoolArrayOutput() GoogleCloudAiplatformV1beta1ResourcePoolArrayOutput {
	return i.ToGoogleCloudAiplatformV1beta1ResourcePoolArrayOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1ResourcePoolArray) ToGoogleCloudAiplatformV1beta1ResourcePoolArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ResourcePoolArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ResourcePoolArrayOutput)
}

// Represents the spec of a group of resources of the same type, for example machine type, disk, and accelerators, in a PersistentResource.
type GoogleCloudAiplatformV1beta1ResourcePoolOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ResourcePoolOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ResourcePool)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ResourcePoolOutput) ToGoogleCloudAiplatformV1beta1ResourcePoolOutput() GoogleCloudAiplatformV1beta1ResourcePoolOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ResourcePoolOutput) ToGoogleCloudAiplatformV1beta1ResourcePoolOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ResourcePoolOutput {
	return o
}

// Optional. Optional spec to configure GKE autoscaling
func (o GoogleCloudAiplatformV1beta1ResourcePoolOutput) AutoscalingSpec() GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ResourcePool) *GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpec {
		return v.AutoscalingSpec
	}).(GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecPtrOutput)
}

// Optional. Disk spec for the machine in this node pool.
func (o GoogleCloudAiplatformV1beta1ResourcePoolOutput) DiskSpec() GoogleCloudAiplatformV1beta1DiskSpecPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ResourcePool) *GoogleCloudAiplatformV1beta1DiskSpec {
		return v.DiskSpec
	}).(GoogleCloudAiplatformV1beta1DiskSpecPtrOutput)
}

// Immutable. The unique ID in a PersistentResource for referring to this resource pool. User can specify it if necessary. Otherwise, it's generated automatically.
func (o GoogleCloudAiplatformV1beta1ResourcePoolOutput) Id() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ResourcePool) *string { return v.Id }).(pulumi.StringPtrOutput)
}

// Immutable. The specification of a single machine.
func (o GoogleCloudAiplatformV1beta1ResourcePoolOutput) MachineSpec() GoogleCloudAiplatformV1beta1MachineSpecOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ResourcePool) GoogleCloudAiplatformV1beta1MachineSpec {
		return v.MachineSpec
	}).(GoogleCloudAiplatformV1beta1MachineSpecOutput)
}

// Optional. The total number of machines to use for this resource pool.
func (o GoogleCloudAiplatformV1beta1ResourcePoolOutput) ReplicaCount() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ResourcePool) *string { return v.ReplicaCount }).(pulumi.StringPtrOutput)
}

type GoogleCloudAiplatformV1beta1ResourcePoolArrayOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ResourcePoolArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1beta1ResourcePool)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ResourcePoolArrayOutput) ToGoogleCloudAiplatformV1beta1ResourcePoolArrayOutput() GoogleCloudAiplatformV1beta1ResourcePoolArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ResourcePoolArrayOutput) ToGoogleCloudAiplatformV1beta1ResourcePoolArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ResourcePoolArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ResourcePoolArrayOutput) Index(i pulumi.IntInput) GoogleCloudAiplatformV1beta1ResourcePoolOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GoogleCloudAiplatformV1beta1ResourcePool {
		return vs[0].([]GoogleCloudAiplatformV1beta1ResourcePool)[vs[1].(int)]
	}).(GoogleCloudAiplatformV1beta1ResourcePoolOutput)
}

// The min/max number of replicas allowed if enabling autoscaling
type GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpec struct {
	// Optional. max replicas in the node pool, must be ≥ replica_count and > min_replica_count or will throw error
	MaxReplicaCount *string `pulumi:"maxReplicaCount"`
	// Optional. min replicas in the node pool, must be ≤ replica_count and < max_replica_count or will throw error
	MinReplicaCount *string `pulumi:"minReplicaCount"`
}

// GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecInput is an input type that accepts GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecArgs and GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecInput` via:
//
//	GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecArgs{...}
type GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecOutput() GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecOutput
	ToGoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecOutput
}

// The min/max number of replicas allowed if enabling autoscaling
type GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecArgs struct {
	// Optional. max replicas in the node pool, must be ≥ replica_count and > min_replica_count or will throw error
	MaxReplicaCount pulumi.StringPtrInput `pulumi:"maxReplicaCount"`
	// Optional. min replicas in the node pool, must be ≤ replica_count and < max_replica_count or will throw error
	MinReplicaCount pulumi.StringPtrInput `pulumi:"minReplicaCount"`
}

func (GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpec)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecArgs) ToGoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecOutput() GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecOutput {
	return i.ToGoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecArgs) ToGoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecOutput)
}

func (i GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecArgs) ToGoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecPtrOutput() GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecArgs) ToGoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecOutput).ToGoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecArgs, GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecPtr and GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecPtrOutput() GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecPtrOutput
	ToGoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecPtrOutput
}

type googleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecPtrType GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecArgs

func GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecPtr(v *GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecArgs) GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecPtrInput {
	return (*googleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecPtrType)(v)
}

func (*googleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpec)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecPtrType) ToGoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecPtrOutput() GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecPtrType) ToGoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecPtrOutput)
}

// The min/max number of replicas allowed if enabling autoscaling
type GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecOutput) ToGoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecOutput() GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecOutput) ToGoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecOutput) ToGoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecPtrOutput() GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecOutput) ToGoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpec) *GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpec {
		return &v
	}).(GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecPtrOutput)
}

// Optional. max replicas in the node pool, must be ≥ replica_count and > min_replica_count or will throw error
func (o GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecOutput) MaxReplicaCount() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpec) *string { return v.MaxReplicaCount }).(pulumi.StringPtrOutput)
}

// Optional. min replicas in the node pool, must be ≤ replica_count and < max_replica_count or will throw error
func (o GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecOutput) MinReplicaCount() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpec) *string { return v.MinReplicaCount }).(pulumi.StringPtrOutput)
}

type GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecPtrOutput) ToGoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecPtrOutput() GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecPtrOutput) ToGoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecPtrOutput) Elem() GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpec) GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpec {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpec
		return ret
	}).(GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecOutput)
}

// Optional. max replicas in the node pool, must be ≥ replica_count and > min_replica_count or will throw error
func (o GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecPtrOutput) MaxReplicaCount() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpec) *string {
		if v == nil {
			return nil
		}
		return v.MaxReplicaCount
	}).(pulumi.StringPtrOutput)
}

// Optional. min replicas in the node pool, must be ≤ replica_count and < max_replica_count or will throw error
func (o GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecPtrOutput) MinReplicaCount() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpec) *string {
		if v == nil {
			return nil
		}
		return v.MinReplicaCount
	}).(pulumi.StringPtrOutput)
}

// The min/max number of replicas allowed if enabling autoscaling
type GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecResponse struct {
	// Optional. max replicas in the node pool, must be ≥ replica_count and > min_replica_count or will throw error
	MaxReplicaCount string `pulumi:"maxReplicaCount"`
	// Optional. min replicas in the node pool, must be ≤ replica_count and < max_replica_count or will throw error
	MinReplicaCount string `pulumi:"minReplicaCount"`
}

// The min/max number of replicas allowed if enabling autoscaling
type GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecResponseOutput) ToGoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecResponseOutput() GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecResponseOutput) ToGoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecResponseOutput {
	return o
}

// Optional. max replicas in the node pool, must be ≥ replica_count and > min_replica_count or will throw error
func (o GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecResponseOutput) MaxReplicaCount() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecResponse) string {
		return v.MaxReplicaCount
	}).(pulumi.StringOutput)
}

// Optional. min replicas in the node pool, must be ≤ replica_count and < max_replica_count or will throw error
func (o GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecResponseOutput) MinReplicaCount() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecResponse) string {
		return v.MinReplicaCount
	}).(pulumi.StringOutput)
}

// Represents the spec of a group of resources of the same type, for example machine type, disk, and accelerators, in a PersistentResource.
type GoogleCloudAiplatformV1beta1ResourcePoolResponse struct {
	// Optional. Optional spec to configure GKE autoscaling
	AutoscalingSpec GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecResponse `pulumi:"autoscalingSpec"`
	// Optional. Disk spec for the machine in this node pool.
	DiskSpec GoogleCloudAiplatformV1beta1DiskSpecResponse `pulumi:"diskSpec"`
	// Immutable. The specification of a single machine.
	MachineSpec GoogleCloudAiplatformV1beta1MachineSpecResponse `pulumi:"machineSpec"`
	// Optional. The total number of machines to use for this resource pool.
	ReplicaCount string `pulumi:"replicaCount"`
	// The number of machines currently in use by training jobs for this resource pool. Will replace idle_replica_count.
	UsedReplicaCount string `pulumi:"usedReplicaCount"`
}

// Represents the spec of a group of resources of the same type, for example machine type, disk, and accelerators, in a PersistentResource.
type GoogleCloudAiplatformV1beta1ResourcePoolResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ResourcePoolResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ResourcePoolResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ResourcePoolResponseOutput) ToGoogleCloudAiplatformV1beta1ResourcePoolResponseOutput() GoogleCloudAiplatformV1beta1ResourcePoolResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ResourcePoolResponseOutput) ToGoogleCloudAiplatformV1beta1ResourcePoolResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ResourcePoolResponseOutput {
	return o
}

// Optional. Optional spec to configure GKE autoscaling
func (o GoogleCloudAiplatformV1beta1ResourcePoolResponseOutput) AutoscalingSpec() GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ResourcePoolResponse) GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecResponse {
		return v.AutoscalingSpec
	}).(GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecResponseOutput)
}

// Optional. Disk spec for the machine in this node pool.
func (o GoogleCloudAiplatformV1beta1ResourcePoolResponseOutput) DiskSpec() GoogleCloudAiplatformV1beta1DiskSpecResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ResourcePoolResponse) GoogleCloudAiplatformV1beta1DiskSpecResponse {
		return v.DiskSpec
	}).(GoogleCloudAiplatformV1beta1DiskSpecResponseOutput)
}

// Immutable. The specification of a single machine.
func (o GoogleCloudAiplatformV1beta1ResourcePoolResponseOutput) MachineSpec() GoogleCloudAiplatformV1beta1MachineSpecResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ResourcePoolResponse) GoogleCloudAiplatformV1beta1MachineSpecResponse {
		return v.MachineSpec
	}).(GoogleCloudAiplatformV1beta1MachineSpecResponseOutput)
}

// Optional. The total number of machines to use for this resource pool.
func (o GoogleCloudAiplatformV1beta1ResourcePoolResponseOutput) ReplicaCount() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ResourcePoolResponse) string { return v.ReplicaCount }).(pulumi.StringOutput)
}

// The number of machines currently in use by training jobs for this resource pool. Will replace idle_replica_count.
func (o GoogleCloudAiplatformV1beta1ResourcePoolResponseOutput) UsedReplicaCount() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ResourcePoolResponse) string { return v.UsedReplicaCount }).(pulumi.StringOutput)
}

type GoogleCloudAiplatformV1beta1ResourcePoolResponseArrayOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ResourcePoolResponseArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1beta1ResourcePoolResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ResourcePoolResponseArrayOutput) ToGoogleCloudAiplatformV1beta1ResourcePoolResponseArrayOutput() GoogleCloudAiplatformV1beta1ResourcePoolResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ResourcePoolResponseArrayOutput) ToGoogleCloudAiplatformV1beta1ResourcePoolResponseArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ResourcePoolResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ResourcePoolResponseArrayOutput) Index(i pulumi.IntInput) GoogleCloudAiplatformV1beta1ResourcePoolResponseOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GoogleCloudAiplatformV1beta1ResourcePoolResponse {
		return vs[0].([]GoogleCloudAiplatformV1beta1ResourcePoolResponse)[vs[1].(int)]
	}).(GoogleCloudAiplatformV1beta1ResourcePoolResponseOutput)
}

// Persistent Cluster runtime information as output
type GoogleCloudAiplatformV1beta1ResourceRuntimeResponse struct {
	// URIs for user to connect to the Cluster. Example: { "RAY_HEAD_NODE_INTERNAL_IP": "head-node-IP:10001" "RAY_DASHBOARD_URI": "ray-dashboard-address:8888" }
	AccessUris map[string]string `pulumi:"accessUris"`
	// The resource name of NotebookRuntimeTemplate for the RoV Persistent Cluster The NotebokRuntimeTemplate is created in the same VPC (if set), and with the same Ray and Python version as the Persistent Cluster. Example: "projects/1000/locations/us-central1/notebookRuntimeTemplates/abc123"
	NotebookRuntimeTemplate string `pulumi:"notebookRuntimeTemplate"`
}

// Persistent Cluster runtime information as output
type GoogleCloudAiplatformV1beta1ResourceRuntimeResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ResourceRuntimeResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ResourceRuntimeResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ResourceRuntimeResponseOutput) ToGoogleCloudAiplatformV1beta1ResourceRuntimeResponseOutput() GoogleCloudAiplatformV1beta1ResourceRuntimeResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ResourceRuntimeResponseOutput) ToGoogleCloudAiplatformV1beta1ResourceRuntimeResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ResourceRuntimeResponseOutput {
	return o
}

// URIs for user to connect to the Cluster. Example: { "RAY_HEAD_NODE_INTERNAL_IP": "head-node-IP:10001" "RAY_DASHBOARD_URI": "ray-dashboard-address:8888" }
func (o GoogleCloudAiplatformV1beta1ResourceRuntimeResponseOutput) AccessUris() pulumi.StringMapOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ResourceRuntimeResponse) map[string]string { return v.AccessUris }).(pulumi.StringMapOutput)
}

// The resource name of NotebookRuntimeTemplate for the RoV Persistent Cluster The NotebokRuntimeTemplate is created in the same VPC (if set), and with the same Ray and Python version as the Persistent Cluster. Example: "projects/1000/locations/us-central1/notebookRuntimeTemplates/abc123"
func (o GoogleCloudAiplatformV1beta1ResourceRuntimeResponseOutput) NotebookRuntimeTemplate() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ResourceRuntimeResponse) string { return v.NotebookRuntimeTemplate }).(pulumi.StringOutput)
}

// Configuration for the runtime on a PersistentResource instance, including but not limited to: * Service accounts used to run the workloads. * Whether to make it a dedicated Ray Cluster.
type GoogleCloudAiplatformV1beta1ResourceRuntimeSpec struct {
	// Optional. Ray cluster configuration. Required when creating a dedicated RayCluster on the PersistentResource.
	RaySpec *GoogleCloudAiplatformV1beta1RaySpec `pulumi:"raySpec"`
	// Optional. Configure the use of workload identity on the PersistentResource
	ServiceAccountSpec *GoogleCloudAiplatformV1beta1ServiceAccountSpec `pulumi:"serviceAccountSpec"`
}

// GoogleCloudAiplatformV1beta1ResourceRuntimeSpecInput is an input type that accepts GoogleCloudAiplatformV1beta1ResourceRuntimeSpecArgs and GoogleCloudAiplatformV1beta1ResourceRuntimeSpecOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1ResourceRuntimeSpecInput` via:
//
//	GoogleCloudAiplatformV1beta1ResourceRuntimeSpecArgs{...}
type GoogleCloudAiplatformV1beta1ResourceRuntimeSpecInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1ResourceRuntimeSpecOutput() GoogleCloudAiplatformV1beta1ResourceRuntimeSpecOutput
	ToGoogleCloudAiplatformV1beta1ResourceRuntimeSpecOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1ResourceRuntimeSpecOutput
}

// Configuration for the runtime on a PersistentResource instance, including but not limited to: * Service accounts used to run the workloads. * Whether to make it a dedicated Ray Cluster.
type GoogleCloudAiplatformV1beta1ResourceRuntimeSpecArgs struct {
	// Optional. Ray cluster configuration. Required when creating a dedicated RayCluster on the PersistentResource.
	RaySpec GoogleCloudAiplatformV1beta1RaySpecPtrInput `pulumi:"raySpec"`
	// Optional. Configure the use of workload identity on the PersistentResource
	ServiceAccountSpec GoogleCloudAiplatformV1beta1ServiceAccountSpecPtrInput `pulumi:"serviceAccountSpec"`
}

func (GoogleCloudAiplatformV1beta1ResourceRuntimeSpecArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ResourceRuntimeSpec)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1ResourceRuntimeSpecArgs) ToGoogleCloudAiplatformV1beta1ResourceRuntimeSpecOutput() GoogleCloudAiplatformV1beta1ResourceRuntimeSpecOutput {
	return i.ToGoogleCloudAiplatformV1beta1ResourceRuntimeSpecOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1ResourceRuntimeSpecArgs) ToGoogleCloudAiplatformV1beta1ResourceRuntimeSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ResourceRuntimeSpecOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ResourceRuntimeSpecOutput)
}

func (i GoogleCloudAiplatformV1beta1ResourceRuntimeSpecArgs) ToGoogleCloudAiplatformV1beta1ResourceRuntimeSpecPtrOutput() GoogleCloudAiplatformV1beta1ResourceRuntimeSpecPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1ResourceRuntimeSpecPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1ResourceRuntimeSpecArgs) ToGoogleCloudAiplatformV1beta1ResourceRuntimeSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ResourceRuntimeSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ResourceRuntimeSpecOutput).ToGoogleCloudAiplatformV1beta1ResourceRuntimeSpecPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1ResourceRuntimeSpecPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1ResourceRuntimeSpecArgs, GoogleCloudAiplatformV1beta1ResourceRuntimeSpecPtr and GoogleCloudAiplatformV1beta1ResourceRuntimeSpecPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1ResourceRuntimeSpecPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1ResourceRuntimeSpecArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1ResourceRuntimeSpecPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1ResourceRuntimeSpecPtrOutput() GoogleCloudAiplatformV1beta1ResourceRuntimeSpecPtrOutput
	ToGoogleCloudAiplatformV1beta1ResourceRuntimeSpecPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1ResourceRuntimeSpecPtrOutput
}

type googleCloudAiplatformV1beta1ResourceRuntimeSpecPtrType GoogleCloudAiplatformV1beta1ResourceRuntimeSpecArgs

func GoogleCloudAiplatformV1beta1ResourceRuntimeSpecPtr(v *GoogleCloudAiplatformV1beta1ResourceRuntimeSpecArgs) GoogleCloudAiplatformV1beta1ResourceRuntimeSpecPtrInput {
	return (*googleCloudAiplatformV1beta1ResourceRuntimeSpecPtrType)(v)
}

func (*googleCloudAiplatformV1beta1ResourceRuntimeSpecPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1ResourceRuntimeSpec)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1ResourceRuntimeSpecPtrType) ToGoogleCloudAiplatformV1beta1ResourceRuntimeSpecPtrOutput() GoogleCloudAiplatformV1beta1ResourceRuntimeSpecPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1ResourceRuntimeSpecPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1ResourceRuntimeSpecPtrType) ToGoogleCloudAiplatformV1beta1ResourceRuntimeSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ResourceRuntimeSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ResourceRuntimeSpecPtrOutput)
}

// Configuration for the runtime on a PersistentResource instance, including but not limited to: * Service accounts used to run the workloads. * Whether to make it a dedicated Ray Cluster.
type GoogleCloudAiplatformV1beta1ResourceRuntimeSpecOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ResourceRuntimeSpecOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ResourceRuntimeSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ResourceRuntimeSpecOutput) ToGoogleCloudAiplatformV1beta1ResourceRuntimeSpecOutput() GoogleCloudAiplatformV1beta1ResourceRuntimeSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ResourceRuntimeSpecOutput) ToGoogleCloudAiplatformV1beta1ResourceRuntimeSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ResourceRuntimeSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ResourceRuntimeSpecOutput) ToGoogleCloudAiplatformV1beta1ResourceRuntimeSpecPtrOutput() GoogleCloudAiplatformV1beta1ResourceRuntimeSpecPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1ResourceRuntimeSpecPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1ResourceRuntimeSpecOutput) ToGoogleCloudAiplatformV1beta1ResourceRuntimeSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ResourceRuntimeSpecPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1ResourceRuntimeSpec) *GoogleCloudAiplatformV1beta1ResourceRuntimeSpec {
		return &v
	}).(GoogleCloudAiplatformV1beta1ResourceRuntimeSpecPtrOutput)
}

// Optional. Ray cluster configuration. Required when creating a dedicated RayCluster on the PersistentResource.
func (o GoogleCloudAiplatformV1beta1ResourceRuntimeSpecOutput) RaySpec() GoogleCloudAiplatformV1beta1RaySpecPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ResourceRuntimeSpec) *GoogleCloudAiplatformV1beta1RaySpec {
		return v.RaySpec
	}).(GoogleCloudAiplatformV1beta1RaySpecPtrOutput)
}

// Optional. Configure the use of workload identity on the PersistentResource
func (o GoogleCloudAiplatformV1beta1ResourceRuntimeSpecOutput) ServiceAccountSpec() GoogleCloudAiplatformV1beta1ServiceAccountSpecPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ResourceRuntimeSpec) *GoogleCloudAiplatformV1beta1ServiceAccountSpec {
		return v.ServiceAccountSpec
	}).(GoogleCloudAiplatformV1beta1ServiceAccountSpecPtrOutput)
}

type GoogleCloudAiplatformV1beta1ResourceRuntimeSpecPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ResourceRuntimeSpecPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1ResourceRuntimeSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ResourceRuntimeSpecPtrOutput) ToGoogleCloudAiplatformV1beta1ResourceRuntimeSpecPtrOutput() GoogleCloudAiplatformV1beta1ResourceRuntimeSpecPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ResourceRuntimeSpecPtrOutput) ToGoogleCloudAiplatformV1beta1ResourceRuntimeSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ResourceRuntimeSpecPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ResourceRuntimeSpecPtrOutput) Elem() GoogleCloudAiplatformV1beta1ResourceRuntimeSpecOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ResourceRuntimeSpec) GoogleCloudAiplatformV1beta1ResourceRuntimeSpec {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1ResourceRuntimeSpec
		return ret
	}).(GoogleCloudAiplatformV1beta1ResourceRuntimeSpecOutput)
}

// Optional. Ray cluster configuration. Required when creating a dedicated RayCluster on the PersistentResource.
func (o GoogleCloudAiplatformV1beta1ResourceRuntimeSpecPtrOutput) RaySpec() GoogleCloudAiplatformV1beta1RaySpecPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ResourceRuntimeSpec) *GoogleCloudAiplatformV1beta1RaySpec {
		if v == nil {
			return nil
		}
		return v.RaySpec
	}).(GoogleCloudAiplatformV1beta1RaySpecPtrOutput)
}

// Optional. Configure the use of workload identity on the PersistentResource
func (o GoogleCloudAiplatformV1beta1ResourceRuntimeSpecPtrOutput) ServiceAccountSpec() GoogleCloudAiplatformV1beta1ServiceAccountSpecPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ResourceRuntimeSpec) *GoogleCloudAiplatformV1beta1ServiceAccountSpec {
		if v == nil {
			return nil
		}
		return v.ServiceAccountSpec
	}).(GoogleCloudAiplatformV1beta1ServiceAccountSpecPtrOutput)
}

// Configuration for the runtime on a PersistentResource instance, including but not limited to: * Service accounts used to run the workloads. * Whether to make it a dedicated Ray Cluster.
type GoogleCloudAiplatformV1beta1ResourceRuntimeSpecResponse struct {
	// Optional. Ray cluster configuration. Required when creating a dedicated RayCluster on the PersistentResource.
	RaySpec GoogleCloudAiplatformV1beta1RaySpecResponse `pulumi:"raySpec"`
	// Optional. Configure the use of workload identity on the PersistentResource
	ServiceAccountSpec GoogleCloudAiplatformV1beta1ServiceAccountSpecResponse `pulumi:"serviceAccountSpec"`
}

// Configuration for the runtime on a PersistentResource instance, including but not limited to: * Service accounts used to run the workloads. * Whether to make it a dedicated Ray Cluster.
type GoogleCloudAiplatformV1beta1ResourceRuntimeSpecResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ResourceRuntimeSpecResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ResourceRuntimeSpecResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ResourceRuntimeSpecResponseOutput) ToGoogleCloudAiplatformV1beta1ResourceRuntimeSpecResponseOutput() GoogleCloudAiplatformV1beta1ResourceRuntimeSpecResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ResourceRuntimeSpecResponseOutput) ToGoogleCloudAiplatformV1beta1ResourceRuntimeSpecResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ResourceRuntimeSpecResponseOutput {
	return o
}

// Optional. Ray cluster configuration. Required when creating a dedicated RayCluster on the PersistentResource.
func (o GoogleCloudAiplatformV1beta1ResourceRuntimeSpecResponseOutput) RaySpec() GoogleCloudAiplatformV1beta1RaySpecResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ResourceRuntimeSpecResponse) GoogleCloudAiplatformV1beta1RaySpecResponse {
		return v.RaySpec
	}).(GoogleCloudAiplatformV1beta1RaySpecResponseOutput)
}

// Optional. Configure the use of workload identity on the PersistentResource
func (o GoogleCloudAiplatformV1beta1ResourceRuntimeSpecResponseOutput) ServiceAccountSpec() GoogleCloudAiplatformV1beta1ServiceAccountSpecResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ResourceRuntimeSpecResponse) GoogleCloudAiplatformV1beta1ServiceAccountSpecResponse {
		return v.ServiceAccountSpec
	}).(GoogleCloudAiplatformV1beta1ServiceAccountSpecResponseOutput)
}

// Statistics information about resource consumption.
type GoogleCloudAiplatformV1beta1ResourcesConsumedResponse struct {
	// The number of replica hours used. Note that many replicas may run in parallel, and additionally any given work may be queued for some time. Therefore this value is not strictly related to wall time.
	ReplicaHours float64 `pulumi:"replicaHours"`
}

// Statistics information about resource consumption.
type GoogleCloudAiplatformV1beta1ResourcesConsumedResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ResourcesConsumedResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ResourcesConsumedResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ResourcesConsumedResponseOutput) ToGoogleCloudAiplatformV1beta1ResourcesConsumedResponseOutput() GoogleCloudAiplatformV1beta1ResourcesConsumedResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ResourcesConsumedResponseOutput) ToGoogleCloudAiplatformV1beta1ResourcesConsumedResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ResourcesConsumedResponseOutput {
	return o
}

// The number of replica hours used. Note that many replicas may run in parallel, and additionally any given work may be queued for some time. Therefore this value is not strictly related to wall time.
func (o GoogleCloudAiplatformV1beta1ResourcesConsumedResponseOutput) ReplicaHours() pulumi.Float64Output {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ResourcesConsumedResponse) float64 { return v.ReplicaHours }).(pulumi.Float64Output)
}

// Active learning data sampling config. For every active learning labeling iteration, it will select a batch of data based on the sampling strategy.
type GoogleCloudAiplatformV1beta1SampleConfig struct {
	// The percentage of data needed to be labeled in each following batch (except the first batch).
	FollowingBatchSamplePercentage *int `pulumi:"followingBatchSamplePercentage"`
	// The percentage of data needed to be labeled in the first batch.
	InitialBatchSamplePercentage *int `pulumi:"initialBatchSamplePercentage"`
	// Field to choose sampling strategy. Sampling strategy will decide which data should be selected for human labeling in every batch.
	SampleStrategy *GoogleCloudAiplatformV1beta1SampleConfigSampleStrategy `pulumi:"sampleStrategy"`
}

// GoogleCloudAiplatformV1beta1SampleConfigInput is an input type that accepts GoogleCloudAiplatformV1beta1SampleConfigArgs and GoogleCloudAiplatformV1beta1SampleConfigOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1SampleConfigInput` via:
//
//	GoogleCloudAiplatformV1beta1SampleConfigArgs{...}
type GoogleCloudAiplatformV1beta1SampleConfigInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1SampleConfigOutput() GoogleCloudAiplatformV1beta1SampleConfigOutput
	ToGoogleCloudAiplatformV1beta1SampleConfigOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1SampleConfigOutput
}

// Active learning data sampling config. For every active learning labeling iteration, it will select a batch of data based on the sampling strategy.
type GoogleCloudAiplatformV1beta1SampleConfigArgs struct {
	// The percentage of data needed to be labeled in each following batch (except the first batch).
	FollowingBatchSamplePercentage pulumi.IntPtrInput `pulumi:"followingBatchSamplePercentage"`
	// The percentage of data needed to be labeled in the first batch.
	InitialBatchSamplePercentage pulumi.IntPtrInput `pulumi:"initialBatchSamplePercentage"`
	// Field to choose sampling strategy. Sampling strategy will decide which data should be selected for human labeling in every batch.
	SampleStrategy GoogleCloudAiplatformV1beta1SampleConfigSampleStrategyPtrInput `pulumi:"sampleStrategy"`
}

func (GoogleCloudAiplatformV1beta1SampleConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1SampleConfig)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1SampleConfigArgs) ToGoogleCloudAiplatformV1beta1SampleConfigOutput() GoogleCloudAiplatformV1beta1SampleConfigOutput {
	return i.ToGoogleCloudAiplatformV1beta1SampleConfigOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1SampleConfigArgs) ToGoogleCloudAiplatformV1beta1SampleConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1SampleConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1SampleConfigOutput)
}

func (i GoogleCloudAiplatformV1beta1SampleConfigArgs) ToGoogleCloudAiplatformV1beta1SampleConfigPtrOutput() GoogleCloudAiplatformV1beta1SampleConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1SampleConfigPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1SampleConfigArgs) ToGoogleCloudAiplatformV1beta1SampleConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1SampleConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1SampleConfigOutput).ToGoogleCloudAiplatformV1beta1SampleConfigPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1SampleConfigPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1SampleConfigArgs, GoogleCloudAiplatformV1beta1SampleConfigPtr and GoogleCloudAiplatformV1beta1SampleConfigPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1SampleConfigPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1SampleConfigArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1SampleConfigPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1SampleConfigPtrOutput() GoogleCloudAiplatformV1beta1SampleConfigPtrOutput
	ToGoogleCloudAiplatformV1beta1SampleConfigPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1SampleConfigPtrOutput
}

type googleCloudAiplatformV1beta1SampleConfigPtrType GoogleCloudAiplatformV1beta1SampleConfigArgs

func GoogleCloudAiplatformV1beta1SampleConfigPtr(v *GoogleCloudAiplatformV1beta1SampleConfigArgs) GoogleCloudAiplatformV1beta1SampleConfigPtrInput {
	return (*googleCloudAiplatformV1beta1SampleConfigPtrType)(v)
}

func (*googleCloudAiplatformV1beta1SampleConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1SampleConfig)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1SampleConfigPtrType) ToGoogleCloudAiplatformV1beta1SampleConfigPtrOutput() GoogleCloudAiplatformV1beta1SampleConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1SampleConfigPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1SampleConfigPtrType) ToGoogleCloudAiplatformV1beta1SampleConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1SampleConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1SampleConfigPtrOutput)
}

// Active learning data sampling config. For every active learning labeling iteration, it will select a batch of data based on the sampling strategy.
type GoogleCloudAiplatformV1beta1SampleConfigOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1SampleConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1SampleConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1SampleConfigOutput) ToGoogleCloudAiplatformV1beta1SampleConfigOutput() GoogleCloudAiplatformV1beta1SampleConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1SampleConfigOutput) ToGoogleCloudAiplatformV1beta1SampleConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1SampleConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1SampleConfigOutput) ToGoogleCloudAiplatformV1beta1SampleConfigPtrOutput() GoogleCloudAiplatformV1beta1SampleConfigPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1SampleConfigPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1SampleConfigOutput) ToGoogleCloudAiplatformV1beta1SampleConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1SampleConfigPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1SampleConfig) *GoogleCloudAiplatformV1beta1SampleConfig {
		return &v
	}).(GoogleCloudAiplatformV1beta1SampleConfigPtrOutput)
}

// The percentage of data needed to be labeled in each following batch (except the first batch).
func (o GoogleCloudAiplatformV1beta1SampleConfigOutput) FollowingBatchSamplePercentage() pulumi.IntPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1SampleConfig) *int { return v.FollowingBatchSamplePercentage }).(pulumi.IntPtrOutput)
}

// The percentage of data needed to be labeled in the first batch.
func (o GoogleCloudAiplatformV1beta1SampleConfigOutput) InitialBatchSamplePercentage() pulumi.IntPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1SampleConfig) *int { return v.InitialBatchSamplePercentage }).(pulumi.IntPtrOutput)
}

// Field to choose sampling strategy. Sampling strategy will decide which data should be selected for human labeling in every batch.
func (o GoogleCloudAiplatformV1beta1SampleConfigOutput) SampleStrategy() GoogleCloudAiplatformV1beta1SampleConfigSampleStrategyPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1SampleConfig) *GoogleCloudAiplatformV1beta1SampleConfigSampleStrategy {
		return v.SampleStrategy
	}).(GoogleCloudAiplatformV1beta1SampleConfigSampleStrategyPtrOutput)
}

type GoogleCloudAiplatformV1beta1SampleConfigPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1SampleConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1SampleConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1SampleConfigPtrOutput) ToGoogleCloudAiplatformV1beta1SampleConfigPtrOutput() GoogleCloudAiplatformV1beta1SampleConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1SampleConfigPtrOutput) ToGoogleCloudAiplatformV1beta1SampleConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1SampleConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1SampleConfigPtrOutput) Elem() GoogleCloudAiplatformV1beta1SampleConfigOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1SampleConfig) GoogleCloudAiplatformV1beta1SampleConfig {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1SampleConfig
		return ret
	}).(GoogleCloudAiplatformV1beta1SampleConfigOutput)
}

// The percentage of data needed to be labeled in each following batch (except the first batch).
func (o GoogleCloudAiplatformV1beta1SampleConfigPtrOutput) FollowingBatchSamplePercentage() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1SampleConfig) *int {
		if v == nil {
			return nil
		}
		return v.FollowingBatchSamplePercentage
	}).(pulumi.IntPtrOutput)
}

// The percentage of data needed to be labeled in the first batch.
func (o GoogleCloudAiplatformV1beta1SampleConfigPtrOutput) InitialBatchSamplePercentage() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1SampleConfig) *int {
		if v == nil {
			return nil
		}
		return v.InitialBatchSamplePercentage
	}).(pulumi.IntPtrOutput)
}

// Field to choose sampling strategy. Sampling strategy will decide which data should be selected for human labeling in every batch.
func (o GoogleCloudAiplatformV1beta1SampleConfigPtrOutput) SampleStrategy() GoogleCloudAiplatformV1beta1SampleConfigSampleStrategyPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1SampleConfig) *GoogleCloudAiplatformV1beta1SampleConfigSampleStrategy {
		if v == nil {
			return nil
		}
		return v.SampleStrategy
	}).(GoogleCloudAiplatformV1beta1SampleConfigSampleStrategyPtrOutput)
}

// Active learning data sampling config. For every active learning labeling iteration, it will select a batch of data based on the sampling strategy.
type GoogleCloudAiplatformV1beta1SampleConfigResponse struct {
	// The percentage of data needed to be labeled in each following batch (except the first batch).
	FollowingBatchSamplePercentage int `pulumi:"followingBatchSamplePercentage"`
	// The percentage of data needed to be labeled in the first batch.
	InitialBatchSamplePercentage int `pulumi:"initialBatchSamplePercentage"`
	// Field to choose sampling strategy. Sampling strategy will decide which data should be selected for human labeling in every batch.
	SampleStrategy string `pulumi:"sampleStrategy"`
}

// Active learning data sampling config. For every active learning labeling iteration, it will select a batch of data based on the sampling strategy.
type GoogleCloudAiplatformV1beta1SampleConfigResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1SampleConfigResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1SampleConfigResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1SampleConfigResponseOutput) ToGoogleCloudAiplatformV1beta1SampleConfigResponseOutput() GoogleCloudAiplatformV1beta1SampleConfigResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1SampleConfigResponseOutput) ToGoogleCloudAiplatformV1beta1SampleConfigResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1SampleConfigResponseOutput {
	return o
}

// The percentage of data needed to be labeled in each following batch (except the first batch).
func (o GoogleCloudAiplatformV1beta1SampleConfigResponseOutput) FollowingBatchSamplePercentage() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1SampleConfigResponse) int { return v.FollowingBatchSamplePercentage }).(pulumi.IntOutput)
}

// The percentage of data needed to be labeled in the first batch.
func (o GoogleCloudAiplatformV1beta1SampleConfigResponseOutput) InitialBatchSamplePercentage() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1SampleConfigResponse) int { return v.InitialBatchSamplePercentage }).(pulumi.IntOutput)
}

// Field to choose sampling strategy. Sampling strategy will decide which data should be selected for human labeling in every batch.
func (o GoogleCloudAiplatformV1beta1SampleConfigResponseOutput) SampleStrategy() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1SampleConfigResponse) string { return v.SampleStrategy }).(pulumi.StringOutput)
}

// An attribution method that approximates Shapley values for features that contribute to the label being predicted. A sampling strategy is used to approximate the value rather than considering all subsets of features.
type GoogleCloudAiplatformV1beta1SampledShapleyAttribution struct {
	// The number of feature permutations to consider when approximating the Shapley values. Valid range of its value is [1, 50], inclusively.
	PathCount int `pulumi:"pathCount"`
}

// GoogleCloudAiplatformV1beta1SampledShapleyAttributionInput is an input type that accepts GoogleCloudAiplatformV1beta1SampledShapleyAttributionArgs and GoogleCloudAiplatformV1beta1SampledShapleyAttributionOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1SampledShapleyAttributionInput` via:
//
//	GoogleCloudAiplatformV1beta1SampledShapleyAttributionArgs{...}
type GoogleCloudAiplatformV1beta1SampledShapleyAttributionInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1SampledShapleyAttributionOutput() GoogleCloudAiplatformV1beta1SampledShapleyAttributionOutput
	ToGoogleCloudAiplatformV1beta1SampledShapleyAttributionOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1SampledShapleyAttributionOutput
}

// An attribution method that approximates Shapley values for features that contribute to the label being predicted. A sampling strategy is used to approximate the value rather than considering all subsets of features.
type GoogleCloudAiplatformV1beta1SampledShapleyAttributionArgs struct {
	// The number of feature permutations to consider when approximating the Shapley values. Valid range of its value is [1, 50], inclusively.
	PathCount pulumi.IntInput `pulumi:"pathCount"`
}

func (GoogleCloudAiplatformV1beta1SampledShapleyAttributionArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1SampledShapleyAttribution)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1SampledShapleyAttributionArgs) ToGoogleCloudAiplatformV1beta1SampledShapleyAttributionOutput() GoogleCloudAiplatformV1beta1SampledShapleyAttributionOutput {
	return i.ToGoogleCloudAiplatformV1beta1SampledShapleyAttributionOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1SampledShapleyAttributionArgs) ToGoogleCloudAiplatformV1beta1SampledShapleyAttributionOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1SampledShapleyAttributionOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1SampledShapleyAttributionOutput)
}

func (i GoogleCloudAiplatformV1beta1SampledShapleyAttributionArgs) ToGoogleCloudAiplatformV1beta1SampledShapleyAttributionPtrOutput() GoogleCloudAiplatformV1beta1SampledShapleyAttributionPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1SampledShapleyAttributionPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1SampledShapleyAttributionArgs) ToGoogleCloudAiplatformV1beta1SampledShapleyAttributionPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1SampledShapleyAttributionPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1SampledShapleyAttributionOutput).ToGoogleCloudAiplatformV1beta1SampledShapleyAttributionPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1SampledShapleyAttributionPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1SampledShapleyAttributionArgs, GoogleCloudAiplatformV1beta1SampledShapleyAttributionPtr and GoogleCloudAiplatformV1beta1SampledShapleyAttributionPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1SampledShapleyAttributionPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1SampledShapleyAttributionArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1SampledShapleyAttributionPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1SampledShapleyAttributionPtrOutput() GoogleCloudAiplatformV1beta1SampledShapleyAttributionPtrOutput
	ToGoogleCloudAiplatformV1beta1SampledShapleyAttributionPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1SampledShapleyAttributionPtrOutput
}

type googleCloudAiplatformV1beta1SampledShapleyAttributionPtrType GoogleCloudAiplatformV1beta1SampledShapleyAttributionArgs

func GoogleCloudAiplatformV1beta1SampledShapleyAttributionPtr(v *GoogleCloudAiplatformV1beta1SampledShapleyAttributionArgs) GoogleCloudAiplatformV1beta1SampledShapleyAttributionPtrInput {
	return (*googleCloudAiplatformV1beta1SampledShapleyAttributionPtrType)(v)
}

func (*googleCloudAiplatformV1beta1SampledShapleyAttributionPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1SampledShapleyAttribution)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1SampledShapleyAttributionPtrType) ToGoogleCloudAiplatformV1beta1SampledShapleyAttributionPtrOutput() GoogleCloudAiplatformV1beta1SampledShapleyAttributionPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1SampledShapleyAttributionPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1SampledShapleyAttributionPtrType) ToGoogleCloudAiplatformV1beta1SampledShapleyAttributionPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1SampledShapleyAttributionPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1SampledShapleyAttributionPtrOutput)
}

// An attribution method that approximates Shapley values for features that contribute to the label being predicted. A sampling strategy is used to approximate the value rather than considering all subsets of features.
type GoogleCloudAiplatformV1beta1SampledShapleyAttributionOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1SampledShapleyAttributionOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1SampledShapleyAttribution)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1SampledShapleyAttributionOutput) ToGoogleCloudAiplatformV1beta1SampledShapleyAttributionOutput() GoogleCloudAiplatformV1beta1SampledShapleyAttributionOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1SampledShapleyAttributionOutput) ToGoogleCloudAiplatformV1beta1SampledShapleyAttributionOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1SampledShapleyAttributionOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1SampledShapleyAttributionOutput) ToGoogleCloudAiplatformV1beta1SampledShapleyAttributionPtrOutput() GoogleCloudAiplatformV1beta1SampledShapleyAttributionPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1SampledShapleyAttributionPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1SampledShapleyAttributionOutput) ToGoogleCloudAiplatformV1beta1SampledShapleyAttributionPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1SampledShapleyAttributionPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1SampledShapleyAttribution) *GoogleCloudAiplatformV1beta1SampledShapleyAttribution {
		return &v
	}).(GoogleCloudAiplatformV1beta1SampledShapleyAttributionPtrOutput)
}

// The number of feature permutations to consider when approximating the Shapley values. Valid range of its value is [1, 50], inclusively.
func (o GoogleCloudAiplatformV1beta1SampledShapleyAttributionOutput) PathCount() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1SampledShapleyAttribution) int { return v.PathCount }).(pulumi.IntOutput)
}

type GoogleCloudAiplatformV1beta1SampledShapleyAttributionPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1SampledShapleyAttributionPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1SampledShapleyAttribution)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1SampledShapleyAttributionPtrOutput) ToGoogleCloudAiplatformV1beta1SampledShapleyAttributionPtrOutput() GoogleCloudAiplatformV1beta1SampledShapleyAttributionPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1SampledShapleyAttributionPtrOutput) ToGoogleCloudAiplatformV1beta1SampledShapleyAttributionPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1SampledShapleyAttributionPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1SampledShapleyAttributionPtrOutput) Elem() GoogleCloudAiplatformV1beta1SampledShapleyAttributionOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1SampledShapleyAttribution) GoogleCloudAiplatformV1beta1SampledShapleyAttribution {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1SampledShapleyAttribution
		return ret
	}).(GoogleCloudAiplatformV1beta1SampledShapleyAttributionOutput)
}

// The number of feature permutations to consider when approximating the Shapley values. Valid range of its value is [1, 50], inclusively.
func (o GoogleCloudAiplatformV1beta1SampledShapleyAttributionPtrOutput) PathCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1SampledShapleyAttribution) *int {
		if v == nil {
			return nil
		}
		return &v.PathCount
	}).(pulumi.IntPtrOutput)
}

// An attribution method that approximates Shapley values for features that contribute to the label being predicted. A sampling strategy is used to approximate the value rather than considering all subsets of features.
type GoogleCloudAiplatformV1beta1SampledShapleyAttributionResponse struct {
	// The number of feature permutations to consider when approximating the Shapley values. Valid range of its value is [1, 50], inclusively.
	PathCount int `pulumi:"pathCount"`
}

// An attribution method that approximates Shapley values for features that contribute to the label being predicted. A sampling strategy is used to approximate the value rather than considering all subsets of features.
type GoogleCloudAiplatformV1beta1SampledShapleyAttributionResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1SampledShapleyAttributionResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1SampledShapleyAttributionResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1SampledShapleyAttributionResponseOutput) ToGoogleCloudAiplatformV1beta1SampledShapleyAttributionResponseOutput() GoogleCloudAiplatformV1beta1SampledShapleyAttributionResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1SampledShapleyAttributionResponseOutput) ToGoogleCloudAiplatformV1beta1SampledShapleyAttributionResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1SampledShapleyAttributionResponseOutput {
	return o
}

// The number of feature permutations to consider when approximating the Shapley values. Valid range of its value is [1, 50], inclusively.
func (o GoogleCloudAiplatformV1beta1SampledShapleyAttributionResponseOutput) PathCount() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1SampledShapleyAttributionResponse) int { return v.PathCount }).(pulumi.IntOutput)
}

// Sampling Strategy for logging, can be for both training and prediction dataset.
type GoogleCloudAiplatformV1beta1SamplingStrategy struct {
	// Random sample config. Will support more sampling strategies later.
	RandomSampleConfig *GoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfig `pulumi:"randomSampleConfig"`
}

// GoogleCloudAiplatformV1beta1SamplingStrategyInput is an input type that accepts GoogleCloudAiplatformV1beta1SamplingStrategyArgs and GoogleCloudAiplatformV1beta1SamplingStrategyOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1SamplingStrategyInput` via:
//
//	GoogleCloudAiplatformV1beta1SamplingStrategyArgs{...}
type GoogleCloudAiplatformV1beta1SamplingStrategyInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1SamplingStrategyOutput() GoogleCloudAiplatformV1beta1SamplingStrategyOutput
	ToGoogleCloudAiplatformV1beta1SamplingStrategyOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1SamplingStrategyOutput
}

// Sampling Strategy for logging, can be for both training and prediction dataset.
type GoogleCloudAiplatformV1beta1SamplingStrategyArgs struct {
	// Random sample config. Will support more sampling strategies later.
	RandomSampleConfig GoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigPtrInput `pulumi:"randomSampleConfig"`
}

func (GoogleCloudAiplatformV1beta1SamplingStrategyArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1SamplingStrategy)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1SamplingStrategyArgs) ToGoogleCloudAiplatformV1beta1SamplingStrategyOutput() GoogleCloudAiplatformV1beta1SamplingStrategyOutput {
	return i.ToGoogleCloudAiplatformV1beta1SamplingStrategyOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1SamplingStrategyArgs) ToGoogleCloudAiplatformV1beta1SamplingStrategyOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1SamplingStrategyOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1SamplingStrategyOutput)
}

func (i GoogleCloudAiplatformV1beta1SamplingStrategyArgs) ToGoogleCloudAiplatformV1beta1SamplingStrategyPtrOutput() GoogleCloudAiplatformV1beta1SamplingStrategyPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1SamplingStrategyPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1SamplingStrategyArgs) ToGoogleCloudAiplatformV1beta1SamplingStrategyPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1SamplingStrategyPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1SamplingStrategyOutput).ToGoogleCloudAiplatformV1beta1SamplingStrategyPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1SamplingStrategyPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1SamplingStrategyArgs, GoogleCloudAiplatformV1beta1SamplingStrategyPtr and GoogleCloudAiplatformV1beta1SamplingStrategyPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1SamplingStrategyPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1SamplingStrategyArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1SamplingStrategyPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1SamplingStrategyPtrOutput() GoogleCloudAiplatformV1beta1SamplingStrategyPtrOutput
	ToGoogleCloudAiplatformV1beta1SamplingStrategyPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1SamplingStrategyPtrOutput
}

type googleCloudAiplatformV1beta1SamplingStrategyPtrType GoogleCloudAiplatformV1beta1SamplingStrategyArgs

func GoogleCloudAiplatformV1beta1SamplingStrategyPtr(v *GoogleCloudAiplatformV1beta1SamplingStrategyArgs) GoogleCloudAiplatformV1beta1SamplingStrategyPtrInput {
	return (*googleCloudAiplatformV1beta1SamplingStrategyPtrType)(v)
}

func (*googleCloudAiplatformV1beta1SamplingStrategyPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1SamplingStrategy)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1SamplingStrategyPtrType) ToGoogleCloudAiplatformV1beta1SamplingStrategyPtrOutput() GoogleCloudAiplatformV1beta1SamplingStrategyPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1SamplingStrategyPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1SamplingStrategyPtrType) ToGoogleCloudAiplatformV1beta1SamplingStrategyPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1SamplingStrategyPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1SamplingStrategyPtrOutput)
}

// Sampling Strategy for logging, can be for both training and prediction dataset.
type GoogleCloudAiplatformV1beta1SamplingStrategyOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1SamplingStrategyOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1SamplingStrategy)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1SamplingStrategyOutput) ToGoogleCloudAiplatformV1beta1SamplingStrategyOutput() GoogleCloudAiplatformV1beta1SamplingStrategyOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1SamplingStrategyOutput) ToGoogleCloudAiplatformV1beta1SamplingStrategyOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1SamplingStrategyOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1SamplingStrategyOutput) ToGoogleCloudAiplatformV1beta1SamplingStrategyPtrOutput() GoogleCloudAiplatformV1beta1SamplingStrategyPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1SamplingStrategyPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1SamplingStrategyOutput) ToGoogleCloudAiplatformV1beta1SamplingStrategyPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1SamplingStrategyPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1SamplingStrategy) *GoogleCloudAiplatformV1beta1SamplingStrategy {
		return &v
	}).(GoogleCloudAiplatformV1beta1SamplingStrategyPtrOutput)
}

// Random sample config. Will support more sampling strategies later.
func (o GoogleCloudAiplatformV1beta1SamplingStrategyOutput) RandomSampleConfig() GoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1SamplingStrategy) *GoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfig {
		return v.RandomSampleConfig
	}).(GoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigPtrOutput)
}

type GoogleCloudAiplatformV1beta1SamplingStrategyPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1SamplingStrategyPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1SamplingStrategy)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1SamplingStrategyPtrOutput) ToGoogleCloudAiplatformV1beta1SamplingStrategyPtrOutput() GoogleCloudAiplatformV1beta1SamplingStrategyPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1SamplingStrategyPtrOutput) ToGoogleCloudAiplatformV1beta1SamplingStrategyPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1SamplingStrategyPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1SamplingStrategyPtrOutput) Elem() GoogleCloudAiplatformV1beta1SamplingStrategyOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1SamplingStrategy) GoogleCloudAiplatformV1beta1SamplingStrategy {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1SamplingStrategy
		return ret
	}).(GoogleCloudAiplatformV1beta1SamplingStrategyOutput)
}

// Random sample config. Will support more sampling strategies later.
func (o GoogleCloudAiplatformV1beta1SamplingStrategyPtrOutput) RandomSampleConfig() GoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1SamplingStrategy) *GoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfig {
		if v == nil {
			return nil
		}
		return v.RandomSampleConfig
	}).(GoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigPtrOutput)
}

// Requests are randomly selected.
type GoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfig struct {
	// Sample rate (0, 1]
	SampleRate *float64 `pulumi:"sampleRate"`
}

// GoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigInput is an input type that accepts GoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigArgs and GoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigInput` via:
//
//	GoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigArgs{...}
type GoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigOutput() GoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigOutput
	ToGoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigOutput
}

// Requests are randomly selected.
type GoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigArgs struct {
	// Sample rate (0, 1]
	SampleRate pulumi.Float64PtrInput `pulumi:"sampleRate"`
}

func (GoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfig)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigArgs) ToGoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigOutput() GoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigOutput {
	return i.ToGoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigArgs) ToGoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigOutput)
}

func (i GoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigArgs) ToGoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigPtrOutput() GoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigArgs) ToGoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigOutput).ToGoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigArgs, GoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigPtr and GoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigPtrOutput() GoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigPtrOutput
	ToGoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigPtrOutput
}

type googleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigPtrType GoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigArgs

func GoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigPtr(v *GoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigArgs) GoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigPtrInput {
	return (*googleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigPtrType)(v)
}

func (*googleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfig)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigPtrType) ToGoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigPtrOutput() GoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigPtrType) ToGoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigPtrOutput)
}

// Requests are randomly selected.
type GoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigOutput) ToGoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigOutput() GoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigOutput) ToGoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigOutput) ToGoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigPtrOutput() GoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigOutput) ToGoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfig) *GoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfig {
		return &v
	}).(GoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigPtrOutput)
}

// Sample rate (0, 1]
func (o GoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigOutput) SampleRate() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfig) *float64 { return v.SampleRate }).(pulumi.Float64PtrOutput)
}

type GoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigPtrOutput) ToGoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigPtrOutput() GoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigPtrOutput) ToGoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigPtrOutput) Elem() GoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfig) GoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfig {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfig
		return ret
	}).(GoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigOutput)
}

// Sample rate (0, 1]
func (o GoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigPtrOutput) SampleRate() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfig) *float64 {
		if v == nil {
			return nil
		}
		return v.SampleRate
	}).(pulumi.Float64PtrOutput)
}

// Requests are randomly selected.
type GoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigResponse struct {
	// Sample rate (0, 1]
	SampleRate float64 `pulumi:"sampleRate"`
}

// Requests are randomly selected.
type GoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigResponseOutput) ToGoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigResponseOutput() GoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigResponseOutput) ToGoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigResponseOutput {
	return o
}

// Sample rate (0, 1]
func (o GoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigResponseOutput) SampleRate() pulumi.Float64Output {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigResponse) float64 {
		return v.SampleRate
	}).(pulumi.Float64Output)
}

// Sampling Strategy for logging, can be for both training and prediction dataset.
type GoogleCloudAiplatformV1beta1SamplingStrategyResponse struct {
	// Random sample config. Will support more sampling strategies later.
	RandomSampleConfig GoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigResponse `pulumi:"randomSampleConfig"`
}

// Sampling Strategy for logging, can be for both training and prediction dataset.
type GoogleCloudAiplatformV1beta1SamplingStrategyResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1SamplingStrategyResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1SamplingStrategyResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1SamplingStrategyResponseOutput) ToGoogleCloudAiplatformV1beta1SamplingStrategyResponseOutput() GoogleCloudAiplatformV1beta1SamplingStrategyResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1SamplingStrategyResponseOutput) ToGoogleCloudAiplatformV1beta1SamplingStrategyResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1SamplingStrategyResponseOutput {
	return o
}

// Random sample config. Will support more sampling strategies later.
func (o GoogleCloudAiplatformV1beta1SamplingStrategyResponseOutput) RandomSampleConfig() GoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1SamplingStrategyResponse) GoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigResponse {
		return v.RandomSampleConfig
	}).(GoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigResponseOutput)
}

// A SavedQuery is a view of the dataset. It references a subset of annotations by problem type and filters.
type GoogleCloudAiplatformV1beta1SavedQuery struct {
	// The user-defined name of the SavedQuery. The name can be up to 128 characters long and can consist of any UTF-8 characters.
	DisplayName string `pulumi:"displayName"`
	// Used to perform a consistent read-modify-write update. If not set, a blind "overwrite" update happens.
	Etag *string `pulumi:"etag"`
	// Some additional information about the SavedQuery.
	Metadata interface{} `pulumi:"metadata"`
	// Problem type of the SavedQuery. Allowed values: * IMAGE_CLASSIFICATION_SINGLE_LABEL * IMAGE_CLASSIFICATION_MULTI_LABEL * IMAGE_BOUNDING_POLY * IMAGE_BOUNDING_BOX * TEXT_CLASSIFICATION_SINGLE_LABEL * TEXT_CLASSIFICATION_MULTI_LABEL * TEXT_EXTRACTION * TEXT_SENTIMENT * VIDEO_CLASSIFICATION * VIDEO_OBJECT_TRACKING
	ProblemType string `pulumi:"problemType"`
}

// GoogleCloudAiplatformV1beta1SavedQueryInput is an input type that accepts GoogleCloudAiplatformV1beta1SavedQueryArgs and GoogleCloudAiplatformV1beta1SavedQueryOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1SavedQueryInput` via:
//
//	GoogleCloudAiplatformV1beta1SavedQueryArgs{...}
type GoogleCloudAiplatformV1beta1SavedQueryInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1SavedQueryOutput() GoogleCloudAiplatformV1beta1SavedQueryOutput
	ToGoogleCloudAiplatformV1beta1SavedQueryOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1SavedQueryOutput
}

// A SavedQuery is a view of the dataset. It references a subset of annotations by problem type and filters.
type GoogleCloudAiplatformV1beta1SavedQueryArgs struct {
	// The user-defined name of the SavedQuery. The name can be up to 128 characters long and can consist of any UTF-8 characters.
	DisplayName pulumi.StringInput `pulumi:"displayName"`
	// Used to perform a consistent read-modify-write update. If not set, a blind "overwrite" update happens.
	Etag pulumi.StringPtrInput `pulumi:"etag"`
	// Some additional information about the SavedQuery.
	Metadata pulumi.Input `pulumi:"metadata"`
	// Problem type of the SavedQuery. Allowed values: * IMAGE_CLASSIFICATION_SINGLE_LABEL * IMAGE_CLASSIFICATION_MULTI_LABEL * IMAGE_BOUNDING_POLY * IMAGE_BOUNDING_BOX * TEXT_CLASSIFICATION_SINGLE_LABEL * TEXT_CLASSIFICATION_MULTI_LABEL * TEXT_EXTRACTION * TEXT_SENTIMENT * VIDEO_CLASSIFICATION * VIDEO_OBJECT_TRACKING
	ProblemType pulumi.StringInput `pulumi:"problemType"`
}

func (GoogleCloudAiplatformV1beta1SavedQueryArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1SavedQuery)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1SavedQueryArgs) ToGoogleCloudAiplatformV1beta1SavedQueryOutput() GoogleCloudAiplatformV1beta1SavedQueryOutput {
	return i.ToGoogleCloudAiplatformV1beta1SavedQueryOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1SavedQueryArgs) ToGoogleCloudAiplatformV1beta1SavedQueryOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1SavedQueryOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1SavedQueryOutput)
}

// GoogleCloudAiplatformV1beta1SavedQueryArrayInput is an input type that accepts GoogleCloudAiplatformV1beta1SavedQueryArray and GoogleCloudAiplatformV1beta1SavedQueryArrayOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1SavedQueryArrayInput` via:
//
//	GoogleCloudAiplatformV1beta1SavedQueryArray{ GoogleCloudAiplatformV1beta1SavedQueryArgs{...} }
type GoogleCloudAiplatformV1beta1SavedQueryArrayInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1SavedQueryArrayOutput() GoogleCloudAiplatformV1beta1SavedQueryArrayOutput
	ToGoogleCloudAiplatformV1beta1SavedQueryArrayOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1SavedQueryArrayOutput
}

type GoogleCloudAiplatformV1beta1SavedQueryArray []GoogleCloudAiplatformV1beta1SavedQueryInput

func (GoogleCloudAiplatformV1beta1SavedQueryArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1beta1SavedQuery)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1SavedQueryArray) ToGoogleCloudAiplatformV1beta1SavedQueryArrayOutput() GoogleCloudAiplatformV1beta1SavedQueryArrayOutput {
	return i.ToGoogleCloudAiplatformV1beta1SavedQueryArrayOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1SavedQueryArray) ToGoogleCloudAiplatformV1beta1SavedQueryArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1SavedQueryArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1SavedQueryArrayOutput)
}

// A SavedQuery is a view of the dataset. It references a subset of annotations by problem type and filters.
type GoogleCloudAiplatformV1beta1SavedQueryOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1SavedQueryOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1SavedQuery)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1SavedQueryOutput) ToGoogleCloudAiplatformV1beta1SavedQueryOutput() GoogleCloudAiplatformV1beta1SavedQueryOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1SavedQueryOutput) ToGoogleCloudAiplatformV1beta1SavedQueryOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1SavedQueryOutput {
	return o
}

// The user-defined name of the SavedQuery. The name can be up to 128 characters long and can consist of any UTF-8 characters.
func (o GoogleCloudAiplatformV1beta1SavedQueryOutput) DisplayName() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1SavedQuery) string { return v.DisplayName }).(pulumi.StringOutput)
}

// Used to perform a consistent read-modify-write update. If not set, a blind "overwrite" update happens.
func (o GoogleCloudAiplatformV1beta1SavedQueryOutput) Etag() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1SavedQuery) *string { return v.Etag }).(pulumi.StringPtrOutput)
}

// Some additional information about the SavedQuery.
func (o GoogleCloudAiplatformV1beta1SavedQueryOutput) Metadata() pulumi.AnyOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1SavedQuery) interface{} { return v.Metadata }).(pulumi.AnyOutput)
}

// Problem type of the SavedQuery. Allowed values: * IMAGE_CLASSIFICATION_SINGLE_LABEL * IMAGE_CLASSIFICATION_MULTI_LABEL * IMAGE_BOUNDING_POLY * IMAGE_BOUNDING_BOX * TEXT_CLASSIFICATION_SINGLE_LABEL * TEXT_CLASSIFICATION_MULTI_LABEL * TEXT_EXTRACTION * TEXT_SENTIMENT * VIDEO_CLASSIFICATION * VIDEO_OBJECT_TRACKING
func (o GoogleCloudAiplatformV1beta1SavedQueryOutput) ProblemType() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1SavedQuery) string { return v.ProblemType }).(pulumi.StringOutput)
}

type GoogleCloudAiplatformV1beta1SavedQueryArrayOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1SavedQueryArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1beta1SavedQuery)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1SavedQueryArrayOutput) ToGoogleCloudAiplatformV1beta1SavedQueryArrayOutput() GoogleCloudAiplatformV1beta1SavedQueryArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1SavedQueryArrayOutput) ToGoogleCloudAiplatformV1beta1SavedQueryArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1SavedQueryArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1SavedQueryArrayOutput) Index(i pulumi.IntInput) GoogleCloudAiplatformV1beta1SavedQueryOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GoogleCloudAiplatformV1beta1SavedQuery {
		return vs[0].([]GoogleCloudAiplatformV1beta1SavedQuery)[vs[1].(int)]
	}).(GoogleCloudAiplatformV1beta1SavedQueryOutput)
}

// A SavedQuery is a view of the dataset. It references a subset of annotations by problem type and filters.
type GoogleCloudAiplatformV1beta1SavedQueryResponse struct {
	// Filters on the Annotations in the dataset.
	AnnotationFilter string `pulumi:"annotationFilter"`
	// Number of AnnotationSpecs in the context of the SavedQuery.
	AnnotationSpecCount int `pulumi:"annotationSpecCount"`
	// Timestamp when this SavedQuery was created.
	CreateTime string `pulumi:"createTime"`
	// The user-defined name of the SavedQuery. The name can be up to 128 characters long and can consist of any UTF-8 characters.
	DisplayName string `pulumi:"displayName"`
	// Used to perform a consistent read-modify-write update. If not set, a blind "overwrite" update happens.
	Etag string `pulumi:"etag"`
	// Some additional information about the SavedQuery.
	Metadata interface{} `pulumi:"metadata"`
	// Resource name of the SavedQuery.
	Name string `pulumi:"name"`
	// Problem type of the SavedQuery. Allowed values: * IMAGE_CLASSIFICATION_SINGLE_LABEL * IMAGE_CLASSIFICATION_MULTI_LABEL * IMAGE_BOUNDING_POLY * IMAGE_BOUNDING_BOX * TEXT_CLASSIFICATION_SINGLE_LABEL * TEXT_CLASSIFICATION_MULTI_LABEL * TEXT_EXTRACTION * TEXT_SENTIMENT * VIDEO_CLASSIFICATION * VIDEO_OBJECT_TRACKING
	ProblemType string `pulumi:"problemType"`
	// If the Annotations belonging to the SavedQuery can be used for AutoML training.
	SupportAutomlTraining bool `pulumi:"supportAutomlTraining"`
	// Timestamp when SavedQuery was last updated.
	UpdateTime string `pulumi:"updateTime"`
}

// A SavedQuery is a view of the dataset. It references a subset of annotations by problem type and filters.
type GoogleCloudAiplatformV1beta1SavedQueryResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1SavedQueryResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1SavedQueryResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1SavedQueryResponseOutput) ToGoogleCloudAiplatformV1beta1SavedQueryResponseOutput() GoogleCloudAiplatformV1beta1SavedQueryResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1SavedQueryResponseOutput) ToGoogleCloudAiplatformV1beta1SavedQueryResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1SavedQueryResponseOutput {
	return o
}

// Filters on the Annotations in the dataset.
func (o GoogleCloudAiplatformV1beta1SavedQueryResponseOutput) AnnotationFilter() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1SavedQueryResponse) string { return v.AnnotationFilter }).(pulumi.StringOutput)
}

// Number of AnnotationSpecs in the context of the SavedQuery.
func (o GoogleCloudAiplatformV1beta1SavedQueryResponseOutput) AnnotationSpecCount() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1SavedQueryResponse) int { return v.AnnotationSpecCount }).(pulumi.IntOutput)
}

// Timestamp when this SavedQuery was created.
func (o GoogleCloudAiplatformV1beta1SavedQueryResponseOutput) CreateTime() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1SavedQueryResponse) string { return v.CreateTime }).(pulumi.StringOutput)
}

// The user-defined name of the SavedQuery. The name can be up to 128 characters long and can consist of any UTF-8 characters.
func (o GoogleCloudAiplatformV1beta1SavedQueryResponseOutput) DisplayName() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1SavedQueryResponse) string { return v.DisplayName }).(pulumi.StringOutput)
}

// Used to perform a consistent read-modify-write update. If not set, a blind "overwrite" update happens.
func (o GoogleCloudAiplatformV1beta1SavedQueryResponseOutput) Etag() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1SavedQueryResponse) string { return v.Etag }).(pulumi.StringOutput)
}

// Some additional information about the SavedQuery.
func (o GoogleCloudAiplatformV1beta1SavedQueryResponseOutput) Metadata() pulumi.AnyOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1SavedQueryResponse) interface{} { return v.Metadata }).(pulumi.AnyOutput)
}

// Resource name of the SavedQuery.
func (o GoogleCloudAiplatformV1beta1SavedQueryResponseOutput) Name() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1SavedQueryResponse) string { return v.Name }).(pulumi.StringOutput)
}

// Problem type of the SavedQuery. Allowed values: * IMAGE_CLASSIFICATION_SINGLE_LABEL * IMAGE_CLASSIFICATION_MULTI_LABEL * IMAGE_BOUNDING_POLY * IMAGE_BOUNDING_BOX * TEXT_CLASSIFICATION_SINGLE_LABEL * TEXT_CLASSIFICATION_MULTI_LABEL * TEXT_EXTRACTION * TEXT_SENTIMENT * VIDEO_CLASSIFICATION * VIDEO_OBJECT_TRACKING
func (o GoogleCloudAiplatformV1beta1SavedQueryResponseOutput) ProblemType() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1SavedQueryResponse) string { return v.ProblemType }).(pulumi.StringOutput)
}

// If the Annotations belonging to the SavedQuery can be used for AutoML training.
func (o GoogleCloudAiplatformV1beta1SavedQueryResponseOutput) SupportAutomlTraining() pulumi.BoolOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1SavedQueryResponse) bool { return v.SupportAutomlTraining }).(pulumi.BoolOutput)
}

// Timestamp when SavedQuery was last updated.
func (o GoogleCloudAiplatformV1beta1SavedQueryResponseOutput) UpdateTime() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1SavedQueryResponse) string { return v.UpdateTime }).(pulumi.StringOutput)
}

type GoogleCloudAiplatformV1beta1SavedQueryResponseArrayOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1SavedQueryResponseArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1beta1SavedQueryResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1SavedQueryResponseArrayOutput) ToGoogleCloudAiplatformV1beta1SavedQueryResponseArrayOutput() GoogleCloudAiplatformV1beta1SavedQueryResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1SavedQueryResponseArrayOutput) ToGoogleCloudAiplatformV1beta1SavedQueryResponseArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1SavedQueryResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1SavedQueryResponseArrayOutput) Index(i pulumi.IntInput) GoogleCloudAiplatformV1beta1SavedQueryResponseOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GoogleCloudAiplatformV1beta1SavedQueryResponse {
		return vs[0].([]GoogleCloudAiplatformV1beta1SavedQueryResponse)[vs[1].(int)]
	}).(GoogleCloudAiplatformV1beta1SavedQueryResponseOutput)
}

// Status of a scheduled run.
type GoogleCloudAiplatformV1beta1ScheduleRunResponseResponse struct {
	// The response of the scheduled run.
	RunResponse string `pulumi:"runResponse"`
	// The scheduled run time based on the user-specified schedule.
	ScheduledRunTime string `pulumi:"scheduledRunTime"`
}

// Status of a scheduled run.
type GoogleCloudAiplatformV1beta1ScheduleRunResponseResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ScheduleRunResponseResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ScheduleRunResponseResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ScheduleRunResponseResponseOutput) ToGoogleCloudAiplatformV1beta1ScheduleRunResponseResponseOutput() GoogleCloudAiplatformV1beta1ScheduleRunResponseResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ScheduleRunResponseResponseOutput) ToGoogleCloudAiplatformV1beta1ScheduleRunResponseResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ScheduleRunResponseResponseOutput {
	return o
}

// The response of the scheduled run.
func (o GoogleCloudAiplatformV1beta1ScheduleRunResponseResponseOutput) RunResponse() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ScheduleRunResponseResponse) string { return v.RunResponse }).(pulumi.StringOutput)
}

// The scheduled run time based on the user-specified schedule.
func (o GoogleCloudAiplatformV1beta1ScheduleRunResponseResponseOutput) ScheduledRunTime() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ScheduleRunResponseResponse) string { return v.ScheduledRunTime }).(pulumi.StringOutput)
}

// All parameters related to queuing and scheduling of custom jobs.
type GoogleCloudAiplatformV1beta1Scheduling struct {
	// Optional. Indicates if the job should retry for internal errors after the job starts running. If true, overrides `Scheduling.restart_job_on_worker_restart` to false.
	DisableRetries *bool `pulumi:"disableRetries"`
	// Restarts the entire CustomJob if a worker gets restarted. This feature can be used by distributed training jobs that are not resilient to workers leaving and joining a job.
	RestartJobOnWorkerRestart *bool `pulumi:"restartJobOnWorkerRestart"`
	// The maximum job running time. The default is 7 days.
	Timeout *string `pulumi:"timeout"`
}

// GoogleCloudAiplatformV1beta1SchedulingInput is an input type that accepts GoogleCloudAiplatformV1beta1SchedulingArgs and GoogleCloudAiplatformV1beta1SchedulingOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1SchedulingInput` via:
//
//	GoogleCloudAiplatformV1beta1SchedulingArgs{...}
type GoogleCloudAiplatformV1beta1SchedulingInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1SchedulingOutput() GoogleCloudAiplatformV1beta1SchedulingOutput
	ToGoogleCloudAiplatformV1beta1SchedulingOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1SchedulingOutput
}

// All parameters related to queuing and scheduling of custom jobs.
type GoogleCloudAiplatformV1beta1SchedulingArgs struct {
	// Optional. Indicates if the job should retry for internal errors after the job starts running. If true, overrides `Scheduling.restart_job_on_worker_restart` to false.
	DisableRetries pulumi.BoolPtrInput `pulumi:"disableRetries"`
	// Restarts the entire CustomJob if a worker gets restarted. This feature can be used by distributed training jobs that are not resilient to workers leaving and joining a job.
	RestartJobOnWorkerRestart pulumi.BoolPtrInput `pulumi:"restartJobOnWorkerRestart"`
	// The maximum job running time. The default is 7 days.
	Timeout pulumi.StringPtrInput `pulumi:"timeout"`
}

func (GoogleCloudAiplatformV1beta1SchedulingArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1Scheduling)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1SchedulingArgs) ToGoogleCloudAiplatformV1beta1SchedulingOutput() GoogleCloudAiplatformV1beta1SchedulingOutput {
	return i.ToGoogleCloudAiplatformV1beta1SchedulingOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1SchedulingArgs) ToGoogleCloudAiplatformV1beta1SchedulingOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1SchedulingOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1SchedulingOutput)
}

func (i GoogleCloudAiplatformV1beta1SchedulingArgs) ToGoogleCloudAiplatformV1beta1SchedulingPtrOutput() GoogleCloudAiplatformV1beta1SchedulingPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1SchedulingPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1SchedulingArgs) ToGoogleCloudAiplatformV1beta1SchedulingPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1SchedulingPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1SchedulingOutput).ToGoogleCloudAiplatformV1beta1SchedulingPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1SchedulingPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1SchedulingArgs, GoogleCloudAiplatformV1beta1SchedulingPtr and GoogleCloudAiplatformV1beta1SchedulingPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1SchedulingPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1SchedulingArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1SchedulingPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1SchedulingPtrOutput() GoogleCloudAiplatformV1beta1SchedulingPtrOutput
	ToGoogleCloudAiplatformV1beta1SchedulingPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1SchedulingPtrOutput
}

type googleCloudAiplatformV1beta1SchedulingPtrType GoogleCloudAiplatformV1beta1SchedulingArgs

func GoogleCloudAiplatformV1beta1SchedulingPtr(v *GoogleCloudAiplatformV1beta1SchedulingArgs) GoogleCloudAiplatformV1beta1SchedulingPtrInput {
	return (*googleCloudAiplatformV1beta1SchedulingPtrType)(v)
}

func (*googleCloudAiplatformV1beta1SchedulingPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1Scheduling)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1SchedulingPtrType) ToGoogleCloudAiplatformV1beta1SchedulingPtrOutput() GoogleCloudAiplatformV1beta1SchedulingPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1SchedulingPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1SchedulingPtrType) ToGoogleCloudAiplatformV1beta1SchedulingPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1SchedulingPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1SchedulingPtrOutput)
}

// All parameters related to queuing and scheduling of custom jobs.
type GoogleCloudAiplatformV1beta1SchedulingOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1SchedulingOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1Scheduling)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1SchedulingOutput) ToGoogleCloudAiplatformV1beta1SchedulingOutput() GoogleCloudAiplatformV1beta1SchedulingOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1SchedulingOutput) ToGoogleCloudAiplatformV1beta1SchedulingOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1SchedulingOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1SchedulingOutput) ToGoogleCloudAiplatformV1beta1SchedulingPtrOutput() GoogleCloudAiplatformV1beta1SchedulingPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1SchedulingPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1SchedulingOutput) ToGoogleCloudAiplatformV1beta1SchedulingPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1SchedulingPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1Scheduling) *GoogleCloudAiplatformV1beta1Scheduling {
		return &v
	}).(GoogleCloudAiplatformV1beta1SchedulingPtrOutput)
}

// Optional. Indicates if the job should retry for internal errors after the job starts running. If true, overrides `Scheduling.restart_job_on_worker_restart` to false.
func (o GoogleCloudAiplatformV1beta1SchedulingOutput) DisableRetries() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1Scheduling) *bool { return v.DisableRetries }).(pulumi.BoolPtrOutput)
}

// Restarts the entire CustomJob if a worker gets restarted. This feature can be used by distributed training jobs that are not resilient to workers leaving and joining a job.
func (o GoogleCloudAiplatformV1beta1SchedulingOutput) RestartJobOnWorkerRestart() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1Scheduling) *bool { return v.RestartJobOnWorkerRestart }).(pulumi.BoolPtrOutput)
}

// The maximum job running time. The default is 7 days.
func (o GoogleCloudAiplatformV1beta1SchedulingOutput) Timeout() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1Scheduling) *string { return v.Timeout }).(pulumi.StringPtrOutput)
}

type GoogleCloudAiplatformV1beta1SchedulingPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1SchedulingPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1Scheduling)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1SchedulingPtrOutput) ToGoogleCloudAiplatformV1beta1SchedulingPtrOutput() GoogleCloudAiplatformV1beta1SchedulingPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1SchedulingPtrOutput) ToGoogleCloudAiplatformV1beta1SchedulingPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1SchedulingPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1SchedulingPtrOutput) Elem() GoogleCloudAiplatformV1beta1SchedulingOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1Scheduling) GoogleCloudAiplatformV1beta1Scheduling {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1Scheduling
		return ret
	}).(GoogleCloudAiplatformV1beta1SchedulingOutput)
}

// Optional. Indicates if the job should retry for internal errors after the job starts running. If true, overrides `Scheduling.restart_job_on_worker_restart` to false.
func (o GoogleCloudAiplatformV1beta1SchedulingPtrOutput) DisableRetries() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1Scheduling) *bool {
		if v == nil {
			return nil
		}
		return v.DisableRetries
	}).(pulumi.BoolPtrOutput)
}

// Restarts the entire CustomJob if a worker gets restarted. This feature can be used by distributed training jobs that are not resilient to workers leaving and joining a job.
func (o GoogleCloudAiplatformV1beta1SchedulingPtrOutput) RestartJobOnWorkerRestart() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1Scheduling) *bool {
		if v == nil {
			return nil
		}
		return v.RestartJobOnWorkerRestart
	}).(pulumi.BoolPtrOutput)
}

// The maximum job running time. The default is 7 days.
func (o GoogleCloudAiplatformV1beta1SchedulingPtrOutput) Timeout() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1Scheduling) *string {
		if v == nil {
			return nil
		}
		return v.Timeout
	}).(pulumi.StringPtrOutput)
}

// All parameters related to queuing and scheduling of custom jobs.
type GoogleCloudAiplatformV1beta1SchedulingResponse struct {
	// Optional. Indicates if the job should retry for internal errors after the job starts running. If true, overrides `Scheduling.restart_job_on_worker_restart` to false.
	DisableRetries bool `pulumi:"disableRetries"`
	// Restarts the entire CustomJob if a worker gets restarted. This feature can be used by distributed training jobs that are not resilient to workers leaving and joining a job.
	RestartJobOnWorkerRestart bool `pulumi:"restartJobOnWorkerRestart"`
	// The maximum job running time. The default is 7 days.
	Timeout string `pulumi:"timeout"`
}

// All parameters related to queuing and scheduling of custom jobs.
type GoogleCloudAiplatformV1beta1SchedulingResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1SchedulingResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1SchedulingResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1SchedulingResponseOutput) ToGoogleCloudAiplatformV1beta1SchedulingResponseOutput() GoogleCloudAiplatformV1beta1SchedulingResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1SchedulingResponseOutput) ToGoogleCloudAiplatformV1beta1SchedulingResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1SchedulingResponseOutput {
	return o
}

// Optional. Indicates if the job should retry for internal errors after the job starts running. If true, overrides `Scheduling.restart_job_on_worker_restart` to false.
func (o GoogleCloudAiplatformV1beta1SchedulingResponseOutput) DisableRetries() pulumi.BoolOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1SchedulingResponse) bool { return v.DisableRetries }).(pulumi.BoolOutput)
}

// Restarts the entire CustomJob if a worker gets restarted. This feature can be used by distributed training jobs that are not resilient to workers leaving and joining a job.
func (o GoogleCloudAiplatformV1beta1SchedulingResponseOutput) RestartJobOnWorkerRestart() pulumi.BoolOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1SchedulingResponse) bool { return v.RestartJobOnWorkerRestart }).(pulumi.BoolOutput)
}

// The maximum job running time. The default is 7 days.
func (o GoogleCloudAiplatformV1beta1SchedulingResponseOutput) Timeout() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1SchedulingResponse) string { return v.Timeout }).(pulumi.StringOutput)
}

// Configuration for the use of custom service account to run the workloads.
type GoogleCloudAiplatformV1beta1ServiceAccountSpec struct {
	// If true, custom user-managed service account is enforced to run any workloads (for example, Vertex Jobs) on the resource. Otherwise, uses the [Vertex AI Custom Code Service Agent](https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents).
	EnableCustomServiceAccount bool `pulumi:"enableCustomServiceAccount"`
	// Optional. Default service account that this PersistentResource's workloads run as. The workloads include: * Any runtime specified via `ResourceRuntimeSpec` on creation time, for example, Ray. * Jobs submitted to PersistentResource, if no other service account specified in the job specs. Only works when custom service account is enabled and users have the `iam.serviceAccounts.actAs` permission on this service account. Required if any containers are specified in `ResourceRuntimeSpec`.
	ServiceAccount *string `pulumi:"serviceAccount"`
}

// GoogleCloudAiplatformV1beta1ServiceAccountSpecInput is an input type that accepts GoogleCloudAiplatformV1beta1ServiceAccountSpecArgs and GoogleCloudAiplatformV1beta1ServiceAccountSpecOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1ServiceAccountSpecInput` via:
//
//	GoogleCloudAiplatformV1beta1ServiceAccountSpecArgs{...}
type GoogleCloudAiplatformV1beta1ServiceAccountSpecInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1ServiceAccountSpecOutput() GoogleCloudAiplatformV1beta1ServiceAccountSpecOutput
	ToGoogleCloudAiplatformV1beta1ServiceAccountSpecOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1ServiceAccountSpecOutput
}

// Configuration for the use of custom service account to run the workloads.
type GoogleCloudAiplatformV1beta1ServiceAccountSpecArgs struct {
	// If true, custom user-managed service account is enforced to run any workloads (for example, Vertex Jobs) on the resource. Otherwise, uses the [Vertex AI Custom Code Service Agent](https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents).
	EnableCustomServiceAccount pulumi.BoolInput `pulumi:"enableCustomServiceAccount"`
	// Optional. Default service account that this PersistentResource's workloads run as. The workloads include: * Any runtime specified via `ResourceRuntimeSpec` on creation time, for example, Ray. * Jobs submitted to PersistentResource, if no other service account specified in the job specs. Only works when custom service account is enabled and users have the `iam.serviceAccounts.actAs` permission on this service account. Required if any containers are specified in `ResourceRuntimeSpec`.
	ServiceAccount pulumi.StringPtrInput `pulumi:"serviceAccount"`
}

func (GoogleCloudAiplatformV1beta1ServiceAccountSpecArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ServiceAccountSpec)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1ServiceAccountSpecArgs) ToGoogleCloudAiplatformV1beta1ServiceAccountSpecOutput() GoogleCloudAiplatformV1beta1ServiceAccountSpecOutput {
	return i.ToGoogleCloudAiplatformV1beta1ServiceAccountSpecOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1ServiceAccountSpecArgs) ToGoogleCloudAiplatformV1beta1ServiceAccountSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ServiceAccountSpecOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ServiceAccountSpecOutput)
}

func (i GoogleCloudAiplatformV1beta1ServiceAccountSpecArgs) ToGoogleCloudAiplatformV1beta1ServiceAccountSpecPtrOutput() GoogleCloudAiplatformV1beta1ServiceAccountSpecPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1ServiceAccountSpecPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1ServiceAccountSpecArgs) ToGoogleCloudAiplatformV1beta1ServiceAccountSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ServiceAccountSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ServiceAccountSpecOutput).ToGoogleCloudAiplatformV1beta1ServiceAccountSpecPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1ServiceAccountSpecPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1ServiceAccountSpecArgs, GoogleCloudAiplatformV1beta1ServiceAccountSpecPtr and GoogleCloudAiplatformV1beta1ServiceAccountSpecPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1ServiceAccountSpecPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1ServiceAccountSpecArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1ServiceAccountSpecPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1ServiceAccountSpecPtrOutput() GoogleCloudAiplatformV1beta1ServiceAccountSpecPtrOutput
	ToGoogleCloudAiplatformV1beta1ServiceAccountSpecPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1ServiceAccountSpecPtrOutput
}

type googleCloudAiplatformV1beta1ServiceAccountSpecPtrType GoogleCloudAiplatformV1beta1ServiceAccountSpecArgs

func GoogleCloudAiplatformV1beta1ServiceAccountSpecPtr(v *GoogleCloudAiplatformV1beta1ServiceAccountSpecArgs) GoogleCloudAiplatformV1beta1ServiceAccountSpecPtrInput {
	return (*googleCloudAiplatformV1beta1ServiceAccountSpecPtrType)(v)
}

func (*googleCloudAiplatformV1beta1ServiceAccountSpecPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1ServiceAccountSpec)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1ServiceAccountSpecPtrType) ToGoogleCloudAiplatformV1beta1ServiceAccountSpecPtrOutput() GoogleCloudAiplatformV1beta1ServiceAccountSpecPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1ServiceAccountSpecPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1ServiceAccountSpecPtrType) ToGoogleCloudAiplatformV1beta1ServiceAccountSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ServiceAccountSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ServiceAccountSpecPtrOutput)
}

// Configuration for the use of custom service account to run the workloads.
type GoogleCloudAiplatformV1beta1ServiceAccountSpecOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ServiceAccountSpecOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ServiceAccountSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ServiceAccountSpecOutput) ToGoogleCloudAiplatformV1beta1ServiceAccountSpecOutput() GoogleCloudAiplatformV1beta1ServiceAccountSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ServiceAccountSpecOutput) ToGoogleCloudAiplatformV1beta1ServiceAccountSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ServiceAccountSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ServiceAccountSpecOutput) ToGoogleCloudAiplatformV1beta1ServiceAccountSpecPtrOutput() GoogleCloudAiplatformV1beta1ServiceAccountSpecPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1ServiceAccountSpecPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1ServiceAccountSpecOutput) ToGoogleCloudAiplatformV1beta1ServiceAccountSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ServiceAccountSpecPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1ServiceAccountSpec) *GoogleCloudAiplatformV1beta1ServiceAccountSpec {
		return &v
	}).(GoogleCloudAiplatformV1beta1ServiceAccountSpecPtrOutput)
}

// If true, custom user-managed service account is enforced to run any workloads (for example, Vertex Jobs) on the resource. Otherwise, uses the [Vertex AI Custom Code Service Agent](https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents).
func (o GoogleCloudAiplatformV1beta1ServiceAccountSpecOutput) EnableCustomServiceAccount() pulumi.BoolOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ServiceAccountSpec) bool { return v.EnableCustomServiceAccount }).(pulumi.BoolOutput)
}

// Optional. Default service account that this PersistentResource's workloads run as. The workloads include: * Any runtime specified via `ResourceRuntimeSpec` on creation time, for example, Ray. * Jobs submitted to PersistentResource, if no other service account specified in the job specs. Only works when custom service account is enabled and users have the `iam.serviceAccounts.actAs` permission on this service account. Required if any containers are specified in `ResourceRuntimeSpec`.
func (o GoogleCloudAiplatformV1beta1ServiceAccountSpecOutput) ServiceAccount() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ServiceAccountSpec) *string { return v.ServiceAccount }).(pulumi.StringPtrOutput)
}

type GoogleCloudAiplatformV1beta1ServiceAccountSpecPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ServiceAccountSpecPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1ServiceAccountSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ServiceAccountSpecPtrOutput) ToGoogleCloudAiplatformV1beta1ServiceAccountSpecPtrOutput() GoogleCloudAiplatformV1beta1ServiceAccountSpecPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ServiceAccountSpecPtrOutput) ToGoogleCloudAiplatformV1beta1ServiceAccountSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ServiceAccountSpecPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ServiceAccountSpecPtrOutput) Elem() GoogleCloudAiplatformV1beta1ServiceAccountSpecOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ServiceAccountSpec) GoogleCloudAiplatformV1beta1ServiceAccountSpec {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1ServiceAccountSpec
		return ret
	}).(GoogleCloudAiplatformV1beta1ServiceAccountSpecOutput)
}

// If true, custom user-managed service account is enforced to run any workloads (for example, Vertex Jobs) on the resource. Otherwise, uses the [Vertex AI Custom Code Service Agent](https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents).
func (o GoogleCloudAiplatformV1beta1ServiceAccountSpecPtrOutput) EnableCustomServiceAccount() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ServiceAccountSpec) *bool {
		if v == nil {
			return nil
		}
		return &v.EnableCustomServiceAccount
	}).(pulumi.BoolPtrOutput)
}

// Optional. Default service account that this PersistentResource's workloads run as. The workloads include: * Any runtime specified via `ResourceRuntimeSpec` on creation time, for example, Ray. * Jobs submitted to PersistentResource, if no other service account specified in the job specs. Only works when custom service account is enabled and users have the `iam.serviceAccounts.actAs` permission on this service account. Required if any containers are specified in `ResourceRuntimeSpec`.
func (o GoogleCloudAiplatformV1beta1ServiceAccountSpecPtrOutput) ServiceAccount() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ServiceAccountSpec) *string {
		if v == nil {
			return nil
		}
		return v.ServiceAccount
	}).(pulumi.StringPtrOutput)
}

// Configuration for the use of custom service account to run the workloads.
type GoogleCloudAiplatformV1beta1ServiceAccountSpecResponse struct {
	// If true, custom user-managed service account is enforced to run any workloads (for example, Vertex Jobs) on the resource. Otherwise, uses the [Vertex AI Custom Code Service Agent](https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents).
	EnableCustomServiceAccount bool `pulumi:"enableCustomServiceAccount"`
	// Optional. Default service account that this PersistentResource's workloads run as. The workloads include: * Any runtime specified via `ResourceRuntimeSpec` on creation time, for example, Ray. * Jobs submitted to PersistentResource, if no other service account specified in the job specs. Only works when custom service account is enabled and users have the `iam.serviceAccounts.actAs` permission on this service account. Required if any containers are specified in `ResourceRuntimeSpec`.
	ServiceAccount string `pulumi:"serviceAccount"`
}

// Configuration for the use of custom service account to run the workloads.
type GoogleCloudAiplatformV1beta1ServiceAccountSpecResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ServiceAccountSpecResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ServiceAccountSpecResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ServiceAccountSpecResponseOutput) ToGoogleCloudAiplatformV1beta1ServiceAccountSpecResponseOutput() GoogleCloudAiplatformV1beta1ServiceAccountSpecResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ServiceAccountSpecResponseOutput) ToGoogleCloudAiplatformV1beta1ServiceAccountSpecResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ServiceAccountSpecResponseOutput {
	return o
}

// If true, custom user-managed service account is enforced to run any workloads (for example, Vertex Jobs) on the resource. Otherwise, uses the [Vertex AI Custom Code Service Agent](https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents).
func (o GoogleCloudAiplatformV1beta1ServiceAccountSpecResponseOutput) EnableCustomServiceAccount() pulumi.BoolOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ServiceAccountSpecResponse) bool {
		return v.EnableCustomServiceAccount
	}).(pulumi.BoolOutput)
}

// Optional. Default service account that this PersistentResource's workloads run as. The workloads include: * Any runtime specified via `ResourceRuntimeSpec` on creation time, for example, Ray. * Jobs submitted to PersistentResource, if no other service account specified in the job specs. Only works when custom service account is enabled and users have the `iam.serviceAccounts.actAs` permission on this service account. Required if any containers are specified in `ResourceRuntimeSpec`.
func (o GoogleCloudAiplatformV1beta1ServiceAccountSpecResponseOutput) ServiceAccount() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ServiceAccountSpecResponse) string { return v.ServiceAccount }).(pulumi.StringOutput)
}

// Config for SmoothGrad approximation of gradients. When enabled, the gradients are approximated by averaging the gradients from noisy samples in the vicinity of the inputs. Adding noise can help improve the computed gradients. Refer to this paper for more details: https://arxiv.org/pdf/1706.03825.pdf
type GoogleCloudAiplatformV1beta1SmoothGradConfig struct {
	// This is similar to noise_sigma, but provides additional flexibility. A separate noise sigma can be provided for each feature, which is useful if their distributions are different. No noise is added to features that are not set. If this field is unset, noise_sigma will be used for all features.
	FeatureNoiseSigma *GoogleCloudAiplatformV1beta1FeatureNoiseSigma `pulumi:"featureNoiseSigma"`
	// This is a single float value and will be used to add noise to all the features. Use this field when all features are normalized to have the same distribution: scale to range [0, 1], [-1, 1] or z-scoring, where features are normalized to have 0-mean and 1-variance. Learn more about [normalization](https://developers.google.com/machine-learning/data-prep/transform/normalization). For best results the recommended value is about 10% - 20% of the standard deviation of the input feature. Refer to section 3.2 of the SmoothGrad paper: https://arxiv.org/pdf/1706.03825.pdf. Defaults to 0.1. If the distribution is different per feature, set feature_noise_sigma instead for each feature.
	NoiseSigma *float64 `pulumi:"noiseSigma"`
	// The number of gradient samples to use for approximation. The higher this number, the more accurate the gradient is, but the runtime complexity increases by this factor as well. Valid range of its value is [1, 50]. Defaults to 3.
	NoisySampleCount *int `pulumi:"noisySampleCount"`
}

// GoogleCloudAiplatformV1beta1SmoothGradConfigInput is an input type that accepts GoogleCloudAiplatformV1beta1SmoothGradConfigArgs and GoogleCloudAiplatformV1beta1SmoothGradConfigOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1SmoothGradConfigInput` via:
//
//	GoogleCloudAiplatformV1beta1SmoothGradConfigArgs{...}
type GoogleCloudAiplatformV1beta1SmoothGradConfigInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1SmoothGradConfigOutput() GoogleCloudAiplatformV1beta1SmoothGradConfigOutput
	ToGoogleCloudAiplatformV1beta1SmoothGradConfigOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1SmoothGradConfigOutput
}

// Config for SmoothGrad approximation of gradients. When enabled, the gradients are approximated by averaging the gradients from noisy samples in the vicinity of the inputs. Adding noise can help improve the computed gradients. Refer to this paper for more details: https://arxiv.org/pdf/1706.03825.pdf
type GoogleCloudAiplatformV1beta1SmoothGradConfigArgs struct {
	// This is similar to noise_sigma, but provides additional flexibility. A separate noise sigma can be provided for each feature, which is useful if their distributions are different. No noise is added to features that are not set. If this field is unset, noise_sigma will be used for all features.
	FeatureNoiseSigma GoogleCloudAiplatformV1beta1FeatureNoiseSigmaPtrInput `pulumi:"featureNoiseSigma"`
	// This is a single float value and will be used to add noise to all the features. Use this field when all features are normalized to have the same distribution: scale to range [0, 1], [-1, 1] or z-scoring, where features are normalized to have 0-mean and 1-variance. Learn more about [normalization](https://developers.google.com/machine-learning/data-prep/transform/normalization). For best results the recommended value is about 10% - 20% of the standard deviation of the input feature. Refer to section 3.2 of the SmoothGrad paper: https://arxiv.org/pdf/1706.03825.pdf. Defaults to 0.1. If the distribution is different per feature, set feature_noise_sigma instead for each feature.
	NoiseSigma pulumi.Float64PtrInput `pulumi:"noiseSigma"`
	// The number of gradient samples to use for approximation. The higher this number, the more accurate the gradient is, but the runtime complexity increases by this factor as well. Valid range of its value is [1, 50]. Defaults to 3.
	NoisySampleCount pulumi.IntPtrInput `pulumi:"noisySampleCount"`
}

func (GoogleCloudAiplatformV1beta1SmoothGradConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1SmoothGradConfig)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1SmoothGradConfigArgs) ToGoogleCloudAiplatformV1beta1SmoothGradConfigOutput() GoogleCloudAiplatformV1beta1SmoothGradConfigOutput {
	return i.ToGoogleCloudAiplatformV1beta1SmoothGradConfigOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1SmoothGradConfigArgs) ToGoogleCloudAiplatformV1beta1SmoothGradConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1SmoothGradConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1SmoothGradConfigOutput)
}

func (i GoogleCloudAiplatformV1beta1SmoothGradConfigArgs) ToGoogleCloudAiplatformV1beta1SmoothGradConfigPtrOutput() GoogleCloudAiplatformV1beta1SmoothGradConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1SmoothGradConfigPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1SmoothGradConfigArgs) ToGoogleCloudAiplatformV1beta1SmoothGradConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1SmoothGradConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1SmoothGradConfigOutput).ToGoogleCloudAiplatformV1beta1SmoothGradConfigPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1SmoothGradConfigPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1SmoothGradConfigArgs, GoogleCloudAiplatformV1beta1SmoothGradConfigPtr and GoogleCloudAiplatformV1beta1SmoothGradConfigPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1SmoothGradConfigPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1SmoothGradConfigArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1SmoothGradConfigPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1SmoothGradConfigPtrOutput() GoogleCloudAiplatformV1beta1SmoothGradConfigPtrOutput
	ToGoogleCloudAiplatformV1beta1SmoothGradConfigPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1SmoothGradConfigPtrOutput
}

type googleCloudAiplatformV1beta1SmoothGradConfigPtrType GoogleCloudAiplatformV1beta1SmoothGradConfigArgs

func GoogleCloudAiplatformV1beta1SmoothGradConfigPtr(v *GoogleCloudAiplatformV1beta1SmoothGradConfigArgs) GoogleCloudAiplatformV1beta1SmoothGradConfigPtrInput {
	return (*googleCloudAiplatformV1beta1SmoothGradConfigPtrType)(v)
}

func (*googleCloudAiplatformV1beta1SmoothGradConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1SmoothGradConfig)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1SmoothGradConfigPtrType) ToGoogleCloudAiplatformV1beta1SmoothGradConfigPtrOutput() GoogleCloudAiplatformV1beta1SmoothGradConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1SmoothGradConfigPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1SmoothGradConfigPtrType) ToGoogleCloudAiplatformV1beta1SmoothGradConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1SmoothGradConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1SmoothGradConfigPtrOutput)
}

// Config for SmoothGrad approximation of gradients. When enabled, the gradients are approximated by averaging the gradients from noisy samples in the vicinity of the inputs. Adding noise can help improve the computed gradients. Refer to this paper for more details: https://arxiv.org/pdf/1706.03825.pdf
type GoogleCloudAiplatformV1beta1SmoothGradConfigOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1SmoothGradConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1SmoothGradConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1SmoothGradConfigOutput) ToGoogleCloudAiplatformV1beta1SmoothGradConfigOutput() GoogleCloudAiplatformV1beta1SmoothGradConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1SmoothGradConfigOutput) ToGoogleCloudAiplatformV1beta1SmoothGradConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1SmoothGradConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1SmoothGradConfigOutput) ToGoogleCloudAiplatformV1beta1SmoothGradConfigPtrOutput() GoogleCloudAiplatformV1beta1SmoothGradConfigPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1SmoothGradConfigPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1SmoothGradConfigOutput) ToGoogleCloudAiplatformV1beta1SmoothGradConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1SmoothGradConfigPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1SmoothGradConfig) *GoogleCloudAiplatformV1beta1SmoothGradConfig {
		return &v
	}).(GoogleCloudAiplatformV1beta1SmoothGradConfigPtrOutput)
}

// This is similar to noise_sigma, but provides additional flexibility. A separate noise sigma can be provided for each feature, which is useful if their distributions are different. No noise is added to features that are not set. If this field is unset, noise_sigma will be used for all features.
func (o GoogleCloudAiplatformV1beta1SmoothGradConfigOutput) FeatureNoiseSigma() GoogleCloudAiplatformV1beta1FeatureNoiseSigmaPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1SmoothGradConfig) *GoogleCloudAiplatformV1beta1FeatureNoiseSigma {
		return v.FeatureNoiseSigma
	}).(GoogleCloudAiplatformV1beta1FeatureNoiseSigmaPtrOutput)
}

// This is a single float value and will be used to add noise to all the features. Use this field when all features are normalized to have the same distribution: scale to range [0, 1], [-1, 1] or z-scoring, where features are normalized to have 0-mean and 1-variance. Learn more about [normalization](https://developers.google.com/machine-learning/data-prep/transform/normalization). For best results the recommended value is about 10% - 20% of the standard deviation of the input feature. Refer to section 3.2 of the SmoothGrad paper: https://arxiv.org/pdf/1706.03825.pdf. Defaults to 0.1. If the distribution is different per feature, set feature_noise_sigma instead for each feature.
func (o GoogleCloudAiplatformV1beta1SmoothGradConfigOutput) NoiseSigma() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1SmoothGradConfig) *float64 { return v.NoiseSigma }).(pulumi.Float64PtrOutput)
}

// The number of gradient samples to use for approximation. The higher this number, the more accurate the gradient is, but the runtime complexity increases by this factor as well. Valid range of its value is [1, 50]. Defaults to 3.
func (o GoogleCloudAiplatformV1beta1SmoothGradConfigOutput) NoisySampleCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1SmoothGradConfig) *int { return v.NoisySampleCount }).(pulumi.IntPtrOutput)
}

type GoogleCloudAiplatformV1beta1SmoothGradConfigPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1SmoothGradConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1SmoothGradConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1SmoothGradConfigPtrOutput) ToGoogleCloudAiplatformV1beta1SmoothGradConfigPtrOutput() GoogleCloudAiplatformV1beta1SmoothGradConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1SmoothGradConfigPtrOutput) ToGoogleCloudAiplatformV1beta1SmoothGradConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1SmoothGradConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1SmoothGradConfigPtrOutput) Elem() GoogleCloudAiplatformV1beta1SmoothGradConfigOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1SmoothGradConfig) GoogleCloudAiplatformV1beta1SmoothGradConfig {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1SmoothGradConfig
		return ret
	}).(GoogleCloudAiplatformV1beta1SmoothGradConfigOutput)
}

// This is similar to noise_sigma, but provides additional flexibility. A separate noise sigma can be provided for each feature, which is useful if their distributions are different. No noise is added to features that are not set. If this field is unset, noise_sigma will be used for all features.
func (o GoogleCloudAiplatformV1beta1SmoothGradConfigPtrOutput) FeatureNoiseSigma() GoogleCloudAiplatformV1beta1FeatureNoiseSigmaPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1SmoothGradConfig) *GoogleCloudAiplatformV1beta1FeatureNoiseSigma {
		if v == nil {
			return nil
		}
		return v.FeatureNoiseSigma
	}).(GoogleCloudAiplatformV1beta1FeatureNoiseSigmaPtrOutput)
}

// This is a single float value and will be used to add noise to all the features. Use this field when all features are normalized to have the same distribution: scale to range [0, 1], [-1, 1] or z-scoring, where features are normalized to have 0-mean and 1-variance. Learn more about [normalization](https://developers.google.com/machine-learning/data-prep/transform/normalization). For best results the recommended value is about 10% - 20% of the standard deviation of the input feature. Refer to section 3.2 of the SmoothGrad paper: https://arxiv.org/pdf/1706.03825.pdf. Defaults to 0.1. If the distribution is different per feature, set feature_noise_sigma instead for each feature.
func (o GoogleCloudAiplatformV1beta1SmoothGradConfigPtrOutput) NoiseSigma() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1SmoothGradConfig) *float64 {
		if v == nil {
			return nil
		}
		return v.NoiseSigma
	}).(pulumi.Float64PtrOutput)
}

// The number of gradient samples to use for approximation. The higher this number, the more accurate the gradient is, but the runtime complexity increases by this factor as well. Valid range of its value is [1, 50]. Defaults to 3.
func (o GoogleCloudAiplatformV1beta1SmoothGradConfigPtrOutput) NoisySampleCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1SmoothGradConfig) *int {
		if v == nil {
			return nil
		}
		return v.NoisySampleCount
	}).(pulumi.IntPtrOutput)
}

// Config for SmoothGrad approximation of gradients. When enabled, the gradients are approximated by averaging the gradients from noisy samples in the vicinity of the inputs. Adding noise can help improve the computed gradients. Refer to this paper for more details: https://arxiv.org/pdf/1706.03825.pdf
type GoogleCloudAiplatformV1beta1SmoothGradConfigResponse struct {
	// This is similar to noise_sigma, but provides additional flexibility. A separate noise sigma can be provided for each feature, which is useful if their distributions are different. No noise is added to features that are not set. If this field is unset, noise_sigma will be used for all features.
	FeatureNoiseSigma GoogleCloudAiplatformV1beta1FeatureNoiseSigmaResponse `pulumi:"featureNoiseSigma"`
	// This is a single float value and will be used to add noise to all the features. Use this field when all features are normalized to have the same distribution: scale to range [0, 1], [-1, 1] or z-scoring, where features are normalized to have 0-mean and 1-variance. Learn more about [normalization](https://developers.google.com/machine-learning/data-prep/transform/normalization). For best results the recommended value is about 10% - 20% of the standard deviation of the input feature. Refer to section 3.2 of the SmoothGrad paper: https://arxiv.org/pdf/1706.03825.pdf. Defaults to 0.1. If the distribution is different per feature, set feature_noise_sigma instead for each feature.
	NoiseSigma float64 `pulumi:"noiseSigma"`
	// The number of gradient samples to use for approximation. The higher this number, the more accurate the gradient is, but the runtime complexity increases by this factor as well. Valid range of its value is [1, 50]. Defaults to 3.
	NoisySampleCount int `pulumi:"noisySampleCount"`
}

// Config for SmoothGrad approximation of gradients. When enabled, the gradients are approximated by averaging the gradients from noisy samples in the vicinity of the inputs. Adding noise can help improve the computed gradients. Refer to this paper for more details: https://arxiv.org/pdf/1706.03825.pdf
type GoogleCloudAiplatformV1beta1SmoothGradConfigResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1SmoothGradConfigResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1SmoothGradConfigResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1SmoothGradConfigResponseOutput) ToGoogleCloudAiplatformV1beta1SmoothGradConfigResponseOutput() GoogleCloudAiplatformV1beta1SmoothGradConfigResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1SmoothGradConfigResponseOutput) ToGoogleCloudAiplatformV1beta1SmoothGradConfigResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1SmoothGradConfigResponseOutput {
	return o
}

// This is similar to noise_sigma, but provides additional flexibility. A separate noise sigma can be provided for each feature, which is useful if their distributions are different. No noise is added to features that are not set. If this field is unset, noise_sigma will be used for all features.
func (o GoogleCloudAiplatformV1beta1SmoothGradConfigResponseOutput) FeatureNoiseSigma() GoogleCloudAiplatformV1beta1FeatureNoiseSigmaResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1SmoothGradConfigResponse) GoogleCloudAiplatformV1beta1FeatureNoiseSigmaResponse {
		return v.FeatureNoiseSigma
	}).(GoogleCloudAiplatformV1beta1FeatureNoiseSigmaResponseOutput)
}

// This is a single float value and will be used to add noise to all the features. Use this field when all features are normalized to have the same distribution: scale to range [0, 1], [-1, 1] or z-scoring, where features are normalized to have 0-mean and 1-variance. Learn more about [normalization](https://developers.google.com/machine-learning/data-prep/transform/normalization). For best results the recommended value is about 10% - 20% of the standard deviation of the input feature. Refer to section 3.2 of the SmoothGrad paper: https://arxiv.org/pdf/1706.03825.pdf. Defaults to 0.1. If the distribution is different per feature, set feature_noise_sigma instead for each feature.
func (o GoogleCloudAiplatformV1beta1SmoothGradConfigResponseOutput) NoiseSigma() pulumi.Float64Output {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1SmoothGradConfigResponse) float64 { return v.NoiseSigma }).(pulumi.Float64Output)
}

// The number of gradient samples to use for approximation. The higher this number, the more accurate the gradient is, but the runtime complexity increases by this factor as well. Valid range of its value is [1, 50]. Defaults to 3.
func (o GoogleCloudAiplatformV1beta1SmoothGradConfigResponseOutput) NoisySampleCount() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1SmoothGradConfigResponse) int { return v.NoisySampleCount }).(pulumi.IntOutput)
}

// Assigns input data to the training, validation, and test sets so that the distribution of values found in the categorical column (as specified by the `key` field) is mirrored within each split. The fraction values determine the relative sizes of the splits. For example, if the specified column has three values, with 50% of the rows having value "A", 25% value "B", and 25% value "C", and the split fractions are specified as 80/10/10, then the training set will constitute 80% of the training data, with about 50% of the training set rows having the value "A" for the specified column, about 25% having the value "B", and about 25% having the value "C". Only the top 500 occurring values are used; any values not in the top 500 values are randomly assigned to a split. If less than three rows contain a specific value, those rows are randomly assigned. Supported only for tabular Datasets.
type GoogleCloudAiplatformV1beta1StratifiedSplit struct {
	// The key is a name of one of the Dataset's data columns. The key provided must be for a categorical column.
	Key string `pulumi:"key"`
	// The fraction of the input data that is to be used to evaluate the Model.
	TestFraction *float64 `pulumi:"testFraction"`
	// The fraction of the input data that is to be used to train the Model.
	TrainingFraction *float64 `pulumi:"trainingFraction"`
	// The fraction of the input data that is to be used to validate the Model.
	ValidationFraction *float64 `pulumi:"validationFraction"`
}

// GoogleCloudAiplatformV1beta1StratifiedSplitInput is an input type that accepts GoogleCloudAiplatformV1beta1StratifiedSplitArgs and GoogleCloudAiplatformV1beta1StratifiedSplitOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1StratifiedSplitInput` via:
//
//	GoogleCloudAiplatformV1beta1StratifiedSplitArgs{...}
type GoogleCloudAiplatformV1beta1StratifiedSplitInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1StratifiedSplitOutput() GoogleCloudAiplatformV1beta1StratifiedSplitOutput
	ToGoogleCloudAiplatformV1beta1StratifiedSplitOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1StratifiedSplitOutput
}

// Assigns input data to the training, validation, and test sets so that the distribution of values found in the categorical column (as specified by the `key` field) is mirrored within each split. The fraction values determine the relative sizes of the splits. For example, if the specified column has three values, with 50% of the rows having value "A", 25% value "B", and 25% value "C", and the split fractions are specified as 80/10/10, then the training set will constitute 80% of the training data, with about 50% of the training set rows having the value "A" for the specified column, about 25% having the value "B", and about 25% having the value "C". Only the top 500 occurring values are used; any values not in the top 500 values are randomly assigned to a split. If less than three rows contain a specific value, those rows are randomly assigned. Supported only for tabular Datasets.
type GoogleCloudAiplatformV1beta1StratifiedSplitArgs struct {
	// The key is a name of one of the Dataset's data columns. The key provided must be for a categorical column.
	Key pulumi.StringInput `pulumi:"key"`
	// The fraction of the input data that is to be used to evaluate the Model.
	TestFraction pulumi.Float64PtrInput `pulumi:"testFraction"`
	// The fraction of the input data that is to be used to train the Model.
	TrainingFraction pulumi.Float64PtrInput `pulumi:"trainingFraction"`
	// The fraction of the input data that is to be used to validate the Model.
	ValidationFraction pulumi.Float64PtrInput `pulumi:"validationFraction"`
}

func (GoogleCloudAiplatformV1beta1StratifiedSplitArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1StratifiedSplit)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1StratifiedSplitArgs) ToGoogleCloudAiplatformV1beta1StratifiedSplitOutput() GoogleCloudAiplatformV1beta1StratifiedSplitOutput {
	return i.ToGoogleCloudAiplatformV1beta1StratifiedSplitOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1StratifiedSplitArgs) ToGoogleCloudAiplatformV1beta1StratifiedSplitOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StratifiedSplitOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1StratifiedSplitOutput)
}

func (i GoogleCloudAiplatformV1beta1StratifiedSplitArgs) ToGoogleCloudAiplatformV1beta1StratifiedSplitPtrOutput() GoogleCloudAiplatformV1beta1StratifiedSplitPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1StratifiedSplitPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1StratifiedSplitArgs) ToGoogleCloudAiplatformV1beta1StratifiedSplitPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StratifiedSplitPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1StratifiedSplitOutput).ToGoogleCloudAiplatformV1beta1StratifiedSplitPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1StratifiedSplitPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1StratifiedSplitArgs, GoogleCloudAiplatformV1beta1StratifiedSplitPtr and GoogleCloudAiplatformV1beta1StratifiedSplitPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1StratifiedSplitPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1StratifiedSplitArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1StratifiedSplitPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1StratifiedSplitPtrOutput() GoogleCloudAiplatformV1beta1StratifiedSplitPtrOutput
	ToGoogleCloudAiplatformV1beta1StratifiedSplitPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1StratifiedSplitPtrOutput
}

type googleCloudAiplatformV1beta1StratifiedSplitPtrType GoogleCloudAiplatformV1beta1StratifiedSplitArgs

func GoogleCloudAiplatformV1beta1StratifiedSplitPtr(v *GoogleCloudAiplatformV1beta1StratifiedSplitArgs) GoogleCloudAiplatformV1beta1StratifiedSplitPtrInput {
	return (*googleCloudAiplatformV1beta1StratifiedSplitPtrType)(v)
}

func (*googleCloudAiplatformV1beta1StratifiedSplitPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1StratifiedSplit)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1StratifiedSplitPtrType) ToGoogleCloudAiplatformV1beta1StratifiedSplitPtrOutput() GoogleCloudAiplatformV1beta1StratifiedSplitPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1StratifiedSplitPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1StratifiedSplitPtrType) ToGoogleCloudAiplatformV1beta1StratifiedSplitPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StratifiedSplitPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1StratifiedSplitPtrOutput)
}

// Assigns input data to the training, validation, and test sets so that the distribution of values found in the categorical column (as specified by the `key` field) is mirrored within each split. The fraction values determine the relative sizes of the splits. For example, if the specified column has three values, with 50% of the rows having value "A", 25% value "B", and 25% value "C", and the split fractions are specified as 80/10/10, then the training set will constitute 80% of the training data, with about 50% of the training set rows having the value "A" for the specified column, about 25% having the value "B", and about 25% having the value "C". Only the top 500 occurring values are used; any values not in the top 500 values are randomly assigned to a split. If less than three rows contain a specific value, those rows are randomly assigned. Supported only for tabular Datasets.
type GoogleCloudAiplatformV1beta1StratifiedSplitOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1StratifiedSplitOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1StratifiedSplit)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1StratifiedSplitOutput) ToGoogleCloudAiplatformV1beta1StratifiedSplitOutput() GoogleCloudAiplatformV1beta1StratifiedSplitOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StratifiedSplitOutput) ToGoogleCloudAiplatformV1beta1StratifiedSplitOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StratifiedSplitOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StratifiedSplitOutput) ToGoogleCloudAiplatformV1beta1StratifiedSplitPtrOutput() GoogleCloudAiplatformV1beta1StratifiedSplitPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1StratifiedSplitPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1StratifiedSplitOutput) ToGoogleCloudAiplatformV1beta1StratifiedSplitPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StratifiedSplitPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1StratifiedSplit) *GoogleCloudAiplatformV1beta1StratifiedSplit {
		return &v
	}).(GoogleCloudAiplatformV1beta1StratifiedSplitPtrOutput)
}

// The key is a name of one of the Dataset's data columns. The key provided must be for a categorical column.
func (o GoogleCloudAiplatformV1beta1StratifiedSplitOutput) Key() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StratifiedSplit) string { return v.Key }).(pulumi.StringOutput)
}

// The fraction of the input data that is to be used to evaluate the Model.
func (o GoogleCloudAiplatformV1beta1StratifiedSplitOutput) TestFraction() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StratifiedSplit) *float64 { return v.TestFraction }).(pulumi.Float64PtrOutput)
}

// The fraction of the input data that is to be used to train the Model.
func (o GoogleCloudAiplatformV1beta1StratifiedSplitOutput) TrainingFraction() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StratifiedSplit) *float64 { return v.TrainingFraction }).(pulumi.Float64PtrOutput)
}

// The fraction of the input data that is to be used to validate the Model.
func (o GoogleCloudAiplatformV1beta1StratifiedSplitOutput) ValidationFraction() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StratifiedSplit) *float64 { return v.ValidationFraction }).(pulumi.Float64PtrOutput)
}

type GoogleCloudAiplatformV1beta1StratifiedSplitPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1StratifiedSplitPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1StratifiedSplit)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1StratifiedSplitPtrOutput) ToGoogleCloudAiplatformV1beta1StratifiedSplitPtrOutput() GoogleCloudAiplatformV1beta1StratifiedSplitPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StratifiedSplitPtrOutput) ToGoogleCloudAiplatformV1beta1StratifiedSplitPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StratifiedSplitPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StratifiedSplitPtrOutput) Elem() GoogleCloudAiplatformV1beta1StratifiedSplitOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1StratifiedSplit) GoogleCloudAiplatformV1beta1StratifiedSplit {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1StratifiedSplit
		return ret
	}).(GoogleCloudAiplatformV1beta1StratifiedSplitOutput)
}

// The key is a name of one of the Dataset's data columns. The key provided must be for a categorical column.
func (o GoogleCloudAiplatformV1beta1StratifiedSplitPtrOutput) Key() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1StratifiedSplit) *string {
		if v == nil {
			return nil
		}
		return &v.Key
	}).(pulumi.StringPtrOutput)
}

// The fraction of the input data that is to be used to evaluate the Model.
func (o GoogleCloudAiplatformV1beta1StratifiedSplitPtrOutput) TestFraction() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1StratifiedSplit) *float64 {
		if v == nil {
			return nil
		}
		return v.TestFraction
	}).(pulumi.Float64PtrOutput)
}

// The fraction of the input data that is to be used to train the Model.
func (o GoogleCloudAiplatformV1beta1StratifiedSplitPtrOutput) TrainingFraction() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1StratifiedSplit) *float64 {
		if v == nil {
			return nil
		}
		return v.TrainingFraction
	}).(pulumi.Float64PtrOutput)
}

// The fraction of the input data that is to be used to validate the Model.
func (o GoogleCloudAiplatformV1beta1StratifiedSplitPtrOutput) ValidationFraction() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1StratifiedSplit) *float64 {
		if v == nil {
			return nil
		}
		return v.ValidationFraction
	}).(pulumi.Float64PtrOutput)
}

// Assigns input data to the training, validation, and test sets so that the distribution of values found in the categorical column (as specified by the `key` field) is mirrored within each split. The fraction values determine the relative sizes of the splits. For example, if the specified column has three values, with 50% of the rows having value "A", 25% value "B", and 25% value "C", and the split fractions are specified as 80/10/10, then the training set will constitute 80% of the training data, with about 50% of the training set rows having the value "A" for the specified column, about 25% having the value "B", and about 25% having the value "C". Only the top 500 occurring values are used; any values not in the top 500 values are randomly assigned to a split. If less than three rows contain a specific value, those rows are randomly assigned. Supported only for tabular Datasets.
type GoogleCloudAiplatformV1beta1StratifiedSplitResponse struct {
	// The key is a name of one of the Dataset's data columns. The key provided must be for a categorical column.
	Key string `pulumi:"key"`
	// The fraction of the input data that is to be used to evaluate the Model.
	TestFraction float64 `pulumi:"testFraction"`
	// The fraction of the input data that is to be used to train the Model.
	TrainingFraction float64 `pulumi:"trainingFraction"`
	// The fraction of the input data that is to be used to validate the Model.
	ValidationFraction float64 `pulumi:"validationFraction"`
}

// Assigns input data to the training, validation, and test sets so that the distribution of values found in the categorical column (as specified by the `key` field) is mirrored within each split. The fraction values determine the relative sizes of the splits. For example, if the specified column has three values, with 50% of the rows having value "A", 25% value "B", and 25% value "C", and the split fractions are specified as 80/10/10, then the training set will constitute 80% of the training data, with about 50% of the training set rows having the value "A" for the specified column, about 25% having the value "B", and about 25% having the value "C". Only the top 500 occurring values are used; any values not in the top 500 values are randomly assigned to a split. If less than three rows contain a specific value, those rows are randomly assigned. Supported only for tabular Datasets.
type GoogleCloudAiplatformV1beta1StratifiedSplitResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1StratifiedSplitResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1StratifiedSplitResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1StratifiedSplitResponseOutput) ToGoogleCloudAiplatformV1beta1StratifiedSplitResponseOutput() GoogleCloudAiplatformV1beta1StratifiedSplitResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StratifiedSplitResponseOutput) ToGoogleCloudAiplatformV1beta1StratifiedSplitResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StratifiedSplitResponseOutput {
	return o
}

// The key is a name of one of the Dataset's data columns. The key provided must be for a categorical column.
func (o GoogleCloudAiplatformV1beta1StratifiedSplitResponseOutput) Key() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StratifiedSplitResponse) string { return v.Key }).(pulumi.StringOutput)
}

// The fraction of the input data that is to be used to evaluate the Model.
func (o GoogleCloudAiplatformV1beta1StratifiedSplitResponseOutput) TestFraction() pulumi.Float64Output {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StratifiedSplitResponse) float64 { return v.TestFraction }).(pulumi.Float64Output)
}

// The fraction of the input data that is to be used to train the Model.
func (o GoogleCloudAiplatformV1beta1StratifiedSplitResponseOutput) TrainingFraction() pulumi.Float64Output {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StratifiedSplitResponse) float64 { return v.TrainingFraction }).(pulumi.Float64Output)
}

// The fraction of the input data that is to be used to validate the Model.
func (o GoogleCloudAiplatformV1beta1StratifiedSplitResponseOutput) ValidationFraction() pulumi.Float64Output {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StratifiedSplitResponse) float64 { return v.ValidationFraction }).(pulumi.Float64Output)
}

// Represents specification of a Study.
type GoogleCloudAiplatformV1beta1StudySpec struct {
	// The search algorithm specified for the Study.
	Algorithm *GoogleCloudAiplatformV1beta1StudySpecAlgorithm `pulumi:"algorithm"`
	// The automated early stopping spec using convex stopping rule.
	ConvexAutomatedStoppingSpec *GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpec `pulumi:"convexAutomatedStoppingSpec"`
	// Deprecated. The automated early stopping using convex stopping rule.
	//
	// Deprecated: Deprecated. The automated early stopping using convex stopping rule.
	ConvexStopConfig *GoogleCloudAiplatformV1beta1StudySpecConvexStopConfig `pulumi:"convexStopConfig"`
	// The automated early stopping spec using decay curve rule.
	DecayCurveStoppingSpec *GoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpec `pulumi:"decayCurveStoppingSpec"`
	// Describe which measurement selection type will be used
	MeasurementSelectionType *GoogleCloudAiplatformV1beta1StudySpecMeasurementSelectionType `pulumi:"measurementSelectionType"`
	// The automated early stopping spec using median rule.
	MedianAutomatedStoppingSpec *GoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpec `pulumi:"medianAutomatedStoppingSpec"`
	// Metric specs for the Study.
	Metrics []GoogleCloudAiplatformV1beta1StudySpecMetricSpec `pulumi:"metrics"`
	// The observation noise level of the study. Currently only supported by the Vertex AI Vizier service. Not supported by HyperparameterTuningJob or TrainingPipeline.
	ObservationNoise *GoogleCloudAiplatformV1beta1StudySpecObservationNoise `pulumi:"observationNoise"`
	// The set of parameters to tune.
	Parameters []GoogleCloudAiplatformV1beta1StudySpecParameterSpec `pulumi:"parameters"`
	// Conditions for automated stopping of a Study. Enable automated stopping by configuring at least one condition.
	StudyStoppingConfig *GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfig `pulumi:"studyStoppingConfig"`
	// The configuration info/options for transfer learning. Currently supported for Vertex AI Vizier service, not HyperParameterTuningJob
	TransferLearningConfig *GoogleCloudAiplatformV1beta1StudySpecTransferLearningConfig `pulumi:"transferLearningConfig"`
}

// GoogleCloudAiplatformV1beta1StudySpecInput is an input type that accepts GoogleCloudAiplatformV1beta1StudySpecArgs and GoogleCloudAiplatformV1beta1StudySpecOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1StudySpecInput` via:
//
//	GoogleCloudAiplatformV1beta1StudySpecArgs{...}
type GoogleCloudAiplatformV1beta1StudySpecInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1StudySpecOutput() GoogleCloudAiplatformV1beta1StudySpecOutput
	ToGoogleCloudAiplatformV1beta1StudySpecOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1StudySpecOutput
}

// Represents specification of a Study.
type GoogleCloudAiplatformV1beta1StudySpecArgs struct {
	// The search algorithm specified for the Study.
	Algorithm GoogleCloudAiplatformV1beta1StudySpecAlgorithmPtrInput `pulumi:"algorithm"`
	// The automated early stopping spec using convex stopping rule.
	ConvexAutomatedStoppingSpec GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecPtrInput `pulumi:"convexAutomatedStoppingSpec"`
	// Deprecated. The automated early stopping using convex stopping rule.
	//
	// Deprecated: Deprecated. The automated early stopping using convex stopping rule.
	ConvexStopConfig GoogleCloudAiplatformV1beta1StudySpecConvexStopConfigPtrInput `pulumi:"convexStopConfig"`
	// The automated early stopping spec using decay curve rule.
	DecayCurveStoppingSpec GoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecPtrInput `pulumi:"decayCurveStoppingSpec"`
	// Describe which measurement selection type will be used
	MeasurementSelectionType GoogleCloudAiplatformV1beta1StudySpecMeasurementSelectionTypePtrInput `pulumi:"measurementSelectionType"`
	// The automated early stopping spec using median rule.
	MedianAutomatedStoppingSpec GoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecPtrInput `pulumi:"medianAutomatedStoppingSpec"`
	// Metric specs for the Study.
	Metrics GoogleCloudAiplatformV1beta1StudySpecMetricSpecArrayInput `pulumi:"metrics"`
	// The observation noise level of the study. Currently only supported by the Vertex AI Vizier service. Not supported by HyperparameterTuningJob or TrainingPipeline.
	ObservationNoise GoogleCloudAiplatformV1beta1StudySpecObservationNoisePtrInput `pulumi:"observationNoise"`
	// The set of parameters to tune.
	Parameters GoogleCloudAiplatformV1beta1StudySpecParameterSpecArrayInput `pulumi:"parameters"`
	// Conditions for automated stopping of a Study. Enable automated stopping by configuring at least one condition.
	StudyStoppingConfig GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigPtrInput `pulumi:"studyStoppingConfig"`
	// The configuration info/options for transfer learning. Currently supported for Vertex AI Vizier service, not HyperParameterTuningJob
	TransferLearningConfig GoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigPtrInput `pulumi:"transferLearningConfig"`
}

func (GoogleCloudAiplatformV1beta1StudySpecArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1StudySpec)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1StudySpecArgs) ToGoogleCloudAiplatformV1beta1StudySpecOutput() GoogleCloudAiplatformV1beta1StudySpecOutput {
	return i.ToGoogleCloudAiplatformV1beta1StudySpecOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1StudySpecArgs) ToGoogleCloudAiplatformV1beta1StudySpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1StudySpecOutput)
}

// Represents specification of a Study.
type GoogleCloudAiplatformV1beta1StudySpecOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1StudySpecOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1StudySpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1StudySpecOutput) ToGoogleCloudAiplatformV1beta1StudySpecOutput() GoogleCloudAiplatformV1beta1StudySpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StudySpecOutput) ToGoogleCloudAiplatformV1beta1StudySpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecOutput {
	return o
}

// The search algorithm specified for the Study.
func (o GoogleCloudAiplatformV1beta1StudySpecOutput) Algorithm() GoogleCloudAiplatformV1beta1StudySpecAlgorithmPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpec) *GoogleCloudAiplatformV1beta1StudySpecAlgorithm {
		return v.Algorithm
	}).(GoogleCloudAiplatformV1beta1StudySpecAlgorithmPtrOutput)
}

// The automated early stopping spec using convex stopping rule.
func (o GoogleCloudAiplatformV1beta1StudySpecOutput) ConvexAutomatedStoppingSpec() GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpec) *GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpec {
		return v.ConvexAutomatedStoppingSpec
	}).(GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecPtrOutput)
}

// Deprecated. The automated early stopping using convex stopping rule.
//
// Deprecated: Deprecated. The automated early stopping using convex stopping rule.
func (o GoogleCloudAiplatformV1beta1StudySpecOutput) ConvexStopConfig() GoogleCloudAiplatformV1beta1StudySpecConvexStopConfigPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpec) *GoogleCloudAiplatformV1beta1StudySpecConvexStopConfig {
		return v.ConvexStopConfig
	}).(GoogleCloudAiplatformV1beta1StudySpecConvexStopConfigPtrOutput)
}

// The automated early stopping spec using decay curve rule.
func (o GoogleCloudAiplatformV1beta1StudySpecOutput) DecayCurveStoppingSpec() GoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpec) *GoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpec {
		return v.DecayCurveStoppingSpec
	}).(GoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecPtrOutput)
}

// Describe which measurement selection type will be used
func (o GoogleCloudAiplatformV1beta1StudySpecOutput) MeasurementSelectionType() GoogleCloudAiplatformV1beta1StudySpecMeasurementSelectionTypePtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpec) *GoogleCloudAiplatformV1beta1StudySpecMeasurementSelectionType {
		return v.MeasurementSelectionType
	}).(GoogleCloudAiplatformV1beta1StudySpecMeasurementSelectionTypePtrOutput)
}

// The automated early stopping spec using median rule.
func (o GoogleCloudAiplatformV1beta1StudySpecOutput) MedianAutomatedStoppingSpec() GoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpec) *GoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpec {
		return v.MedianAutomatedStoppingSpec
	}).(GoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecPtrOutput)
}

// Metric specs for the Study.
func (o GoogleCloudAiplatformV1beta1StudySpecOutput) Metrics() GoogleCloudAiplatformV1beta1StudySpecMetricSpecArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpec) []GoogleCloudAiplatformV1beta1StudySpecMetricSpec {
		return v.Metrics
	}).(GoogleCloudAiplatformV1beta1StudySpecMetricSpecArrayOutput)
}

// The observation noise level of the study. Currently only supported by the Vertex AI Vizier service. Not supported by HyperparameterTuningJob or TrainingPipeline.
func (o GoogleCloudAiplatformV1beta1StudySpecOutput) ObservationNoise() GoogleCloudAiplatformV1beta1StudySpecObservationNoisePtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpec) *GoogleCloudAiplatformV1beta1StudySpecObservationNoise {
		return v.ObservationNoise
	}).(GoogleCloudAiplatformV1beta1StudySpecObservationNoisePtrOutput)
}

// The set of parameters to tune.
func (o GoogleCloudAiplatformV1beta1StudySpecOutput) Parameters() GoogleCloudAiplatformV1beta1StudySpecParameterSpecArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpec) []GoogleCloudAiplatformV1beta1StudySpecParameterSpec {
		return v.Parameters
	}).(GoogleCloudAiplatformV1beta1StudySpecParameterSpecArrayOutput)
}

// Conditions for automated stopping of a Study. Enable automated stopping by configuring at least one condition.
func (o GoogleCloudAiplatformV1beta1StudySpecOutput) StudyStoppingConfig() GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpec) *GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfig {
		return v.StudyStoppingConfig
	}).(GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigPtrOutput)
}

// The configuration info/options for transfer learning. Currently supported for Vertex AI Vizier service, not HyperParameterTuningJob
func (o GoogleCloudAiplatformV1beta1StudySpecOutput) TransferLearningConfig() GoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpec) *GoogleCloudAiplatformV1beta1StudySpecTransferLearningConfig {
		return v.TransferLearningConfig
	}).(GoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigPtrOutput)
}

// Configuration for ConvexAutomatedStoppingSpec. When there are enough completed trials (configured by min_measurement_count), for pending trials with enough measurements and steps, the policy first computes an overestimate of the objective value at max_num_steps according to the slope of the incomplete objective value curve. No prediction can be made if the curve is completely flat. If the overestimation is worse than the best objective value of the completed trials, this pending trial will be early-stopped, but a last measurement will be added to the pending trial with max_num_steps and predicted objective value from the autoregression model.
type GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpec struct {
	// The hyper-parameter name used in the tuning job that stands for learning rate. Leave it blank if learning rate is not in a parameter in tuning. The learning_rate is used to estimate the objective value of the ongoing trial.
	LearningRateParameterName *string `pulumi:"learningRateParameterName"`
	// Steps used in predicting the final objective for early stopped trials. In general, it's set to be the same as the defined steps in training / tuning. If not defined, it will learn it from the completed trials. When use_steps is false, this field is set to the maximum elapsed seconds.
	MaxStepCount *string `pulumi:"maxStepCount"`
	// The minimal number of measurements in a Trial. Early-stopping checks will not trigger if less than min_measurement_count+1 completed trials or pending trials with less than min_measurement_count measurements. If not defined, the default value is 5.
	MinMeasurementCount *string `pulumi:"minMeasurementCount"`
	// Minimum number of steps for a trial to complete. Trials which do not have a measurement with step_count > min_step_count won't be considered for early stopping. It's ok to set it to 0, and a trial can be early stopped at any stage. By default, min_step_count is set to be one-tenth of the max_step_count. When use_elapsed_duration is true, this field is set to the minimum elapsed seconds.
	MinStepCount *string `pulumi:"minStepCount"`
	// ConvexAutomatedStoppingSpec by default only updates the trials that needs to be early stopped using a newly trained auto-regressive model. When this flag is set to True, all stopped trials from the beginning are potentially updated in terms of their `final_measurement`. Also, note that the training logic of autoregressive models is different in this case. Enabling this option has shown better results and this may be the default option in the future.
	UpdateAllStoppedTrials *bool `pulumi:"updateAllStoppedTrials"`
	// This bool determines whether or not the rule is applied based on elapsed_secs or steps. If use_elapsed_duration==false, the early stopping decision is made according to the predicted objective values according to the target steps. If use_elapsed_duration==true, elapsed_secs is used instead of steps. Also, in this case, the parameters max_num_steps and min_num_steps are overloaded to contain max_elapsed_seconds and min_elapsed_seconds.
	UseElapsedDuration *bool `pulumi:"useElapsedDuration"`
}

// GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecInput is an input type that accepts GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecArgs and GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecInput` via:
//
//	GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecArgs{...}
type GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecOutput() GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecOutput
	ToGoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecOutput
}

// Configuration for ConvexAutomatedStoppingSpec. When there are enough completed trials (configured by min_measurement_count), for pending trials with enough measurements and steps, the policy first computes an overestimate of the objective value at max_num_steps according to the slope of the incomplete objective value curve. No prediction can be made if the curve is completely flat. If the overestimation is worse than the best objective value of the completed trials, this pending trial will be early-stopped, but a last measurement will be added to the pending trial with max_num_steps and predicted objective value from the autoregression model.
type GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecArgs struct {
	// The hyper-parameter name used in the tuning job that stands for learning rate. Leave it blank if learning rate is not in a parameter in tuning. The learning_rate is used to estimate the objective value of the ongoing trial.
	LearningRateParameterName pulumi.StringPtrInput `pulumi:"learningRateParameterName"`
	// Steps used in predicting the final objective for early stopped trials. In general, it's set to be the same as the defined steps in training / tuning. If not defined, it will learn it from the completed trials. When use_steps is false, this field is set to the maximum elapsed seconds.
	MaxStepCount pulumi.StringPtrInput `pulumi:"maxStepCount"`
	// The minimal number of measurements in a Trial. Early-stopping checks will not trigger if less than min_measurement_count+1 completed trials or pending trials with less than min_measurement_count measurements. If not defined, the default value is 5.
	MinMeasurementCount pulumi.StringPtrInput `pulumi:"minMeasurementCount"`
	// Minimum number of steps for a trial to complete. Trials which do not have a measurement with step_count > min_step_count won't be considered for early stopping. It's ok to set it to 0, and a trial can be early stopped at any stage. By default, min_step_count is set to be one-tenth of the max_step_count. When use_elapsed_duration is true, this field is set to the minimum elapsed seconds.
	MinStepCount pulumi.StringPtrInput `pulumi:"minStepCount"`
	// ConvexAutomatedStoppingSpec by default only updates the trials that needs to be early stopped using a newly trained auto-regressive model. When this flag is set to True, all stopped trials from the beginning are potentially updated in terms of their `final_measurement`. Also, note that the training logic of autoregressive models is different in this case. Enabling this option has shown better results and this may be the default option in the future.
	UpdateAllStoppedTrials pulumi.BoolPtrInput `pulumi:"updateAllStoppedTrials"`
	// This bool determines whether or not the rule is applied based on elapsed_secs or steps. If use_elapsed_duration==false, the early stopping decision is made according to the predicted objective values according to the target steps. If use_elapsed_duration==true, elapsed_secs is used instead of steps. Also, in this case, the parameters max_num_steps and min_num_steps are overloaded to contain max_elapsed_seconds and min_elapsed_seconds.
	UseElapsedDuration pulumi.BoolPtrInput `pulumi:"useElapsedDuration"`
}

func (GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpec)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecArgs) ToGoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecOutput() GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecOutput {
	return i.ToGoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecArgs) ToGoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecOutput)
}

func (i GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecArgs) ToGoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecPtrOutput() GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecArgs) ToGoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecOutput).ToGoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecArgs, GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecPtr and GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecPtrOutput() GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecPtrOutput
	ToGoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecPtrOutput
}

type googleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecPtrType GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecArgs

func GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecPtr(v *GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecArgs) GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecPtrInput {
	return (*googleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecPtrType)(v)
}

func (*googleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpec)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecPtrType) ToGoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecPtrOutput() GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecPtrType) ToGoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecPtrOutput)
}

// Configuration for ConvexAutomatedStoppingSpec. When there are enough completed trials (configured by min_measurement_count), for pending trials with enough measurements and steps, the policy first computes an overestimate of the objective value at max_num_steps according to the slope of the incomplete objective value curve. No prediction can be made if the curve is completely flat. If the overestimation is worse than the best objective value of the completed trials, this pending trial will be early-stopped, but a last measurement will be added to the pending trial with max_num_steps and predicted objective value from the autoregression model.
type GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecOutput) ToGoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecOutput() GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecOutput) ToGoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecOutput) ToGoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecPtrOutput() GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecOutput) ToGoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpec) *GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpec {
		return &v
	}).(GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecPtrOutput)
}

// The hyper-parameter name used in the tuning job that stands for learning rate. Leave it blank if learning rate is not in a parameter in tuning. The learning_rate is used to estimate the objective value of the ongoing trial.
func (o GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecOutput) LearningRateParameterName() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpec) *string {
		return v.LearningRateParameterName
	}).(pulumi.StringPtrOutput)
}

// Steps used in predicting the final objective for early stopped trials. In general, it's set to be the same as the defined steps in training / tuning. If not defined, it will learn it from the completed trials. When use_steps is false, this field is set to the maximum elapsed seconds.
func (o GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecOutput) MaxStepCount() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpec) *string {
		return v.MaxStepCount
	}).(pulumi.StringPtrOutput)
}

// The minimal number of measurements in a Trial. Early-stopping checks will not trigger if less than min_measurement_count+1 completed trials or pending trials with less than min_measurement_count measurements. If not defined, the default value is 5.
func (o GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecOutput) MinMeasurementCount() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpec) *string {
		return v.MinMeasurementCount
	}).(pulumi.StringPtrOutput)
}

// Minimum number of steps for a trial to complete. Trials which do not have a measurement with step_count > min_step_count won't be considered for early stopping. It's ok to set it to 0, and a trial can be early stopped at any stage. By default, min_step_count is set to be one-tenth of the max_step_count. When use_elapsed_duration is true, this field is set to the minimum elapsed seconds.
func (o GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecOutput) MinStepCount() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpec) *string {
		return v.MinStepCount
	}).(pulumi.StringPtrOutput)
}

// ConvexAutomatedStoppingSpec by default only updates the trials that needs to be early stopped using a newly trained auto-regressive model. When this flag is set to True, all stopped trials from the beginning are potentially updated in terms of their `final_measurement`. Also, note that the training logic of autoregressive models is different in this case. Enabling this option has shown better results and this may be the default option in the future.
func (o GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecOutput) UpdateAllStoppedTrials() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpec) *bool {
		return v.UpdateAllStoppedTrials
	}).(pulumi.BoolPtrOutput)
}

// This bool determines whether or not the rule is applied based on elapsed_secs or steps. If use_elapsed_duration==false, the early stopping decision is made according to the predicted objective values according to the target steps. If use_elapsed_duration==true, elapsed_secs is used instead of steps. Also, in this case, the parameters max_num_steps and min_num_steps are overloaded to contain max_elapsed_seconds and min_elapsed_seconds.
func (o GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecOutput) UseElapsedDuration() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpec) *bool {
		return v.UseElapsedDuration
	}).(pulumi.BoolPtrOutput)
}

type GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecPtrOutput) ToGoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecPtrOutput() GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecPtrOutput) ToGoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecPtrOutput) Elem() GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpec) GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpec {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpec
		return ret
	}).(GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecOutput)
}

// The hyper-parameter name used in the tuning job that stands for learning rate. Leave it blank if learning rate is not in a parameter in tuning. The learning_rate is used to estimate the objective value of the ongoing trial.
func (o GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecPtrOutput) LearningRateParameterName() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpec) *string {
		if v == nil {
			return nil
		}
		return v.LearningRateParameterName
	}).(pulumi.StringPtrOutput)
}

// Steps used in predicting the final objective for early stopped trials. In general, it's set to be the same as the defined steps in training / tuning. If not defined, it will learn it from the completed trials. When use_steps is false, this field is set to the maximum elapsed seconds.
func (o GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecPtrOutput) MaxStepCount() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpec) *string {
		if v == nil {
			return nil
		}
		return v.MaxStepCount
	}).(pulumi.StringPtrOutput)
}

// The minimal number of measurements in a Trial. Early-stopping checks will not trigger if less than min_measurement_count+1 completed trials or pending trials with less than min_measurement_count measurements. If not defined, the default value is 5.
func (o GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecPtrOutput) MinMeasurementCount() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpec) *string {
		if v == nil {
			return nil
		}
		return v.MinMeasurementCount
	}).(pulumi.StringPtrOutput)
}

// Minimum number of steps for a trial to complete. Trials which do not have a measurement with step_count > min_step_count won't be considered for early stopping. It's ok to set it to 0, and a trial can be early stopped at any stage. By default, min_step_count is set to be one-tenth of the max_step_count. When use_elapsed_duration is true, this field is set to the minimum elapsed seconds.
func (o GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecPtrOutput) MinStepCount() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpec) *string {
		if v == nil {
			return nil
		}
		return v.MinStepCount
	}).(pulumi.StringPtrOutput)
}

// ConvexAutomatedStoppingSpec by default only updates the trials that needs to be early stopped using a newly trained auto-regressive model. When this flag is set to True, all stopped trials from the beginning are potentially updated in terms of their `final_measurement`. Also, note that the training logic of autoregressive models is different in this case. Enabling this option has shown better results and this may be the default option in the future.
func (o GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecPtrOutput) UpdateAllStoppedTrials() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpec) *bool {
		if v == nil {
			return nil
		}
		return v.UpdateAllStoppedTrials
	}).(pulumi.BoolPtrOutput)
}

// This bool determines whether or not the rule is applied based on elapsed_secs or steps. If use_elapsed_duration==false, the early stopping decision is made according to the predicted objective values according to the target steps. If use_elapsed_duration==true, elapsed_secs is used instead of steps. Also, in this case, the parameters max_num_steps and min_num_steps are overloaded to contain max_elapsed_seconds and min_elapsed_seconds.
func (o GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecPtrOutput) UseElapsedDuration() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpec) *bool {
		if v == nil {
			return nil
		}
		return v.UseElapsedDuration
	}).(pulumi.BoolPtrOutput)
}

// Configuration for ConvexAutomatedStoppingSpec. When there are enough completed trials (configured by min_measurement_count), for pending trials with enough measurements and steps, the policy first computes an overestimate of the objective value at max_num_steps according to the slope of the incomplete objective value curve. No prediction can be made if the curve is completely flat. If the overestimation is worse than the best objective value of the completed trials, this pending trial will be early-stopped, but a last measurement will be added to the pending trial with max_num_steps and predicted objective value from the autoregression model.
type GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecResponse struct {
	// The hyper-parameter name used in the tuning job that stands for learning rate. Leave it blank if learning rate is not in a parameter in tuning. The learning_rate is used to estimate the objective value of the ongoing trial.
	LearningRateParameterName string `pulumi:"learningRateParameterName"`
	// Steps used in predicting the final objective for early stopped trials. In general, it's set to be the same as the defined steps in training / tuning. If not defined, it will learn it from the completed trials. When use_steps is false, this field is set to the maximum elapsed seconds.
	MaxStepCount string `pulumi:"maxStepCount"`
	// The minimal number of measurements in a Trial. Early-stopping checks will not trigger if less than min_measurement_count+1 completed trials or pending trials with less than min_measurement_count measurements. If not defined, the default value is 5.
	MinMeasurementCount string `pulumi:"minMeasurementCount"`
	// Minimum number of steps for a trial to complete. Trials which do not have a measurement with step_count > min_step_count won't be considered for early stopping. It's ok to set it to 0, and a trial can be early stopped at any stage. By default, min_step_count is set to be one-tenth of the max_step_count. When use_elapsed_duration is true, this field is set to the minimum elapsed seconds.
	MinStepCount string `pulumi:"minStepCount"`
	// ConvexAutomatedStoppingSpec by default only updates the trials that needs to be early stopped using a newly trained auto-regressive model. When this flag is set to True, all stopped trials from the beginning are potentially updated in terms of their `final_measurement`. Also, note that the training logic of autoregressive models is different in this case. Enabling this option has shown better results and this may be the default option in the future.
	UpdateAllStoppedTrials bool `pulumi:"updateAllStoppedTrials"`
	// This bool determines whether or not the rule is applied based on elapsed_secs or steps. If use_elapsed_duration==false, the early stopping decision is made according to the predicted objective values according to the target steps. If use_elapsed_duration==true, elapsed_secs is used instead of steps. Also, in this case, the parameters max_num_steps and min_num_steps are overloaded to contain max_elapsed_seconds and min_elapsed_seconds.
	UseElapsedDuration bool `pulumi:"useElapsedDuration"`
}

// Configuration for ConvexAutomatedStoppingSpec. When there are enough completed trials (configured by min_measurement_count), for pending trials with enough measurements and steps, the policy first computes an overestimate of the objective value at max_num_steps according to the slope of the incomplete objective value curve. No prediction can be made if the curve is completely flat. If the overestimation is worse than the best objective value of the completed trials, this pending trial will be early-stopped, but a last measurement will be added to the pending trial with max_num_steps and predicted objective value from the autoregression model.
type GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecResponseOutput) ToGoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecResponseOutput() GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecResponseOutput) ToGoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecResponseOutput {
	return o
}

// The hyper-parameter name used in the tuning job that stands for learning rate. Leave it blank if learning rate is not in a parameter in tuning. The learning_rate is used to estimate the objective value of the ongoing trial.
func (o GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecResponseOutput) LearningRateParameterName() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecResponse) string {
		return v.LearningRateParameterName
	}).(pulumi.StringOutput)
}

// Steps used in predicting the final objective for early stopped trials. In general, it's set to be the same as the defined steps in training / tuning. If not defined, it will learn it from the completed trials. When use_steps is false, this field is set to the maximum elapsed seconds.
func (o GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecResponseOutput) MaxStepCount() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecResponse) string {
		return v.MaxStepCount
	}).(pulumi.StringOutput)
}

// The minimal number of measurements in a Trial. Early-stopping checks will not trigger if less than min_measurement_count+1 completed trials or pending trials with less than min_measurement_count measurements. If not defined, the default value is 5.
func (o GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecResponseOutput) MinMeasurementCount() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecResponse) string {
		return v.MinMeasurementCount
	}).(pulumi.StringOutput)
}

// Minimum number of steps for a trial to complete. Trials which do not have a measurement with step_count > min_step_count won't be considered for early stopping. It's ok to set it to 0, and a trial can be early stopped at any stage. By default, min_step_count is set to be one-tenth of the max_step_count. When use_elapsed_duration is true, this field is set to the minimum elapsed seconds.
func (o GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecResponseOutput) MinStepCount() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecResponse) string {
		return v.MinStepCount
	}).(pulumi.StringOutput)
}

// ConvexAutomatedStoppingSpec by default only updates the trials that needs to be early stopped using a newly trained auto-regressive model. When this flag is set to True, all stopped trials from the beginning are potentially updated in terms of their `final_measurement`. Also, note that the training logic of autoregressive models is different in this case. Enabling this option has shown better results and this may be the default option in the future.
func (o GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecResponseOutput) UpdateAllStoppedTrials() pulumi.BoolOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecResponse) bool {
		return v.UpdateAllStoppedTrials
	}).(pulumi.BoolOutput)
}

// This bool determines whether or not the rule is applied based on elapsed_secs or steps. If use_elapsed_duration==false, the early stopping decision is made according to the predicted objective values according to the target steps. If use_elapsed_duration==true, elapsed_secs is used instead of steps. Also, in this case, the parameters max_num_steps and min_num_steps are overloaded to contain max_elapsed_seconds and min_elapsed_seconds.
func (o GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecResponseOutput) UseElapsedDuration() pulumi.BoolOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecResponse) bool {
		return v.UseElapsedDuration
	}).(pulumi.BoolOutput)
}

// Configuration for ConvexStopPolicy.
type GoogleCloudAiplatformV1beta1StudySpecConvexStopConfig struct {
	// The number of Trial measurements used in autoregressive model for value prediction. A trial won't be considered early stopping if has fewer measurement points.
	AutoregressiveOrder *string `pulumi:"autoregressiveOrder"`
	// The hyper-parameter name used in the tuning job that stands for learning rate. Leave it blank if learning rate is not in a parameter in tuning. The learning_rate is used to estimate the objective value of the ongoing trial.
	LearningRateParameterName *string `pulumi:"learningRateParameterName"`
	// Steps used in predicting the final objective for early stopped trials. In general, it's set to be the same as the defined steps in training / tuning. When use_steps is false, this field is set to the maximum elapsed seconds.
	MaxNumSteps *string `pulumi:"maxNumSteps"`
	// Minimum number of steps for a trial to complete. Trials which do not have a measurement with num_steps > min_num_steps won't be considered for early stopping. It's ok to set it to 0, and a trial can be early stopped at any stage. By default, min_num_steps is set to be one-tenth of the max_num_steps. When use_steps is false, this field is set to the minimum elapsed seconds.
	MinNumSteps *string `pulumi:"minNumSteps"`
	// This bool determines whether or not the rule is applied based on elapsed_secs or steps. If use_seconds==false, the early stopping decision is made according to the predicted objective values according to the target steps. If use_seconds==true, elapsed_secs is used instead of steps. Also, in this case, the parameters max_num_steps and min_num_steps are overloaded to contain max_elapsed_seconds and min_elapsed_seconds.
	UseSeconds *bool `pulumi:"useSeconds"`
}

// GoogleCloudAiplatformV1beta1StudySpecConvexStopConfigInput is an input type that accepts GoogleCloudAiplatformV1beta1StudySpecConvexStopConfigArgs and GoogleCloudAiplatformV1beta1StudySpecConvexStopConfigOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1StudySpecConvexStopConfigInput` via:
//
//	GoogleCloudAiplatformV1beta1StudySpecConvexStopConfigArgs{...}
type GoogleCloudAiplatformV1beta1StudySpecConvexStopConfigInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1StudySpecConvexStopConfigOutput() GoogleCloudAiplatformV1beta1StudySpecConvexStopConfigOutput
	ToGoogleCloudAiplatformV1beta1StudySpecConvexStopConfigOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1StudySpecConvexStopConfigOutput
}

// Configuration for ConvexStopPolicy.
type GoogleCloudAiplatformV1beta1StudySpecConvexStopConfigArgs struct {
	// The number of Trial measurements used in autoregressive model for value prediction. A trial won't be considered early stopping if has fewer measurement points.
	AutoregressiveOrder pulumi.StringPtrInput `pulumi:"autoregressiveOrder"`
	// The hyper-parameter name used in the tuning job that stands for learning rate. Leave it blank if learning rate is not in a parameter in tuning. The learning_rate is used to estimate the objective value of the ongoing trial.
	LearningRateParameterName pulumi.StringPtrInput `pulumi:"learningRateParameterName"`
	// Steps used in predicting the final objective for early stopped trials. In general, it's set to be the same as the defined steps in training / tuning. When use_steps is false, this field is set to the maximum elapsed seconds.
	MaxNumSteps pulumi.StringPtrInput `pulumi:"maxNumSteps"`
	// Minimum number of steps for a trial to complete. Trials which do not have a measurement with num_steps > min_num_steps won't be considered for early stopping. It's ok to set it to 0, and a trial can be early stopped at any stage. By default, min_num_steps is set to be one-tenth of the max_num_steps. When use_steps is false, this field is set to the minimum elapsed seconds.
	MinNumSteps pulumi.StringPtrInput `pulumi:"minNumSteps"`
	// This bool determines whether or not the rule is applied based on elapsed_secs or steps. If use_seconds==false, the early stopping decision is made according to the predicted objective values according to the target steps. If use_seconds==true, elapsed_secs is used instead of steps. Also, in this case, the parameters max_num_steps and min_num_steps are overloaded to contain max_elapsed_seconds and min_elapsed_seconds.
	UseSeconds pulumi.BoolPtrInput `pulumi:"useSeconds"`
}

func (GoogleCloudAiplatformV1beta1StudySpecConvexStopConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1StudySpecConvexStopConfig)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1StudySpecConvexStopConfigArgs) ToGoogleCloudAiplatformV1beta1StudySpecConvexStopConfigOutput() GoogleCloudAiplatformV1beta1StudySpecConvexStopConfigOutput {
	return i.ToGoogleCloudAiplatformV1beta1StudySpecConvexStopConfigOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1StudySpecConvexStopConfigArgs) ToGoogleCloudAiplatformV1beta1StudySpecConvexStopConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecConvexStopConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1StudySpecConvexStopConfigOutput)
}

func (i GoogleCloudAiplatformV1beta1StudySpecConvexStopConfigArgs) ToGoogleCloudAiplatformV1beta1StudySpecConvexStopConfigPtrOutput() GoogleCloudAiplatformV1beta1StudySpecConvexStopConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1StudySpecConvexStopConfigPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1StudySpecConvexStopConfigArgs) ToGoogleCloudAiplatformV1beta1StudySpecConvexStopConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecConvexStopConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1StudySpecConvexStopConfigOutput).ToGoogleCloudAiplatformV1beta1StudySpecConvexStopConfigPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1StudySpecConvexStopConfigPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1StudySpecConvexStopConfigArgs, GoogleCloudAiplatformV1beta1StudySpecConvexStopConfigPtr and GoogleCloudAiplatformV1beta1StudySpecConvexStopConfigPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1StudySpecConvexStopConfigPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1StudySpecConvexStopConfigArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1StudySpecConvexStopConfigPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1StudySpecConvexStopConfigPtrOutput() GoogleCloudAiplatformV1beta1StudySpecConvexStopConfigPtrOutput
	ToGoogleCloudAiplatformV1beta1StudySpecConvexStopConfigPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1StudySpecConvexStopConfigPtrOutput
}

type googleCloudAiplatformV1beta1StudySpecConvexStopConfigPtrType GoogleCloudAiplatformV1beta1StudySpecConvexStopConfigArgs

func GoogleCloudAiplatformV1beta1StudySpecConvexStopConfigPtr(v *GoogleCloudAiplatformV1beta1StudySpecConvexStopConfigArgs) GoogleCloudAiplatformV1beta1StudySpecConvexStopConfigPtrInput {
	return (*googleCloudAiplatformV1beta1StudySpecConvexStopConfigPtrType)(v)
}

func (*googleCloudAiplatformV1beta1StudySpecConvexStopConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1StudySpecConvexStopConfig)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1StudySpecConvexStopConfigPtrType) ToGoogleCloudAiplatformV1beta1StudySpecConvexStopConfigPtrOutput() GoogleCloudAiplatformV1beta1StudySpecConvexStopConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1StudySpecConvexStopConfigPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1StudySpecConvexStopConfigPtrType) ToGoogleCloudAiplatformV1beta1StudySpecConvexStopConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecConvexStopConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1StudySpecConvexStopConfigPtrOutput)
}

// Configuration for ConvexStopPolicy.
type GoogleCloudAiplatformV1beta1StudySpecConvexStopConfigOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1StudySpecConvexStopConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1StudySpecConvexStopConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1StudySpecConvexStopConfigOutput) ToGoogleCloudAiplatformV1beta1StudySpecConvexStopConfigOutput() GoogleCloudAiplatformV1beta1StudySpecConvexStopConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StudySpecConvexStopConfigOutput) ToGoogleCloudAiplatformV1beta1StudySpecConvexStopConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecConvexStopConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StudySpecConvexStopConfigOutput) ToGoogleCloudAiplatformV1beta1StudySpecConvexStopConfigPtrOutput() GoogleCloudAiplatformV1beta1StudySpecConvexStopConfigPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1StudySpecConvexStopConfigPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1StudySpecConvexStopConfigOutput) ToGoogleCloudAiplatformV1beta1StudySpecConvexStopConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecConvexStopConfigPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1StudySpecConvexStopConfig) *GoogleCloudAiplatformV1beta1StudySpecConvexStopConfig {
		return &v
	}).(GoogleCloudAiplatformV1beta1StudySpecConvexStopConfigPtrOutput)
}

// The number of Trial measurements used in autoregressive model for value prediction. A trial won't be considered early stopping if has fewer measurement points.
func (o GoogleCloudAiplatformV1beta1StudySpecConvexStopConfigOutput) AutoregressiveOrder() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecConvexStopConfig) *string { return v.AutoregressiveOrder }).(pulumi.StringPtrOutput)
}

// The hyper-parameter name used in the tuning job that stands for learning rate. Leave it blank if learning rate is not in a parameter in tuning. The learning_rate is used to estimate the objective value of the ongoing trial.
func (o GoogleCloudAiplatformV1beta1StudySpecConvexStopConfigOutput) LearningRateParameterName() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecConvexStopConfig) *string {
		return v.LearningRateParameterName
	}).(pulumi.StringPtrOutput)
}

// Steps used in predicting the final objective for early stopped trials. In general, it's set to be the same as the defined steps in training / tuning. When use_steps is false, this field is set to the maximum elapsed seconds.
func (o GoogleCloudAiplatformV1beta1StudySpecConvexStopConfigOutput) MaxNumSteps() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecConvexStopConfig) *string { return v.MaxNumSteps }).(pulumi.StringPtrOutput)
}

// Minimum number of steps for a trial to complete. Trials which do not have a measurement with num_steps > min_num_steps won't be considered for early stopping. It's ok to set it to 0, and a trial can be early stopped at any stage. By default, min_num_steps is set to be one-tenth of the max_num_steps. When use_steps is false, this field is set to the minimum elapsed seconds.
func (o GoogleCloudAiplatformV1beta1StudySpecConvexStopConfigOutput) MinNumSteps() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecConvexStopConfig) *string { return v.MinNumSteps }).(pulumi.StringPtrOutput)
}

// This bool determines whether or not the rule is applied based on elapsed_secs or steps. If use_seconds==false, the early stopping decision is made according to the predicted objective values according to the target steps. If use_seconds==true, elapsed_secs is used instead of steps. Also, in this case, the parameters max_num_steps and min_num_steps are overloaded to contain max_elapsed_seconds and min_elapsed_seconds.
func (o GoogleCloudAiplatformV1beta1StudySpecConvexStopConfigOutput) UseSeconds() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecConvexStopConfig) *bool { return v.UseSeconds }).(pulumi.BoolPtrOutput)
}

type GoogleCloudAiplatformV1beta1StudySpecConvexStopConfigPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1StudySpecConvexStopConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1StudySpecConvexStopConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1StudySpecConvexStopConfigPtrOutput) ToGoogleCloudAiplatformV1beta1StudySpecConvexStopConfigPtrOutput() GoogleCloudAiplatformV1beta1StudySpecConvexStopConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StudySpecConvexStopConfigPtrOutput) ToGoogleCloudAiplatformV1beta1StudySpecConvexStopConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecConvexStopConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StudySpecConvexStopConfigPtrOutput) Elem() GoogleCloudAiplatformV1beta1StudySpecConvexStopConfigOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1StudySpecConvexStopConfig) GoogleCloudAiplatformV1beta1StudySpecConvexStopConfig {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1StudySpecConvexStopConfig
		return ret
	}).(GoogleCloudAiplatformV1beta1StudySpecConvexStopConfigOutput)
}

// The number of Trial measurements used in autoregressive model for value prediction. A trial won't be considered early stopping if has fewer measurement points.
func (o GoogleCloudAiplatformV1beta1StudySpecConvexStopConfigPtrOutput) AutoregressiveOrder() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1StudySpecConvexStopConfig) *string {
		if v == nil {
			return nil
		}
		return v.AutoregressiveOrder
	}).(pulumi.StringPtrOutput)
}

// The hyper-parameter name used in the tuning job that stands for learning rate. Leave it blank if learning rate is not in a parameter in tuning. The learning_rate is used to estimate the objective value of the ongoing trial.
func (o GoogleCloudAiplatformV1beta1StudySpecConvexStopConfigPtrOutput) LearningRateParameterName() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1StudySpecConvexStopConfig) *string {
		if v == nil {
			return nil
		}
		return v.LearningRateParameterName
	}).(pulumi.StringPtrOutput)
}

// Steps used in predicting the final objective for early stopped trials. In general, it's set to be the same as the defined steps in training / tuning. When use_steps is false, this field is set to the maximum elapsed seconds.
func (o GoogleCloudAiplatformV1beta1StudySpecConvexStopConfigPtrOutput) MaxNumSteps() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1StudySpecConvexStopConfig) *string {
		if v == nil {
			return nil
		}
		return v.MaxNumSteps
	}).(pulumi.StringPtrOutput)
}

// Minimum number of steps for a trial to complete. Trials which do not have a measurement with num_steps > min_num_steps won't be considered for early stopping. It's ok to set it to 0, and a trial can be early stopped at any stage. By default, min_num_steps is set to be one-tenth of the max_num_steps. When use_steps is false, this field is set to the minimum elapsed seconds.
func (o GoogleCloudAiplatformV1beta1StudySpecConvexStopConfigPtrOutput) MinNumSteps() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1StudySpecConvexStopConfig) *string {
		if v == nil {
			return nil
		}
		return v.MinNumSteps
	}).(pulumi.StringPtrOutput)
}

// This bool determines whether or not the rule is applied based on elapsed_secs or steps. If use_seconds==false, the early stopping decision is made according to the predicted objective values according to the target steps. If use_seconds==true, elapsed_secs is used instead of steps. Also, in this case, the parameters max_num_steps and min_num_steps are overloaded to contain max_elapsed_seconds and min_elapsed_seconds.
func (o GoogleCloudAiplatformV1beta1StudySpecConvexStopConfigPtrOutput) UseSeconds() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1StudySpecConvexStopConfig) *bool {
		if v == nil {
			return nil
		}
		return v.UseSeconds
	}).(pulumi.BoolPtrOutput)
}

// Configuration for ConvexStopPolicy.
type GoogleCloudAiplatformV1beta1StudySpecConvexStopConfigResponse struct {
	// The number of Trial measurements used in autoregressive model for value prediction. A trial won't be considered early stopping if has fewer measurement points.
	AutoregressiveOrder string `pulumi:"autoregressiveOrder"`
	// The hyper-parameter name used in the tuning job that stands for learning rate. Leave it blank if learning rate is not in a parameter in tuning. The learning_rate is used to estimate the objective value of the ongoing trial.
	LearningRateParameterName string `pulumi:"learningRateParameterName"`
	// Steps used in predicting the final objective for early stopped trials. In general, it's set to be the same as the defined steps in training / tuning. When use_steps is false, this field is set to the maximum elapsed seconds.
	MaxNumSteps string `pulumi:"maxNumSteps"`
	// Minimum number of steps for a trial to complete. Trials which do not have a measurement with num_steps > min_num_steps won't be considered for early stopping. It's ok to set it to 0, and a trial can be early stopped at any stage. By default, min_num_steps is set to be one-tenth of the max_num_steps. When use_steps is false, this field is set to the minimum elapsed seconds.
	MinNumSteps string `pulumi:"minNumSteps"`
	// This bool determines whether or not the rule is applied based on elapsed_secs or steps. If use_seconds==false, the early stopping decision is made according to the predicted objective values according to the target steps. If use_seconds==true, elapsed_secs is used instead of steps. Also, in this case, the parameters max_num_steps and min_num_steps are overloaded to contain max_elapsed_seconds and min_elapsed_seconds.
	UseSeconds bool `pulumi:"useSeconds"`
}

// Configuration for ConvexStopPolicy.
type GoogleCloudAiplatformV1beta1StudySpecConvexStopConfigResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1StudySpecConvexStopConfigResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1StudySpecConvexStopConfigResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1StudySpecConvexStopConfigResponseOutput) ToGoogleCloudAiplatformV1beta1StudySpecConvexStopConfigResponseOutput() GoogleCloudAiplatformV1beta1StudySpecConvexStopConfigResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StudySpecConvexStopConfigResponseOutput) ToGoogleCloudAiplatformV1beta1StudySpecConvexStopConfigResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecConvexStopConfigResponseOutput {
	return o
}

// The number of Trial measurements used in autoregressive model for value prediction. A trial won't be considered early stopping if has fewer measurement points.
func (o GoogleCloudAiplatformV1beta1StudySpecConvexStopConfigResponseOutput) AutoregressiveOrder() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecConvexStopConfigResponse) string {
		return v.AutoregressiveOrder
	}).(pulumi.StringOutput)
}

// The hyper-parameter name used in the tuning job that stands for learning rate. Leave it blank if learning rate is not in a parameter in tuning. The learning_rate is used to estimate the objective value of the ongoing trial.
func (o GoogleCloudAiplatformV1beta1StudySpecConvexStopConfigResponseOutput) LearningRateParameterName() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecConvexStopConfigResponse) string {
		return v.LearningRateParameterName
	}).(pulumi.StringOutput)
}

// Steps used in predicting the final objective for early stopped trials. In general, it's set to be the same as the defined steps in training / tuning. When use_steps is false, this field is set to the maximum elapsed seconds.
func (o GoogleCloudAiplatformV1beta1StudySpecConvexStopConfigResponseOutput) MaxNumSteps() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecConvexStopConfigResponse) string { return v.MaxNumSteps }).(pulumi.StringOutput)
}

// Minimum number of steps for a trial to complete. Trials which do not have a measurement with num_steps > min_num_steps won't be considered for early stopping. It's ok to set it to 0, and a trial can be early stopped at any stage. By default, min_num_steps is set to be one-tenth of the max_num_steps. When use_steps is false, this field is set to the minimum elapsed seconds.
func (o GoogleCloudAiplatformV1beta1StudySpecConvexStopConfigResponseOutput) MinNumSteps() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecConvexStopConfigResponse) string { return v.MinNumSteps }).(pulumi.StringOutput)
}

// This bool determines whether or not the rule is applied based on elapsed_secs or steps. If use_seconds==false, the early stopping decision is made according to the predicted objective values according to the target steps. If use_seconds==true, elapsed_secs is used instead of steps. Also, in this case, the parameters max_num_steps and min_num_steps are overloaded to contain max_elapsed_seconds and min_elapsed_seconds.
func (o GoogleCloudAiplatformV1beta1StudySpecConvexStopConfigResponseOutput) UseSeconds() pulumi.BoolOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecConvexStopConfigResponse) bool { return v.UseSeconds }).(pulumi.BoolOutput)
}

// The decay curve automated stopping rule builds a Gaussian Process Regressor to predict the final objective value of a Trial based on the already completed Trials and the intermediate measurements of the current Trial. Early stopping is requested for the current Trial if there is very low probability to exceed the optimal value found so far.
type GoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpec struct {
	// True if Measurement.elapsed_duration is used as the x-axis of each Trials Decay Curve. Otherwise, Measurement.step_count will be used as the x-axis.
	UseElapsedDuration *bool `pulumi:"useElapsedDuration"`
}

// GoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecInput is an input type that accepts GoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecArgs and GoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecInput` via:
//
//	GoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecArgs{...}
type GoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecOutput() GoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecOutput
	ToGoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecOutput
}

// The decay curve automated stopping rule builds a Gaussian Process Regressor to predict the final objective value of a Trial based on the already completed Trials and the intermediate measurements of the current Trial. Early stopping is requested for the current Trial if there is very low probability to exceed the optimal value found so far.
type GoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecArgs struct {
	// True if Measurement.elapsed_duration is used as the x-axis of each Trials Decay Curve. Otherwise, Measurement.step_count will be used as the x-axis.
	UseElapsedDuration pulumi.BoolPtrInput `pulumi:"useElapsedDuration"`
}

func (GoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpec)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecArgs) ToGoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecOutput() GoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecOutput {
	return i.ToGoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecArgs) ToGoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecOutput)
}

func (i GoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecArgs) ToGoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecPtrOutput() GoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecArgs) ToGoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecOutput).ToGoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecArgs, GoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecPtr and GoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecPtrOutput() GoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecPtrOutput
	ToGoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecPtrOutput
}

type googleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecPtrType GoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecArgs

func GoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecPtr(v *GoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecArgs) GoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecPtrInput {
	return (*googleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecPtrType)(v)
}

func (*googleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpec)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecPtrType) ToGoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecPtrOutput() GoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecPtrType) ToGoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecPtrOutput)
}

// The decay curve automated stopping rule builds a Gaussian Process Regressor to predict the final objective value of a Trial based on the already completed Trials and the intermediate measurements of the current Trial. Early stopping is requested for the current Trial if there is very low probability to exceed the optimal value found so far.
type GoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecOutput) ToGoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecOutput() GoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecOutput) ToGoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecOutput) ToGoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecPtrOutput() GoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecOutput) ToGoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpec) *GoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpec {
		return &v
	}).(GoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecPtrOutput)
}

// True if Measurement.elapsed_duration is used as the x-axis of each Trials Decay Curve. Otherwise, Measurement.step_count will be used as the x-axis.
func (o GoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecOutput) UseElapsedDuration() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpec) *bool {
		return v.UseElapsedDuration
	}).(pulumi.BoolPtrOutput)
}

type GoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecPtrOutput) ToGoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecPtrOutput() GoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecPtrOutput) ToGoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecPtrOutput) Elem() GoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpec) GoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpec {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpec
		return ret
	}).(GoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecOutput)
}

// True if Measurement.elapsed_duration is used as the x-axis of each Trials Decay Curve. Otherwise, Measurement.step_count will be used as the x-axis.
func (o GoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecPtrOutput) UseElapsedDuration() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpec) *bool {
		if v == nil {
			return nil
		}
		return v.UseElapsedDuration
	}).(pulumi.BoolPtrOutput)
}

// The decay curve automated stopping rule builds a Gaussian Process Regressor to predict the final objective value of a Trial based on the already completed Trials and the intermediate measurements of the current Trial. Early stopping is requested for the current Trial if there is very low probability to exceed the optimal value found so far.
type GoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecResponse struct {
	// True if Measurement.elapsed_duration is used as the x-axis of each Trials Decay Curve. Otherwise, Measurement.step_count will be used as the x-axis.
	UseElapsedDuration bool `pulumi:"useElapsedDuration"`
}

// The decay curve automated stopping rule builds a Gaussian Process Regressor to predict the final objective value of a Trial based on the already completed Trials and the intermediate measurements of the current Trial. Early stopping is requested for the current Trial if there is very low probability to exceed the optimal value found so far.
type GoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecResponseOutput) ToGoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecResponseOutput() GoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecResponseOutput) ToGoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecResponseOutput {
	return o
}

// True if Measurement.elapsed_duration is used as the x-axis of each Trials Decay Curve. Otherwise, Measurement.step_count will be used as the x-axis.
func (o GoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecResponseOutput) UseElapsedDuration() pulumi.BoolOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecResponse) bool {
		return v.UseElapsedDuration
	}).(pulumi.BoolOutput)
}

// The median automated stopping rule stops a pending Trial if the Trial's best objective_value is strictly below the median 'performance' of all completed Trials reported up to the Trial's last measurement. Currently, 'performance' refers to the running average of the objective values reported by the Trial in each measurement.
type GoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpec struct {
	// True if median automated stopping rule applies on Measurement.elapsed_duration. It means that elapsed_duration field of latest measurement of current Trial is used to compute median objective value for each completed Trials.
	UseElapsedDuration *bool `pulumi:"useElapsedDuration"`
}

// GoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecInput is an input type that accepts GoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecArgs and GoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecInput` via:
//
//	GoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecArgs{...}
type GoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecOutput() GoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecOutput
	ToGoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecOutput
}

// The median automated stopping rule stops a pending Trial if the Trial's best objective_value is strictly below the median 'performance' of all completed Trials reported up to the Trial's last measurement. Currently, 'performance' refers to the running average of the objective values reported by the Trial in each measurement.
type GoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecArgs struct {
	// True if median automated stopping rule applies on Measurement.elapsed_duration. It means that elapsed_duration field of latest measurement of current Trial is used to compute median objective value for each completed Trials.
	UseElapsedDuration pulumi.BoolPtrInput `pulumi:"useElapsedDuration"`
}

func (GoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpec)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecArgs) ToGoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecOutput() GoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecOutput {
	return i.ToGoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecArgs) ToGoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecOutput)
}

func (i GoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecArgs) ToGoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecPtrOutput() GoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecArgs) ToGoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecOutput).ToGoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecArgs, GoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecPtr and GoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecPtrOutput() GoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecPtrOutput
	ToGoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecPtrOutput
}

type googleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecPtrType GoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecArgs

func GoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecPtr(v *GoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecArgs) GoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecPtrInput {
	return (*googleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecPtrType)(v)
}

func (*googleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpec)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecPtrType) ToGoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecPtrOutput() GoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecPtrType) ToGoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecPtrOutput)
}

// The median automated stopping rule stops a pending Trial if the Trial's best objective_value is strictly below the median 'performance' of all completed Trials reported up to the Trial's last measurement. Currently, 'performance' refers to the running average of the objective values reported by the Trial in each measurement.
type GoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecOutput) ToGoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecOutput() GoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecOutput) ToGoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecOutput) ToGoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecPtrOutput() GoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecOutput) ToGoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpec) *GoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpec {
		return &v
	}).(GoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecPtrOutput)
}

// True if median automated stopping rule applies on Measurement.elapsed_duration. It means that elapsed_duration field of latest measurement of current Trial is used to compute median objective value for each completed Trials.
func (o GoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecOutput) UseElapsedDuration() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpec) *bool {
		return v.UseElapsedDuration
	}).(pulumi.BoolPtrOutput)
}

type GoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecPtrOutput) ToGoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecPtrOutput() GoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecPtrOutput) ToGoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecPtrOutput) Elem() GoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpec) GoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpec {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpec
		return ret
	}).(GoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecOutput)
}

// True if median automated stopping rule applies on Measurement.elapsed_duration. It means that elapsed_duration field of latest measurement of current Trial is used to compute median objective value for each completed Trials.
func (o GoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecPtrOutput) UseElapsedDuration() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpec) *bool {
		if v == nil {
			return nil
		}
		return v.UseElapsedDuration
	}).(pulumi.BoolPtrOutput)
}

// The median automated stopping rule stops a pending Trial if the Trial's best objective_value is strictly below the median 'performance' of all completed Trials reported up to the Trial's last measurement. Currently, 'performance' refers to the running average of the objective values reported by the Trial in each measurement.
type GoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecResponse struct {
	// True if median automated stopping rule applies on Measurement.elapsed_duration. It means that elapsed_duration field of latest measurement of current Trial is used to compute median objective value for each completed Trials.
	UseElapsedDuration bool `pulumi:"useElapsedDuration"`
}

// The median automated stopping rule stops a pending Trial if the Trial's best objective_value is strictly below the median 'performance' of all completed Trials reported up to the Trial's last measurement. Currently, 'performance' refers to the running average of the objective values reported by the Trial in each measurement.
type GoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecResponseOutput) ToGoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecResponseOutput() GoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecResponseOutput) ToGoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecResponseOutput {
	return o
}

// True if median automated stopping rule applies on Measurement.elapsed_duration. It means that elapsed_duration field of latest measurement of current Trial is used to compute median objective value for each completed Trials.
func (o GoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecResponseOutput) UseElapsedDuration() pulumi.BoolOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecResponse) bool {
		return v.UseElapsedDuration
	}).(pulumi.BoolOutput)
}

// Represents a metric to optimize.
type GoogleCloudAiplatformV1beta1StudySpecMetricSpec struct {
	// The optimization goal of the metric.
	Goal GoogleCloudAiplatformV1beta1StudySpecMetricSpecGoal `pulumi:"goal"`
	// The ID of the metric. Must not contain whitespaces and must be unique amongst all MetricSpecs.
	MetricId string `pulumi:"metricId"`
	// Used for safe search. In the case, the metric will be a safety metric. You must provide a separate metric for objective metric.
	SafetyConfig *GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfig `pulumi:"safetyConfig"`
}

// GoogleCloudAiplatformV1beta1StudySpecMetricSpecInput is an input type that accepts GoogleCloudAiplatformV1beta1StudySpecMetricSpecArgs and GoogleCloudAiplatformV1beta1StudySpecMetricSpecOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1StudySpecMetricSpecInput` via:
//
//	GoogleCloudAiplatformV1beta1StudySpecMetricSpecArgs{...}
type GoogleCloudAiplatformV1beta1StudySpecMetricSpecInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1StudySpecMetricSpecOutput() GoogleCloudAiplatformV1beta1StudySpecMetricSpecOutput
	ToGoogleCloudAiplatformV1beta1StudySpecMetricSpecOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1StudySpecMetricSpecOutput
}

// Represents a metric to optimize.
type GoogleCloudAiplatformV1beta1StudySpecMetricSpecArgs struct {
	// The optimization goal of the metric.
	Goal GoogleCloudAiplatformV1beta1StudySpecMetricSpecGoalInput `pulumi:"goal"`
	// The ID of the metric. Must not contain whitespaces and must be unique amongst all MetricSpecs.
	MetricId pulumi.StringInput `pulumi:"metricId"`
	// Used for safe search. In the case, the metric will be a safety metric. You must provide a separate metric for objective metric.
	SafetyConfig GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigPtrInput `pulumi:"safetyConfig"`
}

func (GoogleCloudAiplatformV1beta1StudySpecMetricSpecArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1StudySpecMetricSpec)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1StudySpecMetricSpecArgs) ToGoogleCloudAiplatformV1beta1StudySpecMetricSpecOutput() GoogleCloudAiplatformV1beta1StudySpecMetricSpecOutput {
	return i.ToGoogleCloudAiplatformV1beta1StudySpecMetricSpecOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1StudySpecMetricSpecArgs) ToGoogleCloudAiplatformV1beta1StudySpecMetricSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecMetricSpecOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1StudySpecMetricSpecOutput)
}

// GoogleCloudAiplatformV1beta1StudySpecMetricSpecArrayInput is an input type that accepts GoogleCloudAiplatformV1beta1StudySpecMetricSpecArray and GoogleCloudAiplatformV1beta1StudySpecMetricSpecArrayOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1StudySpecMetricSpecArrayInput` via:
//
//	GoogleCloudAiplatformV1beta1StudySpecMetricSpecArray{ GoogleCloudAiplatformV1beta1StudySpecMetricSpecArgs{...} }
type GoogleCloudAiplatformV1beta1StudySpecMetricSpecArrayInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1StudySpecMetricSpecArrayOutput() GoogleCloudAiplatformV1beta1StudySpecMetricSpecArrayOutput
	ToGoogleCloudAiplatformV1beta1StudySpecMetricSpecArrayOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1StudySpecMetricSpecArrayOutput
}

type GoogleCloudAiplatformV1beta1StudySpecMetricSpecArray []GoogleCloudAiplatformV1beta1StudySpecMetricSpecInput

func (GoogleCloudAiplatformV1beta1StudySpecMetricSpecArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1beta1StudySpecMetricSpec)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1StudySpecMetricSpecArray) ToGoogleCloudAiplatformV1beta1StudySpecMetricSpecArrayOutput() GoogleCloudAiplatformV1beta1StudySpecMetricSpecArrayOutput {
	return i.ToGoogleCloudAiplatformV1beta1StudySpecMetricSpecArrayOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1StudySpecMetricSpecArray) ToGoogleCloudAiplatformV1beta1StudySpecMetricSpecArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecMetricSpecArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1StudySpecMetricSpecArrayOutput)
}

// Represents a metric to optimize.
type GoogleCloudAiplatformV1beta1StudySpecMetricSpecOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1StudySpecMetricSpecOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1StudySpecMetricSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1StudySpecMetricSpecOutput) ToGoogleCloudAiplatformV1beta1StudySpecMetricSpecOutput() GoogleCloudAiplatformV1beta1StudySpecMetricSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StudySpecMetricSpecOutput) ToGoogleCloudAiplatformV1beta1StudySpecMetricSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecMetricSpecOutput {
	return o
}

// The optimization goal of the metric.
func (o GoogleCloudAiplatformV1beta1StudySpecMetricSpecOutput) Goal() GoogleCloudAiplatformV1beta1StudySpecMetricSpecGoalOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecMetricSpec) GoogleCloudAiplatformV1beta1StudySpecMetricSpecGoal {
		return v.Goal
	}).(GoogleCloudAiplatformV1beta1StudySpecMetricSpecGoalOutput)
}

// The ID of the metric. Must not contain whitespaces and must be unique amongst all MetricSpecs.
func (o GoogleCloudAiplatformV1beta1StudySpecMetricSpecOutput) MetricId() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecMetricSpec) string { return v.MetricId }).(pulumi.StringOutput)
}

// Used for safe search. In the case, the metric will be a safety metric. You must provide a separate metric for objective metric.
func (o GoogleCloudAiplatformV1beta1StudySpecMetricSpecOutput) SafetyConfig() GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecMetricSpec) *GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfig {
		return v.SafetyConfig
	}).(GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigPtrOutput)
}

type GoogleCloudAiplatformV1beta1StudySpecMetricSpecArrayOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1StudySpecMetricSpecArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1beta1StudySpecMetricSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1StudySpecMetricSpecArrayOutput) ToGoogleCloudAiplatformV1beta1StudySpecMetricSpecArrayOutput() GoogleCloudAiplatformV1beta1StudySpecMetricSpecArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StudySpecMetricSpecArrayOutput) ToGoogleCloudAiplatformV1beta1StudySpecMetricSpecArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecMetricSpecArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StudySpecMetricSpecArrayOutput) Index(i pulumi.IntInput) GoogleCloudAiplatformV1beta1StudySpecMetricSpecOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GoogleCloudAiplatformV1beta1StudySpecMetricSpec {
		return vs[0].([]GoogleCloudAiplatformV1beta1StudySpecMetricSpec)[vs[1].(int)]
	}).(GoogleCloudAiplatformV1beta1StudySpecMetricSpecOutput)
}

// Represents a metric to optimize.
type GoogleCloudAiplatformV1beta1StudySpecMetricSpecResponse struct {
	// The optimization goal of the metric.
	Goal string `pulumi:"goal"`
	// The ID of the metric. Must not contain whitespaces and must be unique amongst all MetricSpecs.
	MetricId string `pulumi:"metricId"`
	// Used for safe search. In the case, the metric will be a safety metric. You must provide a separate metric for objective metric.
	SafetyConfig GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigResponse `pulumi:"safetyConfig"`
}

// Represents a metric to optimize.
type GoogleCloudAiplatformV1beta1StudySpecMetricSpecResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1StudySpecMetricSpecResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1StudySpecMetricSpecResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1StudySpecMetricSpecResponseOutput) ToGoogleCloudAiplatformV1beta1StudySpecMetricSpecResponseOutput() GoogleCloudAiplatformV1beta1StudySpecMetricSpecResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StudySpecMetricSpecResponseOutput) ToGoogleCloudAiplatformV1beta1StudySpecMetricSpecResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecMetricSpecResponseOutput {
	return o
}

// The optimization goal of the metric.
func (o GoogleCloudAiplatformV1beta1StudySpecMetricSpecResponseOutput) Goal() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecMetricSpecResponse) string { return v.Goal }).(pulumi.StringOutput)
}

// The ID of the metric. Must not contain whitespaces and must be unique amongst all MetricSpecs.
func (o GoogleCloudAiplatformV1beta1StudySpecMetricSpecResponseOutput) MetricId() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecMetricSpecResponse) string { return v.MetricId }).(pulumi.StringOutput)
}

// Used for safe search. In the case, the metric will be a safety metric. You must provide a separate metric for objective metric.
func (o GoogleCloudAiplatformV1beta1StudySpecMetricSpecResponseOutput) SafetyConfig() GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecMetricSpecResponse) GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigResponse {
		return v.SafetyConfig
	}).(GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigResponseOutput)
}

type GoogleCloudAiplatformV1beta1StudySpecMetricSpecResponseArrayOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1StudySpecMetricSpecResponseArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1beta1StudySpecMetricSpecResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1StudySpecMetricSpecResponseArrayOutput) ToGoogleCloudAiplatformV1beta1StudySpecMetricSpecResponseArrayOutput() GoogleCloudAiplatformV1beta1StudySpecMetricSpecResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StudySpecMetricSpecResponseArrayOutput) ToGoogleCloudAiplatformV1beta1StudySpecMetricSpecResponseArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecMetricSpecResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StudySpecMetricSpecResponseArrayOutput) Index(i pulumi.IntInput) GoogleCloudAiplatformV1beta1StudySpecMetricSpecResponseOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GoogleCloudAiplatformV1beta1StudySpecMetricSpecResponse {
		return vs[0].([]GoogleCloudAiplatformV1beta1StudySpecMetricSpecResponse)[vs[1].(int)]
	}).(GoogleCloudAiplatformV1beta1StudySpecMetricSpecResponseOutput)
}

// Used in safe optimization to specify threshold levels and risk tolerance.
type GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfig struct {
	// Desired minimum fraction of safe trials (over total number of trials) that should be targeted by the algorithm at any time during the study (best effort). This should be between 0.0 and 1.0 and a value of 0.0 means that there is no minimum and an algorithm proceeds without targeting any specific fraction. A value of 1.0 means that the algorithm attempts to only Suggest safe Trials.
	DesiredMinSafeTrialsFraction *float64 `pulumi:"desiredMinSafeTrialsFraction"`
	// Safety threshold (boundary value between safe and unsafe). NOTE that if you leave SafetyMetricConfig unset, a default value of 0 will be used.
	SafetyThreshold *float64 `pulumi:"safetyThreshold"`
}

// GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigInput is an input type that accepts GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigArgs and GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigInput` via:
//
//	GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigArgs{...}
type GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigOutput() GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigOutput
	ToGoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigOutput
}

// Used in safe optimization to specify threshold levels and risk tolerance.
type GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigArgs struct {
	// Desired minimum fraction of safe trials (over total number of trials) that should be targeted by the algorithm at any time during the study (best effort). This should be between 0.0 and 1.0 and a value of 0.0 means that there is no minimum and an algorithm proceeds without targeting any specific fraction. A value of 1.0 means that the algorithm attempts to only Suggest safe Trials.
	DesiredMinSafeTrialsFraction pulumi.Float64PtrInput `pulumi:"desiredMinSafeTrialsFraction"`
	// Safety threshold (boundary value between safe and unsafe). NOTE that if you leave SafetyMetricConfig unset, a default value of 0 will be used.
	SafetyThreshold pulumi.Float64PtrInput `pulumi:"safetyThreshold"`
}

func (GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfig)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigArgs) ToGoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigOutput() GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigOutput {
	return i.ToGoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigArgs) ToGoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigOutput)
}

func (i GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigArgs) ToGoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigPtrOutput() GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigArgs) ToGoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigOutput).ToGoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigArgs, GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigPtr and GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigPtrOutput() GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigPtrOutput
	ToGoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigPtrOutput
}

type googleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigPtrType GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigArgs

func GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigPtr(v *GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigArgs) GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigPtrInput {
	return (*googleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigPtrType)(v)
}

func (*googleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfig)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigPtrType) ToGoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigPtrOutput() GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigPtrType) ToGoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigPtrOutput)
}

// Used in safe optimization to specify threshold levels and risk tolerance.
type GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigOutput) ToGoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigOutput() GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigOutput) ToGoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigOutput) ToGoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigPtrOutput() GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigOutput) ToGoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfig) *GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfig {
		return &v
	}).(GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigPtrOutput)
}

// Desired minimum fraction of safe trials (over total number of trials) that should be targeted by the algorithm at any time during the study (best effort). This should be between 0.0 and 1.0 and a value of 0.0 means that there is no minimum and an algorithm proceeds without targeting any specific fraction. A value of 1.0 means that the algorithm attempts to only Suggest safe Trials.
func (o GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigOutput) DesiredMinSafeTrialsFraction() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfig) *float64 {
		return v.DesiredMinSafeTrialsFraction
	}).(pulumi.Float64PtrOutput)
}

// Safety threshold (boundary value between safe and unsafe). NOTE that if you leave SafetyMetricConfig unset, a default value of 0 will be used.
func (o GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigOutput) SafetyThreshold() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfig) *float64 {
		return v.SafetyThreshold
	}).(pulumi.Float64PtrOutput)
}

type GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigPtrOutput) ToGoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigPtrOutput() GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigPtrOutput) ToGoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigPtrOutput) Elem() GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfig) GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfig {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfig
		return ret
	}).(GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigOutput)
}

// Desired minimum fraction of safe trials (over total number of trials) that should be targeted by the algorithm at any time during the study (best effort). This should be between 0.0 and 1.0 and a value of 0.0 means that there is no minimum and an algorithm proceeds without targeting any specific fraction. A value of 1.0 means that the algorithm attempts to only Suggest safe Trials.
func (o GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigPtrOutput) DesiredMinSafeTrialsFraction() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfig) *float64 {
		if v == nil {
			return nil
		}
		return v.DesiredMinSafeTrialsFraction
	}).(pulumi.Float64PtrOutput)
}

// Safety threshold (boundary value between safe and unsafe). NOTE that if you leave SafetyMetricConfig unset, a default value of 0 will be used.
func (o GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigPtrOutput) SafetyThreshold() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfig) *float64 {
		if v == nil {
			return nil
		}
		return v.SafetyThreshold
	}).(pulumi.Float64PtrOutput)
}

// Used in safe optimization to specify threshold levels and risk tolerance.
type GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigResponse struct {
	// Desired minimum fraction of safe trials (over total number of trials) that should be targeted by the algorithm at any time during the study (best effort). This should be between 0.0 and 1.0 and a value of 0.0 means that there is no minimum and an algorithm proceeds without targeting any specific fraction. A value of 1.0 means that the algorithm attempts to only Suggest safe Trials.
	DesiredMinSafeTrialsFraction float64 `pulumi:"desiredMinSafeTrialsFraction"`
	// Safety threshold (boundary value between safe and unsafe). NOTE that if you leave SafetyMetricConfig unset, a default value of 0 will be used.
	SafetyThreshold float64 `pulumi:"safetyThreshold"`
}

// Used in safe optimization to specify threshold levels and risk tolerance.
type GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigResponseOutput) ToGoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigResponseOutput() GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigResponseOutput) ToGoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigResponseOutput {
	return o
}

// Desired minimum fraction of safe trials (over total number of trials) that should be targeted by the algorithm at any time during the study (best effort). This should be between 0.0 and 1.0 and a value of 0.0 means that there is no minimum and an algorithm proceeds without targeting any specific fraction. A value of 1.0 means that the algorithm attempts to only Suggest safe Trials.
func (o GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigResponseOutput) DesiredMinSafeTrialsFraction() pulumi.Float64Output {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigResponse) float64 {
		return v.DesiredMinSafeTrialsFraction
	}).(pulumi.Float64Output)
}

// Safety threshold (boundary value between safe and unsafe). NOTE that if you leave SafetyMetricConfig unset, a default value of 0 will be used.
func (o GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigResponseOutput) SafetyThreshold() pulumi.Float64Output {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigResponse) float64 {
		return v.SafetyThreshold
	}).(pulumi.Float64Output)
}

// Represents a single parameter to optimize.
type GoogleCloudAiplatformV1beta1StudySpecParameterSpec struct {
	// The value spec for a 'CATEGORICAL' parameter.
	CategoricalValueSpec *GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpec `pulumi:"categoricalValueSpec"`
	// A conditional parameter node is active if the parameter's value matches the conditional node's parent_value_condition. If two items in conditional_parameter_specs have the same name, they must have disjoint parent_value_condition.
	ConditionalParameterSpecs []GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpec `pulumi:"conditionalParameterSpecs"`
	// The value spec for a 'DISCRETE' parameter.
	DiscreteValueSpec *GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpec `pulumi:"discreteValueSpec"`
	// The value spec for a 'DOUBLE' parameter.
	DoubleValueSpec *GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpec `pulumi:"doubleValueSpec"`
	// The value spec for an 'INTEGER' parameter.
	IntegerValueSpec *GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpec `pulumi:"integerValueSpec"`
	// The ID of the parameter. Must not contain whitespaces and must be unique amongst all ParameterSpecs.
	ParameterId string `pulumi:"parameterId"`
	// How the parameter should be scaled. Leave unset for `CATEGORICAL` parameters.
	ScaleType *GoogleCloudAiplatformV1beta1StudySpecParameterSpecScaleType `pulumi:"scaleType"`
}

// GoogleCloudAiplatformV1beta1StudySpecParameterSpecInput is an input type that accepts GoogleCloudAiplatformV1beta1StudySpecParameterSpecArgs and GoogleCloudAiplatformV1beta1StudySpecParameterSpecOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1StudySpecParameterSpecInput` via:
//
//	GoogleCloudAiplatformV1beta1StudySpecParameterSpecArgs{...}
type GoogleCloudAiplatformV1beta1StudySpecParameterSpecInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecOutput() GoogleCloudAiplatformV1beta1StudySpecParameterSpecOutput
	ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1StudySpecParameterSpecOutput
}

// Represents a single parameter to optimize.
type GoogleCloudAiplatformV1beta1StudySpecParameterSpecArgs struct {
	// The value spec for a 'CATEGORICAL' parameter.
	CategoricalValueSpec GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecPtrInput `pulumi:"categoricalValueSpec"`
	// A conditional parameter node is active if the parameter's value matches the conditional node's parent_value_condition. If two items in conditional_parameter_specs have the same name, they must have disjoint parent_value_condition.
	ConditionalParameterSpecs GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecArrayInput `pulumi:"conditionalParameterSpecs"`
	// The value spec for a 'DISCRETE' parameter.
	DiscreteValueSpec GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecPtrInput `pulumi:"discreteValueSpec"`
	// The value spec for a 'DOUBLE' parameter.
	DoubleValueSpec GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecPtrInput `pulumi:"doubleValueSpec"`
	// The value spec for an 'INTEGER' parameter.
	IntegerValueSpec GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecPtrInput `pulumi:"integerValueSpec"`
	// The ID of the parameter. Must not contain whitespaces and must be unique amongst all ParameterSpecs.
	ParameterId pulumi.StringInput `pulumi:"parameterId"`
	// How the parameter should be scaled. Leave unset for `CATEGORICAL` parameters.
	ScaleType GoogleCloudAiplatformV1beta1StudySpecParameterSpecScaleTypePtrInput `pulumi:"scaleType"`
}

func (GoogleCloudAiplatformV1beta1StudySpecParameterSpecArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1StudySpecParameterSpec)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1StudySpecParameterSpecArgs) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecOutput() GoogleCloudAiplatformV1beta1StudySpecParameterSpecOutput {
	return i.ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1StudySpecParameterSpecArgs) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecParameterSpecOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1StudySpecParameterSpecOutput)
}

// GoogleCloudAiplatformV1beta1StudySpecParameterSpecArrayInput is an input type that accepts GoogleCloudAiplatformV1beta1StudySpecParameterSpecArray and GoogleCloudAiplatformV1beta1StudySpecParameterSpecArrayOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1StudySpecParameterSpecArrayInput` via:
//
//	GoogleCloudAiplatformV1beta1StudySpecParameterSpecArray{ GoogleCloudAiplatformV1beta1StudySpecParameterSpecArgs{...} }
type GoogleCloudAiplatformV1beta1StudySpecParameterSpecArrayInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecArrayOutput() GoogleCloudAiplatformV1beta1StudySpecParameterSpecArrayOutput
	ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecArrayOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1StudySpecParameterSpecArrayOutput
}

type GoogleCloudAiplatformV1beta1StudySpecParameterSpecArray []GoogleCloudAiplatformV1beta1StudySpecParameterSpecInput

func (GoogleCloudAiplatformV1beta1StudySpecParameterSpecArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1beta1StudySpecParameterSpec)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1StudySpecParameterSpecArray) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecArrayOutput() GoogleCloudAiplatformV1beta1StudySpecParameterSpecArrayOutput {
	return i.ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecArrayOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1StudySpecParameterSpecArray) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecParameterSpecArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1StudySpecParameterSpecArrayOutput)
}

// Represents a single parameter to optimize.
type GoogleCloudAiplatformV1beta1StudySpecParameterSpecOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1StudySpecParameterSpecOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1StudySpecParameterSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecOutput) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecOutput() GoogleCloudAiplatformV1beta1StudySpecParameterSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecOutput) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecParameterSpecOutput {
	return o
}

// The value spec for a 'CATEGORICAL' parameter.
func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecOutput) CategoricalValueSpec() GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecParameterSpec) *GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpec {
		return v.CategoricalValueSpec
	}).(GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecPtrOutput)
}

// A conditional parameter node is active if the parameter's value matches the conditional node's parent_value_condition. If two items in conditional_parameter_specs have the same name, they must have disjoint parent_value_condition.
func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecOutput) ConditionalParameterSpecs() GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecParameterSpec) []GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpec {
		return v.ConditionalParameterSpecs
	}).(GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecArrayOutput)
}

// The value spec for a 'DISCRETE' parameter.
func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecOutput) DiscreteValueSpec() GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecParameterSpec) *GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpec {
		return v.DiscreteValueSpec
	}).(GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecPtrOutput)
}

// The value spec for a 'DOUBLE' parameter.
func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecOutput) DoubleValueSpec() GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecParameterSpec) *GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpec {
		return v.DoubleValueSpec
	}).(GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecPtrOutput)
}

// The value spec for an 'INTEGER' parameter.
func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecOutput) IntegerValueSpec() GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecParameterSpec) *GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpec {
		return v.IntegerValueSpec
	}).(GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecPtrOutput)
}

// The ID of the parameter. Must not contain whitespaces and must be unique amongst all ParameterSpecs.
func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecOutput) ParameterId() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecParameterSpec) string { return v.ParameterId }).(pulumi.StringOutput)
}

// How the parameter should be scaled. Leave unset for `CATEGORICAL` parameters.
func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecOutput) ScaleType() GoogleCloudAiplatformV1beta1StudySpecParameterSpecScaleTypePtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecParameterSpec) *GoogleCloudAiplatformV1beta1StudySpecParameterSpecScaleType {
		return v.ScaleType
	}).(GoogleCloudAiplatformV1beta1StudySpecParameterSpecScaleTypePtrOutput)
}

type GoogleCloudAiplatformV1beta1StudySpecParameterSpecArrayOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1StudySpecParameterSpecArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1beta1StudySpecParameterSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecArrayOutput) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecArrayOutput() GoogleCloudAiplatformV1beta1StudySpecParameterSpecArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecArrayOutput) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecParameterSpecArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecArrayOutput) Index(i pulumi.IntInput) GoogleCloudAiplatformV1beta1StudySpecParameterSpecOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GoogleCloudAiplatformV1beta1StudySpecParameterSpec {
		return vs[0].([]GoogleCloudAiplatformV1beta1StudySpecParameterSpec)[vs[1].(int)]
	}).(GoogleCloudAiplatformV1beta1StudySpecParameterSpecOutput)
}

// Value specification for a parameter in `CATEGORICAL` type.
type GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpec struct {
	// A default value for a `CATEGORICAL` parameter that is assumed to be a relatively good starting point. Unset value signals that there is no offered starting point. Currently only supported by the Vertex AI Vizier service. Not supported by HyperparameterTuningJob or TrainingPipeline.
	DefaultValue *string `pulumi:"defaultValue"`
	// The list of possible categories.
	Values []string `pulumi:"values"`
}

// GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecInput is an input type that accepts GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecArgs and GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecInput` via:
//
//	GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecArgs{...}
type GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecOutput() GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecOutput
	ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecOutput
}

// Value specification for a parameter in `CATEGORICAL` type.
type GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecArgs struct {
	// A default value for a `CATEGORICAL` parameter that is assumed to be a relatively good starting point. Unset value signals that there is no offered starting point. Currently only supported by the Vertex AI Vizier service. Not supported by HyperparameterTuningJob or TrainingPipeline.
	DefaultValue pulumi.StringPtrInput `pulumi:"defaultValue"`
	// The list of possible categories.
	Values pulumi.StringArrayInput `pulumi:"values"`
}

func (GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpec)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecArgs) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecOutput() GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecOutput {
	return i.ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecArgs) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecOutput)
}

func (i GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecArgs) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecPtrOutput() GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecArgs) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecOutput).ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecArgs, GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecPtr and GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecPtrOutput() GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecPtrOutput
	ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecPtrOutput
}

type googleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecPtrType GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecArgs

func GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecPtr(v *GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecArgs) GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecPtrInput {
	return (*googleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecPtrType)(v)
}

func (*googleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpec)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecPtrType) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecPtrOutput() GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecPtrType) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecPtrOutput)
}

// Value specification for a parameter in `CATEGORICAL` type.
type GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecOutput) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecOutput() GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecOutput) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecOutput) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecPtrOutput() GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecOutput) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpec) *GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpec {
		return &v
	}).(GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecPtrOutput)
}

// A default value for a `CATEGORICAL` parameter that is assumed to be a relatively good starting point. Unset value signals that there is no offered starting point. Currently only supported by the Vertex AI Vizier service. Not supported by HyperparameterTuningJob or TrainingPipeline.
func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecOutput) DefaultValue() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpec) *string {
		return v.DefaultValue
	}).(pulumi.StringPtrOutput)
}

// The list of possible categories.
func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecOutput) Values() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpec) []string {
		return v.Values
	}).(pulumi.StringArrayOutput)
}

type GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecPtrOutput) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecPtrOutput() GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecPtrOutput) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecPtrOutput) Elem() GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpec) GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpec {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpec
		return ret
	}).(GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecOutput)
}

// A default value for a `CATEGORICAL` parameter that is assumed to be a relatively good starting point. Unset value signals that there is no offered starting point. Currently only supported by the Vertex AI Vizier service. Not supported by HyperparameterTuningJob or TrainingPipeline.
func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecPtrOutput) DefaultValue() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpec) *string {
		if v == nil {
			return nil
		}
		return v.DefaultValue
	}).(pulumi.StringPtrOutput)
}

// The list of possible categories.
func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecPtrOutput) Values() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpec) []string {
		if v == nil {
			return nil
		}
		return v.Values
	}).(pulumi.StringArrayOutput)
}

// Value specification for a parameter in `CATEGORICAL` type.
type GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecResponse struct {
	// A default value for a `CATEGORICAL` parameter that is assumed to be a relatively good starting point. Unset value signals that there is no offered starting point. Currently only supported by the Vertex AI Vizier service. Not supported by HyperparameterTuningJob or TrainingPipeline.
	DefaultValue string `pulumi:"defaultValue"`
	// The list of possible categories.
	Values []string `pulumi:"values"`
}

// Value specification for a parameter in `CATEGORICAL` type.
type GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecResponseOutput) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecResponseOutput() GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecResponseOutput) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecResponseOutput {
	return o
}

// A default value for a `CATEGORICAL` parameter that is assumed to be a relatively good starting point. Unset value signals that there is no offered starting point. Currently only supported by the Vertex AI Vizier service. Not supported by HyperparameterTuningJob or TrainingPipeline.
func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecResponseOutput) DefaultValue() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecResponse) string {
		return v.DefaultValue
	}).(pulumi.StringOutput)
}

// The list of possible categories.
func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecResponseOutput) Values() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecResponse) []string {
		return v.Values
	}).(pulumi.StringArrayOutput)
}

// Represents a parameter spec with condition from its parent parameter.
type GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpec struct {
	// The spec for a conditional parameter.
	ParameterSpec GoogleCloudAiplatformV1beta1StudySpecParameterSpec `pulumi:"parameterSpec"`
	// The spec for matching values from a parent parameter of `CATEGORICAL` type.
	ParentCategoricalValues *GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueCondition `pulumi:"parentCategoricalValues"`
	// The spec for matching values from a parent parameter of `DISCRETE` type.
	ParentDiscreteValues *GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueCondition `pulumi:"parentDiscreteValues"`
	// The spec for matching values from a parent parameter of `INTEGER` type.
	ParentIntValues *GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueCondition `pulumi:"parentIntValues"`
}

// GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecInput is an input type that accepts GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecArgs and GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecInput` via:
//
//	GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecArgs{...}
type GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecOutput() GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecOutput
	ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecOutput
}

// Represents a parameter spec with condition from its parent parameter.
type GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecArgs struct {
	// The spec for a conditional parameter.
	ParameterSpec GoogleCloudAiplatformV1beta1StudySpecParameterSpecInput `pulumi:"parameterSpec"`
	// The spec for matching values from a parent parameter of `CATEGORICAL` type.
	ParentCategoricalValues GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionPtrInput `pulumi:"parentCategoricalValues"`
	// The spec for matching values from a parent parameter of `DISCRETE` type.
	ParentDiscreteValues GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionPtrInput `pulumi:"parentDiscreteValues"`
	// The spec for matching values from a parent parameter of `INTEGER` type.
	ParentIntValues GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionPtrInput `pulumi:"parentIntValues"`
}

func (GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpec)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecArgs) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecOutput() GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecOutput {
	return i.ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecArgs) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecOutput)
}

// GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecArrayInput is an input type that accepts GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecArray and GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecArrayOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecArrayInput` via:
//
//	GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecArray{ GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecArgs{...} }
type GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecArrayInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecArrayOutput() GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecArrayOutput
	ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecArrayOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecArrayOutput
}

type GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecArray []GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecInput

func (GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpec)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecArray) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecArrayOutput() GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecArrayOutput {
	return i.ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecArrayOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecArray) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecArrayOutput)
}

// Represents a parameter spec with condition from its parent parameter.
type GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecOutput) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecOutput() GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecOutput) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecOutput {
	return o
}

// The spec for a conditional parameter.
func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecOutput) ParameterSpec() GoogleCloudAiplatformV1beta1StudySpecParameterSpecOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpec) GoogleCloudAiplatformV1beta1StudySpecParameterSpec {
		return v.ParameterSpec
	}).(GoogleCloudAiplatformV1beta1StudySpecParameterSpecOutput)
}

// The spec for matching values from a parent parameter of `CATEGORICAL` type.
func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecOutput) ParentCategoricalValues() GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpec) *GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueCondition {
		return v.ParentCategoricalValues
	}).(GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionPtrOutput)
}

// The spec for matching values from a parent parameter of `DISCRETE` type.
func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecOutput) ParentDiscreteValues() GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpec) *GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueCondition {
		return v.ParentDiscreteValues
	}).(GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionPtrOutput)
}

// The spec for matching values from a parent parameter of `INTEGER` type.
func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecOutput) ParentIntValues() GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpec) *GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueCondition {
		return v.ParentIntValues
	}).(GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionPtrOutput)
}

type GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecArrayOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecArrayOutput) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecArrayOutput() GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecArrayOutput) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecArrayOutput) Index(i pulumi.IntInput) GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpec {
		return vs[0].([]GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpec)[vs[1].(int)]
	}).(GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecOutput)
}

// Represents the spec to match categorical values from parent parameter.
type GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueCondition struct {
	// Matches values of the parent parameter of 'CATEGORICAL' type. All values must exist in `categorical_value_spec` of parent parameter.
	Values []string `pulumi:"values"`
}

// GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionInput is an input type that accepts GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionArgs and GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionInput` via:
//
//	GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionArgs{...}
type GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionOutput() GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionOutput
	ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionOutput
}

// Represents the spec to match categorical values from parent parameter.
type GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionArgs struct {
	// Matches values of the parent parameter of 'CATEGORICAL' type. All values must exist in `categorical_value_spec` of parent parameter.
	Values pulumi.StringArrayInput `pulumi:"values"`
}

func (GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueCondition)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionArgs) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionOutput() GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionOutput {
	return i.ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionArgs) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionOutput)
}

func (i GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionArgs) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionPtrOutput() GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionArgs) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionOutput).ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionArgs, GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionPtr and GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionPtrOutput() GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionPtrOutput
	ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionPtrOutput
}

type googleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionPtrType GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionArgs

func GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionPtr(v *GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionArgs) GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionPtrInput {
	return (*googleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionPtrType)(v)
}

func (*googleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueCondition)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionPtrType) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionPtrOutput() GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionPtrType) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionPtrOutput)
}

// Represents the spec to match categorical values from parent parameter.
type GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueCondition)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionOutput) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionOutput() GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionOutput) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionOutput) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionPtrOutput() GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionOutput) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueCondition) *GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueCondition {
		return &v
	}).(GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionPtrOutput)
}

// Matches values of the parent parameter of 'CATEGORICAL' type. All values must exist in `categorical_value_spec` of parent parameter.
func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionOutput) Values() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueCondition) []string {
		return v.Values
	}).(pulumi.StringArrayOutput)
}

type GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueCondition)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionPtrOutput) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionPtrOutput() GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionPtrOutput) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionPtrOutput) Elem() GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueCondition) GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueCondition {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueCondition
		return ret
	}).(GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionOutput)
}

// Matches values of the parent parameter of 'CATEGORICAL' type. All values must exist in `categorical_value_spec` of parent parameter.
func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionPtrOutput) Values() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueCondition) []string {
		if v == nil {
			return nil
		}
		return v.Values
	}).(pulumi.StringArrayOutput)
}

// Represents the spec to match categorical values from parent parameter.
type GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionResponse struct {
	// Matches values of the parent parameter of 'CATEGORICAL' type. All values must exist in `categorical_value_spec` of parent parameter.
	Values []string `pulumi:"values"`
}

// Represents the spec to match categorical values from parent parameter.
type GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionResponseOutput) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionResponseOutput() GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionResponseOutput) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionResponseOutput {
	return o
}

// Matches values of the parent parameter of 'CATEGORICAL' type. All values must exist in `categorical_value_spec` of parent parameter.
func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionResponseOutput) Values() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionResponse) []string {
		return v.Values
	}).(pulumi.StringArrayOutput)
}

// Represents the spec to match discrete values from parent parameter.
type GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueCondition struct {
	// Matches values of the parent parameter of 'DISCRETE' type. All values must exist in `discrete_value_spec` of parent parameter. The Epsilon of the value matching is 1e-10.
	Values []float64 `pulumi:"values"`
}

// GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionInput is an input type that accepts GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionArgs and GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionInput` via:
//
//	GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionArgs{...}
type GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionOutput() GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionOutput
	ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionOutput
}

// Represents the spec to match discrete values from parent parameter.
type GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionArgs struct {
	// Matches values of the parent parameter of 'DISCRETE' type. All values must exist in `discrete_value_spec` of parent parameter. The Epsilon of the value matching is 1e-10.
	Values pulumi.Float64ArrayInput `pulumi:"values"`
}

func (GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueCondition)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionArgs) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionOutput() GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionOutput {
	return i.ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionArgs) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionOutput)
}

func (i GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionArgs) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionPtrOutput() GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionArgs) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionOutput).ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionArgs, GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionPtr and GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionPtrOutput() GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionPtrOutput
	ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionPtrOutput
}

type googleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionPtrType GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionArgs

func GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionPtr(v *GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionArgs) GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionPtrInput {
	return (*googleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionPtrType)(v)
}

func (*googleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueCondition)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionPtrType) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionPtrOutput() GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionPtrType) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionPtrOutput)
}

// Represents the spec to match discrete values from parent parameter.
type GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueCondition)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionOutput) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionOutput() GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionOutput) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionOutput) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionPtrOutput() GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionOutput) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueCondition) *GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueCondition {
		return &v
	}).(GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionPtrOutput)
}

// Matches values of the parent parameter of 'DISCRETE' type. All values must exist in `discrete_value_spec` of parent parameter. The Epsilon of the value matching is 1e-10.
func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionOutput) Values() pulumi.Float64ArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueCondition) []float64 {
		return v.Values
	}).(pulumi.Float64ArrayOutput)
}

type GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueCondition)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionPtrOutput) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionPtrOutput() GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionPtrOutput) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionPtrOutput) Elem() GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueCondition) GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueCondition {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueCondition
		return ret
	}).(GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionOutput)
}

// Matches values of the parent parameter of 'DISCRETE' type. All values must exist in `discrete_value_spec` of parent parameter. The Epsilon of the value matching is 1e-10.
func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionPtrOutput) Values() pulumi.Float64ArrayOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueCondition) []float64 {
		if v == nil {
			return nil
		}
		return v.Values
	}).(pulumi.Float64ArrayOutput)
}

// Represents the spec to match discrete values from parent parameter.
type GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionResponse struct {
	// Matches values of the parent parameter of 'DISCRETE' type. All values must exist in `discrete_value_spec` of parent parameter. The Epsilon of the value matching is 1e-10.
	Values []float64 `pulumi:"values"`
}

// Represents the spec to match discrete values from parent parameter.
type GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionResponseOutput) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionResponseOutput() GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionResponseOutput) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionResponseOutput {
	return o
}

// Matches values of the parent parameter of 'DISCRETE' type. All values must exist in `discrete_value_spec` of parent parameter. The Epsilon of the value matching is 1e-10.
func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionResponseOutput) Values() pulumi.Float64ArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionResponse) []float64 {
		return v.Values
	}).(pulumi.Float64ArrayOutput)
}

// Represents the spec to match integer values from parent parameter.
type GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueCondition struct {
	// Matches values of the parent parameter of 'INTEGER' type. All values must lie in `integer_value_spec` of parent parameter.
	Values []string `pulumi:"values"`
}

// GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionInput is an input type that accepts GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionArgs and GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionInput` via:
//
//	GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionArgs{...}
type GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionOutput() GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionOutput
	ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionOutput
}

// Represents the spec to match integer values from parent parameter.
type GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionArgs struct {
	// Matches values of the parent parameter of 'INTEGER' type. All values must lie in `integer_value_spec` of parent parameter.
	Values pulumi.StringArrayInput `pulumi:"values"`
}

func (GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueCondition)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionArgs) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionOutput() GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionOutput {
	return i.ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionArgs) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionOutput)
}

func (i GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionArgs) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionPtrOutput() GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionArgs) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionOutput).ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionArgs, GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionPtr and GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionPtrOutput() GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionPtrOutput
	ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionPtrOutput
}

type googleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionPtrType GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionArgs

func GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionPtr(v *GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionArgs) GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionPtrInput {
	return (*googleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionPtrType)(v)
}

func (*googleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueCondition)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionPtrType) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionPtrOutput() GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionPtrType) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionPtrOutput)
}

// Represents the spec to match integer values from parent parameter.
type GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueCondition)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionOutput) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionOutput() GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionOutput) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionOutput) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionPtrOutput() GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionOutput) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueCondition) *GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueCondition {
		return &v
	}).(GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionPtrOutput)
}

// Matches values of the parent parameter of 'INTEGER' type. All values must lie in `integer_value_spec` of parent parameter.
func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionOutput) Values() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueCondition) []string {
		return v.Values
	}).(pulumi.StringArrayOutput)
}

type GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueCondition)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionPtrOutput) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionPtrOutput() GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionPtrOutput) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionPtrOutput) Elem() GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueCondition) GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueCondition {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueCondition
		return ret
	}).(GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionOutput)
}

// Matches values of the parent parameter of 'INTEGER' type. All values must lie in `integer_value_spec` of parent parameter.
func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionPtrOutput) Values() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueCondition) []string {
		if v == nil {
			return nil
		}
		return v.Values
	}).(pulumi.StringArrayOutput)
}

// Represents the spec to match integer values from parent parameter.
type GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionResponse struct {
	// Matches values of the parent parameter of 'INTEGER' type. All values must lie in `integer_value_spec` of parent parameter.
	Values []string `pulumi:"values"`
}

// Represents the spec to match integer values from parent parameter.
type GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionResponseOutput) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionResponseOutput() GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionResponseOutput) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionResponseOutput {
	return o
}

// Matches values of the parent parameter of 'INTEGER' type. All values must lie in `integer_value_spec` of parent parameter.
func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionResponseOutput) Values() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionResponse) []string {
		return v.Values
	}).(pulumi.StringArrayOutput)
}

// Represents a parameter spec with condition from its parent parameter.
type GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecResponse struct {
	// The spec for a conditional parameter.
	ParameterSpec GoogleCloudAiplatformV1beta1StudySpecParameterSpecResponse `pulumi:"parameterSpec"`
	// The spec for matching values from a parent parameter of `CATEGORICAL` type.
	ParentCategoricalValues GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionResponse `pulumi:"parentCategoricalValues"`
	// The spec for matching values from a parent parameter of `DISCRETE` type.
	ParentDiscreteValues GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionResponse `pulumi:"parentDiscreteValues"`
	// The spec for matching values from a parent parameter of `INTEGER` type.
	ParentIntValues GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionResponse `pulumi:"parentIntValues"`
}

// Represents a parameter spec with condition from its parent parameter.
type GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecResponseOutput) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecResponseOutput() GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecResponseOutput) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecResponseOutput {
	return o
}

// The spec for a conditional parameter.
func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecResponseOutput) ParameterSpec() GoogleCloudAiplatformV1beta1StudySpecParameterSpecResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecResponse) GoogleCloudAiplatformV1beta1StudySpecParameterSpecResponse {
		return v.ParameterSpec
	}).(GoogleCloudAiplatformV1beta1StudySpecParameterSpecResponseOutput)
}

// The spec for matching values from a parent parameter of `CATEGORICAL` type.
func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecResponseOutput) ParentCategoricalValues() GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecResponse) GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionResponse {
		return v.ParentCategoricalValues
	}).(GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionResponseOutput)
}

// The spec for matching values from a parent parameter of `DISCRETE` type.
func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecResponseOutput) ParentDiscreteValues() GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecResponse) GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionResponse {
		return v.ParentDiscreteValues
	}).(GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionResponseOutput)
}

// The spec for matching values from a parent parameter of `INTEGER` type.
func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecResponseOutput) ParentIntValues() GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecResponse) GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionResponse {
		return v.ParentIntValues
	}).(GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionResponseOutput)
}

type GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecResponseArrayOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecResponseArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecResponseArrayOutput) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecResponseArrayOutput() GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecResponseArrayOutput) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecResponseArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecResponseArrayOutput) Index(i pulumi.IntInput) GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecResponseOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecResponse {
		return vs[0].([]GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecResponse)[vs[1].(int)]
	}).(GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecResponseOutput)
}

// Value specification for a parameter in `DISCRETE` type.
type GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpec struct {
	// A default value for a `DISCRETE` parameter that is assumed to be a relatively good starting point. Unset value signals that there is no offered starting point. It automatically rounds to the nearest feasible discrete point. Currently only supported by the Vertex AI Vizier service. Not supported by HyperparameterTuningJob or TrainingPipeline.
	DefaultValue *float64 `pulumi:"defaultValue"`
	// A list of possible values. The list should be in increasing order and at least 1e-10 apart. For instance, this parameter might have possible settings of 1.5, 2.5, and 4.0. This list should not contain more than 1,000 values.
	Values []float64 `pulumi:"values"`
}

// GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecInput is an input type that accepts GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecArgs and GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecInput` via:
//
//	GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecArgs{...}
type GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecOutput() GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecOutput
	ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecOutput
}

// Value specification for a parameter in `DISCRETE` type.
type GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecArgs struct {
	// A default value for a `DISCRETE` parameter that is assumed to be a relatively good starting point. Unset value signals that there is no offered starting point. It automatically rounds to the nearest feasible discrete point. Currently only supported by the Vertex AI Vizier service. Not supported by HyperparameterTuningJob or TrainingPipeline.
	DefaultValue pulumi.Float64PtrInput `pulumi:"defaultValue"`
	// A list of possible values. The list should be in increasing order and at least 1e-10 apart. For instance, this parameter might have possible settings of 1.5, 2.5, and 4.0. This list should not contain more than 1,000 values.
	Values pulumi.Float64ArrayInput `pulumi:"values"`
}

func (GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpec)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecArgs) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecOutput() GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecOutput {
	return i.ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecArgs) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecOutput)
}

func (i GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecArgs) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecPtrOutput() GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecArgs) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecOutput).ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecArgs, GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecPtr and GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecPtrOutput() GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecPtrOutput
	ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecPtrOutput
}

type googleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecPtrType GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecArgs

func GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecPtr(v *GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecArgs) GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecPtrInput {
	return (*googleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecPtrType)(v)
}

func (*googleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpec)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecPtrType) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecPtrOutput() GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecPtrType) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecPtrOutput)
}

// Value specification for a parameter in `DISCRETE` type.
type GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecOutput) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecOutput() GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecOutput) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecOutput) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecPtrOutput() GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecOutput) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpec) *GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpec {
		return &v
	}).(GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecPtrOutput)
}

// A default value for a `DISCRETE` parameter that is assumed to be a relatively good starting point. Unset value signals that there is no offered starting point. It automatically rounds to the nearest feasible discrete point. Currently only supported by the Vertex AI Vizier service. Not supported by HyperparameterTuningJob or TrainingPipeline.
func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecOutput) DefaultValue() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpec) *float64 {
		return v.DefaultValue
	}).(pulumi.Float64PtrOutput)
}

// A list of possible values. The list should be in increasing order and at least 1e-10 apart. For instance, this parameter might have possible settings of 1.5, 2.5, and 4.0. This list should not contain more than 1,000 values.
func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecOutput) Values() pulumi.Float64ArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpec) []float64 { return v.Values }).(pulumi.Float64ArrayOutput)
}

type GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecPtrOutput) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecPtrOutput() GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecPtrOutput) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecPtrOutput) Elem() GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpec) GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpec {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpec
		return ret
	}).(GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecOutput)
}

// A default value for a `DISCRETE` parameter that is assumed to be a relatively good starting point. Unset value signals that there is no offered starting point. It automatically rounds to the nearest feasible discrete point. Currently only supported by the Vertex AI Vizier service. Not supported by HyperparameterTuningJob or TrainingPipeline.
func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecPtrOutput) DefaultValue() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpec) *float64 {
		if v == nil {
			return nil
		}
		return v.DefaultValue
	}).(pulumi.Float64PtrOutput)
}

// A list of possible values. The list should be in increasing order and at least 1e-10 apart. For instance, this parameter might have possible settings of 1.5, 2.5, and 4.0. This list should not contain more than 1,000 values.
func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecPtrOutput) Values() pulumi.Float64ArrayOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpec) []float64 {
		if v == nil {
			return nil
		}
		return v.Values
	}).(pulumi.Float64ArrayOutput)
}

// Value specification for a parameter in `DISCRETE` type.
type GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecResponse struct {
	// A default value for a `DISCRETE` parameter that is assumed to be a relatively good starting point. Unset value signals that there is no offered starting point. It automatically rounds to the nearest feasible discrete point. Currently only supported by the Vertex AI Vizier service. Not supported by HyperparameterTuningJob or TrainingPipeline.
	DefaultValue float64 `pulumi:"defaultValue"`
	// A list of possible values. The list should be in increasing order and at least 1e-10 apart. For instance, this parameter might have possible settings of 1.5, 2.5, and 4.0. This list should not contain more than 1,000 values.
	Values []float64 `pulumi:"values"`
}

// Value specification for a parameter in `DISCRETE` type.
type GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecResponseOutput) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecResponseOutput() GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecResponseOutput) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecResponseOutput {
	return o
}

// A default value for a `DISCRETE` parameter that is assumed to be a relatively good starting point. Unset value signals that there is no offered starting point. It automatically rounds to the nearest feasible discrete point. Currently only supported by the Vertex AI Vizier service. Not supported by HyperparameterTuningJob or TrainingPipeline.
func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecResponseOutput) DefaultValue() pulumi.Float64Output {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecResponse) float64 {
		return v.DefaultValue
	}).(pulumi.Float64Output)
}

// A list of possible values. The list should be in increasing order and at least 1e-10 apart. For instance, this parameter might have possible settings of 1.5, 2.5, and 4.0. This list should not contain more than 1,000 values.
func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecResponseOutput) Values() pulumi.Float64ArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecResponse) []float64 {
		return v.Values
	}).(pulumi.Float64ArrayOutput)
}

// Value specification for a parameter in `DOUBLE` type.
type GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpec struct {
	// A default value for a `DOUBLE` parameter that is assumed to be a relatively good starting point. Unset value signals that there is no offered starting point. Currently only supported by the Vertex AI Vizier service. Not supported by HyperparameterTuningJob or TrainingPipeline.
	DefaultValue *float64 `pulumi:"defaultValue"`
	// Inclusive maximum value of the parameter.
	MaxValue float64 `pulumi:"maxValue"`
	// Inclusive minimum value of the parameter.
	MinValue float64 `pulumi:"minValue"`
}

// GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecInput is an input type that accepts GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecArgs and GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecInput` via:
//
//	GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecArgs{...}
type GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecOutput() GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecOutput
	ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecOutput
}

// Value specification for a parameter in `DOUBLE` type.
type GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecArgs struct {
	// A default value for a `DOUBLE` parameter that is assumed to be a relatively good starting point. Unset value signals that there is no offered starting point. Currently only supported by the Vertex AI Vizier service. Not supported by HyperparameterTuningJob or TrainingPipeline.
	DefaultValue pulumi.Float64PtrInput `pulumi:"defaultValue"`
	// Inclusive maximum value of the parameter.
	MaxValue pulumi.Float64Input `pulumi:"maxValue"`
	// Inclusive minimum value of the parameter.
	MinValue pulumi.Float64Input `pulumi:"minValue"`
}

func (GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpec)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecArgs) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecOutput() GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecOutput {
	return i.ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecArgs) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecOutput)
}

func (i GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecArgs) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecPtrOutput() GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecArgs) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecOutput).ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecArgs, GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecPtr and GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecPtrOutput() GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecPtrOutput
	ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecPtrOutput
}

type googleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecPtrType GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecArgs

func GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecPtr(v *GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecArgs) GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecPtrInput {
	return (*googleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecPtrType)(v)
}

func (*googleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpec)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecPtrType) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecPtrOutput() GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecPtrType) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecPtrOutput)
}

// Value specification for a parameter in `DOUBLE` type.
type GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecOutput) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecOutput() GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecOutput) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecOutput) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecPtrOutput() GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecOutput) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpec) *GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpec {
		return &v
	}).(GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecPtrOutput)
}

// A default value for a `DOUBLE` parameter that is assumed to be a relatively good starting point. Unset value signals that there is no offered starting point. Currently only supported by the Vertex AI Vizier service. Not supported by HyperparameterTuningJob or TrainingPipeline.
func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecOutput) DefaultValue() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpec) *float64 {
		return v.DefaultValue
	}).(pulumi.Float64PtrOutput)
}

// Inclusive maximum value of the parameter.
func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecOutput) MaxValue() pulumi.Float64Output {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpec) float64 { return v.MaxValue }).(pulumi.Float64Output)
}

// Inclusive minimum value of the parameter.
func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecOutput) MinValue() pulumi.Float64Output {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpec) float64 { return v.MinValue }).(pulumi.Float64Output)
}

type GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecPtrOutput) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecPtrOutput() GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecPtrOutput) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecPtrOutput) Elem() GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpec) GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpec {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpec
		return ret
	}).(GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecOutput)
}

// A default value for a `DOUBLE` parameter that is assumed to be a relatively good starting point. Unset value signals that there is no offered starting point. Currently only supported by the Vertex AI Vizier service. Not supported by HyperparameterTuningJob or TrainingPipeline.
func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecPtrOutput) DefaultValue() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpec) *float64 {
		if v == nil {
			return nil
		}
		return v.DefaultValue
	}).(pulumi.Float64PtrOutput)
}

// Inclusive maximum value of the parameter.
func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecPtrOutput) MaxValue() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpec) *float64 {
		if v == nil {
			return nil
		}
		return &v.MaxValue
	}).(pulumi.Float64PtrOutput)
}

// Inclusive minimum value of the parameter.
func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecPtrOutput) MinValue() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpec) *float64 {
		if v == nil {
			return nil
		}
		return &v.MinValue
	}).(pulumi.Float64PtrOutput)
}

// Value specification for a parameter in `DOUBLE` type.
type GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecResponse struct {
	// A default value for a `DOUBLE` parameter that is assumed to be a relatively good starting point. Unset value signals that there is no offered starting point. Currently only supported by the Vertex AI Vizier service. Not supported by HyperparameterTuningJob or TrainingPipeline.
	DefaultValue float64 `pulumi:"defaultValue"`
	// Inclusive maximum value of the parameter.
	MaxValue float64 `pulumi:"maxValue"`
	// Inclusive minimum value of the parameter.
	MinValue float64 `pulumi:"minValue"`
}

// Value specification for a parameter in `DOUBLE` type.
type GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecResponseOutput) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecResponseOutput() GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecResponseOutput) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecResponseOutput {
	return o
}

// A default value for a `DOUBLE` parameter that is assumed to be a relatively good starting point. Unset value signals that there is no offered starting point. Currently only supported by the Vertex AI Vizier service. Not supported by HyperparameterTuningJob or TrainingPipeline.
func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecResponseOutput) DefaultValue() pulumi.Float64Output {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecResponse) float64 {
		return v.DefaultValue
	}).(pulumi.Float64Output)
}

// Inclusive maximum value of the parameter.
func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecResponseOutput) MaxValue() pulumi.Float64Output {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecResponse) float64 {
		return v.MaxValue
	}).(pulumi.Float64Output)
}

// Inclusive minimum value of the parameter.
func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecResponseOutput) MinValue() pulumi.Float64Output {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecResponse) float64 {
		return v.MinValue
	}).(pulumi.Float64Output)
}

// Value specification for a parameter in `INTEGER` type.
type GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpec struct {
	// A default value for an `INTEGER` parameter that is assumed to be a relatively good starting point. Unset value signals that there is no offered starting point. Currently only supported by the Vertex AI Vizier service. Not supported by HyperparameterTuningJob or TrainingPipeline.
	DefaultValue *string `pulumi:"defaultValue"`
	// Inclusive maximum value of the parameter.
	MaxValue string `pulumi:"maxValue"`
	// Inclusive minimum value of the parameter.
	MinValue string `pulumi:"minValue"`
}

// GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecInput is an input type that accepts GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecArgs and GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecInput` via:
//
//	GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecArgs{...}
type GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecOutput() GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecOutput
	ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecOutput
}

// Value specification for a parameter in `INTEGER` type.
type GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecArgs struct {
	// A default value for an `INTEGER` parameter that is assumed to be a relatively good starting point. Unset value signals that there is no offered starting point. Currently only supported by the Vertex AI Vizier service. Not supported by HyperparameterTuningJob or TrainingPipeline.
	DefaultValue pulumi.StringPtrInput `pulumi:"defaultValue"`
	// Inclusive maximum value of the parameter.
	MaxValue pulumi.StringInput `pulumi:"maxValue"`
	// Inclusive minimum value of the parameter.
	MinValue pulumi.StringInput `pulumi:"minValue"`
}

func (GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpec)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecArgs) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecOutput() GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecOutput {
	return i.ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecArgs) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecOutput)
}

func (i GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecArgs) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecPtrOutput() GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecArgs) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecOutput).ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecArgs, GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecPtr and GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecPtrOutput() GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecPtrOutput
	ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecPtrOutput
}

type googleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecPtrType GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecArgs

func GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecPtr(v *GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecArgs) GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecPtrInput {
	return (*googleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecPtrType)(v)
}

func (*googleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpec)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecPtrType) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecPtrOutput() GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecPtrType) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecPtrOutput)
}

// Value specification for a parameter in `INTEGER` type.
type GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecOutput) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecOutput() GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecOutput) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecOutput) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecPtrOutput() GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecOutput) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpec) *GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpec {
		return &v
	}).(GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecPtrOutput)
}

// A default value for an `INTEGER` parameter that is assumed to be a relatively good starting point. Unset value signals that there is no offered starting point. Currently only supported by the Vertex AI Vizier service. Not supported by HyperparameterTuningJob or TrainingPipeline.
func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecOutput) DefaultValue() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpec) *string {
		return v.DefaultValue
	}).(pulumi.StringPtrOutput)
}

// Inclusive maximum value of the parameter.
func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecOutput) MaxValue() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpec) string { return v.MaxValue }).(pulumi.StringOutput)
}

// Inclusive minimum value of the parameter.
func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecOutput) MinValue() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpec) string { return v.MinValue }).(pulumi.StringOutput)
}

type GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecPtrOutput) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecPtrOutput() GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecPtrOutput) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecPtrOutput) Elem() GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpec) GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpec {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpec
		return ret
	}).(GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecOutput)
}

// A default value for an `INTEGER` parameter that is assumed to be a relatively good starting point. Unset value signals that there is no offered starting point. Currently only supported by the Vertex AI Vizier service. Not supported by HyperparameterTuningJob or TrainingPipeline.
func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecPtrOutput) DefaultValue() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpec) *string {
		if v == nil {
			return nil
		}
		return v.DefaultValue
	}).(pulumi.StringPtrOutput)
}

// Inclusive maximum value of the parameter.
func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecPtrOutput) MaxValue() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpec) *string {
		if v == nil {
			return nil
		}
		return &v.MaxValue
	}).(pulumi.StringPtrOutput)
}

// Inclusive minimum value of the parameter.
func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecPtrOutput) MinValue() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpec) *string {
		if v == nil {
			return nil
		}
		return &v.MinValue
	}).(pulumi.StringPtrOutput)
}

// Value specification for a parameter in `INTEGER` type.
type GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecResponse struct {
	// A default value for an `INTEGER` parameter that is assumed to be a relatively good starting point. Unset value signals that there is no offered starting point. Currently only supported by the Vertex AI Vizier service. Not supported by HyperparameterTuningJob or TrainingPipeline.
	DefaultValue string `pulumi:"defaultValue"`
	// Inclusive maximum value of the parameter.
	MaxValue string `pulumi:"maxValue"`
	// Inclusive minimum value of the parameter.
	MinValue string `pulumi:"minValue"`
}

// Value specification for a parameter in `INTEGER` type.
type GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecResponseOutput) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecResponseOutput() GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecResponseOutput) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecResponseOutput {
	return o
}

// A default value for an `INTEGER` parameter that is assumed to be a relatively good starting point. Unset value signals that there is no offered starting point. Currently only supported by the Vertex AI Vizier service. Not supported by HyperparameterTuningJob or TrainingPipeline.
func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecResponseOutput) DefaultValue() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecResponse) string {
		return v.DefaultValue
	}).(pulumi.StringOutput)
}

// Inclusive maximum value of the parameter.
func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecResponseOutput) MaxValue() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecResponse) string {
		return v.MaxValue
	}).(pulumi.StringOutput)
}

// Inclusive minimum value of the parameter.
func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecResponseOutput) MinValue() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecResponse) string {
		return v.MinValue
	}).(pulumi.StringOutput)
}

// Represents a single parameter to optimize.
type GoogleCloudAiplatformV1beta1StudySpecParameterSpecResponse struct {
	// The value spec for a 'CATEGORICAL' parameter.
	CategoricalValueSpec GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecResponse `pulumi:"categoricalValueSpec"`
	// A conditional parameter node is active if the parameter's value matches the conditional node's parent_value_condition. If two items in conditional_parameter_specs have the same name, they must have disjoint parent_value_condition.
	ConditionalParameterSpecs []GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecResponse `pulumi:"conditionalParameterSpecs"`
	// The value spec for a 'DISCRETE' parameter.
	DiscreteValueSpec GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecResponse `pulumi:"discreteValueSpec"`
	// The value spec for a 'DOUBLE' parameter.
	DoubleValueSpec GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecResponse `pulumi:"doubleValueSpec"`
	// The value spec for an 'INTEGER' parameter.
	IntegerValueSpec GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecResponse `pulumi:"integerValueSpec"`
	// The ID of the parameter. Must not contain whitespaces and must be unique amongst all ParameterSpecs.
	ParameterId string `pulumi:"parameterId"`
	// How the parameter should be scaled. Leave unset for `CATEGORICAL` parameters.
	ScaleType string `pulumi:"scaleType"`
}

// Represents a single parameter to optimize.
type GoogleCloudAiplatformV1beta1StudySpecParameterSpecResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1StudySpecParameterSpecResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1StudySpecParameterSpecResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecResponseOutput) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecResponseOutput() GoogleCloudAiplatformV1beta1StudySpecParameterSpecResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecResponseOutput) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecParameterSpecResponseOutput {
	return o
}

// The value spec for a 'CATEGORICAL' parameter.
func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecResponseOutput) CategoricalValueSpec() GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecParameterSpecResponse) GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecResponse {
		return v.CategoricalValueSpec
	}).(GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecResponseOutput)
}

// A conditional parameter node is active if the parameter's value matches the conditional node's parent_value_condition. If two items in conditional_parameter_specs have the same name, they must have disjoint parent_value_condition.
func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecResponseOutput) ConditionalParameterSpecs() GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecResponseArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecParameterSpecResponse) []GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecResponse {
		return v.ConditionalParameterSpecs
	}).(GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecResponseArrayOutput)
}

// The value spec for a 'DISCRETE' parameter.
func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecResponseOutput) DiscreteValueSpec() GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecParameterSpecResponse) GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecResponse {
		return v.DiscreteValueSpec
	}).(GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecResponseOutput)
}

// The value spec for a 'DOUBLE' parameter.
func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecResponseOutput) DoubleValueSpec() GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecParameterSpecResponse) GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecResponse {
		return v.DoubleValueSpec
	}).(GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecResponseOutput)
}

// The value spec for an 'INTEGER' parameter.
func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecResponseOutput) IntegerValueSpec() GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecParameterSpecResponse) GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecResponse {
		return v.IntegerValueSpec
	}).(GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecResponseOutput)
}

// The ID of the parameter. Must not contain whitespaces and must be unique amongst all ParameterSpecs.
func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecResponseOutput) ParameterId() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecParameterSpecResponse) string { return v.ParameterId }).(pulumi.StringOutput)
}

// How the parameter should be scaled. Leave unset for `CATEGORICAL` parameters.
func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecResponseOutput) ScaleType() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecParameterSpecResponse) string { return v.ScaleType }).(pulumi.StringOutput)
}

type GoogleCloudAiplatformV1beta1StudySpecParameterSpecResponseArrayOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1StudySpecParameterSpecResponseArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1beta1StudySpecParameterSpecResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecResponseArrayOutput) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecResponseArrayOutput() GoogleCloudAiplatformV1beta1StudySpecParameterSpecResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecResponseArrayOutput) ToGoogleCloudAiplatformV1beta1StudySpecParameterSpecResponseArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecParameterSpecResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StudySpecParameterSpecResponseArrayOutput) Index(i pulumi.IntInput) GoogleCloudAiplatformV1beta1StudySpecParameterSpecResponseOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GoogleCloudAiplatformV1beta1StudySpecParameterSpecResponse {
		return vs[0].([]GoogleCloudAiplatformV1beta1StudySpecParameterSpecResponse)[vs[1].(int)]
	}).(GoogleCloudAiplatformV1beta1StudySpecParameterSpecResponseOutput)
}

// Represents specification of a Study.
type GoogleCloudAiplatformV1beta1StudySpecResponse struct {
	// The search algorithm specified for the Study.
	Algorithm string `pulumi:"algorithm"`
	// The automated early stopping spec using convex stopping rule.
	ConvexAutomatedStoppingSpec GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecResponse `pulumi:"convexAutomatedStoppingSpec"`
	// Deprecated. The automated early stopping using convex stopping rule.
	//
	// Deprecated: Deprecated. The automated early stopping using convex stopping rule.
	ConvexStopConfig GoogleCloudAiplatformV1beta1StudySpecConvexStopConfigResponse `pulumi:"convexStopConfig"`
	// The automated early stopping spec using decay curve rule.
	DecayCurveStoppingSpec GoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecResponse `pulumi:"decayCurveStoppingSpec"`
	// Describe which measurement selection type will be used
	MeasurementSelectionType string `pulumi:"measurementSelectionType"`
	// The automated early stopping spec using median rule.
	MedianAutomatedStoppingSpec GoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecResponse `pulumi:"medianAutomatedStoppingSpec"`
	// Metric specs for the Study.
	Metrics []GoogleCloudAiplatformV1beta1StudySpecMetricSpecResponse `pulumi:"metrics"`
	// The observation noise level of the study. Currently only supported by the Vertex AI Vizier service. Not supported by HyperparameterTuningJob or TrainingPipeline.
	ObservationNoise string `pulumi:"observationNoise"`
	// The set of parameters to tune.
	Parameters []GoogleCloudAiplatformV1beta1StudySpecParameterSpecResponse `pulumi:"parameters"`
	// Conditions for automated stopping of a Study. Enable automated stopping by configuring at least one condition.
	StudyStoppingConfig GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigResponse `pulumi:"studyStoppingConfig"`
	// The configuration info/options for transfer learning. Currently supported for Vertex AI Vizier service, not HyperParameterTuningJob
	TransferLearningConfig GoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigResponse `pulumi:"transferLearningConfig"`
}

// Represents specification of a Study.
type GoogleCloudAiplatformV1beta1StudySpecResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1StudySpecResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1StudySpecResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1StudySpecResponseOutput) ToGoogleCloudAiplatformV1beta1StudySpecResponseOutput() GoogleCloudAiplatformV1beta1StudySpecResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StudySpecResponseOutput) ToGoogleCloudAiplatformV1beta1StudySpecResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecResponseOutput {
	return o
}

// The search algorithm specified for the Study.
func (o GoogleCloudAiplatformV1beta1StudySpecResponseOutput) Algorithm() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecResponse) string { return v.Algorithm }).(pulumi.StringOutput)
}

// The automated early stopping spec using convex stopping rule.
func (o GoogleCloudAiplatformV1beta1StudySpecResponseOutput) ConvexAutomatedStoppingSpec() GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecResponse) GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecResponse {
		return v.ConvexAutomatedStoppingSpec
	}).(GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecResponseOutput)
}

// Deprecated. The automated early stopping using convex stopping rule.
//
// Deprecated: Deprecated. The automated early stopping using convex stopping rule.
func (o GoogleCloudAiplatformV1beta1StudySpecResponseOutput) ConvexStopConfig() GoogleCloudAiplatformV1beta1StudySpecConvexStopConfigResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecResponse) GoogleCloudAiplatformV1beta1StudySpecConvexStopConfigResponse {
		return v.ConvexStopConfig
	}).(GoogleCloudAiplatformV1beta1StudySpecConvexStopConfigResponseOutput)
}

// The automated early stopping spec using decay curve rule.
func (o GoogleCloudAiplatformV1beta1StudySpecResponseOutput) DecayCurveStoppingSpec() GoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecResponse) GoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecResponse {
		return v.DecayCurveStoppingSpec
	}).(GoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecResponseOutput)
}

// Describe which measurement selection type will be used
func (o GoogleCloudAiplatformV1beta1StudySpecResponseOutput) MeasurementSelectionType() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecResponse) string { return v.MeasurementSelectionType }).(pulumi.StringOutput)
}

// The automated early stopping spec using median rule.
func (o GoogleCloudAiplatformV1beta1StudySpecResponseOutput) MedianAutomatedStoppingSpec() GoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecResponse) GoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecResponse {
		return v.MedianAutomatedStoppingSpec
	}).(GoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecResponseOutput)
}

// Metric specs for the Study.
func (o GoogleCloudAiplatformV1beta1StudySpecResponseOutput) Metrics() GoogleCloudAiplatformV1beta1StudySpecMetricSpecResponseArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecResponse) []GoogleCloudAiplatformV1beta1StudySpecMetricSpecResponse {
		return v.Metrics
	}).(GoogleCloudAiplatformV1beta1StudySpecMetricSpecResponseArrayOutput)
}

// The observation noise level of the study. Currently only supported by the Vertex AI Vizier service. Not supported by HyperparameterTuningJob or TrainingPipeline.
func (o GoogleCloudAiplatformV1beta1StudySpecResponseOutput) ObservationNoise() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecResponse) string { return v.ObservationNoise }).(pulumi.StringOutput)
}

// The set of parameters to tune.
func (o GoogleCloudAiplatformV1beta1StudySpecResponseOutput) Parameters() GoogleCloudAiplatformV1beta1StudySpecParameterSpecResponseArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecResponse) []GoogleCloudAiplatformV1beta1StudySpecParameterSpecResponse {
		return v.Parameters
	}).(GoogleCloudAiplatformV1beta1StudySpecParameterSpecResponseArrayOutput)
}

// Conditions for automated stopping of a Study. Enable automated stopping by configuring at least one condition.
func (o GoogleCloudAiplatformV1beta1StudySpecResponseOutput) StudyStoppingConfig() GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecResponse) GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigResponse {
		return v.StudyStoppingConfig
	}).(GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigResponseOutput)
}

// The configuration info/options for transfer learning. Currently supported for Vertex AI Vizier service, not HyperParameterTuningJob
func (o GoogleCloudAiplatformV1beta1StudySpecResponseOutput) TransferLearningConfig() GoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecResponse) GoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigResponse {
		return v.TransferLearningConfig
	}).(GoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigResponseOutput)
}

// The configuration (stopping conditions) for automated stopping of a Study. Conditions include trial budgets, time budgets, and convergence detection.
type GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfig struct {
	// If the objective value has not improved for this much time, stop the study. WARNING: Effective only for single-objective studies.
	MaxDurationNoProgress *string `pulumi:"maxDurationNoProgress"`
	// If there are more than this many trials, stop the study.
	MaxNumTrials *int `pulumi:"maxNumTrials"`
	// If the objective value has not improved for this many consecutive trials, stop the study. WARNING: Effective only for single-objective studies.
	MaxNumTrialsNoProgress *int `pulumi:"maxNumTrialsNoProgress"`
	// If the specified time or duration has passed, stop the study.
	MaximumRuntimeConstraint *GoogleCloudAiplatformV1beta1StudyTimeConstraint `pulumi:"maximumRuntimeConstraint"`
	// If there are fewer than this many COMPLETED trials, do not stop the study.
	MinNumTrials *int `pulumi:"minNumTrials"`
	// Each "stopping rule" in this proto specifies an "if" condition. Before Vizier would generate a new suggestion, it first checks each specified stopping rule, from top to bottom in this list. Note that the first few rules (e.g. minimum_runtime_constraint, min_num_trials) will prevent other stopping rules from being evaluated until they are met. For example, setting `min_num_trials=5` and `always_stop_after= 1 hour` means that the Study will ONLY stop after it has 5 COMPLETED trials, even if more than an hour has passed since its creation. It follows the first applicable rule (whose "if" condition is satisfied) to make a stopping decision. If none of the specified rules are applicable, then Vizier decides that the study should not stop. If Vizier decides that the study should stop, the study enters STOPPING state (or STOPPING_ASAP if should_stop_asap = true). IMPORTANT: The automatic study state transition happens precisely as described above; that is, deleting trials or updating StudyConfig NEVER automatically moves the study state back to ACTIVE. If you want to _resume_ a Study that was stopped, 1) change the stopping conditions if necessary, 2) activate the study, and then 3) ask for suggestions. If the specified time or duration has not passed, do not stop the study.
	MinimumRuntimeConstraint *GoogleCloudAiplatformV1beta1StudyTimeConstraint `pulumi:"minimumRuntimeConstraint"`
	// If true, a Study enters STOPPING_ASAP whenever it would normally enters STOPPING state. The bottom line is: set to true if you want to interrupt on-going evaluations of Trials as soon as the study stopping condition is met. (Please see Study.State documentation for the source of truth).
	ShouldStopAsap *bool `pulumi:"shouldStopAsap"`
}

// GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigInput is an input type that accepts GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigArgs and GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigInput` via:
//
//	GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigArgs{...}
type GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigOutput() GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigOutput
	ToGoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigOutput
}

// The configuration (stopping conditions) for automated stopping of a Study. Conditions include trial budgets, time budgets, and convergence detection.
type GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigArgs struct {
	// If the objective value has not improved for this much time, stop the study. WARNING: Effective only for single-objective studies.
	MaxDurationNoProgress pulumi.StringPtrInput `pulumi:"maxDurationNoProgress"`
	// If there are more than this many trials, stop the study.
	MaxNumTrials pulumi.IntPtrInput `pulumi:"maxNumTrials"`
	// If the objective value has not improved for this many consecutive trials, stop the study. WARNING: Effective only for single-objective studies.
	MaxNumTrialsNoProgress pulumi.IntPtrInput `pulumi:"maxNumTrialsNoProgress"`
	// If the specified time or duration has passed, stop the study.
	MaximumRuntimeConstraint GoogleCloudAiplatformV1beta1StudyTimeConstraintPtrInput `pulumi:"maximumRuntimeConstraint"`
	// If there are fewer than this many COMPLETED trials, do not stop the study.
	MinNumTrials pulumi.IntPtrInput `pulumi:"minNumTrials"`
	// Each "stopping rule" in this proto specifies an "if" condition. Before Vizier would generate a new suggestion, it first checks each specified stopping rule, from top to bottom in this list. Note that the first few rules (e.g. minimum_runtime_constraint, min_num_trials) will prevent other stopping rules from being evaluated until they are met. For example, setting `min_num_trials=5` and `always_stop_after= 1 hour` means that the Study will ONLY stop after it has 5 COMPLETED trials, even if more than an hour has passed since its creation. It follows the first applicable rule (whose "if" condition is satisfied) to make a stopping decision. If none of the specified rules are applicable, then Vizier decides that the study should not stop. If Vizier decides that the study should stop, the study enters STOPPING state (or STOPPING_ASAP if should_stop_asap = true). IMPORTANT: The automatic study state transition happens precisely as described above; that is, deleting trials or updating StudyConfig NEVER automatically moves the study state back to ACTIVE. If you want to _resume_ a Study that was stopped, 1) change the stopping conditions if necessary, 2) activate the study, and then 3) ask for suggestions. If the specified time or duration has not passed, do not stop the study.
	MinimumRuntimeConstraint GoogleCloudAiplatformV1beta1StudyTimeConstraintPtrInput `pulumi:"minimumRuntimeConstraint"`
	// If true, a Study enters STOPPING_ASAP whenever it would normally enters STOPPING state. The bottom line is: set to true if you want to interrupt on-going evaluations of Trials as soon as the study stopping condition is met. (Please see Study.State documentation for the source of truth).
	ShouldStopAsap pulumi.BoolPtrInput `pulumi:"shouldStopAsap"`
}

func (GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfig)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigArgs) ToGoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigOutput() GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigOutput {
	return i.ToGoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigArgs) ToGoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigOutput)
}

func (i GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigArgs) ToGoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigPtrOutput() GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigArgs) ToGoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigOutput).ToGoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigArgs, GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigPtr and GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigPtrOutput() GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigPtrOutput
	ToGoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigPtrOutput
}

type googleCloudAiplatformV1beta1StudySpecStudyStoppingConfigPtrType GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigArgs

func GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigPtr(v *GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigArgs) GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigPtrInput {
	return (*googleCloudAiplatformV1beta1StudySpecStudyStoppingConfigPtrType)(v)
}

func (*googleCloudAiplatformV1beta1StudySpecStudyStoppingConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfig)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1StudySpecStudyStoppingConfigPtrType) ToGoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigPtrOutput() GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1StudySpecStudyStoppingConfigPtrType) ToGoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigPtrOutput)
}

// The configuration (stopping conditions) for automated stopping of a Study. Conditions include trial budgets, time budgets, and convergence detection.
type GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigOutput) ToGoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigOutput() GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigOutput) ToGoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigOutput) ToGoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigPtrOutput() GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigOutput) ToGoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfig) *GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfig {
		return &v
	}).(GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigPtrOutput)
}

// If the objective value has not improved for this much time, stop the study. WARNING: Effective only for single-objective studies.
func (o GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigOutput) MaxDurationNoProgress() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfig) *string {
		return v.MaxDurationNoProgress
	}).(pulumi.StringPtrOutput)
}

// If there are more than this many trials, stop the study.
func (o GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigOutput) MaxNumTrials() pulumi.IntPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfig) *int { return v.MaxNumTrials }).(pulumi.IntPtrOutput)
}

// If the objective value has not improved for this many consecutive trials, stop the study. WARNING: Effective only for single-objective studies.
func (o GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigOutput) MaxNumTrialsNoProgress() pulumi.IntPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfig) *int { return v.MaxNumTrialsNoProgress }).(pulumi.IntPtrOutput)
}

// If the specified time or duration has passed, stop the study.
func (o GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigOutput) MaximumRuntimeConstraint() GoogleCloudAiplatformV1beta1StudyTimeConstraintPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfig) *GoogleCloudAiplatformV1beta1StudyTimeConstraint {
		return v.MaximumRuntimeConstraint
	}).(GoogleCloudAiplatformV1beta1StudyTimeConstraintPtrOutput)
}

// If there are fewer than this many COMPLETED trials, do not stop the study.
func (o GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigOutput) MinNumTrials() pulumi.IntPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfig) *int { return v.MinNumTrials }).(pulumi.IntPtrOutput)
}

// Each "stopping rule" in this proto specifies an "if" condition. Before Vizier would generate a new suggestion, it first checks each specified stopping rule, from top to bottom in this list. Note that the first few rules (e.g. minimum_runtime_constraint, min_num_trials) will prevent other stopping rules from being evaluated until they are met. For example, setting `min_num_trials=5` and `always_stop_after= 1 hour` means that the Study will ONLY stop after it has 5 COMPLETED trials, even if more than an hour has passed since its creation. It follows the first applicable rule (whose "if" condition is satisfied) to make a stopping decision. If none of the specified rules are applicable, then Vizier decides that the study should not stop. If Vizier decides that the study should stop, the study enters STOPPING state (or STOPPING_ASAP if should_stop_asap = true). IMPORTANT: The automatic study state transition happens precisely as described above; that is, deleting trials or updating StudyConfig NEVER automatically moves the study state back to ACTIVE. If you want to _resume_ a Study that was stopped, 1) change the stopping conditions if necessary, 2) activate the study, and then 3) ask for suggestions. If the specified time or duration has not passed, do not stop the study.
func (o GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigOutput) MinimumRuntimeConstraint() GoogleCloudAiplatformV1beta1StudyTimeConstraintPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfig) *GoogleCloudAiplatformV1beta1StudyTimeConstraint {
		return v.MinimumRuntimeConstraint
	}).(GoogleCloudAiplatformV1beta1StudyTimeConstraintPtrOutput)
}

// If true, a Study enters STOPPING_ASAP whenever it would normally enters STOPPING state. The bottom line is: set to true if you want to interrupt on-going evaluations of Trials as soon as the study stopping condition is met. (Please see Study.State documentation for the source of truth).
func (o GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigOutput) ShouldStopAsap() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfig) *bool { return v.ShouldStopAsap }).(pulumi.BoolPtrOutput)
}

type GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigPtrOutput) ToGoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigPtrOutput() GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigPtrOutput) ToGoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigPtrOutput) Elem() GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfig) GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfig {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfig
		return ret
	}).(GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigOutput)
}

// If the objective value has not improved for this much time, stop the study. WARNING: Effective only for single-objective studies.
func (o GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigPtrOutput) MaxDurationNoProgress() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfig) *string {
		if v == nil {
			return nil
		}
		return v.MaxDurationNoProgress
	}).(pulumi.StringPtrOutput)
}

// If there are more than this many trials, stop the study.
func (o GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigPtrOutput) MaxNumTrials() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfig) *int {
		if v == nil {
			return nil
		}
		return v.MaxNumTrials
	}).(pulumi.IntPtrOutput)
}

// If the objective value has not improved for this many consecutive trials, stop the study. WARNING: Effective only for single-objective studies.
func (o GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigPtrOutput) MaxNumTrialsNoProgress() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfig) *int {
		if v == nil {
			return nil
		}
		return v.MaxNumTrialsNoProgress
	}).(pulumi.IntPtrOutput)
}

// If the specified time or duration has passed, stop the study.
func (o GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigPtrOutput) MaximumRuntimeConstraint() GoogleCloudAiplatformV1beta1StudyTimeConstraintPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfig) *GoogleCloudAiplatformV1beta1StudyTimeConstraint {
		if v == nil {
			return nil
		}
		return v.MaximumRuntimeConstraint
	}).(GoogleCloudAiplatformV1beta1StudyTimeConstraintPtrOutput)
}

// If there are fewer than this many COMPLETED trials, do not stop the study.
func (o GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigPtrOutput) MinNumTrials() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfig) *int {
		if v == nil {
			return nil
		}
		return v.MinNumTrials
	}).(pulumi.IntPtrOutput)
}

// Each "stopping rule" in this proto specifies an "if" condition. Before Vizier would generate a new suggestion, it first checks each specified stopping rule, from top to bottom in this list. Note that the first few rules (e.g. minimum_runtime_constraint, min_num_trials) will prevent other stopping rules from being evaluated until they are met. For example, setting `min_num_trials=5` and `always_stop_after= 1 hour` means that the Study will ONLY stop after it has 5 COMPLETED trials, even if more than an hour has passed since its creation. It follows the first applicable rule (whose "if" condition is satisfied) to make a stopping decision. If none of the specified rules are applicable, then Vizier decides that the study should not stop. If Vizier decides that the study should stop, the study enters STOPPING state (or STOPPING_ASAP if should_stop_asap = true). IMPORTANT: The automatic study state transition happens precisely as described above; that is, deleting trials or updating StudyConfig NEVER automatically moves the study state back to ACTIVE. If you want to _resume_ a Study that was stopped, 1) change the stopping conditions if necessary, 2) activate the study, and then 3) ask for suggestions. If the specified time or duration has not passed, do not stop the study.
func (o GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigPtrOutput) MinimumRuntimeConstraint() GoogleCloudAiplatformV1beta1StudyTimeConstraintPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfig) *GoogleCloudAiplatformV1beta1StudyTimeConstraint {
		if v == nil {
			return nil
		}
		return v.MinimumRuntimeConstraint
	}).(GoogleCloudAiplatformV1beta1StudyTimeConstraintPtrOutput)
}

// If true, a Study enters STOPPING_ASAP whenever it would normally enters STOPPING state. The bottom line is: set to true if you want to interrupt on-going evaluations of Trials as soon as the study stopping condition is met. (Please see Study.State documentation for the source of truth).
func (o GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigPtrOutput) ShouldStopAsap() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfig) *bool {
		if v == nil {
			return nil
		}
		return v.ShouldStopAsap
	}).(pulumi.BoolPtrOutput)
}

// The configuration (stopping conditions) for automated stopping of a Study. Conditions include trial budgets, time budgets, and convergence detection.
type GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigResponse struct {
	// If the objective value has not improved for this much time, stop the study. WARNING: Effective only for single-objective studies.
	MaxDurationNoProgress string `pulumi:"maxDurationNoProgress"`
	// If there are more than this many trials, stop the study.
	MaxNumTrials int `pulumi:"maxNumTrials"`
	// If the objective value has not improved for this many consecutive trials, stop the study. WARNING: Effective only for single-objective studies.
	MaxNumTrialsNoProgress int `pulumi:"maxNumTrialsNoProgress"`
	// If the specified time or duration has passed, stop the study.
	MaximumRuntimeConstraint GoogleCloudAiplatformV1beta1StudyTimeConstraintResponse `pulumi:"maximumRuntimeConstraint"`
	// If there are fewer than this many COMPLETED trials, do not stop the study.
	MinNumTrials int `pulumi:"minNumTrials"`
	// Each "stopping rule" in this proto specifies an "if" condition. Before Vizier would generate a new suggestion, it first checks each specified stopping rule, from top to bottom in this list. Note that the first few rules (e.g. minimum_runtime_constraint, min_num_trials) will prevent other stopping rules from being evaluated until they are met. For example, setting `min_num_trials=5` and `always_stop_after= 1 hour` means that the Study will ONLY stop after it has 5 COMPLETED trials, even if more than an hour has passed since its creation. It follows the first applicable rule (whose "if" condition is satisfied) to make a stopping decision. If none of the specified rules are applicable, then Vizier decides that the study should not stop. If Vizier decides that the study should stop, the study enters STOPPING state (or STOPPING_ASAP if should_stop_asap = true). IMPORTANT: The automatic study state transition happens precisely as described above; that is, deleting trials or updating StudyConfig NEVER automatically moves the study state back to ACTIVE. If you want to _resume_ a Study that was stopped, 1) change the stopping conditions if necessary, 2) activate the study, and then 3) ask for suggestions. If the specified time or duration has not passed, do not stop the study.
	MinimumRuntimeConstraint GoogleCloudAiplatformV1beta1StudyTimeConstraintResponse `pulumi:"minimumRuntimeConstraint"`
	// If true, a Study enters STOPPING_ASAP whenever it would normally enters STOPPING state. The bottom line is: set to true if you want to interrupt on-going evaluations of Trials as soon as the study stopping condition is met. (Please see Study.State documentation for the source of truth).
	ShouldStopAsap bool `pulumi:"shouldStopAsap"`
}

// The configuration (stopping conditions) for automated stopping of a Study. Conditions include trial budgets, time budgets, and convergence detection.
type GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigResponseOutput) ToGoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigResponseOutput() GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigResponseOutput) ToGoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigResponseOutput {
	return o
}

// If the objective value has not improved for this much time, stop the study. WARNING: Effective only for single-objective studies.
func (o GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigResponseOutput) MaxDurationNoProgress() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigResponse) string {
		return v.MaxDurationNoProgress
	}).(pulumi.StringOutput)
}

// If there are more than this many trials, stop the study.
func (o GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigResponseOutput) MaxNumTrials() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigResponse) int { return v.MaxNumTrials }).(pulumi.IntOutput)
}

// If the objective value has not improved for this many consecutive trials, stop the study. WARNING: Effective only for single-objective studies.
func (o GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigResponseOutput) MaxNumTrialsNoProgress() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigResponse) int {
		return v.MaxNumTrialsNoProgress
	}).(pulumi.IntOutput)
}

// If the specified time or duration has passed, stop the study.
func (o GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigResponseOutput) MaximumRuntimeConstraint() GoogleCloudAiplatformV1beta1StudyTimeConstraintResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigResponse) GoogleCloudAiplatformV1beta1StudyTimeConstraintResponse {
		return v.MaximumRuntimeConstraint
	}).(GoogleCloudAiplatformV1beta1StudyTimeConstraintResponseOutput)
}

// If there are fewer than this many COMPLETED trials, do not stop the study.
func (o GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigResponseOutput) MinNumTrials() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigResponse) int { return v.MinNumTrials }).(pulumi.IntOutput)
}

// Each "stopping rule" in this proto specifies an "if" condition. Before Vizier would generate a new suggestion, it first checks each specified stopping rule, from top to bottom in this list. Note that the first few rules (e.g. minimum_runtime_constraint, min_num_trials) will prevent other stopping rules from being evaluated until they are met. For example, setting `min_num_trials=5` and `always_stop_after= 1 hour` means that the Study will ONLY stop after it has 5 COMPLETED trials, even if more than an hour has passed since its creation. It follows the first applicable rule (whose "if" condition is satisfied) to make a stopping decision. If none of the specified rules are applicable, then Vizier decides that the study should not stop. If Vizier decides that the study should stop, the study enters STOPPING state (or STOPPING_ASAP if should_stop_asap = true). IMPORTANT: The automatic study state transition happens precisely as described above; that is, deleting trials or updating StudyConfig NEVER automatically moves the study state back to ACTIVE. If you want to _resume_ a Study that was stopped, 1) change the stopping conditions if necessary, 2) activate the study, and then 3) ask for suggestions. If the specified time or duration has not passed, do not stop the study.
func (o GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigResponseOutput) MinimumRuntimeConstraint() GoogleCloudAiplatformV1beta1StudyTimeConstraintResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigResponse) GoogleCloudAiplatformV1beta1StudyTimeConstraintResponse {
		return v.MinimumRuntimeConstraint
	}).(GoogleCloudAiplatformV1beta1StudyTimeConstraintResponseOutput)
}

// If true, a Study enters STOPPING_ASAP whenever it would normally enters STOPPING state. The bottom line is: set to true if you want to interrupt on-going evaluations of Trials as soon as the study stopping condition is met. (Please see Study.State documentation for the source of truth).
func (o GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigResponseOutput) ShouldStopAsap() pulumi.BoolOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigResponse) bool { return v.ShouldStopAsap }).(pulumi.BoolOutput)
}

// This contains flag for manually disabling transfer learning for a study. The names of prior studies being used for transfer learning (if any) are also listed here.
type GoogleCloudAiplatformV1beta1StudySpecTransferLearningConfig struct {
	// Flag to to manually prevent vizier from using transfer learning on a new study. Otherwise, vizier will automatically determine whether or not to use transfer learning.
	DisableTransferLearning *bool `pulumi:"disableTransferLearning"`
}

// GoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigInput is an input type that accepts GoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigArgs and GoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigInput` via:
//
//	GoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigArgs{...}
type GoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigOutput() GoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigOutput
	ToGoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigOutput
}

// This contains flag for manually disabling transfer learning for a study. The names of prior studies being used for transfer learning (if any) are also listed here.
type GoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigArgs struct {
	// Flag to to manually prevent vizier from using transfer learning on a new study. Otherwise, vizier will automatically determine whether or not to use transfer learning.
	DisableTransferLearning pulumi.BoolPtrInput `pulumi:"disableTransferLearning"`
}

func (GoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1StudySpecTransferLearningConfig)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigArgs) ToGoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigOutput() GoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigOutput {
	return i.ToGoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigArgs) ToGoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigOutput)
}

func (i GoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigArgs) ToGoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigPtrOutput() GoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigArgs) ToGoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigOutput).ToGoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigArgs, GoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigPtr and GoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigPtrOutput() GoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigPtrOutput
	ToGoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigPtrOutput
}

type googleCloudAiplatformV1beta1StudySpecTransferLearningConfigPtrType GoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigArgs

func GoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigPtr(v *GoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigArgs) GoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigPtrInput {
	return (*googleCloudAiplatformV1beta1StudySpecTransferLearningConfigPtrType)(v)
}

func (*googleCloudAiplatformV1beta1StudySpecTransferLearningConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1StudySpecTransferLearningConfig)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1StudySpecTransferLearningConfigPtrType) ToGoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigPtrOutput() GoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1StudySpecTransferLearningConfigPtrType) ToGoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigPtrOutput)
}

// This contains flag for manually disabling transfer learning for a study. The names of prior studies being used for transfer learning (if any) are also listed here.
type GoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1StudySpecTransferLearningConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigOutput) ToGoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigOutput() GoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigOutput) ToGoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigOutput) ToGoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigPtrOutput() GoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigOutput) ToGoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1StudySpecTransferLearningConfig) *GoogleCloudAiplatformV1beta1StudySpecTransferLearningConfig {
		return &v
	}).(GoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigPtrOutput)
}

// Flag to to manually prevent vizier from using transfer learning on a new study. Otherwise, vizier will automatically determine whether or not to use transfer learning.
func (o GoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigOutput) DisableTransferLearning() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecTransferLearningConfig) *bool {
		return v.DisableTransferLearning
	}).(pulumi.BoolPtrOutput)
}

type GoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1StudySpecTransferLearningConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigPtrOutput) ToGoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigPtrOutput() GoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigPtrOutput) ToGoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigPtrOutput) Elem() GoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1StudySpecTransferLearningConfig) GoogleCloudAiplatformV1beta1StudySpecTransferLearningConfig {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1StudySpecTransferLearningConfig
		return ret
	}).(GoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigOutput)
}

// Flag to to manually prevent vizier from using transfer learning on a new study. Otherwise, vizier will automatically determine whether or not to use transfer learning.
func (o GoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigPtrOutput) DisableTransferLearning() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1StudySpecTransferLearningConfig) *bool {
		if v == nil {
			return nil
		}
		return v.DisableTransferLearning
	}).(pulumi.BoolPtrOutput)
}

// This contains flag for manually disabling transfer learning for a study. The names of prior studies being used for transfer learning (if any) are also listed here.
type GoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigResponse struct {
	// Flag to to manually prevent vizier from using transfer learning on a new study. Otherwise, vizier will automatically determine whether or not to use transfer learning.
	DisableTransferLearning bool `pulumi:"disableTransferLearning"`
	// Names of previously completed studies
	PriorStudyNames []string `pulumi:"priorStudyNames"`
}

// This contains flag for manually disabling transfer learning for a study. The names of prior studies being used for transfer learning (if any) are also listed here.
type GoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigResponseOutput) ToGoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigResponseOutput() GoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigResponseOutput) ToGoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigResponseOutput {
	return o
}

// Flag to to manually prevent vizier from using transfer learning on a new study. Otherwise, vizier will automatically determine whether or not to use transfer learning.
func (o GoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigResponseOutput) DisableTransferLearning() pulumi.BoolOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigResponse) bool {
		return v.DisableTransferLearning
	}).(pulumi.BoolOutput)
}

// Names of previously completed studies
func (o GoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigResponseOutput) PriorStudyNames() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigResponse) []string {
		return v.PriorStudyNames
	}).(pulumi.StringArrayOutput)
}

// Time-based Constraint for Study
type GoogleCloudAiplatformV1beta1StudyTimeConstraint struct {
	// Compares the wallclock time to this time. Must use UTC timezone.
	EndTime *string `pulumi:"endTime"`
	// Counts the wallclock time passed since the creation of this Study.
	MaxDuration *string `pulumi:"maxDuration"`
}

// GoogleCloudAiplatformV1beta1StudyTimeConstraintInput is an input type that accepts GoogleCloudAiplatformV1beta1StudyTimeConstraintArgs and GoogleCloudAiplatformV1beta1StudyTimeConstraintOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1StudyTimeConstraintInput` via:
//
//	GoogleCloudAiplatformV1beta1StudyTimeConstraintArgs{...}
type GoogleCloudAiplatformV1beta1StudyTimeConstraintInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1StudyTimeConstraintOutput() GoogleCloudAiplatformV1beta1StudyTimeConstraintOutput
	ToGoogleCloudAiplatformV1beta1StudyTimeConstraintOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1StudyTimeConstraintOutput
}

// Time-based Constraint for Study
type GoogleCloudAiplatformV1beta1StudyTimeConstraintArgs struct {
	// Compares the wallclock time to this time. Must use UTC timezone.
	EndTime pulumi.StringPtrInput `pulumi:"endTime"`
	// Counts the wallclock time passed since the creation of this Study.
	MaxDuration pulumi.StringPtrInput `pulumi:"maxDuration"`
}

func (GoogleCloudAiplatformV1beta1StudyTimeConstraintArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1StudyTimeConstraint)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1StudyTimeConstraintArgs) ToGoogleCloudAiplatformV1beta1StudyTimeConstraintOutput() GoogleCloudAiplatformV1beta1StudyTimeConstraintOutput {
	return i.ToGoogleCloudAiplatformV1beta1StudyTimeConstraintOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1StudyTimeConstraintArgs) ToGoogleCloudAiplatformV1beta1StudyTimeConstraintOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudyTimeConstraintOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1StudyTimeConstraintOutput)
}

func (i GoogleCloudAiplatformV1beta1StudyTimeConstraintArgs) ToGoogleCloudAiplatformV1beta1StudyTimeConstraintPtrOutput() GoogleCloudAiplatformV1beta1StudyTimeConstraintPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1StudyTimeConstraintPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1StudyTimeConstraintArgs) ToGoogleCloudAiplatformV1beta1StudyTimeConstraintPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudyTimeConstraintPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1StudyTimeConstraintOutput).ToGoogleCloudAiplatformV1beta1StudyTimeConstraintPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1StudyTimeConstraintPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1StudyTimeConstraintArgs, GoogleCloudAiplatformV1beta1StudyTimeConstraintPtr and GoogleCloudAiplatformV1beta1StudyTimeConstraintPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1StudyTimeConstraintPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1StudyTimeConstraintArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1StudyTimeConstraintPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1StudyTimeConstraintPtrOutput() GoogleCloudAiplatformV1beta1StudyTimeConstraintPtrOutput
	ToGoogleCloudAiplatformV1beta1StudyTimeConstraintPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1StudyTimeConstraintPtrOutput
}

type googleCloudAiplatformV1beta1StudyTimeConstraintPtrType GoogleCloudAiplatformV1beta1StudyTimeConstraintArgs

func GoogleCloudAiplatformV1beta1StudyTimeConstraintPtr(v *GoogleCloudAiplatformV1beta1StudyTimeConstraintArgs) GoogleCloudAiplatformV1beta1StudyTimeConstraintPtrInput {
	return (*googleCloudAiplatformV1beta1StudyTimeConstraintPtrType)(v)
}

func (*googleCloudAiplatformV1beta1StudyTimeConstraintPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1StudyTimeConstraint)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1StudyTimeConstraintPtrType) ToGoogleCloudAiplatformV1beta1StudyTimeConstraintPtrOutput() GoogleCloudAiplatformV1beta1StudyTimeConstraintPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1StudyTimeConstraintPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1StudyTimeConstraintPtrType) ToGoogleCloudAiplatformV1beta1StudyTimeConstraintPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudyTimeConstraintPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1StudyTimeConstraintPtrOutput)
}

// Time-based Constraint for Study
type GoogleCloudAiplatformV1beta1StudyTimeConstraintOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1StudyTimeConstraintOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1StudyTimeConstraint)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1StudyTimeConstraintOutput) ToGoogleCloudAiplatformV1beta1StudyTimeConstraintOutput() GoogleCloudAiplatformV1beta1StudyTimeConstraintOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StudyTimeConstraintOutput) ToGoogleCloudAiplatformV1beta1StudyTimeConstraintOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudyTimeConstraintOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StudyTimeConstraintOutput) ToGoogleCloudAiplatformV1beta1StudyTimeConstraintPtrOutput() GoogleCloudAiplatformV1beta1StudyTimeConstraintPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1StudyTimeConstraintPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1StudyTimeConstraintOutput) ToGoogleCloudAiplatformV1beta1StudyTimeConstraintPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudyTimeConstraintPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1StudyTimeConstraint) *GoogleCloudAiplatformV1beta1StudyTimeConstraint {
		return &v
	}).(GoogleCloudAiplatformV1beta1StudyTimeConstraintPtrOutput)
}

// Compares the wallclock time to this time. Must use UTC timezone.
func (o GoogleCloudAiplatformV1beta1StudyTimeConstraintOutput) EndTime() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudyTimeConstraint) *string { return v.EndTime }).(pulumi.StringPtrOutput)
}

// Counts the wallclock time passed since the creation of this Study.
func (o GoogleCloudAiplatformV1beta1StudyTimeConstraintOutput) MaxDuration() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudyTimeConstraint) *string { return v.MaxDuration }).(pulumi.StringPtrOutput)
}

type GoogleCloudAiplatformV1beta1StudyTimeConstraintPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1StudyTimeConstraintPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1StudyTimeConstraint)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1StudyTimeConstraintPtrOutput) ToGoogleCloudAiplatformV1beta1StudyTimeConstraintPtrOutput() GoogleCloudAiplatformV1beta1StudyTimeConstraintPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StudyTimeConstraintPtrOutput) ToGoogleCloudAiplatformV1beta1StudyTimeConstraintPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudyTimeConstraintPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StudyTimeConstraintPtrOutput) Elem() GoogleCloudAiplatformV1beta1StudyTimeConstraintOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1StudyTimeConstraint) GoogleCloudAiplatformV1beta1StudyTimeConstraint {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1StudyTimeConstraint
		return ret
	}).(GoogleCloudAiplatformV1beta1StudyTimeConstraintOutput)
}

// Compares the wallclock time to this time. Must use UTC timezone.
func (o GoogleCloudAiplatformV1beta1StudyTimeConstraintPtrOutput) EndTime() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1StudyTimeConstraint) *string {
		if v == nil {
			return nil
		}
		return v.EndTime
	}).(pulumi.StringPtrOutput)
}

// Counts the wallclock time passed since the creation of this Study.
func (o GoogleCloudAiplatformV1beta1StudyTimeConstraintPtrOutput) MaxDuration() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1StudyTimeConstraint) *string {
		if v == nil {
			return nil
		}
		return v.MaxDuration
	}).(pulumi.StringPtrOutput)
}

// Time-based Constraint for Study
type GoogleCloudAiplatformV1beta1StudyTimeConstraintResponse struct {
	// Compares the wallclock time to this time. Must use UTC timezone.
	EndTime string `pulumi:"endTime"`
	// Counts the wallclock time passed since the creation of this Study.
	MaxDuration string `pulumi:"maxDuration"`
}

// Time-based Constraint for Study
type GoogleCloudAiplatformV1beta1StudyTimeConstraintResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1StudyTimeConstraintResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1StudyTimeConstraintResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1StudyTimeConstraintResponseOutput) ToGoogleCloudAiplatformV1beta1StudyTimeConstraintResponseOutput() GoogleCloudAiplatformV1beta1StudyTimeConstraintResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1StudyTimeConstraintResponseOutput) ToGoogleCloudAiplatformV1beta1StudyTimeConstraintResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1StudyTimeConstraintResponseOutput {
	return o
}

// Compares the wallclock time to this time. Must use UTC timezone.
func (o GoogleCloudAiplatformV1beta1StudyTimeConstraintResponseOutput) EndTime() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudyTimeConstraintResponse) string { return v.EndTime }).(pulumi.StringOutput)
}

// Counts the wallclock time passed since the creation of this Study.
func (o GoogleCloudAiplatformV1beta1StudyTimeConstraintResponseOutput) MaxDuration() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1StudyTimeConstraintResponse) string { return v.MaxDuration }).(pulumi.StringOutput)
}

// Describes metadata for a TensorboardTimeSeries.
type GoogleCloudAiplatformV1beta1TensorboardTimeSeriesMetadataResponse struct {
	// The largest blob sequence length (number of blobs) of all data points in this time series, if its ValueType is BLOB_SEQUENCE.
	MaxBlobSequenceLength string `pulumi:"maxBlobSequenceLength"`
	// Max step index of all data points within a TensorboardTimeSeries.
	MaxStep string `pulumi:"maxStep"`
	// Max wall clock timestamp of all data points within a TensorboardTimeSeries.
	MaxWallTime string `pulumi:"maxWallTime"`
}

// Describes metadata for a TensorboardTimeSeries.
type GoogleCloudAiplatformV1beta1TensorboardTimeSeriesMetadataResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1TensorboardTimeSeriesMetadataResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1TensorboardTimeSeriesMetadataResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1TensorboardTimeSeriesMetadataResponseOutput) ToGoogleCloudAiplatformV1beta1TensorboardTimeSeriesMetadataResponseOutput() GoogleCloudAiplatformV1beta1TensorboardTimeSeriesMetadataResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1TensorboardTimeSeriesMetadataResponseOutput) ToGoogleCloudAiplatformV1beta1TensorboardTimeSeriesMetadataResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1TensorboardTimeSeriesMetadataResponseOutput {
	return o
}

// The largest blob sequence length (number of blobs) of all data points in this time series, if its ValueType is BLOB_SEQUENCE.
func (o GoogleCloudAiplatformV1beta1TensorboardTimeSeriesMetadataResponseOutput) MaxBlobSequenceLength() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1TensorboardTimeSeriesMetadataResponse) string {
		return v.MaxBlobSequenceLength
	}).(pulumi.StringOutput)
}

// Max step index of all data points within a TensorboardTimeSeries.
func (o GoogleCloudAiplatformV1beta1TensorboardTimeSeriesMetadataResponseOutput) MaxStep() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1TensorboardTimeSeriesMetadataResponse) string { return v.MaxStep }).(pulumi.StringOutput)
}

// Max wall clock timestamp of all data points within a TensorboardTimeSeries.
func (o GoogleCloudAiplatformV1beta1TensorboardTimeSeriesMetadataResponseOutput) MaxWallTime() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1TensorboardTimeSeriesMetadataResponse) string { return v.MaxWallTime }).(pulumi.StringOutput)
}

// The config for feature monitoring threshold.
type GoogleCloudAiplatformV1beta1ThresholdConfig struct {
	// Specify a threshold value that can trigger the alert. If this threshold config is for feature distribution distance: 1. For categorical feature, the distribution distance is calculated by L-inifinity norm. 2. For numerical feature, the distribution distance is calculated by Jensen–Shannon divergence. Each feature must have a non-zero threshold if they need to be monitored. Otherwise no alert will be triggered for that feature.
	Value *float64 `pulumi:"value"`
}

// GoogleCloudAiplatformV1beta1ThresholdConfigInput is an input type that accepts GoogleCloudAiplatformV1beta1ThresholdConfigArgs and GoogleCloudAiplatformV1beta1ThresholdConfigOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1ThresholdConfigInput` via:
//
//	GoogleCloudAiplatformV1beta1ThresholdConfigArgs{...}
type GoogleCloudAiplatformV1beta1ThresholdConfigInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1ThresholdConfigOutput() GoogleCloudAiplatformV1beta1ThresholdConfigOutput
	ToGoogleCloudAiplatformV1beta1ThresholdConfigOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1ThresholdConfigOutput
}

// The config for feature monitoring threshold.
type GoogleCloudAiplatformV1beta1ThresholdConfigArgs struct {
	// Specify a threshold value that can trigger the alert. If this threshold config is for feature distribution distance: 1. For categorical feature, the distribution distance is calculated by L-inifinity norm. 2. For numerical feature, the distribution distance is calculated by Jensen–Shannon divergence. Each feature must have a non-zero threshold if they need to be monitored. Otherwise no alert will be triggered for that feature.
	Value pulumi.Float64PtrInput `pulumi:"value"`
}

func (GoogleCloudAiplatformV1beta1ThresholdConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ThresholdConfig)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1ThresholdConfigArgs) ToGoogleCloudAiplatformV1beta1ThresholdConfigOutput() GoogleCloudAiplatformV1beta1ThresholdConfigOutput {
	return i.ToGoogleCloudAiplatformV1beta1ThresholdConfigOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1ThresholdConfigArgs) ToGoogleCloudAiplatformV1beta1ThresholdConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ThresholdConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ThresholdConfigOutput)
}

func (i GoogleCloudAiplatformV1beta1ThresholdConfigArgs) ToGoogleCloudAiplatformV1beta1ThresholdConfigPtrOutput() GoogleCloudAiplatformV1beta1ThresholdConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1ThresholdConfigPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1ThresholdConfigArgs) ToGoogleCloudAiplatformV1beta1ThresholdConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ThresholdConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ThresholdConfigOutput).ToGoogleCloudAiplatformV1beta1ThresholdConfigPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1ThresholdConfigPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1ThresholdConfigArgs, GoogleCloudAiplatformV1beta1ThresholdConfigPtr and GoogleCloudAiplatformV1beta1ThresholdConfigPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1ThresholdConfigPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1ThresholdConfigArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1ThresholdConfigPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1ThresholdConfigPtrOutput() GoogleCloudAiplatformV1beta1ThresholdConfigPtrOutput
	ToGoogleCloudAiplatformV1beta1ThresholdConfigPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1ThresholdConfigPtrOutput
}

type googleCloudAiplatformV1beta1ThresholdConfigPtrType GoogleCloudAiplatformV1beta1ThresholdConfigArgs

func GoogleCloudAiplatformV1beta1ThresholdConfigPtr(v *GoogleCloudAiplatformV1beta1ThresholdConfigArgs) GoogleCloudAiplatformV1beta1ThresholdConfigPtrInput {
	return (*googleCloudAiplatformV1beta1ThresholdConfigPtrType)(v)
}

func (*googleCloudAiplatformV1beta1ThresholdConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1ThresholdConfig)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1ThresholdConfigPtrType) ToGoogleCloudAiplatformV1beta1ThresholdConfigPtrOutput() GoogleCloudAiplatformV1beta1ThresholdConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1ThresholdConfigPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1ThresholdConfigPtrType) ToGoogleCloudAiplatformV1beta1ThresholdConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ThresholdConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ThresholdConfigPtrOutput)
}

// The config for feature monitoring threshold.
type GoogleCloudAiplatformV1beta1ThresholdConfigOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ThresholdConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ThresholdConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ThresholdConfigOutput) ToGoogleCloudAiplatformV1beta1ThresholdConfigOutput() GoogleCloudAiplatformV1beta1ThresholdConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ThresholdConfigOutput) ToGoogleCloudAiplatformV1beta1ThresholdConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ThresholdConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ThresholdConfigOutput) ToGoogleCloudAiplatformV1beta1ThresholdConfigPtrOutput() GoogleCloudAiplatformV1beta1ThresholdConfigPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1ThresholdConfigPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1ThresholdConfigOutput) ToGoogleCloudAiplatformV1beta1ThresholdConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ThresholdConfigPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1ThresholdConfig) *GoogleCloudAiplatformV1beta1ThresholdConfig {
		return &v
	}).(GoogleCloudAiplatformV1beta1ThresholdConfigPtrOutput)
}

// Specify a threshold value that can trigger the alert. If this threshold config is for feature distribution distance: 1. For categorical feature, the distribution distance is calculated by L-inifinity norm. 2. For numerical feature, the distribution distance is calculated by Jensen–Shannon divergence. Each feature must have a non-zero threshold if they need to be monitored. Otherwise no alert will be triggered for that feature.
func (o GoogleCloudAiplatformV1beta1ThresholdConfigOutput) Value() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ThresholdConfig) *float64 { return v.Value }).(pulumi.Float64PtrOutput)
}

type GoogleCloudAiplatformV1beta1ThresholdConfigPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ThresholdConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1ThresholdConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ThresholdConfigPtrOutput) ToGoogleCloudAiplatformV1beta1ThresholdConfigPtrOutput() GoogleCloudAiplatformV1beta1ThresholdConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ThresholdConfigPtrOutput) ToGoogleCloudAiplatformV1beta1ThresholdConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ThresholdConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ThresholdConfigPtrOutput) Elem() GoogleCloudAiplatformV1beta1ThresholdConfigOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ThresholdConfig) GoogleCloudAiplatformV1beta1ThresholdConfig {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1ThresholdConfig
		return ret
	}).(GoogleCloudAiplatformV1beta1ThresholdConfigOutput)
}

// Specify a threshold value that can trigger the alert. If this threshold config is for feature distribution distance: 1. For categorical feature, the distribution distance is calculated by L-inifinity norm. 2. For numerical feature, the distribution distance is calculated by Jensen–Shannon divergence. Each feature must have a non-zero threshold if they need to be monitored. Otherwise no alert will be triggered for that feature.
func (o GoogleCloudAiplatformV1beta1ThresholdConfigPtrOutput) Value() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1ThresholdConfig) *float64 {
		if v == nil {
			return nil
		}
		return v.Value
	}).(pulumi.Float64PtrOutput)
}

// The config for feature monitoring threshold.
type GoogleCloudAiplatformV1beta1ThresholdConfigResponse struct {
	// Specify a threshold value that can trigger the alert. If this threshold config is for feature distribution distance: 1. For categorical feature, the distribution distance is calculated by L-inifinity norm. 2. For numerical feature, the distribution distance is calculated by Jensen–Shannon divergence. Each feature must have a non-zero threshold if they need to be monitored. Otherwise no alert will be triggered for that feature.
	Value float64 `pulumi:"value"`
}

// The config for feature monitoring threshold.
type GoogleCloudAiplatformV1beta1ThresholdConfigResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ThresholdConfigResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ThresholdConfigResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ThresholdConfigResponseOutput) ToGoogleCloudAiplatformV1beta1ThresholdConfigResponseOutput() GoogleCloudAiplatformV1beta1ThresholdConfigResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ThresholdConfigResponseOutput) ToGoogleCloudAiplatformV1beta1ThresholdConfigResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ThresholdConfigResponseOutput {
	return o
}

// Specify a threshold value that can trigger the alert. If this threshold config is for feature distribution distance: 1. For categorical feature, the distribution distance is calculated by L-inifinity norm. 2. For numerical feature, the distribution distance is calculated by Jensen–Shannon divergence. Each feature must have a non-zero threshold if they need to be monitored. Otherwise no alert will be triggered for that feature.
func (o GoogleCloudAiplatformV1beta1ThresholdConfigResponseOutput) Value() pulumi.Float64Output {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ThresholdConfigResponse) float64 { return v.Value }).(pulumi.Float64Output)
}

// Assigns input data to training, validation, and test sets based on a provided timestamps. The youngest data pieces are assigned to training set, next to validation set, and the oldest to the test set. Supported only for tabular Datasets.
type GoogleCloudAiplatformV1beta1TimestampSplit struct {
	// The key is a name of one of the Dataset's data columns. The values of the key (the values in the column) must be in RFC 3339 `date-time` format, where `time-offset` = `"Z"` (e.g. 1985-04-12T23:20:50.52Z). If for a piece of data the key is not present or has an invalid value, that piece is ignored by the pipeline.
	Key string `pulumi:"key"`
	// The fraction of the input data that is to be used to evaluate the Model.
	TestFraction *float64 `pulumi:"testFraction"`
	// The fraction of the input data that is to be used to train the Model.
	TrainingFraction *float64 `pulumi:"trainingFraction"`
	// The fraction of the input data that is to be used to validate the Model.
	ValidationFraction *float64 `pulumi:"validationFraction"`
}

// GoogleCloudAiplatformV1beta1TimestampSplitInput is an input type that accepts GoogleCloudAiplatformV1beta1TimestampSplitArgs and GoogleCloudAiplatformV1beta1TimestampSplitOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1TimestampSplitInput` via:
//
//	GoogleCloudAiplatformV1beta1TimestampSplitArgs{...}
type GoogleCloudAiplatformV1beta1TimestampSplitInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1TimestampSplitOutput() GoogleCloudAiplatformV1beta1TimestampSplitOutput
	ToGoogleCloudAiplatformV1beta1TimestampSplitOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1TimestampSplitOutput
}

// Assigns input data to training, validation, and test sets based on a provided timestamps. The youngest data pieces are assigned to training set, next to validation set, and the oldest to the test set. Supported only for tabular Datasets.
type GoogleCloudAiplatformV1beta1TimestampSplitArgs struct {
	// The key is a name of one of the Dataset's data columns. The values of the key (the values in the column) must be in RFC 3339 `date-time` format, where `time-offset` = `"Z"` (e.g. 1985-04-12T23:20:50.52Z). If for a piece of data the key is not present or has an invalid value, that piece is ignored by the pipeline.
	Key pulumi.StringInput `pulumi:"key"`
	// The fraction of the input data that is to be used to evaluate the Model.
	TestFraction pulumi.Float64PtrInput `pulumi:"testFraction"`
	// The fraction of the input data that is to be used to train the Model.
	TrainingFraction pulumi.Float64PtrInput `pulumi:"trainingFraction"`
	// The fraction of the input data that is to be used to validate the Model.
	ValidationFraction pulumi.Float64PtrInput `pulumi:"validationFraction"`
}

func (GoogleCloudAiplatformV1beta1TimestampSplitArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1TimestampSplit)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1TimestampSplitArgs) ToGoogleCloudAiplatformV1beta1TimestampSplitOutput() GoogleCloudAiplatformV1beta1TimestampSplitOutput {
	return i.ToGoogleCloudAiplatformV1beta1TimestampSplitOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1TimestampSplitArgs) ToGoogleCloudAiplatformV1beta1TimestampSplitOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1TimestampSplitOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1TimestampSplitOutput)
}

func (i GoogleCloudAiplatformV1beta1TimestampSplitArgs) ToGoogleCloudAiplatformV1beta1TimestampSplitPtrOutput() GoogleCloudAiplatformV1beta1TimestampSplitPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1TimestampSplitPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1TimestampSplitArgs) ToGoogleCloudAiplatformV1beta1TimestampSplitPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1TimestampSplitPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1TimestampSplitOutput).ToGoogleCloudAiplatformV1beta1TimestampSplitPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1TimestampSplitPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1TimestampSplitArgs, GoogleCloudAiplatformV1beta1TimestampSplitPtr and GoogleCloudAiplatformV1beta1TimestampSplitPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1TimestampSplitPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1TimestampSplitArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1TimestampSplitPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1TimestampSplitPtrOutput() GoogleCloudAiplatformV1beta1TimestampSplitPtrOutput
	ToGoogleCloudAiplatformV1beta1TimestampSplitPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1TimestampSplitPtrOutput
}

type googleCloudAiplatformV1beta1TimestampSplitPtrType GoogleCloudAiplatformV1beta1TimestampSplitArgs

func GoogleCloudAiplatformV1beta1TimestampSplitPtr(v *GoogleCloudAiplatformV1beta1TimestampSplitArgs) GoogleCloudAiplatformV1beta1TimestampSplitPtrInput {
	return (*googleCloudAiplatformV1beta1TimestampSplitPtrType)(v)
}

func (*googleCloudAiplatformV1beta1TimestampSplitPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1TimestampSplit)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1TimestampSplitPtrType) ToGoogleCloudAiplatformV1beta1TimestampSplitPtrOutput() GoogleCloudAiplatformV1beta1TimestampSplitPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1TimestampSplitPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1TimestampSplitPtrType) ToGoogleCloudAiplatformV1beta1TimestampSplitPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1TimestampSplitPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1TimestampSplitPtrOutput)
}

// Assigns input data to training, validation, and test sets based on a provided timestamps. The youngest data pieces are assigned to training set, next to validation set, and the oldest to the test set. Supported only for tabular Datasets.
type GoogleCloudAiplatformV1beta1TimestampSplitOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1TimestampSplitOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1TimestampSplit)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1TimestampSplitOutput) ToGoogleCloudAiplatformV1beta1TimestampSplitOutput() GoogleCloudAiplatformV1beta1TimestampSplitOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1TimestampSplitOutput) ToGoogleCloudAiplatformV1beta1TimestampSplitOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1TimestampSplitOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1TimestampSplitOutput) ToGoogleCloudAiplatformV1beta1TimestampSplitPtrOutput() GoogleCloudAiplatformV1beta1TimestampSplitPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1TimestampSplitPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1TimestampSplitOutput) ToGoogleCloudAiplatformV1beta1TimestampSplitPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1TimestampSplitPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1TimestampSplit) *GoogleCloudAiplatformV1beta1TimestampSplit {
		return &v
	}).(GoogleCloudAiplatformV1beta1TimestampSplitPtrOutput)
}

// The key is a name of one of the Dataset's data columns. The values of the key (the values in the column) must be in RFC 3339 `date-time` format, where `time-offset` = `"Z"` (e.g. 1985-04-12T23:20:50.52Z). If for a piece of data the key is not present or has an invalid value, that piece is ignored by the pipeline.
func (o GoogleCloudAiplatformV1beta1TimestampSplitOutput) Key() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1TimestampSplit) string { return v.Key }).(pulumi.StringOutput)
}

// The fraction of the input data that is to be used to evaluate the Model.
func (o GoogleCloudAiplatformV1beta1TimestampSplitOutput) TestFraction() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1TimestampSplit) *float64 { return v.TestFraction }).(pulumi.Float64PtrOutput)
}

// The fraction of the input data that is to be used to train the Model.
func (o GoogleCloudAiplatformV1beta1TimestampSplitOutput) TrainingFraction() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1TimestampSplit) *float64 { return v.TrainingFraction }).(pulumi.Float64PtrOutput)
}

// The fraction of the input data that is to be used to validate the Model.
func (o GoogleCloudAiplatformV1beta1TimestampSplitOutput) ValidationFraction() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1TimestampSplit) *float64 { return v.ValidationFraction }).(pulumi.Float64PtrOutput)
}

type GoogleCloudAiplatformV1beta1TimestampSplitPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1TimestampSplitPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1TimestampSplit)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1TimestampSplitPtrOutput) ToGoogleCloudAiplatformV1beta1TimestampSplitPtrOutput() GoogleCloudAiplatformV1beta1TimestampSplitPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1TimestampSplitPtrOutput) ToGoogleCloudAiplatformV1beta1TimestampSplitPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1TimestampSplitPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1TimestampSplitPtrOutput) Elem() GoogleCloudAiplatformV1beta1TimestampSplitOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1TimestampSplit) GoogleCloudAiplatformV1beta1TimestampSplit {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1TimestampSplit
		return ret
	}).(GoogleCloudAiplatformV1beta1TimestampSplitOutput)
}

// The key is a name of one of the Dataset's data columns. The values of the key (the values in the column) must be in RFC 3339 `date-time` format, where `time-offset` = `"Z"` (e.g. 1985-04-12T23:20:50.52Z). If for a piece of data the key is not present or has an invalid value, that piece is ignored by the pipeline.
func (o GoogleCloudAiplatformV1beta1TimestampSplitPtrOutput) Key() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1TimestampSplit) *string {
		if v == nil {
			return nil
		}
		return &v.Key
	}).(pulumi.StringPtrOutput)
}

// The fraction of the input data that is to be used to evaluate the Model.
func (o GoogleCloudAiplatformV1beta1TimestampSplitPtrOutput) TestFraction() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1TimestampSplit) *float64 {
		if v == nil {
			return nil
		}
		return v.TestFraction
	}).(pulumi.Float64PtrOutput)
}

// The fraction of the input data that is to be used to train the Model.
func (o GoogleCloudAiplatformV1beta1TimestampSplitPtrOutput) TrainingFraction() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1TimestampSplit) *float64 {
		if v == nil {
			return nil
		}
		return v.TrainingFraction
	}).(pulumi.Float64PtrOutput)
}

// The fraction of the input data that is to be used to validate the Model.
func (o GoogleCloudAiplatformV1beta1TimestampSplitPtrOutput) ValidationFraction() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1TimestampSplit) *float64 {
		if v == nil {
			return nil
		}
		return v.ValidationFraction
	}).(pulumi.Float64PtrOutput)
}

// Assigns input data to training, validation, and test sets based on a provided timestamps. The youngest data pieces are assigned to training set, next to validation set, and the oldest to the test set. Supported only for tabular Datasets.
type GoogleCloudAiplatformV1beta1TimestampSplitResponse struct {
	// The key is a name of one of the Dataset's data columns. The values of the key (the values in the column) must be in RFC 3339 `date-time` format, where `time-offset` = `"Z"` (e.g. 1985-04-12T23:20:50.52Z). If for a piece of data the key is not present or has an invalid value, that piece is ignored by the pipeline.
	Key string `pulumi:"key"`
	// The fraction of the input data that is to be used to evaluate the Model.
	TestFraction float64 `pulumi:"testFraction"`
	// The fraction of the input data that is to be used to train the Model.
	TrainingFraction float64 `pulumi:"trainingFraction"`
	// The fraction of the input data that is to be used to validate the Model.
	ValidationFraction float64 `pulumi:"validationFraction"`
}

// Assigns input data to training, validation, and test sets based on a provided timestamps. The youngest data pieces are assigned to training set, next to validation set, and the oldest to the test set. Supported only for tabular Datasets.
type GoogleCloudAiplatformV1beta1TimestampSplitResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1TimestampSplitResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1TimestampSplitResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1TimestampSplitResponseOutput) ToGoogleCloudAiplatformV1beta1TimestampSplitResponseOutput() GoogleCloudAiplatformV1beta1TimestampSplitResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1TimestampSplitResponseOutput) ToGoogleCloudAiplatformV1beta1TimestampSplitResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1TimestampSplitResponseOutput {
	return o
}

// The key is a name of one of the Dataset's data columns. The values of the key (the values in the column) must be in RFC 3339 `date-time` format, where `time-offset` = `"Z"` (e.g. 1985-04-12T23:20:50.52Z). If for a piece of data the key is not present or has an invalid value, that piece is ignored by the pipeline.
func (o GoogleCloudAiplatformV1beta1TimestampSplitResponseOutput) Key() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1TimestampSplitResponse) string { return v.Key }).(pulumi.StringOutput)
}

// The fraction of the input data that is to be used to evaluate the Model.
func (o GoogleCloudAiplatformV1beta1TimestampSplitResponseOutput) TestFraction() pulumi.Float64Output {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1TimestampSplitResponse) float64 { return v.TestFraction }).(pulumi.Float64Output)
}

// The fraction of the input data that is to be used to train the Model.
func (o GoogleCloudAiplatformV1beta1TimestampSplitResponseOutput) TrainingFraction() pulumi.Float64Output {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1TimestampSplitResponse) float64 { return v.TrainingFraction }).(pulumi.Float64Output)
}

// The fraction of the input data that is to be used to validate the Model.
func (o GoogleCloudAiplatformV1beta1TimestampSplitResponseOutput) ValidationFraction() pulumi.Float64Output {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1TimestampSplitResponse) float64 { return v.ValidationFraction }).(pulumi.Float64Output)
}

// CMLE training config. For every active learning labeling iteration, system will train a machine learning model on CMLE. The trained model will be used by data sampling algorithm to select DataItems.
type GoogleCloudAiplatformV1beta1TrainingConfig struct {
	// The timeout hours for the CMLE training job, expressed in milli hours i.e. 1,000 value in this field means 1 hour.
	TimeoutTrainingMilliHours *string `pulumi:"timeoutTrainingMilliHours"`
}

// GoogleCloudAiplatformV1beta1TrainingConfigInput is an input type that accepts GoogleCloudAiplatformV1beta1TrainingConfigArgs and GoogleCloudAiplatformV1beta1TrainingConfigOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1TrainingConfigInput` via:
//
//	GoogleCloudAiplatformV1beta1TrainingConfigArgs{...}
type GoogleCloudAiplatformV1beta1TrainingConfigInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1TrainingConfigOutput() GoogleCloudAiplatformV1beta1TrainingConfigOutput
	ToGoogleCloudAiplatformV1beta1TrainingConfigOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1TrainingConfigOutput
}

// CMLE training config. For every active learning labeling iteration, system will train a machine learning model on CMLE. The trained model will be used by data sampling algorithm to select DataItems.
type GoogleCloudAiplatformV1beta1TrainingConfigArgs struct {
	// The timeout hours for the CMLE training job, expressed in milli hours i.e. 1,000 value in this field means 1 hour.
	TimeoutTrainingMilliHours pulumi.StringPtrInput `pulumi:"timeoutTrainingMilliHours"`
}

func (GoogleCloudAiplatformV1beta1TrainingConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1TrainingConfig)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1TrainingConfigArgs) ToGoogleCloudAiplatformV1beta1TrainingConfigOutput() GoogleCloudAiplatformV1beta1TrainingConfigOutput {
	return i.ToGoogleCloudAiplatformV1beta1TrainingConfigOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1TrainingConfigArgs) ToGoogleCloudAiplatformV1beta1TrainingConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1TrainingConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1TrainingConfigOutput)
}

func (i GoogleCloudAiplatformV1beta1TrainingConfigArgs) ToGoogleCloudAiplatformV1beta1TrainingConfigPtrOutput() GoogleCloudAiplatformV1beta1TrainingConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1TrainingConfigPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1TrainingConfigArgs) ToGoogleCloudAiplatformV1beta1TrainingConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1TrainingConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1TrainingConfigOutput).ToGoogleCloudAiplatformV1beta1TrainingConfigPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1TrainingConfigPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1TrainingConfigArgs, GoogleCloudAiplatformV1beta1TrainingConfigPtr and GoogleCloudAiplatformV1beta1TrainingConfigPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1TrainingConfigPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1TrainingConfigArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1TrainingConfigPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1TrainingConfigPtrOutput() GoogleCloudAiplatformV1beta1TrainingConfigPtrOutput
	ToGoogleCloudAiplatformV1beta1TrainingConfigPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1TrainingConfigPtrOutput
}

type googleCloudAiplatformV1beta1TrainingConfigPtrType GoogleCloudAiplatformV1beta1TrainingConfigArgs

func GoogleCloudAiplatformV1beta1TrainingConfigPtr(v *GoogleCloudAiplatformV1beta1TrainingConfigArgs) GoogleCloudAiplatformV1beta1TrainingConfigPtrInput {
	return (*googleCloudAiplatformV1beta1TrainingConfigPtrType)(v)
}

func (*googleCloudAiplatformV1beta1TrainingConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1TrainingConfig)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1TrainingConfigPtrType) ToGoogleCloudAiplatformV1beta1TrainingConfigPtrOutput() GoogleCloudAiplatformV1beta1TrainingConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1TrainingConfigPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1TrainingConfigPtrType) ToGoogleCloudAiplatformV1beta1TrainingConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1TrainingConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1TrainingConfigPtrOutput)
}

// CMLE training config. For every active learning labeling iteration, system will train a machine learning model on CMLE. The trained model will be used by data sampling algorithm to select DataItems.
type GoogleCloudAiplatformV1beta1TrainingConfigOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1TrainingConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1TrainingConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1TrainingConfigOutput) ToGoogleCloudAiplatformV1beta1TrainingConfigOutput() GoogleCloudAiplatformV1beta1TrainingConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1TrainingConfigOutput) ToGoogleCloudAiplatformV1beta1TrainingConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1TrainingConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1TrainingConfigOutput) ToGoogleCloudAiplatformV1beta1TrainingConfigPtrOutput() GoogleCloudAiplatformV1beta1TrainingConfigPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1TrainingConfigPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1TrainingConfigOutput) ToGoogleCloudAiplatformV1beta1TrainingConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1TrainingConfigPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1TrainingConfig) *GoogleCloudAiplatformV1beta1TrainingConfig {
		return &v
	}).(GoogleCloudAiplatformV1beta1TrainingConfigPtrOutput)
}

// The timeout hours for the CMLE training job, expressed in milli hours i.e. 1,000 value in this field means 1 hour.
func (o GoogleCloudAiplatformV1beta1TrainingConfigOutput) TimeoutTrainingMilliHours() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1TrainingConfig) *string { return v.TimeoutTrainingMilliHours }).(pulumi.StringPtrOutput)
}

type GoogleCloudAiplatformV1beta1TrainingConfigPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1TrainingConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1TrainingConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1TrainingConfigPtrOutput) ToGoogleCloudAiplatformV1beta1TrainingConfigPtrOutput() GoogleCloudAiplatformV1beta1TrainingConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1TrainingConfigPtrOutput) ToGoogleCloudAiplatformV1beta1TrainingConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1TrainingConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1TrainingConfigPtrOutput) Elem() GoogleCloudAiplatformV1beta1TrainingConfigOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1TrainingConfig) GoogleCloudAiplatformV1beta1TrainingConfig {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1TrainingConfig
		return ret
	}).(GoogleCloudAiplatformV1beta1TrainingConfigOutput)
}

// The timeout hours for the CMLE training job, expressed in milli hours i.e. 1,000 value in this field means 1 hour.
func (o GoogleCloudAiplatformV1beta1TrainingConfigPtrOutput) TimeoutTrainingMilliHours() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1TrainingConfig) *string {
		if v == nil {
			return nil
		}
		return v.TimeoutTrainingMilliHours
	}).(pulumi.StringPtrOutput)
}

// CMLE training config. For every active learning labeling iteration, system will train a machine learning model on CMLE. The trained model will be used by data sampling algorithm to select DataItems.
type GoogleCloudAiplatformV1beta1TrainingConfigResponse struct {
	// The timeout hours for the CMLE training job, expressed in milli hours i.e. 1,000 value in this field means 1 hour.
	TimeoutTrainingMilliHours string `pulumi:"timeoutTrainingMilliHours"`
}

// CMLE training config. For every active learning labeling iteration, system will train a machine learning model on CMLE. The trained model will be used by data sampling algorithm to select DataItems.
type GoogleCloudAiplatformV1beta1TrainingConfigResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1TrainingConfigResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1TrainingConfigResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1TrainingConfigResponseOutput) ToGoogleCloudAiplatformV1beta1TrainingConfigResponseOutput() GoogleCloudAiplatformV1beta1TrainingConfigResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1TrainingConfigResponseOutput) ToGoogleCloudAiplatformV1beta1TrainingConfigResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1TrainingConfigResponseOutput {
	return o
}

// The timeout hours for the CMLE training job, expressed in milli hours i.e. 1,000 value in this field means 1 hour.
func (o GoogleCloudAiplatformV1beta1TrainingConfigResponseOutput) TimeoutTrainingMilliHours() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1TrainingConfigResponse) string { return v.TimeoutTrainingMilliHours }).(pulumi.StringOutput)
}

// A message representing a parameter to be tuned.
type GoogleCloudAiplatformV1beta1TrialParameterResponse struct {
	// The ID of the parameter. The parameter should be defined in StudySpec's Parameters.
	ParameterId string `pulumi:"parameterId"`
	// The value of the parameter. `number_value` will be set if a parameter defined in StudySpec is in type 'INTEGER', 'DOUBLE' or 'DISCRETE'. `string_value` will be set if a parameter defined in StudySpec is in type 'CATEGORICAL'.
	Value interface{} `pulumi:"value"`
}

// A message representing a parameter to be tuned.
type GoogleCloudAiplatformV1beta1TrialParameterResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1TrialParameterResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1TrialParameterResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1TrialParameterResponseOutput) ToGoogleCloudAiplatformV1beta1TrialParameterResponseOutput() GoogleCloudAiplatformV1beta1TrialParameterResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1TrialParameterResponseOutput) ToGoogleCloudAiplatformV1beta1TrialParameterResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1TrialParameterResponseOutput {
	return o
}

// The ID of the parameter. The parameter should be defined in StudySpec's Parameters.
func (o GoogleCloudAiplatformV1beta1TrialParameterResponseOutput) ParameterId() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1TrialParameterResponse) string { return v.ParameterId }).(pulumi.StringOutput)
}

// The value of the parameter. `number_value` will be set if a parameter defined in StudySpec is in type 'INTEGER', 'DOUBLE' or 'DISCRETE'. `string_value` will be set if a parameter defined in StudySpec is in type 'CATEGORICAL'.
func (o GoogleCloudAiplatformV1beta1TrialParameterResponseOutput) Value() pulumi.AnyOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1TrialParameterResponse) interface{} { return v.Value }).(pulumi.AnyOutput)
}

type GoogleCloudAiplatformV1beta1TrialParameterResponseArrayOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1TrialParameterResponseArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1beta1TrialParameterResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1TrialParameterResponseArrayOutput) ToGoogleCloudAiplatformV1beta1TrialParameterResponseArrayOutput() GoogleCloudAiplatformV1beta1TrialParameterResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1TrialParameterResponseArrayOutput) ToGoogleCloudAiplatformV1beta1TrialParameterResponseArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1TrialParameterResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1TrialParameterResponseArrayOutput) Index(i pulumi.IntInput) GoogleCloudAiplatformV1beta1TrialParameterResponseOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GoogleCloudAiplatformV1beta1TrialParameterResponse {
		return vs[0].([]GoogleCloudAiplatformV1beta1TrialParameterResponse)[vs[1].(int)]
	}).(GoogleCloudAiplatformV1beta1TrialParameterResponseOutput)
}

// A message representing a Trial. A Trial contains a unique set of Parameters that has been or will be evaluated, along with the objective metrics got by running the Trial.
type GoogleCloudAiplatformV1beta1TrialResponse struct {
	// The identifier of the client that originally requested this Trial. Each client is identified by a unique client_id. When a client asks for a suggestion, Vertex AI Vizier will assign it a Trial. The client should evaluate the Trial, complete it, and report back to Vertex AI Vizier. If suggestion is asked again by same client_id before the Trial is completed, the same Trial will be returned. Multiple clients with different client_ids can ask for suggestions simultaneously, each of them will get their own Trial.
	ClientId string `pulumi:"clientId"`
	// The CustomJob name linked to the Trial. It's set for a HyperparameterTuningJob's Trial.
	CustomJob string `pulumi:"customJob"`
	// Time when the Trial's status changed to `SUCCEEDED` or `INFEASIBLE`.
	EndTime string `pulumi:"endTime"`
	// The final measurement containing the objective value.
	FinalMeasurement GoogleCloudAiplatformV1beta1MeasurementResponse `pulumi:"finalMeasurement"`
	// A human readable string describing why the Trial is infeasible. This is set only if Trial state is `INFEASIBLE`.
	InfeasibleReason string `pulumi:"infeasibleReason"`
	// A list of measurements that are strictly lexicographically ordered by their induced tuples (steps, elapsed_duration). These are used for early stopping computations.
	Measurements []GoogleCloudAiplatformV1beta1MeasurementResponse `pulumi:"measurements"`
	// Resource name of the Trial assigned by the service.
	Name string `pulumi:"name"`
	// The parameters of the Trial.
	Parameters []GoogleCloudAiplatformV1beta1TrialParameterResponse `pulumi:"parameters"`
	// Time when the Trial was started.
	StartTime string `pulumi:"startTime"`
	// The detailed state of the Trial.
	State string `pulumi:"state"`
	// URIs for accessing [interactive shells](https://cloud.google.com/vertex-ai/docs/training/monitor-debug-interactive-shell) (one URI for each training node). Only available if this trial is part of a HyperparameterTuningJob and the job's trial_job_spec.enable_web_access field is `true`. The keys are names of each node used for the trial; for example, `workerpool0-0` for the primary node, `workerpool1-0` for the first node in the second worker pool, and `workerpool1-1` for the second node in the second worker pool. The values are the URIs for each node's interactive shell.
	WebAccessUris map[string]string `pulumi:"webAccessUris"`
}

// A message representing a Trial. A Trial contains a unique set of Parameters that has been or will be evaluated, along with the objective metrics got by running the Trial.
type GoogleCloudAiplatformV1beta1TrialResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1TrialResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1TrialResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1TrialResponseOutput) ToGoogleCloudAiplatformV1beta1TrialResponseOutput() GoogleCloudAiplatformV1beta1TrialResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1TrialResponseOutput) ToGoogleCloudAiplatformV1beta1TrialResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1TrialResponseOutput {
	return o
}

// The identifier of the client that originally requested this Trial. Each client is identified by a unique client_id. When a client asks for a suggestion, Vertex AI Vizier will assign it a Trial. The client should evaluate the Trial, complete it, and report back to Vertex AI Vizier. If suggestion is asked again by same client_id before the Trial is completed, the same Trial will be returned. Multiple clients with different client_ids can ask for suggestions simultaneously, each of them will get their own Trial.
func (o GoogleCloudAiplatformV1beta1TrialResponseOutput) ClientId() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1TrialResponse) string { return v.ClientId }).(pulumi.StringOutput)
}

// The CustomJob name linked to the Trial. It's set for a HyperparameterTuningJob's Trial.
func (o GoogleCloudAiplatformV1beta1TrialResponseOutput) CustomJob() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1TrialResponse) string { return v.CustomJob }).(pulumi.StringOutput)
}

// Time when the Trial's status changed to `SUCCEEDED` or `INFEASIBLE`.
func (o GoogleCloudAiplatformV1beta1TrialResponseOutput) EndTime() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1TrialResponse) string { return v.EndTime }).(pulumi.StringOutput)
}

// The final measurement containing the objective value.
func (o GoogleCloudAiplatformV1beta1TrialResponseOutput) FinalMeasurement() GoogleCloudAiplatformV1beta1MeasurementResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1TrialResponse) GoogleCloudAiplatformV1beta1MeasurementResponse {
		return v.FinalMeasurement
	}).(GoogleCloudAiplatformV1beta1MeasurementResponseOutput)
}

// A human readable string describing why the Trial is infeasible. This is set only if Trial state is `INFEASIBLE`.
func (o GoogleCloudAiplatformV1beta1TrialResponseOutput) InfeasibleReason() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1TrialResponse) string { return v.InfeasibleReason }).(pulumi.StringOutput)
}

// A list of measurements that are strictly lexicographically ordered by their induced tuples (steps, elapsed_duration). These are used for early stopping computations.
func (o GoogleCloudAiplatformV1beta1TrialResponseOutput) Measurements() GoogleCloudAiplatformV1beta1MeasurementResponseArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1TrialResponse) []GoogleCloudAiplatformV1beta1MeasurementResponse {
		return v.Measurements
	}).(GoogleCloudAiplatformV1beta1MeasurementResponseArrayOutput)
}

// Resource name of the Trial assigned by the service.
func (o GoogleCloudAiplatformV1beta1TrialResponseOutput) Name() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1TrialResponse) string { return v.Name }).(pulumi.StringOutput)
}

// The parameters of the Trial.
func (o GoogleCloudAiplatformV1beta1TrialResponseOutput) Parameters() GoogleCloudAiplatformV1beta1TrialParameterResponseArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1TrialResponse) []GoogleCloudAiplatformV1beta1TrialParameterResponse {
		return v.Parameters
	}).(GoogleCloudAiplatformV1beta1TrialParameterResponseArrayOutput)
}

// Time when the Trial was started.
func (o GoogleCloudAiplatformV1beta1TrialResponseOutput) StartTime() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1TrialResponse) string { return v.StartTime }).(pulumi.StringOutput)
}

// The detailed state of the Trial.
func (o GoogleCloudAiplatformV1beta1TrialResponseOutput) State() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1TrialResponse) string { return v.State }).(pulumi.StringOutput)
}

// URIs for accessing [interactive shells](https://cloud.google.com/vertex-ai/docs/training/monitor-debug-interactive-shell) (one URI for each training node). Only available if this trial is part of a HyperparameterTuningJob and the job's trial_job_spec.enable_web_access field is `true`. The keys are names of each node used for the trial; for example, `workerpool0-0` for the primary node, `workerpool1-0` for the first node in the second worker pool, and `workerpool1-1` for the second node in the second worker pool. The values are the URIs for each node's interactive shell.
func (o GoogleCloudAiplatformV1beta1TrialResponseOutput) WebAccessUris() pulumi.StringMapOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1TrialResponse) map[string]string { return v.WebAccessUris }).(pulumi.StringMapOutput)
}

type GoogleCloudAiplatformV1beta1TrialResponseArrayOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1TrialResponseArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1beta1TrialResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1TrialResponseArrayOutput) ToGoogleCloudAiplatformV1beta1TrialResponseArrayOutput() GoogleCloudAiplatformV1beta1TrialResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1TrialResponseArrayOutput) ToGoogleCloudAiplatformV1beta1TrialResponseArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1TrialResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1TrialResponseArrayOutput) Index(i pulumi.IntInput) GoogleCloudAiplatformV1beta1TrialResponseOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GoogleCloudAiplatformV1beta1TrialResponse {
		return vs[0].([]GoogleCloudAiplatformV1beta1TrialResponse)[vs[1].(int)]
	}).(GoogleCloudAiplatformV1beta1TrialResponseOutput)
}

// Contains model information necessary to perform batch prediction without requiring a full model import.
type GoogleCloudAiplatformV1beta1UnmanagedContainerModel struct {
	// The path to the directory containing the Model artifact and any of its supporting files.
	ArtifactUri *string `pulumi:"artifactUri"`
	// Input only. The specification of the container that is to be used when deploying this Model.
	ContainerSpec *GoogleCloudAiplatformV1beta1ModelContainerSpec `pulumi:"containerSpec"`
	// Contains the schemata used in Model's predictions and explanations
	PredictSchemata *GoogleCloudAiplatformV1beta1PredictSchemata `pulumi:"predictSchemata"`
}

// GoogleCloudAiplatformV1beta1UnmanagedContainerModelInput is an input type that accepts GoogleCloudAiplatformV1beta1UnmanagedContainerModelArgs and GoogleCloudAiplatformV1beta1UnmanagedContainerModelOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1UnmanagedContainerModelInput` via:
//
//	GoogleCloudAiplatformV1beta1UnmanagedContainerModelArgs{...}
type GoogleCloudAiplatformV1beta1UnmanagedContainerModelInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1UnmanagedContainerModelOutput() GoogleCloudAiplatformV1beta1UnmanagedContainerModelOutput
	ToGoogleCloudAiplatformV1beta1UnmanagedContainerModelOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1UnmanagedContainerModelOutput
}

// Contains model information necessary to perform batch prediction without requiring a full model import.
type GoogleCloudAiplatformV1beta1UnmanagedContainerModelArgs struct {
	// The path to the directory containing the Model artifact and any of its supporting files.
	ArtifactUri pulumi.StringPtrInput `pulumi:"artifactUri"`
	// Input only. The specification of the container that is to be used when deploying this Model.
	ContainerSpec GoogleCloudAiplatformV1beta1ModelContainerSpecPtrInput `pulumi:"containerSpec"`
	// Contains the schemata used in Model's predictions and explanations
	PredictSchemata GoogleCloudAiplatformV1beta1PredictSchemataPtrInput `pulumi:"predictSchemata"`
}

func (GoogleCloudAiplatformV1beta1UnmanagedContainerModelArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1UnmanagedContainerModel)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1UnmanagedContainerModelArgs) ToGoogleCloudAiplatformV1beta1UnmanagedContainerModelOutput() GoogleCloudAiplatformV1beta1UnmanagedContainerModelOutput {
	return i.ToGoogleCloudAiplatformV1beta1UnmanagedContainerModelOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1UnmanagedContainerModelArgs) ToGoogleCloudAiplatformV1beta1UnmanagedContainerModelOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1UnmanagedContainerModelOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1UnmanagedContainerModelOutput)
}

func (i GoogleCloudAiplatformV1beta1UnmanagedContainerModelArgs) ToGoogleCloudAiplatformV1beta1UnmanagedContainerModelPtrOutput() GoogleCloudAiplatformV1beta1UnmanagedContainerModelPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1UnmanagedContainerModelPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1UnmanagedContainerModelArgs) ToGoogleCloudAiplatformV1beta1UnmanagedContainerModelPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1UnmanagedContainerModelPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1UnmanagedContainerModelOutput).ToGoogleCloudAiplatformV1beta1UnmanagedContainerModelPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1UnmanagedContainerModelPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1UnmanagedContainerModelArgs, GoogleCloudAiplatformV1beta1UnmanagedContainerModelPtr and GoogleCloudAiplatformV1beta1UnmanagedContainerModelPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1UnmanagedContainerModelPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1UnmanagedContainerModelArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1UnmanagedContainerModelPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1UnmanagedContainerModelPtrOutput() GoogleCloudAiplatformV1beta1UnmanagedContainerModelPtrOutput
	ToGoogleCloudAiplatformV1beta1UnmanagedContainerModelPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1UnmanagedContainerModelPtrOutput
}

type googleCloudAiplatformV1beta1UnmanagedContainerModelPtrType GoogleCloudAiplatformV1beta1UnmanagedContainerModelArgs

func GoogleCloudAiplatformV1beta1UnmanagedContainerModelPtr(v *GoogleCloudAiplatformV1beta1UnmanagedContainerModelArgs) GoogleCloudAiplatformV1beta1UnmanagedContainerModelPtrInput {
	return (*googleCloudAiplatformV1beta1UnmanagedContainerModelPtrType)(v)
}

func (*googleCloudAiplatformV1beta1UnmanagedContainerModelPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1UnmanagedContainerModel)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1UnmanagedContainerModelPtrType) ToGoogleCloudAiplatformV1beta1UnmanagedContainerModelPtrOutput() GoogleCloudAiplatformV1beta1UnmanagedContainerModelPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1UnmanagedContainerModelPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1UnmanagedContainerModelPtrType) ToGoogleCloudAiplatformV1beta1UnmanagedContainerModelPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1UnmanagedContainerModelPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1UnmanagedContainerModelPtrOutput)
}

// Contains model information necessary to perform batch prediction without requiring a full model import.
type GoogleCloudAiplatformV1beta1UnmanagedContainerModelOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1UnmanagedContainerModelOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1UnmanagedContainerModel)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1UnmanagedContainerModelOutput) ToGoogleCloudAiplatformV1beta1UnmanagedContainerModelOutput() GoogleCloudAiplatformV1beta1UnmanagedContainerModelOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1UnmanagedContainerModelOutput) ToGoogleCloudAiplatformV1beta1UnmanagedContainerModelOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1UnmanagedContainerModelOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1UnmanagedContainerModelOutput) ToGoogleCloudAiplatformV1beta1UnmanagedContainerModelPtrOutput() GoogleCloudAiplatformV1beta1UnmanagedContainerModelPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1UnmanagedContainerModelPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1UnmanagedContainerModelOutput) ToGoogleCloudAiplatformV1beta1UnmanagedContainerModelPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1UnmanagedContainerModelPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1UnmanagedContainerModel) *GoogleCloudAiplatformV1beta1UnmanagedContainerModel {
		return &v
	}).(GoogleCloudAiplatformV1beta1UnmanagedContainerModelPtrOutput)
}

// The path to the directory containing the Model artifact and any of its supporting files.
func (o GoogleCloudAiplatformV1beta1UnmanagedContainerModelOutput) ArtifactUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1UnmanagedContainerModel) *string { return v.ArtifactUri }).(pulumi.StringPtrOutput)
}

// Input only. The specification of the container that is to be used when deploying this Model.
func (o GoogleCloudAiplatformV1beta1UnmanagedContainerModelOutput) ContainerSpec() GoogleCloudAiplatformV1beta1ModelContainerSpecPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1UnmanagedContainerModel) *GoogleCloudAiplatformV1beta1ModelContainerSpec {
		return v.ContainerSpec
	}).(GoogleCloudAiplatformV1beta1ModelContainerSpecPtrOutput)
}

// Contains the schemata used in Model's predictions and explanations
func (o GoogleCloudAiplatformV1beta1UnmanagedContainerModelOutput) PredictSchemata() GoogleCloudAiplatformV1beta1PredictSchemataPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1UnmanagedContainerModel) *GoogleCloudAiplatformV1beta1PredictSchemata {
		return v.PredictSchemata
	}).(GoogleCloudAiplatformV1beta1PredictSchemataPtrOutput)
}

type GoogleCloudAiplatformV1beta1UnmanagedContainerModelPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1UnmanagedContainerModelPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1UnmanagedContainerModel)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1UnmanagedContainerModelPtrOutput) ToGoogleCloudAiplatformV1beta1UnmanagedContainerModelPtrOutput() GoogleCloudAiplatformV1beta1UnmanagedContainerModelPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1UnmanagedContainerModelPtrOutput) ToGoogleCloudAiplatformV1beta1UnmanagedContainerModelPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1UnmanagedContainerModelPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1UnmanagedContainerModelPtrOutput) Elem() GoogleCloudAiplatformV1beta1UnmanagedContainerModelOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1UnmanagedContainerModel) GoogleCloudAiplatformV1beta1UnmanagedContainerModel {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1UnmanagedContainerModel
		return ret
	}).(GoogleCloudAiplatformV1beta1UnmanagedContainerModelOutput)
}

// The path to the directory containing the Model artifact and any of its supporting files.
func (o GoogleCloudAiplatformV1beta1UnmanagedContainerModelPtrOutput) ArtifactUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1UnmanagedContainerModel) *string {
		if v == nil {
			return nil
		}
		return v.ArtifactUri
	}).(pulumi.StringPtrOutput)
}

// Input only. The specification of the container that is to be used when deploying this Model.
func (o GoogleCloudAiplatformV1beta1UnmanagedContainerModelPtrOutput) ContainerSpec() GoogleCloudAiplatformV1beta1ModelContainerSpecPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1UnmanagedContainerModel) *GoogleCloudAiplatformV1beta1ModelContainerSpec {
		if v == nil {
			return nil
		}
		return v.ContainerSpec
	}).(GoogleCloudAiplatformV1beta1ModelContainerSpecPtrOutput)
}

// Contains the schemata used in Model's predictions and explanations
func (o GoogleCloudAiplatformV1beta1UnmanagedContainerModelPtrOutput) PredictSchemata() GoogleCloudAiplatformV1beta1PredictSchemataPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1UnmanagedContainerModel) *GoogleCloudAiplatformV1beta1PredictSchemata {
		if v == nil {
			return nil
		}
		return v.PredictSchemata
	}).(GoogleCloudAiplatformV1beta1PredictSchemataPtrOutput)
}

// Contains model information necessary to perform batch prediction without requiring a full model import.
type GoogleCloudAiplatformV1beta1UnmanagedContainerModelResponse struct {
	// The path to the directory containing the Model artifact and any of its supporting files.
	ArtifactUri string `pulumi:"artifactUri"`
	// Input only. The specification of the container that is to be used when deploying this Model.
	ContainerSpec GoogleCloudAiplatformV1beta1ModelContainerSpecResponse `pulumi:"containerSpec"`
	// Contains the schemata used in Model's predictions and explanations
	PredictSchemata GoogleCloudAiplatformV1beta1PredictSchemataResponse `pulumi:"predictSchemata"`
}

// Contains model information necessary to perform batch prediction without requiring a full model import.
type GoogleCloudAiplatformV1beta1UnmanagedContainerModelResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1UnmanagedContainerModelResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1UnmanagedContainerModelResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1UnmanagedContainerModelResponseOutput) ToGoogleCloudAiplatformV1beta1UnmanagedContainerModelResponseOutput() GoogleCloudAiplatformV1beta1UnmanagedContainerModelResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1UnmanagedContainerModelResponseOutput) ToGoogleCloudAiplatformV1beta1UnmanagedContainerModelResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1UnmanagedContainerModelResponseOutput {
	return o
}

// The path to the directory containing the Model artifact and any of its supporting files.
func (o GoogleCloudAiplatformV1beta1UnmanagedContainerModelResponseOutput) ArtifactUri() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1UnmanagedContainerModelResponse) string { return v.ArtifactUri }).(pulumi.StringOutput)
}

// Input only. The specification of the container that is to be used when deploying this Model.
func (o GoogleCloudAiplatformV1beta1UnmanagedContainerModelResponseOutput) ContainerSpec() GoogleCloudAiplatformV1beta1ModelContainerSpecResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1UnmanagedContainerModelResponse) GoogleCloudAiplatformV1beta1ModelContainerSpecResponse {
		return v.ContainerSpec
	}).(GoogleCloudAiplatformV1beta1ModelContainerSpecResponseOutput)
}

// Contains the schemata used in Model's predictions and explanations
func (o GoogleCloudAiplatformV1beta1UnmanagedContainerModelResponseOutput) PredictSchemata() GoogleCloudAiplatformV1beta1PredictSchemataResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1UnmanagedContainerModelResponse) GoogleCloudAiplatformV1beta1PredictSchemataResponse {
		return v.PredictSchemata
	}).(GoogleCloudAiplatformV1beta1PredictSchemataResponseOutput)
}

// Value is the value of the field.
type GoogleCloudAiplatformV1beta1Value struct {
	// A double value.
	DoubleValue *float64 `pulumi:"doubleValue"`
	// An integer value.
	IntValue *string `pulumi:"intValue"`
	// A string value.
	StringValue *string `pulumi:"stringValue"`
}

// GoogleCloudAiplatformV1beta1ValueInput is an input type that accepts GoogleCloudAiplatformV1beta1ValueArgs and GoogleCloudAiplatformV1beta1ValueOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1ValueInput` via:
//
//	GoogleCloudAiplatformV1beta1ValueArgs{...}
type GoogleCloudAiplatformV1beta1ValueInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1ValueOutput() GoogleCloudAiplatformV1beta1ValueOutput
	ToGoogleCloudAiplatformV1beta1ValueOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1ValueOutput
}

// Value is the value of the field.
type GoogleCloudAiplatformV1beta1ValueArgs struct {
	// A double value.
	DoubleValue pulumi.Float64PtrInput `pulumi:"doubleValue"`
	// An integer value.
	IntValue pulumi.StringPtrInput `pulumi:"intValue"`
	// A string value.
	StringValue pulumi.StringPtrInput `pulumi:"stringValue"`
}

func (GoogleCloudAiplatformV1beta1ValueArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1Value)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1ValueArgs) ToGoogleCloudAiplatformV1beta1ValueOutput() GoogleCloudAiplatformV1beta1ValueOutput {
	return i.ToGoogleCloudAiplatformV1beta1ValueOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1ValueArgs) ToGoogleCloudAiplatformV1beta1ValueOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ValueOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ValueOutput)
}

func (i GoogleCloudAiplatformV1beta1ValueArgs) ToGoogleCloudAiplatformV1beta1ValuePtrOutput() GoogleCloudAiplatformV1beta1ValuePtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1ValuePtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1ValueArgs) ToGoogleCloudAiplatformV1beta1ValuePtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ValuePtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ValueOutput).ToGoogleCloudAiplatformV1beta1ValuePtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1ValuePtrInput is an input type that accepts GoogleCloudAiplatformV1beta1ValueArgs, GoogleCloudAiplatformV1beta1ValuePtr and GoogleCloudAiplatformV1beta1ValuePtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1ValuePtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1ValueArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1ValuePtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1ValuePtrOutput() GoogleCloudAiplatformV1beta1ValuePtrOutput
	ToGoogleCloudAiplatformV1beta1ValuePtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1ValuePtrOutput
}

type googleCloudAiplatformV1beta1ValuePtrType GoogleCloudAiplatformV1beta1ValueArgs

func GoogleCloudAiplatformV1beta1ValuePtr(v *GoogleCloudAiplatformV1beta1ValueArgs) GoogleCloudAiplatformV1beta1ValuePtrInput {
	return (*googleCloudAiplatformV1beta1ValuePtrType)(v)
}

func (*googleCloudAiplatformV1beta1ValuePtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1Value)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1ValuePtrType) ToGoogleCloudAiplatformV1beta1ValuePtrOutput() GoogleCloudAiplatformV1beta1ValuePtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1ValuePtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1ValuePtrType) ToGoogleCloudAiplatformV1beta1ValuePtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ValuePtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1ValuePtrOutput)
}

// Value is the value of the field.
type GoogleCloudAiplatformV1beta1ValueOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ValueOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1Value)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ValueOutput) ToGoogleCloudAiplatformV1beta1ValueOutput() GoogleCloudAiplatformV1beta1ValueOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ValueOutput) ToGoogleCloudAiplatformV1beta1ValueOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ValueOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ValueOutput) ToGoogleCloudAiplatformV1beta1ValuePtrOutput() GoogleCloudAiplatformV1beta1ValuePtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1ValuePtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1ValueOutput) ToGoogleCloudAiplatformV1beta1ValuePtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ValuePtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1Value) *GoogleCloudAiplatformV1beta1Value {
		return &v
	}).(GoogleCloudAiplatformV1beta1ValuePtrOutput)
}

// A double value.
func (o GoogleCloudAiplatformV1beta1ValueOutput) DoubleValue() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1Value) *float64 { return v.DoubleValue }).(pulumi.Float64PtrOutput)
}

// An integer value.
func (o GoogleCloudAiplatformV1beta1ValueOutput) IntValue() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1Value) *string { return v.IntValue }).(pulumi.StringPtrOutput)
}

// A string value.
func (o GoogleCloudAiplatformV1beta1ValueOutput) StringValue() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1Value) *string { return v.StringValue }).(pulumi.StringPtrOutput)
}

type GoogleCloudAiplatformV1beta1ValuePtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ValuePtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1Value)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ValuePtrOutput) ToGoogleCloudAiplatformV1beta1ValuePtrOutput() GoogleCloudAiplatformV1beta1ValuePtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ValuePtrOutput) ToGoogleCloudAiplatformV1beta1ValuePtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ValuePtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ValuePtrOutput) Elem() GoogleCloudAiplatformV1beta1ValueOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1Value) GoogleCloudAiplatformV1beta1Value {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1Value
		return ret
	}).(GoogleCloudAiplatformV1beta1ValueOutput)
}

// A double value.
func (o GoogleCloudAiplatformV1beta1ValuePtrOutput) DoubleValue() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1Value) *float64 {
		if v == nil {
			return nil
		}
		return v.DoubleValue
	}).(pulumi.Float64PtrOutput)
}

// An integer value.
func (o GoogleCloudAiplatformV1beta1ValuePtrOutput) IntValue() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1Value) *string {
		if v == nil {
			return nil
		}
		return v.IntValue
	}).(pulumi.StringPtrOutput)
}

// A string value.
func (o GoogleCloudAiplatformV1beta1ValuePtrOutput) StringValue() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1Value) *string {
		if v == nil {
			return nil
		}
		return v.StringValue
	}).(pulumi.StringPtrOutput)
}

// Value is the value of the field.
type GoogleCloudAiplatformV1beta1ValueResponse struct {
	// A double value.
	DoubleValue float64 `pulumi:"doubleValue"`
	// An integer value.
	IntValue string `pulumi:"intValue"`
	// A string value.
	StringValue string `pulumi:"stringValue"`
}

// Value is the value of the field.
type GoogleCloudAiplatformV1beta1ValueResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1ValueResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1ValueResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1ValueResponseOutput) ToGoogleCloudAiplatformV1beta1ValueResponseOutput() GoogleCloudAiplatformV1beta1ValueResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1ValueResponseOutput) ToGoogleCloudAiplatformV1beta1ValueResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1ValueResponseOutput {
	return o
}

// A double value.
func (o GoogleCloudAiplatformV1beta1ValueResponseOutput) DoubleValue() pulumi.Float64Output {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ValueResponse) float64 { return v.DoubleValue }).(pulumi.Float64Output)
}

// An integer value.
func (o GoogleCloudAiplatformV1beta1ValueResponseOutput) IntValue() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ValueResponse) string { return v.IntValue }).(pulumi.StringOutput)
}

// A string value.
func (o GoogleCloudAiplatformV1beta1ValueResponseOutput) StringValue() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1ValueResponse) string { return v.StringValue }).(pulumi.StringOutput)
}

// Represents the spec of a worker pool in a job.
type GoogleCloudAiplatformV1beta1WorkerPoolSpec struct {
	// The custom container task.
	ContainerSpec *GoogleCloudAiplatformV1beta1ContainerSpec `pulumi:"containerSpec"`
	// Disk spec.
	DiskSpec *GoogleCloudAiplatformV1beta1DiskSpec `pulumi:"diskSpec"`
	// Optional. Immutable. The specification of a single machine.
	MachineSpec *GoogleCloudAiplatformV1beta1MachineSpec `pulumi:"machineSpec"`
	// Optional. List of NFS mount spec.
	NfsMounts []GoogleCloudAiplatformV1beta1NfsMount `pulumi:"nfsMounts"`
	// The Python packaged task.
	PythonPackageSpec *GoogleCloudAiplatformV1beta1PythonPackageSpec `pulumi:"pythonPackageSpec"`
	// Optional. The number of worker replicas to use for this worker pool.
	ReplicaCount *string `pulumi:"replicaCount"`
}

// GoogleCloudAiplatformV1beta1WorkerPoolSpecInput is an input type that accepts GoogleCloudAiplatformV1beta1WorkerPoolSpecArgs and GoogleCloudAiplatformV1beta1WorkerPoolSpecOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1WorkerPoolSpecInput` via:
//
//	GoogleCloudAiplatformV1beta1WorkerPoolSpecArgs{...}
type GoogleCloudAiplatformV1beta1WorkerPoolSpecInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1WorkerPoolSpecOutput() GoogleCloudAiplatformV1beta1WorkerPoolSpecOutput
	ToGoogleCloudAiplatformV1beta1WorkerPoolSpecOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1WorkerPoolSpecOutput
}

// Represents the spec of a worker pool in a job.
type GoogleCloudAiplatformV1beta1WorkerPoolSpecArgs struct {
	// The custom container task.
	ContainerSpec GoogleCloudAiplatformV1beta1ContainerSpecPtrInput `pulumi:"containerSpec"`
	// Disk spec.
	DiskSpec GoogleCloudAiplatformV1beta1DiskSpecPtrInput `pulumi:"diskSpec"`
	// Optional. Immutable. The specification of a single machine.
	MachineSpec GoogleCloudAiplatformV1beta1MachineSpecPtrInput `pulumi:"machineSpec"`
	// Optional. List of NFS mount spec.
	NfsMounts GoogleCloudAiplatformV1beta1NfsMountArrayInput `pulumi:"nfsMounts"`
	// The Python packaged task.
	PythonPackageSpec GoogleCloudAiplatformV1beta1PythonPackageSpecPtrInput `pulumi:"pythonPackageSpec"`
	// Optional. The number of worker replicas to use for this worker pool.
	ReplicaCount pulumi.StringPtrInput `pulumi:"replicaCount"`
}

func (GoogleCloudAiplatformV1beta1WorkerPoolSpecArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1WorkerPoolSpec)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1WorkerPoolSpecArgs) ToGoogleCloudAiplatformV1beta1WorkerPoolSpecOutput() GoogleCloudAiplatformV1beta1WorkerPoolSpecOutput {
	return i.ToGoogleCloudAiplatformV1beta1WorkerPoolSpecOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1WorkerPoolSpecArgs) ToGoogleCloudAiplatformV1beta1WorkerPoolSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1WorkerPoolSpecOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1WorkerPoolSpecOutput)
}

// GoogleCloudAiplatformV1beta1WorkerPoolSpecArrayInput is an input type that accepts GoogleCloudAiplatformV1beta1WorkerPoolSpecArray and GoogleCloudAiplatformV1beta1WorkerPoolSpecArrayOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1WorkerPoolSpecArrayInput` via:
//
//	GoogleCloudAiplatformV1beta1WorkerPoolSpecArray{ GoogleCloudAiplatformV1beta1WorkerPoolSpecArgs{...} }
type GoogleCloudAiplatformV1beta1WorkerPoolSpecArrayInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1WorkerPoolSpecArrayOutput() GoogleCloudAiplatformV1beta1WorkerPoolSpecArrayOutput
	ToGoogleCloudAiplatformV1beta1WorkerPoolSpecArrayOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1WorkerPoolSpecArrayOutput
}

type GoogleCloudAiplatformV1beta1WorkerPoolSpecArray []GoogleCloudAiplatformV1beta1WorkerPoolSpecInput

func (GoogleCloudAiplatformV1beta1WorkerPoolSpecArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1beta1WorkerPoolSpec)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1WorkerPoolSpecArray) ToGoogleCloudAiplatformV1beta1WorkerPoolSpecArrayOutput() GoogleCloudAiplatformV1beta1WorkerPoolSpecArrayOutput {
	return i.ToGoogleCloudAiplatformV1beta1WorkerPoolSpecArrayOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1WorkerPoolSpecArray) ToGoogleCloudAiplatformV1beta1WorkerPoolSpecArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1WorkerPoolSpecArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1WorkerPoolSpecArrayOutput)
}

// Represents the spec of a worker pool in a job.
type GoogleCloudAiplatformV1beta1WorkerPoolSpecOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1WorkerPoolSpecOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1WorkerPoolSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1WorkerPoolSpecOutput) ToGoogleCloudAiplatformV1beta1WorkerPoolSpecOutput() GoogleCloudAiplatformV1beta1WorkerPoolSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1WorkerPoolSpecOutput) ToGoogleCloudAiplatformV1beta1WorkerPoolSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1WorkerPoolSpecOutput {
	return o
}

// The custom container task.
func (o GoogleCloudAiplatformV1beta1WorkerPoolSpecOutput) ContainerSpec() GoogleCloudAiplatformV1beta1ContainerSpecPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1WorkerPoolSpec) *GoogleCloudAiplatformV1beta1ContainerSpec {
		return v.ContainerSpec
	}).(GoogleCloudAiplatformV1beta1ContainerSpecPtrOutput)
}

// Disk spec.
func (o GoogleCloudAiplatformV1beta1WorkerPoolSpecOutput) DiskSpec() GoogleCloudAiplatformV1beta1DiskSpecPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1WorkerPoolSpec) *GoogleCloudAiplatformV1beta1DiskSpec {
		return v.DiskSpec
	}).(GoogleCloudAiplatformV1beta1DiskSpecPtrOutput)
}

// Optional. Immutable. The specification of a single machine.
func (o GoogleCloudAiplatformV1beta1WorkerPoolSpecOutput) MachineSpec() GoogleCloudAiplatformV1beta1MachineSpecPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1WorkerPoolSpec) *GoogleCloudAiplatformV1beta1MachineSpec {
		return v.MachineSpec
	}).(GoogleCloudAiplatformV1beta1MachineSpecPtrOutput)
}

// Optional. List of NFS mount spec.
func (o GoogleCloudAiplatformV1beta1WorkerPoolSpecOutput) NfsMounts() GoogleCloudAiplatformV1beta1NfsMountArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1WorkerPoolSpec) []GoogleCloudAiplatformV1beta1NfsMount {
		return v.NfsMounts
	}).(GoogleCloudAiplatformV1beta1NfsMountArrayOutput)
}

// The Python packaged task.
func (o GoogleCloudAiplatformV1beta1WorkerPoolSpecOutput) PythonPackageSpec() GoogleCloudAiplatformV1beta1PythonPackageSpecPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1WorkerPoolSpec) *GoogleCloudAiplatformV1beta1PythonPackageSpec {
		return v.PythonPackageSpec
	}).(GoogleCloudAiplatformV1beta1PythonPackageSpecPtrOutput)
}

// Optional. The number of worker replicas to use for this worker pool.
func (o GoogleCloudAiplatformV1beta1WorkerPoolSpecOutput) ReplicaCount() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1WorkerPoolSpec) *string { return v.ReplicaCount }).(pulumi.StringPtrOutput)
}

type GoogleCloudAiplatformV1beta1WorkerPoolSpecArrayOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1WorkerPoolSpecArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1beta1WorkerPoolSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1WorkerPoolSpecArrayOutput) ToGoogleCloudAiplatformV1beta1WorkerPoolSpecArrayOutput() GoogleCloudAiplatformV1beta1WorkerPoolSpecArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1WorkerPoolSpecArrayOutput) ToGoogleCloudAiplatformV1beta1WorkerPoolSpecArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1WorkerPoolSpecArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1WorkerPoolSpecArrayOutput) Index(i pulumi.IntInput) GoogleCloudAiplatformV1beta1WorkerPoolSpecOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GoogleCloudAiplatformV1beta1WorkerPoolSpec {
		return vs[0].([]GoogleCloudAiplatformV1beta1WorkerPoolSpec)[vs[1].(int)]
	}).(GoogleCloudAiplatformV1beta1WorkerPoolSpecOutput)
}

// Represents the spec of a worker pool in a job.
type GoogleCloudAiplatformV1beta1WorkerPoolSpecResponse struct {
	// The custom container task.
	ContainerSpec GoogleCloudAiplatformV1beta1ContainerSpecResponse `pulumi:"containerSpec"`
	// Disk spec.
	DiskSpec GoogleCloudAiplatformV1beta1DiskSpecResponse `pulumi:"diskSpec"`
	// Optional. Immutable. The specification of a single machine.
	MachineSpec GoogleCloudAiplatformV1beta1MachineSpecResponse `pulumi:"machineSpec"`
	// Optional. List of NFS mount spec.
	NfsMounts []GoogleCloudAiplatformV1beta1NfsMountResponse `pulumi:"nfsMounts"`
	// The Python packaged task.
	PythonPackageSpec GoogleCloudAiplatformV1beta1PythonPackageSpecResponse `pulumi:"pythonPackageSpec"`
	// Optional. The number of worker replicas to use for this worker pool.
	ReplicaCount string `pulumi:"replicaCount"`
}

// Represents the spec of a worker pool in a job.
type GoogleCloudAiplatformV1beta1WorkerPoolSpecResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1WorkerPoolSpecResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1WorkerPoolSpecResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1WorkerPoolSpecResponseOutput) ToGoogleCloudAiplatformV1beta1WorkerPoolSpecResponseOutput() GoogleCloudAiplatformV1beta1WorkerPoolSpecResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1WorkerPoolSpecResponseOutput) ToGoogleCloudAiplatformV1beta1WorkerPoolSpecResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1WorkerPoolSpecResponseOutput {
	return o
}

// The custom container task.
func (o GoogleCloudAiplatformV1beta1WorkerPoolSpecResponseOutput) ContainerSpec() GoogleCloudAiplatformV1beta1ContainerSpecResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1WorkerPoolSpecResponse) GoogleCloudAiplatformV1beta1ContainerSpecResponse {
		return v.ContainerSpec
	}).(GoogleCloudAiplatformV1beta1ContainerSpecResponseOutput)
}

// Disk spec.
func (o GoogleCloudAiplatformV1beta1WorkerPoolSpecResponseOutput) DiskSpec() GoogleCloudAiplatformV1beta1DiskSpecResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1WorkerPoolSpecResponse) GoogleCloudAiplatformV1beta1DiskSpecResponse {
		return v.DiskSpec
	}).(GoogleCloudAiplatformV1beta1DiskSpecResponseOutput)
}

// Optional. Immutable. The specification of a single machine.
func (o GoogleCloudAiplatformV1beta1WorkerPoolSpecResponseOutput) MachineSpec() GoogleCloudAiplatformV1beta1MachineSpecResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1WorkerPoolSpecResponse) GoogleCloudAiplatformV1beta1MachineSpecResponse {
		return v.MachineSpec
	}).(GoogleCloudAiplatformV1beta1MachineSpecResponseOutput)
}

// Optional. List of NFS mount spec.
func (o GoogleCloudAiplatformV1beta1WorkerPoolSpecResponseOutput) NfsMounts() GoogleCloudAiplatformV1beta1NfsMountResponseArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1WorkerPoolSpecResponse) []GoogleCloudAiplatformV1beta1NfsMountResponse {
		return v.NfsMounts
	}).(GoogleCloudAiplatformV1beta1NfsMountResponseArrayOutput)
}

// The Python packaged task.
func (o GoogleCloudAiplatformV1beta1WorkerPoolSpecResponseOutput) PythonPackageSpec() GoogleCloudAiplatformV1beta1PythonPackageSpecResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1WorkerPoolSpecResponse) GoogleCloudAiplatformV1beta1PythonPackageSpecResponse {
		return v.PythonPackageSpec
	}).(GoogleCloudAiplatformV1beta1PythonPackageSpecResponseOutput)
}

// Optional. The number of worker replicas to use for this worker pool.
func (o GoogleCloudAiplatformV1beta1WorkerPoolSpecResponseOutput) ReplicaCount() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1WorkerPoolSpecResponse) string { return v.ReplicaCount }).(pulumi.StringOutput)
}

type GoogleCloudAiplatformV1beta1WorkerPoolSpecResponseArrayOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1WorkerPoolSpecResponseArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1beta1WorkerPoolSpecResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1WorkerPoolSpecResponseArrayOutput) ToGoogleCloudAiplatformV1beta1WorkerPoolSpecResponseArrayOutput() GoogleCloudAiplatformV1beta1WorkerPoolSpecResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1WorkerPoolSpecResponseArrayOutput) ToGoogleCloudAiplatformV1beta1WorkerPoolSpecResponseArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1WorkerPoolSpecResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1WorkerPoolSpecResponseArrayOutput) Index(i pulumi.IntInput) GoogleCloudAiplatformV1beta1WorkerPoolSpecResponseOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GoogleCloudAiplatformV1beta1WorkerPoolSpecResponse {
		return vs[0].([]GoogleCloudAiplatformV1beta1WorkerPoolSpecResponse)[vs[1].(int)]
	}).(GoogleCloudAiplatformV1beta1WorkerPoolSpecResponseOutput)
}

// An explanation method that redistributes Integrated Gradients attributions to segmented regions, taking advantage of the model's fully differentiable structure. Refer to this paper for more details: https://arxiv.org/abs/1906.02825 Supported only by image Models.
type GoogleCloudAiplatformV1beta1XraiAttribution struct {
	// Config for XRAI with blur baseline. When enabled, a linear path from the maximally blurred image to the input image is created. Using a blurred baseline instead of zero (black image) is motivated by the BlurIG approach explained here: https://arxiv.org/abs/2004.03383
	BlurBaselineConfig *GoogleCloudAiplatformV1beta1BlurBaselineConfig `pulumi:"blurBaselineConfig"`
	// Config for SmoothGrad approximation of gradients. When enabled, the gradients are approximated by averaging the gradients from noisy samples in the vicinity of the inputs. Adding noise can help improve the computed gradients. Refer to this paper for more details: https://arxiv.org/pdf/1706.03825.pdf
	SmoothGradConfig *GoogleCloudAiplatformV1beta1SmoothGradConfig `pulumi:"smoothGradConfig"`
	// The number of steps for approximating the path integral. A good value to start is 50 and gradually increase until the sum to diff property is met within the desired error range. Valid range of its value is [1, 100], inclusively.
	StepCount int `pulumi:"stepCount"`
}

// GoogleCloudAiplatformV1beta1XraiAttributionInput is an input type that accepts GoogleCloudAiplatformV1beta1XraiAttributionArgs and GoogleCloudAiplatformV1beta1XraiAttributionOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1XraiAttributionInput` via:
//
//	GoogleCloudAiplatformV1beta1XraiAttributionArgs{...}
type GoogleCloudAiplatformV1beta1XraiAttributionInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1XraiAttributionOutput() GoogleCloudAiplatformV1beta1XraiAttributionOutput
	ToGoogleCloudAiplatformV1beta1XraiAttributionOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1XraiAttributionOutput
}

// An explanation method that redistributes Integrated Gradients attributions to segmented regions, taking advantage of the model's fully differentiable structure. Refer to this paper for more details: https://arxiv.org/abs/1906.02825 Supported only by image Models.
type GoogleCloudAiplatformV1beta1XraiAttributionArgs struct {
	// Config for XRAI with blur baseline. When enabled, a linear path from the maximally blurred image to the input image is created. Using a blurred baseline instead of zero (black image) is motivated by the BlurIG approach explained here: https://arxiv.org/abs/2004.03383
	BlurBaselineConfig GoogleCloudAiplatformV1beta1BlurBaselineConfigPtrInput `pulumi:"blurBaselineConfig"`
	// Config for SmoothGrad approximation of gradients. When enabled, the gradients are approximated by averaging the gradients from noisy samples in the vicinity of the inputs. Adding noise can help improve the computed gradients. Refer to this paper for more details: https://arxiv.org/pdf/1706.03825.pdf
	SmoothGradConfig GoogleCloudAiplatformV1beta1SmoothGradConfigPtrInput `pulumi:"smoothGradConfig"`
	// The number of steps for approximating the path integral. A good value to start is 50 and gradually increase until the sum to diff property is met within the desired error range. Valid range of its value is [1, 100], inclusively.
	StepCount pulumi.IntInput `pulumi:"stepCount"`
}

func (GoogleCloudAiplatformV1beta1XraiAttributionArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1XraiAttribution)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1beta1XraiAttributionArgs) ToGoogleCloudAiplatformV1beta1XraiAttributionOutput() GoogleCloudAiplatformV1beta1XraiAttributionOutput {
	return i.ToGoogleCloudAiplatformV1beta1XraiAttributionOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1XraiAttributionArgs) ToGoogleCloudAiplatformV1beta1XraiAttributionOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1XraiAttributionOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1XraiAttributionOutput)
}

func (i GoogleCloudAiplatformV1beta1XraiAttributionArgs) ToGoogleCloudAiplatformV1beta1XraiAttributionPtrOutput() GoogleCloudAiplatformV1beta1XraiAttributionPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1XraiAttributionPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1beta1XraiAttributionArgs) ToGoogleCloudAiplatformV1beta1XraiAttributionPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1XraiAttributionPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1XraiAttributionOutput).ToGoogleCloudAiplatformV1beta1XraiAttributionPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1beta1XraiAttributionPtrInput is an input type that accepts GoogleCloudAiplatformV1beta1XraiAttributionArgs, GoogleCloudAiplatformV1beta1XraiAttributionPtr and GoogleCloudAiplatformV1beta1XraiAttributionPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1beta1XraiAttributionPtrInput` via:
//
//	        GoogleCloudAiplatformV1beta1XraiAttributionArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1beta1XraiAttributionPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1beta1XraiAttributionPtrOutput() GoogleCloudAiplatformV1beta1XraiAttributionPtrOutput
	ToGoogleCloudAiplatformV1beta1XraiAttributionPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1beta1XraiAttributionPtrOutput
}

type googleCloudAiplatformV1beta1XraiAttributionPtrType GoogleCloudAiplatformV1beta1XraiAttributionArgs

func GoogleCloudAiplatformV1beta1XraiAttributionPtr(v *GoogleCloudAiplatformV1beta1XraiAttributionArgs) GoogleCloudAiplatformV1beta1XraiAttributionPtrInput {
	return (*googleCloudAiplatformV1beta1XraiAttributionPtrType)(v)
}

func (*googleCloudAiplatformV1beta1XraiAttributionPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1XraiAttribution)(nil)).Elem()
}

func (i *googleCloudAiplatformV1beta1XraiAttributionPtrType) ToGoogleCloudAiplatformV1beta1XraiAttributionPtrOutput() GoogleCloudAiplatformV1beta1XraiAttributionPtrOutput {
	return i.ToGoogleCloudAiplatformV1beta1XraiAttributionPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1beta1XraiAttributionPtrType) ToGoogleCloudAiplatformV1beta1XraiAttributionPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1XraiAttributionPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1beta1XraiAttributionPtrOutput)
}

// An explanation method that redistributes Integrated Gradients attributions to segmented regions, taking advantage of the model's fully differentiable structure. Refer to this paper for more details: https://arxiv.org/abs/1906.02825 Supported only by image Models.
type GoogleCloudAiplatformV1beta1XraiAttributionOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1XraiAttributionOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1XraiAttribution)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1XraiAttributionOutput) ToGoogleCloudAiplatformV1beta1XraiAttributionOutput() GoogleCloudAiplatformV1beta1XraiAttributionOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1XraiAttributionOutput) ToGoogleCloudAiplatformV1beta1XraiAttributionOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1XraiAttributionOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1XraiAttributionOutput) ToGoogleCloudAiplatformV1beta1XraiAttributionPtrOutput() GoogleCloudAiplatformV1beta1XraiAttributionPtrOutput {
	return o.ToGoogleCloudAiplatformV1beta1XraiAttributionPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1beta1XraiAttributionOutput) ToGoogleCloudAiplatformV1beta1XraiAttributionPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1XraiAttributionPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1beta1XraiAttribution) *GoogleCloudAiplatformV1beta1XraiAttribution {
		return &v
	}).(GoogleCloudAiplatformV1beta1XraiAttributionPtrOutput)
}

// Config for XRAI with blur baseline. When enabled, a linear path from the maximally blurred image to the input image is created. Using a blurred baseline instead of zero (black image) is motivated by the BlurIG approach explained here: https://arxiv.org/abs/2004.03383
func (o GoogleCloudAiplatformV1beta1XraiAttributionOutput) BlurBaselineConfig() GoogleCloudAiplatformV1beta1BlurBaselineConfigPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1XraiAttribution) *GoogleCloudAiplatformV1beta1BlurBaselineConfig {
		return v.BlurBaselineConfig
	}).(GoogleCloudAiplatformV1beta1BlurBaselineConfigPtrOutput)
}

// Config for SmoothGrad approximation of gradients. When enabled, the gradients are approximated by averaging the gradients from noisy samples in the vicinity of the inputs. Adding noise can help improve the computed gradients. Refer to this paper for more details: https://arxiv.org/pdf/1706.03825.pdf
func (o GoogleCloudAiplatformV1beta1XraiAttributionOutput) SmoothGradConfig() GoogleCloudAiplatformV1beta1SmoothGradConfigPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1XraiAttribution) *GoogleCloudAiplatformV1beta1SmoothGradConfig {
		return v.SmoothGradConfig
	}).(GoogleCloudAiplatformV1beta1SmoothGradConfigPtrOutput)
}

// The number of steps for approximating the path integral. A good value to start is 50 and gradually increase until the sum to diff property is met within the desired error range. Valid range of its value is [1, 100], inclusively.
func (o GoogleCloudAiplatformV1beta1XraiAttributionOutput) StepCount() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1XraiAttribution) int { return v.StepCount }).(pulumi.IntOutput)
}

type GoogleCloudAiplatformV1beta1XraiAttributionPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1XraiAttributionPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1beta1XraiAttribution)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1XraiAttributionPtrOutput) ToGoogleCloudAiplatformV1beta1XraiAttributionPtrOutput() GoogleCloudAiplatformV1beta1XraiAttributionPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1XraiAttributionPtrOutput) ToGoogleCloudAiplatformV1beta1XraiAttributionPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1XraiAttributionPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1XraiAttributionPtrOutput) Elem() GoogleCloudAiplatformV1beta1XraiAttributionOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1XraiAttribution) GoogleCloudAiplatformV1beta1XraiAttribution {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1beta1XraiAttribution
		return ret
	}).(GoogleCloudAiplatformV1beta1XraiAttributionOutput)
}

// Config for XRAI with blur baseline. When enabled, a linear path from the maximally blurred image to the input image is created. Using a blurred baseline instead of zero (black image) is motivated by the BlurIG approach explained here: https://arxiv.org/abs/2004.03383
func (o GoogleCloudAiplatformV1beta1XraiAttributionPtrOutput) BlurBaselineConfig() GoogleCloudAiplatformV1beta1BlurBaselineConfigPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1XraiAttribution) *GoogleCloudAiplatformV1beta1BlurBaselineConfig {
		if v == nil {
			return nil
		}
		return v.BlurBaselineConfig
	}).(GoogleCloudAiplatformV1beta1BlurBaselineConfigPtrOutput)
}

// Config for SmoothGrad approximation of gradients. When enabled, the gradients are approximated by averaging the gradients from noisy samples in the vicinity of the inputs. Adding noise can help improve the computed gradients. Refer to this paper for more details: https://arxiv.org/pdf/1706.03825.pdf
func (o GoogleCloudAiplatformV1beta1XraiAttributionPtrOutput) SmoothGradConfig() GoogleCloudAiplatformV1beta1SmoothGradConfigPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1XraiAttribution) *GoogleCloudAiplatformV1beta1SmoothGradConfig {
		if v == nil {
			return nil
		}
		return v.SmoothGradConfig
	}).(GoogleCloudAiplatformV1beta1SmoothGradConfigPtrOutput)
}

// The number of steps for approximating the path integral. A good value to start is 50 and gradually increase until the sum to diff property is met within the desired error range. Valid range of its value is [1, 100], inclusively.
func (o GoogleCloudAiplatformV1beta1XraiAttributionPtrOutput) StepCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1beta1XraiAttribution) *int {
		if v == nil {
			return nil
		}
		return &v.StepCount
	}).(pulumi.IntPtrOutput)
}

// An explanation method that redistributes Integrated Gradients attributions to segmented regions, taking advantage of the model's fully differentiable structure. Refer to this paper for more details: https://arxiv.org/abs/1906.02825 Supported only by image Models.
type GoogleCloudAiplatformV1beta1XraiAttributionResponse struct {
	// Config for XRAI with blur baseline. When enabled, a linear path from the maximally blurred image to the input image is created. Using a blurred baseline instead of zero (black image) is motivated by the BlurIG approach explained here: https://arxiv.org/abs/2004.03383
	BlurBaselineConfig GoogleCloudAiplatformV1beta1BlurBaselineConfigResponse `pulumi:"blurBaselineConfig"`
	// Config for SmoothGrad approximation of gradients. When enabled, the gradients are approximated by averaging the gradients from noisy samples in the vicinity of the inputs. Adding noise can help improve the computed gradients. Refer to this paper for more details: https://arxiv.org/pdf/1706.03825.pdf
	SmoothGradConfig GoogleCloudAiplatformV1beta1SmoothGradConfigResponse `pulumi:"smoothGradConfig"`
	// The number of steps for approximating the path integral. A good value to start is 50 and gradually increase until the sum to diff property is met within the desired error range. Valid range of its value is [1, 100], inclusively.
	StepCount int `pulumi:"stepCount"`
}

// An explanation method that redistributes Integrated Gradients attributions to segmented regions, taking advantage of the model's fully differentiable structure. Refer to this paper for more details: https://arxiv.org/abs/1906.02825 Supported only by image Models.
type GoogleCloudAiplatformV1beta1XraiAttributionResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1beta1XraiAttributionResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1beta1XraiAttributionResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1beta1XraiAttributionResponseOutput) ToGoogleCloudAiplatformV1beta1XraiAttributionResponseOutput() GoogleCloudAiplatformV1beta1XraiAttributionResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1beta1XraiAttributionResponseOutput) ToGoogleCloudAiplatformV1beta1XraiAttributionResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1beta1XraiAttributionResponseOutput {
	return o
}

// Config for XRAI with blur baseline. When enabled, a linear path from the maximally blurred image to the input image is created. Using a blurred baseline instead of zero (black image) is motivated by the BlurIG approach explained here: https://arxiv.org/abs/2004.03383
func (o GoogleCloudAiplatformV1beta1XraiAttributionResponseOutput) BlurBaselineConfig() GoogleCloudAiplatformV1beta1BlurBaselineConfigResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1XraiAttributionResponse) GoogleCloudAiplatformV1beta1BlurBaselineConfigResponse {
		return v.BlurBaselineConfig
	}).(GoogleCloudAiplatformV1beta1BlurBaselineConfigResponseOutput)
}

// Config for SmoothGrad approximation of gradients. When enabled, the gradients are approximated by averaging the gradients from noisy samples in the vicinity of the inputs. Adding noise can help improve the computed gradients. Refer to this paper for more details: https://arxiv.org/pdf/1706.03825.pdf
func (o GoogleCloudAiplatformV1beta1XraiAttributionResponseOutput) SmoothGradConfig() GoogleCloudAiplatformV1beta1SmoothGradConfigResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1XraiAttributionResponse) GoogleCloudAiplatformV1beta1SmoothGradConfigResponse {
		return v.SmoothGradConfig
	}).(GoogleCloudAiplatformV1beta1SmoothGradConfigResponseOutput)
}

// The number of steps for approximating the path integral. A good value to start is 50 and gradually increase until the sum to diff property is met within the desired error range. Valid range of its value is [1, 100], inclusively.
func (o GoogleCloudAiplatformV1beta1XraiAttributionResponseOutput) StepCount() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1beta1XraiAttributionResponse) int { return v.StepCount }).(pulumi.IntOutput)
}

// Associates `members`, or principals, with a `role`.
type GoogleIamV1Binding struct {
	// The condition that is associated with this binding. If the condition evaluates to `true`, then this binding applies to the current request. If the condition evaluates to `false`, then this binding does not apply to the current request. However, a different role binding might grant the same role to one or more of the principals in this binding. To learn which resources support conditions in their IAM policies, see the [IAM documentation](https://cloud.google.com/iam/help/conditions/resource-policies).
	Condition *GoogleTypeExpr `pulumi:"condition"`
	// Specifies the principals requesting access for a Google Cloud resource. `members` can have the following values: * `allUsers`: A special identifier that represents anyone who is on the internet; with or without a Google account. * `allAuthenticatedUsers`: A special identifier that represents anyone who is authenticated with a Google account or a service account. Does not include identities that come from external identity providers (IdPs) through identity federation. * `user:{emailid}`: An email address that represents a specific Google account. For example, `alice@example.com` . * `serviceAccount:{emailid}`: An email address that represents a Google service account. For example, `my-other-app@appspot.gserviceaccount.com`. * `serviceAccount:{projectid}.svc.id.goog[{namespace}/{kubernetes-sa}]`: An identifier for a [Kubernetes service account](https://cloud.google.com/kubernetes-engine/docs/how-to/kubernetes-service-accounts). For example, `my-project.svc.id.goog[my-namespace/my-kubernetes-sa]`. * `group:{emailid}`: An email address that represents a Google group. For example, `admins@example.com`. * `domain:{domain}`: The G Suite domain (primary) that represents all the users of that domain. For example, `google.com` or `example.com`. * `deleted:user:{emailid}?uid={uniqueid}`: An email address (plus unique identifier) representing a user that has been recently deleted. For example, `alice@example.com?uid=123456789012345678901`. If the user is recovered, this value reverts to `user:{emailid}` and the recovered user retains the role in the binding. * `deleted:serviceAccount:{emailid}?uid={uniqueid}`: An email address (plus unique identifier) representing a service account that has been recently deleted. For example, `my-other-app@appspot.gserviceaccount.com?uid=123456789012345678901`. If the service account is undeleted, this value reverts to `serviceAccount:{emailid}` and the undeleted service account retains the role in the binding. * `deleted:group:{emailid}?uid={uniqueid}`: An email address (plus unique identifier) representing a Google group that has been recently deleted. For example, `admins@example.com?uid=123456789012345678901`. If the group is recovered, this value reverts to `group:{emailid}` and the recovered group retains the role in the binding.
	Members []string `pulumi:"members"`
	// Role that is assigned to the list of `members`, or principals. For example, `roles/viewer`, `roles/editor`, or `roles/owner`.
	Role *string `pulumi:"role"`
}

// GoogleIamV1BindingInput is an input type that accepts GoogleIamV1BindingArgs and GoogleIamV1BindingOutput values.
// You can construct a concrete instance of `GoogleIamV1BindingInput` via:
//
//	GoogleIamV1BindingArgs{...}
type GoogleIamV1BindingInput interface {
	pulumi.Input

	ToGoogleIamV1BindingOutput() GoogleIamV1BindingOutput
	ToGoogleIamV1BindingOutputWithContext(context.Context) GoogleIamV1BindingOutput
}

// Associates `members`, or principals, with a `role`.
type GoogleIamV1BindingArgs struct {
	// The condition that is associated with this binding. If the condition evaluates to `true`, then this binding applies to the current request. If the condition evaluates to `false`, then this binding does not apply to the current request. However, a different role binding might grant the same role to one or more of the principals in this binding. To learn which resources support conditions in their IAM policies, see the [IAM documentation](https://cloud.google.com/iam/help/conditions/resource-policies).
	Condition GoogleTypeExprPtrInput `pulumi:"condition"`
	// Specifies the principals requesting access for a Google Cloud resource. `members` can have the following values: * `allUsers`: A special identifier that represents anyone who is on the internet; with or without a Google account. * `allAuthenticatedUsers`: A special identifier that represents anyone who is authenticated with a Google account or a service account. Does not include identities that come from external identity providers (IdPs) through identity federation. * `user:{emailid}`: An email address that represents a specific Google account. For example, `alice@example.com` . * `serviceAccount:{emailid}`: An email address that represents a Google service account. For example, `my-other-app@appspot.gserviceaccount.com`. * `serviceAccount:{projectid}.svc.id.goog[{namespace}/{kubernetes-sa}]`: An identifier for a [Kubernetes service account](https://cloud.google.com/kubernetes-engine/docs/how-to/kubernetes-service-accounts). For example, `my-project.svc.id.goog[my-namespace/my-kubernetes-sa]`. * `group:{emailid}`: An email address that represents a Google group. For example, `admins@example.com`. * `domain:{domain}`: The G Suite domain (primary) that represents all the users of that domain. For example, `google.com` or `example.com`. * `deleted:user:{emailid}?uid={uniqueid}`: An email address (plus unique identifier) representing a user that has been recently deleted. For example, `alice@example.com?uid=123456789012345678901`. If the user is recovered, this value reverts to `user:{emailid}` and the recovered user retains the role in the binding. * `deleted:serviceAccount:{emailid}?uid={uniqueid}`: An email address (plus unique identifier) representing a service account that has been recently deleted. For example, `my-other-app@appspot.gserviceaccount.com?uid=123456789012345678901`. If the service account is undeleted, this value reverts to `serviceAccount:{emailid}` and the undeleted service account retains the role in the binding. * `deleted:group:{emailid}?uid={uniqueid}`: An email address (plus unique identifier) representing a Google group that has been recently deleted. For example, `admins@example.com?uid=123456789012345678901`. If the group is recovered, this value reverts to `group:{emailid}` and the recovered group retains the role in the binding.
	Members pulumi.StringArrayInput `pulumi:"members"`
	// Role that is assigned to the list of `members`, or principals. For example, `roles/viewer`, `roles/editor`, or `roles/owner`.
	Role pulumi.StringPtrInput `pulumi:"role"`
}

func (GoogleIamV1BindingArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleIamV1Binding)(nil)).Elem()
}

func (i GoogleIamV1BindingArgs) ToGoogleIamV1BindingOutput() GoogleIamV1BindingOutput {
	return i.ToGoogleIamV1BindingOutputWithContext(context.Background())
}

func (i GoogleIamV1BindingArgs) ToGoogleIamV1BindingOutputWithContext(ctx context.Context) GoogleIamV1BindingOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleIamV1BindingOutput)
}

// GoogleIamV1BindingArrayInput is an input type that accepts GoogleIamV1BindingArray and GoogleIamV1BindingArrayOutput values.
// You can construct a concrete instance of `GoogleIamV1BindingArrayInput` via:
//
//	GoogleIamV1BindingArray{ GoogleIamV1BindingArgs{...} }
type GoogleIamV1BindingArrayInput interface {
	pulumi.Input

	ToGoogleIamV1BindingArrayOutput() GoogleIamV1BindingArrayOutput
	ToGoogleIamV1BindingArrayOutputWithContext(context.Context) GoogleIamV1BindingArrayOutput
}

type GoogleIamV1BindingArray []GoogleIamV1BindingInput

func (GoogleIamV1BindingArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleIamV1Binding)(nil)).Elem()
}

func (i GoogleIamV1BindingArray) ToGoogleIamV1BindingArrayOutput() GoogleIamV1BindingArrayOutput {
	return i.ToGoogleIamV1BindingArrayOutputWithContext(context.Background())
}

func (i GoogleIamV1BindingArray) ToGoogleIamV1BindingArrayOutputWithContext(ctx context.Context) GoogleIamV1BindingArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleIamV1BindingArrayOutput)
}

// Associates `members`, or principals, with a `role`.
type GoogleIamV1BindingOutput struct{ *pulumi.OutputState }

func (GoogleIamV1BindingOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleIamV1Binding)(nil)).Elem()
}

func (o GoogleIamV1BindingOutput) ToGoogleIamV1BindingOutput() GoogleIamV1BindingOutput {
	return o
}

func (o GoogleIamV1BindingOutput) ToGoogleIamV1BindingOutputWithContext(ctx context.Context) GoogleIamV1BindingOutput {
	return o
}

// The condition that is associated with this binding. If the condition evaluates to `true`, then this binding applies to the current request. If the condition evaluates to `false`, then this binding does not apply to the current request. However, a different role binding might grant the same role to one or more of the principals in this binding. To learn which resources support conditions in their IAM policies, see the [IAM documentation](https://cloud.google.com/iam/help/conditions/resource-policies).
func (o GoogleIamV1BindingOutput) Condition() GoogleTypeExprPtrOutput {
	return o.ApplyT(func(v GoogleIamV1Binding) *GoogleTypeExpr { return v.Condition }).(GoogleTypeExprPtrOutput)
}

// Specifies the principals requesting access for a Google Cloud resource. `members` can have the following values: * `allUsers`: A special identifier that represents anyone who is on the internet; with or without a Google account. * `allAuthenticatedUsers`: A special identifier that represents anyone who is authenticated with a Google account or a service account. Does not include identities that come from external identity providers (IdPs) through identity federation. * `user:{emailid}`: An email address that represents a specific Google account. For example, `alice@example.com` . * `serviceAccount:{emailid}`: An email address that represents a Google service account. For example, `my-other-app@appspot.gserviceaccount.com`. * `serviceAccount:{projectid}.svc.id.goog[{namespace}/{kubernetes-sa}]`: An identifier for a [Kubernetes service account](https://cloud.google.com/kubernetes-engine/docs/how-to/kubernetes-service-accounts). For example, `my-project.svc.id.goog[my-namespace/my-kubernetes-sa]`. * `group:{emailid}`: An email address that represents a Google group. For example, `admins@example.com`. * `domain:{domain}`: The G Suite domain (primary) that represents all the users of that domain. For example, `google.com` or `example.com`. * `deleted:user:{emailid}?uid={uniqueid}`: An email address (plus unique identifier) representing a user that has been recently deleted. For example, `alice@example.com?uid=123456789012345678901`. If the user is recovered, this value reverts to `user:{emailid}` and the recovered user retains the role in the binding. * `deleted:serviceAccount:{emailid}?uid={uniqueid}`: An email address (plus unique identifier) representing a service account that has been recently deleted. For example, `my-other-app@appspot.gserviceaccount.com?uid=123456789012345678901`. If the service account is undeleted, this value reverts to `serviceAccount:{emailid}` and the undeleted service account retains the role in the binding. * `deleted:group:{emailid}?uid={uniqueid}`: An email address (plus unique identifier) representing a Google group that has been recently deleted. For example, `admins@example.com?uid=123456789012345678901`. If the group is recovered, this value reverts to `group:{emailid}` and the recovered group retains the role in the binding.
func (o GoogleIamV1BindingOutput) Members() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleIamV1Binding) []string { return v.Members }).(pulumi.StringArrayOutput)
}

// Role that is assigned to the list of `members`, or principals. For example, `roles/viewer`, `roles/editor`, or `roles/owner`.
func (o GoogleIamV1BindingOutput) Role() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleIamV1Binding) *string { return v.Role }).(pulumi.StringPtrOutput)
}

type GoogleIamV1BindingArrayOutput struct{ *pulumi.OutputState }

func (GoogleIamV1BindingArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleIamV1Binding)(nil)).Elem()
}

func (o GoogleIamV1BindingArrayOutput) ToGoogleIamV1BindingArrayOutput() GoogleIamV1BindingArrayOutput {
	return o
}

func (o GoogleIamV1BindingArrayOutput) ToGoogleIamV1BindingArrayOutputWithContext(ctx context.Context) GoogleIamV1BindingArrayOutput {
	return o
}

func (o GoogleIamV1BindingArrayOutput) Index(i pulumi.IntInput) GoogleIamV1BindingOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GoogleIamV1Binding {
		return vs[0].([]GoogleIamV1Binding)[vs[1].(int)]
	}).(GoogleIamV1BindingOutput)
}

// Associates `members`, or principals, with a `role`.
type GoogleIamV1BindingResponse struct {
	// The condition that is associated with this binding. If the condition evaluates to `true`, then this binding applies to the current request. If the condition evaluates to `false`, then this binding does not apply to the current request. However, a different role binding might grant the same role to one or more of the principals in this binding. To learn which resources support conditions in their IAM policies, see the [IAM documentation](https://cloud.google.com/iam/help/conditions/resource-policies).
	Condition GoogleTypeExprResponse `pulumi:"condition"`
	// Specifies the principals requesting access for a Google Cloud resource. `members` can have the following values: * `allUsers`: A special identifier that represents anyone who is on the internet; with or without a Google account. * `allAuthenticatedUsers`: A special identifier that represents anyone who is authenticated with a Google account or a service account. Does not include identities that come from external identity providers (IdPs) through identity federation. * `user:{emailid}`: An email address that represents a specific Google account. For example, `alice@example.com` . * `serviceAccount:{emailid}`: An email address that represents a Google service account. For example, `my-other-app@appspot.gserviceaccount.com`. * `serviceAccount:{projectid}.svc.id.goog[{namespace}/{kubernetes-sa}]`: An identifier for a [Kubernetes service account](https://cloud.google.com/kubernetes-engine/docs/how-to/kubernetes-service-accounts). For example, `my-project.svc.id.goog[my-namespace/my-kubernetes-sa]`. * `group:{emailid}`: An email address that represents a Google group. For example, `admins@example.com`. * `domain:{domain}`: The G Suite domain (primary) that represents all the users of that domain. For example, `google.com` or `example.com`. * `deleted:user:{emailid}?uid={uniqueid}`: An email address (plus unique identifier) representing a user that has been recently deleted. For example, `alice@example.com?uid=123456789012345678901`. If the user is recovered, this value reverts to `user:{emailid}` and the recovered user retains the role in the binding. * `deleted:serviceAccount:{emailid}?uid={uniqueid}`: An email address (plus unique identifier) representing a service account that has been recently deleted. For example, `my-other-app@appspot.gserviceaccount.com?uid=123456789012345678901`. If the service account is undeleted, this value reverts to `serviceAccount:{emailid}` and the undeleted service account retains the role in the binding. * `deleted:group:{emailid}?uid={uniqueid}`: An email address (plus unique identifier) representing a Google group that has been recently deleted. For example, `admins@example.com?uid=123456789012345678901`. If the group is recovered, this value reverts to `group:{emailid}` and the recovered group retains the role in the binding.
	Members []string `pulumi:"members"`
	// Role that is assigned to the list of `members`, or principals. For example, `roles/viewer`, `roles/editor`, or `roles/owner`.
	Role string `pulumi:"role"`
}

// Associates `members`, or principals, with a `role`.
type GoogleIamV1BindingResponseOutput struct{ *pulumi.OutputState }

func (GoogleIamV1BindingResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleIamV1BindingResponse)(nil)).Elem()
}

func (o GoogleIamV1BindingResponseOutput) ToGoogleIamV1BindingResponseOutput() GoogleIamV1BindingResponseOutput {
	return o
}

func (o GoogleIamV1BindingResponseOutput) ToGoogleIamV1BindingResponseOutputWithContext(ctx context.Context) GoogleIamV1BindingResponseOutput {
	return o
}

// The condition that is associated with this binding. If the condition evaluates to `true`, then this binding applies to the current request. If the condition evaluates to `false`, then this binding does not apply to the current request. However, a different role binding might grant the same role to one or more of the principals in this binding. To learn which resources support conditions in their IAM policies, see the [IAM documentation](https://cloud.google.com/iam/help/conditions/resource-policies).
func (o GoogleIamV1BindingResponseOutput) Condition() GoogleTypeExprResponseOutput {
	return o.ApplyT(func(v GoogleIamV1BindingResponse) GoogleTypeExprResponse { return v.Condition }).(GoogleTypeExprResponseOutput)
}

// Specifies the principals requesting access for a Google Cloud resource. `members` can have the following values: * `allUsers`: A special identifier that represents anyone who is on the internet; with or without a Google account. * `allAuthenticatedUsers`: A special identifier that represents anyone who is authenticated with a Google account or a service account. Does not include identities that come from external identity providers (IdPs) through identity federation. * `user:{emailid}`: An email address that represents a specific Google account. For example, `alice@example.com` . * `serviceAccount:{emailid}`: An email address that represents a Google service account. For example, `my-other-app@appspot.gserviceaccount.com`. * `serviceAccount:{projectid}.svc.id.goog[{namespace}/{kubernetes-sa}]`: An identifier for a [Kubernetes service account](https://cloud.google.com/kubernetes-engine/docs/how-to/kubernetes-service-accounts). For example, `my-project.svc.id.goog[my-namespace/my-kubernetes-sa]`. * `group:{emailid}`: An email address that represents a Google group. For example, `admins@example.com`. * `domain:{domain}`: The G Suite domain (primary) that represents all the users of that domain. For example, `google.com` or `example.com`. * `deleted:user:{emailid}?uid={uniqueid}`: An email address (plus unique identifier) representing a user that has been recently deleted. For example, `alice@example.com?uid=123456789012345678901`. If the user is recovered, this value reverts to `user:{emailid}` and the recovered user retains the role in the binding. * `deleted:serviceAccount:{emailid}?uid={uniqueid}`: An email address (plus unique identifier) representing a service account that has been recently deleted. For example, `my-other-app@appspot.gserviceaccount.com?uid=123456789012345678901`. If the service account is undeleted, this value reverts to `serviceAccount:{emailid}` and the undeleted service account retains the role in the binding. * `deleted:group:{emailid}?uid={uniqueid}`: An email address (plus unique identifier) representing a Google group that has been recently deleted. For example, `admins@example.com?uid=123456789012345678901`. If the group is recovered, this value reverts to `group:{emailid}` and the recovered group retains the role in the binding.
func (o GoogleIamV1BindingResponseOutput) Members() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleIamV1BindingResponse) []string { return v.Members }).(pulumi.StringArrayOutput)
}

// Role that is assigned to the list of `members`, or principals. For example, `roles/viewer`, `roles/editor`, or `roles/owner`.
func (o GoogleIamV1BindingResponseOutput) Role() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleIamV1BindingResponse) string { return v.Role }).(pulumi.StringOutput)
}

type GoogleIamV1BindingResponseArrayOutput struct{ *pulumi.OutputState }

func (GoogleIamV1BindingResponseArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleIamV1BindingResponse)(nil)).Elem()
}

func (o GoogleIamV1BindingResponseArrayOutput) ToGoogleIamV1BindingResponseArrayOutput() GoogleIamV1BindingResponseArrayOutput {
	return o
}

func (o GoogleIamV1BindingResponseArrayOutput) ToGoogleIamV1BindingResponseArrayOutputWithContext(ctx context.Context) GoogleIamV1BindingResponseArrayOutput {
	return o
}

func (o GoogleIamV1BindingResponseArrayOutput) Index(i pulumi.IntInput) GoogleIamV1BindingResponseOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GoogleIamV1BindingResponse {
		return vs[0].([]GoogleIamV1BindingResponse)[vs[1].(int)]
	}).(GoogleIamV1BindingResponseOutput)
}

// The `Status` type defines a logical error model that is suitable for different programming environments, including REST APIs and RPC APIs. It is used by [gRPC](https://github.com/grpc). Each `Status` message contains three pieces of data: error code, error message, and error details. You can find out more about this error model and how to work with it in the [API Design Guide](https://cloud.google.com/apis/design/errors).
type GoogleRpcStatusResponse struct {
	// The status code, which should be an enum value of google.rpc.Code.
	Code int `pulumi:"code"`
	// A list of messages that carry the error details. There is a common set of message types for APIs to use.
	Details []map[string]interface{} `pulumi:"details"`
	// A developer-facing error message, which should be in English. Any user-facing error message should be localized and sent in the google.rpc.Status.details field, or localized by the client.
	Message string `pulumi:"message"`
}

// The `Status` type defines a logical error model that is suitable for different programming environments, including REST APIs and RPC APIs. It is used by [gRPC](https://github.com/grpc). Each `Status` message contains three pieces of data: error code, error message, and error details. You can find out more about this error model and how to work with it in the [API Design Guide](https://cloud.google.com/apis/design/errors).
type GoogleRpcStatusResponseOutput struct{ *pulumi.OutputState }

func (GoogleRpcStatusResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleRpcStatusResponse)(nil)).Elem()
}

func (o GoogleRpcStatusResponseOutput) ToGoogleRpcStatusResponseOutput() GoogleRpcStatusResponseOutput {
	return o
}

func (o GoogleRpcStatusResponseOutput) ToGoogleRpcStatusResponseOutputWithContext(ctx context.Context) GoogleRpcStatusResponseOutput {
	return o
}

// The status code, which should be an enum value of google.rpc.Code.
func (o GoogleRpcStatusResponseOutput) Code() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleRpcStatusResponse) int { return v.Code }).(pulumi.IntOutput)
}

// A list of messages that carry the error details. There is a common set of message types for APIs to use.
func (o GoogleRpcStatusResponseOutput) Details() pulumi.MapArrayOutput {
	return o.ApplyT(func(v GoogleRpcStatusResponse) []map[string]interface{} { return v.Details }).(pulumi.MapArrayOutput)
}

// A developer-facing error message, which should be in English. Any user-facing error message should be localized and sent in the google.rpc.Status.details field, or localized by the client.
func (o GoogleRpcStatusResponseOutput) Message() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleRpcStatusResponse) string { return v.Message }).(pulumi.StringOutput)
}

type GoogleRpcStatusResponseArrayOutput struct{ *pulumi.OutputState }

func (GoogleRpcStatusResponseArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleRpcStatusResponse)(nil)).Elem()
}

func (o GoogleRpcStatusResponseArrayOutput) ToGoogleRpcStatusResponseArrayOutput() GoogleRpcStatusResponseArrayOutput {
	return o
}

func (o GoogleRpcStatusResponseArrayOutput) ToGoogleRpcStatusResponseArrayOutputWithContext(ctx context.Context) GoogleRpcStatusResponseArrayOutput {
	return o
}

func (o GoogleRpcStatusResponseArrayOutput) Index(i pulumi.IntInput) GoogleRpcStatusResponseOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GoogleRpcStatusResponse {
		return vs[0].([]GoogleRpcStatusResponse)[vs[1].(int)]
	}).(GoogleRpcStatusResponseOutput)
}

// Represents a textual expression in the Common Expression Language (CEL) syntax. CEL is a C-like expression language. The syntax and semantics of CEL are documented at https://github.com/google/cel-spec. Example (Comparison): title: "Summary size limit" description: "Determines if a summary is less than 100 chars" expression: "document.summary.size() < 100" Example (Equality): title: "Requestor is owner" description: "Determines if requestor is the document owner" expression: "document.owner == request.auth.claims.email" Example (Logic): title: "Public documents" description: "Determine whether the document should be publicly visible" expression: "document.type != 'private' && document.type != 'internal'" Example (Data Manipulation): title: "Notification string" description: "Create a notification string with a timestamp." expression: "'New message received at ' + string(document.create_time)" The exact variables and functions that may be referenced within an expression are determined by the service that evaluates it. See the service documentation for additional information.
type GoogleTypeExpr struct {
	// Optional. Description of the expression. This is a longer text which describes the expression, e.g. when hovered over it in a UI.
	Description *string `pulumi:"description"`
	// Textual representation of an expression in Common Expression Language syntax.
	Expression *string `pulumi:"expression"`
	// Optional. String indicating the location of the expression for error reporting, e.g. a file name and a position in the file.
	Location *string `pulumi:"location"`
	// Optional. Title for the expression, i.e. a short string describing its purpose. This can be used e.g. in UIs which allow to enter the expression.
	Title *string `pulumi:"title"`
}

// GoogleTypeExprInput is an input type that accepts GoogleTypeExprArgs and GoogleTypeExprOutput values.
// You can construct a concrete instance of `GoogleTypeExprInput` via:
//
//	GoogleTypeExprArgs{...}
type GoogleTypeExprInput interface {
	pulumi.Input

	ToGoogleTypeExprOutput() GoogleTypeExprOutput
	ToGoogleTypeExprOutputWithContext(context.Context) GoogleTypeExprOutput
}

// Represents a textual expression in the Common Expression Language (CEL) syntax. CEL is a C-like expression language. The syntax and semantics of CEL are documented at https://github.com/google/cel-spec. Example (Comparison): title: "Summary size limit" description: "Determines if a summary is less than 100 chars" expression: "document.summary.size() < 100" Example (Equality): title: "Requestor is owner" description: "Determines if requestor is the document owner" expression: "document.owner == request.auth.claims.email" Example (Logic): title: "Public documents" description: "Determine whether the document should be publicly visible" expression: "document.type != 'private' && document.type != 'internal'" Example (Data Manipulation): title: "Notification string" description: "Create a notification string with a timestamp." expression: "'New message received at ' + string(document.create_time)" The exact variables and functions that may be referenced within an expression are determined by the service that evaluates it. See the service documentation for additional information.
type GoogleTypeExprArgs struct {
	// Optional. Description of the expression. This is a longer text which describes the expression, e.g. when hovered over it in a UI.
	Description pulumi.StringPtrInput `pulumi:"description"`
	// Textual representation of an expression in Common Expression Language syntax.
	Expression pulumi.StringPtrInput `pulumi:"expression"`
	// Optional. String indicating the location of the expression for error reporting, e.g. a file name and a position in the file.
	Location pulumi.StringPtrInput `pulumi:"location"`
	// Optional. Title for the expression, i.e. a short string describing its purpose. This can be used e.g. in UIs which allow to enter the expression.
	Title pulumi.StringPtrInput `pulumi:"title"`
}

func (GoogleTypeExprArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleTypeExpr)(nil)).Elem()
}

func (i GoogleTypeExprArgs) ToGoogleTypeExprOutput() GoogleTypeExprOutput {
	return i.ToGoogleTypeExprOutputWithContext(context.Background())
}

func (i GoogleTypeExprArgs) ToGoogleTypeExprOutputWithContext(ctx context.Context) GoogleTypeExprOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleTypeExprOutput)
}

func (i GoogleTypeExprArgs) ToGoogleTypeExprPtrOutput() GoogleTypeExprPtrOutput {
	return i.ToGoogleTypeExprPtrOutputWithContext(context.Background())
}

func (i GoogleTypeExprArgs) ToGoogleTypeExprPtrOutputWithContext(ctx context.Context) GoogleTypeExprPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleTypeExprOutput).ToGoogleTypeExprPtrOutputWithContext(ctx)
}

// GoogleTypeExprPtrInput is an input type that accepts GoogleTypeExprArgs, GoogleTypeExprPtr and GoogleTypeExprPtrOutput values.
// You can construct a concrete instance of `GoogleTypeExprPtrInput` via:
//
//	        GoogleTypeExprArgs{...}
//
//	or:
//
//	        nil
type GoogleTypeExprPtrInput interface {
	pulumi.Input

	ToGoogleTypeExprPtrOutput() GoogleTypeExprPtrOutput
	ToGoogleTypeExprPtrOutputWithContext(context.Context) GoogleTypeExprPtrOutput
}

type googleTypeExprPtrType GoogleTypeExprArgs

func GoogleTypeExprPtr(v *GoogleTypeExprArgs) GoogleTypeExprPtrInput {
	return (*googleTypeExprPtrType)(v)
}

func (*googleTypeExprPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleTypeExpr)(nil)).Elem()
}

func (i *googleTypeExprPtrType) ToGoogleTypeExprPtrOutput() GoogleTypeExprPtrOutput {
	return i.ToGoogleTypeExprPtrOutputWithContext(context.Background())
}

func (i *googleTypeExprPtrType) ToGoogleTypeExprPtrOutputWithContext(ctx context.Context) GoogleTypeExprPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleTypeExprPtrOutput)
}

// Represents a textual expression in the Common Expression Language (CEL) syntax. CEL is a C-like expression language. The syntax and semantics of CEL are documented at https://github.com/google/cel-spec. Example (Comparison): title: "Summary size limit" description: "Determines if a summary is less than 100 chars" expression: "document.summary.size() < 100" Example (Equality): title: "Requestor is owner" description: "Determines if requestor is the document owner" expression: "document.owner == request.auth.claims.email" Example (Logic): title: "Public documents" description: "Determine whether the document should be publicly visible" expression: "document.type != 'private' && document.type != 'internal'" Example (Data Manipulation): title: "Notification string" description: "Create a notification string with a timestamp." expression: "'New message received at ' + string(document.create_time)" The exact variables and functions that may be referenced within an expression are determined by the service that evaluates it. See the service documentation for additional information.
type GoogleTypeExprOutput struct{ *pulumi.OutputState }

func (GoogleTypeExprOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleTypeExpr)(nil)).Elem()
}

func (o GoogleTypeExprOutput) ToGoogleTypeExprOutput() GoogleTypeExprOutput {
	return o
}

func (o GoogleTypeExprOutput) ToGoogleTypeExprOutputWithContext(ctx context.Context) GoogleTypeExprOutput {
	return o
}

func (o GoogleTypeExprOutput) ToGoogleTypeExprPtrOutput() GoogleTypeExprPtrOutput {
	return o.ToGoogleTypeExprPtrOutputWithContext(context.Background())
}

func (o GoogleTypeExprOutput) ToGoogleTypeExprPtrOutputWithContext(ctx context.Context) GoogleTypeExprPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleTypeExpr) *GoogleTypeExpr {
		return &v
	}).(GoogleTypeExprPtrOutput)
}

// Optional. Description of the expression. This is a longer text which describes the expression, e.g. when hovered over it in a UI.
func (o GoogleTypeExprOutput) Description() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleTypeExpr) *string { return v.Description }).(pulumi.StringPtrOutput)
}

// Textual representation of an expression in Common Expression Language syntax.
func (o GoogleTypeExprOutput) Expression() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleTypeExpr) *string { return v.Expression }).(pulumi.StringPtrOutput)
}

// Optional. String indicating the location of the expression for error reporting, e.g. a file name and a position in the file.
func (o GoogleTypeExprOutput) Location() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleTypeExpr) *string { return v.Location }).(pulumi.StringPtrOutput)
}

// Optional. Title for the expression, i.e. a short string describing its purpose. This can be used e.g. in UIs which allow to enter the expression.
func (o GoogleTypeExprOutput) Title() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleTypeExpr) *string { return v.Title }).(pulumi.StringPtrOutput)
}

type GoogleTypeExprPtrOutput struct{ *pulumi.OutputState }

func (GoogleTypeExprPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleTypeExpr)(nil)).Elem()
}

func (o GoogleTypeExprPtrOutput) ToGoogleTypeExprPtrOutput() GoogleTypeExprPtrOutput {
	return o
}

func (o GoogleTypeExprPtrOutput) ToGoogleTypeExprPtrOutputWithContext(ctx context.Context) GoogleTypeExprPtrOutput {
	return o
}

func (o GoogleTypeExprPtrOutput) Elem() GoogleTypeExprOutput {
	return o.ApplyT(func(v *GoogleTypeExpr) GoogleTypeExpr {
		if v != nil {
			return *v
		}
		var ret GoogleTypeExpr
		return ret
	}).(GoogleTypeExprOutput)
}

// Optional. Description of the expression. This is a longer text which describes the expression, e.g. when hovered over it in a UI.
func (o GoogleTypeExprPtrOutput) Description() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleTypeExpr) *string {
		if v == nil {
			return nil
		}
		return v.Description
	}).(pulumi.StringPtrOutput)
}

// Textual representation of an expression in Common Expression Language syntax.
func (o GoogleTypeExprPtrOutput) Expression() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleTypeExpr) *string {
		if v == nil {
			return nil
		}
		return v.Expression
	}).(pulumi.StringPtrOutput)
}

// Optional. String indicating the location of the expression for error reporting, e.g. a file name and a position in the file.
func (o GoogleTypeExprPtrOutput) Location() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleTypeExpr) *string {
		if v == nil {
			return nil
		}
		return v.Location
	}).(pulumi.StringPtrOutput)
}

// Optional. Title for the expression, i.e. a short string describing its purpose. This can be used e.g. in UIs which allow to enter the expression.
func (o GoogleTypeExprPtrOutput) Title() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleTypeExpr) *string {
		if v == nil {
			return nil
		}
		return v.Title
	}).(pulumi.StringPtrOutput)
}

// Represents a textual expression in the Common Expression Language (CEL) syntax. CEL is a C-like expression language. The syntax and semantics of CEL are documented at https://github.com/google/cel-spec. Example (Comparison): title: "Summary size limit" description: "Determines if a summary is less than 100 chars" expression: "document.summary.size() < 100" Example (Equality): title: "Requestor is owner" description: "Determines if requestor is the document owner" expression: "document.owner == request.auth.claims.email" Example (Logic): title: "Public documents" description: "Determine whether the document should be publicly visible" expression: "document.type != 'private' && document.type != 'internal'" Example (Data Manipulation): title: "Notification string" description: "Create a notification string with a timestamp." expression: "'New message received at ' + string(document.create_time)" The exact variables and functions that may be referenced within an expression are determined by the service that evaluates it. See the service documentation for additional information.
type GoogleTypeExprResponse struct {
	// Optional. Description of the expression. This is a longer text which describes the expression, e.g. when hovered over it in a UI.
	Description string `pulumi:"description"`
	// Textual representation of an expression in Common Expression Language syntax.
	Expression string `pulumi:"expression"`
	// Optional. String indicating the location of the expression for error reporting, e.g. a file name and a position in the file.
	Location string `pulumi:"location"`
	// Optional. Title for the expression, i.e. a short string describing its purpose. This can be used e.g. in UIs which allow to enter the expression.
	Title string `pulumi:"title"`
}

// Represents a textual expression in the Common Expression Language (CEL) syntax. CEL is a C-like expression language. The syntax and semantics of CEL are documented at https://github.com/google/cel-spec. Example (Comparison): title: "Summary size limit" description: "Determines if a summary is less than 100 chars" expression: "document.summary.size() < 100" Example (Equality): title: "Requestor is owner" description: "Determines if requestor is the document owner" expression: "document.owner == request.auth.claims.email" Example (Logic): title: "Public documents" description: "Determine whether the document should be publicly visible" expression: "document.type != 'private' && document.type != 'internal'" Example (Data Manipulation): title: "Notification string" description: "Create a notification string with a timestamp." expression: "'New message received at ' + string(document.create_time)" The exact variables and functions that may be referenced within an expression are determined by the service that evaluates it. See the service documentation for additional information.
type GoogleTypeExprResponseOutput struct{ *pulumi.OutputState }

func (GoogleTypeExprResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleTypeExprResponse)(nil)).Elem()
}

func (o GoogleTypeExprResponseOutput) ToGoogleTypeExprResponseOutput() GoogleTypeExprResponseOutput {
	return o
}

func (o GoogleTypeExprResponseOutput) ToGoogleTypeExprResponseOutputWithContext(ctx context.Context) GoogleTypeExprResponseOutput {
	return o
}

// Optional. Description of the expression. This is a longer text which describes the expression, e.g. when hovered over it in a UI.
func (o GoogleTypeExprResponseOutput) Description() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleTypeExprResponse) string { return v.Description }).(pulumi.StringOutput)
}

// Textual representation of an expression in Common Expression Language syntax.
func (o GoogleTypeExprResponseOutput) Expression() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleTypeExprResponse) string { return v.Expression }).(pulumi.StringOutput)
}

// Optional. String indicating the location of the expression for error reporting, e.g. a file name and a position in the file.
func (o GoogleTypeExprResponseOutput) Location() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleTypeExprResponse) string { return v.Location }).(pulumi.StringOutput)
}

// Optional. Title for the expression, i.e. a short string describing its purpose. This can be used e.g. in UIs which allow to enter the expression.
func (o GoogleTypeExprResponseOutput) Title() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleTypeExprResponse) string { return v.Title }).(pulumi.StringOutput)
}

// Represents an amount of money with its currency type.
type GoogleTypeMoneyResponse struct {
	// The three-letter currency code defined in ISO 4217.
	CurrencyCode string `pulumi:"currencyCode"`
	// Number of nano (10^-9) units of the amount. The value must be between -999,999,999 and +999,999,999 inclusive. If `units` is positive, `nanos` must be positive or zero. If `units` is zero, `nanos` can be positive, zero, or negative. If `units` is negative, `nanos` must be negative or zero. For example $-1.75 is represented as `units`=-1 and `nanos`=-750,000,000.
	Nanos int `pulumi:"nanos"`
	// The whole units of the amount. For example if `currencyCode` is `"USD"`, then 1 unit is one US dollar.
	Units string `pulumi:"units"`
}

// Represents an amount of money with its currency type.
type GoogleTypeMoneyResponseOutput struct{ *pulumi.OutputState }

func (GoogleTypeMoneyResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleTypeMoneyResponse)(nil)).Elem()
}

func (o GoogleTypeMoneyResponseOutput) ToGoogleTypeMoneyResponseOutput() GoogleTypeMoneyResponseOutput {
	return o
}

func (o GoogleTypeMoneyResponseOutput) ToGoogleTypeMoneyResponseOutputWithContext(ctx context.Context) GoogleTypeMoneyResponseOutput {
	return o
}

// The three-letter currency code defined in ISO 4217.
func (o GoogleTypeMoneyResponseOutput) CurrencyCode() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleTypeMoneyResponse) string { return v.CurrencyCode }).(pulumi.StringOutput)
}

// Number of nano (10^-9) units of the amount. The value must be between -999,999,999 and +999,999,999 inclusive. If `units` is positive, `nanos` must be positive or zero. If `units` is zero, `nanos` can be positive, zero, or negative. If `units` is negative, `nanos` must be negative or zero. For example $-1.75 is represented as `units`=-1 and `nanos`=-750,000,000.
func (o GoogleTypeMoneyResponseOutput) Nanos() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleTypeMoneyResponse) int { return v.Nanos }).(pulumi.IntOutput)
}

// The whole units of the amount. For example if `currencyCode` is `"USD"`, then 1 unit is one US dollar.
func (o GoogleTypeMoneyResponseOutput) Units() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleTypeMoneyResponse) string { return v.Units }).(pulumi.StringOutput)
}

func init() {
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1ActiveLearningConfigInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1ActiveLearningConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1ActiveLearningConfigPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1ActiveLearningConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1AutoscalingMetricSpecInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1AutoscalingMetricSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1AutoscalingMetricSpecArrayInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1AutoscalingMetricSpecArray{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1BatchDedicatedResourcesInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1BatchDedicatedResourcesArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1BatchDedicatedResourcesPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1BatchDedicatedResourcesArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1BatchPredictionJobInputConfigInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1BatchPredictionJobInputConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1BatchPredictionJobOutputConfigInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1BatchPredictionJobOutputConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1BigQueryDestinationInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1BigQueryDestinationArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1BigQueryDestinationPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1BigQueryDestinationArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1BigQuerySourceInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1BigQuerySourceArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1BigQuerySourcePtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1BigQuerySourceArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1BlurBaselineConfigInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1BlurBaselineConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1BlurBaselineConfigPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1BlurBaselineConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1ContainerSpecInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1ContainerSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1ContainerSpecPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1ContainerSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1CreatePipelineJobRequestInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1CreatePipelineJobRequestArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1CreatePipelineJobRequestPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1CreatePipelineJobRequestArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1CustomJobSpecInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1CustomJobSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1CustomJobSpecPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1CustomJobSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1DedicatedResourcesInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1DedicatedResourcesArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1DiskSpecInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1DiskSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1DiskSpecPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1DiskSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1EncryptionSpecInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1EncryptionSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1EncryptionSpecPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1EncryptionSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1EnvVarInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1EnvVarArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1EnvVarArrayInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1EnvVarArray{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1ExamplesInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1ExamplesArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1ExamplesPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1ExamplesArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1ExamplesExampleGcsSourceInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1ExamplesExampleGcsSourceArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1ExamplesExampleGcsSourcePtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1ExamplesExampleGcsSourceArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1ExplanationMetadataInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1ExplanationMetadataArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1ExplanationMetadataPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1ExplanationMetadataArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1ExplanationParametersInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1ExplanationParametersArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1ExplanationParametersPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1ExplanationParametersArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1ExplanationSpecInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1ExplanationSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1ExplanationSpecPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1ExplanationSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeatureGroupBigQueryInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1FeatureGroupBigQueryArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeatureGroupBigQueryPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1FeatureGroupBigQueryArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeatureNoiseSigmaInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1FeatureNoiseSigmaArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeatureNoiseSigmaPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1FeatureNoiseSigmaArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureArrayInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureArray{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtablePtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimizedInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimizedArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimizedPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimizedArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeatureStatsAnomalyInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1FeatureStatsAnomalyArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeatureStatsAnomalyPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1FeatureStatsAnomalyArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeatureStatsAnomalyArrayInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1FeatureStatsAnomalyArray{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeatureViewBigQuerySourceInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1FeatureViewBigQuerySourceArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeatureViewBigQuerySourcePtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1FeatureViewBigQuerySourceArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourcePtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupArrayInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupArray{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeatureViewSyncConfigInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1FeatureViewSyncConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeatureViewSyncConfigPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1FeatureViewSyncConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1FilterSplitInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1FilterSplitArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1FilterSplitPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1FilterSplitArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1FractionSplitInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1FractionSplitArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1FractionSplitPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1FractionSplitArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1GcsDestinationInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1GcsDestinationArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1GcsDestinationPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1GcsDestinationArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1GcsSourceInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1GcsSourceArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1GcsSourcePtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1GcsSourceArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1InputDataConfigInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1InputDataConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1InputDataConfigPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1InputDataConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1IntegratedGradientsAttributionInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1IntegratedGradientsAttributionArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1IntegratedGradientsAttributionPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1IntegratedGradientsAttributionArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1MachineSpecInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1MachineSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1MachineSpecPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1MachineSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1ManualBatchTuningParametersInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1ManualBatchTuningParametersArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1ManualBatchTuningParametersPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1ManualBatchTuningParametersArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1ModelInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1ModelArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1ModelPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1ModelArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1ModelContainerSpecInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1ModelContainerSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1ModelContainerSpecPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1ModelContainerSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigArrayInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigArray{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringScheduleConfigInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringScheduleConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1ModelMonitoringConfigInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1ModelMonitoringConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1ModelMonitoringConfigPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1ModelMonitoringConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigArrayInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigArray{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesArrayInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesArray{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesArrayInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesArray{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1NasJobSpecInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1NasJobSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1NetworkSpecInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1NetworkSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1NetworkSpecPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1NetworkSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1NfsMountInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1NfsMountArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1NfsMountArrayInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1NfsMountArray{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1NotebookEucConfigInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1NotebookEucConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1NotebookEucConfigPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1NotebookEucConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1PersistentDiskSpecInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1PersistentDiskSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1PersistentDiskSpecPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1PersistentDiskSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1PipelineJobInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1PipelineJobArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1PipelineJobPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1PipelineJobArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1PortInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1PortArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1PortArrayInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1PortArray{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1PredefinedSplitInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1PredefinedSplitArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1PredefinedSplitPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1PredefinedSplitArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1PredictSchemataInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1PredictSchemataArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1PredictSchemataPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1PredictSchemataArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1PresetsInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1PresetsArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1PresetsPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1PresetsArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1PrivateServiceConnectConfigInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1PrivateServiceConnectConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1PrivateServiceConnectConfigPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1PrivateServiceConnectConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1ProbeInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1ProbeArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1ProbePtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1ProbeArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1ProbeExecActionInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1ProbeExecActionArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1ProbeExecActionPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1ProbeExecActionArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1PythonPackageSpecInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1PythonPackageSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1PythonPackageSpecPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1PythonPackageSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1RaySpecInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1RaySpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1RaySpecPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1RaySpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1ResourcePoolInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1ResourcePoolArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1ResourcePoolArrayInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1ResourcePoolArray{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1ResourceRuntimeSpecInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1ResourceRuntimeSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1ResourceRuntimeSpecPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1ResourceRuntimeSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1SampleConfigInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1SampleConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1SampleConfigPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1SampleConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1SampledShapleyAttributionInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1SampledShapleyAttributionArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1SampledShapleyAttributionPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1SampledShapleyAttributionArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1SamplingStrategyInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1SamplingStrategyArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1SamplingStrategyPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1SamplingStrategyArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1SavedQueryInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1SavedQueryArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1SavedQueryArrayInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1SavedQueryArray{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1SchedulingInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1SchedulingArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1SchedulingPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1SchedulingArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1ServiceAccountSpecInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1ServiceAccountSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1ServiceAccountSpecPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1ServiceAccountSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1SmoothGradConfigInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1SmoothGradConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1SmoothGradConfigPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1SmoothGradConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1StratifiedSplitInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1StratifiedSplitArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1StratifiedSplitPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1StratifiedSplitArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1StudySpecInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1StudySpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1StudySpecConvexStopConfigInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1StudySpecConvexStopConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1StudySpecConvexStopConfigPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1StudySpecConvexStopConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1StudySpecMetricSpecInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1StudySpecMetricSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1StudySpecMetricSpecArrayInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1StudySpecMetricSpecArray{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1StudySpecParameterSpecInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1StudySpecParameterSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1StudySpecParameterSpecArrayInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1StudySpecParameterSpecArray{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecArrayInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecArray{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1StudyTimeConstraintInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1StudyTimeConstraintArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1StudyTimeConstraintPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1StudyTimeConstraintArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1ThresholdConfigInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1ThresholdConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1ThresholdConfigPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1ThresholdConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1TimestampSplitInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1TimestampSplitArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1TimestampSplitPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1TimestampSplitArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1TrainingConfigInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1TrainingConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1TrainingConfigPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1TrainingConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1UnmanagedContainerModelInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1UnmanagedContainerModelArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1UnmanagedContainerModelPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1UnmanagedContainerModelArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1ValueInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1ValueArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1ValuePtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1ValueArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1WorkerPoolSpecInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1WorkerPoolSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1WorkerPoolSpecArrayInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1WorkerPoolSpecArray{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1XraiAttributionInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1XraiAttributionArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1beta1XraiAttributionPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1beta1XraiAttributionArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleIamV1BindingInput)(nil)).Elem(), GoogleIamV1BindingArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleIamV1BindingArrayInput)(nil)).Elem(), GoogleIamV1BindingArray{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleTypeExprInput)(nil)).Elem(), GoogleTypeExprArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleTypeExprPtrInput)(nil)).Elem(), GoogleTypeExprArgs{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ActiveLearningConfigOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ActiveLearningConfigPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ActiveLearningConfigResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ArtifactResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ArtifactResponseArrayOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1AutomaticResourcesResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1AutoscalingMetricSpecOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1AutoscalingMetricSpecArrayOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1AutoscalingMetricSpecResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1AutoscalingMetricSpecResponseArrayOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1BatchDedicatedResourcesOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1BatchDedicatedResourcesPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1BatchDedicatedResourcesResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1BatchPredictionJobInputConfigOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1BatchPredictionJobInputConfigResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1BatchPredictionJobInstanceConfigResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1BatchPredictionJobOutputConfigOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1BatchPredictionJobOutputConfigResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1BatchPredictionJobOutputInfoResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1BigQueryDestinationOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1BigQueryDestinationPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1BigQueryDestinationResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1BigQuerySourceOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1BigQuerySourcePtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1BigQuerySourceResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1BlurBaselineConfigOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1BlurBaselineConfigPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1BlurBaselineConfigResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1CompletionStatsResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ContainerSpecOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ContainerSpecPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ContainerSpecResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ContextResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1CreatePipelineJobRequestOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1CreatePipelineJobRequestPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1CreatePipelineJobRequestResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1CustomJobSpecOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1CustomJobSpecPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1CustomJobSpecResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1DedicatedResourcesOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1DedicatedResourcesResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1DeployedIndexAuthConfigAuthProviderResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1DeployedIndexAuthConfigResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1DeployedIndexRefResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1DeployedIndexRefResponseArrayOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1DeployedIndexResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1DeployedIndexResponseArrayOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1DeployedModelRefResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1DeployedModelRefResponseArrayOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1DeployedModelResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1DeployedModelResponseArrayOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1DiskSpecOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1DiskSpecPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1DiskSpecResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1EncryptionSpecOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1EncryptionSpecPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1EncryptionSpecResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1EnvVarOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1EnvVarArrayOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1EnvVarResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1EnvVarResponseArrayOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ExamplesOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ExamplesPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ExamplesExampleGcsSourceOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ExamplesExampleGcsSourcePtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ExamplesExampleGcsSourceResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ExamplesResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ExecutionResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ExplanationMetadataOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ExplanationMetadataPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataFeatureValueDomainResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ExplanationMetadataInputMetadataVisualizationResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ExplanationMetadataOutputMetadataResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ExplanationMetadataResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ExplanationParametersOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ExplanationParametersPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ExplanationParametersResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ExplanationSpecOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ExplanationSpecPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ExplanationSpecResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1FeatureGroupBigQueryOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1FeatureGroupBigQueryPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1FeatureGroupBigQueryResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1FeatureMonitoringStatsAnomalyResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1FeatureMonitoringStatsAnomalyResponseArrayOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1FeatureNoiseSigmaOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1FeatureNoiseSigmaPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureArrayOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1FeatureNoiseSigmaNoiseSigmaForFeatureResponseArrayOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1FeatureNoiseSigmaResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtablePtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableAutoScalingResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1FeatureOnlineStoreBigtableResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1FeatureOnlineStoreDedicatedServingEndpointResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1FeatureOnlineStoreEmbeddingManagementResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimizedOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimizedPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1FeatureOnlineStoreOptimizedResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1FeatureStatsAnomalyOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1FeatureStatsAnomalyPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1FeatureStatsAnomalyArrayOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1FeatureStatsAnomalyResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1FeatureStatsAnomalyResponseArrayOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1FeatureViewBigQuerySourceOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1FeatureViewBigQuerySourcePtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1FeatureViewBigQuerySourceResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourcePtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupArrayOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceFeatureGroupResponseArrayOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1FeatureViewFeatureRegistrySourceResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1FeatureViewSyncConfigOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1FeatureViewSyncConfigPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1FeatureViewSyncConfigResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigBruteForceConfigResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1FeatureViewVectorSearchConfigTreeAHConfigResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigImportFeaturesAnalysisResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigSnapshotAnalysisResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1FeaturestoreMonitoringConfigThresholdConfigResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1FeaturestoreOnlineServingConfigScalingResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1FilterSplitOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1FilterSplitPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1FilterSplitResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1FractionSplitOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1FractionSplitPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1FractionSplitResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1GcsDestinationOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1GcsDestinationPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1GcsDestinationResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1GcsSourceOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1GcsSourcePtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1GcsSourceResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1IndexPrivateEndpointsResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1IndexStatsResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1InputDataConfigOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1InputDataConfigPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1InputDataConfigResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1IntegratedGradientsAttributionOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1IntegratedGradientsAttributionPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1IntegratedGradientsAttributionResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1MachineSpecOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1MachineSpecPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1MachineSpecResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ManualBatchTuningParametersOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ManualBatchTuningParametersPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ManualBatchTuningParametersResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1MeasurementMetricResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1MeasurementMetricResponseArrayOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1MeasurementResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1MeasurementResponseArrayOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1MetadataStoreMetadataStoreStateResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ModelOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ModelPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ModelContainerSpecOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ModelContainerSpecPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ModelContainerSpecResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringBigQueryTableResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringBigQueryTableResponseArrayOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringJobLatestMonitoringPipelineMetadataResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigArrayOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigResponseArrayOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringScheduleConfigOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringScheduleConfigResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ModelExportFormatResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ModelExportFormatResponseArrayOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigEmailAlertConfigResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ModelMonitoringConfigOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ModelMonitoringConfigPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ModelMonitoringConfigResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigArrayOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigExplanationConfigResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigResponseArrayOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingDatasetResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesArrayOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesArrayOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesFeatureHistoricStatsAnomaliesResponseArrayOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ModelMonitoringStatsAnomaliesResponseArrayOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ModelOriginalModelInfoResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ModelResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ModelSourceInfoResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1NasJobOutputMultiTrialJobOutputResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1NasJobOutputResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1NasJobSpecOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecMetricSpecResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1NasJobSpecResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1NasTrialResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1NasTrialResponseArrayOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1NetworkSpecOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1NetworkSpecPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1NetworkSpecResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1NfsMountOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1NfsMountArrayOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1NfsMountResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1NfsMountResponseArrayOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1NotebookEucConfigOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1NotebookEucConfigPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1NotebookEucConfigResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1NotebookIdleShutdownConfigResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1PersistentDiskSpecOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1PersistentDiskSpecPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1PersistentDiskSpecResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1PipelineJobOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1PipelineJobPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1PipelineJobDetailResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1PipelineJobResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigInputArtifactResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1PipelineJobRuntimeConfigResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1PipelineTaskDetailArtifactListResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1PipelineTaskDetailPipelineTaskStatusResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1PipelineTaskDetailPipelineTaskStatusResponseArrayOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1PipelineTaskDetailResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1PipelineTaskDetailResponseArrayOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1PipelineTaskExecutorDetailContainerDetailResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1PipelineTaskExecutorDetailCustomJobDetailResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1PipelineTaskExecutorDetailResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1PipelineTemplateMetadataResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1PortOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1PortArrayOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1PortResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1PortResponseArrayOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1PredefinedSplitOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1PredefinedSplitPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1PredefinedSplitResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1PredictRequestResponseLoggingConfigResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1PredictSchemataOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1PredictSchemataPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1PredictSchemataResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1PresetsOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1PresetsPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1PresetsResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1PrivateEndpointsResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1PrivateServiceConnectConfigOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1PrivateServiceConnectConfigPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1PrivateServiceConnectConfigResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ProbeOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ProbePtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ProbeExecActionOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ProbeExecActionPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ProbeExecActionResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ProbeResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1PythonPackageSpecOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1PythonPackageSpecPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1PythonPackageSpecResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1RaySpecOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1RaySpecPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1RaySpecResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ResourcePoolOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ResourcePoolArrayOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ResourcePoolAutoscalingSpecResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ResourcePoolResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ResourcePoolResponseArrayOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ResourceRuntimeResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ResourceRuntimeSpecOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ResourceRuntimeSpecPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ResourceRuntimeSpecResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ResourcesConsumedResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1SampleConfigOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1SampleConfigPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1SampleConfigResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1SampledShapleyAttributionOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1SampledShapleyAttributionPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1SampledShapleyAttributionResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1SamplingStrategyOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1SamplingStrategyPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1SamplingStrategyRandomSampleConfigResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1SamplingStrategyResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1SavedQueryOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1SavedQueryArrayOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1SavedQueryResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1SavedQueryResponseArrayOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ScheduleRunResponseResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1SchedulingOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1SchedulingPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1SchedulingResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ServiceAccountSpecOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ServiceAccountSpecPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ServiceAccountSpecResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1SmoothGradConfigOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1SmoothGradConfigPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1SmoothGradConfigResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1StratifiedSplitOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1StratifiedSplitPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1StratifiedSplitResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1StudySpecOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1StudySpecConvexAutomatedStoppingSpecResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1StudySpecConvexStopConfigOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1StudySpecConvexStopConfigPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1StudySpecConvexStopConfigResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1StudySpecDecayCurveAutomatedStoppingSpecResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1StudySpecMedianAutomatedStoppingSpecResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1StudySpecMetricSpecOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1StudySpecMetricSpecArrayOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1StudySpecMetricSpecResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1StudySpecMetricSpecResponseArrayOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1StudySpecMetricSpecSafetyMetricConfigResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1StudySpecParameterSpecOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1StudySpecParameterSpecArrayOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1StudySpecParameterSpecCategoricalValueSpecResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecArrayOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecIntValueConditionResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1StudySpecParameterSpecConditionalParameterSpecResponseArrayOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1StudySpecParameterSpecDiscreteValueSpecResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1StudySpecParameterSpecDoubleValueSpecResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1StudySpecParameterSpecIntegerValueSpecResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1StudySpecParameterSpecResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1StudySpecParameterSpecResponseArrayOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1StudySpecResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1StudySpecStudyStoppingConfigResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1StudySpecTransferLearningConfigResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1StudyTimeConstraintOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1StudyTimeConstraintPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1StudyTimeConstraintResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1TensorboardTimeSeriesMetadataResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ThresholdConfigOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ThresholdConfigPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ThresholdConfigResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1TimestampSplitOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1TimestampSplitPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1TimestampSplitResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1TrainingConfigOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1TrainingConfigPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1TrainingConfigResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1TrialParameterResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1TrialParameterResponseArrayOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1TrialResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1TrialResponseArrayOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1UnmanagedContainerModelOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1UnmanagedContainerModelPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1UnmanagedContainerModelResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ValueOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ValuePtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1ValueResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1WorkerPoolSpecOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1WorkerPoolSpecArrayOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1WorkerPoolSpecResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1WorkerPoolSpecResponseArrayOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1XraiAttributionOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1XraiAttributionPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1beta1XraiAttributionResponseOutput{})
	pulumi.RegisterOutputType(GoogleIamV1BindingOutput{})
	pulumi.RegisterOutputType(GoogleIamV1BindingArrayOutput{})
	pulumi.RegisterOutputType(GoogleIamV1BindingResponseOutput{})
	pulumi.RegisterOutputType(GoogleIamV1BindingResponseArrayOutput{})
	pulumi.RegisterOutputType(GoogleRpcStatusResponseOutput{})
	pulumi.RegisterOutputType(GoogleRpcStatusResponseArrayOutput{})
	pulumi.RegisterOutputType(GoogleTypeExprOutput{})
	pulumi.RegisterOutputType(GoogleTypeExprPtrOutput{})
	pulumi.RegisterOutputType(GoogleTypeExprResponseOutput{})
	pulumi.RegisterOutputType(GoogleTypeMoneyResponseOutput{})
}

// Code generated by the Pulumi SDK Generator DO NOT EDIT.
// *** WARNING: Do not edit by hand unless you're certain you know what you are doing! ***

package v1beta1

import (
	"context"
	"reflect"

	"github.com/pulumi/pulumi-google-native/sdk/go/google/internal"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

// Gets a ModelDeploymentMonitoringJob.
func LookupModelDeploymentMonitoringJob(ctx *pulumi.Context, args *LookupModelDeploymentMonitoringJobArgs, opts ...pulumi.InvokeOption) (*LookupModelDeploymentMonitoringJobResult, error) {
	opts = internal.PkgInvokeDefaultOpts(opts)
	var rv LookupModelDeploymentMonitoringJobResult
	err := ctx.Invoke("google-native:aiplatform/v1beta1:getModelDeploymentMonitoringJob", args, &rv, opts...)
	if err != nil {
		return nil, err
	}
	return &rv, nil
}

type LookupModelDeploymentMonitoringJobArgs struct {
	Location                       string  `pulumi:"location"`
	ModelDeploymentMonitoringJobId string  `pulumi:"modelDeploymentMonitoringJobId"`
	Project                        *string `pulumi:"project"`
}

type LookupModelDeploymentMonitoringJobResult struct {
	// YAML schema file uri describing the format of a single instance that you want Tensorflow Data Validation (TFDV) to analyze. If this field is empty, all the feature data types are inferred from predict_instance_schema_uri, meaning that TFDV will use the data in the exact format(data type) as prediction request/response. If there are any data type differences between predict instance and TFDV instance, this field can be used to override the schema. For models trained with Vertex AI, this field must be set as all the fields in predict instance formatted as string.
	AnalysisInstanceSchemaUri string `pulumi:"analysisInstanceSchemaUri"`
	// The created bigquery tables for the job under customer project. Customer could do their own query & analysis. There could be 4 log tables in maximum: 1. Training data logging predict request/response 2. Serving data logging predict request/response
	BigqueryTables []GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringBigQueryTableResponse `pulumi:"bigqueryTables"`
	// Timestamp when this ModelDeploymentMonitoringJob was created.
	CreateTime string `pulumi:"createTime"`
	// The user-defined name of the ModelDeploymentMonitoringJob. The name can be up to 128 characters long and can consist of any UTF-8 characters. Display name of a ModelDeploymentMonitoringJob.
	DisplayName string `pulumi:"displayName"`
	// If true, the scheduled monitoring pipeline logs are sent to Google Cloud Logging, including pipeline status and anomalies detected. Please note the logs incur cost, which are subject to [Cloud Logging pricing](https://cloud.google.com/logging#pricing).
	EnableMonitoringPipelineLogs bool `pulumi:"enableMonitoringPipelineLogs"`
	// Customer-managed encryption key spec for a ModelDeploymentMonitoringJob. If set, this ModelDeploymentMonitoringJob and all sub-resources of this ModelDeploymentMonitoringJob will be secured by this key.
	EncryptionSpec GoogleCloudAiplatformV1beta1EncryptionSpecResponse `pulumi:"encryptionSpec"`
	// Endpoint resource name. Format: `projects/{project}/locations/{location}/endpoints/{endpoint}`
	Endpoint string `pulumi:"endpoint"`
	// Only populated when the job's state is `JOB_STATE_FAILED` or `JOB_STATE_CANCELLED`.
	Error GoogleRpcStatusResponse `pulumi:"error"`
	// The labels with user-defined metadata to organize your ModelDeploymentMonitoringJob. Label keys and values can be no longer than 64 characters (Unicode codepoints), can only contain lowercase letters, numeric characters, underscores and dashes. International characters are allowed. See https://goo.gl/xmQnxf for more information and examples of labels.
	Labels map[string]string `pulumi:"labels"`
	// Latest triggered monitoring pipeline metadata.
	LatestMonitoringPipelineMetadata GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringJobLatestMonitoringPipelineMetadataResponse `pulumi:"latestMonitoringPipelineMetadata"`
	// The TTL of BigQuery tables in user projects which stores logs. A day is the basic unit of the TTL and we take the ceil of TTL/86400(a day). e.g. { second: 3600} indicates ttl = 1 day.
	LogTtl string `pulumi:"logTtl"`
	// Sample Strategy for logging.
	LoggingSamplingStrategy GoogleCloudAiplatformV1beta1SamplingStrategyResponse `pulumi:"loggingSamplingStrategy"`
	// The config for monitoring objectives. This is a per DeployedModel config. Each DeployedModel needs to be configured separately.
	ModelDeploymentMonitoringObjectiveConfigs []GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigResponse `pulumi:"modelDeploymentMonitoringObjectiveConfigs"`
	// Schedule config for running the monitoring job.
	ModelDeploymentMonitoringScheduleConfig GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringScheduleConfigResponse `pulumi:"modelDeploymentMonitoringScheduleConfig"`
	// Alert config for model monitoring.
	ModelMonitoringAlertConfig GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigResponse `pulumi:"modelMonitoringAlertConfig"`
	// Resource name of a ModelDeploymentMonitoringJob.
	Name string `pulumi:"name"`
	// Timestamp when this monitoring pipeline will be scheduled to run for the next round.
	NextScheduleTime string `pulumi:"nextScheduleTime"`
	// YAML schema file uri describing the format of a single instance, which are given to format this Endpoint's prediction (and explanation). If not set, we will generate predict schema from collected predict requests.
	PredictInstanceSchemaUri string `pulumi:"predictInstanceSchemaUri"`
	// Sample Predict instance, same format as PredictRequest.instances, this can be set as a replacement of ModelDeploymentMonitoringJob.predict_instance_schema_uri. If not set, we will generate predict schema from collected predict requests.
	SamplePredictInstance interface{} `pulumi:"samplePredictInstance"`
	// Schedule state when the monitoring job is in Running state.
	ScheduleState string `pulumi:"scheduleState"`
	// The detailed state of the monitoring job. When the job is still creating, the state will be 'PENDING'. Once the job is successfully created, the state will be 'RUNNING'. Pause the job, the state will be 'PAUSED'. Resume the job, the state will return to 'RUNNING'.
	State string `pulumi:"state"`
	// Stats anomalies base folder path.
	StatsAnomaliesBaseDirectory GoogleCloudAiplatformV1beta1GcsDestinationResponse `pulumi:"statsAnomaliesBaseDirectory"`
	// Timestamp when this ModelDeploymentMonitoringJob was updated most recently.
	UpdateTime string `pulumi:"updateTime"`
}

func LookupModelDeploymentMonitoringJobOutput(ctx *pulumi.Context, args LookupModelDeploymentMonitoringJobOutputArgs, opts ...pulumi.InvokeOption) LookupModelDeploymentMonitoringJobResultOutput {
	return pulumi.ToOutputWithContext(context.Background(), args).
		ApplyT(func(v interface{}) (LookupModelDeploymentMonitoringJobResult, error) {
			args := v.(LookupModelDeploymentMonitoringJobArgs)
			r, err := LookupModelDeploymentMonitoringJob(ctx, &args, opts...)
			var s LookupModelDeploymentMonitoringJobResult
			if r != nil {
				s = *r
			}
			return s, err
		}).(LookupModelDeploymentMonitoringJobResultOutput)
}

type LookupModelDeploymentMonitoringJobOutputArgs struct {
	Location                       pulumi.StringInput    `pulumi:"location"`
	ModelDeploymentMonitoringJobId pulumi.StringInput    `pulumi:"modelDeploymentMonitoringJobId"`
	Project                        pulumi.StringPtrInput `pulumi:"project"`
}

func (LookupModelDeploymentMonitoringJobOutputArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*LookupModelDeploymentMonitoringJobArgs)(nil)).Elem()
}

type LookupModelDeploymentMonitoringJobResultOutput struct{ *pulumi.OutputState }

func (LookupModelDeploymentMonitoringJobResultOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*LookupModelDeploymentMonitoringJobResult)(nil)).Elem()
}

func (o LookupModelDeploymentMonitoringJobResultOutput) ToLookupModelDeploymentMonitoringJobResultOutput() LookupModelDeploymentMonitoringJobResultOutput {
	return o
}

func (o LookupModelDeploymentMonitoringJobResultOutput) ToLookupModelDeploymentMonitoringJobResultOutputWithContext(ctx context.Context) LookupModelDeploymentMonitoringJobResultOutput {
	return o
}

// YAML schema file uri describing the format of a single instance that you want Tensorflow Data Validation (TFDV) to analyze. If this field is empty, all the feature data types are inferred from predict_instance_schema_uri, meaning that TFDV will use the data in the exact format(data type) as prediction request/response. If there are any data type differences between predict instance and TFDV instance, this field can be used to override the schema. For models trained with Vertex AI, this field must be set as all the fields in predict instance formatted as string.
func (o LookupModelDeploymentMonitoringJobResultOutput) AnalysisInstanceSchemaUri() pulumi.StringOutput {
	return o.ApplyT(func(v LookupModelDeploymentMonitoringJobResult) string { return v.AnalysisInstanceSchemaUri }).(pulumi.StringOutput)
}

// The created bigquery tables for the job under customer project. Customer could do their own query & analysis. There could be 4 log tables in maximum: 1. Training data logging predict request/response 2. Serving data logging predict request/response
func (o LookupModelDeploymentMonitoringJobResultOutput) BigqueryTables() GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringBigQueryTableResponseArrayOutput {
	return o.ApplyT(func(v LookupModelDeploymentMonitoringJobResult) []GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringBigQueryTableResponse {
		return v.BigqueryTables
	}).(GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringBigQueryTableResponseArrayOutput)
}

// Timestamp when this ModelDeploymentMonitoringJob was created.
func (o LookupModelDeploymentMonitoringJobResultOutput) CreateTime() pulumi.StringOutput {
	return o.ApplyT(func(v LookupModelDeploymentMonitoringJobResult) string { return v.CreateTime }).(pulumi.StringOutput)
}

// The user-defined name of the ModelDeploymentMonitoringJob. The name can be up to 128 characters long and can consist of any UTF-8 characters. Display name of a ModelDeploymentMonitoringJob.
func (o LookupModelDeploymentMonitoringJobResultOutput) DisplayName() pulumi.StringOutput {
	return o.ApplyT(func(v LookupModelDeploymentMonitoringJobResult) string { return v.DisplayName }).(pulumi.StringOutput)
}

// If true, the scheduled monitoring pipeline logs are sent to Google Cloud Logging, including pipeline status and anomalies detected. Please note the logs incur cost, which are subject to [Cloud Logging pricing](https://cloud.google.com/logging#pricing).
func (o LookupModelDeploymentMonitoringJobResultOutput) EnableMonitoringPipelineLogs() pulumi.BoolOutput {
	return o.ApplyT(func(v LookupModelDeploymentMonitoringJobResult) bool { return v.EnableMonitoringPipelineLogs }).(pulumi.BoolOutput)
}

// Customer-managed encryption key spec for a ModelDeploymentMonitoringJob. If set, this ModelDeploymentMonitoringJob and all sub-resources of this ModelDeploymentMonitoringJob will be secured by this key.
func (o LookupModelDeploymentMonitoringJobResultOutput) EncryptionSpec() GoogleCloudAiplatformV1beta1EncryptionSpecResponseOutput {
	return o.ApplyT(func(v LookupModelDeploymentMonitoringJobResult) GoogleCloudAiplatformV1beta1EncryptionSpecResponse {
		return v.EncryptionSpec
	}).(GoogleCloudAiplatformV1beta1EncryptionSpecResponseOutput)
}

// Endpoint resource name. Format: `projects/{project}/locations/{location}/endpoints/{endpoint}`
func (o LookupModelDeploymentMonitoringJobResultOutput) Endpoint() pulumi.StringOutput {
	return o.ApplyT(func(v LookupModelDeploymentMonitoringJobResult) string { return v.Endpoint }).(pulumi.StringOutput)
}

// Only populated when the job's state is `JOB_STATE_FAILED` or `JOB_STATE_CANCELLED`.
func (o LookupModelDeploymentMonitoringJobResultOutput) Error() GoogleRpcStatusResponseOutput {
	return o.ApplyT(func(v LookupModelDeploymentMonitoringJobResult) GoogleRpcStatusResponse { return v.Error }).(GoogleRpcStatusResponseOutput)
}

// The labels with user-defined metadata to organize your ModelDeploymentMonitoringJob. Label keys and values can be no longer than 64 characters (Unicode codepoints), can only contain lowercase letters, numeric characters, underscores and dashes. International characters are allowed. See https://goo.gl/xmQnxf for more information and examples of labels.
func (o LookupModelDeploymentMonitoringJobResultOutput) Labels() pulumi.StringMapOutput {
	return o.ApplyT(func(v LookupModelDeploymentMonitoringJobResult) map[string]string { return v.Labels }).(pulumi.StringMapOutput)
}

// Latest triggered monitoring pipeline metadata.
func (o LookupModelDeploymentMonitoringJobResultOutput) LatestMonitoringPipelineMetadata() GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringJobLatestMonitoringPipelineMetadataResponseOutput {
	return o.ApplyT(func(v LookupModelDeploymentMonitoringJobResult) GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringJobLatestMonitoringPipelineMetadataResponse {
		return v.LatestMonitoringPipelineMetadata
	}).(GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringJobLatestMonitoringPipelineMetadataResponseOutput)
}

// The TTL of BigQuery tables in user projects which stores logs. A day is the basic unit of the TTL and we take the ceil of TTL/86400(a day). e.g. { second: 3600} indicates ttl = 1 day.
func (o LookupModelDeploymentMonitoringJobResultOutput) LogTtl() pulumi.StringOutput {
	return o.ApplyT(func(v LookupModelDeploymentMonitoringJobResult) string { return v.LogTtl }).(pulumi.StringOutput)
}

// Sample Strategy for logging.
func (o LookupModelDeploymentMonitoringJobResultOutput) LoggingSamplingStrategy() GoogleCloudAiplatformV1beta1SamplingStrategyResponseOutput {
	return o.ApplyT(func(v LookupModelDeploymentMonitoringJobResult) GoogleCloudAiplatformV1beta1SamplingStrategyResponse {
		return v.LoggingSamplingStrategy
	}).(GoogleCloudAiplatformV1beta1SamplingStrategyResponseOutput)
}

// The config for monitoring objectives. This is a per DeployedModel config. Each DeployedModel needs to be configured separately.
func (o LookupModelDeploymentMonitoringJobResultOutput) ModelDeploymentMonitoringObjectiveConfigs() GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigResponseArrayOutput {
	return o.ApplyT(func(v LookupModelDeploymentMonitoringJobResult) []GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigResponse {
		return v.ModelDeploymentMonitoringObjectiveConfigs
	}).(GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringObjectiveConfigResponseArrayOutput)
}

// Schedule config for running the monitoring job.
func (o LookupModelDeploymentMonitoringJobResultOutput) ModelDeploymentMonitoringScheduleConfig() GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringScheduleConfigResponseOutput {
	return o.ApplyT(func(v LookupModelDeploymentMonitoringJobResult) GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringScheduleConfigResponse {
		return v.ModelDeploymentMonitoringScheduleConfig
	}).(GoogleCloudAiplatformV1beta1ModelDeploymentMonitoringScheduleConfigResponseOutput)
}

// Alert config for model monitoring.
func (o LookupModelDeploymentMonitoringJobResultOutput) ModelMonitoringAlertConfig() GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigResponseOutput {
	return o.ApplyT(func(v LookupModelDeploymentMonitoringJobResult) GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigResponse {
		return v.ModelMonitoringAlertConfig
	}).(GoogleCloudAiplatformV1beta1ModelMonitoringAlertConfigResponseOutput)
}

// Resource name of a ModelDeploymentMonitoringJob.
func (o LookupModelDeploymentMonitoringJobResultOutput) Name() pulumi.StringOutput {
	return o.ApplyT(func(v LookupModelDeploymentMonitoringJobResult) string { return v.Name }).(pulumi.StringOutput)
}

// Timestamp when this monitoring pipeline will be scheduled to run for the next round.
func (o LookupModelDeploymentMonitoringJobResultOutput) NextScheduleTime() pulumi.StringOutput {
	return o.ApplyT(func(v LookupModelDeploymentMonitoringJobResult) string { return v.NextScheduleTime }).(pulumi.StringOutput)
}

// YAML schema file uri describing the format of a single instance, which are given to format this Endpoint's prediction (and explanation). If not set, we will generate predict schema from collected predict requests.
func (o LookupModelDeploymentMonitoringJobResultOutput) PredictInstanceSchemaUri() pulumi.StringOutput {
	return o.ApplyT(func(v LookupModelDeploymentMonitoringJobResult) string { return v.PredictInstanceSchemaUri }).(pulumi.StringOutput)
}

// Sample Predict instance, same format as PredictRequest.instances, this can be set as a replacement of ModelDeploymentMonitoringJob.predict_instance_schema_uri. If not set, we will generate predict schema from collected predict requests.
func (o LookupModelDeploymentMonitoringJobResultOutput) SamplePredictInstance() pulumi.AnyOutput {
	return o.ApplyT(func(v LookupModelDeploymentMonitoringJobResult) interface{} { return v.SamplePredictInstance }).(pulumi.AnyOutput)
}

// Schedule state when the monitoring job is in Running state.
func (o LookupModelDeploymentMonitoringJobResultOutput) ScheduleState() pulumi.StringOutput {
	return o.ApplyT(func(v LookupModelDeploymentMonitoringJobResult) string { return v.ScheduleState }).(pulumi.StringOutput)
}

// The detailed state of the monitoring job. When the job is still creating, the state will be 'PENDING'. Once the job is successfully created, the state will be 'RUNNING'. Pause the job, the state will be 'PAUSED'. Resume the job, the state will return to 'RUNNING'.
func (o LookupModelDeploymentMonitoringJobResultOutput) State() pulumi.StringOutput {
	return o.ApplyT(func(v LookupModelDeploymentMonitoringJobResult) string { return v.State }).(pulumi.StringOutput)
}

// Stats anomalies base folder path.
func (o LookupModelDeploymentMonitoringJobResultOutput) StatsAnomaliesBaseDirectory() GoogleCloudAiplatformV1beta1GcsDestinationResponseOutput {
	return o.ApplyT(func(v LookupModelDeploymentMonitoringJobResult) GoogleCloudAiplatformV1beta1GcsDestinationResponse {
		return v.StatsAnomaliesBaseDirectory
	}).(GoogleCloudAiplatformV1beta1GcsDestinationResponseOutput)
}

// Timestamp when this ModelDeploymentMonitoringJob was updated most recently.
func (o LookupModelDeploymentMonitoringJobResultOutput) UpdateTime() pulumi.StringOutput {
	return o.ApplyT(func(v LookupModelDeploymentMonitoringJobResult) string { return v.UpdateTime }).(pulumi.StringOutput)
}

func init() {
	pulumi.RegisterOutputType(LookupModelDeploymentMonitoringJobResultOutput{})
}

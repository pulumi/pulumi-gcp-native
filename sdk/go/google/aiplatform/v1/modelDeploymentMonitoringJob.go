// Code generated by the Pulumi SDK Generator DO NOT EDIT.
// *** WARNING: Do not edit by hand unless you're certain you know what you are doing! ***

package v1

import (
	"context"
	"reflect"

	"errors"
	"github.com/pulumi/pulumi-google-native/sdk/go/google/internal"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

// Creates a ModelDeploymentMonitoringJob. It will run periodically on a configured interval.
// Auto-naming is currently not supported for this resource.
type ModelDeploymentMonitoringJob struct {
	pulumi.CustomResourceState

	// YAML schema file uri describing the format of a single instance that you want Tensorflow Data Validation (TFDV) to analyze. If this field is empty, all the feature data types are inferred from predict_instance_schema_uri, meaning that TFDV will use the data in the exact format(data type) as prediction request/response. If there are any data type differences between predict instance and TFDV instance, this field can be used to override the schema. For models trained with Vertex AI, this field must be set as all the fields in predict instance formatted as string.
	AnalysisInstanceSchemaUri pulumi.StringOutput `pulumi:"analysisInstanceSchemaUri"`
	// The created bigquery tables for the job under customer project. Customer could do their own query & analysis. There could be 4 log tables in maximum: 1. Training data logging predict request/response 2. Serving data logging predict request/response
	BigqueryTables GoogleCloudAiplatformV1ModelDeploymentMonitoringBigQueryTableResponseArrayOutput `pulumi:"bigqueryTables"`
	// Timestamp when this ModelDeploymentMonitoringJob was created.
	CreateTime pulumi.StringOutput `pulumi:"createTime"`
	// The user-defined name of the ModelDeploymentMonitoringJob. The name can be up to 128 characters long and can consist of any UTF-8 characters. Display name of a ModelDeploymentMonitoringJob.
	DisplayName pulumi.StringOutput `pulumi:"displayName"`
	// If true, the scheduled monitoring pipeline logs are sent to Google Cloud Logging, including pipeline status and anomalies detected. Please note the logs incur cost, which are subject to [Cloud Logging pricing](https://cloud.google.com/logging#pricing).
	EnableMonitoringPipelineLogs pulumi.BoolOutput `pulumi:"enableMonitoringPipelineLogs"`
	// Customer-managed encryption key spec for a ModelDeploymentMonitoringJob. If set, this ModelDeploymentMonitoringJob and all sub-resources of this ModelDeploymentMonitoringJob will be secured by this key.
	EncryptionSpec GoogleCloudAiplatformV1EncryptionSpecResponseOutput `pulumi:"encryptionSpec"`
	// Endpoint resource name. Format: `projects/{project}/locations/{location}/endpoints/{endpoint}`
	Endpoint pulumi.StringOutput `pulumi:"endpoint"`
	// Only populated when the job's state is `JOB_STATE_FAILED` or `JOB_STATE_CANCELLED`.
	Error GoogleRpcStatusResponseOutput `pulumi:"error"`
	// The labels with user-defined metadata to organize your ModelDeploymentMonitoringJob. Label keys and values can be no longer than 64 characters (Unicode codepoints), can only contain lowercase letters, numeric characters, underscores and dashes. International characters are allowed. See https://goo.gl/xmQnxf for more information and examples of labels.
	Labels pulumi.StringMapOutput `pulumi:"labels"`
	// Latest triggered monitoring pipeline metadata.
	LatestMonitoringPipelineMetadata GoogleCloudAiplatformV1ModelDeploymentMonitoringJobLatestMonitoringPipelineMetadataResponseOutput `pulumi:"latestMonitoringPipelineMetadata"`
	Location                         pulumi.StringOutput                                                                               `pulumi:"location"`
	// The TTL of BigQuery tables in user projects which stores logs. A day is the basic unit of the TTL and we take the ceil of TTL/86400(a day). e.g. { second: 3600} indicates ttl = 1 day.
	LogTtl pulumi.StringOutput `pulumi:"logTtl"`
	// Sample Strategy for logging.
	LoggingSamplingStrategy GoogleCloudAiplatformV1SamplingStrategyResponseOutput `pulumi:"loggingSamplingStrategy"`
	// The config for monitoring objectives. This is a per DeployedModel config. Each DeployedModel needs to be configured separately.
	ModelDeploymentMonitoringObjectiveConfigs GoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigResponseArrayOutput `pulumi:"modelDeploymentMonitoringObjectiveConfigs"`
	// Schedule config for running the monitoring job.
	ModelDeploymentMonitoringScheduleConfig GoogleCloudAiplatformV1ModelDeploymentMonitoringScheduleConfigResponseOutput `pulumi:"modelDeploymentMonitoringScheduleConfig"`
	// Alert config for model monitoring.
	ModelMonitoringAlertConfig GoogleCloudAiplatformV1ModelMonitoringAlertConfigResponseOutput `pulumi:"modelMonitoringAlertConfig"`
	// Resource name of a ModelDeploymentMonitoringJob.
	Name pulumi.StringOutput `pulumi:"name"`
	// Timestamp when this monitoring pipeline will be scheduled to run for the next round.
	NextScheduleTime pulumi.StringOutput `pulumi:"nextScheduleTime"`
	// YAML schema file uri describing the format of a single instance, which are given to format this Endpoint's prediction (and explanation). If not set, we will generate predict schema from collected predict requests.
	PredictInstanceSchemaUri pulumi.StringOutput `pulumi:"predictInstanceSchemaUri"`
	Project                  pulumi.StringOutput `pulumi:"project"`
	// Sample Predict instance, same format as PredictRequest.instances, this can be set as a replacement of ModelDeploymentMonitoringJob.predict_instance_schema_uri. If not set, we will generate predict schema from collected predict requests.
	SamplePredictInstance pulumi.AnyOutput `pulumi:"samplePredictInstance"`
	// Schedule state when the monitoring job is in Running state.
	ScheduleState pulumi.StringOutput `pulumi:"scheduleState"`
	// The detailed state of the monitoring job. When the job is still creating, the state will be 'PENDING'. Once the job is successfully created, the state will be 'RUNNING'. Pause the job, the state will be 'PAUSED'. Resume the job, the state will return to 'RUNNING'.
	State pulumi.StringOutput `pulumi:"state"`
	// Stats anomalies base folder path.
	StatsAnomaliesBaseDirectory GoogleCloudAiplatformV1GcsDestinationResponseOutput `pulumi:"statsAnomaliesBaseDirectory"`
	// Timestamp when this ModelDeploymentMonitoringJob was updated most recently.
	UpdateTime pulumi.StringOutput `pulumi:"updateTime"`
}

// NewModelDeploymentMonitoringJob registers a new resource with the given unique name, arguments, and options.
func NewModelDeploymentMonitoringJob(ctx *pulumi.Context,
	name string, args *ModelDeploymentMonitoringJobArgs, opts ...pulumi.ResourceOption) (*ModelDeploymentMonitoringJob, error) {
	if args == nil {
		return nil, errors.New("missing one or more required arguments")
	}

	if args.DisplayName == nil {
		return nil, errors.New("invalid value for required argument 'DisplayName'")
	}
	if args.Endpoint == nil {
		return nil, errors.New("invalid value for required argument 'Endpoint'")
	}
	if args.LoggingSamplingStrategy == nil {
		return nil, errors.New("invalid value for required argument 'LoggingSamplingStrategy'")
	}
	if args.ModelDeploymentMonitoringObjectiveConfigs == nil {
		return nil, errors.New("invalid value for required argument 'ModelDeploymentMonitoringObjectiveConfigs'")
	}
	if args.ModelDeploymentMonitoringScheduleConfig == nil {
		return nil, errors.New("invalid value for required argument 'ModelDeploymentMonitoringScheduleConfig'")
	}
	replaceOnChanges := pulumi.ReplaceOnChanges([]string{
		"location",
		"project",
	})
	opts = append(opts, replaceOnChanges)
	opts = internal.PkgResourceDefaultOpts(opts)
	var resource ModelDeploymentMonitoringJob
	err := ctx.RegisterResource("google-native:aiplatform/v1:ModelDeploymentMonitoringJob", name, args, &resource, opts...)
	if err != nil {
		return nil, err
	}
	return &resource, nil
}

// GetModelDeploymentMonitoringJob gets an existing ModelDeploymentMonitoringJob resource's state with the given name, ID, and optional
// state properties that are used to uniquely qualify the lookup (nil if not required).
func GetModelDeploymentMonitoringJob(ctx *pulumi.Context,
	name string, id pulumi.IDInput, state *ModelDeploymentMonitoringJobState, opts ...pulumi.ResourceOption) (*ModelDeploymentMonitoringJob, error) {
	var resource ModelDeploymentMonitoringJob
	err := ctx.ReadResource("google-native:aiplatform/v1:ModelDeploymentMonitoringJob", name, id, state, &resource, opts...)
	if err != nil {
		return nil, err
	}
	return &resource, nil
}

// Input properties used for looking up and filtering ModelDeploymentMonitoringJob resources.
type modelDeploymentMonitoringJobState struct {
}

type ModelDeploymentMonitoringJobState struct {
}

func (ModelDeploymentMonitoringJobState) ElementType() reflect.Type {
	return reflect.TypeOf((*modelDeploymentMonitoringJobState)(nil)).Elem()
}

type modelDeploymentMonitoringJobArgs struct {
	// YAML schema file uri describing the format of a single instance that you want Tensorflow Data Validation (TFDV) to analyze. If this field is empty, all the feature data types are inferred from predict_instance_schema_uri, meaning that TFDV will use the data in the exact format(data type) as prediction request/response. If there are any data type differences between predict instance and TFDV instance, this field can be used to override the schema. For models trained with Vertex AI, this field must be set as all the fields in predict instance formatted as string.
	AnalysisInstanceSchemaUri *string `pulumi:"analysisInstanceSchemaUri"`
	// The user-defined name of the ModelDeploymentMonitoringJob. The name can be up to 128 characters long and can consist of any UTF-8 characters. Display name of a ModelDeploymentMonitoringJob.
	DisplayName string `pulumi:"displayName"`
	// If true, the scheduled monitoring pipeline logs are sent to Google Cloud Logging, including pipeline status and anomalies detected. Please note the logs incur cost, which are subject to [Cloud Logging pricing](https://cloud.google.com/logging#pricing).
	EnableMonitoringPipelineLogs *bool `pulumi:"enableMonitoringPipelineLogs"`
	// Customer-managed encryption key spec for a ModelDeploymentMonitoringJob. If set, this ModelDeploymentMonitoringJob and all sub-resources of this ModelDeploymentMonitoringJob will be secured by this key.
	EncryptionSpec *GoogleCloudAiplatformV1EncryptionSpec `pulumi:"encryptionSpec"`
	// Endpoint resource name. Format: `projects/{project}/locations/{location}/endpoints/{endpoint}`
	Endpoint string `pulumi:"endpoint"`
	// The labels with user-defined metadata to organize your ModelDeploymentMonitoringJob. Label keys and values can be no longer than 64 characters (Unicode codepoints), can only contain lowercase letters, numeric characters, underscores and dashes. International characters are allowed. See https://goo.gl/xmQnxf for more information and examples of labels.
	Labels   map[string]string `pulumi:"labels"`
	Location *string           `pulumi:"location"`
	// The TTL of BigQuery tables in user projects which stores logs. A day is the basic unit of the TTL and we take the ceil of TTL/86400(a day). e.g. { second: 3600} indicates ttl = 1 day.
	LogTtl *string `pulumi:"logTtl"`
	// Sample Strategy for logging.
	LoggingSamplingStrategy GoogleCloudAiplatformV1SamplingStrategy `pulumi:"loggingSamplingStrategy"`
	// The config for monitoring objectives. This is a per DeployedModel config. Each DeployedModel needs to be configured separately.
	ModelDeploymentMonitoringObjectiveConfigs []GoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfig `pulumi:"modelDeploymentMonitoringObjectiveConfigs"`
	// Schedule config for running the monitoring job.
	ModelDeploymentMonitoringScheduleConfig GoogleCloudAiplatformV1ModelDeploymentMonitoringScheduleConfig `pulumi:"modelDeploymentMonitoringScheduleConfig"`
	// Alert config for model monitoring.
	ModelMonitoringAlertConfig *GoogleCloudAiplatformV1ModelMonitoringAlertConfig `pulumi:"modelMonitoringAlertConfig"`
	// YAML schema file uri describing the format of a single instance, which are given to format this Endpoint's prediction (and explanation). If not set, we will generate predict schema from collected predict requests.
	PredictInstanceSchemaUri *string `pulumi:"predictInstanceSchemaUri"`
	Project                  *string `pulumi:"project"`
	// Sample Predict instance, same format as PredictRequest.instances, this can be set as a replacement of ModelDeploymentMonitoringJob.predict_instance_schema_uri. If not set, we will generate predict schema from collected predict requests.
	SamplePredictInstance interface{} `pulumi:"samplePredictInstance"`
	// Stats anomalies base folder path.
	StatsAnomaliesBaseDirectory *GoogleCloudAiplatformV1GcsDestination `pulumi:"statsAnomaliesBaseDirectory"`
}

// The set of arguments for constructing a ModelDeploymentMonitoringJob resource.
type ModelDeploymentMonitoringJobArgs struct {
	// YAML schema file uri describing the format of a single instance that you want Tensorflow Data Validation (TFDV) to analyze. If this field is empty, all the feature data types are inferred from predict_instance_schema_uri, meaning that TFDV will use the data in the exact format(data type) as prediction request/response. If there are any data type differences between predict instance and TFDV instance, this field can be used to override the schema. For models trained with Vertex AI, this field must be set as all the fields in predict instance formatted as string.
	AnalysisInstanceSchemaUri pulumi.StringPtrInput
	// The user-defined name of the ModelDeploymentMonitoringJob. The name can be up to 128 characters long and can consist of any UTF-8 characters. Display name of a ModelDeploymentMonitoringJob.
	DisplayName pulumi.StringInput
	// If true, the scheduled monitoring pipeline logs are sent to Google Cloud Logging, including pipeline status and anomalies detected. Please note the logs incur cost, which are subject to [Cloud Logging pricing](https://cloud.google.com/logging#pricing).
	EnableMonitoringPipelineLogs pulumi.BoolPtrInput
	// Customer-managed encryption key spec for a ModelDeploymentMonitoringJob. If set, this ModelDeploymentMonitoringJob and all sub-resources of this ModelDeploymentMonitoringJob will be secured by this key.
	EncryptionSpec GoogleCloudAiplatformV1EncryptionSpecPtrInput
	// Endpoint resource name. Format: `projects/{project}/locations/{location}/endpoints/{endpoint}`
	Endpoint pulumi.StringInput
	// The labels with user-defined metadata to organize your ModelDeploymentMonitoringJob. Label keys and values can be no longer than 64 characters (Unicode codepoints), can only contain lowercase letters, numeric characters, underscores and dashes. International characters are allowed. See https://goo.gl/xmQnxf for more information and examples of labels.
	Labels   pulumi.StringMapInput
	Location pulumi.StringPtrInput
	// The TTL of BigQuery tables in user projects which stores logs. A day is the basic unit of the TTL and we take the ceil of TTL/86400(a day). e.g. { second: 3600} indicates ttl = 1 day.
	LogTtl pulumi.StringPtrInput
	// Sample Strategy for logging.
	LoggingSamplingStrategy GoogleCloudAiplatformV1SamplingStrategyInput
	// The config for monitoring objectives. This is a per DeployedModel config. Each DeployedModel needs to be configured separately.
	ModelDeploymentMonitoringObjectiveConfigs GoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigArrayInput
	// Schedule config for running the monitoring job.
	ModelDeploymentMonitoringScheduleConfig GoogleCloudAiplatformV1ModelDeploymentMonitoringScheduleConfigInput
	// Alert config for model monitoring.
	ModelMonitoringAlertConfig GoogleCloudAiplatformV1ModelMonitoringAlertConfigPtrInput
	// YAML schema file uri describing the format of a single instance, which are given to format this Endpoint's prediction (and explanation). If not set, we will generate predict schema from collected predict requests.
	PredictInstanceSchemaUri pulumi.StringPtrInput
	Project                  pulumi.StringPtrInput
	// Sample Predict instance, same format as PredictRequest.instances, this can be set as a replacement of ModelDeploymentMonitoringJob.predict_instance_schema_uri. If not set, we will generate predict schema from collected predict requests.
	SamplePredictInstance pulumi.Input
	// Stats anomalies base folder path.
	StatsAnomaliesBaseDirectory GoogleCloudAiplatformV1GcsDestinationPtrInput
}

func (ModelDeploymentMonitoringJobArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*modelDeploymentMonitoringJobArgs)(nil)).Elem()
}

type ModelDeploymentMonitoringJobInput interface {
	pulumi.Input

	ToModelDeploymentMonitoringJobOutput() ModelDeploymentMonitoringJobOutput
	ToModelDeploymentMonitoringJobOutputWithContext(ctx context.Context) ModelDeploymentMonitoringJobOutput
}

func (*ModelDeploymentMonitoringJob) ElementType() reflect.Type {
	return reflect.TypeOf((**ModelDeploymentMonitoringJob)(nil)).Elem()
}

func (i *ModelDeploymentMonitoringJob) ToModelDeploymentMonitoringJobOutput() ModelDeploymentMonitoringJobOutput {
	return i.ToModelDeploymentMonitoringJobOutputWithContext(context.Background())
}

func (i *ModelDeploymentMonitoringJob) ToModelDeploymentMonitoringJobOutputWithContext(ctx context.Context) ModelDeploymentMonitoringJobOutput {
	return pulumi.ToOutputWithContext(ctx, i).(ModelDeploymentMonitoringJobOutput)
}

type ModelDeploymentMonitoringJobOutput struct{ *pulumi.OutputState }

func (ModelDeploymentMonitoringJobOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**ModelDeploymentMonitoringJob)(nil)).Elem()
}

func (o ModelDeploymentMonitoringJobOutput) ToModelDeploymentMonitoringJobOutput() ModelDeploymentMonitoringJobOutput {
	return o
}

func (o ModelDeploymentMonitoringJobOutput) ToModelDeploymentMonitoringJobOutputWithContext(ctx context.Context) ModelDeploymentMonitoringJobOutput {
	return o
}

// YAML schema file uri describing the format of a single instance that you want Tensorflow Data Validation (TFDV) to analyze. If this field is empty, all the feature data types are inferred from predict_instance_schema_uri, meaning that TFDV will use the data in the exact format(data type) as prediction request/response. If there are any data type differences between predict instance and TFDV instance, this field can be used to override the schema. For models trained with Vertex AI, this field must be set as all the fields in predict instance formatted as string.
func (o ModelDeploymentMonitoringJobOutput) AnalysisInstanceSchemaUri() pulumi.StringOutput {
	return o.ApplyT(func(v *ModelDeploymentMonitoringJob) pulumi.StringOutput { return v.AnalysisInstanceSchemaUri }).(pulumi.StringOutput)
}

// The created bigquery tables for the job under customer project. Customer could do their own query & analysis. There could be 4 log tables in maximum: 1. Training data logging predict request/response 2. Serving data logging predict request/response
func (o ModelDeploymentMonitoringJobOutput) BigqueryTables() GoogleCloudAiplatformV1ModelDeploymentMonitoringBigQueryTableResponseArrayOutput {
	return o.ApplyT(func(v *ModelDeploymentMonitoringJob) GoogleCloudAiplatformV1ModelDeploymentMonitoringBigQueryTableResponseArrayOutput {
		return v.BigqueryTables
	}).(GoogleCloudAiplatformV1ModelDeploymentMonitoringBigQueryTableResponseArrayOutput)
}

// Timestamp when this ModelDeploymentMonitoringJob was created.
func (o ModelDeploymentMonitoringJobOutput) CreateTime() pulumi.StringOutput {
	return o.ApplyT(func(v *ModelDeploymentMonitoringJob) pulumi.StringOutput { return v.CreateTime }).(pulumi.StringOutput)
}

// The user-defined name of the ModelDeploymentMonitoringJob. The name can be up to 128 characters long and can consist of any UTF-8 characters. Display name of a ModelDeploymentMonitoringJob.
func (o ModelDeploymentMonitoringJobOutput) DisplayName() pulumi.StringOutput {
	return o.ApplyT(func(v *ModelDeploymentMonitoringJob) pulumi.StringOutput { return v.DisplayName }).(pulumi.StringOutput)
}

// If true, the scheduled monitoring pipeline logs are sent to Google Cloud Logging, including pipeline status and anomalies detected. Please note the logs incur cost, which are subject to [Cloud Logging pricing](https://cloud.google.com/logging#pricing).
func (o ModelDeploymentMonitoringJobOutput) EnableMonitoringPipelineLogs() pulumi.BoolOutput {
	return o.ApplyT(func(v *ModelDeploymentMonitoringJob) pulumi.BoolOutput { return v.EnableMonitoringPipelineLogs }).(pulumi.BoolOutput)
}

// Customer-managed encryption key spec for a ModelDeploymentMonitoringJob. If set, this ModelDeploymentMonitoringJob and all sub-resources of this ModelDeploymentMonitoringJob will be secured by this key.
func (o ModelDeploymentMonitoringJobOutput) EncryptionSpec() GoogleCloudAiplatformV1EncryptionSpecResponseOutput {
	return o.ApplyT(func(v *ModelDeploymentMonitoringJob) GoogleCloudAiplatformV1EncryptionSpecResponseOutput {
		return v.EncryptionSpec
	}).(GoogleCloudAiplatformV1EncryptionSpecResponseOutput)
}

// Endpoint resource name. Format: `projects/{project}/locations/{location}/endpoints/{endpoint}`
func (o ModelDeploymentMonitoringJobOutput) Endpoint() pulumi.StringOutput {
	return o.ApplyT(func(v *ModelDeploymentMonitoringJob) pulumi.StringOutput { return v.Endpoint }).(pulumi.StringOutput)
}

// Only populated when the job's state is `JOB_STATE_FAILED` or `JOB_STATE_CANCELLED`.
func (o ModelDeploymentMonitoringJobOutput) Error() GoogleRpcStatusResponseOutput {
	return o.ApplyT(func(v *ModelDeploymentMonitoringJob) GoogleRpcStatusResponseOutput { return v.Error }).(GoogleRpcStatusResponseOutput)
}

// The labels with user-defined metadata to organize your ModelDeploymentMonitoringJob. Label keys and values can be no longer than 64 characters (Unicode codepoints), can only contain lowercase letters, numeric characters, underscores and dashes. International characters are allowed. See https://goo.gl/xmQnxf for more information and examples of labels.
func (o ModelDeploymentMonitoringJobOutput) Labels() pulumi.StringMapOutput {
	return o.ApplyT(func(v *ModelDeploymentMonitoringJob) pulumi.StringMapOutput { return v.Labels }).(pulumi.StringMapOutput)
}

// Latest triggered monitoring pipeline metadata.
func (o ModelDeploymentMonitoringJobOutput) LatestMonitoringPipelineMetadata() GoogleCloudAiplatformV1ModelDeploymentMonitoringJobLatestMonitoringPipelineMetadataResponseOutput {
	return o.ApplyT(func(v *ModelDeploymentMonitoringJob) GoogleCloudAiplatformV1ModelDeploymentMonitoringJobLatestMonitoringPipelineMetadataResponseOutput {
		return v.LatestMonitoringPipelineMetadata
	}).(GoogleCloudAiplatformV1ModelDeploymentMonitoringJobLatestMonitoringPipelineMetadataResponseOutput)
}

func (o ModelDeploymentMonitoringJobOutput) Location() pulumi.StringOutput {
	return o.ApplyT(func(v *ModelDeploymentMonitoringJob) pulumi.StringOutput { return v.Location }).(pulumi.StringOutput)
}

// The TTL of BigQuery tables in user projects which stores logs. A day is the basic unit of the TTL and we take the ceil of TTL/86400(a day). e.g. { second: 3600} indicates ttl = 1 day.
func (o ModelDeploymentMonitoringJobOutput) LogTtl() pulumi.StringOutput {
	return o.ApplyT(func(v *ModelDeploymentMonitoringJob) pulumi.StringOutput { return v.LogTtl }).(pulumi.StringOutput)
}

// Sample Strategy for logging.
func (o ModelDeploymentMonitoringJobOutput) LoggingSamplingStrategy() GoogleCloudAiplatformV1SamplingStrategyResponseOutput {
	return o.ApplyT(func(v *ModelDeploymentMonitoringJob) GoogleCloudAiplatformV1SamplingStrategyResponseOutput {
		return v.LoggingSamplingStrategy
	}).(GoogleCloudAiplatformV1SamplingStrategyResponseOutput)
}

// The config for monitoring objectives. This is a per DeployedModel config. Each DeployedModel needs to be configured separately.
func (o ModelDeploymentMonitoringJobOutput) ModelDeploymentMonitoringObjectiveConfigs() GoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigResponseArrayOutput {
	return o.ApplyT(func(v *ModelDeploymentMonitoringJob) GoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigResponseArrayOutput {
		return v.ModelDeploymentMonitoringObjectiveConfigs
	}).(GoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigResponseArrayOutput)
}

// Schedule config for running the monitoring job.
func (o ModelDeploymentMonitoringJobOutput) ModelDeploymentMonitoringScheduleConfig() GoogleCloudAiplatformV1ModelDeploymentMonitoringScheduleConfigResponseOutput {
	return o.ApplyT(func(v *ModelDeploymentMonitoringJob) GoogleCloudAiplatformV1ModelDeploymentMonitoringScheduleConfigResponseOutput {
		return v.ModelDeploymentMonitoringScheduleConfig
	}).(GoogleCloudAiplatformV1ModelDeploymentMonitoringScheduleConfigResponseOutput)
}

// Alert config for model monitoring.
func (o ModelDeploymentMonitoringJobOutput) ModelMonitoringAlertConfig() GoogleCloudAiplatformV1ModelMonitoringAlertConfigResponseOutput {
	return o.ApplyT(func(v *ModelDeploymentMonitoringJob) GoogleCloudAiplatformV1ModelMonitoringAlertConfigResponseOutput {
		return v.ModelMonitoringAlertConfig
	}).(GoogleCloudAiplatformV1ModelMonitoringAlertConfigResponseOutput)
}

// Resource name of a ModelDeploymentMonitoringJob.
func (o ModelDeploymentMonitoringJobOutput) Name() pulumi.StringOutput {
	return o.ApplyT(func(v *ModelDeploymentMonitoringJob) pulumi.StringOutput { return v.Name }).(pulumi.StringOutput)
}

// Timestamp when this monitoring pipeline will be scheduled to run for the next round.
func (o ModelDeploymentMonitoringJobOutput) NextScheduleTime() pulumi.StringOutput {
	return o.ApplyT(func(v *ModelDeploymentMonitoringJob) pulumi.StringOutput { return v.NextScheduleTime }).(pulumi.StringOutput)
}

// YAML schema file uri describing the format of a single instance, which are given to format this Endpoint's prediction (and explanation). If not set, we will generate predict schema from collected predict requests.
func (o ModelDeploymentMonitoringJobOutput) PredictInstanceSchemaUri() pulumi.StringOutput {
	return o.ApplyT(func(v *ModelDeploymentMonitoringJob) pulumi.StringOutput { return v.PredictInstanceSchemaUri }).(pulumi.StringOutput)
}

func (o ModelDeploymentMonitoringJobOutput) Project() pulumi.StringOutput {
	return o.ApplyT(func(v *ModelDeploymentMonitoringJob) pulumi.StringOutput { return v.Project }).(pulumi.StringOutput)
}

// Sample Predict instance, same format as PredictRequest.instances, this can be set as a replacement of ModelDeploymentMonitoringJob.predict_instance_schema_uri. If not set, we will generate predict schema from collected predict requests.
func (o ModelDeploymentMonitoringJobOutput) SamplePredictInstance() pulumi.AnyOutput {
	return o.ApplyT(func(v *ModelDeploymentMonitoringJob) pulumi.AnyOutput { return v.SamplePredictInstance }).(pulumi.AnyOutput)
}

// Schedule state when the monitoring job is in Running state.
func (o ModelDeploymentMonitoringJobOutput) ScheduleState() pulumi.StringOutput {
	return o.ApplyT(func(v *ModelDeploymentMonitoringJob) pulumi.StringOutput { return v.ScheduleState }).(pulumi.StringOutput)
}

// The detailed state of the monitoring job. When the job is still creating, the state will be 'PENDING'. Once the job is successfully created, the state will be 'RUNNING'. Pause the job, the state will be 'PAUSED'. Resume the job, the state will return to 'RUNNING'.
func (o ModelDeploymentMonitoringJobOutput) State() pulumi.StringOutput {
	return o.ApplyT(func(v *ModelDeploymentMonitoringJob) pulumi.StringOutput { return v.State }).(pulumi.StringOutput)
}

// Stats anomalies base folder path.
func (o ModelDeploymentMonitoringJobOutput) StatsAnomaliesBaseDirectory() GoogleCloudAiplatformV1GcsDestinationResponseOutput {
	return o.ApplyT(func(v *ModelDeploymentMonitoringJob) GoogleCloudAiplatformV1GcsDestinationResponseOutput {
		return v.StatsAnomaliesBaseDirectory
	}).(GoogleCloudAiplatformV1GcsDestinationResponseOutput)
}

// Timestamp when this ModelDeploymentMonitoringJob was updated most recently.
func (o ModelDeploymentMonitoringJobOutput) UpdateTime() pulumi.StringOutput {
	return o.ApplyT(func(v *ModelDeploymentMonitoringJob) pulumi.StringOutput { return v.UpdateTime }).(pulumi.StringOutput)
}

func init() {
	pulumi.RegisterInputType(reflect.TypeOf((*ModelDeploymentMonitoringJobInput)(nil)).Elem(), &ModelDeploymentMonitoringJob{})
	pulumi.RegisterOutputType(ModelDeploymentMonitoringJobOutput{})
}

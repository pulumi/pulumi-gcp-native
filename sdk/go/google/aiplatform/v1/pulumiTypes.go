// Code generated by the Pulumi SDK Generator DO NOT EDIT.
// *** WARNING: Do not edit by hand unless you're certain you know what you are doing! ***

package v1

import (
	"context"
	"reflect"

	"github.com/pulumi/pulumi-google-native/sdk/go/google/internal"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

var _ = internal.GetEnvOrDefault

// Parameters that configure the active learning pipeline. Active learning will label the data incrementally by several iterations. For every iteration, it will select a batch of data based on the sampling strategy.
type GoogleCloudAiplatformV1ActiveLearningConfig struct {
	// Max number of human labeled DataItems.
	MaxDataItemCount *string `pulumi:"maxDataItemCount"`
	// Max percent of total DataItems for human labeling.
	MaxDataItemPercentage *int `pulumi:"maxDataItemPercentage"`
	// Active learning data sampling config. For every active learning labeling iteration, it will select a batch of data based on the sampling strategy.
	SampleConfig *GoogleCloudAiplatformV1SampleConfig `pulumi:"sampleConfig"`
	// CMLE training config. For every active learning labeling iteration, system will train a machine learning model on CMLE. The trained model will be used by data sampling algorithm to select DataItems.
	TrainingConfig *GoogleCloudAiplatformV1TrainingConfig `pulumi:"trainingConfig"`
}

// GoogleCloudAiplatformV1ActiveLearningConfigInput is an input type that accepts GoogleCloudAiplatformV1ActiveLearningConfigArgs and GoogleCloudAiplatformV1ActiveLearningConfigOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1ActiveLearningConfigInput` via:
//
//	GoogleCloudAiplatformV1ActiveLearningConfigArgs{...}
type GoogleCloudAiplatformV1ActiveLearningConfigInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1ActiveLearningConfigOutput() GoogleCloudAiplatformV1ActiveLearningConfigOutput
	ToGoogleCloudAiplatformV1ActiveLearningConfigOutputWithContext(context.Context) GoogleCloudAiplatformV1ActiveLearningConfigOutput
}

// Parameters that configure the active learning pipeline. Active learning will label the data incrementally by several iterations. For every iteration, it will select a batch of data based on the sampling strategy.
type GoogleCloudAiplatformV1ActiveLearningConfigArgs struct {
	// Max number of human labeled DataItems.
	MaxDataItemCount pulumi.StringPtrInput `pulumi:"maxDataItemCount"`
	// Max percent of total DataItems for human labeling.
	MaxDataItemPercentage pulumi.IntPtrInput `pulumi:"maxDataItemPercentage"`
	// Active learning data sampling config. For every active learning labeling iteration, it will select a batch of data based on the sampling strategy.
	SampleConfig GoogleCloudAiplatformV1SampleConfigPtrInput `pulumi:"sampleConfig"`
	// CMLE training config. For every active learning labeling iteration, system will train a machine learning model on CMLE. The trained model will be used by data sampling algorithm to select DataItems.
	TrainingConfig GoogleCloudAiplatformV1TrainingConfigPtrInput `pulumi:"trainingConfig"`
}

func (GoogleCloudAiplatformV1ActiveLearningConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1ActiveLearningConfig)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1ActiveLearningConfigArgs) ToGoogleCloudAiplatformV1ActiveLearningConfigOutput() GoogleCloudAiplatformV1ActiveLearningConfigOutput {
	return i.ToGoogleCloudAiplatformV1ActiveLearningConfigOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1ActiveLearningConfigArgs) ToGoogleCloudAiplatformV1ActiveLearningConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ActiveLearningConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1ActiveLearningConfigOutput)
}

func (i GoogleCloudAiplatformV1ActiveLearningConfigArgs) ToGoogleCloudAiplatformV1ActiveLearningConfigPtrOutput() GoogleCloudAiplatformV1ActiveLearningConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1ActiveLearningConfigPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1ActiveLearningConfigArgs) ToGoogleCloudAiplatformV1ActiveLearningConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ActiveLearningConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1ActiveLearningConfigOutput).ToGoogleCloudAiplatformV1ActiveLearningConfigPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1ActiveLearningConfigPtrInput is an input type that accepts GoogleCloudAiplatformV1ActiveLearningConfigArgs, GoogleCloudAiplatformV1ActiveLearningConfigPtr and GoogleCloudAiplatformV1ActiveLearningConfigPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1ActiveLearningConfigPtrInput` via:
//
//	        GoogleCloudAiplatformV1ActiveLearningConfigArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1ActiveLearningConfigPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1ActiveLearningConfigPtrOutput() GoogleCloudAiplatformV1ActiveLearningConfigPtrOutput
	ToGoogleCloudAiplatformV1ActiveLearningConfigPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1ActiveLearningConfigPtrOutput
}

type googleCloudAiplatformV1ActiveLearningConfigPtrType GoogleCloudAiplatformV1ActiveLearningConfigArgs

func GoogleCloudAiplatformV1ActiveLearningConfigPtr(v *GoogleCloudAiplatformV1ActiveLearningConfigArgs) GoogleCloudAiplatformV1ActiveLearningConfigPtrInput {
	return (*googleCloudAiplatformV1ActiveLearningConfigPtrType)(v)
}

func (*googleCloudAiplatformV1ActiveLearningConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1ActiveLearningConfig)(nil)).Elem()
}

func (i *googleCloudAiplatformV1ActiveLearningConfigPtrType) ToGoogleCloudAiplatformV1ActiveLearningConfigPtrOutput() GoogleCloudAiplatformV1ActiveLearningConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1ActiveLearningConfigPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1ActiveLearningConfigPtrType) ToGoogleCloudAiplatformV1ActiveLearningConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ActiveLearningConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1ActiveLearningConfigPtrOutput)
}

// Parameters that configure the active learning pipeline. Active learning will label the data incrementally by several iterations. For every iteration, it will select a batch of data based on the sampling strategy.
type GoogleCloudAiplatformV1ActiveLearningConfigOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ActiveLearningConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1ActiveLearningConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ActiveLearningConfigOutput) ToGoogleCloudAiplatformV1ActiveLearningConfigOutput() GoogleCloudAiplatformV1ActiveLearningConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1ActiveLearningConfigOutput) ToGoogleCloudAiplatformV1ActiveLearningConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ActiveLearningConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1ActiveLearningConfigOutput) ToGoogleCloudAiplatformV1ActiveLearningConfigPtrOutput() GoogleCloudAiplatformV1ActiveLearningConfigPtrOutput {
	return o.ToGoogleCloudAiplatformV1ActiveLearningConfigPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1ActiveLearningConfigOutput) ToGoogleCloudAiplatformV1ActiveLearningConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ActiveLearningConfigPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1ActiveLearningConfig) *GoogleCloudAiplatformV1ActiveLearningConfig {
		return &v
	}).(GoogleCloudAiplatformV1ActiveLearningConfigPtrOutput)
}

// Max number of human labeled DataItems.
func (o GoogleCloudAiplatformV1ActiveLearningConfigOutput) MaxDataItemCount() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ActiveLearningConfig) *string { return v.MaxDataItemCount }).(pulumi.StringPtrOutput)
}

// Max percent of total DataItems for human labeling.
func (o GoogleCloudAiplatformV1ActiveLearningConfigOutput) MaxDataItemPercentage() pulumi.IntPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ActiveLearningConfig) *int { return v.MaxDataItemPercentage }).(pulumi.IntPtrOutput)
}

// Active learning data sampling config. For every active learning labeling iteration, it will select a batch of data based on the sampling strategy.
func (o GoogleCloudAiplatformV1ActiveLearningConfigOutput) SampleConfig() GoogleCloudAiplatformV1SampleConfigPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ActiveLearningConfig) *GoogleCloudAiplatformV1SampleConfig {
		return v.SampleConfig
	}).(GoogleCloudAiplatformV1SampleConfigPtrOutput)
}

// CMLE training config. For every active learning labeling iteration, system will train a machine learning model on CMLE. The trained model will be used by data sampling algorithm to select DataItems.
func (o GoogleCloudAiplatformV1ActiveLearningConfigOutput) TrainingConfig() GoogleCloudAiplatformV1TrainingConfigPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ActiveLearningConfig) *GoogleCloudAiplatformV1TrainingConfig {
		return v.TrainingConfig
	}).(GoogleCloudAiplatformV1TrainingConfigPtrOutput)
}

type GoogleCloudAiplatformV1ActiveLearningConfigPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ActiveLearningConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1ActiveLearningConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ActiveLearningConfigPtrOutput) ToGoogleCloudAiplatformV1ActiveLearningConfigPtrOutput() GoogleCloudAiplatformV1ActiveLearningConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1ActiveLearningConfigPtrOutput) ToGoogleCloudAiplatformV1ActiveLearningConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ActiveLearningConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1ActiveLearningConfigPtrOutput) Elem() GoogleCloudAiplatformV1ActiveLearningConfigOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1ActiveLearningConfig) GoogleCloudAiplatformV1ActiveLearningConfig {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1ActiveLearningConfig
		return ret
	}).(GoogleCloudAiplatformV1ActiveLearningConfigOutput)
}

// Max number of human labeled DataItems.
func (o GoogleCloudAiplatformV1ActiveLearningConfigPtrOutput) MaxDataItemCount() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1ActiveLearningConfig) *string {
		if v == nil {
			return nil
		}
		return v.MaxDataItemCount
	}).(pulumi.StringPtrOutput)
}

// Max percent of total DataItems for human labeling.
func (o GoogleCloudAiplatformV1ActiveLearningConfigPtrOutput) MaxDataItemPercentage() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1ActiveLearningConfig) *int {
		if v == nil {
			return nil
		}
		return v.MaxDataItemPercentage
	}).(pulumi.IntPtrOutput)
}

// Active learning data sampling config. For every active learning labeling iteration, it will select a batch of data based on the sampling strategy.
func (o GoogleCloudAiplatformV1ActiveLearningConfigPtrOutput) SampleConfig() GoogleCloudAiplatformV1SampleConfigPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1ActiveLearningConfig) *GoogleCloudAiplatformV1SampleConfig {
		if v == nil {
			return nil
		}
		return v.SampleConfig
	}).(GoogleCloudAiplatformV1SampleConfigPtrOutput)
}

// CMLE training config. For every active learning labeling iteration, system will train a machine learning model on CMLE. The trained model will be used by data sampling algorithm to select DataItems.
func (o GoogleCloudAiplatformV1ActiveLearningConfigPtrOutput) TrainingConfig() GoogleCloudAiplatformV1TrainingConfigPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1ActiveLearningConfig) *GoogleCloudAiplatformV1TrainingConfig {
		if v == nil {
			return nil
		}
		return v.TrainingConfig
	}).(GoogleCloudAiplatformV1TrainingConfigPtrOutput)
}

// Parameters that configure the active learning pipeline. Active learning will label the data incrementally by several iterations. For every iteration, it will select a batch of data based on the sampling strategy.
type GoogleCloudAiplatformV1ActiveLearningConfigResponse struct {
	// Max number of human labeled DataItems.
	MaxDataItemCount string `pulumi:"maxDataItemCount"`
	// Max percent of total DataItems for human labeling.
	MaxDataItemPercentage int `pulumi:"maxDataItemPercentage"`
	// Active learning data sampling config. For every active learning labeling iteration, it will select a batch of data based on the sampling strategy.
	SampleConfig GoogleCloudAiplatformV1SampleConfigResponse `pulumi:"sampleConfig"`
	// CMLE training config. For every active learning labeling iteration, system will train a machine learning model on CMLE. The trained model will be used by data sampling algorithm to select DataItems.
	TrainingConfig GoogleCloudAiplatformV1TrainingConfigResponse `pulumi:"trainingConfig"`
}

// Parameters that configure the active learning pipeline. Active learning will label the data incrementally by several iterations. For every iteration, it will select a batch of data based on the sampling strategy.
type GoogleCloudAiplatformV1ActiveLearningConfigResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ActiveLearningConfigResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1ActiveLearningConfigResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ActiveLearningConfigResponseOutput) ToGoogleCloudAiplatformV1ActiveLearningConfigResponseOutput() GoogleCloudAiplatformV1ActiveLearningConfigResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1ActiveLearningConfigResponseOutput) ToGoogleCloudAiplatformV1ActiveLearningConfigResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ActiveLearningConfigResponseOutput {
	return o
}

// Max number of human labeled DataItems.
func (o GoogleCloudAiplatformV1ActiveLearningConfigResponseOutput) MaxDataItemCount() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ActiveLearningConfigResponse) string { return v.MaxDataItemCount }).(pulumi.StringOutput)
}

// Max percent of total DataItems for human labeling.
func (o GoogleCloudAiplatformV1ActiveLearningConfigResponseOutput) MaxDataItemPercentage() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ActiveLearningConfigResponse) int { return v.MaxDataItemPercentage }).(pulumi.IntOutput)
}

// Active learning data sampling config. For every active learning labeling iteration, it will select a batch of data based on the sampling strategy.
func (o GoogleCloudAiplatformV1ActiveLearningConfigResponseOutput) SampleConfig() GoogleCloudAiplatformV1SampleConfigResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ActiveLearningConfigResponse) GoogleCloudAiplatformV1SampleConfigResponse {
		return v.SampleConfig
	}).(GoogleCloudAiplatformV1SampleConfigResponseOutput)
}

// CMLE training config. For every active learning labeling iteration, system will train a machine learning model on CMLE. The trained model will be used by data sampling algorithm to select DataItems.
func (o GoogleCloudAiplatformV1ActiveLearningConfigResponseOutput) TrainingConfig() GoogleCloudAiplatformV1TrainingConfigResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ActiveLearningConfigResponse) GoogleCloudAiplatformV1TrainingConfigResponse {
		return v.TrainingConfig
	}).(GoogleCloudAiplatformV1TrainingConfigResponseOutput)
}

// Instance of a general artifact.
type GoogleCloudAiplatformV1ArtifactResponse struct {
	// Timestamp when this Artifact was created.
	CreateTime string `pulumi:"createTime"`
	// Description of the Artifact
	Description string `pulumi:"description"`
	// User provided display name of the Artifact. May be up to 128 Unicode characters.
	DisplayName string `pulumi:"displayName"`
	// An eTag used to perform consistent read-modify-write updates. If not set, a blind "overwrite" update happens.
	Etag string `pulumi:"etag"`
	// The labels with user-defined metadata to organize your Artifacts. Label keys and values can be no longer than 64 characters (Unicode codepoints), can only contain lowercase letters, numeric characters, underscores and dashes. International characters are allowed. No more than 64 user labels can be associated with one Artifact (System labels are excluded).
	Labels map[string]string `pulumi:"labels"`
	// Properties of the Artifact. Top level metadata keys' heading and trailing spaces will be trimmed. The size of this field should not exceed 200KB.
	Metadata map[string]interface{} `pulumi:"metadata"`
	// The resource name of the Artifact.
	Name string `pulumi:"name"`
	// The title of the schema describing the metadata. Schema title and version is expected to be registered in earlier Create Schema calls. And both are used together as unique identifiers to identify schemas within the local metadata store.
	SchemaTitle string `pulumi:"schemaTitle"`
	// The version of the schema in schema_name to use. Schema title and version is expected to be registered in earlier Create Schema calls. And both are used together as unique identifiers to identify schemas within the local metadata store.
	SchemaVersion string `pulumi:"schemaVersion"`
	// The state of this Artifact. This is a property of the Artifact, and does not imply or capture any ongoing process. This property is managed by clients (such as Vertex AI Pipelines), and the system does not prescribe or check the validity of state transitions.
	State string `pulumi:"state"`
	// Timestamp when this Artifact was last updated.
	UpdateTime string `pulumi:"updateTime"`
	// The uniform resource identifier of the artifact file. May be empty if there is no actual artifact file.
	Uri string `pulumi:"uri"`
}

// Instance of a general artifact.
type GoogleCloudAiplatformV1ArtifactResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ArtifactResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1ArtifactResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ArtifactResponseOutput) ToGoogleCloudAiplatformV1ArtifactResponseOutput() GoogleCloudAiplatformV1ArtifactResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1ArtifactResponseOutput) ToGoogleCloudAiplatformV1ArtifactResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ArtifactResponseOutput {
	return o
}

// Timestamp when this Artifact was created.
func (o GoogleCloudAiplatformV1ArtifactResponseOutput) CreateTime() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ArtifactResponse) string { return v.CreateTime }).(pulumi.StringOutput)
}

// Description of the Artifact
func (o GoogleCloudAiplatformV1ArtifactResponseOutput) Description() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ArtifactResponse) string { return v.Description }).(pulumi.StringOutput)
}

// User provided display name of the Artifact. May be up to 128 Unicode characters.
func (o GoogleCloudAiplatformV1ArtifactResponseOutput) DisplayName() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ArtifactResponse) string { return v.DisplayName }).(pulumi.StringOutput)
}

// An eTag used to perform consistent read-modify-write updates. If not set, a blind "overwrite" update happens.
func (o GoogleCloudAiplatformV1ArtifactResponseOutput) Etag() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ArtifactResponse) string { return v.Etag }).(pulumi.StringOutput)
}

// The labels with user-defined metadata to organize your Artifacts. Label keys and values can be no longer than 64 characters (Unicode codepoints), can only contain lowercase letters, numeric characters, underscores and dashes. International characters are allowed. No more than 64 user labels can be associated with one Artifact (System labels are excluded).
func (o GoogleCloudAiplatformV1ArtifactResponseOutput) Labels() pulumi.StringMapOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ArtifactResponse) map[string]string { return v.Labels }).(pulumi.StringMapOutput)
}

// Properties of the Artifact. Top level metadata keys' heading and trailing spaces will be trimmed. The size of this field should not exceed 200KB.
func (o GoogleCloudAiplatformV1ArtifactResponseOutput) Metadata() pulumi.MapOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ArtifactResponse) map[string]interface{} { return v.Metadata }).(pulumi.MapOutput)
}

// The resource name of the Artifact.
func (o GoogleCloudAiplatformV1ArtifactResponseOutput) Name() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ArtifactResponse) string { return v.Name }).(pulumi.StringOutput)
}

// The title of the schema describing the metadata. Schema title and version is expected to be registered in earlier Create Schema calls. And both are used together as unique identifiers to identify schemas within the local metadata store.
func (o GoogleCloudAiplatformV1ArtifactResponseOutput) SchemaTitle() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ArtifactResponse) string { return v.SchemaTitle }).(pulumi.StringOutput)
}

// The version of the schema in schema_name to use. Schema title and version is expected to be registered in earlier Create Schema calls. And both are used together as unique identifiers to identify schemas within the local metadata store.
func (o GoogleCloudAiplatformV1ArtifactResponseOutput) SchemaVersion() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ArtifactResponse) string { return v.SchemaVersion }).(pulumi.StringOutput)
}

// The state of this Artifact. This is a property of the Artifact, and does not imply or capture any ongoing process. This property is managed by clients (such as Vertex AI Pipelines), and the system does not prescribe or check the validity of state transitions.
func (o GoogleCloudAiplatformV1ArtifactResponseOutput) State() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ArtifactResponse) string { return v.State }).(pulumi.StringOutput)
}

// Timestamp when this Artifact was last updated.
func (o GoogleCloudAiplatformV1ArtifactResponseOutput) UpdateTime() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ArtifactResponse) string { return v.UpdateTime }).(pulumi.StringOutput)
}

// The uniform resource identifier of the artifact file. May be empty if there is no actual artifact file.
func (o GoogleCloudAiplatformV1ArtifactResponseOutput) Uri() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ArtifactResponse) string { return v.Uri }).(pulumi.StringOutput)
}

type GoogleCloudAiplatformV1ArtifactResponseArrayOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ArtifactResponseArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1ArtifactResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ArtifactResponseArrayOutput) ToGoogleCloudAiplatformV1ArtifactResponseArrayOutput() GoogleCloudAiplatformV1ArtifactResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1ArtifactResponseArrayOutput) ToGoogleCloudAiplatformV1ArtifactResponseArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ArtifactResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1ArtifactResponseArrayOutput) Index(i pulumi.IntInput) GoogleCloudAiplatformV1ArtifactResponseOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GoogleCloudAiplatformV1ArtifactResponse {
		return vs[0].([]GoogleCloudAiplatformV1ArtifactResponse)[vs[1].(int)]
	}).(GoogleCloudAiplatformV1ArtifactResponseOutput)
}

// A description of resources that to large degree are decided by Vertex AI, and require only a modest additional configuration. Each Model supporting these resources documents its specific guidelines.
type GoogleCloudAiplatformV1AutomaticResourcesResponse struct {
	// Immutable. The maximum number of replicas this DeployedModel may be deployed on when the traffic against it increases. If the requested value is too large, the deployment will error, but if deployment succeeds then the ability to scale the model to that many replicas is guaranteed (barring service outages). If traffic against the DeployedModel increases beyond what its replicas at maximum may handle, a portion of the traffic will be dropped. If this value is not provided, a no upper bound for scaling under heavy traffic will be assume, though Vertex AI may be unable to scale beyond certain replica number.
	MaxReplicaCount int `pulumi:"maxReplicaCount"`
	// Immutable. The minimum number of replicas this DeployedModel will be always deployed on. If traffic against it increases, it may dynamically be deployed onto more replicas up to max_replica_count, and as traffic decreases, some of these extra replicas may be freed. If the requested value is too large, the deployment will error.
	MinReplicaCount int `pulumi:"minReplicaCount"`
}

// A description of resources that to large degree are decided by Vertex AI, and require only a modest additional configuration. Each Model supporting these resources documents its specific guidelines.
type GoogleCloudAiplatformV1AutomaticResourcesResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1AutomaticResourcesResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1AutomaticResourcesResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1AutomaticResourcesResponseOutput) ToGoogleCloudAiplatformV1AutomaticResourcesResponseOutput() GoogleCloudAiplatformV1AutomaticResourcesResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1AutomaticResourcesResponseOutput) ToGoogleCloudAiplatformV1AutomaticResourcesResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1AutomaticResourcesResponseOutput {
	return o
}

// Immutable. The maximum number of replicas this DeployedModel may be deployed on when the traffic against it increases. If the requested value is too large, the deployment will error, but if deployment succeeds then the ability to scale the model to that many replicas is guaranteed (barring service outages). If traffic against the DeployedModel increases beyond what its replicas at maximum may handle, a portion of the traffic will be dropped. If this value is not provided, a no upper bound for scaling under heavy traffic will be assume, though Vertex AI may be unable to scale beyond certain replica number.
func (o GoogleCloudAiplatformV1AutomaticResourcesResponseOutput) MaxReplicaCount() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1AutomaticResourcesResponse) int { return v.MaxReplicaCount }).(pulumi.IntOutput)
}

// Immutable. The minimum number of replicas this DeployedModel will be always deployed on. If traffic against it increases, it may dynamically be deployed onto more replicas up to max_replica_count, and as traffic decreases, some of these extra replicas may be freed. If the requested value is too large, the deployment will error.
func (o GoogleCloudAiplatformV1AutomaticResourcesResponseOutput) MinReplicaCount() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1AutomaticResourcesResponse) int { return v.MinReplicaCount }).(pulumi.IntOutput)
}

// The metric specification that defines the target resource utilization (CPU utilization, accelerator's duty cycle, and so on) for calculating the desired replica count.
type GoogleCloudAiplatformV1AutoscalingMetricSpec struct {
	// The resource metric name. Supported metrics: * For Online Prediction: * `aiplatform.googleapis.com/prediction/online/accelerator/duty_cycle` * `aiplatform.googleapis.com/prediction/online/cpu/utilization`
	MetricName string `pulumi:"metricName"`
	// The target resource utilization in percentage (1% - 100%) for the given metric; once the real usage deviates from the target by a certain percentage, the machine replicas change. The default value is 60 (representing 60%) if not provided.
	Target *int `pulumi:"target"`
}

// GoogleCloudAiplatformV1AutoscalingMetricSpecInput is an input type that accepts GoogleCloudAiplatformV1AutoscalingMetricSpecArgs and GoogleCloudAiplatformV1AutoscalingMetricSpecOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1AutoscalingMetricSpecInput` via:
//
//	GoogleCloudAiplatformV1AutoscalingMetricSpecArgs{...}
type GoogleCloudAiplatformV1AutoscalingMetricSpecInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1AutoscalingMetricSpecOutput() GoogleCloudAiplatformV1AutoscalingMetricSpecOutput
	ToGoogleCloudAiplatformV1AutoscalingMetricSpecOutputWithContext(context.Context) GoogleCloudAiplatformV1AutoscalingMetricSpecOutput
}

// The metric specification that defines the target resource utilization (CPU utilization, accelerator's duty cycle, and so on) for calculating the desired replica count.
type GoogleCloudAiplatformV1AutoscalingMetricSpecArgs struct {
	// The resource metric name. Supported metrics: * For Online Prediction: * `aiplatform.googleapis.com/prediction/online/accelerator/duty_cycle` * `aiplatform.googleapis.com/prediction/online/cpu/utilization`
	MetricName pulumi.StringInput `pulumi:"metricName"`
	// The target resource utilization in percentage (1% - 100%) for the given metric; once the real usage deviates from the target by a certain percentage, the machine replicas change. The default value is 60 (representing 60%) if not provided.
	Target pulumi.IntPtrInput `pulumi:"target"`
}

func (GoogleCloudAiplatformV1AutoscalingMetricSpecArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1AutoscalingMetricSpec)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1AutoscalingMetricSpecArgs) ToGoogleCloudAiplatformV1AutoscalingMetricSpecOutput() GoogleCloudAiplatformV1AutoscalingMetricSpecOutput {
	return i.ToGoogleCloudAiplatformV1AutoscalingMetricSpecOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1AutoscalingMetricSpecArgs) ToGoogleCloudAiplatformV1AutoscalingMetricSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1AutoscalingMetricSpecOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1AutoscalingMetricSpecOutput)
}

// GoogleCloudAiplatformV1AutoscalingMetricSpecArrayInput is an input type that accepts GoogleCloudAiplatformV1AutoscalingMetricSpecArray and GoogleCloudAiplatformV1AutoscalingMetricSpecArrayOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1AutoscalingMetricSpecArrayInput` via:
//
//	GoogleCloudAiplatformV1AutoscalingMetricSpecArray{ GoogleCloudAiplatformV1AutoscalingMetricSpecArgs{...} }
type GoogleCloudAiplatformV1AutoscalingMetricSpecArrayInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1AutoscalingMetricSpecArrayOutput() GoogleCloudAiplatformV1AutoscalingMetricSpecArrayOutput
	ToGoogleCloudAiplatformV1AutoscalingMetricSpecArrayOutputWithContext(context.Context) GoogleCloudAiplatformV1AutoscalingMetricSpecArrayOutput
}

type GoogleCloudAiplatformV1AutoscalingMetricSpecArray []GoogleCloudAiplatformV1AutoscalingMetricSpecInput

func (GoogleCloudAiplatformV1AutoscalingMetricSpecArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1AutoscalingMetricSpec)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1AutoscalingMetricSpecArray) ToGoogleCloudAiplatformV1AutoscalingMetricSpecArrayOutput() GoogleCloudAiplatformV1AutoscalingMetricSpecArrayOutput {
	return i.ToGoogleCloudAiplatformV1AutoscalingMetricSpecArrayOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1AutoscalingMetricSpecArray) ToGoogleCloudAiplatformV1AutoscalingMetricSpecArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1AutoscalingMetricSpecArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1AutoscalingMetricSpecArrayOutput)
}

// The metric specification that defines the target resource utilization (CPU utilization, accelerator's duty cycle, and so on) for calculating the desired replica count.
type GoogleCloudAiplatformV1AutoscalingMetricSpecOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1AutoscalingMetricSpecOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1AutoscalingMetricSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1AutoscalingMetricSpecOutput) ToGoogleCloudAiplatformV1AutoscalingMetricSpecOutput() GoogleCloudAiplatformV1AutoscalingMetricSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1AutoscalingMetricSpecOutput) ToGoogleCloudAiplatformV1AutoscalingMetricSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1AutoscalingMetricSpecOutput {
	return o
}

// The resource metric name. Supported metrics: * For Online Prediction: * `aiplatform.googleapis.com/prediction/online/accelerator/duty_cycle` * `aiplatform.googleapis.com/prediction/online/cpu/utilization`
func (o GoogleCloudAiplatformV1AutoscalingMetricSpecOutput) MetricName() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1AutoscalingMetricSpec) string { return v.MetricName }).(pulumi.StringOutput)
}

// The target resource utilization in percentage (1% - 100%) for the given metric; once the real usage deviates from the target by a certain percentage, the machine replicas change. The default value is 60 (representing 60%) if not provided.
func (o GoogleCloudAiplatformV1AutoscalingMetricSpecOutput) Target() pulumi.IntPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1AutoscalingMetricSpec) *int { return v.Target }).(pulumi.IntPtrOutput)
}

type GoogleCloudAiplatformV1AutoscalingMetricSpecArrayOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1AutoscalingMetricSpecArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1AutoscalingMetricSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1AutoscalingMetricSpecArrayOutput) ToGoogleCloudAiplatformV1AutoscalingMetricSpecArrayOutput() GoogleCloudAiplatformV1AutoscalingMetricSpecArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1AutoscalingMetricSpecArrayOutput) ToGoogleCloudAiplatformV1AutoscalingMetricSpecArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1AutoscalingMetricSpecArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1AutoscalingMetricSpecArrayOutput) Index(i pulumi.IntInput) GoogleCloudAiplatformV1AutoscalingMetricSpecOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GoogleCloudAiplatformV1AutoscalingMetricSpec {
		return vs[0].([]GoogleCloudAiplatformV1AutoscalingMetricSpec)[vs[1].(int)]
	}).(GoogleCloudAiplatformV1AutoscalingMetricSpecOutput)
}

// The metric specification that defines the target resource utilization (CPU utilization, accelerator's duty cycle, and so on) for calculating the desired replica count.
type GoogleCloudAiplatformV1AutoscalingMetricSpecResponse struct {
	// The resource metric name. Supported metrics: * For Online Prediction: * `aiplatform.googleapis.com/prediction/online/accelerator/duty_cycle` * `aiplatform.googleapis.com/prediction/online/cpu/utilization`
	MetricName string `pulumi:"metricName"`
	// The target resource utilization in percentage (1% - 100%) for the given metric; once the real usage deviates from the target by a certain percentage, the machine replicas change. The default value is 60 (representing 60%) if not provided.
	Target int `pulumi:"target"`
}

// The metric specification that defines the target resource utilization (CPU utilization, accelerator's duty cycle, and so on) for calculating the desired replica count.
type GoogleCloudAiplatformV1AutoscalingMetricSpecResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1AutoscalingMetricSpecResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1AutoscalingMetricSpecResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1AutoscalingMetricSpecResponseOutput) ToGoogleCloudAiplatformV1AutoscalingMetricSpecResponseOutput() GoogleCloudAiplatformV1AutoscalingMetricSpecResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1AutoscalingMetricSpecResponseOutput) ToGoogleCloudAiplatformV1AutoscalingMetricSpecResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1AutoscalingMetricSpecResponseOutput {
	return o
}

// The resource metric name. Supported metrics: * For Online Prediction: * `aiplatform.googleapis.com/prediction/online/accelerator/duty_cycle` * `aiplatform.googleapis.com/prediction/online/cpu/utilization`
func (o GoogleCloudAiplatformV1AutoscalingMetricSpecResponseOutput) MetricName() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1AutoscalingMetricSpecResponse) string { return v.MetricName }).(pulumi.StringOutput)
}

// The target resource utilization in percentage (1% - 100%) for the given metric; once the real usage deviates from the target by a certain percentage, the machine replicas change. The default value is 60 (representing 60%) if not provided.
func (o GoogleCloudAiplatformV1AutoscalingMetricSpecResponseOutput) Target() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1AutoscalingMetricSpecResponse) int { return v.Target }).(pulumi.IntOutput)
}

type GoogleCloudAiplatformV1AutoscalingMetricSpecResponseArrayOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1AutoscalingMetricSpecResponseArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1AutoscalingMetricSpecResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1AutoscalingMetricSpecResponseArrayOutput) ToGoogleCloudAiplatformV1AutoscalingMetricSpecResponseArrayOutput() GoogleCloudAiplatformV1AutoscalingMetricSpecResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1AutoscalingMetricSpecResponseArrayOutput) ToGoogleCloudAiplatformV1AutoscalingMetricSpecResponseArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1AutoscalingMetricSpecResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1AutoscalingMetricSpecResponseArrayOutput) Index(i pulumi.IntInput) GoogleCloudAiplatformV1AutoscalingMetricSpecResponseOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GoogleCloudAiplatformV1AutoscalingMetricSpecResponse {
		return vs[0].([]GoogleCloudAiplatformV1AutoscalingMetricSpecResponse)[vs[1].(int)]
	}).(GoogleCloudAiplatformV1AutoscalingMetricSpecResponseOutput)
}

// A description of resources that are used for performing batch operations, are dedicated to a Model, and need manual configuration.
type GoogleCloudAiplatformV1BatchDedicatedResources struct {
	// Immutable. The specification of a single machine.
	MachineSpec GoogleCloudAiplatformV1MachineSpec `pulumi:"machineSpec"`
	// Immutable. The maximum number of machine replicas the batch operation may be scaled to. The default value is 10.
	MaxReplicaCount *int `pulumi:"maxReplicaCount"`
	// Immutable. The number of machine replicas used at the start of the batch operation. If not set, Vertex AI decides starting number, not greater than max_replica_count
	StartingReplicaCount *int `pulumi:"startingReplicaCount"`
}

// GoogleCloudAiplatformV1BatchDedicatedResourcesInput is an input type that accepts GoogleCloudAiplatformV1BatchDedicatedResourcesArgs and GoogleCloudAiplatformV1BatchDedicatedResourcesOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1BatchDedicatedResourcesInput` via:
//
//	GoogleCloudAiplatformV1BatchDedicatedResourcesArgs{...}
type GoogleCloudAiplatformV1BatchDedicatedResourcesInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1BatchDedicatedResourcesOutput() GoogleCloudAiplatformV1BatchDedicatedResourcesOutput
	ToGoogleCloudAiplatformV1BatchDedicatedResourcesOutputWithContext(context.Context) GoogleCloudAiplatformV1BatchDedicatedResourcesOutput
}

// A description of resources that are used for performing batch operations, are dedicated to a Model, and need manual configuration.
type GoogleCloudAiplatformV1BatchDedicatedResourcesArgs struct {
	// Immutable. The specification of a single machine.
	MachineSpec GoogleCloudAiplatformV1MachineSpecInput `pulumi:"machineSpec"`
	// Immutable. The maximum number of machine replicas the batch operation may be scaled to. The default value is 10.
	MaxReplicaCount pulumi.IntPtrInput `pulumi:"maxReplicaCount"`
	// Immutable. The number of machine replicas used at the start of the batch operation. If not set, Vertex AI decides starting number, not greater than max_replica_count
	StartingReplicaCount pulumi.IntPtrInput `pulumi:"startingReplicaCount"`
}

func (GoogleCloudAiplatformV1BatchDedicatedResourcesArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1BatchDedicatedResources)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1BatchDedicatedResourcesArgs) ToGoogleCloudAiplatformV1BatchDedicatedResourcesOutput() GoogleCloudAiplatformV1BatchDedicatedResourcesOutput {
	return i.ToGoogleCloudAiplatformV1BatchDedicatedResourcesOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1BatchDedicatedResourcesArgs) ToGoogleCloudAiplatformV1BatchDedicatedResourcesOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1BatchDedicatedResourcesOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1BatchDedicatedResourcesOutput)
}

func (i GoogleCloudAiplatformV1BatchDedicatedResourcesArgs) ToGoogleCloudAiplatformV1BatchDedicatedResourcesPtrOutput() GoogleCloudAiplatformV1BatchDedicatedResourcesPtrOutput {
	return i.ToGoogleCloudAiplatformV1BatchDedicatedResourcesPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1BatchDedicatedResourcesArgs) ToGoogleCloudAiplatformV1BatchDedicatedResourcesPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1BatchDedicatedResourcesPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1BatchDedicatedResourcesOutput).ToGoogleCloudAiplatformV1BatchDedicatedResourcesPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1BatchDedicatedResourcesPtrInput is an input type that accepts GoogleCloudAiplatformV1BatchDedicatedResourcesArgs, GoogleCloudAiplatformV1BatchDedicatedResourcesPtr and GoogleCloudAiplatformV1BatchDedicatedResourcesPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1BatchDedicatedResourcesPtrInput` via:
//
//	        GoogleCloudAiplatformV1BatchDedicatedResourcesArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1BatchDedicatedResourcesPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1BatchDedicatedResourcesPtrOutput() GoogleCloudAiplatformV1BatchDedicatedResourcesPtrOutput
	ToGoogleCloudAiplatformV1BatchDedicatedResourcesPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1BatchDedicatedResourcesPtrOutput
}

type googleCloudAiplatformV1BatchDedicatedResourcesPtrType GoogleCloudAiplatformV1BatchDedicatedResourcesArgs

func GoogleCloudAiplatformV1BatchDedicatedResourcesPtr(v *GoogleCloudAiplatformV1BatchDedicatedResourcesArgs) GoogleCloudAiplatformV1BatchDedicatedResourcesPtrInput {
	return (*googleCloudAiplatformV1BatchDedicatedResourcesPtrType)(v)
}

func (*googleCloudAiplatformV1BatchDedicatedResourcesPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1BatchDedicatedResources)(nil)).Elem()
}

func (i *googleCloudAiplatformV1BatchDedicatedResourcesPtrType) ToGoogleCloudAiplatformV1BatchDedicatedResourcesPtrOutput() GoogleCloudAiplatformV1BatchDedicatedResourcesPtrOutput {
	return i.ToGoogleCloudAiplatformV1BatchDedicatedResourcesPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1BatchDedicatedResourcesPtrType) ToGoogleCloudAiplatformV1BatchDedicatedResourcesPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1BatchDedicatedResourcesPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1BatchDedicatedResourcesPtrOutput)
}

// A description of resources that are used for performing batch operations, are dedicated to a Model, and need manual configuration.
type GoogleCloudAiplatformV1BatchDedicatedResourcesOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1BatchDedicatedResourcesOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1BatchDedicatedResources)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1BatchDedicatedResourcesOutput) ToGoogleCloudAiplatformV1BatchDedicatedResourcesOutput() GoogleCloudAiplatformV1BatchDedicatedResourcesOutput {
	return o
}

func (o GoogleCloudAiplatformV1BatchDedicatedResourcesOutput) ToGoogleCloudAiplatformV1BatchDedicatedResourcesOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1BatchDedicatedResourcesOutput {
	return o
}

func (o GoogleCloudAiplatformV1BatchDedicatedResourcesOutput) ToGoogleCloudAiplatformV1BatchDedicatedResourcesPtrOutput() GoogleCloudAiplatformV1BatchDedicatedResourcesPtrOutput {
	return o.ToGoogleCloudAiplatformV1BatchDedicatedResourcesPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1BatchDedicatedResourcesOutput) ToGoogleCloudAiplatformV1BatchDedicatedResourcesPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1BatchDedicatedResourcesPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1BatchDedicatedResources) *GoogleCloudAiplatformV1BatchDedicatedResources {
		return &v
	}).(GoogleCloudAiplatformV1BatchDedicatedResourcesPtrOutput)
}

// Immutable. The specification of a single machine.
func (o GoogleCloudAiplatformV1BatchDedicatedResourcesOutput) MachineSpec() GoogleCloudAiplatformV1MachineSpecOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1BatchDedicatedResources) GoogleCloudAiplatformV1MachineSpec {
		return v.MachineSpec
	}).(GoogleCloudAiplatformV1MachineSpecOutput)
}

// Immutable. The maximum number of machine replicas the batch operation may be scaled to. The default value is 10.
func (o GoogleCloudAiplatformV1BatchDedicatedResourcesOutput) MaxReplicaCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1BatchDedicatedResources) *int { return v.MaxReplicaCount }).(pulumi.IntPtrOutput)
}

// Immutable. The number of machine replicas used at the start of the batch operation. If not set, Vertex AI decides starting number, not greater than max_replica_count
func (o GoogleCloudAiplatformV1BatchDedicatedResourcesOutput) StartingReplicaCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1BatchDedicatedResources) *int { return v.StartingReplicaCount }).(pulumi.IntPtrOutput)
}

type GoogleCloudAiplatformV1BatchDedicatedResourcesPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1BatchDedicatedResourcesPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1BatchDedicatedResources)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1BatchDedicatedResourcesPtrOutput) ToGoogleCloudAiplatformV1BatchDedicatedResourcesPtrOutput() GoogleCloudAiplatformV1BatchDedicatedResourcesPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1BatchDedicatedResourcesPtrOutput) ToGoogleCloudAiplatformV1BatchDedicatedResourcesPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1BatchDedicatedResourcesPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1BatchDedicatedResourcesPtrOutput) Elem() GoogleCloudAiplatformV1BatchDedicatedResourcesOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1BatchDedicatedResources) GoogleCloudAiplatformV1BatchDedicatedResources {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1BatchDedicatedResources
		return ret
	}).(GoogleCloudAiplatformV1BatchDedicatedResourcesOutput)
}

// Immutable. The specification of a single machine.
func (o GoogleCloudAiplatformV1BatchDedicatedResourcesPtrOutput) MachineSpec() GoogleCloudAiplatformV1MachineSpecPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1BatchDedicatedResources) *GoogleCloudAiplatformV1MachineSpec {
		if v == nil {
			return nil
		}
		return &v.MachineSpec
	}).(GoogleCloudAiplatformV1MachineSpecPtrOutput)
}

// Immutable. The maximum number of machine replicas the batch operation may be scaled to. The default value is 10.
func (o GoogleCloudAiplatformV1BatchDedicatedResourcesPtrOutput) MaxReplicaCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1BatchDedicatedResources) *int {
		if v == nil {
			return nil
		}
		return v.MaxReplicaCount
	}).(pulumi.IntPtrOutput)
}

// Immutable. The number of machine replicas used at the start of the batch operation. If not set, Vertex AI decides starting number, not greater than max_replica_count
func (o GoogleCloudAiplatformV1BatchDedicatedResourcesPtrOutput) StartingReplicaCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1BatchDedicatedResources) *int {
		if v == nil {
			return nil
		}
		return v.StartingReplicaCount
	}).(pulumi.IntPtrOutput)
}

// A description of resources that are used for performing batch operations, are dedicated to a Model, and need manual configuration.
type GoogleCloudAiplatformV1BatchDedicatedResourcesResponse struct {
	// Immutable. The specification of a single machine.
	MachineSpec GoogleCloudAiplatformV1MachineSpecResponse `pulumi:"machineSpec"`
	// Immutable. The maximum number of machine replicas the batch operation may be scaled to. The default value is 10.
	MaxReplicaCount int `pulumi:"maxReplicaCount"`
	// Immutable. The number of machine replicas used at the start of the batch operation. If not set, Vertex AI decides starting number, not greater than max_replica_count
	StartingReplicaCount int `pulumi:"startingReplicaCount"`
}

// A description of resources that are used for performing batch operations, are dedicated to a Model, and need manual configuration.
type GoogleCloudAiplatformV1BatchDedicatedResourcesResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1BatchDedicatedResourcesResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1BatchDedicatedResourcesResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1BatchDedicatedResourcesResponseOutput) ToGoogleCloudAiplatformV1BatchDedicatedResourcesResponseOutput() GoogleCloudAiplatformV1BatchDedicatedResourcesResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1BatchDedicatedResourcesResponseOutput) ToGoogleCloudAiplatformV1BatchDedicatedResourcesResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1BatchDedicatedResourcesResponseOutput {
	return o
}

// Immutable. The specification of a single machine.
func (o GoogleCloudAiplatformV1BatchDedicatedResourcesResponseOutput) MachineSpec() GoogleCloudAiplatformV1MachineSpecResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1BatchDedicatedResourcesResponse) GoogleCloudAiplatformV1MachineSpecResponse {
		return v.MachineSpec
	}).(GoogleCloudAiplatformV1MachineSpecResponseOutput)
}

// Immutable. The maximum number of machine replicas the batch operation may be scaled to. The default value is 10.
func (o GoogleCloudAiplatformV1BatchDedicatedResourcesResponseOutput) MaxReplicaCount() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1BatchDedicatedResourcesResponse) int { return v.MaxReplicaCount }).(pulumi.IntOutput)
}

// Immutable. The number of machine replicas used at the start of the batch operation. If not set, Vertex AI decides starting number, not greater than max_replica_count
func (o GoogleCloudAiplatformV1BatchDedicatedResourcesResponseOutput) StartingReplicaCount() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1BatchDedicatedResourcesResponse) int { return v.StartingReplicaCount }).(pulumi.IntOutput)
}

// Configures the input to BatchPredictionJob. See Model.supported_input_storage_formats for Model's supported input formats, and how instances should be expressed via any of them.
type GoogleCloudAiplatformV1BatchPredictionJobInputConfig struct {
	// The BigQuery location of the input table. The schema of the table should be in the format described by the given context OpenAPI Schema, if one is provided. The table may contain additional columns that are not described by the schema, and they will be ignored.
	BigquerySource *GoogleCloudAiplatformV1BigQuerySource `pulumi:"bigquerySource"`
	// The Cloud Storage location for the input instances.
	GcsSource *GoogleCloudAiplatformV1GcsSource `pulumi:"gcsSource"`
	// The format in which instances are given, must be one of the Model's supported_input_storage_formats.
	InstancesFormat string `pulumi:"instancesFormat"`
}

// GoogleCloudAiplatformV1BatchPredictionJobInputConfigInput is an input type that accepts GoogleCloudAiplatformV1BatchPredictionJobInputConfigArgs and GoogleCloudAiplatformV1BatchPredictionJobInputConfigOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1BatchPredictionJobInputConfigInput` via:
//
//	GoogleCloudAiplatformV1BatchPredictionJobInputConfigArgs{...}
type GoogleCloudAiplatformV1BatchPredictionJobInputConfigInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1BatchPredictionJobInputConfigOutput() GoogleCloudAiplatformV1BatchPredictionJobInputConfigOutput
	ToGoogleCloudAiplatformV1BatchPredictionJobInputConfigOutputWithContext(context.Context) GoogleCloudAiplatformV1BatchPredictionJobInputConfigOutput
}

// Configures the input to BatchPredictionJob. See Model.supported_input_storage_formats for Model's supported input formats, and how instances should be expressed via any of them.
type GoogleCloudAiplatformV1BatchPredictionJobInputConfigArgs struct {
	// The BigQuery location of the input table. The schema of the table should be in the format described by the given context OpenAPI Schema, if one is provided. The table may contain additional columns that are not described by the schema, and they will be ignored.
	BigquerySource GoogleCloudAiplatformV1BigQuerySourcePtrInput `pulumi:"bigquerySource"`
	// The Cloud Storage location for the input instances.
	GcsSource GoogleCloudAiplatformV1GcsSourcePtrInput `pulumi:"gcsSource"`
	// The format in which instances are given, must be one of the Model's supported_input_storage_formats.
	InstancesFormat pulumi.StringInput `pulumi:"instancesFormat"`
}

func (GoogleCloudAiplatformV1BatchPredictionJobInputConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1BatchPredictionJobInputConfig)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1BatchPredictionJobInputConfigArgs) ToGoogleCloudAiplatformV1BatchPredictionJobInputConfigOutput() GoogleCloudAiplatformV1BatchPredictionJobInputConfigOutput {
	return i.ToGoogleCloudAiplatformV1BatchPredictionJobInputConfigOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1BatchPredictionJobInputConfigArgs) ToGoogleCloudAiplatformV1BatchPredictionJobInputConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1BatchPredictionJobInputConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1BatchPredictionJobInputConfigOutput)
}

// Configures the input to BatchPredictionJob. See Model.supported_input_storage_formats for Model's supported input formats, and how instances should be expressed via any of them.
type GoogleCloudAiplatformV1BatchPredictionJobInputConfigOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1BatchPredictionJobInputConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1BatchPredictionJobInputConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1BatchPredictionJobInputConfigOutput) ToGoogleCloudAiplatformV1BatchPredictionJobInputConfigOutput() GoogleCloudAiplatformV1BatchPredictionJobInputConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1BatchPredictionJobInputConfigOutput) ToGoogleCloudAiplatformV1BatchPredictionJobInputConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1BatchPredictionJobInputConfigOutput {
	return o
}

// The BigQuery location of the input table. The schema of the table should be in the format described by the given context OpenAPI Schema, if one is provided. The table may contain additional columns that are not described by the schema, and they will be ignored.
func (o GoogleCloudAiplatformV1BatchPredictionJobInputConfigOutput) BigquerySource() GoogleCloudAiplatformV1BigQuerySourcePtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1BatchPredictionJobInputConfig) *GoogleCloudAiplatformV1BigQuerySource {
		return v.BigquerySource
	}).(GoogleCloudAiplatformV1BigQuerySourcePtrOutput)
}

// The Cloud Storage location for the input instances.
func (o GoogleCloudAiplatformV1BatchPredictionJobInputConfigOutput) GcsSource() GoogleCloudAiplatformV1GcsSourcePtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1BatchPredictionJobInputConfig) *GoogleCloudAiplatformV1GcsSource {
		return v.GcsSource
	}).(GoogleCloudAiplatformV1GcsSourcePtrOutput)
}

// The format in which instances are given, must be one of the Model's supported_input_storage_formats.
func (o GoogleCloudAiplatformV1BatchPredictionJobInputConfigOutput) InstancesFormat() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1BatchPredictionJobInputConfig) string { return v.InstancesFormat }).(pulumi.StringOutput)
}

// Configures the input to BatchPredictionJob. See Model.supported_input_storage_formats for Model's supported input formats, and how instances should be expressed via any of them.
type GoogleCloudAiplatformV1BatchPredictionJobInputConfigResponse struct {
	// The BigQuery location of the input table. The schema of the table should be in the format described by the given context OpenAPI Schema, if one is provided. The table may contain additional columns that are not described by the schema, and they will be ignored.
	BigquerySource GoogleCloudAiplatformV1BigQuerySourceResponse `pulumi:"bigquerySource"`
	// The Cloud Storage location for the input instances.
	GcsSource GoogleCloudAiplatformV1GcsSourceResponse `pulumi:"gcsSource"`
	// The format in which instances are given, must be one of the Model's supported_input_storage_formats.
	InstancesFormat string `pulumi:"instancesFormat"`
}

// Configures the input to BatchPredictionJob. See Model.supported_input_storage_formats for Model's supported input formats, and how instances should be expressed via any of them.
type GoogleCloudAiplatformV1BatchPredictionJobInputConfigResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1BatchPredictionJobInputConfigResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1BatchPredictionJobInputConfigResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1BatchPredictionJobInputConfigResponseOutput) ToGoogleCloudAiplatformV1BatchPredictionJobInputConfigResponseOutput() GoogleCloudAiplatformV1BatchPredictionJobInputConfigResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1BatchPredictionJobInputConfigResponseOutput) ToGoogleCloudAiplatformV1BatchPredictionJobInputConfigResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1BatchPredictionJobInputConfigResponseOutput {
	return o
}

// The BigQuery location of the input table. The schema of the table should be in the format described by the given context OpenAPI Schema, if one is provided. The table may contain additional columns that are not described by the schema, and they will be ignored.
func (o GoogleCloudAiplatformV1BatchPredictionJobInputConfigResponseOutput) BigquerySource() GoogleCloudAiplatformV1BigQuerySourceResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1BatchPredictionJobInputConfigResponse) GoogleCloudAiplatformV1BigQuerySourceResponse {
		return v.BigquerySource
	}).(GoogleCloudAiplatformV1BigQuerySourceResponseOutput)
}

// The Cloud Storage location for the input instances.
func (o GoogleCloudAiplatformV1BatchPredictionJobInputConfigResponseOutput) GcsSource() GoogleCloudAiplatformV1GcsSourceResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1BatchPredictionJobInputConfigResponse) GoogleCloudAiplatformV1GcsSourceResponse {
		return v.GcsSource
	}).(GoogleCloudAiplatformV1GcsSourceResponseOutput)
}

// The format in which instances are given, must be one of the Model's supported_input_storage_formats.
func (o GoogleCloudAiplatformV1BatchPredictionJobInputConfigResponseOutput) InstancesFormat() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1BatchPredictionJobInputConfigResponse) string { return v.InstancesFormat }).(pulumi.StringOutput)
}

// Configuration defining how to transform batch prediction input instances to the instances that the Model accepts.
type GoogleCloudAiplatformV1BatchPredictionJobInstanceConfig struct {
	// Fields that will be excluded in the prediction instance that is sent to the Model. Excluded will be attached to the batch prediction output if key_field is not specified. When excluded_fields is populated, included_fields must be empty. The input must be JSONL with objects at each line, CSV, BigQuery or TfRecord.
	ExcludedFields []string `pulumi:"excludedFields"`
	// Fields that will be included in the prediction instance that is sent to the Model. If instance_type is `array`, the order of field names in included_fields also determines the order of the values in the array. When included_fields is populated, excluded_fields must be empty. The input must be JSONL with objects at each line, CSV, BigQuery or TfRecord.
	IncludedFields []string `pulumi:"includedFields"`
	// The format of the instance that the Model accepts. Vertex AI will convert compatible batch prediction input instance formats to the specified format. Supported values are: * `object`: Each input is converted to JSON object format. * For `bigquery`, each row is converted to an object. * For `jsonl`, each line of the JSONL input must be an object. * Does not apply to `csv`, `file-list`, `tf-record`, or `tf-record-gzip`. * `array`: Each input is converted to JSON array format. * For `bigquery`, each row is converted to an array. The order of columns is determined by the BigQuery column order, unless included_fields is populated. included_fields must be populated for specifying field orders. * For `jsonl`, if each line of the JSONL input is an object, included_fields must be populated for specifying field orders. * Does not apply to `csv`, `file-list`, `tf-record`, or `tf-record-gzip`. If not specified, Vertex AI converts the batch prediction input as follows: * For `bigquery` and `csv`, the behavior is the same as `array`. The order of columns is the same as defined in the file or table, unless included_fields is populated. * For `jsonl`, the prediction instance format is determined by each line of the input. * For `tf-record`/`tf-record-gzip`, each record will be converted to an object in the format of `{"b64": }`, where ``is the Base64-encoded string of the content of the record. * For `file-list`, each file in the list will be converted to an object in the format of `{"b64": }`, where`` is the Base64-encoded string of the content of the file.
	InstanceType *string `pulumi:"instanceType"`
	// The name of the field that is considered as a key. The values identified by the key field is not included in the transformed instances that is sent to the Model. This is similar to specifying this name of the field in excluded_fields. In addition, the batch prediction output will not include the instances. Instead the output will only include the value of the key field, in a field named `key` in the output: * For `jsonl` output format, the output will have a `key` field instead of the `instance` field. * For `csv`/`bigquery` output format, the output will have have a `key` column instead of the instance feature columns. The input must be JSONL with objects at each line, CSV, BigQuery or TfRecord.
	KeyField *string `pulumi:"keyField"`
}

// GoogleCloudAiplatformV1BatchPredictionJobInstanceConfigInput is an input type that accepts GoogleCloudAiplatformV1BatchPredictionJobInstanceConfigArgs and GoogleCloudAiplatformV1BatchPredictionJobInstanceConfigOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1BatchPredictionJobInstanceConfigInput` via:
//
//	GoogleCloudAiplatformV1BatchPredictionJobInstanceConfigArgs{...}
type GoogleCloudAiplatformV1BatchPredictionJobInstanceConfigInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1BatchPredictionJobInstanceConfigOutput() GoogleCloudAiplatformV1BatchPredictionJobInstanceConfigOutput
	ToGoogleCloudAiplatformV1BatchPredictionJobInstanceConfigOutputWithContext(context.Context) GoogleCloudAiplatformV1BatchPredictionJobInstanceConfigOutput
}

// Configuration defining how to transform batch prediction input instances to the instances that the Model accepts.
type GoogleCloudAiplatformV1BatchPredictionJobInstanceConfigArgs struct {
	// Fields that will be excluded in the prediction instance that is sent to the Model. Excluded will be attached to the batch prediction output if key_field is not specified. When excluded_fields is populated, included_fields must be empty. The input must be JSONL with objects at each line, CSV, BigQuery or TfRecord.
	ExcludedFields pulumi.StringArrayInput `pulumi:"excludedFields"`
	// Fields that will be included in the prediction instance that is sent to the Model. If instance_type is `array`, the order of field names in included_fields also determines the order of the values in the array. When included_fields is populated, excluded_fields must be empty. The input must be JSONL with objects at each line, CSV, BigQuery or TfRecord.
	IncludedFields pulumi.StringArrayInput `pulumi:"includedFields"`
	// The format of the instance that the Model accepts. Vertex AI will convert compatible batch prediction input instance formats to the specified format. Supported values are: * `object`: Each input is converted to JSON object format. * For `bigquery`, each row is converted to an object. * For `jsonl`, each line of the JSONL input must be an object. * Does not apply to `csv`, `file-list`, `tf-record`, or `tf-record-gzip`. * `array`: Each input is converted to JSON array format. * For `bigquery`, each row is converted to an array. The order of columns is determined by the BigQuery column order, unless included_fields is populated. included_fields must be populated for specifying field orders. * For `jsonl`, if each line of the JSONL input is an object, included_fields must be populated for specifying field orders. * Does not apply to `csv`, `file-list`, `tf-record`, or `tf-record-gzip`. If not specified, Vertex AI converts the batch prediction input as follows: * For `bigquery` and `csv`, the behavior is the same as `array`. The order of columns is the same as defined in the file or table, unless included_fields is populated. * For `jsonl`, the prediction instance format is determined by each line of the input. * For `tf-record`/`tf-record-gzip`, each record will be converted to an object in the format of `{"b64": }`, where ``is the Base64-encoded string of the content of the record. * For `file-list`, each file in the list will be converted to an object in the format of `{"b64": }`, where`` is the Base64-encoded string of the content of the file.
	InstanceType pulumi.StringPtrInput `pulumi:"instanceType"`
	// The name of the field that is considered as a key. The values identified by the key field is not included in the transformed instances that is sent to the Model. This is similar to specifying this name of the field in excluded_fields. In addition, the batch prediction output will not include the instances. Instead the output will only include the value of the key field, in a field named `key` in the output: * For `jsonl` output format, the output will have a `key` field instead of the `instance` field. * For `csv`/`bigquery` output format, the output will have have a `key` column instead of the instance feature columns. The input must be JSONL with objects at each line, CSV, BigQuery or TfRecord.
	KeyField pulumi.StringPtrInput `pulumi:"keyField"`
}

func (GoogleCloudAiplatformV1BatchPredictionJobInstanceConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1BatchPredictionJobInstanceConfig)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1BatchPredictionJobInstanceConfigArgs) ToGoogleCloudAiplatformV1BatchPredictionJobInstanceConfigOutput() GoogleCloudAiplatformV1BatchPredictionJobInstanceConfigOutput {
	return i.ToGoogleCloudAiplatformV1BatchPredictionJobInstanceConfigOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1BatchPredictionJobInstanceConfigArgs) ToGoogleCloudAiplatformV1BatchPredictionJobInstanceConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1BatchPredictionJobInstanceConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1BatchPredictionJobInstanceConfigOutput)
}

func (i GoogleCloudAiplatformV1BatchPredictionJobInstanceConfigArgs) ToGoogleCloudAiplatformV1BatchPredictionJobInstanceConfigPtrOutput() GoogleCloudAiplatformV1BatchPredictionJobInstanceConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1BatchPredictionJobInstanceConfigPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1BatchPredictionJobInstanceConfigArgs) ToGoogleCloudAiplatformV1BatchPredictionJobInstanceConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1BatchPredictionJobInstanceConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1BatchPredictionJobInstanceConfigOutput).ToGoogleCloudAiplatformV1BatchPredictionJobInstanceConfigPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1BatchPredictionJobInstanceConfigPtrInput is an input type that accepts GoogleCloudAiplatformV1BatchPredictionJobInstanceConfigArgs, GoogleCloudAiplatformV1BatchPredictionJobInstanceConfigPtr and GoogleCloudAiplatformV1BatchPredictionJobInstanceConfigPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1BatchPredictionJobInstanceConfigPtrInput` via:
//
//	        GoogleCloudAiplatformV1BatchPredictionJobInstanceConfigArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1BatchPredictionJobInstanceConfigPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1BatchPredictionJobInstanceConfigPtrOutput() GoogleCloudAiplatformV1BatchPredictionJobInstanceConfigPtrOutput
	ToGoogleCloudAiplatformV1BatchPredictionJobInstanceConfigPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1BatchPredictionJobInstanceConfigPtrOutput
}

type googleCloudAiplatformV1BatchPredictionJobInstanceConfigPtrType GoogleCloudAiplatformV1BatchPredictionJobInstanceConfigArgs

func GoogleCloudAiplatformV1BatchPredictionJobInstanceConfigPtr(v *GoogleCloudAiplatformV1BatchPredictionJobInstanceConfigArgs) GoogleCloudAiplatformV1BatchPredictionJobInstanceConfigPtrInput {
	return (*googleCloudAiplatformV1BatchPredictionJobInstanceConfigPtrType)(v)
}

func (*googleCloudAiplatformV1BatchPredictionJobInstanceConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1BatchPredictionJobInstanceConfig)(nil)).Elem()
}

func (i *googleCloudAiplatformV1BatchPredictionJobInstanceConfigPtrType) ToGoogleCloudAiplatformV1BatchPredictionJobInstanceConfigPtrOutput() GoogleCloudAiplatformV1BatchPredictionJobInstanceConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1BatchPredictionJobInstanceConfigPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1BatchPredictionJobInstanceConfigPtrType) ToGoogleCloudAiplatformV1BatchPredictionJobInstanceConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1BatchPredictionJobInstanceConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1BatchPredictionJobInstanceConfigPtrOutput)
}

// Configuration defining how to transform batch prediction input instances to the instances that the Model accepts.
type GoogleCloudAiplatformV1BatchPredictionJobInstanceConfigOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1BatchPredictionJobInstanceConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1BatchPredictionJobInstanceConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1BatchPredictionJobInstanceConfigOutput) ToGoogleCloudAiplatformV1BatchPredictionJobInstanceConfigOutput() GoogleCloudAiplatformV1BatchPredictionJobInstanceConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1BatchPredictionJobInstanceConfigOutput) ToGoogleCloudAiplatformV1BatchPredictionJobInstanceConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1BatchPredictionJobInstanceConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1BatchPredictionJobInstanceConfigOutput) ToGoogleCloudAiplatformV1BatchPredictionJobInstanceConfigPtrOutput() GoogleCloudAiplatformV1BatchPredictionJobInstanceConfigPtrOutput {
	return o.ToGoogleCloudAiplatformV1BatchPredictionJobInstanceConfigPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1BatchPredictionJobInstanceConfigOutput) ToGoogleCloudAiplatformV1BatchPredictionJobInstanceConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1BatchPredictionJobInstanceConfigPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1BatchPredictionJobInstanceConfig) *GoogleCloudAiplatformV1BatchPredictionJobInstanceConfig {
		return &v
	}).(GoogleCloudAiplatformV1BatchPredictionJobInstanceConfigPtrOutput)
}

// Fields that will be excluded in the prediction instance that is sent to the Model. Excluded will be attached to the batch prediction output if key_field is not specified. When excluded_fields is populated, included_fields must be empty. The input must be JSONL with objects at each line, CSV, BigQuery or TfRecord.
func (o GoogleCloudAiplatformV1BatchPredictionJobInstanceConfigOutput) ExcludedFields() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1BatchPredictionJobInstanceConfig) []string { return v.ExcludedFields }).(pulumi.StringArrayOutput)
}

// Fields that will be included in the prediction instance that is sent to the Model. If instance_type is `array`, the order of field names in included_fields also determines the order of the values in the array. When included_fields is populated, excluded_fields must be empty. The input must be JSONL with objects at each line, CSV, BigQuery or TfRecord.
func (o GoogleCloudAiplatformV1BatchPredictionJobInstanceConfigOutput) IncludedFields() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1BatchPredictionJobInstanceConfig) []string { return v.IncludedFields }).(pulumi.StringArrayOutput)
}

// The format of the instance that the Model accepts. Vertex AI will convert compatible batch prediction input instance formats to the specified format. Supported values are: * `object`: Each input is converted to JSON object format. * For `bigquery`, each row is converted to an object. * For `jsonl`, each line of the JSONL input must be an object. * Does not apply to `csv`, `file-list`, `tf-record`, or `tf-record-gzip`. * `array`: Each input is converted to JSON array format. * For `bigquery`, each row is converted to an array. The order of columns is determined by the BigQuery column order, unless included_fields is populated. included_fields must be populated for specifying field orders. * For `jsonl`, if each line of the JSONL input is an object, included_fields must be populated for specifying field orders. * Does not apply to `csv`, `file-list`, `tf-record`, or `tf-record-gzip`. If not specified, Vertex AI converts the batch prediction input as follows: * For `bigquery` and `csv`, the behavior is the same as `array`. The order of columns is the same as defined in the file or table, unless included_fields is populated. * For `jsonl`, the prediction instance format is determined by each line of the input. * For `tf-record`/`tf-record-gzip`, each record will be converted to an object in the format of `{"b64": }`, where “is the Base64-encoded string of the content of the record. * For `file-list`, each file in the list will be converted to an object in the format of `{"b64": }`, where“ is the Base64-encoded string of the content of the file.
func (o GoogleCloudAiplatformV1BatchPredictionJobInstanceConfigOutput) InstanceType() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1BatchPredictionJobInstanceConfig) *string { return v.InstanceType }).(pulumi.StringPtrOutput)
}

// The name of the field that is considered as a key. The values identified by the key field is not included in the transformed instances that is sent to the Model. This is similar to specifying this name of the field in excluded_fields. In addition, the batch prediction output will not include the instances. Instead the output will only include the value of the key field, in a field named `key` in the output: * For `jsonl` output format, the output will have a `key` field instead of the `instance` field. * For `csv`/`bigquery` output format, the output will have have a `key` column instead of the instance feature columns. The input must be JSONL with objects at each line, CSV, BigQuery or TfRecord.
func (o GoogleCloudAiplatformV1BatchPredictionJobInstanceConfigOutput) KeyField() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1BatchPredictionJobInstanceConfig) *string { return v.KeyField }).(pulumi.StringPtrOutput)
}

type GoogleCloudAiplatformV1BatchPredictionJobInstanceConfigPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1BatchPredictionJobInstanceConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1BatchPredictionJobInstanceConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1BatchPredictionJobInstanceConfigPtrOutput) ToGoogleCloudAiplatformV1BatchPredictionJobInstanceConfigPtrOutput() GoogleCloudAiplatformV1BatchPredictionJobInstanceConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1BatchPredictionJobInstanceConfigPtrOutput) ToGoogleCloudAiplatformV1BatchPredictionJobInstanceConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1BatchPredictionJobInstanceConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1BatchPredictionJobInstanceConfigPtrOutput) Elem() GoogleCloudAiplatformV1BatchPredictionJobInstanceConfigOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1BatchPredictionJobInstanceConfig) GoogleCloudAiplatformV1BatchPredictionJobInstanceConfig {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1BatchPredictionJobInstanceConfig
		return ret
	}).(GoogleCloudAiplatformV1BatchPredictionJobInstanceConfigOutput)
}

// Fields that will be excluded in the prediction instance that is sent to the Model. Excluded will be attached to the batch prediction output if key_field is not specified. When excluded_fields is populated, included_fields must be empty. The input must be JSONL with objects at each line, CSV, BigQuery or TfRecord.
func (o GoogleCloudAiplatformV1BatchPredictionJobInstanceConfigPtrOutput) ExcludedFields() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1BatchPredictionJobInstanceConfig) []string {
		if v == nil {
			return nil
		}
		return v.ExcludedFields
	}).(pulumi.StringArrayOutput)
}

// Fields that will be included in the prediction instance that is sent to the Model. If instance_type is `array`, the order of field names in included_fields also determines the order of the values in the array. When included_fields is populated, excluded_fields must be empty. The input must be JSONL with objects at each line, CSV, BigQuery or TfRecord.
func (o GoogleCloudAiplatformV1BatchPredictionJobInstanceConfigPtrOutput) IncludedFields() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1BatchPredictionJobInstanceConfig) []string {
		if v == nil {
			return nil
		}
		return v.IncludedFields
	}).(pulumi.StringArrayOutput)
}

// The format of the instance that the Model accepts. Vertex AI will convert compatible batch prediction input instance formats to the specified format. Supported values are: * `object`: Each input is converted to JSON object format. * For `bigquery`, each row is converted to an object. * For `jsonl`, each line of the JSONL input must be an object. * Does not apply to `csv`, `file-list`, `tf-record`, or `tf-record-gzip`. * `array`: Each input is converted to JSON array format. * For `bigquery`, each row is converted to an array. The order of columns is determined by the BigQuery column order, unless included_fields is populated. included_fields must be populated for specifying field orders. * For `jsonl`, if each line of the JSONL input is an object, included_fields must be populated for specifying field orders. * Does not apply to `csv`, `file-list`, `tf-record`, or `tf-record-gzip`. If not specified, Vertex AI converts the batch prediction input as follows: * For `bigquery` and `csv`, the behavior is the same as `array`. The order of columns is the same as defined in the file or table, unless included_fields is populated. * For `jsonl`, the prediction instance format is determined by each line of the input. * For `tf-record`/`tf-record-gzip`, each record will be converted to an object in the format of `{"b64": }`, where “is the Base64-encoded string of the content of the record. * For `file-list`, each file in the list will be converted to an object in the format of `{"b64": }`, where“ is the Base64-encoded string of the content of the file.
func (o GoogleCloudAiplatformV1BatchPredictionJobInstanceConfigPtrOutput) InstanceType() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1BatchPredictionJobInstanceConfig) *string {
		if v == nil {
			return nil
		}
		return v.InstanceType
	}).(pulumi.StringPtrOutput)
}

// The name of the field that is considered as a key. The values identified by the key field is not included in the transformed instances that is sent to the Model. This is similar to specifying this name of the field in excluded_fields. In addition, the batch prediction output will not include the instances. Instead the output will only include the value of the key field, in a field named `key` in the output: * For `jsonl` output format, the output will have a `key` field instead of the `instance` field. * For `csv`/`bigquery` output format, the output will have have a `key` column instead of the instance feature columns. The input must be JSONL with objects at each line, CSV, BigQuery or TfRecord.
func (o GoogleCloudAiplatformV1BatchPredictionJobInstanceConfigPtrOutput) KeyField() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1BatchPredictionJobInstanceConfig) *string {
		if v == nil {
			return nil
		}
		return v.KeyField
	}).(pulumi.StringPtrOutput)
}

// Configuration defining how to transform batch prediction input instances to the instances that the Model accepts.
type GoogleCloudAiplatformV1BatchPredictionJobInstanceConfigResponse struct {
	// Fields that will be excluded in the prediction instance that is sent to the Model. Excluded will be attached to the batch prediction output if key_field is not specified. When excluded_fields is populated, included_fields must be empty. The input must be JSONL with objects at each line, CSV, BigQuery or TfRecord.
	ExcludedFields []string `pulumi:"excludedFields"`
	// Fields that will be included in the prediction instance that is sent to the Model. If instance_type is `array`, the order of field names in included_fields also determines the order of the values in the array. When included_fields is populated, excluded_fields must be empty. The input must be JSONL with objects at each line, CSV, BigQuery or TfRecord.
	IncludedFields []string `pulumi:"includedFields"`
	// The format of the instance that the Model accepts. Vertex AI will convert compatible batch prediction input instance formats to the specified format. Supported values are: * `object`: Each input is converted to JSON object format. * For `bigquery`, each row is converted to an object. * For `jsonl`, each line of the JSONL input must be an object. * Does not apply to `csv`, `file-list`, `tf-record`, or `tf-record-gzip`. * `array`: Each input is converted to JSON array format. * For `bigquery`, each row is converted to an array. The order of columns is determined by the BigQuery column order, unless included_fields is populated. included_fields must be populated for specifying field orders. * For `jsonl`, if each line of the JSONL input is an object, included_fields must be populated for specifying field orders. * Does not apply to `csv`, `file-list`, `tf-record`, or `tf-record-gzip`. If not specified, Vertex AI converts the batch prediction input as follows: * For `bigquery` and `csv`, the behavior is the same as `array`. The order of columns is the same as defined in the file or table, unless included_fields is populated. * For `jsonl`, the prediction instance format is determined by each line of the input. * For `tf-record`/`tf-record-gzip`, each record will be converted to an object in the format of `{"b64": }`, where ``is the Base64-encoded string of the content of the record. * For `file-list`, each file in the list will be converted to an object in the format of `{"b64": }`, where`` is the Base64-encoded string of the content of the file.
	InstanceType string `pulumi:"instanceType"`
	// The name of the field that is considered as a key. The values identified by the key field is not included in the transformed instances that is sent to the Model. This is similar to specifying this name of the field in excluded_fields. In addition, the batch prediction output will not include the instances. Instead the output will only include the value of the key field, in a field named `key` in the output: * For `jsonl` output format, the output will have a `key` field instead of the `instance` field. * For `csv`/`bigquery` output format, the output will have have a `key` column instead of the instance feature columns. The input must be JSONL with objects at each line, CSV, BigQuery or TfRecord.
	KeyField string `pulumi:"keyField"`
}

// Configuration defining how to transform batch prediction input instances to the instances that the Model accepts.
type GoogleCloudAiplatformV1BatchPredictionJobInstanceConfigResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1BatchPredictionJobInstanceConfigResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1BatchPredictionJobInstanceConfigResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1BatchPredictionJobInstanceConfigResponseOutput) ToGoogleCloudAiplatformV1BatchPredictionJobInstanceConfigResponseOutput() GoogleCloudAiplatformV1BatchPredictionJobInstanceConfigResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1BatchPredictionJobInstanceConfigResponseOutput) ToGoogleCloudAiplatformV1BatchPredictionJobInstanceConfigResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1BatchPredictionJobInstanceConfigResponseOutput {
	return o
}

// Fields that will be excluded in the prediction instance that is sent to the Model. Excluded will be attached to the batch prediction output if key_field is not specified. When excluded_fields is populated, included_fields must be empty. The input must be JSONL with objects at each line, CSV, BigQuery or TfRecord.
func (o GoogleCloudAiplatformV1BatchPredictionJobInstanceConfigResponseOutput) ExcludedFields() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1BatchPredictionJobInstanceConfigResponse) []string {
		return v.ExcludedFields
	}).(pulumi.StringArrayOutput)
}

// Fields that will be included in the prediction instance that is sent to the Model. If instance_type is `array`, the order of field names in included_fields also determines the order of the values in the array. When included_fields is populated, excluded_fields must be empty. The input must be JSONL with objects at each line, CSV, BigQuery or TfRecord.
func (o GoogleCloudAiplatformV1BatchPredictionJobInstanceConfigResponseOutput) IncludedFields() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1BatchPredictionJobInstanceConfigResponse) []string {
		return v.IncludedFields
	}).(pulumi.StringArrayOutput)
}

// The format of the instance that the Model accepts. Vertex AI will convert compatible batch prediction input instance formats to the specified format. Supported values are: * `object`: Each input is converted to JSON object format. * For `bigquery`, each row is converted to an object. * For `jsonl`, each line of the JSONL input must be an object. * Does not apply to `csv`, `file-list`, `tf-record`, or `tf-record-gzip`. * `array`: Each input is converted to JSON array format. * For `bigquery`, each row is converted to an array. The order of columns is determined by the BigQuery column order, unless included_fields is populated. included_fields must be populated for specifying field orders. * For `jsonl`, if each line of the JSONL input is an object, included_fields must be populated for specifying field orders. * Does not apply to `csv`, `file-list`, `tf-record`, or `tf-record-gzip`. If not specified, Vertex AI converts the batch prediction input as follows: * For `bigquery` and `csv`, the behavior is the same as `array`. The order of columns is the same as defined in the file or table, unless included_fields is populated. * For `jsonl`, the prediction instance format is determined by each line of the input. * For `tf-record`/`tf-record-gzip`, each record will be converted to an object in the format of `{"b64": }`, where “is the Base64-encoded string of the content of the record. * For `file-list`, each file in the list will be converted to an object in the format of `{"b64": }`, where“ is the Base64-encoded string of the content of the file.
func (o GoogleCloudAiplatformV1BatchPredictionJobInstanceConfigResponseOutput) InstanceType() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1BatchPredictionJobInstanceConfigResponse) string { return v.InstanceType }).(pulumi.StringOutput)
}

// The name of the field that is considered as a key. The values identified by the key field is not included in the transformed instances that is sent to the Model. This is similar to specifying this name of the field in excluded_fields. In addition, the batch prediction output will not include the instances. Instead the output will only include the value of the key field, in a field named `key` in the output: * For `jsonl` output format, the output will have a `key` field instead of the `instance` field. * For `csv`/`bigquery` output format, the output will have have a `key` column instead of the instance feature columns. The input must be JSONL with objects at each line, CSV, BigQuery or TfRecord.
func (o GoogleCloudAiplatformV1BatchPredictionJobInstanceConfigResponseOutput) KeyField() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1BatchPredictionJobInstanceConfigResponse) string { return v.KeyField }).(pulumi.StringOutput)
}

// Configures the output of BatchPredictionJob. See Model.supported_output_storage_formats for supported output formats, and how predictions are expressed via any of them.
type GoogleCloudAiplatformV1BatchPredictionJobOutputConfig struct {
	// The BigQuery project or dataset location where the output is to be written to. If project is provided, a new dataset is created with name `prediction__` where is made BigQuery-dataset-name compatible (for example, most special characters become underscores), and timestamp is in YYYY_MM_DDThh_mm_ss_sssZ "based on ISO-8601" format. In the dataset two tables will be created, `predictions`, and `errors`. If the Model has both instance and prediction schemata defined then the tables have columns as follows: The `predictions` table contains instances for which the prediction succeeded, it has columns as per a concatenation of the Model's instance and prediction schemata. The `errors` table contains rows for which the prediction has failed, it has instance columns, as per the instance schema, followed by a single "errors" column, which as values has google.rpc.Status represented as a STRUCT, and containing only `code` and `message`.
	BigqueryDestination *GoogleCloudAiplatformV1BigQueryDestination `pulumi:"bigqueryDestination"`
	// The Cloud Storage location of the directory where the output is to be written to. In the given directory a new directory is created. Its name is `prediction--`, where timestamp is in YYYY-MM-DDThh:mm:ss.sssZ ISO-8601 format. Inside of it files `predictions_0001.`, `predictions_0002.`, ..., `predictions_N.` are created where `` depends on chosen predictions_format, and N may equal 0001 and depends on the total number of successfully predicted instances. If the Model has both instance and prediction schemata defined then each such file contains predictions as per the predictions_format. If prediction for any instance failed (partially or completely), then an additional `errors_0001.`, `errors_0002.`,..., `errors_N.` files are created (N depends on total number of failed predictions). These files contain the failed instances, as per their schema, followed by an additional `error` field which as value has google.rpc.Status containing only `code` and `message` fields.
	GcsDestination *GoogleCloudAiplatformV1GcsDestination `pulumi:"gcsDestination"`
	// The format in which Vertex AI gives the predictions, must be one of the Model's supported_output_storage_formats.
	PredictionsFormat string `pulumi:"predictionsFormat"`
}

// GoogleCloudAiplatformV1BatchPredictionJobOutputConfigInput is an input type that accepts GoogleCloudAiplatformV1BatchPredictionJobOutputConfigArgs and GoogleCloudAiplatformV1BatchPredictionJobOutputConfigOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1BatchPredictionJobOutputConfigInput` via:
//
//	GoogleCloudAiplatformV1BatchPredictionJobOutputConfigArgs{...}
type GoogleCloudAiplatformV1BatchPredictionJobOutputConfigInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1BatchPredictionJobOutputConfigOutput() GoogleCloudAiplatformV1BatchPredictionJobOutputConfigOutput
	ToGoogleCloudAiplatformV1BatchPredictionJobOutputConfigOutputWithContext(context.Context) GoogleCloudAiplatformV1BatchPredictionJobOutputConfigOutput
}

// Configures the output of BatchPredictionJob. See Model.supported_output_storage_formats for supported output formats, and how predictions are expressed via any of them.
type GoogleCloudAiplatformV1BatchPredictionJobOutputConfigArgs struct {
	// The BigQuery project or dataset location where the output is to be written to. If project is provided, a new dataset is created with name `prediction__` where is made BigQuery-dataset-name compatible (for example, most special characters become underscores), and timestamp is in YYYY_MM_DDThh_mm_ss_sssZ "based on ISO-8601" format. In the dataset two tables will be created, `predictions`, and `errors`. If the Model has both instance and prediction schemata defined then the tables have columns as follows: The `predictions` table contains instances for which the prediction succeeded, it has columns as per a concatenation of the Model's instance and prediction schemata. The `errors` table contains rows for which the prediction has failed, it has instance columns, as per the instance schema, followed by a single "errors" column, which as values has google.rpc.Status represented as a STRUCT, and containing only `code` and `message`.
	BigqueryDestination GoogleCloudAiplatformV1BigQueryDestinationPtrInput `pulumi:"bigqueryDestination"`
	// The Cloud Storage location of the directory where the output is to be written to. In the given directory a new directory is created. Its name is `prediction--`, where timestamp is in YYYY-MM-DDThh:mm:ss.sssZ ISO-8601 format. Inside of it files `predictions_0001.`, `predictions_0002.`, ..., `predictions_N.` are created where `` depends on chosen predictions_format, and N may equal 0001 and depends on the total number of successfully predicted instances. If the Model has both instance and prediction schemata defined then each such file contains predictions as per the predictions_format. If prediction for any instance failed (partially or completely), then an additional `errors_0001.`, `errors_0002.`,..., `errors_N.` files are created (N depends on total number of failed predictions). These files contain the failed instances, as per their schema, followed by an additional `error` field which as value has google.rpc.Status containing only `code` and `message` fields.
	GcsDestination GoogleCloudAiplatformV1GcsDestinationPtrInput `pulumi:"gcsDestination"`
	// The format in which Vertex AI gives the predictions, must be one of the Model's supported_output_storage_formats.
	PredictionsFormat pulumi.StringInput `pulumi:"predictionsFormat"`
}

func (GoogleCloudAiplatformV1BatchPredictionJobOutputConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1BatchPredictionJobOutputConfig)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1BatchPredictionJobOutputConfigArgs) ToGoogleCloudAiplatformV1BatchPredictionJobOutputConfigOutput() GoogleCloudAiplatformV1BatchPredictionJobOutputConfigOutput {
	return i.ToGoogleCloudAiplatformV1BatchPredictionJobOutputConfigOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1BatchPredictionJobOutputConfigArgs) ToGoogleCloudAiplatformV1BatchPredictionJobOutputConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1BatchPredictionJobOutputConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1BatchPredictionJobOutputConfigOutput)
}

// Configures the output of BatchPredictionJob. See Model.supported_output_storage_formats for supported output formats, and how predictions are expressed via any of them.
type GoogleCloudAiplatformV1BatchPredictionJobOutputConfigOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1BatchPredictionJobOutputConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1BatchPredictionJobOutputConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1BatchPredictionJobOutputConfigOutput) ToGoogleCloudAiplatformV1BatchPredictionJobOutputConfigOutput() GoogleCloudAiplatformV1BatchPredictionJobOutputConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1BatchPredictionJobOutputConfigOutput) ToGoogleCloudAiplatformV1BatchPredictionJobOutputConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1BatchPredictionJobOutputConfigOutput {
	return o
}

// The BigQuery project or dataset location where the output is to be written to. If project is provided, a new dataset is created with name `prediction__` where is made BigQuery-dataset-name compatible (for example, most special characters become underscores), and timestamp is in YYYY_MM_DDThh_mm_ss_sssZ "based on ISO-8601" format. In the dataset two tables will be created, `predictions`, and `errors`. If the Model has both instance and prediction schemata defined then the tables have columns as follows: The `predictions` table contains instances for which the prediction succeeded, it has columns as per a concatenation of the Model's instance and prediction schemata. The `errors` table contains rows for which the prediction has failed, it has instance columns, as per the instance schema, followed by a single "errors" column, which as values has google.rpc.Status represented as a STRUCT, and containing only `code` and `message`.
func (o GoogleCloudAiplatformV1BatchPredictionJobOutputConfigOutput) BigqueryDestination() GoogleCloudAiplatformV1BigQueryDestinationPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1BatchPredictionJobOutputConfig) *GoogleCloudAiplatformV1BigQueryDestination {
		return v.BigqueryDestination
	}).(GoogleCloudAiplatformV1BigQueryDestinationPtrOutput)
}

// The Cloud Storage location of the directory where the output is to be written to. In the given directory a new directory is created. Its name is `prediction--`, where timestamp is in YYYY-MM-DDThh:mm:ss.sssZ ISO-8601 format. Inside of it files `predictions_0001.`, `predictions_0002.`, ..., `predictions_N.` are created where “ depends on chosen predictions_format, and N may equal 0001 and depends on the total number of successfully predicted instances. If the Model has both instance and prediction schemata defined then each such file contains predictions as per the predictions_format. If prediction for any instance failed (partially or completely), then an additional `errors_0001.`, `errors_0002.`,..., `errors_N.` files are created (N depends on total number of failed predictions). These files contain the failed instances, as per their schema, followed by an additional `error` field which as value has google.rpc.Status containing only `code` and `message` fields.
func (o GoogleCloudAiplatformV1BatchPredictionJobOutputConfigOutput) GcsDestination() GoogleCloudAiplatformV1GcsDestinationPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1BatchPredictionJobOutputConfig) *GoogleCloudAiplatformV1GcsDestination {
		return v.GcsDestination
	}).(GoogleCloudAiplatformV1GcsDestinationPtrOutput)
}

// The format in which Vertex AI gives the predictions, must be one of the Model's supported_output_storage_formats.
func (o GoogleCloudAiplatformV1BatchPredictionJobOutputConfigOutput) PredictionsFormat() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1BatchPredictionJobOutputConfig) string { return v.PredictionsFormat }).(pulumi.StringOutput)
}

// Configures the output of BatchPredictionJob. See Model.supported_output_storage_formats for supported output formats, and how predictions are expressed via any of them.
type GoogleCloudAiplatformV1BatchPredictionJobOutputConfigResponse struct {
	// The BigQuery project or dataset location where the output is to be written to. If project is provided, a new dataset is created with name `prediction__` where is made BigQuery-dataset-name compatible (for example, most special characters become underscores), and timestamp is in YYYY_MM_DDThh_mm_ss_sssZ "based on ISO-8601" format. In the dataset two tables will be created, `predictions`, and `errors`. If the Model has both instance and prediction schemata defined then the tables have columns as follows: The `predictions` table contains instances for which the prediction succeeded, it has columns as per a concatenation of the Model's instance and prediction schemata. The `errors` table contains rows for which the prediction has failed, it has instance columns, as per the instance schema, followed by a single "errors" column, which as values has google.rpc.Status represented as a STRUCT, and containing only `code` and `message`.
	BigqueryDestination GoogleCloudAiplatformV1BigQueryDestinationResponse `pulumi:"bigqueryDestination"`
	// The Cloud Storage location of the directory where the output is to be written to. In the given directory a new directory is created. Its name is `prediction--`, where timestamp is in YYYY-MM-DDThh:mm:ss.sssZ ISO-8601 format. Inside of it files `predictions_0001.`, `predictions_0002.`, ..., `predictions_N.` are created where `` depends on chosen predictions_format, and N may equal 0001 and depends on the total number of successfully predicted instances. If the Model has both instance and prediction schemata defined then each such file contains predictions as per the predictions_format. If prediction for any instance failed (partially or completely), then an additional `errors_0001.`, `errors_0002.`,..., `errors_N.` files are created (N depends on total number of failed predictions). These files contain the failed instances, as per their schema, followed by an additional `error` field which as value has google.rpc.Status containing only `code` and `message` fields.
	GcsDestination GoogleCloudAiplatformV1GcsDestinationResponse `pulumi:"gcsDestination"`
	// The format in which Vertex AI gives the predictions, must be one of the Model's supported_output_storage_formats.
	PredictionsFormat string `pulumi:"predictionsFormat"`
}

// Configures the output of BatchPredictionJob. See Model.supported_output_storage_formats for supported output formats, and how predictions are expressed via any of them.
type GoogleCloudAiplatformV1BatchPredictionJobOutputConfigResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1BatchPredictionJobOutputConfigResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1BatchPredictionJobOutputConfigResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1BatchPredictionJobOutputConfigResponseOutput) ToGoogleCloudAiplatformV1BatchPredictionJobOutputConfigResponseOutput() GoogleCloudAiplatformV1BatchPredictionJobOutputConfigResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1BatchPredictionJobOutputConfigResponseOutput) ToGoogleCloudAiplatformV1BatchPredictionJobOutputConfigResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1BatchPredictionJobOutputConfigResponseOutput {
	return o
}

// The BigQuery project or dataset location where the output is to be written to. If project is provided, a new dataset is created with name `prediction__` where is made BigQuery-dataset-name compatible (for example, most special characters become underscores), and timestamp is in YYYY_MM_DDThh_mm_ss_sssZ "based on ISO-8601" format. In the dataset two tables will be created, `predictions`, and `errors`. If the Model has both instance and prediction schemata defined then the tables have columns as follows: The `predictions` table contains instances for which the prediction succeeded, it has columns as per a concatenation of the Model's instance and prediction schemata. The `errors` table contains rows for which the prediction has failed, it has instance columns, as per the instance schema, followed by a single "errors" column, which as values has google.rpc.Status represented as a STRUCT, and containing only `code` and `message`.
func (o GoogleCloudAiplatformV1BatchPredictionJobOutputConfigResponseOutput) BigqueryDestination() GoogleCloudAiplatformV1BigQueryDestinationResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1BatchPredictionJobOutputConfigResponse) GoogleCloudAiplatformV1BigQueryDestinationResponse {
		return v.BigqueryDestination
	}).(GoogleCloudAiplatformV1BigQueryDestinationResponseOutput)
}

// The Cloud Storage location of the directory where the output is to be written to. In the given directory a new directory is created. Its name is `prediction--`, where timestamp is in YYYY-MM-DDThh:mm:ss.sssZ ISO-8601 format. Inside of it files `predictions_0001.`, `predictions_0002.`, ..., `predictions_N.` are created where “ depends on chosen predictions_format, and N may equal 0001 and depends on the total number of successfully predicted instances. If the Model has both instance and prediction schemata defined then each such file contains predictions as per the predictions_format. If prediction for any instance failed (partially or completely), then an additional `errors_0001.`, `errors_0002.`,..., `errors_N.` files are created (N depends on total number of failed predictions). These files contain the failed instances, as per their schema, followed by an additional `error` field which as value has google.rpc.Status containing only `code` and `message` fields.
func (o GoogleCloudAiplatformV1BatchPredictionJobOutputConfigResponseOutput) GcsDestination() GoogleCloudAiplatformV1GcsDestinationResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1BatchPredictionJobOutputConfigResponse) GoogleCloudAiplatformV1GcsDestinationResponse {
		return v.GcsDestination
	}).(GoogleCloudAiplatformV1GcsDestinationResponseOutput)
}

// The format in which Vertex AI gives the predictions, must be one of the Model's supported_output_storage_formats.
func (o GoogleCloudAiplatformV1BatchPredictionJobOutputConfigResponseOutput) PredictionsFormat() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1BatchPredictionJobOutputConfigResponse) string {
		return v.PredictionsFormat
	}).(pulumi.StringOutput)
}

// Further describes this job's output. Supplements output_config.
type GoogleCloudAiplatformV1BatchPredictionJobOutputInfoResponse struct {
	// The path of the BigQuery dataset created, in `bq://projectId.bqDatasetId` format, into which the prediction output is written.
	BigqueryOutputDataset string `pulumi:"bigqueryOutputDataset"`
	// The name of the BigQuery table created, in `predictions_` format, into which the prediction output is written. Can be used by UI to generate the BigQuery output path, for example.
	BigqueryOutputTable string `pulumi:"bigqueryOutputTable"`
	// The full path of the Cloud Storage directory created, into which the prediction output is written.
	GcsOutputDirectory string `pulumi:"gcsOutputDirectory"`
}

// Further describes this job's output. Supplements output_config.
type GoogleCloudAiplatformV1BatchPredictionJobOutputInfoResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1BatchPredictionJobOutputInfoResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1BatchPredictionJobOutputInfoResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1BatchPredictionJobOutputInfoResponseOutput) ToGoogleCloudAiplatformV1BatchPredictionJobOutputInfoResponseOutput() GoogleCloudAiplatformV1BatchPredictionJobOutputInfoResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1BatchPredictionJobOutputInfoResponseOutput) ToGoogleCloudAiplatformV1BatchPredictionJobOutputInfoResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1BatchPredictionJobOutputInfoResponseOutput {
	return o
}

// The path of the BigQuery dataset created, in `bq://projectId.bqDatasetId` format, into which the prediction output is written.
func (o GoogleCloudAiplatformV1BatchPredictionJobOutputInfoResponseOutput) BigqueryOutputDataset() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1BatchPredictionJobOutputInfoResponse) string {
		return v.BigqueryOutputDataset
	}).(pulumi.StringOutput)
}

// The name of the BigQuery table created, in `predictions_` format, into which the prediction output is written. Can be used by UI to generate the BigQuery output path, for example.
func (o GoogleCloudAiplatformV1BatchPredictionJobOutputInfoResponseOutput) BigqueryOutputTable() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1BatchPredictionJobOutputInfoResponse) string {
		return v.BigqueryOutputTable
	}).(pulumi.StringOutput)
}

// The full path of the Cloud Storage directory created, into which the prediction output is written.
func (o GoogleCloudAiplatformV1BatchPredictionJobOutputInfoResponseOutput) GcsOutputDirectory() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1BatchPredictionJobOutputInfoResponse) string {
		return v.GcsOutputDirectory
	}).(pulumi.StringOutput)
}

// The BigQuery location for the output content.
type GoogleCloudAiplatformV1BigQueryDestination struct {
	// BigQuery URI to a project or table, up to 2000 characters long. When only the project is specified, the Dataset and Table is created. When the full table reference is specified, the Dataset must exist and table must not exist. Accepted forms: * BigQuery path. For example: `bq://projectId` or `bq://projectId.bqDatasetId` or `bq://projectId.bqDatasetId.bqTableId`.
	OutputUri string `pulumi:"outputUri"`
}

// GoogleCloudAiplatformV1BigQueryDestinationInput is an input type that accepts GoogleCloudAiplatformV1BigQueryDestinationArgs and GoogleCloudAiplatformV1BigQueryDestinationOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1BigQueryDestinationInput` via:
//
//	GoogleCloudAiplatformV1BigQueryDestinationArgs{...}
type GoogleCloudAiplatformV1BigQueryDestinationInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1BigQueryDestinationOutput() GoogleCloudAiplatformV1BigQueryDestinationOutput
	ToGoogleCloudAiplatformV1BigQueryDestinationOutputWithContext(context.Context) GoogleCloudAiplatformV1BigQueryDestinationOutput
}

// The BigQuery location for the output content.
type GoogleCloudAiplatformV1BigQueryDestinationArgs struct {
	// BigQuery URI to a project or table, up to 2000 characters long. When only the project is specified, the Dataset and Table is created. When the full table reference is specified, the Dataset must exist and table must not exist. Accepted forms: * BigQuery path. For example: `bq://projectId` or `bq://projectId.bqDatasetId` or `bq://projectId.bqDatasetId.bqTableId`.
	OutputUri pulumi.StringInput `pulumi:"outputUri"`
}

func (GoogleCloudAiplatformV1BigQueryDestinationArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1BigQueryDestination)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1BigQueryDestinationArgs) ToGoogleCloudAiplatformV1BigQueryDestinationOutput() GoogleCloudAiplatformV1BigQueryDestinationOutput {
	return i.ToGoogleCloudAiplatformV1BigQueryDestinationOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1BigQueryDestinationArgs) ToGoogleCloudAiplatformV1BigQueryDestinationOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1BigQueryDestinationOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1BigQueryDestinationOutput)
}

func (i GoogleCloudAiplatformV1BigQueryDestinationArgs) ToGoogleCloudAiplatformV1BigQueryDestinationPtrOutput() GoogleCloudAiplatformV1BigQueryDestinationPtrOutput {
	return i.ToGoogleCloudAiplatformV1BigQueryDestinationPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1BigQueryDestinationArgs) ToGoogleCloudAiplatformV1BigQueryDestinationPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1BigQueryDestinationPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1BigQueryDestinationOutput).ToGoogleCloudAiplatformV1BigQueryDestinationPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1BigQueryDestinationPtrInput is an input type that accepts GoogleCloudAiplatformV1BigQueryDestinationArgs, GoogleCloudAiplatformV1BigQueryDestinationPtr and GoogleCloudAiplatformV1BigQueryDestinationPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1BigQueryDestinationPtrInput` via:
//
//	        GoogleCloudAiplatformV1BigQueryDestinationArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1BigQueryDestinationPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1BigQueryDestinationPtrOutput() GoogleCloudAiplatformV1BigQueryDestinationPtrOutput
	ToGoogleCloudAiplatformV1BigQueryDestinationPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1BigQueryDestinationPtrOutput
}

type googleCloudAiplatformV1BigQueryDestinationPtrType GoogleCloudAiplatformV1BigQueryDestinationArgs

func GoogleCloudAiplatformV1BigQueryDestinationPtr(v *GoogleCloudAiplatformV1BigQueryDestinationArgs) GoogleCloudAiplatformV1BigQueryDestinationPtrInput {
	return (*googleCloudAiplatformV1BigQueryDestinationPtrType)(v)
}

func (*googleCloudAiplatformV1BigQueryDestinationPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1BigQueryDestination)(nil)).Elem()
}

func (i *googleCloudAiplatformV1BigQueryDestinationPtrType) ToGoogleCloudAiplatformV1BigQueryDestinationPtrOutput() GoogleCloudAiplatformV1BigQueryDestinationPtrOutput {
	return i.ToGoogleCloudAiplatformV1BigQueryDestinationPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1BigQueryDestinationPtrType) ToGoogleCloudAiplatformV1BigQueryDestinationPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1BigQueryDestinationPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1BigQueryDestinationPtrOutput)
}

// The BigQuery location for the output content.
type GoogleCloudAiplatformV1BigQueryDestinationOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1BigQueryDestinationOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1BigQueryDestination)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1BigQueryDestinationOutput) ToGoogleCloudAiplatformV1BigQueryDestinationOutput() GoogleCloudAiplatformV1BigQueryDestinationOutput {
	return o
}

func (o GoogleCloudAiplatformV1BigQueryDestinationOutput) ToGoogleCloudAiplatformV1BigQueryDestinationOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1BigQueryDestinationOutput {
	return o
}

func (o GoogleCloudAiplatformV1BigQueryDestinationOutput) ToGoogleCloudAiplatformV1BigQueryDestinationPtrOutput() GoogleCloudAiplatformV1BigQueryDestinationPtrOutput {
	return o.ToGoogleCloudAiplatformV1BigQueryDestinationPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1BigQueryDestinationOutput) ToGoogleCloudAiplatformV1BigQueryDestinationPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1BigQueryDestinationPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1BigQueryDestination) *GoogleCloudAiplatformV1BigQueryDestination {
		return &v
	}).(GoogleCloudAiplatformV1BigQueryDestinationPtrOutput)
}

// BigQuery URI to a project or table, up to 2000 characters long. When only the project is specified, the Dataset and Table is created. When the full table reference is specified, the Dataset must exist and table must not exist. Accepted forms: * BigQuery path. For example: `bq://projectId` or `bq://projectId.bqDatasetId` or `bq://projectId.bqDatasetId.bqTableId`.
func (o GoogleCloudAiplatformV1BigQueryDestinationOutput) OutputUri() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1BigQueryDestination) string { return v.OutputUri }).(pulumi.StringOutput)
}

type GoogleCloudAiplatformV1BigQueryDestinationPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1BigQueryDestinationPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1BigQueryDestination)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1BigQueryDestinationPtrOutput) ToGoogleCloudAiplatformV1BigQueryDestinationPtrOutput() GoogleCloudAiplatformV1BigQueryDestinationPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1BigQueryDestinationPtrOutput) ToGoogleCloudAiplatformV1BigQueryDestinationPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1BigQueryDestinationPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1BigQueryDestinationPtrOutput) Elem() GoogleCloudAiplatformV1BigQueryDestinationOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1BigQueryDestination) GoogleCloudAiplatformV1BigQueryDestination {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1BigQueryDestination
		return ret
	}).(GoogleCloudAiplatformV1BigQueryDestinationOutput)
}

// BigQuery URI to a project or table, up to 2000 characters long. When only the project is specified, the Dataset and Table is created. When the full table reference is specified, the Dataset must exist and table must not exist. Accepted forms: * BigQuery path. For example: `bq://projectId` or `bq://projectId.bqDatasetId` or `bq://projectId.bqDatasetId.bqTableId`.
func (o GoogleCloudAiplatformV1BigQueryDestinationPtrOutput) OutputUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1BigQueryDestination) *string {
		if v == nil {
			return nil
		}
		return &v.OutputUri
	}).(pulumi.StringPtrOutput)
}

// The BigQuery location for the output content.
type GoogleCloudAiplatformV1BigQueryDestinationResponse struct {
	// BigQuery URI to a project or table, up to 2000 characters long. When only the project is specified, the Dataset and Table is created. When the full table reference is specified, the Dataset must exist and table must not exist. Accepted forms: * BigQuery path. For example: `bq://projectId` or `bq://projectId.bqDatasetId` or `bq://projectId.bqDatasetId.bqTableId`.
	OutputUri string `pulumi:"outputUri"`
}

// The BigQuery location for the output content.
type GoogleCloudAiplatformV1BigQueryDestinationResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1BigQueryDestinationResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1BigQueryDestinationResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1BigQueryDestinationResponseOutput) ToGoogleCloudAiplatformV1BigQueryDestinationResponseOutput() GoogleCloudAiplatformV1BigQueryDestinationResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1BigQueryDestinationResponseOutput) ToGoogleCloudAiplatformV1BigQueryDestinationResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1BigQueryDestinationResponseOutput {
	return o
}

// BigQuery URI to a project or table, up to 2000 characters long. When only the project is specified, the Dataset and Table is created. When the full table reference is specified, the Dataset must exist and table must not exist. Accepted forms: * BigQuery path. For example: `bq://projectId` or `bq://projectId.bqDatasetId` or `bq://projectId.bqDatasetId.bqTableId`.
func (o GoogleCloudAiplatformV1BigQueryDestinationResponseOutput) OutputUri() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1BigQueryDestinationResponse) string { return v.OutputUri }).(pulumi.StringOutput)
}

// The BigQuery location for the input content.
type GoogleCloudAiplatformV1BigQuerySource struct {
	// BigQuery URI to a table, up to 2000 characters long. Accepted forms: * BigQuery path. For example: `bq://projectId.bqDatasetId.bqTableId`.
	InputUri string `pulumi:"inputUri"`
}

// GoogleCloudAiplatformV1BigQuerySourceInput is an input type that accepts GoogleCloudAiplatformV1BigQuerySourceArgs and GoogleCloudAiplatformV1BigQuerySourceOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1BigQuerySourceInput` via:
//
//	GoogleCloudAiplatformV1BigQuerySourceArgs{...}
type GoogleCloudAiplatformV1BigQuerySourceInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1BigQuerySourceOutput() GoogleCloudAiplatformV1BigQuerySourceOutput
	ToGoogleCloudAiplatformV1BigQuerySourceOutputWithContext(context.Context) GoogleCloudAiplatformV1BigQuerySourceOutput
}

// The BigQuery location for the input content.
type GoogleCloudAiplatformV1BigQuerySourceArgs struct {
	// BigQuery URI to a table, up to 2000 characters long. Accepted forms: * BigQuery path. For example: `bq://projectId.bqDatasetId.bqTableId`.
	InputUri pulumi.StringInput `pulumi:"inputUri"`
}

func (GoogleCloudAiplatformV1BigQuerySourceArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1BigQuerySource)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1BigQuerySourceArgs) ToGoogleCloudAiplatformV1BigQuerySourceOutput() GoogleCloudAiplatformV1BigQuerySourceOutput {
	return i.ToGoogleCloudAiplatformV1BigQuerySourceOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1BigQuerySourceArgs) ToGoogleCloudAiplatformV1BigQuerySourceOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1BigQuerySourceOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1BigQuerySourceOutput)
}

func (i GoogleCloudAiplatformV1BigQuerySourceArgs) ToGoogleCloudAiplatformV1BigQuerySourcePtrOutput() GoogleCloudAiplatformV1BigQuerySourcePtrOutput {
	return i.ToGoogleCloudAiplatformV1BigQuerySourcePtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1BigQuerySourceArgs) ToGoogleCloudAiplatformV1BigQuerySourcePtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1BigQuerySourcePtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1BigQuerySourceOutput).ToGoogleCloudAiplatformV1BigQuerySourcePtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1BigQuerySourcePtrInput is an input type that accepts GoogleCloudAiplatformV1BigQuerySourceArgs, GoogleCloudAiplatformV1BigQuerySourcePtr and GoogleCloudAiplatformV1BigQuerySourcePtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1BigQuerySourcePtrInput` via:
//
//	        GoogleCloudAiplatformV1BigQuerySourceArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1BigQuerySourcePtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1BigQuerySourcePtrOutput() GoogleCloudAiplatformV1BigQuerySourcePtrOutput
	ToGoogleCloudAiplatformV1BigQuerySourcePtrOutputWithContext(context.Context) GoogleCloudAiplatformV1BigQuerySourcePtrOutput
}

type googleCloudAiplatformV1BigQuerySourcePtrType GoogleCloudAiplatformV1BigQuerySourceArgs

func GoogleCloudAiplatformV1BigQuerySourcePtr(v *GoogleCloudAiplatformV1BigQuerySourceArgs) GoogleCloudAiplatformV1BigQuerySourcePtrInput {
	return (*googleCloudAiplatformV1BigQuerySourcePtrType)(v)
}

func (*googleCloudAiplatformV1BigQuerySourcePtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1BigQuerySource)(nil)).Elem()
}

func (i *googleCloudAiplatformV1BigQuerySourcePtrType) ToGoogleCloudAiplatformV1BigQuerySourcePtrOutput() GoogleCloudAiplatformV1BigQuerySourcePtrOutput {
	return i.ToGoogleCloudAiplatformV1BigQuerySourcePtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1BigQuerySourcePtrType) ToGoogleCloudAiplatformV1BigQuerySourcePtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1BigQuerySourcePtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1BigQuerySourcePtrOutput)
}

// The BigQuery location for the input content.
type GoogleCloudAiplatformV1BigQuerySourceOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1BigQuerySourceOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1BigQuerySource)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1BigQuerySourceOutput) ToGoogleCloudAiplatformV1BigQuerySourceOutput() GoogleCloudAiplatformV1BigQuerySourceOutput {
	return o
}

func (o GoogleCloudAiplatformV1BigQuerySourceOutput) ToGoogleCloudAiplatformV1BigQuerySourceOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1BigQuerySourceOutput {
	return o
}

func (o GoogleCloudAiplatformV1BigQuerySourceOutput) ToGoogleCloudAiplatformV1BigQuerySourcePtrOutput() GoogleCloudAiplatformV1BigQuerySourcePtrOutput {
	return o.ToGoogleCloudAiplatformV1BigQuerySourcePtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1BigQuerySourceOutput) ToGoogleCloudAiplatformV1BigQuerySourcePtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1BigQuerySourcePtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1BigQuerySource) *GoogleCloudAiplatformV1BigQuerySource {
		return &v
	}).(GoogleCloudAiplatformV1BigQuerySourcePtrOutput)
}

// BigQuery URI to a table, up to 2000 characters long. Accepted forms: * BigQuery path. For example: `bq://projectId.bqDatasetId.bqTableId`.
func (o GoogleCloudAiplatformV1BigQuerySourceOutput) InputUri() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1BigQuerySource) string { return v.InputUri }).(pulumi.StringOutput)
}

type GoogleCloudAiplatformV1BigQuerySourcePtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1BigQuerySourcePtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1BigQuerySource)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1BigQuerySourcePtrOutput) ToGoogleCloudAiplatformV1BigQuerySourcePtrOutput() GoogleCloudAiplatformV1BigQuerySourcePtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1BigQuerySourcePtrOutput) ToGoogleCloudAiplatformV1BigQuerySourcePtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1BigQuerySourcePtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1BigQuerySourcePtrOutput) Elem() GoogleCloudAiplatformV1BigQuerySourceOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1BigQuerySource) GoogleCloudAiplatformV1BigQuerySource {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1BigQuerySource
		return ret
	}).(GoogleCloudAiplatformV1BigQuerySourceOutput)
}

// BigQuery URI to a table, up to 2000 characters long. Accepted forms: * BigQuery path. For example: `bq://projectId.bqDatasetId.bqTableId`.
func (o GoogleCloudAiplatformV1BigQuerySourcePtrOutput) InputUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1BigQuerySource) *string {
		if v == nil {
			return nil
		}
		return &v.InputUri
	}).(pulumi.StringPtrOutput)
}

// The BigQuery location for the input content.
type GoogleCloudAiplatformV1BigQuerySourceResponse struct {
	// BigQuery URI to a table, up to 2000 characters long. Accepted forms: * BigQuery path. For example: `bq://projectId.bqDatasetId.bqTableId`.
	InputUri string `pulumi:"inputUri"`
}

// The BigQuery location for the input content.
type GoogleCloudAiplatformV1BigQuerySourceResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1BigQuerySourceResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1BigQuerySourceResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1BigQuerySourceResponseOutput) ToGoogleCloudAiplatformV1BigQuerySourceResponseOutput() GoogleCloudAiplatformV1BigQuerySourceResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1BigQuerySourceResponseOutput) ToGoogleCloudAiplatformV1BigQuerySourceResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1BigQuerySourceResponseOutput {
	return o
}

// BigQuery URI to a table, up to 2000 characters long. Accepted forms: * BigQuery path. For example: `bq://projectId.bqDatasetId.bqTableId`.
func (o GoogleCloudAiplatformV1BigQuerySourceResponseOutput) InputUri() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1BigQuerySourceResponse) string { return v.InputUri }).(pulumi.StringOutput)
}

// Config for blur baseline. When enabled, a linear path from the maximally blurred image to the input image is created. Using a blurred baseline instead of zero (black image) is motivated by the BlurIG approach explained here: https://arxiv.org/abs/2004.03383
type GoogleCloudAiplatformV1BlurBaselineConfig struct {
	// The standard deviation of the blur kernel for the blurred baseline. The same blurring parameter is used for both the height and the width dimension. If not set, the method defaults to the zero (i.e. black for images) baseline.
	MaxBlurSigma *float64 `pulumi:"maxBlurSigma"`
}

// GoogleCloudAiplatformV1BlurBaselineConfigInput is an input type that accepts GoogleCloudAiplatformV1BlurBaselineConfigArgs and GoogleCloudAiplatformV1BlurBaselineConfigOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1BlurBaselineConfigInput` via:
//
//	GoogleCloudAiplatformV1BlurBaselineConfigArgs{...}
type GoogleCloudAiplatformV1BlurBaselineConfigInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1BlurBaselineConfigOutput() GoogleCloudAiplatformV1BlurBaselineConfigOutput
	ToGoogleCloudAiplatformV1BlurBaselineConfigOutputWithContext(context.Context) GoogleCloudAiplatformV1BlurBaselineConfigOutput
}

// Config for blur baseline. When enabled, a linear path from the maximally blurred image to the input image is created. Using a blurred baseline instead of zero (black image) is motivated by the BlurIG approach explained here: https://arxiv.org/abs/2004.03383
type GoogleCloudAiplatformV1BlurBaselineConfigArgs struct {
	// The standard deviation of the blur kernel for the blurred baseline. The same blurring parameter is used for both the height and the width dimension. If not set, the method defaults to the zero (i.e. black for images) baseline.
	MaxBlurSigma pulumi.Float64PtrInput `pulumi:"maxBlurSigma"`
}

func (GoogleCloudAiplatformV1BlurBaselineConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1BlurBaselineConfig)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1BlurBaselineConfigArgs) ToGoogleCloudAiplatformV1BlurBaselineConfigOutput() GoogleCloudAiplatformV1BlurBaselineConfigOutput {
	return i.ToGoogleCloudAiplatformV1BlurBaselineConfigOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1BlurBaselineConfigArgs) ToGoogleCloudAiplatformV1BlurBaselineConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1BlurBaselineConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1BlurBaselineConfigOutput)
}

func (i GoogleCloudAiplatformV1BlurBaselineConfigArgs) ToGoogleCloudAiplatformV1BlurBaselineConfigPtrOutput() GoogleCloudAiplatformV1BlurBaselineConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1BlurBaselineConfigPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1BlurBaselineConfigArgs) ToGoogleCloudAiplatformV1BlurBaselineConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1BlurBaselineConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1BlurBaselineConfigOutput).ToGoogleCloudAiplatformV1BlurBaselineConfigPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1BlurBaselineConfigPtrInput is an input type that accepts GoogleCloudAiplatformV1BlurBaselineConfigArgs, GoogleCloudAiplatformV1BlurBaselineConfigPtr and GoogleCloudAiplatformV1BlurBaselineConfigPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1BlurBaselineConfigPtrInput` via:
//
//	        GoogleCloudAiplatformV1BlurBaselineConfigArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1BlurBaselineConfigPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1BlurBaselineConfigPtrOutput() GoogleCloudAiplatformV1BlurBaselineConfigPtrOutput
	ToGoogleCloudAiplatformV1BlurBaselineConfigPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1BlurBaselineConfigPtrOutput
}

type googleCloudAiplatformV1BlurBaselineConfigPtrType GoogleCloudAiplatformV1BlurBaselineConfigArgs

func GoogleCloudAiplatformV1BlurBaselineConfigPtr(v *GoogleCloudAiplatformV1BlurBaselineConfigArgs) GoogleCloudAiplatformV1BlurBaselineConfigPtrInput {
	return (*googleCloudAiplatformV1BlurBaselineConfigPtrType)(v)
}

func (*googleCloudAiplatformV1BlurBaselineConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1BlurBaselineConfig)(nil)).Elem()
}

func (i *googleCloudAiplatformV1BlurBaselineConfigPtrType) ToGoogleCloudAiplatformV1BlurBaselineConfigPtrOutput() GoogleCloudAiplatformV1BlurBaselineConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1BlurBaselineConfigPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1BlurBaselineConfigPtrType) ToGoogleCloudAiplatformV1BlurBaselineConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1BlurBaselineConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1BlurBaselineConfigPtrOutput)
}

// Config for blur baseline. When enabled, a linear path from the maximally blurred image to the input image is created. Using a blurred baseline instead of zero (black image) is motivated by the BlurIG approach explained here: https://arxiv.org/abs/2004.03383
type GoogleCloudAiplatformV1BlurBaselineConfigOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1BlurBaselineConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1BlurBaselineConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1BlurBaselineConfigOutput) ToGoogleCloudAiplatformV1BlurBaselineConfigOutput() GoogleCloudAiplatformV1BlurBaselineConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1BlurBaselineConfigOutput) ToGoogleCloudAiplatformV1BlurBaselineConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1BlurBaselineConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1BlurBaselineConfigOutput) ToGoogleCloudAiplatformV1BlurBaselineConfigPtrOutput() GoogleCloudAiplatformV1BlurBaselineConfigPtrOutput {
	return o.ToGoogleCloudAiplatformV1BlurBaselineConfigPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1BlurBaselineConfigOutput) ToGoogleCloudAiplatformV1BlurBaselineConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1BlurBaselineConfigPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1BlurBaselineConfig) *GoogleCloudAiplatformV1BlurBaselineConfig {
		return &v
	}).(GoogleCloudAiplatformV1BlurBaselineConfigPtrOutput)
}

// The standard deviation of the blur kernel for the blurred baseline. The same blurring parameter is used for both the height and the width dimension. If not set, the method defaults to the zero (i.e. black for images) baseline.
func (o GoogleCloudAiplatformV1BlurBaselineConfigOutput) MaxBlurSigma() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1BlurBaselineConfig) *float64 { return v.MaxBlurSigma }).(pulumi.Float64PtrOutput)
}

type GoogleCloudAiplatformV1BlurBaselineConfigPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1BlurBaselineConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1BlurBaselineConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1BlurBaselineConfigPtrOutput) ToGoogleCloudAiplatformV1BlurBaselineConfigPtrOutput() GoogleCloudAiplatformV1BlurBaselineConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1BlurBaselineConfigPtrOutput) ToGoogleCloudAiplatformV1BlurBaselineConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1BlurBaselineConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1BlurBaselineConfigPtrOutput) Elem() GoogleCloudAiplatformV1BlurBaselineConfigOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1BlurBaselineConfig) GoogleCloudAiplatformV1BlurBaselineConfig {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1BlurBaselineConfig
		return ret
	}).(GoogleCloudAiplatformV1BlurBaselineConfigOutput)
}

// The standard deviation of the blur kernel for the blurred baseline. The same blurring parameter is used for both the height and the width dimension. If not set, the method defaults to the zero (i.e. black for images) baseline.
func (o GoogleCloudAiplatformV1BlurBaselineConfigPtrOutput) MaxBlurSigma() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1BlurBaselineConfig) *float64 {
		if v == nil {
			return nil
		}
		return v.MaxBlurSigma
	}).(pulumi.Float64PtrOutput)
}

// Config for blur baseline. When enabled, a linear path from the maximally blurred image to the input image is created. Using a blurred baseline instead of zero (black image) is motivated by the BlurIG approach explained here: https://arxiv.org/abs/2004.03383
type GoogleCloudAiplatformV1BlurBaselineConfigResponse struct {
	// The standard deviation of the blur kernel for the blurred baseline. The same blurring parameter is used for both the height and the width dimension. If not set, the method defaults to the zero (i.e. black for images) baseline.
	MaxBlurSigma float64 `pulumi:"maxBlurSigma"`
}

// Config for blur baseline. When enabled, a linear path from the maximally blurred image to the input image is created. Using a blurred baseline instead of zero (black image) is motivated by the BlurIG approach explained here: https://arxiv.org/abs/2004.03383
type GoogleCloudAiplatformV1BlurBaselineConfigResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1BlurBaselineConfigResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1BlurBaselineConfigResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1BlurBaselineConfigResponseOutput) ToGoogleCloudAiplatformV1BlurBaselineConfigResponseOutput() GoogleCloudAiplatformV1BlurBaselineConfigResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1BlurBaselineConfigResponseOutput) ToGoogleCloudAiplatformV1BlurBaselineConfigResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1BlurBaselineConfigResponseOutput {
	return o
}

// The standard deviation of the blur kernel for the blurred baseline. The same blurring parameter is used for both the height and the width dimension. If not set, the method defaults to the zero (i.e. black for images) baseline.
func (o GoogleCloudAiplatformV1BlurBaselineConfigResponseOutput) MaxBlurSigma() pulumi.Float64Output {
	return o.ApplyT(func(v GoogleCloudAiplatformV1BlurBaselineConfigResponse) float64 { return v.MaxBlurSigma }).(pulumi.Float64Output)
}

// Success and error statistics of processing multiple entities (for example, DataItems or structured data rows) in batch.
type GoogleCloudAiplatformV1CompletionStatsResponse struct {
	// The number of entities for which any error was encountered.
	FailedCount string `pulumi:"failedCount"`
	// In cases when enough errors are encountered a job, pipeline, or operation may be failed as a whole. Below is the number of entities for which the processing had not been finished (either in successful or failed state). Set to -1 if the number is unknown (for example, the operation failed before the total entity number could be collected).
	IncompleteCount string `pulumi:"incompleteCount"`
	// The number of entities that had been processed successfully.
	SuccessfulCount string `pulumi:"successfulCount"`
	// The number of the successful forecast points that are generated by the forecasting model. This is ONLY used by the forecasting batch prediction.
	SuccessfulForecastPointCount string `pulumi:"successfulForecastPointCount"`
}

// Success and error statistics of processing multiple entities (for example, DataItems or structured data rows) in batch.
type GoogleCloudAiplatformV1CompletionStatsResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1CompletionStatsResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1CompletionStatsResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1CompletionStatsResponseOutput) ToGoogleCloudAiplatformV1CompletionStatsResponseOutput() GoogleCloudAiplatformV1CompletionStatsResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1CompletionStatsResponseOutput) ToGoogleCloudAiplatformV1CompletionStatsResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1CompletionStatsResponseOutput {
	return o
}

// The number of entities for which any error was encountered.
func (o GoogleCloudAiplatformV1CompletionStatsResponseOutput) FailedCount() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1CompletionStatsResponse) string { return v.FailedCount }).(pulumi.StringOutput)
}

// In cases when enough errors are encountered a job, pipeline, or operation may be failed as a whole. Below is the number of entities for which the processing had not been finished (either in successful or failed state). Set to -1 if the number is unknown (for example, the operation failed before the total entity number could be collected).
func (o GoogleCloudAiplatformV1CompletionStatsResponseOutput) IncompleteCount() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1CompletionStatsResponse) string { return v.IncompleteCount }).(pulumi.StringOutput)
}

// The number of entities that had been processed successfully.
func (o GoogleCloudAiplatformV1CompletionStatsResponseOutput) SuccessfulCount() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1CompletionStatsResponse) string { return v.SuccessfulCount }).(pulumi.StringOutput)
}

// The number of the successful forecast points that are generated by the forecasting model. This is ONLY used by the forecasting batch prediction.
func (o GoogleCloudAiplatformV1CompletionStatsResponseOutput) SuccessfulForecastPointCount() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1CompletionStatsResponse) string { return v.SuccessfulForecastPointCount }).(pulumi.StringOutput)
}

// The spec of a Container.
type GoogleCloudAiplatformV1ContainerSpec struct {
	// The arguments to be passed when starting the container.
	Args []string `pulumi:"args"`
	// The command to be invoked when the container is started. It overrides the entrypoint instruction in Dockerfile when provided.
	Command []string `pulumi:"command"`
	// Environment variables to be passed to the container. Maximum limit is 100.
	Env []GoogleCloudAiplatformV1EnvVar `pulumi:"env"`
	// The URI of a container image in the Container Registry that is to be run on each worker replica.
	ImageUri string `pulumi:"imageUri"`
}

// GoogleCloudAiplatformV1ContainerSpecInput is an input type that accepts GoogleCloudAiplatformV1ContainerSpecArgs and GoogleCloudAiplatformV1ContainerSpecOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1ContainerSpecInput` via:
//
//	GoogleCloudAiplatformV1ContainerSpecArgs{...}
type GoogleCloudAiplatformV1ContainerSpecInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1ContainerSpecOutput() GoogleCloudAiplatformV1ContainerSpecOutput
	ToGoogleCloudAiplatformV1ContainerSpecOutputWithContext(context.Context) GoogleCloudAiplatformV1ContainerSpecOutput
}

// The spec of a Container.
type GoogleCloudAiplatformV1ContainerSpecArgs struct {
	// The arguments to be passed when starting the container.
	Args pulumi.StringArrayInput `pulumi:"args"`
	// The command to be invoked when the container is started. It overrides the entrypoint instruction in Dockerfile when provided.
	Command pulumi.StringArrayInput `pulumi:"command"`
	// Environment variables to be passed to the container. Maximum limit is 100.
	Env GoogleCloudAiplatformV1EnvVarArrayInput `pulumi:"env"`
	// The URI of a container image in the Container Registry that is to be run on each worker replica.
	ImageUri pulumi.StringInput `pulumi:"imageUri"`
}

func (GoogleCloudAiplatformV1ContainerSpecArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1ContainerSpec)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1ContainerSpecArgs) ToGoogleCloudAiplatformV1ContainerSpecOutput() GoogleCloudAiplatformV1ContainerSpecOutput {
	return i.ToGoogleCloudAiplatformV1ContainerSpecOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1ContainerSpecArgs) ToGoogleCloudAiplatformV1ContainerSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ContainerSpecOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1ContainerSpecOutput)
}

func (i GoogleCloudAiplatformV1ContainerSpecArgs) ToGoogleCloudAiplatformV1ContainerSpecPtrOutput() GoogleCloudAiplatformV1ContainerSpecPtrOutput {
	return i.ToGoogleCloudAiplatformV1ContainerSpecPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1ContainerSpecArgs) ToGoogleCloudAiplatformV1ContainerSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ContainerSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1ContainerSpecOutput).ToGoogleCloudAiplatformV1ContainerSpecPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1ContainerSpecPtrInput is an input type that accepts GoogleCloudAiplatformV1ContainerSpecArgs, GoogleCloudAiplatformV1ContainerSpecPtr and GoogleCloudAiplatformV1ContainerSpecPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1ContainerSpecPtrInput` via:
//
//	        GoogleCloudAiplatformV1ContainerSpecArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1ContainerSpecPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1ContainerSpecPtrOutput() GoogleCloudAiplatformV1ContainerSpecPtrOutput
	ToGoogleCloudAiplatformV1ContainerSpecPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1ContainerSpecPtrOutput
}

type googleCloudAiplatformV1ContainerSpecPtrType GoogleCloudAiplatformV1ContainerSpecArgs

func GoogleCloudAiplatformV1ContainerSpecPtr(v *GoogleCloudAiplatformV1ContainerSpecArgs) GoogleCloudAiplatformV1ContainerSpecPtrInput {
	return (*googleCloudAiplatformV1ContainerSpecPtrType)(v)
}

func (*googleCloudAiplatformV1ContainerSpecPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1ContainerSpec)(nil)).Elem()
}

func (i *googleCloudAiplatformV1ContainerSpecPtrType) ToGoogleCloudAiplatformV1ContainerSpecPtrOutput() GoogleCloudAiplatformV1ContainerSpecPtrOutput {
	return i.ToGoogleCloudAiplatformV1ContainerSpecPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1ContainerSpecPtrType) ToGoogleCloudAiplatformV1ContainerSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ContainerSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1ContainerSpecPtrOutput)
}

// The spec of a Container.
type GoogleCloudAiplatformV1ContainerSpecOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ContainerSpecOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1ContainerSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ContainerSpecOutput) ToGoogleCloudAiplatformV1ContainerSpecOutput() GoogleCloudAiplatformV1ContainerSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1ContainerSpecOutput) ToGoogleCloudAiplatformV1ContainerSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ContainerSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1ContainerSpecOutput) ToGoogleCloudAiplatformV1ContainerSpecPtrOutput() GoogleCloudAiplatformV1ContainerSpecPtrOutput {
	return o.ToGoogleCloudAiplatformV1ContainerSpecPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1ContainerSpecOutput) ToGoogleCloudAiplatformV1ContainerSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ContainerSpecPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1ContainerSpec) *GoogleCloudAiplatformV1ContainerSpec {
		return &v
	}).(GoogleCloudAiplatformV1ContainerSpecPtrOutput)
}

// The arguments to be passed when starting the container.
func (o GoogleCloudAiplatformV1ContainerSpecOutput) Args() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ContainerSpec) []string { return v.Args }).(pulumi.StringArrayOutput)
}

// The command to be invoked when the container is started. It overrides the entrypoint instruction in Dockerfile when provided.
func (o GoogleCloudAiplatformV1ContainerSpecOutput) Command() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ContainerSpec) []string { return v.Command }).(pulumi.StringArrayOutput)
}

// Environment variables to be passed to the container. Maximum limit is 100.
func (o GoogleCloudAiplatformV1ContainerSpecOutput) Env() GoogleCloudAiplatformV1EnvVarArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ContainerSpec) []GoogleCloudAiplatformV1EnvVar { return v.Env }).(GoogleCloudAiplatformV1EnvVarArrayOutput)
}

// The URI of a container image in the Container Registry that is to be run on each worker replica.
func (o GoogleCloudAiplatformV1ContainerSpecOutput) ImageUri() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ContainerSpec) string { return v.ImageUri }).(pulumi.StringOutput)
}

type GoogleCloudAiplatformV1ContainerSpecPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ContainerSpecPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1ContainerSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ContainerSpecPtrOutput) ToGoogleCloudAiplatformV1ContainerSpecPtrOutput() GoogleCloudAiplatformV1ContainerSpecPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1ContainerSpecPtrOutput) ToGoogleCloudAiplatformV1ContainerSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ContainerSpecPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1ContainerSpecPtrOutput) Elem() GoogleCloudAiplatformV1ContainerSpecOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1ContainerSpec) GoogleCloudAiplatformV1ContainerSpec {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1ContainerSpec
		return ret
	}).(GoogleCloudAiplatformV1ContainerSpecOutput)
}

// The arguments to be passed when starting the container.
func (o GoogleCloudAiplatformV1ContainerSpecPtrOutput) Args() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1ContainerSpec) []string {
		if v == nil {
			return nil
		}
		return v.Args
	}).(pulumi.StringArrayOutput)
}

// The command to be invoked when the container is started. It overrides the entrypoint instruction in Dockerfile when provided.
func (o GoogleCloudAiplatformV1ContainerSpecPtrOutput) Command() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1ContainerSpec) []string {
		if v == nil {
			return nil
		}
		return v.Command
	}).(pulumi.StringArrayOutput)
}

// Environment variables to be passed to the container. Maximum limit is 100.
func (o GoogleCloudAiplatformV1ContainerSpecPtrOutput) Env() GoogleCloudAiplatformV1EnvVarArrayOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1ContainerSpec) []GoogleCloudAiplatformV1EnvVar {
		if v == nil {
			return nil
		}
		return v.Env
	}).(GoogleCloudAiplatformV1EnvVarArrayOutput)
}

// The URI of a container image in the Container Registry that is to be run on each worker replica.
func (o GoogleCloudAiplatformV1ContainerSpecPtrOutput) ImageUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1ContainerSpec) *string {
		if v == nil {
			return nil
		}
		return &v.ImageUri
	}).(pulumi.StringPtrOutput)
}

// The spec of a Container.
type GoogleCloudAiplatformV1ContainerSpecResponse struct {
	// The arguments to be passed when starting the container.
	Args []string `pulumi:"args"`
	// The command to be invoked when the container is started. It overrides the entrypoint instruction in Dockerfile when provided.
	Command []string `pulumi:"command"`
	// Environment variables to be passed to the container. Maximum limit is 100.
	Env []GoogleCloudAiplatformV1EnvVarResponse `pulumi:"env"`
	// The URI of a container image in the Container Registry that is to be run on each worker replica.
	ImageUri string `pulumi:"imageUri"`
}

// The spec of a Container.
type GoogleCloudAiplatformV1ContainerSpecResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ContainerSpecResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1ContainerSpecResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ContainerSpecResponseOutput) ToGoogleCloudAiplatformV1ContainerSpecResponseOutput() GoogleCloudAiplatformV1ContainerSpecResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1ContainerSpecResponseOutput) ToGoogleCloudAiplatformV1ContainerSpecResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ContainerSpecResponseOutput {
	return o
}

// The arguments to be passed when starting the container.
func (o GoogleCloudAiplatformV1ContainerSpecResponseOutput) Args() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ContainerSpecResponse) []string { return v.Args }).(pulumi.StringArrayOutput)
}

// The command to be invoked when the container is started. It overrides the entrypoint instruction in Dockerfile when provided.
func (o GoogleCloudAiplatformV1ContainerSpecResponseOutput) Command() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ContainerSpecResponse) []string { return v.Command }).(pulumi.StringArrayOutput)
}

// Environment variables to be passed to the container. Maximum limit is 100.
func (o GoogleCloudAiplatformV1ContainerSpecResponseOutput) Env() GoogleCloudAiplatformV1EnvVarResponseArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ContainerSpecResponse) []GoogleCloudAiplatformV1EnvVarResponse {
		return v.Env
	}).(GoogleCloudAiplatformV1EnvVarResponseArrayOutput)
}

// The URI of a container image in the Container Registry that is to be run on each worker replica.
func (o GoogleCloudAiplatformV1ContainerSpecResponseOutput) ImageUri() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ContainerSpecResponse) string { return v.ImageUri }).(pulumi.StringOutput)
}

// Instance of a general context.
type GoogleCloudAiplatformV1ContextResponse struct {
	// Timestamp when this Context was created.
	CreateTime string `pulumi:"createTime"`
	// Description of the Context
	Description string `pulumi:"description"`
	// User provided display name of the Context. May be up to 128 Unicode characters.
	DisplayName string `pulumi:"displayName"`
	// An eTag used to perform consistent read-modify-write updates. If not set, a blind "overwrite" update happens.
	Etag string `pulumi:"etag"`
	// The labels with user-defined metadata to organize your Contexts. Label keys and values can be no longer than 64 characters (Unicode codepoints), can only contain lowercase letters, numeric characters, underscores and dashes. International characters are allowed. No more than 64 user labels can be associated with one Context (System labels are excluded).
	Labels map[string]string `pulumi:"labels"`
	// Properties of the Context. Top level metadata keys' heading and trailing spaces will be trimmed. The size of this field should not exceed 200KB.
	Metadata map[string]interface{} `pulumi:"metadata"`
	// Immutable. The resource name of the Context.
	Name string `pulumi:"name"`
	// A list of resource names of Contexts that are parents of this Context. A Context may have at most 10 parent_contexts.
	ParentContexts []string `pulumi:"parentContexts"`
	// The title of the schema describing the metadata. Schema title and version is expected to be registered in earlier Create Schema calls. And both are used together as unique identifiers to identify schemas within the local metadata store.
	SchemaTitle string `pulumi:"schemaTitle"`
	// The version of the schema in schema_name to use. Schema title and version is expected to be registered in earlier Create Schema calls. And both are used together as unique identifiers to identify schemas within the local metadata store.
	SchemaVersion string `pulumi:"schemaVersion"`
	// Timestamp when this Context was last updated.
	UpdateTime string `pulumi:"updateTime"`
}

// Instance of a general context.
type GoogleCloudAiplatformV1ContextResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ContextResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1ContextResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ContextResponseOutput) ToGoogleCloudAiplatformV1ContextResponseOutput() GoogleCloudAiplatformV1ContextResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1ContextResponseOutput) ToGoogleCloudAiplatformV1ContextResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ContextResponseOutput {
	return o
}

// Timestamp when this Context was created.
func (o GoogleCloudAiplatformV1ContextResponseOutput) CreateTime() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ContextResponse) string { return v.CreateTime }).(pulumi.StringOutput)
}

// Description of the Context
func (o GoogleCloudAiplatformV1ContextResponseOutput) Description() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ContextResponse) string { return v.Description }).(pulumi.StringOutput)
}

// User provided display name of the Context. May be up to 128 Unicode characters.
func (o GoogleCloudAiplatformV1ContextResponseOutput) DisplayName() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ContextResponse) string { return v.DisplayName }).(pulumi.StringOutput)
}

// An eTag used to perform consistent read-modify-write updates. If not set, a blind "overwrite" update happens.
func (o GoogleCloudAiplatformV1ContextResponseOutput) Etag() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ContextResponse) string { return v.Etag }).(pulumi.StringOutput)
}

// The labels with user-defined metadata to organize your Contexts. Label keys and values can be no longer than 64 characters (Unicode codepoints), can only contain lowercase letters, numeric characters, underscores and dashes. International characters are allowed. No more than 64 user labels can be associated with one Context (System labels are excluded).
func (o GoogleCloudAiplatformV1ContextResponseOutput) Labels() pulumi.StringMapOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ContextResponse) map[string]string { return v.Labels }).(pulumi.StringMapOutput)
}

// Properties of the Context. Top level metadata keys' heading and trailing spaces will be trimmed. The size of this field should not exceed 200KB.
func (o GoogleCloudAiplatformV1ContextResponseOutput) Metadata() pulumi.MapOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ContextResponse) map[string]interface{} { return v.Metadata }).(pulumi.MapOutput)
}

// Immutable. The resource name of the Context.
func (o GoogleCloudAiplatformV1ContextResponseOutput) Name() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ContextResponse) string { return v.Name }).(pulumi.StringOutput)
}

// A list of resource names of Contexts that are parents of this Context. A Context may have at most 10 parent_contexts.
func (o GoogleCloudAiplatformV1ContextResponseOutput) ParentContexts() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ContextResponse) []string { return v.ParentContexts }).(pulumi.StringArrayOutput)
}

// The title of the schema describing the metadata. Schema title and version is expected to be registered in earlier Create Schema calls. And both are used together as unique identifiers to identify schemas within the local metadata store.
func (o GoogleCloudAiplatformV1ContextResponseOutput) SchemaTitle() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ContextResponse) string { return v.SchemaTitle }).(pulumi.StringOutput)
}

// The version of the schema in schema_name to use. Schema title and version is expected to be registered in earlier Create Schema calls. And both are used together as unique identifiers to identify schemas within the local metadata store.
func (o GoogleCloudAiplatformV1ContextResponseOutput) SchemaVersion() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ContextResponse) string { return v.SchemaVersion }).(pulumi.StringOutput)
}

// Timestamp when this Context was last updated.
func (o GoogleCloudAiplatformV1ContextResponseOutput) UpdateTime() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ContextResponse) string { return v.UpdateTime }).(pulumi.StringOutput)
}

// Request message for PipelineService.CreatePipelineJob.
type GoogleCloudAiplatformV1CreatePipelineJobRequest struct {
	// The resource name of the Location to create the PipelineJob in. Format: `projects/{project}/locations/{location}`
	Parent string `pulumi:"parent"`
	// The PipelineJob to create.
	PipelineJob GoogleCloudAiplatformV1PipelineJob `pulumi:"pipelineJob"`
	// The ID to use for the PipelineJob, which will become the final component of the PipelineJob name. If not provided, an ID will be automatically generated. This value should be less than 128 characters, and valid characters are `/a-z-/`.
	PipelineJobId *string `pulumi:"pipelineJobId"`
}

// GoogleCloudAiplatformV1CreatePipelineJobRequestInput is an input type that accepts GoogleCloudAiplatformV1CreatePipelineJobRequestArgs and GoogleCloudAiplatformV1CreatePipelineJobRequestOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1CreatePipelineJobRequestInput` via:
//
//	GoogleCloudAiplatformV1CreatePipelineJobRequestArgs{...}
type GoogleCloudAiplatformV1CreatePipelineJobRequestInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1CreatePipelineJobRequestOutput() GoogleCloudAiplatformV1CreatePipelineJobRequestOutput
	ToGoogleCloudAiplatformV1CreatePipelineJobRequestOutputWithContext(context.Context) GoogleCloudAiplatformV1CreatePipelineJobRequestOutput
}

// Request message for PipelineService.CreatePipelineJob.
type GoogleCloudAiplatformV1CreatePipelineJobRequestArgs struct {
	// The resource name of the Location to create the PipelineJob in. Format: `projects/{project}/locations/{location}`
	Parent pulumi.StringInput `pulumi:"parent"`
	// The PipelineJob to create.
	PipelineJob GoogleCloudAiplatformV1PipelineJobInput `pulumi:"pipelineJob"`
	// The ID to use for the PipelineJob, which will become the final component of the PipelineJob name. If not provided, an ID will be automatically generated. This value should be less than 128 characters, and valid characters are `/a-z-/`.
	PipelineJobId pulumi.StringPtrInput `pulumi:"pipelineJobId"`
}

func (GoogleCloudAiplatformV1CreatePipelineJobRequestArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1CreatePipelineJobRequest)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1CreatePipelineJobRequestArgs) ToGoogleCloudAiplatformV1CreatePipelineJobRequestOutput() GoogleCloudAiplatformV1CreatePipelineJobRequestOutput {
	return i.ToGoogleCloudAiplatformV1CreatePipelineJobRequestOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1CreatePipelineJobRequestArgs) ToGoogleCloudAiplatformV1CreatePipelineJobRequestOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1CreatePipelineJobRequestOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1CreatePipelineJobRequestOutput)
}

func (i GoogleCloudAiplatformV1CreatePipelineJobRequestArgs) ToGoogleCloudAiplatformV1CreatePipelineJobRequestPtrOutput() GoogleCloudAiplatformV1CreatePipelineJobRequestPtrOutput {
	return i.ToGoogleCloudAiplatformV1CreatePipelineJobRequestPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1CreatePipelineJobRequestArgs) ToGoogleCloudAiplatformV1CreatePipelineJobRequestPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1CreatePipelineJobRequestPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1CreatePipelineJobRequestOutput).ToGoogleCloudAiplatformV1CreatePipelineJobRequestPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1CreatePipelineJobRequestPtrInput is an input type that accepts GoogleCloudAiplatformV1CreatePipelineJobRequestArgs, GoogleCloudAiplatformV1CreatePipelineJobRequestPtr and GoogleCloudAiplatformV1CreatePipelineJobRequestPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1CreatePipelineJobRequestPtrInput` via:
//
//	        GoogleCloudAiplatformV1CreatePipelineJobRequestArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1CreatePipelineJobRequestPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1CreatePipelineJobRequestPtrOutput() GoogleCloudAiplatformV1CreatePipelineJobRequestPtrOutput
	ToGoogleCloudAiplatformV1CreatePipelineJobRequestPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1CreatePipelineJobRequestPtrOutput
}

type googleCloudAiplatformV1CreatePipelineJobRequestPtrType GoogleCloudAiplatformV1CreatePipelineJobRequestArgs

func GoogleCloudAiplatformV1CreatePipelineJobRequestPtr(v *GoogleCloudAiplatformV1CreatePipelineJobRequestArgs) GoogleCloudAiplatformV1CreatePipelineJobRequestPtrInput {
	return (*googleCloudAiplatformV1CreatePipelineJobRequestPtrType)(v)
}

func (*googleCloudAiplatformV1CreatePipelineJobRequestPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1CreatePipelineJobRequest)(nil)).Elem()
}

func (i *googleCloudAiplatformV1CreatePipelineJobRequestPtrType) ToGoogleCloudAiplatformV1CreatePipelineJobRequestPtrOutput() GoogleCloudAiplatformV1CreatePipelineJobRequestPtrOutput {
	return i.ToGoogleCloudAiplatformV1CreatePipelineJobRequestPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1CreatePipelineJobRequestPtrType) ToGoogleCloudAiplatformV1CreatePipelineJobRequestPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1CreatePipelineJobRequestPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1CreatePipelineJobRequestPtrOutput)
}

// Request message for PipelineService.CreatePipelineJob.
type GoogleCloudAiplatformV1CreatePipelineJobRequestOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1CreatePipelineJobRequestOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1CreatePipelineJobRequest)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1CreatePipelineJobRequestOutput) ToGoogleCloudAiplatformV1CreatePipelineJobRequestOutput() GoogleCloudAiplatformV1CreatePipelineJobRequestOutput {
	return o
}

func (o GoogleCloudAiplatformV1CreatePipelineJobRequestOutput) ToGoogleCloudAiplatformV1CreatePipelineJobRequestOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1CreatePipelineJobRequestOutput {
	return o
}

func (o GoogleCloudAiplatformV1CreatePipelineJobRequestOutput) ToGoogleCloudAiplatformV1CreatePipelineJobRequestPtrOutput() GoogleCloudAiplatformV1CreatePipelineJobRequestPtrOutput {
	return o.ToGoogleCloudAiplatformV1CreatePipelineJobRequestPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1CreatePipelineJobRequestOutput) ToGoogleCloudAiplatformV1CreatePipelineJobRequestPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1CreatePipelineJobRequestPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1CreatePipelineJobRequest) *GoogleCloudAiplatformV1CreatePipelineJobRequest {
		return &v
	}).(GoogleCloudAiplatformV1CreatePipelineJobRequestPtrOutput)
}

// The resource name of the Location to create the PipelineJob in. Format: `projects/{project}/locations/{location}`
func (o GoogleCloudAiplatformV1CreatePipelineJobRequestOutput) Parent() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1CreatePipelineJobRequest) string { return v.Parent }).(pulumi.StringOutput)
}

// The PipelineJob to create.
func (o GoogleCloudAiplatformV1CreatePipelineJobRequestOutput) PipelineJob() GoogleCloudAiplatformV1PipelineJobOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1CreatePipelineJobRequest) GoogleCloudAiplatformV1PipelineJob {
		return v.PipelineJob
	}).(GoogleCloudAiplatformV1PipelineJobOutput)
}

// The ID to use for the PipelineJob, which will become the final component of the PipelineJob name. If not provided, an ID will be automatically generated. This value should be less than 128 characters, and valid characters are `/a-z-/`.
func (o GoogleCloudAiplatformV1CreatePipelineJobRequestOutput) PipelineJobId() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1CreatePipelineJobRequest) *string { return v.PipelineJobId }).(pulumi.StringPtrOutput)
}

type GoogleCloudAiplatformV1CreatePipelineJobRequestPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1CreatePipelineJobRequestPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1CreatePipelineJobRequest)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1CreatePipelineJobRequestPtrOutput) ToGoogleCloudAiplatformV1CreatePipelineJobRequestPtrOutput() GoogleCloudAiplatformV1CreatePipelineJobRequestPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1CreatePipelineJobRequestPtrOutput) ToGoogleCloudAiplatformV1CreatePipelineJobRequestPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1CreatePipelineJobRequestPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1CreatePipelineJobRequestPtrOutput) Elem() GoogleCloudAiplatformV1CreatePipelineJobRequestOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1CreatePipelineJobRequest) GoogleCloudAiplatformV1CreatePipelineJobRequest {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1CreatePipelineJobRequest
		return ret
	}).(GoogleCloudAiplatformV1CreatePipelineJobRequestOutput)
}

// The resource name of the Location to create the PipelineJob in. Format: `projects/{project}/locations/{location}`
func (o GoogleCloudAiplatformV1CreatePipelineJobRequestPtrOutput) Parent() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1CreatePipelineJobRequest) *string {
		if v == nil {
			return nil
		}
		return &v.Parent
	}).(pulumi.StringPtrOutput)
}

// The PipelineJob to create.
func (o GoogleCloudAiplatformV1CreatePipelineJobRequestPtrOutput) PipelineJob() GoogleCloudAiplatformV1PipelineJobPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1CreatePipelineJobRequest) *GoogleCloudAiplatformV1PipelineJob {
		if v == nil {
			return nil
		}
		return &v.PipelineJob
	}).(GoogleCloudAiplatformV1PipelineJobPtrOutput)
}

// The ID to use for the PipelineJob, which will become the final component of the PipelineJob name. If not provided, an ID will be automatically generated. This value should be less than 128 characters, and valid characters are `/a-z-/`.
func (o GoogleCloudAiplatformV1CreatePipelineJobRequestPtrOutput) PipelineJobId() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1CreatePipelineJobRequest) *string {
		if v == nil {
			return nil
		}
		return v.PipelineJobId
	}).(pulumi.StringPtrOutput)
}

// Request message for PipelineService.CreatePipelineJob.
type GoogleCloudAiplatformV1CreatePipelineJobRequestResponse struct {
	// The resource name of the Location to create the PipelineJob in. Format: `projects/{project}/locations/{location}`
	Parent string `pulumi:"parent"`
	// The PipelineJob to create.
	PipelineJob GoogleCloudAiplatformV1PipelineJobResponse `pulumi:"pipelineJob"`
	// The ID to use for the PipelineJob, which will become the final component of the PipelineJob name. If not provided, an ID will be automatically generated. This value should be less than 128 characters, and valid characters are `/a-z-/`.
	PipelineJobId string `pulumi:"pipelineJobId"`
}

// Request message for PipelineService.CreatePipelineJob.
type GoogleCloudAiplatformV1CreatePipelineJobRequestResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1CreatePipelineJobRequestResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1CreatePipelineJobRequestResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1CreatePipelineJobRequestResponseOutput) ToGoogleCloudAiplatformV1CreatePipelineJobRequestResponseOutput() GoogleCloudAiplatformV1CreatePipelineJobRequestResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1CreatePipelineJobRequestResponseOutput) ToGoogleCloudAiplatformV1CreatePipelineJobRequestResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1CreatePipelineJobRequestResponseOutput {
	return o
}

// The resource name of the Location to create the PipelineJob in. Format: `projects/{project}/locations/{location}`
func (o GoogleCloudAiplatformV1CreatePipelineJobRequestResponseOutput) Parent() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1CreatePipelineJobRequestResponse) string { return v.Parent }).(pulumi.StringOutput)
}

// The PipelineJob to create.
func (o GoogleCloudAiplatformV1CreatePipelineJobRequestResponseOutput) PipelineJob() GoogleCloudAiplatformV1PipelineJobResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1CreatePipelineJobRequestResponse) GoogleCloudAiplatformV1PipelineJobResponse {
		return v.PipelineJob
	}).(GoogleCloudAiplatformV1PipelineJobResponseOutput)
}

// The ID to use for the PipelineJob, which will become the final component of the PipelineJob name. If not provided, an ID will be automatically generated. This value should be less than 128 characters, and valid characters are `/a-z-/`.
func (o GoogleCloudAiplatformV1CreatePipelineJobRequestResponseOutput) PipelineJobId() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1CreatePipelineJobRequestResponse) string { return v.PipelineJobId }).(pulumi.StringOutput)
}

// Represents the spec of a CustomJob.
type GoogleCloudAiplatformV1CustomJobSpec struct {
	// The Cloud Storage location to store the output of this CustomJob or HyperparameterTuningJob. For HyperparameterTuningJob, the baseOutputDirectory of each child CustomJob backing a Trial is set to a subdirectory of name id under its parent HyperparameterTuningJob's baseOutputDirectory. The following Vertex AI environment variables will be passed to containers or python modules when this field is set: For CustomJob: * AIP_MODEL_DIR = `/model/` * AIP_CHECKPOINT_DIR = `/checkpoints/` * AIP_TENSORBOARD_LOG_DIR = `/logs/` For CustomJob backing a Trial of HyperparameterTuningJob: * AIP_MODEL_DIR = `//model/` * AIP_CHECKPOINT_DIR = `//checkpoints/` * AIP_TENSORBOARD_LOG_DIR = `//logs/`
	BaseOutputDirectory *GoogleCloudAiplatformV1GcsDestination `pulumi:"baseOutputDirectory"`
	// Optional. Whether you want Vertex AI to enable access to the customized dashboard in training chief container. If set to `true`, you can access the dashboard at the URIs given by CustomJob.web_access_uris or Trial.web_access_uris (within HyperparameterTuningJob.trials).
	EnableDashboardAccess *bool `pulumi:"enableDashboardAccess"`
	// Optional. Whether you want Vertex AI to enable [interactive shell access](https://cloud.google.com/vertex-ai/docs/training/monitor-debug-interactive-shell) to training containers. If set to `true`, you can access interactive shells at the URIs given by CustomJob.web_access_uris or Trial.web_access_uris (within HyperparameterTuningJob.trials).
	EnableWebAccess *bool `pulumi:"enableWebAccess"`
	// Optional. The Experiment associated with this job. Format: `projects/{project}/locations/{location}/metadataStores/{metadataStores}/contexts/{experiment-name}`
	Experiment *string `pulumi:"experiment"`
	// Optional. The Experiment Run associated with this job. Format: `projects/{project}/locations/{location}/metadataStores/{metadataStores}/contexts/{experiment-name}-{experiment-run-name}`
	ExperimentRun *string `pulumi:"experimentRun"`
	// Optional. The full name of the Compute Engine [network](/compute/docs/networks-and-firewalls#networks) to which the Job should be peered. For example, `projects/12345/global/networks/myVPC`. [Format](/compute/docs/reference/rest/v1/networks/insert) is of the form `projects/{project}/global/networks/{network}`. Where {project} is a project number, as in `12345`, and {network} is a network name. To specify this field, you must have already [configured VPC Network Peering for Vertex AI](https://cloud.google.com/vertex-ai/docs/general/vpc-peering). If this field is left unspecified, the job is not peered with any network.
	Network *string `pulumi:"network"`
	// The ID of the location to store protected artifacts. e.g. us-central1. Populate only when the location is different than CustomJob location. List of supported locations: https://cloud.google.com/vertex-ai/docs/general/locations
	ProtectedArtifactLocationId *string `pulumi:"protectedArtifactLocationId"`
	// Optional. A list of names for the reserved ip ranges under the VPC network that can be used for this job. If set, we will deploy the job within the provided ip ranges. Otherwise, the job will be deployed to any ip ranges under the provided VPC network. Example: ['vertex-ai-ip-range'].
	ReservedIpRanges []string `pulumi:"reservedIpRanges"`
	// Scheduling options for a CustomJob.
	Scheduling *GoogleCloudAiplatformV1Scheduling `pulumi:"scheduling"`
	// Specifies the service account for workload run-as account. Users submitting jobs must have act-as permission on this run-as account. If unspecified, the [Vertex AI Custom Code Service Agent](https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents) for the CustomJob's project is used.
	ServiceAccount *string `pulumi:"serviceAccount"`
	// Optional. The name of a Vertex AI Tensorboard resource to which this CustomJob will upload Tensorboard logs. Format: `projects/{project}/locations/{location}/tensorboards/{tensorboard}`
	Tensorboard *string `pulumi:"tensorboard"`
	// The spec of the worker pools including machine type and Docker image. All worker pools except the first one are optional and can be skipped by providing an empty value.
	WorkerPoolSpecs []GoogleCloudAiplatformV1WorkerPoolSpec `pulumi:"workerPoolSpecs"`
}

// GoogleCloudAiplatformV1CustomJobSpecInput is an input type that accepts GoogleCloudAiplatformV1CustomJobSpecArgs and GoogleCloudAiplatformV1CustomJobSpecOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1CustomJobSpecInput` via:
//
//	GoogleCloudAiplatformV1CustomJobSpecArgs{...}
type GoogleCloudAiplatformV1CustomJobSpecInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1CustomJobSpecOutput() GoogleCloudAiplatformV1CustomJobSpecOutput
	ToGoogleCloudAiplatformV1CustomJobSpecOutputWithContext(context.Context) GoogleCloudAiplatformV1CustomJobSpecOutput
}

// Represents the spec of a CustomJob.
type GoogleCloudAiplatformV1CustomJobSpecArgs struct {
	// The Cloud Storage location to store the output of this CustomJob or HyperparameterTuningJob. For HyperparameterTuningJob, the baseOutputDirectory of each child CustomJob backing a Trial is set to a subdirectory of name id under its parent HyperparameterTuningJob's baseOutputDirectory. The following Vertex AI environment variables will be passed to containers or python modules when this field is set: For CustomJob: * AIP_MODEL_DIR = `/model/` * AIP_CHECKPOINT_DIR = `/checkpoints/` * AIP_TENSORBOARD_LOG_DIR = `/logs/` For CustomJob backing a Trial of HyperparameterTuningJob: * AIP_MODEL_DIR = `//model/` * AIP_CHECKPOINT_DIR = `//checkpoints/` * AIP_TENSORBOARD_LOG_DIR = `//logs/`
	BaseOutputDirectory GoogleCloudAiplatformV1GcsDestinationPtrInput `pulumi:"baseOutputDirectory"`
	// Optional. Whether you want Vertex AI to enable access to the customized dashboard in training chief container. If set to `true`, you can access the dashboard at the URIs given by CustomJob.web_access_uris or Trial.web_access_uris (within HyperparameterTuningJob.trials).
	EnableDashboardAccess pulumi.BoolPtrInput `pulumi:"enableDashboardAccess"`
	// Optional. Whether you want Vertex AI to enable [interactive shell access](https://cloud.google.com/vertex-ai/docs/training/monitor-debug-interactive-shell) to training containers. If set to `true`, you can access interactive shells at the URIs given by CustomJob.web_access_uris or Trial.web_access_uris (within HyperparameterTuningJob.trials).
	EnableWebAccess pulumi.BoolPtrInput `pulumi:"enableWebAccess"`
	// Optional. The Experiment associated with this job. Format: `projects/{project}/locations/{location}/metadataStores/{metadataStores}/contexts/{experiment-name}`
	Experiment pulumi.StringPtrInput `pulumi:"experiment"`
	// Optional. The Experiment Run associated with this job. Format: `projects/{project}/locations/{location}/metadataStores/{metadataStores}/contexts/{experiment-name}-{experiment-run-name}`
	ExperimentRun pulumi.StringPtrInput `pulumi:"experimentRun"`
	// Optional. The full name of the Compute Engine [network](/compute/docs/networks-and-firewalls#networks) to which the Job should be peered. For example, `projects/12345/global/networks/myVPC`. [Format](/compute/docs/reference/rest/v1/networks/insert) is of the form `projects/{project}/global/networks/{network}`. Where {project} is a project number, as in `12345`, and {network} is a network name. To specify this field, you must have already [configured VPC Network Peering for Vertex AI](https://cloud.google.com/vertex-ai/docs/general/vpc-peering). If this field is left unspecified, the job is not peered with any network.
	Network pulumi.StringPtrInput `pulumi:"network"`
	// The ID of the location to store protected artifacts. e.g. us-central1. Populate only when the location is different than CustomJob location. List of supported locations: https://cloud.google.com/vertex-ai/docs/general/locations
	ProtectedArtifactLocationId pulumi.StringPtrInput `pulumi:"protectedArtifactLocationId"`
	// Optional. A list of names for the reserved ip ranges under the VPC network that can be used for this job. If set, we will deploy the job within the provided ip ranges. Otherwise, the job will be deployed to any ip ranges under the provided VPC network. Example: ['vertex-ai-ip-range'].
	ReservedIpRanges pulumi.StringArrayInput `pulumi:"reservedIpRanges"`
	// Scheduling options for a CustomJob.
	Scheduling GoogleCloudAiplatformV1SchedulingPtrInput `pulumi:"scheduling"`
	// Specifies the service account for workload run-as account. Users submitting jobs must have act-as permission on this run-as account. If unspecified, the [Vertex AI Custom Code Service Agent](https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents) for the CustomJob's project is used.
	ServiceAccount pulumi.StringPtrInput `pulumi:"serviceAccount"`
	// Optional. The name of a Vertex AI Tensorboard resource to which this CustomJob will upload Tensorboard logs. Format: `projects/{project}/locations/{location}/tensorboards/{tensorboard}`
	Tensorboard pulumi.StringPtrInput `pulumi:"tensorboard"`
	// The spec of the worker pools including machine type and Docker image. All worker pools except the first one are optional and can be skipped by providing an empty value.
	WorkerPoolSpecs GoogleCloudAiplatformV1WorkerPoolSpecArrayInput `pulumi:"workerPoolSpecs"`
}

func (GoogleCloudAiplatformV1CustomJobSpecArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1CustomJobSpec)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1CustomJobSpecArgs) ToGoogleCloudAiplatformV1CustomJobSpecOutput() GoogleCloudAiplatformV1CustomJobSpecOutput {
	return i.ToGoogleCloudAiplatformV1CustomJobSpecOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1CustomJobSpecArgs) ToGoogleCloudAiplatformV1CustomJobSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1CustomJobSpecOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1CustomJobSpecOutput)
}

func (i GoogleCloudAiplatformV1CustomJobSpecArgs) ToGoogleCloudAiplatformV1CustomJobSpecPtrOutput() GoogleCloudAiplatformV1CustomJobSpecPtrOutput {
	return i.ToGoogleCloudAiplatformV1CustomJobSpecPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1CustomJobSpecArgs) ToGoogleCloudAiplatformV1CustomJobSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1CustomJobSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1CustomJobSpecOutput).ToGoogleCloudAiplatformV1CustomJobSpecPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1CustomJobSpecPtrInput is an input type that accepts GoogleCloudAiplatformV1CustomJobSpecArgs, GoogleCloudAiplatformV1CustomJobSpecPtr and GoogleCloudAiplatformV1CustomJobSpecPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1CustomJobSpecPtrInput` via:
//
//	        GoogleCloudAiplatformV1CustomJobSpecArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1CustomJobSpecPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1CustomJobSpecPtrOutput() GoogleCloudAiplatformV1CustomJobSpecPtrOutput
	ToGoogleCloudAiplatformV1CustomJobSpecPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1CustomJobSpecPtrOutput
}

type googleCloudAiplatformV1CustomJobSpecPtrType GoogleCloudAiplatformV1CustomJobSpecArgs

func GoogleCloudAiplatformV1CustomJobSpecPtr(v *GoogleCloudAiplatformV1CustomJobSpecArgs) GoogleCloudAiplatformV1CustomJobSpecPtrInput {
	return (*googleCloudAiplatformV1CustomJobSpecPtrType)(v)
}

func (*googleCloudAiplatformV1CustomJobSpecPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1CustomJobSpec)(nil)).Elem()
}

func (i *googleCloudAiplatformV1CustomJobSpecPtrType) ToGoogleCloudAiplatformV1CustomJobSpecPtrOutput() GoogleCloudAiplatformV1CustomJobSpecPtrOutput {
	return i.ToGoogleCloudAiplatformV1CustomJobSpecPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1CustomJobSpecPtrType) ToGoogleCloudAiplatformV1CustomJobSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1CustomJobSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1CustomJobSpecPtrOutput)
}

// Represents the spec of a CustomJob.
type GoogleCloudAiplatformV1CustomJobSpecOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1CustomJobSpecOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1CustomJobSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1CustomJobSpecOutput) ToGoogleCloudAiplatformV1CustomJobSpecOutput() GoogleCloudAiplatformV1CustomJobSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1CustomJobSpecOutput) ToGoogleCloudAiplatformV1CustomJobSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1CustomJobSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1CustomJobSpecOutput) ToGoogleCloudAiplatformV1CustomJobSpecPtrOutput() GoogleCloudAiplatformV1CustomJobSpecPtrOutput {
	return o.ToGoogleCloudAiplatformV1CustomJobSpecPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1CustomJobSpecOutput) ToGoogleCloudAiplatformV1CustomJobSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1CustomJobSpecPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1CustomJobSpec) *GoogleCloudAiplatformV1CustomJobSpec {
		return &v
	}).(GoogleCloudAiplatformV1CustomJobSpecPtrOutput)
}

// The Cloud Storage location to store the output of this CustomJob or HyperparameterTuningJob. For HyperparameterTuningJob, the baseOutputDirectory of each child CustomJob backing a Trial is set to a subdirectory of name id under its parent HyperparameterTuningJob's baseOutputDirectory. The following Vertex AI environment variables will be passed to containers or python modules when this field is set: For CustomJob: * AIP_MODEL_DIR = `/model/` * AIP_CHECKPOINT_DIR = `/checkpoints/` * AIP_TENSORBOARD_LOG_DIR = `/logs/` For CustomJob backing a Trial of HyperparameterTuningJob: * AIP_MODEL_DIR = `//model/` * AIP_CHECKPOINT_DIR = `//checkpoints/` * AIP_TENSORBOARD_LOG_DIR = `//logs/`
func (o GoogleCloudAiplatformV1CustomJobSpecOutput) BaseOutputDirectory() GoogleCloudAiplatformV1GcsDestinationPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1CustomJobSpec) *GoogleCloudAiplatformV1GcsDestination {
		return v.BaseOutputDirectory
	}).(GoogleCloudAiplatformV1GcsDestinationPtrOutput)
}

// Optional. Whether you want Vertex AI to enable access to the customized dashboard in training chief container. If set to `true`, you can access the dashboard at the URIs given by CustomJob.web_access_uris or Trial.web_access_uris (within HyperparameterTuningJob.trials).
func (o GoogleCloudAiplatformV1CustomJobSpecOutput) EnableDashboardAccess() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1CustomJobSpec) *bool { return v.EnableDashboardAccess }).(pulumi.BoolPtrOutput)
}

// Optional. Whether you want Vertex AI to enable [interactive shell access](https://cloud.google.com/vertex-ai/docs/training/monitor-debug-interactive-shell) to training containers. If set to `true`, you can access interactive shells at the URIs given by CustomJob.web_access_uris or Trial.web_access_uris (within HyperparameterTuningJob.trials).
func (o GoogleCloudAiplatformV1CustomJobSpecOutput) EnableWebAccess() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1CustomJobSpec) *bool { return v.EnableWebAccess }).(pulumi.BoolPtrOutput)
}

// Optional. The Experiment associated with this job. Format: `projects/{project}/locations/{location}/metadataStores/{metadataStores}/contexts/{experiment-name}`
func (o GoogleCloudAiplatformV1CustomJobSpecOutput) Experiment() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1CustomJobSpec) *string { return v.Experiment }).(pulumi.StringPtrOutput)
}

// Optional. The Experiment Run associated with this job. Format: `projects/{project}/locations/{location}/metadataStores/{metadataStores}/contexts/{experiment-name}-{experiment-run-name}`
func (o GoogleCloudAiplatformV1CustomJobSpecOutput) ExperimentRun() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1CustomJobSpec) *string { return v.ExperimentRun }).(pulumi.StringPtrOutput)
}

// Optional. The full name of the Compute Engine [network](/compute/docs/networks-and-firewalls#networks) to which the Job should be peered. For example, `projects/12345/global/networks/myVPC`. [Format](/compute/docs/reference/rest/v1/networks/insert) is of the form `projects/{project}/global/networks/{network}`. Where {project} is a project number, as in `12345`, and {network} is a network name. To specify this field, you must have already [configured VPC Network Peering for Vertex AI](https://cloud.google.com/vertex-ai/docs/general/vpc-peering). If this field is left unspecified, the job is not peered with any network.
func (o GoogleCloudAiplatformV1CustomJobSpecOutput) Network() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1CustomJobSpec) *string { return v.Network }).(pulumi.StringPtrOutput)
}

// The ID of the location to store protected artifacts. e.g. us-central1. Populate only when the location is different than CustomJob location. List of supported locations: https://cloud.google.com/vertex-ai/docs/general/locations
func (o GoogleCloudAiplatformV1CustomJobSpecOutput) ProtectedArtifactLocationId() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1CustomJobSpec) *string { return v.ProtectedArtifactLocationId }).(pulumi.StringPtrOutput)
}

// Optional. A list of names for the reserved ip ranges under the VPC network that can be used for this job. If set, we will deploy the job within the provided ip ranges. Otherwise, the job will be deployed to any ip ranges under the provided VPC network. Example: ['vertex-ai-ip-range'].
func (o GoogleCloudAiplatformV1CustomJobSpecOutput) ReservedIpRanges() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1CustomJobSpec) []string { return v.ReservedIpRanges }).(pulumi.StringArrayOutput)
}

// Scheduling options for a CustomJob.
func (o GoogleCloudAiplatformV1CustomJobSpecOutput) Scheduling() GoogleCloudAiplatformV1SchedulingPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1CustomJobSpec) *GoogleCloudAiplatformV1Scheduling { return v.Scheduling }).(GoogleCloudAiplatformV1SchedulingPtrOutput)
}

// Specifies the service account for workload run-as account. Users submitting jobs must have act-as permission on this run-as account. If unspecified, the [Vertex AI Custom Code Service Agent](https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents) for the CustomJob's project is used.
func (o GoogleCloudAiplatformV1CustomJobSpecOutput) ServiceAccount() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1CustomJobSpec) *string { return v.ServiceAccount }).(pulumi.StringPtrOutput)
}

// Optional. The name of a Vertex AI Tensorboard resource to which this CustomJob will upload Tensorboard logs. Format: `projects/{project}/locations/{location}/tensorboards/{tensorboard}`
func (o GoogleCloudAiplatformV1CustomJobSpecOutput) Tensorboard() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1CustomJobSpec) *string { return v.Tensorboard }).(pulumi.StringPtrOutput)
}

// The spec of the worker pools including machine type and Docker image. All worker pools except the first one are optional and can be skipped by providing an empty value.
func (o GoogleCloudAiplatformV1CustomJobSpecOutput) WorkerPoolSpecs() GoogleCloudAiplatformV1WorkerPoolSpecArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1CustomJobSpec) []GoogleCloudAiplatformV1WorkerPoolSpec {
		return v.WorkerPoolSpecs
	}).(GoogleCloudAiplatformV1WorkerPoolSpecArrayOutput)
}

type GoogleCloudAiplatformV1CustomJobSpecPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1CustomJobSpecPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1CustomJobSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1CustomJobSpecPtrOutput) ToGoogleCloudAiplatformV1CustomJobSpecPtrOutput() GoogleCloudAiplatformV1CustomJobSpecPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1CustomJobSpecPtrOutput) ToGoogleCloudAiplatformV1CustomJobSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1CustomJobSpecPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1CustomJobSpecPtrOutput) Elem() GoogleCloudAiplatformV1CustomJobSpecOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1CustomJobSpec) GoogleCloudAiplatformV1CustomJobSpec {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1CustomJobSpec
		return ret
	}).(GoogleCloudAiplatformV1CustomJobSpecOutput)
}

// The Cloud Storage location to store the output of this CustomJob or HyperparameterTuningJob. For HyperparameterTuningJob, the baseOutputDirectory of each child CustomJob backing a Trial is set to a subdirectory of name id under its parent HyperparameterTuningJob's baseOutputDirectory. The following Vertex AI environment variables will be passed to containers or python modules when this field is set: For CustomJob: * AIP_MODEL_DIR = `/model/` * AIP_CHECKPOINT_DIR = `/checkpoints/` * AIP_TENSORBOARD_LOG_DIR = `/logs/` For CustomJob backing a Trial of HyperparameterTuningJob: * AIP_MODEL_DIR = `//model/` * AIP_CHECKPOINT_DIR = `//checkpoints/` * AIP_TENSORBOARD_LOG_DIR = `//logs/`
func (o GoogleCloudAiplatformV1CustomJobSpecPtrOutput) BaseOutputDirectory() GoogleCloudAiplatformV1GcsDestinationPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1CustomJobSpec) *GoogleCloudAiplatformV1GcsDestination {
		if v == nil {
			return nil
		}
		return v.BaseOutputDirectory
	}).(GoogleCloudAiplatformV1GcsDestinationPtrOutput)
}

// Optional. Whether you want Vertex AI to enable access to the customized dashboard in training chief container. If set to `true`, you can access the dashboard at the URIs given by CustomJob.web_access_uris or Trial.web_access_uris (within HyperparameterTuningJob.trials).
func (o GoogleCloudAiplatformV1CustomJobSpecPtrOutput) EnableDashboardAccess() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1CustomJobSpec) *bool {
		if v == nil {
			return nil
		}
		return v.EnableDashboardAccess
	}).(pulumi.BoolPtrOutput)
}

// Optional. Whether you want Vertex AI to enable [interactive shell access](https://cloud.google.com/vertex-ai/docs/training/monitor-debug-interactive-shell) to training containers. If set to `true`, you can access interactive shells at the URIs given by CustomJob.web_access_uris or Trial.web_access_uris (within HyperparameterTuningJob.trials).
func (o GoogleCloudAiplatformV1CustomJobSpecPtrOutput) EnableWebAccess() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1CustomJobSpec) *bool {
		if v == nil {
			return nil
		}
		return v.EnableWebAccess
	}).(pulumi.BoolPtrOutput)
}

// Optional. The Experiment associated with this job. Format: `projects/{project}/locations/{location}/metadataStores/{metadataStores}/contexts/{experiment-name}`
func (o GoogleCloudAiplatformV1CustomJobSpecPtrOutput) Experiment() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1CustomJobSpec) *string {
		if v == nil {
			return nil
		}
		return v.Experiment
	}).(pulumi.StringPtrOutput)
}

// Optional. The Experiment Run associated with this job. Format: `projects/{project}/locations/{location}/metadataStores/{metadataStores}/contexts/{experiment-name}-{experiment-run-name}`
func (o GoogleCloudAiplatformV1CustomJobSpecPtrOutput) ExperimentRun() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1CustomJobSpec) *string {
		if v == nil {
			return nil
		}
		return v.ExperimentRun
	}).(pulumi.StringPtrOutput)
}

// Optional. The full name of the Compute Engine [network](/compute/docs/networks-and-firewalls#networks) to which the Job should be peered. For example, `projects/12345/global/networks/myVPC`. [Format](/compute/docs/reference/rest/v1/networks/insert) is of the form `projects/{project}/global/networks/{network}`. Where {project} is a project number, as in `12345`, and {network} is a network name. To specify this field, you must have already [configured VPC Network Peering for Vertex AI](https://cloud.google.com/vertex-ai/docs/general/vpc-peering). If this field is left unspecified, the job is not peered with any network.
func (o GoogleCloudAiplatformV1CustomJobSpecPtrOutput) Network() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1CustomJobSpec) *string {
		if v == nil {
			return nil
		}
		return v.Network
	}).(pulumi.StringPtrOutput)
}

// The ID of the location to store protected artifacts. e.g. us-central1. Populate only when the location is different than CustomJob location. List of supported locations: https://cloud.google.com/vertex-ai/docs/general/locations
func (o GoogleCloudAiplatformV1CustomJobSpecPtrOutput) ProtectedArtifactLocationId() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1CustomJobSpec) *string {
		if v == nil {
			return nil
		}
		return v.ProtectedArtifactLocationId
	}).(pulumi.StringPtrOutput)
}

// Optional. A list of names for the reserved ip ranges under the VPC network that can be used for this job. If set, we will deploy the job within the provided ip ranges. Otherwise, the job will be deployed to any ip ranges under the provided VPC network. Example: ['vertex-ai-ip-range'].
func (o GoogleCloudAiplatformV1CustomJobSpecPtrOutput) ReservedIpRanges() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1CustomJobSpec) []string {
		if v == nil {
			return nil
		}
		return v.ReservedIpRanges
	}).(pulumi.StringArrayOutput)
}

// Scheduling options for a CustomJob.
func (o GoogleCloudAiplatformV1CustomJobSpecPtrOutput) Scheduling() GoogleCloudAiplatformV1SchedulingPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1CustomJobSpec) *GoogleCloudAiplatformV1Scheduling {
		if v == nil {
			return nil
		}
		return v.Scheduling
	}).(GoogleCloudAiplatformV1SchedulingPtrOutput)
}

// Specifies the service account for workload run-as account. Users submitting jobs must have act-as permission on this run-as account. If unspecified, the [Vertex AI Custom Code Service Agent](https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents) for the CustomJob's project is used.
func (o GoogleCloudAiplatformV1CustomJobSpecPtrOutput) ServiceAccount() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1CustomJobSpec) *string {
		if v == nil {
			return nil
		}
		return v.ServiceAccount
	}).(pulumi.StringPtrOutput)
}

// Optional. The name of a Vertex AI Tensorboard resource to which this CustomJob will upload Tensorboard logs. Format: `projects/{project}/locations/{location}/tensorboards/{tensorboard}`
func (o GoogleCloudAiplatformV1CustomJobSpecPtrOutput) Tensorboard() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1CustomJobSpec) *string {
		if v == nil {
			return nil
		}
		return v.Tensorboard
	}).(pulumi.StringPtrOutput)
}

// The spec of the worker pools including machine type and Docker image. All worker pools except the first one are optional and can be skipped by providing an empty value.
func (o GoogleCloudAiplatformV1CustomJobSpecPtrOutput) WorkerPoolSpecs() GoogleCloudAiplatformV1WorkerPoolSpecArrayOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1CustomJobSpec) []GoogleCloudAiplatformV1WorkerPoolSpec {
		if v == nil {
			return nil
		}
		return v.WorkerPoolSpecs
	}).(GoogleCloudAiplatformV1WorkerPoolSpecArrayOutput)
}

// Represents the spec of a CustomJob.
type GoogleCloudAiplatformV1CustomJobSpecResponse struct {
	// The Cloud Storage location to store the output of this CustomJob or HyperparameterTuningJob. For HyperparameterTuningJob, the baseOutputDirectory of each child CustomJob backing a Trial is set to a subdirectory of name id under its parent HyperparameterTuningJob's baseOutputDirectory. The following Vertex AI environment variables will be passed to containers or python modules when this field is set: For CustomJob: * AIP_MODEL_DIR = `/model/` * AIP_CHECKPOINT_DIR = `/checkpoints/` * AIP_TENSORBOARD_LOG_DIR = `/logs/` For CustomJob backing a Trial of HyperparameterTuningJob: * AIP_MODEL_DIR = `//model/` * AIP_CHECKPOINT_DIR = `//checkpoints/` * AIP_TENSORBOARD_LOG_DIR = `//logs/`
	BaseOutputDirectory GoogleCloudAiplatformV1GcsDestinationResponse `pulumi:"baseOutputDirectory"`
	// Optional. Whether you want Vertex AI to enable access to the customized dashboard in training chief container. If set to `true`, you can access the dashboard at the URIs given by CustomJob.web_access_uris or Trial.web_access_uris (within HyperparameterTuningJob.trials).
	EnableDashboardAccess bool `pulumi:"enableDashboardAccess"`
	// Optional. Whether you want Vertex AI to enable [interactive shell access](https://cloud.google.com/vertex-ai/docs/training/monitor-debug-interactive-shell) to training containers. If set to `true`, you can access interactive shells at the URIs given by CustomJob.web_access_uris or Trial.web_access_uris (within HyperparameterTuningJob.trials).
	EnableWebAccess bool `pulumi:"enableWebAccess"`
	// Optional. The Experiment associated with this job. Format: `projects/{project}/locations/{location}/metadataStores/{metadataStores}/contexts/{experiment-name}`
	Experiment string `pulumi:"experiment"`
	// Optional. The Experiment Run associated with this job. Format: `projects/{project}/locations/{location}/metadataStores/{metadataStores}/contexts/{experiment-name}-{experiment-run-name}`
	ExperimentRun string `pulumi:"experimentRun"`
	// Optional. The full name of the Compute Engine [network](/compute/docs/networks-and-firewalls#networks) to which the Job should be peered. For example, `projects/12345/global/networks/myVPC`. [Format](/compute/docs/reference/rest/v1/networks/insert) is of the form `projects/{project}/global/networks/{network}`. Where {project} is a project number, as in `12345`, and {network} is a network name. To specify this field, you must have already [configured VPC Network Peering for Vertex AI](https://cloud.google.com/vertex-ai/docs/general/vpc-peering). If this field is left unspecified, the job is not peered with any network.
	Network string `pulumi:"network"`
	// The ID of the location to store protected artifacts. e.g. us-central1. Populate only when the location is different than CustomJob location. List of supported locations: https://cloud.google.com/vertex-ai/docs/general/locations
	ProtectedArtifactLocationId string `pulumi:"protectedArtifactLocationId"`
	// Optional. A list of names for the reserved ip ranges under the VPC network that can be used for this job. If set, we will deploy the job within the provided ip ranges. Otherwise, the job will be deployed to any ip ranges under the provided VPC network. Example: ['vertex-ai-ip-range'].
	ReservedIpRanges []string `pulumi:"reservedIpRanges"`
	// Scheduling options for a CustomJob.
	Scheduling GoogleCloudAiplatformV1SchedulingResponse `pulumi:"scheduling"`
	// Specifies the service account for workload run-as account. Users submitting jobs must have act-as permission on this run-as account. If unspecified, the [Vertex AI Custom Code Service Agent](https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents) for the CustomJob's project is used.
	ServiceAccount string `pulumi:"serviceAccount"`
	// Optional. The name of a Vertex AI Tensorboard resource to which this CustomJob will upload Tensorboard logs. Format: `projects/{project}/locations/{location}/tensorboards/{tensorboard}`
	Tensorboard string `pulumi:"tensorboard"`
	// The spec of the worker pools including machine type and Docker image. All worker pools except the first one are optional and can be skipped by providing an empty value.
	WorkerPoolSpecs []GoogleCloudAiplatformV1WorkerPoolSpecResponse `pulumi:"workerPoolSpecs"`
}

// Represents the spec of a CustomJob.
type GoogleCloudAiplatformV1CustomJobSpecResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1CustomJobSpecResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1CustomJobSpecResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1CustomJobSpecResponseOutput) ToGoogleCloudAiplatformV1CustomJobSpecResponseOutput() GoogleCloudAiplatformV1CustomJobSpecResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1CustomJobSpecResponseOutput) ToGoogleCloudAiplatformV1CustomJobSpecResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1CustomJobSpecResponseOutput {
	return o
}

// The Cloud Storage location to store the output of this CustomJob or HyperparameterTuningJob. For HyperparameterTuningJob, the baseOutputDirectory of each child CustomJob backing a Trial is set to a subdirectory of name id under its parent HyperparameterTuningJob's baseOutputDirectory. The following Vertex AI environment variables will be passed to containers or python modules when this field is set: For CustomJob: * AIP_MODEL_DIR = `/model/` * AIP_CHECKPOINT_DIR = `/checkpoints/` * AIP_TENSORBOARD_LOG_DIR = `/logs/` For CustomJob backing a Trial of HyperparameterTuningJob: * AIP_MODEL_DIR = `//model/` * AIP_CHECKPOINT_DIR = `//checkpoints/` * AIP_TENSORBOARD_LOG_DIR = `//logs/`
func (o GoogleCloudAiplatformV1CustomJobSpecResponseOutput) BaseOutputDirectory() GoogleCloudAiplatformV1GcsDestinationResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1CustomJobSpecResponse) GoogleCloudAiplatformV1GcsDestinationResponse {
		return v.BaseOutputDirectory
	}).(GoogleCloudAiplatformV1GcsDestinationResponseOutput)
}

// Optional. Whether you want Vertex AI to enable access to the customized dashboard in training chief container. If set to `true`, you can access the dashboard at the URIs given by CustomJob.web_access_uris or Trial.web_access_uris (within HyperparameterTuningJob.trials).
func (o GoogleCloudAiplatformV1CustomJobSpecResponseOutput) EnableDashboardAccess() pulumi.BoolOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1CustomJobSpecResponse) bool { return v.EnableDashboardAccess }).(pulumi.BoolOutput)
}

// Optional. Whether you want Vertex AI to enable [interactive shell access](https://cloud.google.com/vertex-ai/docs/training/monitor-debug-interactive-shell) to training containers. If set to `true`, you can access interactive shells at the URIs given by CustomJob.web_access_uris or Trial.web_access_uris (within HyperparameterTuningJob.trials).
func (o GoogleCloudAiplatformV1CustomJobSpecResponseOutput) EnableWebAccess() pulumi.BoolOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1CustomJobSpecResponse) bool { return v.EnableWebAccess }).(pulumi.BoolOutput)
}

// Optional. The Experiment associated with this job. Format: `projects/{project}/locations/{location}/metadataStores/{metadataStores}/contexts/{experiment-name}`
func (o GoogleCloudAiplatformV1CustomJobSpecResponseOutput) Experiment() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1CustomJobSpecResponse) string { return v.Experiment }).(pulumi.StringOutput)
}

// Optional. The Experiment Run associated with this job. Format: `projects/{project}/locations/{location}/metadataStores/{metadataStores}/contexts/{experiment-name}-{experiment-run-name}`
func (o GoogleCloudAiplatformV1CustomJobSpecResponseOutput) ExperimentRun() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1CustomJobSpecResponse) string { return v.ExperimentRun }).(pulumi.StringOutput)
}

// Optional. The full name of the Compute Engine [network](/compute/docs/networks-and-firewalls#networks) to which the Job should be peered. For example, `projects/12345/global/networks/myVPC`. [Format](/compute/docs/reference/rest/v1/networks/insert) is of the form `projects/{project}/global/networks/{network}`. Where {project} is a project number, as in `12345`, and {network} is a network name. To specify this field, you must have already [configured VPC Network Peering for Vertex AI](https://cloud.google.com/vertex-ai/docs/general/vpc-peering). If this field is left unspecified, the job is not peered with any network.
func (o GoogleCloudAiplatformV1CustomJobSpecResponseOutput) Network() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1CustomJobSpecResponse) string { return v.Network }).(pulumi.StringOutput)
}

// The ID of the location to store protected artifacts. e.g. us-central1. Populate only when the location is different than CustomJob location. List of supported locations: https://cloud.google.com/vertex-ai/docs/general/locations
func (o GoogleCloudAiplatformV1CustomJobSpecResponseOutput) ProtectedArtifactLocationId() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1CustomJobSpecResponse) string { return v.ProtectedArtifactLocationId }).(pulumi.StringOutput)
}

// Optional. A list of names for the reserved ip ranges under the VPC network that can be used for this job. If set, we will deploy the job within the provided ip ranges. Otherwise, the job will be deployed to any ip ranges under the provided VPC network. Example: ['vertex-ai-ip-range'].
func (o GoogleCloudAiplatformV1CustomJobSpecResponseOutput) ReservedIpRanges() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1CustomJobSpecResponse) []string { return v.ReservedIpRanges }).(pulumi.StringArrayOutput)
}

// Scheduling options for a CustomJob.
func (o GoogleCloudAiplatformV1CustomJobSpecResponseOutput) Scheduling() GoogleCloudAiplatformV1SchedulingResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1CustomJobSpecResponse) GoogleCloudAiplatformV1SchedulingResponse {
		return v.Scheduling
	}).(GoogleCloudAiplatformV1SchedulingResponseOutput)
}

// Specifies the service account for workload run-as account. Users submitting jobs must have act-as permission on this run-as account. If unspecified, the [Vertex AI Custom Code Service Agent](https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents) for the CustomJob's project is used.
func (o GoogleCloudAiplatformV1CustomJobSpecResponseOutput) ServiceAccount() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1CustomJobSpecResponse) string { return v.ServiceAccount }).(pulumi.StringOutput)
}

// Optional. The name of a Vertex AI Tensorboard resource to which this CustomJob will upload Tensorboard logs. Format: `projects/{project}/locations/{location}/tensorboards/{tensorboard}`
func (o GoogleCloudAiplatformV1CustomJobSpecResponseOutput) Tensorboard() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1CustomJobSpecResponse) string { return v.Tensorboard }).(pulumi.StringOutput)
}

// The spec of the worker pools including machine type and Docker image. All worker pools except the first one are optional and can be skipped by providing an empty value.
func (o GoogleCloudAiplatformV1CustomJobSpecResponseOutput) WorkerPoolSpecs() GoogleCloudAiplatformV1WorkerPoolSpecResponseArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1CustomJobSpecResponse) []GoogleCloudAiplatformV1WorkerPoolSpecResponse {
		return v.WorkerPoolSpecs
	}).(GoogleCloudAiplatformV1WorkerPoolSpecResponseArrayOutput)
}

// A description of resources that are dedicated to a DeployedModel, and that need a higher degree of manual configuration.
type GoogleCloudAiplatformV1DedicatedResources struct {
	// Immutable. The metric specifications that overrides a resource utilization metric (CPU utilization, accelerator's duty cycle, and so on) target value (default to 60 if not set). At most one entry is allowed per metric. If machine_spec.accelerator_count is above 0, the autoscaling will be based on both CPU utilization and accelerator's duty cycle metrics and scale up when either metrics exceeds its target value while scale down if both metrics are under their target value. The default target value is 60 for both metrics. If machine_spec.accelerator_count is 0, the autoscaling will be based on CPU utilization metric only with default target value 60 if not explicitly set. For example, in the case of Online Prediction, if you want to override target CPU utilization to 80, you should set autoscaling_metric_specs.metric_name to `aiplatform.googleapis.com/prediction/online/cpu/utilization` and autoscaling_metric_specs.target to `80`.
	AutoscalingMetricSpecs []GoogleCloudAiplatformV1AutoscalingMetricSpec `pulumi:"autoscalingMetricSpecs"`
	// Immutable. The specification of a single machine used by the prediction.
	MachineSpec GoogleCloudAiplatformV1MachineSpec `pulumi:"machineSpec"`
	// Immutable. The maximum number of replicas this DeployedModel may be deployed on when the traffic against it increases. If the requested value is too large, the deployment will error, but if deployment succeeds then the ability to scale the model to that many replicas is guaranteed (barring service outages). If traffic against the DeployedModel increases beyond what its replicas at maximum may handle, a portion of the traffic will be dropped. If this value is not provided, will use min_replica_count as the default value. The value of this field impacts the charge against Vertex CPU and GPU quotas. Specifically, you will be charged for (max_replica_count * number of cores in the selected machine type) and (max_replica_count * number of GPUs per replica in the selected machine type).
	MaxReplicaCount *int `pulumi:"maxReplicaCount"`
	// Immutable. The minimum number of machine replicas this DeployedModel will be always deployed on. This value must be greater than or equal to 1. If traffic against the DeployedModel increases, it may dynamically be deployed onto more replicas, and as traffic decreases, some of these extra replicas may be freed.
	MinReplicaCount int `pulumi:"minReplicaCount"`
}

// GoogleCloudAiplatformV1DedicatedResourcesInput is an input type that accepts GoogleCloudAiplatformV1DedicatedResourcesArgs and GoogleCloudAiplatformV1DedicatedResourcesOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1DedicatedResourcesInput` via:
//
//	GoogleCloudAiplatformV1DedicatedResourcesArgs{...}
type GoogleCloudAiplatformV1DedicatedResourcesInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1DedicatedResourcesOutput() GoogleCloudAiplatformV1DedicatedResourcesOutput
	ToGoogleCloudAiplatformV1DedicatedResourcesOutputWithContext(context.Context) GoogleCloudAiplatformV1DedicatedResourcesOutput
}

// A description of resources that are dedicated to a DeployedModel, and that need a higher degree of manual configuration.
type GoogleCloudAiplatformV1DedicatedResourcesArgs struct {
	// Immutable. The metric specifications that overrides a resource utilization metric (CPU utilization, accelerator's duty cycle, and so on) target value (default to 60 if not set). At most one entry is allowed per metric. If machine_spec.accelerator_count is above 0, the autoscaling will be based on both CPU utilization and accelerator's duty cycle metrics and scale up when either metrics exceeds its target value while scale down if both metrics are under their target value. The default target value is 60 for both metrics. If machine_spec.accelerator_count is 0, the autoscaling will be based on CPU utilization metric only with default target value 60 if not explicitly set. For example, in the case of Online Prediction, if you want to override target CPU utilization to 80, you should set autoscaling_metric_specs.metric_name to `aiplatform.googleapis.com/prediction/online/cpu/utilization` and autoscaling_metric_specs.target to `80`.
	AutoscalingMetricSpecs GoogleCloudAiplatformV1AutoscalingMetricSpecArrayInput `pulumi:"autoscalingMetricSpecs"`
	// Immutable. The specification of a single machine used by the prediction.
	MachineSpec GoogleCloudAiplatformV1MachineSpecInput `pulumi:"machineSpec"`
	// Immutable. The maximum number of replicas this DeployedModel may be deployed on when the traffic against it increases. If the requested value is too large, the deployment will error, but if deployment succeeds then the ability to scale the model to that many replicas is guaranteed (barring service outages). If traffic against the DeployedModel increases beyond what its replicas at maximum may handle, a portion of the traffic will be dropped. If this value is not provided, will use min_replica_count as the default value. The value of this field impacts the charge against Vertex CPU and GPU quotas. Specifically, you will be charged for (max_replica_count * number of cores in the selected machine type) and (max_replica_count * number of GPUs per replica in the selected machine type).
	MaxReplicaCount pulumi.IntPtrInput `pulumi:"maxReplicaCount"`
	// Immutable. The minimum number of machine replicas this DeployedModel will be always deployed on. This value must be greater than or equal to 1. If traffic against the DeployedModel increases, it may dynamically be deployed onto more replicas, and as traffic decreases, some of these extra replicas may be freed.
	MinReplicaCount pulumi.IntInput `pulumi:"minReplicaCount"`
}

func (GoogleCloudAiplatformV1DedicatedResourcesArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1DedicatedResources)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1DedicatedResourcesArgs) ToGoogleCloudAiplatformV1DedicatedResourcesOutput() GoogleCloudAiplatformV1DedicatedResourcesOutput {
	return i.ToGoogleCloudAiplatformV1DedicatedResourcesOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1DedicatedResourcesArgs) ToGoogleCloudAiplatformV1DedicatedResourcesOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1DedicatedResourcesOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1DedicatedResourcesOutput)
}

// A description of resources that are dedicated to a DeployedModel, and that need a higher degree of manual configuration.
type GoogleCloudAiplatformV1DedicatedResourcesOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1DedicatedResourcesOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1DedicatedResources)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1DedicatedResourcesOutput) ToGoogleCloudAiplatformV1DedicatedResourcesOutput() GoogleCloudAiplatformV1DedicatedResourcesOutput {
	return o
}

func (o GoogleCloudAiplatformV1DedicatedResourcesOutput) ToGoogleCloudAiplatformV1DedicatedResourcesOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1DedicatedResourcesOutput {
	return o
}

// Immutable. The metric specifications that overrides a resource utilization metric (CPU utilization, accelerator's duty cycle, and so on) target value (default to 60 if not set). At most one entry is allowed per metric. If machine_spec.accelerator_count is above 0, the autoscaling will be based on both CPU utilization and accelerator's duty cycle metrics and scale up when either metrics exceeds its target value while scale down if both metrics are under their target value. The default target value is 60 for both metrics. If machine_spec.accelerator_count is 0, the autoscaling will be based on CPU utilization metric only with default target value 60 if not explicitly set. For example, in the case of Online Prediction, if you want to override target CPU utilization to 80, you should set autoscaling_metric_specs.metric_name to `aiplatform.googleapis.com/prediction/online/cpu/utilization` and autoscaling_metric_specs.target to `80`.
func (o GoogleCloudAiplatformV1DedicatedResourcesOutput) AutoscalingMetricSpecs() GoogleCloudAiplatformV1AutoscalingMetricSpecArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1DedicatedResources) []GoogleCloudAiplatformV1AutoscalingMetricSpec {
		return v.AutoscalingMetricSpecs
	}).(GoogleCloudAiplatformV1AutoscalingMetricSpecArrayOutput)
}

// Immutable. The specification of a single machine used by the prediction.
func (o GoogleCloudAiplatformV1DedicatedResourcesOutput) MachineSpec() GoogleCloudAiplatformV1MachineSpecOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1DedicatedResources) GoogleCloudAiplatformV1MachineSpec {
		return v.MachineSpec
	}).(GoogleCloudAiplatformV1MachineSpecOutput)
}

// Immutable. The maximum number of replicas this DeployedModel may be deployed on when the traffic against it increases. If the requested value is too large, the deployment will error, but if deployment succeeds then the ability to scale the model to that many replicas is guaranteed (barring service outages). If traffic against the DeployedModel increases beyond what its replicas at maximum may handle, a portion of the traffic will be dropped. If this value is not provided, will use min_replica_count as the default value. The value of this field impacts the charge against Vertex CPU and GPU quotas. Specifically, you will be charged for (max_replica_count * number of cores in the selected machine type) and (max_replica_count * number of GPUs per replica in the selected machine type).
func (o GoogleCloudAiplatformV1DedicatedResourcesOutput) MaxReplicaCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1DedicatedResources) *int { return v.MaxReplicaCount }).(pulumi.IntPtrOutput)
}

// Immutable. The minimum number of machine replicas this DeployedModel will be always deployed on. This value must be greater than or equal to 1. If traffic against the DeployedModel increases, it may dynamically be deployed onto more replicas, and as traffic decreases, some of these extra replicas may be freed.
func (o GoogleCloudAiplatformV1DedicatedResourcesOutput) MinReplicaCount() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1DedicatedResources) int { return v.MinReplicaCount }).(pulumi.IntOutput)
}

// A description of resources that are dedicated to a DeployedModel, and that need a higher degree of manual configuration.
type GoogleCloudAiplatformV1DedicatedResourcesResponse struct {
	// Immutable. The metric specifications that overrides a resource utilization metric (CPU utilization, accelerator's duty cycle, and so on) target value (default to 60 if not set). At most one entry is allowed per metric. If machine_spec.accelerator_count is above 0, the autoscaling will be based on both CPU utilization and accelerator's duty cycle metrics and scale up when either metrics exceeds its target value while scale down if both metrics are under their target value. The default target value is 60 for both metrics. If machine_spec.accelerator_count is 0, the autoscaling will be based on CPU utilization metric only with default target value 60 if not explicitly set. For example, in the case of Online Prediction, if you want to override target CPU utilization to 80, you should set autoscaling_metric_specs.metric_name to `aiplatform.googleapis.com/prediction/online/cpu/utilization` and autoscaling_metric_specs.target to `80`.
	AutoscalingMetricSpecs []GoogleCloudAiplatformV1AutoscalingMetricSpecResponse `pulumi:"autoscalingMetricSpecs"`
	// Immutable. The specification of a single machine used by the prediction.
	MachineSpec GoogleCloudAiplatformV1MachineSpecResponse `pulumi:"machineSpec"`
	// Immutable. The maximum number of replicas this DeployedModel may be deployed on when the traffic against it increases. If the requested value is too large, the deployment will error, but if deployment succeeds then the ability to scale the model to that many replicas is guaranteed (barring service outages). If traffic against the DeployedModel increases beyond what its replicas at maximum may handle, a portion of the traffic will be dropped. If this value is not provided, will use min_replica_count as the default value. The value of this field impacts the charge against Vertex CPU and GPU quotas. Specifically, you will be charged for (max_replica_count * number of cores in the selected machine type) and (max_replica_count * number of GPUs per replica in the selected machine type).
	MaxReplicaCount int `pulumi:"maxReplicaCount"`
	// Immutable. The minimum number of machine replicas this DeployedModel will be always deployed on. This value must be greater than or equal to 1. If traffic against the DeployedModel increases, it may dynamically be deployed onto more replicas, and as traffic decreases, some of these extra replicas may be freed.
	MinReplicaCount int `pulumi:"minReplicaCount"`
}

// A description of resources that are dedicated to a DeployedModel, and that need a higher degree of manual configuration.
type GoogleCloudAiplatformV1DedicatedResourcesResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1DedicatedResourcesResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1DedicatedResourcesResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1DedicatedResourcesResponseOutput) ToGoogleCloudAiplatformV1DedicatedResourcesResponseOutput() GoogleCloudAiplatformV1DedicatedResourcesResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1DedicatedResourcesResponseOutput) ToGoogleCloudAiplatformV1DedicatedResourcesResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1DedicatedResourcesResponseOutput {
	return o
}

// Immutable. The metric specifications that overrides a resource utilization metric (CPU utilization, accelerator's duty cycle, and so on) target value (default to 60 if not set). At most one entry is allowed per metric. If machine_spec.accelerator_count is above 0, the autoscaling will be based on both CPU utilization and accelerator's duty cycle metrics and scale up when either metrics exceeds its target value while scale down if both metrics are under their target value. The default target value is 60 for both metrics. If machine_spec.accelerator_count is 0, the autoscaling will be based on CPU utilization metric only with default target value 60 if not explicitly set. For example, in the case of Online Prediction, if you want to override target CPU utilization to 80, you should set autoscaling_metric_specs.metric_name to `aiplatform.googleapis.com/prediction/online/cpu/utilization` and autoscaling_metric_specs.target to `80`.
func (o GoogleCloudAiplatformV1DedicatedResourcesResponseOutput) AutoscalingMetricSpecs() GoogleCloudAiplatformV1AutoscalingMetricSpecResponseArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1DedicatedResourcesResponse) []GoogleCloudAiplatformV1AutoscalingMetricSpecResponse {
		return v.AutoscalingMetricSpecs
	}).(GoogleCloudAiplatformV1AutoscalingMetricSpecResponseArrayOutput)
}

// Immutable. The specification of a single machine used by the prediction.
func (o GoogleCloudAiplatformV1DedicatedResourcesResponseOutput) MachineSpec() GoogleCloudAiplatformV1MachineSpecResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1DedicatedResourcesResponse) GoogleCloudAiplatformV1MachineSpecResponse {
		return v.MachineSpec
	}).(GoogleCloudAiplatformV1MachineSpecResponseOutput)
}

// Immutable. The maximum number of replicas this DeployedModel may be deployed on when the traffic against it increases. If the requested value is too large, the deployment will error, but if deployment succeeds then the ability to scale the model to that many replicas is guaranteed (barring service outages). If traffic against the DeployedModel increases beyond what its replicas at maximum may handle, a portion of the traffic will be dropped. If this value is not provided, will use min_replica_count as the default value. The value of this field impacts the charge against Vertex CPU and GPU quotas. Specifically, you will be charged for (max_replica_count * number of cores in the selected machine type) and (max_replica_count * number of GPUs per replica in the selected machine type).
func (o GoogleCloudAiplatformV1DedicatedResourcesResponseOutput) MaxReplicaCount() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1DedicatedResourcesResponse) int { return v.MaxReplicaCount }).(pulumi.IntOutput)
}

// Immutable. The minimum number of machine replicas this DeployedModel will be always deployed on. This value must be greater than or equal to 1. If traffic against the DeployedModel increases, it may dynamically be deployed onto more replicas, and as traffic decreases, some of these extra replicas may be freed.
func (o GoogleCloudAiplatformV1DedicatedResourcesResponseOutput) MinReplicaCount() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1DedicatedResourcesResponse) int { return v.MinReplicaCount }).(pulumi.IntOutput)
}

// Configuration for an authentication provider, including support for [JSON Web Token (JWT)](https://tools.ietf.org/html/draft-ietf-oauth-json-web-token-32).
type GoogleCloudAiplatformV1DeployedIndexAuthConfigAuthProviderResponse struct {
	// A list of allowed JWT issuers. Each entry must be a valid Google service account, in the following format: `service-account-name@project-id.iam.gserviceaccount.com`
	AllowedIssuers []string `pulumi:"allowedIssuers"`
	// The list of JWT [audiences](https://tools.ietf.org/html/draft-ietf-oauth-json-web-token-32#section-4.1.3). that are allowed to access. A JWT containing any of these audiences will be accepted.
	Audiences []string `pulumi:"audiences"`
}

// Configuration for an authentication provider, including support for [JSON Web Token (JWT)](https://tools.ietf.org/html/draft-ietf-oauth-json-web-token-32).
type GoogleCloudAiplatformV1DeployedIndexAuthConfigAuthProviderResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1DeployedIndexAuthConfigAuthProviderResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1DeployedIndexAuthConfigAuthProviderResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1DeployedIndexAuthConfigAuthProviderResponseOutput) ToGoogleCloudAiplatformV1DeployedIndexAuthConfigAuthProviderResponseOutput() GoogleCloudAiplatformV1DeployedIndexAuthConfigAuthProviderResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1DeployedIndexAuthConfigAuthProviderResponseOutput) ToGoogleCloudAiplatformV1DeployedIndexAuthConfigAuthProviderResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1DeployedIndexAuthConfigAuthProviderResponseOutput {
	return o
}

// A list of allowed JWT issuers. Each entry must be a valid Google service account, in the following format: `service-account-name@project-id.iam.gserviceaccount.com`
func (o GoogleCloudAiplatformV1DeployedIndexAuthConfigAuthProviderResponseOutput) AllowedIssuers() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1DeployedIndexAuthConfigAuthProviderResponse) []string {
		return v.AllowedIssuers
	}).(pulumi.StringArrayOutput)
}

// The list of JWT [audiences](https://tools.ietf.org/html/draft-ietf-oauth-json-web-token-32#section-4.1.3). that are allowed to access. A JWT containing any of these audiences will be accepted.
func (o GoogleCloudAiplatformV1DeployedIndexAuthConfigAuthProviderResponseOutput) Audiences() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1DeployedIndexAuthConfigAuthProviderResponse) []string {
		return v.Audiences
	}).(pulumi.StringArrayOutput)
}

// Used to set up the auth on the DeployedIndex's private endpoint.
type GoogleCloudAiplatformV1DeployedIndexAuthConfigResponse struct {
	// Defines the authentication provider that the DeployedIndex uses.
	AuthProvider GoogleCloudAiplatformV1DeployedIndexAuthConfigAuthProviderResponse `pulumi:"authProvider"`
}

// Used to set up the auth on the DeployedIndex's private endpoint.
type GoogleCloudAiplatformV1DeployedIndexAuthConfigResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1DeployedIndexAuthConfigResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1DeployedIndexAuthConfigResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1DeployedIndexAuthConfigResponseOutput) ToGoogleCloudAiplatformV1DeployedIndexAuthConfigResponseOutput() GoogleCloudAiplatformV1DeployedIndexAuthConfigResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1DeployedIndexAuthConfigResponseOutput) ToGoogleCloudAiplatformV1DeployedIndexAuthConfigResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1DeployedIndexAuthConfigResponseOutput {
	return o
}

// Defines the authentication provider that the DeployedIndex uses.
func (o GoogleCloudAiplatformV1DeployedIndexAuthConfigResponseOutput) AuthProvider() GoogleCloudAiplatformV1DeployedIndexAuthConfigAuthProviderResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1DeployedIndexAuthConfigResponse) GoogleCloudAiplatformV1DeployedIndexAuthConfigAuthProviderResponse {
		return v.AuthProvider
	}).(GoogleCloudAiplatformV1DeployedIndexAuthConfigAuthProviderResponseOutput)
}

// Points to a DeployedIndex.
type GoogleCloudAiplatformV1DeployedIndexRefResponse struct {
	// Immutable. The ID of the DeployedIndex in the above IndexEndpoint.
	DeployedIndexId string `pulumi:"deployedIndexId"`
	// Immutable. A resource name of the IndexEndpoint.
	IndexEndpoint string `pulumi:"indexEndpoint"`
}

// Points to a DeployedIndex.
type GoogleCloudAiplatformV1DeployedIndexRefResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1DeployedIndexRefResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1DeployedIndexRefResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1DeployedIndexRefResponseOutput) ToGoogleCloudAiplatformV1DeployedIndexRefResponseOutput() GoogleCloudAiplatformV1DeployedIndexRefResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1DeployedIndexRefResponseOutput) ToGoogleCloudAiplatformV1DeployedIndexRefResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1DeployedIndexRefResponseOutput {
	return o
}

// Immutable. The ID of the DeployedIndex in the above IndexEndpoint.
func (o GoogleCloudAiplatformV1DeployedIndexRefResponseOutput) DeployedIndexId() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1DeployedIndexRefResponse) string { return v.DeployedIndexId }).(pulumi.StringOutput)
}

// Immutable. A resource name of the IndexEndpoint.
func (o GoogleCloudAiplatformV1DeployedIndexRefResponseOutput) IndexEndpoint() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1DeployedIndexRefResponse) string { return v.IndexEndpoint }).(pulumi.StringOutput)
}

type GoogleCloudAiplatformV1DeployedIndexRefResponseArrayOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1DeployedIndexRefResponseArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1DeployedIndexRefResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1DeployedIndexRefResponseArrayOutput) ToGoogleCloudAiplatformV1DeployedIndexRefResponseArrayOutput() GoogleCloudAiplatformV1DeployedIndexRefResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1DeployedIndexRefResponseArrayOutput) ToGoogleCloudAiplatformV1DeployedIndexRefResponseArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1DeployedIndexRefResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1DeployedIndexRefResponseArrayOutput) Index(i pulumi.IntInput) GoogleCloudAiplatformV1DeployedIndexRefResponseOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GoogleCloudAiplatformV1DeployedIndexRefResponse {
		return vs[0].([]GoogleCloudAiplatformV1DeployedIndexRefResponse)[vs[1].(int)]
	}).(GoogleCloudAiplatformV1DeployedIndexRefResponseOutput)
}

// A deployment of an Index. IndexEndpoints contain one or more DeployedIndexes.
type GoogleCloudAiplatformV1DeployedIndexResponse struct {
	// Optional. A description of resources that the DeployedIndex uses, which to large degree are decided by Vertex AI, and optionally allows only a modest additional configuration. If min_replica_count is not set, the default value is 2 (we don't provide SLA when min_replica_count=1). If max_replica_count is not set, the default value is min_replica_count. The max allowed replica count is 1000.
	AutomaticResources GoogleCloudAiplatformV1AutomaticResourcesResponse `pulumi:"automaticResources"`
	// Timestamp when the DeployedIndex was created.
	CreateTime string `pulumi:"createTime"`
	// Optional. A description of resources that are dedicated to the DeployedIndex, and that need a higher degree of manual configuration. The field min_replica_count must be set to a value strictly greater than 0, or else validation will fail. We don't provide SLA when min_replica_count=1. If max_replica_count is not set, the default value is min_replica_count. The max allowed replica count is 1000. Available machine types for SMALL shard: e2-standard-2 and all machine types available for MEDIUM and LARGE shard. Available machine types for MEDIUM shard: e2-standard-16 and all machine types available for LARGE shard. Available machine types for LARGE shard: e2-highmem-16, n2d-standard-32. n1-standard-16 and n1-standard-32 are still available, but we recommend e2-standard-16 and e2-highmem-16 for cost efficiency.
	DedicatedResources GoogleCloudAiplatformV1DedicatedResourcesResponse `pulumi:"dedicatedResources"`
	// Optional. If set, the authentication is enabled for the private endpoint.
	DeployedIndexAuthConfig GoogleCloudAiplatformV1DeployedIndexAuthConfigResponse `pulumi:"deployedIndexAuthConfig"`
	// Optional. The deployment group can be no longer than 64 characters (eg: 'test', 'prod'). If not set, we will use the 'default' deployment group. Creating `deployment_groups` with `reserved_ip_ranges` is a recommended practice when the peered network has multiple peering ranges. This creates your deployments from predictable IP spaces for easier traffic administration. Also, one deployment_group (except 'default') can only be used with the same reserved_ip_ranges which means if the deployment_group has been used with reserved_ip_ranges: [a, b, c], using it with [a, b] or [d, e] is disallowed. Note: we only support up to 5 deployment groups(not including 'default').
	DeploymentGroup string `pulumi:"deploymentGroup"`
	// The display name of the DeployedIndex. If not provided upon creation, the Index's display_name is used.
	DisplayName string `pulumi:"displayName"`
	// Optional. If true, private endpoint's access logs are sent to Cloud Logging. These logs are like standard server access logs, containing information like timestamp and latency for each MatchRequest. Note that logs may incur a cost, especially if the deployed index receives a high queries per second rate (QPS). Estimate your costs before enabling this option.
	EnableAccessLogging bool `pulumi:"enableAccessLogging"`
	// The name of the Index this is the deployment of. We may refer to this Index as the DeployedIndex's "original" Index.
	Index string `pulumi:"index"`
	// The DeployedIndex may depend on various data on its original Index. Additionally when certain changes to the original Index are being done (e.g. when what the Index contains is being changed) the DeployedIndex may be asynchronously updated in the background to reflect these changes. If this timestamp's value is at least the Index.update_time of the original Index, it means that this DeployedIndex and the original Index are in sync. If this timestamp is older, then to see which updates this DeployedIndex already contains (and which it does not), one must list the operations that are running on the original Index. Only the successfully completed Operations with update_time equal or before this sync time are contained in this DeployedIndex.
	IndexSyncTime string `pulumi:"indexSyncTime"`
	// Provides paths for users to send requests directly to the deployed index services running on Cloud via private services access. This field is populated if network is configured.
	PrivateEndpoints GoogleCloudAiplatformV1IndexPrivateEndpointsResponse `pulumi:"privateEndpoints"`
	// Optional. A list of reserved ip ranges under the VPC network that can be used for this DeployedIndex. If set, we will deploy the index within the provided ip ranges. Otherwise, the index might be deployed to any ip ranges under the provided VPC network. The value should be the name of the address (https://cloud.google.com/compute/docs/reference/rest/v1/addresses) Example: ['vertex-ai-ip-range']. For more information about subnets and network IP ranges, please see https://cloud.google.com/vpc/docs/subnets#manually_created_subnet_ip_ranges.
	ReservedIpRanges []string `pulumi:"reservedIpRanges"`
}

// A deployment of an Index. IndexEndpoints contain one or more DeployedIndexes.
type GoogleCloudAiplatformV1DeployedIndexResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1DeployedIndexResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1DeployedIndexResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1DeployedIndexResponseOutput) ToGoogleCloudAiplatformV1DeployedIndexResponseOutput() GoogleCloudAiplatformV1DeployedIndexResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1DeployedIndexResponseOutput) ToGoogleCloudAiplatformV1DeployedIndexResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1DeployedIndexResponseOutput {
	return o
}

// Optional. A description of resources that the DeployedIndex uses, which to large degree are decided by Vertex AI, and optionally allows only a modest additional configuration. If min_replica_count is not set, the default value is 2 (we don't provide SLA when min_replica_count=1). If max_replica_count is not set, the default value is min_replica_count. The max allowed replica count is 1000.
func (o GoogleCloudAiplatformV1DeployedIndexResponseOutput) AutomaticResources() GoogleCloudAiplatformV1AutomaticResourcesResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1DeployedIndexResponse) GoogleCloudAiplatformV1AutomaticResourcesResponse {
		return v.AutomaticResources
	}).(GoogleCloudAiplatformV1AutomaticResourcesResponseOutput)
}

// Timestamp when the DeployedIndex was created.
func (o GoogleCloudAiplatformV1DeployedIndexResponseOutput) CreateTime() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1DeployedIndexResponse) string { return v.CreateTime }).(pulumi.StringOutput)
}

// Optional. A description of resources that are dedicated to the DeployedIndex, and that need a higher degree of manual configuration. The field min_replica_count must be set to a value strictly greater than 0, or else validation will fail. We don't provide SLA when min_replica_count=1. If max_replica_count is not set, the default value is min_replica_count. The max allowed replica count is 1000. Available machine types for SMALL shard: e2-standard-2 and all machine types available for MEDIUM and LARGE shard. Available machine types for MEDIUM shard: e2-standard-16 and all machine types available for LARGE shard. Available machine types for LARGE shard: e2-highmem-16, n2d-standard-32. n1-standard-16 and n1-standard-32 are still available, but we recommend e2-standard-16 and e2-highmem-16 for cost efficiency.
func (o GoogleCloudAiplatformV1DeployedIndexResponseOutput) DedicatedResources() GoogleCloudAiplatformV1DedicatedResourcesResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1DeployedIndexResponse) GoogleCloudAiplatformV1DedicatedResourcesResponse {
		return v.DedicatedResources
	}).(GoogleCloudAiplatformV1DedicatedResourcesResponseOutput)
}

// Optional. If set, the authentication is enabled for the private endpoint.
func (o GoogleCloudAiplatformV1DeployedIndexResponseOutput) DeployedIndexAuthConfig() GoogleCloudAiplatformV1DeployedIndexAuthConfigResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1DeployedIndexResponse) GoogleCloudAiplatformV1DeployedIndexAuthConfigResponse {
		return v.DeployedIndexAuthConfig
	}).(GoogleCloudAiplatformV1DeployedIndexAuthConfigResponseOutput)
}

// Optional. The deployment group can be no longer than 64 characters (eg: 'test', 'prod'). If not set, we will use the 'default' deployment group. Creating `deployment_groups` with `reserved_ip_ranges` is a recommended practice when the peered network has multiple peering ranges. This creates your deployments from predictable IP spaces for easier traffic administration. Also, one deployment_group (except 'default') can only be used with the same reserved_ip_ranges which means if the deployment_group has been used with reserved_ip_ranges: [a, b, c], using it with [a, b] or [d, e] is disallowed. Note: we only support up to 5 deployment groups(not including 'default').
func (o GoogleCloudAiplatformV1DeployedIndexResponseOutput) DeploymentGroup() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1DeployedIndexResponse) string { return v.DeploymentGroup }).(pulumi.StringOutput)
}

// The display name of the DeployedIndex. If not provided upon creation, the Index's display_name is used.
func (o GoogleCloudAiplatformV1DeployedIndexResponseOutput) DisplayName() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1DeployedIndexResponse) string { return v.DisplayName }).(pulumi.StringOutput)
}

// Optional. If true, private endpoint's access logs are sent to Cloud Logging. These logs are like standard server access logs, containing information like timestamp and latency for each MatchRequest. Note that logs may incur a cost, especially if the deployed index receives a high queries per second rate (QPS). Estimate your costs before enabling this option.
func (o GoogleCloudAiplatformV1DeployedIndexResponseOutput) EnableAccessLogging() pulumi.BoolOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1DeployedIndexResponse) bool { return v.EnableAccessLogging }).(pulumi.BoolOutput)
}

// The name of the Index this is the deployment of. We may refer to this Index as the DeployedIndex's "original" Index.
func (o GoogleCloudAiplatformV1DeployedIndexResponseOutput) Index() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1DeployedIndexResponse) string { return v.Index }).(pulumi.StringOutput)
}

// The DeployedIndex may depend on various data on its original Index. Additionally when certain changes to the original Index are being done (e.g. when what the Index contains is being changed) the DeployedIndex may be asynchronously updated in the background to reflect these changes. If this timestamp's value is at least the Index.update_time of the original Index, it means that this DeployedIndex and the original Index are in sync. If this timestamp is older, then to see which updates this DeployedIndex already contains (and which it does not), one must list the operations that are running on the original Index. Only the successfully completed Operations with update_time equal or before this sync time are contained in this DeployedIndex.
func (o GoogleCloudAiplatformV1DeployedIndexResponseOutput) IndexSyncTime() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1DeployedIndexResponse) string { return v.IndexSyncTime }).(pulumi.StringOutput)
}

// Provides paths for users to send requests directly to the deployed index services running on Cloud via private services access. This field is populated if network is configured.
func (o GoogleCloudAiplatformV1DeployedIndexResponseOutput) PrivateEndpoints() GoogleCloudAiplatformV1IndexPrivateEndpointsResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1DeployedIndexResponse) GoogleCloudAiplatformV1IndexPrivateEndpointsResponse {
		return v.PrivateEndpoints
	}).(GoogleCloudAiplatformV1IndexPrivateEndpointsResponseOutput)
}

// Optional. A list of reserved ip ranges under the VPC network that can be used for this DeployedIndex. If set, we will deploy the index within the provided ip ranges. Otherwise, the index might be deployed to any ip ranges under the provided VPC network. The value should be the name of the address (https://cloud.google.com/compute/docs/reference/rest/v1/addresses) Example: ['vertex-ai-ip-range']. For more information about subnets and network IP ranges, please see https://cloud.google.com/vpc/docs/subnets#manually_created_subnet_ip_ranges.
func (o GoogleCloudAiplatformV1DeployedIndexResponseOutput) ReservedIpRanges() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1DeployedIndexResponse) []string { return v.ReservedIpRanges }).(pulumi.StringArrayOutput)
}

type GoogleCloudAiplatformV1DeployedIndexResponseArrayOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1DeployedIndexResponseArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1DeployedIndexResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1DeployedIndexResponseArrayOutput) ToGoogleCloudAiplatformV1DeployedIndexResponseArrayOutput() GoogleCloudAiplatformV1DeployedIndexResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1DeployedIndexResponseArrayOutput) ToGoogleCloudAiplatformV1DeployedIndexResponseArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1DeployedIndexResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1DeployedIndexResponseArrayOutput) Index(i pulumi.IntInput) GoogleCloudAiplatformV1DeployedIndexResponseOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GoogleCloudAiplatformV1DeployedIndexResponse {
		return vs[0].([]GoogleCloudAiplatformV1DeployedIndexResponse)[vs[1].(int)]
	}).(GoogleCloudAiplatformV1DeployedIndexResponseOutput)
}

// Points to a DeployedModel.
type GoogleCloudAiplatformV1DeployedModelRefResponse struct {
	// Immutable. An ID of a DeployedModel in the above Endpoint.
	DeployedModelId string `pulumi:"deployedModelId"`
	// Immutable. A resource name of an Endpoint.
	Endpoint string `pulumi:"endpoint"`
}

// Points to a DeployedModel.
type GoogleCloudAiplatformV1DeployedModelRefResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1DeployedModelRefResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1DeployedModelRefResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1DeployedModelRefResponseOutput) ToGoogleCloudAiplatformV1DeployedModelRefResponseOutput() GoogleCloudAiplatformV1DeployedModelRefResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1DeployedModelRefResponseOutput) ToGoogleCloudAiplatformV1DeployedModelRefResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1DeployedModelRefResponseOutput {
	return o
}

// Immutable. An ID of a DeployedModel in the above Endpoint.
func (o GoogleCloudAiplatformV1DeployedModelRefResponseOutput) DeployedModelId() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1DeployedModelRefResponse) string { return v.DeployedModelId }).(pulumi.StringOutput)
}

// Immutable. A resource name of an Endpoint.
func (o GoogleCloudAiplatformV1DeployedModelRefResponseOutput) Endpoint() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1DeployedModelRefResponse) string { return v.Endpoint }).(pulumi.StringOutput)
}

type GoogleCloudAiplatformV1DeployedModelRefResponseArrayOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1DeployedModelRefResponseArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1DeployedModelRefResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1DeployedModelRefResponseArrayOutput) ToGoogleCloudAiplatformV1DeployedModelRefResponseArrayOutput() GoogleCloudAiplatformV1DeployedModelRefResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1DeployedModelRefResponseArrayOutput) ToGoogleCloudAiplatformV1DeployedModelRefResponseArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1DeployedModelRefResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1DeployedModelRefResponseArrayOutput) Index(i pulumi.IntInput) GoogleCloudAiplatformV1DeployedModelRefResponseOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GoogleCloudAiplatformV1DeployedModelRefResponse {
		return vs[0].([]GoogleCloudAiplatformV1DeployedModelRefResponse)[vs[1].(int)]
	}).(GoogleCloudAiplatformV1DeployedModelRefResponseOutput)
}

// A deployment of a Model. Endpoints contain one or more DeployedModels.
type GoogleCloudAiplatformV1DeployedModelResponse struct {
	// A description of resources that to large degree are decided by Vertex AI, and require only a modest additional configuration.
	AutomaticResources GoogleCloudAiplatformV1AutomaticResourcesResponse `pulumi:"automaticResources"`
	// Timestamp when the DeployedModel was created.
	CreateTime string `pulumi:"createTime"`
	// A description of resources that are dedicated to the DeployedModel, and that need a higher degree of manual configuration.
	DedicatedResources GoogleCloudAiplatformV1DedicatedResourcesResponse `pulumi:"dedicatedResources"`
	// For custom-trained Models and AutoML Tabular Models, the container of the DeployedModel instances will send `stderr` and `stdout` streams to Cloud Logging by default. Please note that the logs incur cost, which are subject to [Cloud Logging pricing](https://cloud.google.com/logging/pricing). User can disable container logging by setting this flag to true.
	DisableContainerLogging bool `pulumi:"disableContainerLogging"`
	// The display name of the DeployedModel. If not provided upon creation, the Model's display_name is used.
	DisplayName string `pulumi:"displayName"`
	// If true, online prediction access logs are sent to Cloud Logging. These logs are like standard server access logs, containing information like timestamp and latency for each prediction request. Note that logs may incur a cost, especially if your project receives prediction requests at a high queries per second rate (QPS). Estimate your costs before enabling this option.
	EnableAccessLogging bool `pulumi:"enableAccessLogging"`
	// Explanation configuration for this DeployedModel. When deploying a Model using EndpointService.DeployModel, this value overrides the value of Model.explanation_spec. All fields of explanation_spec are optional in the request. If a field of explanation_spec is not populated, the value of the same field of Model.explanation_spec is inherited. If the corresponding Model.explanation_spec is not populated, all fields of the explanation_spec will be used for the explanation configuration.
	ExplanationSpec GoogleCloudAiplatformV1ExplanationSpecResponse `pulumi:"explanationSpec"`
	// The resource name of the Model that this is the deployment of. Note that the Model may be in a different location than the DeployedModel's Endpoint. The resource name may contain version id or version alias to specify the version. Example: `projects/{project}/locations/{location}/models/{model}@2` or `projects/{project}/locations/{location}/models/{model}@golden` if no version is specified, the default version will be deployed.
	Model string `pulumi:"model"`
	// The version ID of the model that is deployed.
	ModelVersionId string `pulumi:"modelVersionId"`
	// Provide paths for users to send predict/explain/health requests directly to the deployed model services running on Cloud via private services access. This field is populated if network is configured.
	PrivateEndpoints GoogleCloudAiplatformV1PrivateEndpointsResponse `pulumi:"privateEndpoints"`
	// The service account that the DeployedModel's container runs as. Specify the email address of the service account. If this service account is not specified, the container runs as a service account that doesn't have access to the resource project. Users deploying the Model must have the `iam.serviceAccounts.actAs` permission on this service account.
	ServiceAccount string `pulumi:"serviceAccount"`
}

// A deployment of a Model. Endpoints contain one or more DeployedModels.
type GoogleCloudAiplatformV1DeployedModelResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1DeployedModelResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1DeployedModelResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1DeployedModelResponseOutput) ToGoogleCloudAiplatformV1DeployedModelResponseOutput() GoogleCloudAiplatformV1DeployedModelResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1DeployedModelResponseOutput) ToGoogleCloudAiplatformV1DeployedModelResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1DeployedModelResponseOutput {
	return o
}

// A description of resources that to large degree are decided by Vertex AI, and require only a modest additional configuration.
func (o GoogleCloudAiplatformV1DeployedModelResponseOutput) AutomaticResources() GoogleCloudAiplatformV1AutomaticResourcesResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1DeployedModelResponse) GoogleCloudAiplatformV1AutomaticResourcesResponse {
		return v.AutomaticResources
	}).(GoogleCloudAiplatformV1AutomaticResourcesResponseOutput)
}

// Timestamp when the DeployedModel was created.
func (o GoogleCloudAiplatformV1DeployedModelResponseOutput) CreateTime() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1DeployedModelResponse) string { return v.CreateTime }).(pulumi.StringOutput)
}

// A description of resources that are dedicated to the DeployedModel, and that need a higher degree of manual configuration.
func (o GoogleCloudAiplatformV1DeployedModelResponseOutput) DedicatedResources() GoogleCloudAiplatformV1DedicatedResourcesResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1DeployedModelResponse) GoogleCloudAiplatformV1DedicatedResourcesResponse {
		return v.DedicatedResources
	}).(GoogleCloudAiplatformV1DedicatedResourcesResponseOutput)
}

// For custom-trained Models and AutoML Tabular Models, the container of the DeployedModel instances will send `stderr` and `stdout` streams to Cloud Logging by default. Please note that the logs incur cost, which are subject to [Cloud Logging pricing](https://cloud.google.com/logging/pricing). User can disable container logging by setting this flag to true.
func (o GoogleCloudAiplatformV1DeployedModelResponseOutput) DisableContainerLogging() pulumi.BoolOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1DeployedModelResponse) bool { return v.DisableContainerLogging }).(pulumi.BoolOutput)
}

// The display name of the DeployedModel. If not provided upon creation, the Model's display_name is used.
func (o GoogleCloudAiplatformV1DeployedModelResponseOutput) DisplayName() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1DeployedModelResponse) string { return v.DisplayName }).(pulumi.StringOutput)
}

// If true, online prediction access logs are sent to Cloud Logging. These logs are like standard server access logs, containing information like timestamp and latency for each prediction request. Note that logs may incur a cost, especially if your project receives prediction requests at a high queries per second rate (QPS). Estimate your costs before enabling this option.
func (o GoogleCloudAiplatformV1DeployedModelResponseOutput) EnableAccessLogging() pulumi.BoolOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1DeployedModelResponse) bool { return v.EnableAccessLogging }).(pulumi.BoolOutput)
}

// Explanation configuration for this DeployedModel. When deploying a Model using EndpointService.DeployModel, this value overrides the value of Model.explanation_spec. All fields of explanation_spec are optional in the request. If a field of explanation_spec is not populated, the value of the same field of Model.explanation_spec is inherited. If the corresponding Model.explanation_spec is not populated, all fields of the explanation_spec will be used for the explanation configuration.
func (o GoogleCloudAiplatformV1DeployedModelResponseOutput) ExplanationSpec() GoogleCloudAiplatformV1ExplanationSpecResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1DeployedModelResponse) GoogleCloudAiplatformV1ExplanationSpecResponse {
		return v.ExplanationSpec
	}).(GoogleCloudAiplatformV1ExplanationSpecResponseOutput)
}

// The resource name of the Model that this is the deployment of. Note that the Model may be in a different location than the DeployedModel's Endpoint. The resource name may contain version id or version alias to specify the version. Example: `projects/{project}/locations/{location}/models/{model}@2` or `projects/{project}/locations/{location}/models/{model}@golden` if no version is specified, the default version will be deployed.
func (o GoogleCloudAiplatformV1DeployedModelResponseOutput) Model() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1DeployedModelResponse) string { return v.Model }).(pulumi.StringOutput)
}

// The version ID of the model that is deployed.
func (o GoogleCloudAiplatformV1DeployedModelResponseOutput) ModelVersionId() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1DeployedModelResponse) string { return v.ModelVersionId }).(pulumi.StringOutput)
}

// Provide paths for users to send predict/explain/health requests directly to the deployed model services running on Cloud via private services access. This field is populated if network is configured.
func (o GoogleCloudAiplatformV1DeployedModelResponseOutput) PrivateEndpoints() GoogleCloudAiplatformV1PrivateEndpointsResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1DeployedModelResponse) GoogleCloudAiplatformV1PrivateEndpointsResponse {
		return v.PrivateEndpoints
	}).(GoogleCloudAiplatformV1PrivateEndpointsResponseOutput)
}

// The service account that the DeployedModel's container runs as. Specify the email address of the service account. If this service account is not specified, the container runs as a service account that doesn't have access to the resource project. Users deploying the Model must have the `iam.serviceAccounts.actAs` permission on this service account.
func (o GoogleCloudAiplatformV1DeployedModelResponseOutput) ServiceAccount() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1DeployedModelResponse) string { return v.ServiceAccount }).(pulumi.StringOutput)
}

type GoogleCloudAiplatformV1DeployedModelResponseArrayOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1DeployedModelResponseArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1DeployedModelResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1DeployedModelResponseArrayOutput) ToGoogleCloudAiplatformV1DeployedModelResponseArrayOutput() GoogleCloudAiplatformV1DeployedModelResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1DeployedModelResponseArrayOutput) ToGoogleCloudAiplatformV1DeployedModelResponseArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1DeployedModelResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1DeployedModelResponseArrayOutput) Index(i pulumi.IntInput) GoogleCloudAiplatformV1DeployedModelResponseOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GoogleCloudAiplatformV1DeployedModelResponse {
		return vs[0].([]GoogleCloudAiplatformV1DeployedModelResponse)[vs[1].(int)]
	}).(GoogleCloudAiplatformV1DeployedModelResponseOutput)
}

// Represents the spec of disk options.
type GoogleCloudAiplatformV1DiskSpec struct {
	// Size in GB of the boot disk (default is 100GB).
	BootDiskSizeGb *int `pulumi:"bootDiskSizeGb"`
	// Type of the boot disk (default is "pd-ssd"). Valid values: "pd-ssd" (Persistent Disk Solid State Drive) or "pd-standard" (Persistent Disk Hard Disk Drive).
	BootDiskType *string `pulumi:"bootDiskType"`
}

// GoogleCloudAiplatformV1DiskSpecInput is an input type that accepts GoogleCloudAiplatformV1DiskSpecArgs and GoogleCloudAiplatformV1DiskSpecOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1DiskSpecInput` via:
//
//	GoogleCloudAiplatformV1DiskSpecArgs{...}
type GoogleCloudAiplatformV1DiskSpecInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1DiskSpecOutput() GoogleCloudAiplatformV1DiskSpecOutput
	ToGoogleCloudAiplatformV1DiskSpecOutputWithContext(context.Context) GoogleCloudAiplatformV1DiskSpecOutput
}

// Represents the spec of disk options.
type GoogleCloudAiplatformV1DiskSpecArgs struct {
	// Size in GB of the boot disk (default is 100GB).
	BootDiskSizeGb pulumi.IntPtrInput `pulumi:"bootDiskSizeGb"`
	// Type of the boot disk (default is "pd-ssd"). Valid values: "pd-ssd" (Persistent Disk Solid State Drive) or "pd-standard" (Persistent Disk Hard Disk Drive).
	BootDiskType pulumi.StringPtrInput `pulumi:"bootDiskType"`
}

func (GoogleCloudAiplatformV1DiskSpecArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1DiskSpec)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1DiskSpecArgs) ToGoogleCloudAiplatformV1DiskSpecOutput() GoogleCloudAiplatformV1DiskSpecOutput {
	return i.ToGoogleCloudAiplatformV1DiskSpecOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1DiskSpecArgs) ToGoogleCloudAiplatformV1DiskSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1DiskSpecOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1DiskSpecOutput)
}

func (i GoogleCloudAiplatformV1DiskSpecArgs) ToGoogleCloudAiplatformV1DiskSpecPtrOutput() GoogleCloudAiplatformV1DiskSpecPtrOutput {
	return i.ToGoogleCloudAiplatformV1DiskSpecPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1DiskSpecArgs) ToGoogleCloudAiplatformV1DiskSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1DiskSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1DiskSpecOutput).ToGoogleCloudAiplatformV1DiskSpecPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1DiskSpecPtrInput is an input type that accepts GoogleCloudAiplatformV1DiskSpecArgs, GoogleCloudAiplatformV1DiskSpecPtr and GoogleCloudAiplatformV1DiskSpecPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1DiskSpecPtrInput` via:
//
//	        GoogleCloudAiplatformV1DiskSpecArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1DiskSpecPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1DiskSpecPtrOutput() GoogleCloudAiplatformV1DiskSpecPtrOutput
	ToGoogleCloudAiplatformV1DiskSpecPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1DiskSpecPtrOutput
}

type googleCloudAiplatformV1DiskSpecPtrType GoogleCloudAiplatformV1DiskSpecArgs

func GoogleCloudAiplatformV1DiskSpecPtr(v *GoogleCloudAiplatformV1DiskSpecArgs) GoogleCloudAiplatformV1DiskSpecPtrInput {
	return (*googleCloudAiplatformV1DiskSpecPtrType)(v)
}

func (*googleCloudAiplatformV1DiskSpecPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1DiskSpec)(nil)).Elem()
}

func (i *googleCloudAiplatformV1DiskSpecPtrType) ToGoogleCloudAiplatformV1DiskSpecPtrOutput() GoogleCloudAiplatformV1DiskSpecPtrOutput {
	return i.ToGoogleCloudAiplatformV1DiskSpecPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1DiskSpecPtrType) ToGoogleCloudAiplatformV1DiskSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1DiskSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1DiskSpecPtrOutput)
}

// Represents the spec of disk options.
type GoogleCloudAiplatformV1DiskSpecOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1DiskSpecOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1DiskSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1DiskSpecOutput) ToGoogleCloudAiplatformV1DiskSpecOutput() GoogleCloudAiplatformV1DiskSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1DiskSpecOutput) ToGoogleCloudAiplatformV1DiskSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1DiskSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1DiskSpecOutput) ToGoogleCloudAiplatformV1DiskSpecPtrOutput() GoogleCloudAiplatformV1DiskSpecPtrOutput {
	return o.ToGoogleCloudAiplatformV1DiskSpecPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1DiskSpecOutput) ToGoogleCloudAiplatformV1DiskSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1DiskSpecPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1DiskSpec) *GoogleCloudAiplatformV1DiskSpec {
		return &v
	}).(GoogleCloudAiplatformV1DiskSpecPtrOutput)
}

// Size in GB of the boot disk (default is 100GB).
func (o GoogleCloudAiplatformV1DiskSpecOutput) BootDiskSizeGb() pulumi.IntPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1DiskSpec) *int { return v.BootDiskSizeGb }).(pulumi.IntPtrOutput)
}

// Type of the boot disk (default is "pd-ssd"). Valid values: "pd-ssd" (Persistent Disk Solid State Drive) or "pd-standard" (Persistent Disk Hard Disk Drive).
func (o GoogleCloudAiplatformV1DiskSpecOutput) BootDiskType() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1DiskSpec) *string { return v.BootDiskType }).(pulumi.StringPtrOutput)
}

type GoogleCloudAiplatformV1DiskSpecPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1DiskSpecPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1DiskSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1DiskSpecPtrOutput) ToGoogleCloudAiplatformV1DiskSpecPtrOutput() GoogleCloudAiplatformV1DiskSpecPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1DiskSpecPtrOutput) ToGoogleCloudAiplatformV1DiskSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1DiskSpecPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1DiskSpecPtrOutput) Elem() GoogleCloudAiplatformV1DiskSpecOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1DiskSpec) GoogleCloudAiplatformV1DiskSpec {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1DiskSpec
		return ret
	}).(GoogleCloudAiplatformV1DiskSpecOutput)
}

// Size in GB of the boot disk (default is 100GB).
func (o GoogleCloudAiplatformV1DiskSpecPtrOutput) BootDiskSizeGb() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1DiskSpec) *int {
		if v == nil {
			return nil
		}
		return v.BootDiskSizeGb
	}).(pulumi.IntPtrOutput)
}

// Type of the boot disk (default is "pd-ssd"). Valid values: "pd-ssd" (Persistent Disk Solid State Drive) or "pd-standard" (Persistent Disk Hard Disk Drive).
func (o GoogleCloudAiplatformV1DiskSpecPtrOutput) BootDiskType() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1DiskSpec) *string {
		if v == nil {
			return nil
		}
		return v.BootDiskType
	}).(pulumi.StringPtrOutput)
}

// Represents the spec of disk options.
type GoogleCloudAiplatformV1DiskSpecResponse struct {
	// Size in GB of the boot disk (default is 100GB).
	BootDiskSizeGb int `pulumi:"bootDiskSizeGb"`
	// Type of the boot disk (default is "pd-ssd"). Valid values: "pd-ssd" (Persistent Disk Solid State Drive) or "pd-standard" (Persistent Disk Hard Disk Drive).
	BootDiskType string `pulumi:"bootDiskType"`
}

// Represents the spec of disk options.
type GoogleCloudAiplatformV1DiskSpecResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1DiskSpecResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1DiskSpecResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1DiskSpecResponseOutput) ToGoogleCloudAiplatformV1DiskSpecResponseOutput() GoogleCloudAiplatformV1DiskSpecResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1DiskSpecResponseOutput) ToGoogleCloudAiplatformV1DiskSpecResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1DiskSpecResponseOutput {
	return o
}

// Size in GB of the boot disk (default is 100GB).
func (o GoogleCloudAiplatformV1DiskSpecResponseOutput) BootDiskSizeGb() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1DiskSpecResponse) int { return v.BootDiskSizeGb }).(pulumi.IntOutput)
}

// Type of the boot disk (default is "pd-ssd"). Valid values: "pd-ssd" (Persistent Disk Solid State Drive) or "pd-standard" (Persistent Disk Hard Disk Drive).
func (o GoogleCloudAiplatformV1DiskSpecResponseOutput) BootDiskType() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1DiskSpecResponse) string { return v.BootDiskType }).(pulumi.StringOutput)
}

// Represents a customer-managed encryption key spec that can be applied to a top-level resource.
type GoogleCloudAiplatformV1EncryptionSpec struct {
	// The Cloud KMS resource identifier of the customer managed encryption key used to protect a resource. Has the form: `projects/my-project/locations/my-region/keyRings/my-kr/cryptoKeys/my-key`. The key needs to be in the same region as where the compute resource is created.
	KmsKeyName string `pulumi:"kmsKeyName"`
}

// GoogleCloudAiplatformV1EncryptionSpecInput is an input type that accepts GoogleCloudAiplatformV1EncryptionSpecArgs and GoogleCloudAiplatformV1EncryptionSpecOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1EncryptionSpecInput` via:
//
//	GoogleCloudAiplatformV1EncryptionSpecArgs{...}
type GoogleCloudAiplatformV1EncryptionSpecInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1EncryptionSpecOutput() GoogleCloudAiplatformV1EncryptionSpecOutput
	ToGoogleCloudAiplatformV1EncryptionSpecOutputWithContext(context.Context) GoogleCloudAiplatformV1EncryptionSpecOutput
}

// Represents a customer-managed encryption key spec that can be applied to a top-level resource.
type GoogleCloudAiplatformV1EncryptionSpecArgs struct {
	// The Cloud KMS resource identifier of the customer managed encryption key used to protect a resource. Has the form: `projects/my-project/locations/my-region/keyRings/my-kr/cryptoKeys/my-key`. The key needs to be in the same region as where the compute resource is created.
	KmsKeyName pulumi.StringInput `pulumi:"kmsKeyName"`
}

func (GoogleCloudAiplatformV1EncryptionSpecArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1EncryptionSpec)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1EncryptionSpecArgs) ToGoogleCloudAiplatformV1EncryptionSpecOutput() GoogleCloudAiplatformV1EncryptionSpecOutput {
	return i.ToGoogleCloudAiplatformV1EncryptionSpecOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1EncryptionSpecArgs) ToGoogleCloudAiplatformV1EncryptionSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1EncryptionSpecOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1EncryptionSpecOutput)
}

func (i GoogleCloudAiplatformV1EncryptionSpecArgs) ToGoogleCloudAiplatformV1EncryptionSpecPtrOutput() GoogleCloudAiplatformV1EncryptionSpecPtrOutput {
	return i.ToGoogleCloudAiplatformV1EncryptionSpecPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1EncryptionSpecArgs) ToGoogleCloudAiplatformV1EncryptionSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1EncryptionSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1EncryptionSpecOutput).ToGoogleCloudAiplatformV1EncryptionSpecPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1EncryptionSpecPtrInput is an input type that accepts GoogleCloudAiplatformV1EncryptionSpecArgs, GoogleCloudAiplatformV1EncryptionSpecPtr and GoogleCloudAiplatformV1EncryptionSpecPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1EncryptionSpecPtrInput` via:
//
//	        GoogleCloudAiplatformV1EncryptionSpecArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1EncryptionSpecPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1EncryptionSpecPtrOutput() GoogleCloudAiplatformV1EncryptionSpecPtrOutput
	ToGoogleCloudAiplatformV1EncryptionSpecPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1EncryptionSpecPtrOutput
}

type googleCloudAiplatformV1EncryptionSpecPtrType GoogleCloudAiplatformV1EncryptionSpecArgs

func GoogleCloudAiplatformV1EncryptionSpecPtr(v *GoogleCloudAiplatformV1EncryptionSpecArgs) GoogleCloudAiplatformV1EncryptionSpecPtrInput {
	return (*googleCloudAiplatformV1EncryptionSpecPtrType)(v)
}

func (*googleCloudAiplatformV1EncryptionSpecPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1EncryptionSpec)(nil)).Elem()
}

func (i *googleCloudAiplatformV1EncryptionSpecPtrType) ToGoogleCloudAiplatformV1EncryptionSpecPtrOutput() GoogleCloudAiplatformV1EncryptionSpecPtrOutput {
	return i.ToGoogleCloudAiplatformV1EncryptionSpecPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1EncryptionSpecPtrType) ToGoogleCloudAiplatformV1EncryptionSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1EncryptionSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1EncryptionSpecPtrOutput)
}

// Represents a customer-managed encryption key spec that can be applied to a top-level resource.
type GoogleCloudAiplatformV1EncryptionSpecOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1EncryptionSpecOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1EncryptionSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1EncryptionSpecOutput) ToGoogleCloudAiplatformV1EncryptionSpecOutput() GoogleCloudAiplatformV1EncryptionSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1EncryptionSpecOutput) ToGoogleCloudAiplatformV1EncryptionSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1EncryptionSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1EncryptionSpecOutput) ToGoogleCloudAiplatformV1EncryptionSpecPtrOutput() GoogleCloudAiplatformV1EncryptionSpecPtrOutput {
	return o.ToGoogleCloudAiplatformV1EncryptionSpecPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1EncryptionSpecOutput) ToGoogleCloudAiplatformV1EncryptionSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1EncryptionSpecPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1EncryptionSpec) *GoogleCloudAiplatformV1EncryptionSpec {
		return &v
	}).(GoogleCloudAiplatformV1EncryptionSpecPtrOutput)
}

// The Cloud KMS resource identifier of the customer managed encryption key used to protect a resource. Has the form: `projects/my-project/locations/my-region/keyRings/my-kr/cryptoKeys/my-key`. The key needs to be in the same region as where the compute resource is created.
func (o GoogleCloudAiplatformV1EncryptionSpecOutput) KmsKeyName() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1EncryptionSpec) string { return v.KmsKeyName }).(pulumi.StringOutput)
}

type GoogleCloudAiplatformV1EncryptionSpecPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1EncryptionSpecPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1EncryptionSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1EncryptionSpecPtrOutput) ToGoogleCloudAiplatformV1EncryptionSpecPtrOutput() GoogleCloudAiplatformV1EncryptionSpecPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1EncryptionSpecPtrOutput) ToGoogleCloudAiplatformV1EncryptionSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1EncryptionSpecPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1EncryptionSpecPtrOutput) Elem() GoogleCloudAiplatformV1EncryptionSpecOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1EncryptionSpec) GoogleCloudAiplatformV1EncryptionSpec {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1EncryptionSpec
		return ret
	}).(GoogleCloudAiplatformV1EncryptionSpecOutput)
}

// The Cloud KMS resource identifier of the customer managed encryption key used to protect a resource. Has the form: `projects/my-project/locations/my-region/keyRings/my-kr/cryptoKeys/my-key`. The key needs to be in the same region as where the compute resource is created.
func (o GoogleCloudAiplatformV1EncryptionSpecPtrOutput) KmsKeyName() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1EncryptionSpec) *string {
		if v == nil {
			return nil
		}
		return &v.KmsKeyName
	}).(pulumi.StringPtrOutput)
}

// Represents a customer-managed encryption key spec that can be applied to a top-level resource.
type GoogleCloudAiplatformV1EncryptionSpecResponse struct {
	// The Cloud KMS resource identifier of the customer managed encryption key used to protect a resource. Has the form: `projects/my-project/locations/my-region/keyRings/my-kr/cryptoKeys/my-key`. The key needs to be in the same region as where the compute resource is created.
	KmsKeyName string `pulumi:"kmsKeyName"`
}

// Represents a customer-managed encryption key spec that can be applied to a top-level resource.
type GoogleCloudAiplatformV1EncryptionSpecResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1EncryptionSpecResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1EncryptionSpecResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1EncryptionSpecResponseOutput) ToGoogleCloudAiplatformV1EncryptionSpecResponseOutput() GoogleCloudAiplatformV1EncryptionSpecResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1EncryptionSpecResponseOutput) ToGoogleCloudAiplatformV1EncryptionSpecResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1EncryptionSpecResponseOutput {
	return o
}

// The Cloud KMS resource identifier of the customer managed encryption key used to protect a resource. Has the form: `projects/my-project/locations/my-region/keyRings/my-kr/cryptoKeys/my-key`. The key needs to be in the same region as where the compute resource is created.
func (o GoogleCloudAiplatformV1EncryptionSpecResponseOutput) KmsKeyName() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1EncryptionSpecResponse) string { return v.KmsKeyName }).(pulumi.StringOutput)
}

// Represents an environment variable present in a Container or Python Module.
type GoogleCloudAiplatformV1EnvVar struct {
	// Name of the environment variable. Must be a valid C identifier.
	Name string `pulumi:"name"`
	// Variables that reference a $(VAR_NAME) are expanded using the previous defined environment variables in the container and any service environment variables. If a variable cannot be resolved, the reference in the input string will be unchanged. The $(VAR_NAME) syntax can be escaped with a double $$, ie: $$(VAR_NAME). Escaped references will never be expanded, regardless of whether the variable exists or not.
	Value string `pulumi:"value"`
}

// GoogleCloudAiplatformV1EnvVarInput is an input type that accepts GoogleCloudAiplatformV1EnvVarArgs and GoogleCloudAiplatformV1EnvVarOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1EnvVarInput` via:
//
//	GoogleCloudAiplatformV1EnvVarArgs{...}
type GoogleCloudAiplatformV1EnvVarInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1EnvVarOutput() GoogleCloudAiplatformV1EnvVarOutput
	ToGoogleCloudAiplatformV1EnvVarOutputWithContext(context.Context) GoogleCloudAiplatformV1EnvVarOutput
}

// Represents an environment variable present in a Container or Python Module.
type GoogleCloudAiplatformV1EnvVarArgs struct {
	// Name of the environment variable. Must be a valid C identifier.
	Name pulumi.StringInput `pulumi:"name"`
	// Variables that reference a $(VAR_NAME) are expanded using the previous defined environment variables in the container and any service environment variables. If a variable cannot be resolved, the reference in the input string will be unchanged. The $(VAR_NAME) syntax can be escaped with a double $$, ie: $$(VAR_NAME). Escaped references will never be expanded, regardless of whether the variable exists or not.
	Value pulumi.StringInput `pulumi:"value"`
}

func (GoogleCloudAiplatformV1EnvVarArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1EnvVar)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1EnvVarArgs) ToGoogleCloudAiplatformV1EnvVarOutput() GoogleCloudAiplatformV1EnvVarOutput {
	return i.ToGoogleCloudAiplatformV1EnvVarOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1EnvVarArgs) ToGoogleCloudAiplatformV1EnvVarOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1EnvVarOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1EnvVarOutput)
}

// GoogleCloudAiplatformV1EnvVarArrayInput is an input type that accepts GoogleCloudAiplatformV1EnvVarArray and GoogleCloudAiplatformV1EnvVarArrayOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1EnvVarArrayInput` via:
//
//	GoogleCloudAiplatformV1EnvVarArray{ GoogleCloudAiplatformV1EnvVarArgs{...} }
type GoogleCloudAiplatformV1EnvVarArrayInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1EnvVarArrayOutput() GoogleCloudAiplatformV1EnvVarArrayOutput
	ToGoogleCloudAiplatformV1EnvVarArrayOutputWithContext(context.Context) GoogleCloudAiplatformV1EnvVarArrayOutput
}

type GoogleCloudAiplatformV1EnvVarArray []GoogleCloudAiplatformV1EnvVarInput

func (GoogleCloudAiplatformV1EnvVarArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1EnvVar)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1EnvVarArray) ToGoogleCloudAiplatformV1EnvVarArrayOutput() GoogleCloudAiplatformV1EnvVarArrayOutput {
	return i.ToGoogleCloudAiplatformV1EnvVarArrayOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1EnvVarArray) ToGoogleCloudAiplatformV1EnvVarArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1EnvVarArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1EnvVarArrayOutput)
}

// Represents an environment variable present in a Container or Python Module.
type GoogleCloudAiplatformV1EnvVarOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1EnvVarOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1EnvVar)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1EnvVarOutput) ToGoogleCloudAiplatformV1EnvVarOutput() GoogleCloudAiplatformV1EnvVarOutput {
	return o
}

func (o GoogleCloudAiplatformV1EnvVarOutput) ToGoogleCloudAiplatformV1EnvVarOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1EnvVarOutput {
	return o
}

// Name of the environment variable. Must be a valid C identifier.
func (o GoogleCloudAiplatformV1EnvVarOutput) Name() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1EnvVar) string { return v.Name }).(pulumi.StringOutput)
}

// Variables that reference a $(VAR_NAME) are expanded using the previous defined environment variables in the container and any service environment variables. If a variable cannot be resolved, the reference in the input string will be unchanged. The $(VAR_NAME) syntax can be escaped with a double $$, ie: $$(VAR_NAME). Escaped references will never be expanded, regardless of whether the variable exists or not.
func (o GoogleCloudAiplatformV1EnvVarOutput) Value() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1EnvVar) string { return v.Value }).(pulumi.StringOutput)
}

type GoogleCloudAiplatformV1EnvVarArrayOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1EnvVarArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1EnvVar)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1EnvVarArrayOutput) ToGoogleCloudAiplatformV1EnvVarArrayOutput() GoogleCloudAiplatformV1EnvVarArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1EnvVarArrayOutput) ToGoogleCloudAiplatformV1EnvVarArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1EnvVarArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1EnvVarArrayOutput) Index(i pulumi.IntInput) GoogleCloudAiplatformV1EnvVarOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GoogleCloudAiplatformV1EnvVar {
		return vs[0].([]GoogleCloudAiplatformV1EnvVar)[vs[1].(int)]
	}).(GoogleCloudAiplatformV1EnvVarOutput)
}

// Represents an environment variable present in a Container or Python Module.
type GoogleCloudAiplatformV1EnvVarResponse struct {
	// Name of the environment variable. Must be a valid C identifier.
	Name string `pulumi:"name"`
	// Variables that reference a $(VAR_NAME) are expanded using the previous defined environment variables in the container and any service environment variables. If a variable cannot be resolved, the reference in the input string will be unchanged. The $(VAR_NAME) syntax can be escaped with a double $$, ie: $$(VAR_NAME). Escaped references will never be expanded, regardless of whether the variable exists or not.
	Value string `pulumi:"value"`
}

// Represents an environment variable present in a Container or Python Module.
type GoogleCloudAiplatformV1EnvVarResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1EnvVarResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1EnvVarResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1EnvVarResponseOutput) ToGoogleCloudAiplatformV1EnvVarResponseOutput() GoogleCloudAiplatformV1EnvVarResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1EnvVarResponseOutput) ToGoogleCloudAiplatformV1EnvVarResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1EnvVarResponseOutput {
	return o
}

// Name of the environment variable. Must be a valid C identifier.
func (o GoogleCloudAiplatformV1EnvVarResponseOutput) Name() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1EnvVarResponse) string { return v.Name }).(pulumi.StringOutput)
}

// Variables that reference a $(VAR_NAME) are expanded using the previous defined environment variables in the container and any service environment variables. If a variable cannot be resolved, the reference in the input string will be unchanged. The $(VAR_NAME) syntax can be escaped with a double $$, ie: $$(VAR_NAME). Escaped references will never be expanded, regardless of whether the variable exists or not.
func (o GoogleCloudAiplatformV1EnvVarResponseOutput) Value() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1EnvVarResponse) string { return v.Value }).(pulumi.StringOutput)
}

type GoogleCloudAiplatformV1EnvVarResponseArrayOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1EnvVarResponseArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1EnvVarResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1EnvVarResponseArrayOutput) ToGoogleCloudAiplatformV1EnvVarResponseArrayOutput() GoogleCloudAiplatformV1EnvVarResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1EnvVarResponseArrayOutput) ToGoogleCloudAiplatformV1EnvVarResponseArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1EnvVarResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1EnvVarResponseArrayOutput) Index(i pulumi.IntInput) GoogleCloudAiplatformV1EnvVarResponseOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GoogleCloudAiplatformV1EnvVarResponse {
		return vs[0].([]GoogleCloudAiplatformV1EnvVarResponse)[vs[1].(int)]
	}).(GoogleCloudAiplatformV1EnvVarResponseOutput)
}

// Example-based explainability that returns the nearest neighbors from the provided dataset.
type GoogleCloudAiplatformV1Examples struct {
	// The Cloud Storage input instances.
	ExampleGcsSource *GoogleCloudAiplatformV1ExamplesExampleGcsSource `pulumi:"exampleGcsSource"`
	// The full configuration for the generated index, the semantics are the same as metadata and should match [NearestNeighborSearchConfig](https://cloud.google.com/vertex-ai/docs/explainable-ai/configuring-explanations-example-based#nearest-neighbor-search-config).
	NearestNeighborSearchConfig interface{} `pulumi:"nearestNeighborSearchConfig"`
	// The number of neighbors to return when querying for examples.
	NeighborCount *int `pulumi:"neighborCount"`
	// Simplified preset configuration, which automatically sets configuration values based on the desired query speed-precision trade-off and modality.
	Presets *GoogleCloudAiplatformV1Presets `pulumi:"presets"`
}

// GoogleCloudAiplatformV1ExamplesInput is an input type that accepts GoogleCloudAiplatformV1ExamplesArgs and GoogleCloudAiplatformV1ExamplesOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1ExamplesInput` via:
//
//	GoogleCloudAiplatformV1ExamplesArgs{...}
type GoogleCloudAiplatformV1ExamplesInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1ExamplesOutput() GoogleCloudAiplatformV1ExamplesOutput
	ToGoogleCloudAiplatformV1ExamplesOutputWithContext(context.Context) GoogleCloudAiplatformV1ExamplesOutput
}

// Example-based explainability that returns the nearest neighbors from the provided dataset.
type GoogleCloudAiplatformV1ExamplesArgs struct {
	// The Cloud Storage input instances.
	ExampleGcsSource GoogleCloudAiplatformV1ExamplesExampleGcsSourcePtrInput `pulumi:"exampleGcsSource"`
	// The full configuration for the generated index, the semantics are the same as metadata and should match [NearestNeighborSearchConfig](https://cloud.google.com/vertex-ai/docs/explainable-ai/configuring-explanations-example-based#nearest-neighbor-search-config).
	NearestNeighborSearchConfig pulumi.Input `pulumi:"nearestNeighborSearchConfig"`
	// The number of neighbors to return when querying for examples.
	NeighborCount pulumi.IntPtrInput `pulumi:"neighborCount"`
	// Simplified preset configuration, which automatically sets configuration values based on the desired query speed-precision trade-off and modality.
	Presets GoogleCloudAiplatformV1PresetsPtrInput `pulumi:"presets"`
}

func (GoogleCloudAiplatformV1ExamplesArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1Examples)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1ExamplesArgs) ToGoogleCloudAiplatformV1ExamplesOutput() GoogleCloudAiplatformV1ExamplesOutput {
	return i.ToGoogleCloudAiplatformV1ExamplesOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1ExamplesArgs) ToGoogleCloudAiplatformV1ExamplesOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ExamplesOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1ExamplesOutput)
}

func (i GoogleCloudAiplatformV1ExamplesArgs) ToGoogleCloudAiplatformV1ExamplesPtrOutput() GoogleCloudAiplatformV1ExamplesPtrOutput {
	return i.ToGoogleCloudAiplatformV1ExamplesPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1ExamplesArgs) ToGoogleCloudAiplatformV1ExamplesPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ExamplesPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1ExamplesOutput).ToGoogleCloudAiplatformV1ExamplesPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1ExamplesPtrInput is an input type that accepts GoogleCloudAiplatformV1ExamplesArgs, GoogleCloudAiplatformV1ExamplesPtr and GoogleCloudAiplatformV1ExamplesPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1ExamplesPtrInput` via:
//
//	        GoogleCloudAiplatformV1ExamplesArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1ExamplesPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1ExamplesPtrOutput() GoogleCloudAiplatformV1ExamplesPtrOutput
	ToGoogleCloudAiplatformV1ExamplesPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1ExamplesPtrOutput
}

type googleCloudAiplatformV1ExamplesPtrType GoogleCloudAiplatformV1ExamplesArgs

func GoogleCloudAiplatformV1ExamplesPtr(v *GoogleCloudAiplatformV1ExamplesArgs) GoogleCloudAiplatformV1ExamplesPtrInput {
	return (*googleCloudAiplatformV1ExamplesPtrType)(v)
}

func (*googleCloudAiplatformV1ExamplesPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1Examples)(nil)).Elem()
}

func (i *googleCloudAiplatformV1ExamplesPtrType) ToGoogleCloudAiplatformV1ExamplesPtrOutput() GoogleCloudAiplatformV1ExamplesPtrOutput {
	return i.ToGoogleCloudAiplatformV1ExamplesPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1ExamplesPtrType) ToGoogleCloudAiplatformV1ExamplesPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ExamplesPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1ExamplesPtrOutput)
}

// Example-based explainability that returns the nearest neighbors from the provided dataset.
type GoogleCloudAiplatformV1ExamplesOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ExamplesOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1Examples)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ExamplesOutput) ToGoogleCloudAiplatformV1ExamplesOutput() GoogleCloudAiplatformV1ExamplesOutput {
	return o
}

func (o GoogleCloudAiplatformV1ExamplesOutput) ToGoogleCloudAiplatformV1ExamplesOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ExamplesOutput {
	return o
}

func (o GoogleCloudAiplatformV1ExamplesOutput) ToGoogleCloudAiplatformV1ExamplesPtrOutput() GoogleCloudAiplatformV1ExamplesPtrOutput {
	return o.ToGoogleCloudAiplatformV1ExamplesPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1ExamplesOutput) ToGoogleCloudAiplatformV1ExamplesPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ExamplesPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1Examples) *GoogleCloudAiplatformV1Examples {
		return &v
	}).(GoogleCloudAiplatformV1ExamplesPtrOutput)
}

// The Cloud Storage input instances.
func (o GoogleCloudAiplatformV1ExamplesOutput) ExampleGcsSource() GoogleCloudAiplatformV1ExamplesExampleGcsSourcePtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1Examples) *GoogleCloudAiplatformV1ExamplesExampleGcsSource {
		return v.ExampleGcsSource
	}).(GoogleCloudAiplatformV1ExamplesExampleGcsSourcePtrOutput)
}

// The full configuration for the generated index, the semantics are the same as metadata and should match [NearestNeighborSearchConfig](https://cloud.google.com/vertex-ai/docs/explainable-ai/configuring-explanations-example-based#nearest-neighbor-search-config).
func (o GoogleCloudAiplatformV1ExamplesOutput) NearestNeighborSearchConfig() pulumi.AnyOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1Examples) interface{} { return v.NearestNeighborSearchConfig }).(pulumi.AnyOutput)
}

// The number of neighbors to return when querying for examples.
func (o GoogleCloudAiplatformV1ExamplesOutput) NeighborCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1Examples) *int { return v.NeighborCount }).(pulumi.IntPtrOutput)
}

// Simplified preset configuration, which automatically sets configuration values based on the desired query speed-precision trade-off and modality.
func (o GoogleCloudAiplatformV1ExamplesOutput) Presets() GoogleCloudAiplatformV1PresetsPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1Examples) *GoogleCloudAiplatformV1Presets { return v.Presets }).(GoogleCloudAiplatformV1PresetsPtrOutput)
}

type GoogleCloudAiplatformV1ExamplesPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ExamplesPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1Examples)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ExamplesPtrOutput) ToGoogleCloudAiplatformV1ExamplesPtrOutput() GoogleCloudAiplatformV1ExamplesPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1ExamplesPtrOutput) ToGoogleCloudAiplatformV1ExamplesPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ExamplesPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1ExamplesPtrOutput) Elem() GoogleCloudAiplatformV1ExamplesOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1Examples) GoogleCloudAiplatformV1Examples {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1Examples
		return ret
	}).(GoogleCloudAiplatformV1ExamplesOutput)
}

// The Cloud Storage input instances.
func (o GoogleCloudAiplatformV1ExamplesPtrOutput) ExampleGcsSource() GoogleCloudAiplatformV1ExamplesExampleGcsSourcePtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1Examples) *GoogleCloudAiplatformV1ExamplesExampleGcsSource {
		if v == nil {
			return nil
		}
		return v.ExampleGcsSource
	}).(GoogleCloudAiplatformV1ExamplesExampleGcsSourcePtrOutput)
}

// The full configuration for the generated index, the semantics are the same as metadata and should match [NearestNeighborSearchConfig](https://cloud.google.com/vertex-ai/docs/explainable-ai/configuring-explanations-example-based#nearest-neighbor-search-config).
func (o GoogleCloudAiplatformV1ExamplesPtrOutput) NearestNeighborSearchConfig() pulumi.AnyOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1Examples) interface{} {
		if v == nil {
			return nil
		}
		return v.NearestNeighborSearchConfig
	}).(pulumi.AnyOutput)
}

// The number of neighbors to return when querying for examples.
func (o GoogleCloudAiplatformV1ExamplesPtrOutput) NeighborCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1Examples) *int {
		if v == nil {
			return nil
		}
		return v.NeighborCount
	}).(pulumi.IntPtrOutput)
}

// Simplified preset configuration, which automatically sets configuration values based on the desired query speed-precision trade-off and modality.
func (o GoogleCloudAiplatformV1ExamplesPtrOutput) Presets() GoogleCloudAiplatformV1PresetsPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1Examples) *GoogleCloudAiplatformV1Presets {
		if v == nil {
			return nil
		}
		return v.Presets
	}).(GoogleCloudAiplatformV1PresetsPtrOutput)
}

// The Cloud Storage input instances.
type GoogleCloudAiplatformV1ExamplesExampleGcsSource struct {
	// The format in which instances are given, if not specified, assume it's JSONL format. Currently only JSONL format is supported.
	DataFormat *GoogleCloudAiplatformV1ExamplesExampleGcsSourceDataFormat `pulumi:"dataFormat"`
	// The Cloud Storage location for the input instances.
	GcsSource *GoogleCloudAiplatformV1GcsSource `pulumi:"gcsSource"`
}

// GoogleCloudAiplatformV1ExamplesExampleGcsSourceInput is an input type that accepts GoogleCloudAiplatformV1ExamplesExampleGcsSourceArgs and GoogleCloudAiplatformV1ExamplesExampleGcsSourceOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1ExamplesExampleGcsSourceInput` via:
//
//	GoogleCloudAiplatformV1ExamplesExampleGcsSourceArgs{...}
type GoogleCloudAiplatformV1ExamplesExampleGcsSourceInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1ExamplesExampleGcsSourceOutput() GoogleCloudAiplatformV1ExamplesExampleGcsSourceOutput
	ToGoogleCloudAiplatformV1ExamplesExampleGcsSourceOutputWithContext(context.Context) GoogleCloudAiplatformV1ExamplesExampleGcsSourceOutput
}

// The Cloud Storage input instances.
type GoogleCloudAiplatformV1ExamplesExampleGcsSourceArgs struct {
	// The format in which instances are given, if not specified, assume it's JSONL format. Currently only JSONL format is supported.
	DataFormat GoogleCloudAiplatformV1ExamplesExampleGcsSourceDataFormatPtrInput `pulumi:"dataFormat"`
	// The Cloud Storage location for the input instances.
	GcsSource GoogleCloudAiplatformV1GcsSourcePtrInput `pulumi:"gcsSource"`
}

func (GoogleCloudAiplatformV1ExamplesExampleGcsSourceArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1ExamplesExampleGcsSource)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1ExamplesExampleGcsSourceArgs) ToGoogleCloudAiplatformV1ExamplesExampleGcsSourceOutput() GoogleCloudAiplatformV1ExamplesExampleGcsSourceOutput {
	return i.ToGoogleCloudAiplatformV1ExamplesExampleGcsSourceOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1ExamplesExampleGcsSourceArgs) ToGoogleCloudAiplatformV1ExamplesExampleGcsSourceOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ExamplesExampleGcsSourceOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1ExamplesExampleGcsSourceOutput)
}

func (i GoogleCloudAiplatformV1ExamplesExampleGcsSourceArgs) ToGoogleCloudAiplatformV1ExamplesExampleGcsSourcePtrOutput() GoogleCloudAiplatformV1ExamplesExampleGcsSourcePtrOutput {
	return i.ToGoogleCloudAiplatformV1ExamplesExampleGcsSourcePtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1ExamplesExampleGcsSourceArgs) ToGoogleCloudAiplatformV1ExamplesExampleGcsSourcePtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ExamplesExampleGcsSourcePtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1ExamplesExampleGcsSourceOutput).ToGoogleCloudAiplatformV1ExamplesExampleGcsSourcePtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1ExamplesExampleGcsSourcePtrInput is an input type that accepts GoogleCloudAiplatformV1ExamplesExampleGcsSourceArgs, GoogleCloudAiplatformV1ExamplesExampleGcsSourcePtr and GoogleCloudAiplatformV1ExamplesExampleGcsSourcePtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1ExamplesExampleGcsSourcePtrInput` via:
//
//	        GoogleCloudAiplatformV1ExamplesExampleGcsSourceArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1ExamplesExampleGcsSourcePtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1ExamplesExampleGcsSourcePtrOutput() GoogleCloudAiplatformV1ExamplesExampleGcsSourcePtrOutput
	ToGoogleCloudAiplatformV1ExamplesExampleGcsSourcePtrOutputWithContext(context.Context) GoogleCloudAiplatformV1ExamplesExampleGcsSourcePtrOutput
}

type googleCloudAiplatformV1ExamplesExampleGcsSourcePtrType GoogleCloudAiplatformV1ExamplesExampleGcsSourceArgs

func GoogleCloudAiplatformV1ExamplesExampleGcsSourcePtr(v *GoogleCloudAiplatformV1ExamplesExampleGcsSourceArgs) GoogleCloudAiplatformV1ExamplesExampleGcsSourcePtrInput {
	return (*googleCloudAiplatformV1ExamplesExampleGcsSourcePtrType)(v)
}

func (*googleCloudAiplatformV1ExamplesExampleGcsSourcePtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1ExamplesExampleGcsSource)(nil)).Elem()
}

func (i *googleCloudAiplatformV1ExamplesExampleGcsSourcePtrType) ToGoogleCloudAiplatformV1ExamplesExampleGcsSourcePtrOutput() GoogleCloudAiplatformV1ExamplesExampleGcsSourcePtrOutput {
	return i.ToGoogleCloudAiplatformV1ExamplesExampleGcsSourcePtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1ExamplesExampleGcsSourcePtrType) ToGoogleCloudAiplatformV1ExamplesExampleGcsSourcePtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ExamplesExampleGcsSourcePtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1ExamplesExampleGcsSourcePtrOutput)
}

// The Cloud Storage input instances.
type GoogleCloudAiplatformV1ExamplesExampleGcsSourceOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ExamplesExampleGcsSourceOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1ExamplesExampleGcsSource)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ExamplesExampleGcsSourceOutput) ToGoogleCloudAiplatformV1ExamplesExampleGcsSourceOutput() GoogleCloudAiplatformV1ExamplesExampleGcsSourceOutput {
	return o
}

func (o GoogleCloudAiplatformV1ExamplesExampleGcsSourceOutput) ToGoogleCloudAiplatformV1ExamplesExampleGcsSourceOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ExamplesExampleGcsSourceOutput {
	return o
}

func (o GoogleCloudAiplatformV1ExamplesExampleGcsSourceOutput) ToGoogleCloudAiplatformV1ExamplesExampleGcsSourcePtrOutput() GoogleCloudAiplatformV1ExamplesExampleGcsSourcePtrOutput {
	return o.ToGoogleCloudAiplatformV1ExamplesExampleGcsSourcePtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1ExamplesExampleGcsSourceOutput) ToGoogleCloudAiplatformV1ExamplesExampleGcsSourcePtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ExamplesExampleGcsSourcePtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1ExamplesExampleGcsSource) *GoogleCloudAiplatformV1ExamplesExampleGcsSource {
		return &v
	}).(GoogleCloudAiplatformV1ExamplesExampleGcsSourcePtrOutput)
}

// The format in which instances are given, if not specified, assume it's JSONL format. Currently only JSONL format is supported.
func (o GoogleCloudAiplatformV1ExamplesExampleGcsSourceOutput) DataFormat() GoogleCloudAiplatformV1ExamplesExampleGcsSourceDataFormatPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ExamplesExampleGcsSource) *GoogleCloudAiplatformV1ExamplesExampleGcsSourceDataFormat {
		return v.DataFormat
	}).(GoogleCloudAiplatformV1ExamplesExampleGcsSourceDataFormatPtrOutput)
}

// The Cloud Storage location for the input instances.
func (o GoogleCloudAiplatformV1ExamplesExampleGcsSourceOutput) GcsSource() GoogleCloudAiplatformV1GcsSourcePtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ExamplesExampleGcsSource) *GoogleCloudAiplatformV1GcsSource {
		return v.GcsSource
	}).(GoogleCloudAiplatformV1GcsSourcePtrOutput)
}

type GoogleCloudAiplatformV1ExamplesExampleGcsSourcePtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ExamplesExampleGcsSourcePtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1ExamplesExampleGcsSource)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ExamplesExampleGcsSourcePtrOutput) ToGoogleCloudAiplatformV1ExamplesExampleGcsSourcePtrOutput() GoogleCloudAiplatformV1ExamplesExampleGcsSourcePtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1ExamplesExampleGcsSourcePtrOutput) ToGoogleCloudAiplatformV1ExamplesExampleGcsSourcePtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ExamplesExampleGcsSourcePtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1ExamplesExampleGcsSourcePtrOutput) Elem() GoogleCloudAiplatformV1ExamplesExampleGcsSourceOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1ExamplesExampleGcsSource) GoogleCloudAiplatformV1ExamplesExampleGcsSource {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1ExamplesExampleGcsSource
		return ret
	}).(GoogleCloudAiplatformV1ExamplesExampleGcsSourceOutput)
}

// The format in which instances are given, if not specified, assume it's JSONL format. Currently only JSONL format is supported.
func (o GoogleCloudAiplatformV1ExamplesExampleGcsSourcePtrOutput) DataFormat() GoogleCloudAiplatformV1ExamplesExampleGcsSourceDataFormatPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1ExamplesExampleGcsSource) *GoogleCloudAiplatformV1ExamplesExampleGcsSourceDataFormat {
		if v == nil {
			return nil
		}
		return v.DataFormat
	}).(GoogleCloudAiplatformV1ExamplesExampleGcsSourceDataFormatPtrOutput)
}

// The Cloud Storage location for the input instances.
func (o GoogleCloudAiplatformV1ExamplesExampleGcsSourcePtrOutput) GcsSource() GoogleCloudAiplatformV1GcsSourcePtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1ExamplesExampleGcsSource) *GoogleCloudAiplatformV1GcsSource {
		if v == nil {
			return nil
		}
		return v.GcsSource
	}).(GoogleCloudAiplatformV1GcsSourcePtrOutput)
}

// The Cloud Storage input instances.
type GoogleCloudAiplatformV1ExamplesExampleGcsSourceResponse struct {
	// The format in which instances are given, if not specified, assume it's JSONL format. Currently only JSONL format is supported.
	DataFormat string `pulumi:"dataFormat"`
	// The Cloud Storage location for the input instances.
	GcsSource GoogleCloudAiplatformV1GcsSourceResponse `pulumi:"gcsSource"`
}

// The Cloud Storage input instances.
type GoogleCloudAiplatformV1ExamplesExampleGcsSourceResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ExamplesExampleGcsSourceResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1ExamplesExampleGcsSourceResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ExamplesExampleGcsSourceResponseOutput) ToGoogleCloudAiplatformV1ExamplesExampleGcsSourceResponseOutput() GoogleCloudAiplatformV1ExamplesExampleGcsSourceResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1ExamplesExampleGcsSourceResponseOutput) ToGoogleCloudAiplatformV1ExamplesExampleGcsSourceResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ExamplesExampleGcsSourceResponseOutput {
	return o
}

// The format in which instances are given, if not specified, assume it's JSONL format. Currently only JSONL format is supported.
func (o GoogleCloudAiplatformV1ExamplesExampleGcsSourceResponseOutput) DataFormat() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ExamplesExampleGcsSourceResponse) string { return v.DataFormat }).(pulumi.StringOutput)
}

// The Cloud Storage location for the input instances.
func (o GoogleCloudAiplatformV1ExamplesExampleGcsSourceResponseOutput) GcsSource() GoogleCloudAiplatformV1GcsSourceResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ExamplesExampleGcsSourceResponse) GoogleCloudAiplatformV1GcsSourceResponse {
		return v.GcsSource
	}).(GoogleCloudAiplatformV1GcsSourceResponseOutput)
}

// Example-based explainability that returns the nearest neighbors from the provided dataset.
type GoogleCloudAiplatformV1ExamplesResponse struct {
	// The Cloud Storage input instances.
	ExampleGcsSource GoogleCloudAiplatformV1ExamplesExampleGcsSourceResponse `pulumi:"exampleGcsSource"`
	// The full configuration for the generated index, the semantics are the same as metadata and should match [NearestNeighborSearchConfig](https://cloud.google.com/vertex-ai/docs/explainable-ai/configuring-explanations-example-based#nearest-neighbor-search-config).
	NearestNeighborSearchConfig interface{} `pulumi:"nearestNeighborSearchConfig"`
	// The number of neighbors to return when querying for examples.
	NeighborCount int `pulumi:"neighborCount"`
	// Simplified preset configuration, which automatically sets configuration values based on the desired query speed-precision trade-off and modality.
	Presets GoogleCloudAiplatformV1PresetsResponse `pulumi:"presets"`
}

// Example-based explainability that returns the nearest neighbors from the provided dataset.
type GoogleCloudAiplatformV1ExamplesResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ExamplesResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1ExamplesResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ExamplesResponseOutput) ToGoogleCloudAiplatformV1ExamplesResponseOutput() GoogleCloudAiplatformV1ExamplesResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1ExamplesResponseOutput) ToGoogleCloudAiplatformV1ExamplesResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ExamplesResponseOutput {
	return o
}

// The Cloud Storage input instances.
func (o GoogleCloudAiplatformV1ExamplesResponseOutput) ExampleGcsSource() GoogleCloudAiplatformV1ExamplesExampleGcsSourceResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ExamplesResponse) GoogleCloudAiplatformV1ExamplesExampleGcsSourceResponse {
		return v.ExampleGcsSource
	}).(GoogleCloudAiplatformV1ExamplesExampleGcsSourceResponseOutput)
}

// The full configuration for the generated index, the semantics are the same as metadata and should match [NearestNeighborSearchConfig](https://cloud.google.com/vertex-ai/docs/explainable-ai/configuring-explanations-example-based#nearest-neighbor-search-config).
func (o GoogleCloudAiplatformV1ExamplesResponseOutput) NearestNeighborSearchConfig() pulumi.AnyOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ExamplesResponse) interface{} { return v.NearestNeighborSearchConfig }).(pulumi.AnyOutput)
}

// The number of neighbors to return when querying for examples.
func (o GoogleCloudAiplatformV1ExamplesResponseOutput) NeighborCount() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ExamplesResponse) int { return v.NeighborCount }).(pulumi.IntOutput)
}

// Simplified preset configuration, which automatically sets configuration values based on the desired query speed-precision trade-off and modality.
func (o GoogleCloudAiplatformV1ExamplesResponseOutput) Presets() GoogleCloudAiplatformV1PresetsResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ExamplesResponse) GoogleCloudAiplatformV1PresetsResponse {
		return v.Presets
	}).(GoogleCloudAiplatformV1PresetsResponseOutput)
}

// Instance of a general execution.
type GoogleCloudAiplatformV1ExecutionResponse struct {
	// Timestamp when this Execution was created.
	CreateTime string `pulumi:"createTime"`
	// Description of the Execution
	Description string `pulumi:"description"`
	// User provided display name of the Execution. May be up to 128 Unicode characters.
	DisplayName string `pulumi:"displayName"`
	// An eTag used to perform consistent read-modify-write updates. If not set, a blind "overwrite" update happens.
	Etag string `pulumi:"etag"`
	// The labels with user-defined metadata to organize your Executions. Label keys and values can be no longer than 64 characters (Unicode codepoints), can only contain lowercase letters, numeric characters, underscores and dashes. International characters are allowed. No more than 64 user labels can be associated with one Execution (System labels are excluded).
	Labels map[string]string `pulumi:"labels"`
	// Properties of the Execution. Top level metadata keys' heading and trailing spaces will be trimmed. The size of this field should not exceed 200KB.
	Metadata map[string]interface{} `pulumi:"metadata"`
	// The resource name of the Execution.
	Name string `pulumi:"name"`
	// The title of the schema describing the metadata. Schema title and version is expected to be registered in earlier Create Schema calls. And both are used together as unique identifiers to identify schemas within the local metadata store.
	SchemaTitle string `pulumi:"schemaTitle"`
	// The version of the schema in `schema_title` to use. Schema title and version is expected to be registered in earlier Create Schema calls. And both are used together as unique identifiers to identify schemas within the local metadata store.
	SchemaVersion string `pulumi:"schemaVersion"`
	// The state of this Execution. This is a property of the Execution, and does not imply or capture any ongoing process. This property is managed by clients (such as Vertex AI Pipelines) and the system does not prescribe or check the validity of state transitions.
	State string `pulumi:"state"`
	// Timestamp when this Execution was last updated.
	UpdateTime string `pulumi:"updateTime"`
}

// Instance of a general execution.
type GoogleCloudAiplatformV1ExecutionResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ExecutionResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1ExecutionResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ExecutionResponseOutput) ToGoogleCloudAiplatformV1ExecutionResponseOutput() GoogleCloudAiplatformV1ExecutionResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1ExecutionResponseOutput) ToGoogleCloudAiplatformV1ExecutionResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ExecutionResponseOutput {
	return o
}

// Timestamp when this Execution was created.
func (o GoogleCloudAiplatformV1ExecutionResponseOutput) CreateTime() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ExecutionResponse) string { return v.CreateTime }).(pulumi.StringOutput)
}

// Description of the Execution
func (o GoogleCloudAiplatformV1ExecutionResponseOutput) Description() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ExecutionResponse) string { return v.Description }).(pulumi.StringOutput)
}

// User provided display name of the Execution. May be up to 128 Unicode characters.
func (o GoogleCloudAiplatformV1ExecutionResponseOutput) DisplayName() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ExecutionResponse) string { return v.DisplayName }).(pulumi.StringOutput)
}

// An eTag used to perform consistent read-modify-write updates. If not set, a blind "overwrite" update happens.
func (o GoogleCloudAiplatformV1ExecutionResponseOutput) Etag() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ExecutionResponse) string { return v.Etag }).(pulumi.StringOutput)
}

// The labels with user-defined metadata to organize your Executions. Label keys and values can be no longer than 64 characters (Unicode codepoints), can only contain lowercase letters, numeric characters, underscores and dashes. International characters are allowed. No more than 64 user labels can be associated with one Execution (System labels are excluded).
func (o GoogleCloudAiplatformV1ExecutionResponseOutput) Labels() pulumi.StringMapOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ExecutionResponse) map[string]string { return v.Labels }).(pulumi.StringMapOutput)
}

// Properties of the Execution. Top level metadata keys' heading and trailing spaces will be trimmed. The size of this field should not exceed 200KB.
func (o GoogleCloudAiplatformV1ExecutionResponseOutput) Metadata() pulumi.MapOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ExecutionResponse) map[string]interface{} { return v.Metadata }).(pulumi.MapOutput)
}

// The resource name of the Execution.
func (o GoogleCloudAiplatformV1ExecutionResponseOutput) Name() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ExecutionResponse) string { return v.Name }).(pulumi.StringOutput)
}

// The title of the schema describing the metadata. Schema title and version is expected to be registered in earlier Create Schema calls. And both are used together as unique identifiers to identify schemas within the local metadata store.
func (o GoogleCloudAiplatformV1ExecutionResponseOutput) SchemaTitle() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ExecutionResponse) string { return v.SchemaTitle }).(pulumi.StringOutput)
}

// The version of the schema in `schema_title` to use. Schema title and version is expected to be registered in earlier Create Schema calls. And both are used together as unique identifiers to identify schemas within the local metadata store.
func (o GoogleCloudAiplatformV1ExecutionResponseOutput) SchemaVersion() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ExecutionResponse) string { return v.SchemaVersion }).(pulumi.StringOutput)
}

// The state of this Execution. This is a property of the Execution, and does not imply or capture any ongoing process. This property is managed by clients (such as Vertex AI Pipelines) and the system does not prescribe or check the validity of state transitions.
func (o GoogleCloudAiplatformV1ExecutionResponseOutput) State() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ExecutionResponse) string { return v.State }).(pulumi.StringOutput)
}

// Timestamp when this Execution was last updated.
func (o GoogleCloudAiplatformV1ExecutionResponseOutput) UpdateTime() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ExecutionResponse) string { return v.UpdateTime }).(pulumi.StringOutput)
}

// Metadata describing the Model's input and output for explanation.
type GoogleCloudAiplatformV1ExplanationMetadata struct {
	// Points to a YAML file stored on Google Cloud Storage describing the format of the feature attributions. The schema is defined as an OpenAPI 3.0.2 [Schema Object](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject). AutoML tabular Models always have this field populated by Vertex AI. Note: The URI given on output may be different, including the URI scheme, than the one given on input. The output URI will point to a location where the user only has a read access.
	FeatureAttributionsSchemaUri *string `pulumi:"featureAttributionsSchemaUri"`
	// Map from feature names to feature input metadata. Keys are the name of the features. Values are the specification of the feature. An empty InputMetadata is valid. It describes a text feature which has the name specified as the key in ExplanationMetadata.inputs. The baseline of the empty feature is chosen by Vertex AI. For Vertex AI-provided Tensorflow images, the key can be any friendly name of the feature. Once specified, featureAttributions are keyed by this key (if not grouped with another feature). For custom images, the key must match with the key in instance.
	Inputs map[string]GoogleCloudAiplatformV1ExplanationMetadataInputMetadata `pulumi:"inputs"`
	// Name of the source to generate embeddings for example based explanations.
	LatentSpaceSource *string `pulumi:"latentSpaceSource"`
	// Map from output names to output metadata. For Vertex AI-provided Tensorflow images, keys can be any user defined string that consists of any UTF-8 characters. For custom images, keys are the name of the output field in the prediction to be explained. Currently only one key is allowed.
	Outputs map[string]GoogleCloudAiplatformV1ExplanationMetadataOutputMetadata `pulumi:"outputs"`
}

// GoogleCloudAiplatformV1ExplanationMetadataInput is an input type that accepts GoogleCloudAiplatformV1ExplanationMetadataArgs and GoogleCloudAiplatformV1ExplanationMetadataOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1ExplanationMetadataInput` via:
//
//	GoogleCloudAiplatformV1ExplanationMetadataArgs{...}
type GoogleCloudAiplatformV1ExplanationMetadataInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1ExplanationMetadataOutput() GoogleCloudAiplatformV1ExplanationMetadataOutput
	ToGoogleCloudAiplatformV1ExplanationMetadataOutputWithContext(context.Context) GoogleCloudAiplatformV1ExplanationMetadataOutput
}

// Metadata describing the Model's input and output for explanation.
type GoogleCloudAiplatformV1ExplanationMetadataArgs struct {
	// Points to a YAML file stored on Google Cloud Storage describing the format of the feature attributions. The schema is defined as an OpenAPI 3.0.2 [Schema Object](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject). AutoML tabular Models always have this field populated by Vertex AI. Note: The URI given on output may be different, including the URI scheme, than the one given on input. The output URI will point to a location where the user only has a read access.
	FeatureAttributionsSchemaUri pulumi.StringPtrInput `pulumi:"featureAttributionsSchemaUri"`
	// Map from feature names to feature input metadata. Keys are the name of the features. Values are the specification of the feature. An empty InputMetadata is valid. It describes a text feature which has the name specified as the key in ExplanationMetadata.inputs. The baseline of the empty feature is chosen by Vertex AI. For Vertex AI-provided Tensorflow images, the key can be any friendly name of the feature. Once specified, featureAttributions are keyed by this key (if not grouped with another feature). For custom images, the key must match with the key in instance.
	Inputs GoogleCloudAiplatformV1ExplanationMetadataInputMetadataMapInput `pulumi:"inputs"`
	// Name of the source to generate embeddings for example based explanations.
	LatentSpaceSource pulumi.StringPtrInput `pulumi:"latentSpaceSource"`
	// Map from output names to output metadata. For Vertex AI-provided Tensorflow images, keys can be any user defined string that consists of any UTF-8 characters. For custom images, keys are the name of the output field in the prediction to be explained. Currently only one key is allowed.
	Outputs GoogleCloudAiplatformV1ExplanationMetadataOutputMetadataMapInput `pulumi:"outputs"`
}

func (GoogleCloudAiplatformV1ExplanationMetadataArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1ExplanationMetadata)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1ExplanationMetadataArgs) ToGoogleCloudAiplatformV1ExplanationMetadataOutput() GoogleCloudAiplatformV1ExplanationMetadataOutput {
	return i.ToGoogleCloudAiplatformV1ExplanationMetadataOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1ExplanationMetadataArgs) ToGoogleCloudAiplatformV1ExplanationMetadataOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ExplanationMetadataOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1ExplanationMetadataOutput)
}

func (i GoogleCloudAiplatformV1ExplanationMetadataArgs) ToGoogleCloudAiplatformV1ExplanationMetadataPtrOutput() GoogleCloudAiplatformV1ExplanationMetadataPtrOutput {
	return i.ToGoogleCloudAiplatformV1ExplanationMetadataPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1ExplanationMetadataArgs) ToGoogleCloudAiplatformV1ExplanationMetadataPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ExplanationMetadataPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1ExplanationMetadataOutput).ToGoogleCloudAiplatformV1ExplanationMetadataPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1ExplanationMetadataPtrInput is an input type that accepts GoogleCloudAiplatformV1ExplanationMetadataArgs, GoogleCloudAiplatformV1ExplanationMetadataPtr and GoogleCloudAiplatformV1ExplanationMetadataPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1ExplanationMetadataPtrInput` via:
//
//	        GoogleCloudAiplatformV1ExplanationMetadataArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1ExplanationMetadataPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1ExplanationMetadataPtrOutput() GoogleCloudAiplatformV1ExplanationMetadataPtrOutput
	ToGoogleCloudAiplatformV1ExplanationMetadataPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1ExplanationMetadataPtrOutput
}

type googleCloudAiplatformV1ExplanationMetadataPtrType GoogleCloudAiplatformV1ExplanationMetadataArgs

func GoogleCloudAiplatformV1ExplanationMetadataPtr(v *GoogleCloudAiplatformV1ExplanationMetadataArgs) GoogleCloudAiplatformV1ExplanationMetadataPtrInput {
	return (*googleCloudAiplatformV1ExplanationMetadataPtrType)(v)
}

func (*googleCloudAiplatformV1ExplanationMetadataPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1ExplanationMetadata)(nil)).Elem()
}

func (i *googleCloudAiplatformV1ExplanationMetadataPtrType) ToGoogleCloudAiplatformV1ExplanationMetadataPtrOutput() GoogleCloudAiplatformV1ExplanationMetadataPtrOutput {
	return i.ToGoogleCloudAiplatformV1ExplanationMetadataPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1ExplanationMetadataPtrType) ToGoogleCloudAiplatformV1ExplanationMetadataPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ExplanationMetadataPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1ExplanationMetadataPtrOutput)
}

// Metadata describing the Model's input and output for explanation.
type GoogleCloudAiplatformV1ExplanationMetadataOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ExplanationMetadataOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1ExplanationMetadata)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ExplanationMetadataOutput) ToGoogleCloudAiplatformV1ExplanationMetadataOutput() GoogleCloudAiplatformV1ExplanationMetadataOutput {
	return o
}

func (o GoogleCloudAiplatformV1ExplanationMetadataOutput) ToGoogleCloudAiplatformV1ExplanationMetadataOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ExplanationMetadataOutput {
	return o
}

func (o GoogleCloudAiplatformV1ExplanationMetadataOutput) ToGoogleCloudAiplatformV1ExplanationMetadataPtrOutput() GoogleCloudAiplatformV1ExplanationMetadataPtrOutput {
	return o.ToGoogleCloudAiplatformV1ExplanationMetadataPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1ExplanationMetadataOutput) ToGoogleCloudAiplatformV1ExplanationMetadataPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ExplanationMetadataPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1ExplanationMetadata) *GoogleCloudAiplatformV1ExplanationMetadata {
		return &v
	}).(GoogleCloudAiplatformV1ExplanationMetadataPtrOutput)
}

// Points to a YAML file stored on Google Cloud Storage describing the format of the feature attributions. The schema is defined as an OpenAPI 3.0.2 [Schema Object](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject). AutoML tabular Models always have this field populated by Vertex AI. Note: The URI given on output may be different, including the URI scheme, than the one given on input. The output URI will point to a location where the user only has a read access.
func (o GoogleCloudAiplatformV1ExplanationMetadataOutput) FeatureAttributionsSchemaUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ExplanationMetadata) *string { return v.FeatureAttributionsSchemaUri }).(pulumi.StringPtrOutput)
}

// Map from feature names to feature input metadata. Keys are the name of the features. Values are the specification of the feature. An empty InputMetadata is valid. It describes a text feature which has the name specified as the key in ExplanationMetadata.inputs. The baseline of the empty feature is chosen by Vertex AI. For Vertex AI-provided Tensorflow images, the key can be any friendly name of the feature. Once specified, featureAttributions are keyed by this key (if not grouped with another feature). For custom images, the key must match with the key in instance.
func (o GoogleCloudAiplatformV1ExplanationMetadataOutput) Inputs() GoogleCloudAiplatformV1ExplanationMetadataInputMetadataMapOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ExplanationMetadata) map[string]GoogleCloudAiplatformV1ExplanationMetadataInputMetadata {
		return v.Inputs
	}).(GoogleCloudAiplatformV1ExplanationMetadataInputMetadataMapOutput)
}

// Name of the source to generate embeddings for example based explanations.
func (o GoogleCloudAiplatformV1ExplanationMetadataOutput) LatentSpaceSource() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ExplanationMetadata) *string { return v.LatentSpaceSource }).(pulumi.StringPtrOutput)
}

// Map from output names to output metadata. For Vertex AI-provided Tensorflow images, keys can be any user defined string that consists of any UTF-8 characters. For custom images, keys are the name of the output field in the prediction to be explained. Currently only one key is allowed.
func (o GoogleCloudAiplatformV1ExplanationMetadataOutput) Outputs() GoogleCloudAiplatformV1ExplanationMetadataOutputMetadataMapOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ExplanationMetadata) map[string]GoogleCloudAiplatformV1ExplanationMetadataOutputMetadata {
		return v.Outputs
	}).(GoogleCloudAiplatformV1ExplanationMetadataOutputMetadataMapOutput)
}

type GoogleCloudAiplatformV1ExplanationMetadataPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ExplanationMetadataPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1ExplanationMetadata)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ExplanationMetadataPtrOutput) ToGoogleCloudAiplatformV1ExplanationMetadataPtrOutput() GoogleCloudAiplatformV1ExplanationMetadataPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1ExplanationMetadataPtrOutput) ToGoogleCloudAiplatformV1ExplanationMetadataPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ExplanationMetadataPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1ExplanationMetadataPtrOutput) Elem() GoogleCloudAiplatformV1ExplanationMetadataOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1ExplanationMetadata) GoogleCloudAiplatformV1ExplanationMetadata {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1ExplanationMetadata
		return ret
	}).(GoogleCloudAiplatformV1ExplanationMetadataOutput)
}

// Points to a YAML file stored on Google Cloud Storage describing the format of the feature attributions. The schema is defined as an OpenAPI 3.0.2 [Schema Object](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject). AutoML tabular Models always have this field populated by Vertex AI. Note: The URI given on output may be different, including the URI scheme, than the one given on input. The output URI will point to a location where the user only has a read access.
func (o GoogleCloudAiplatformV1ExplanationMetadataPtrOutput) FeatureAttributionsSchemaUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1ExplanationMetadata) *string {
		if v == nil {
			return nil
		}
		return v.FeatureAttributionsSchemaUri
	}).(pulumi.StringPtrOutput)
}

// Map from feature names to feature input metadata. Keys are the name of the features. Values are the specification of the feature. An empty InputMetadata is valid. It describes a text feature which has the name specified as the key in ExplanationMetadata.inputs. The baseline of the empty feature is chosen by Vertex AI. For Vertex AI-provided Tensorflow images, the key can be any friendly name of the feature. Once specified, featureAttributions are keyed by this key (if not grouped with another feature). For custom images, the key must match with the key in instance.
func (o GoogleCloudAiplatformV1ExplanationMetadataPtrOutput) Inputs() GoogleCloudAiplatformV1ExplanationMetadataInputMetadataMapOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1ExplanationMetadata) map[string]GoogleCloudAiplatformV1ExplanationMetadataInputMetadata {
		if v == nil {
			return nil
		}
		return v.Inputs
	}).(GoogleCloudAiplatformV1ExplanationMetadataInputMetadataMapOutput)
}

// Name of the source to generate embeddings for example based explanations.
func (o GoogleCloudAiplatformV1ExplanationMetadataPtrOutput) LatentSpaceSource() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1ExplanationMetadata) *string {
		if v == nil {
			return nil
		}
		return v.LatentSpaceSource
	}).(pulumi.StringPtrOutput)
}

// Map from output names to output metadata. For Vertex AI-provided Tensorflow images, keys can be any user defined string that consists of any UTF-8 characters. For custom images, keys are the name of the output field in the prediction to be explained. Currently only one key is allowed.
func (o GoogleCloudAiplatformV1ExplanationMetadataPtrOutput) Outputs() GoogleCloudAiplatformV1ExplanationMetadataOutputMetadataMapOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1ExplanationMetadata) map[string]GoogleCloudAiplatformV1ExplanationMetadataOutputMetadata {
		if v == nil {
			return nil
		}
		return v.Outputs
	}).(GoogleCloudAiplatformV1ExplanationMetadataOutputMetadataMapOutput)
}

// Metadata of the input of a feature. Fields other than InputMetadata.input_baselines are applicable only for Models that are using Vertex AI-provided images for Tensorflow.
type GoogleCloudAiplatformV1ExplanationMetadataInputMetadata struct {
	// Specifies the shape of the values of the input if the input is a sparse representation. Refer to Tensorflow documentation for more details: https://www.tensorflow.org/api_docs/python/tf/sparse/SparseTensor.
	DenseShapeTensorName *string `pulumi:"denseShapeTensorName"`
	// A list of baselines for the encoded tensor. The shape of each baseline should match the shape of the encoded tensor. If a scalar is provided, Vertex AI broadcasts to the same shape as the encoded tensor.
	EncodedBaselines []interface{} `pulumi:"encodedBaselines"`
	// Encoded tensor is a transformation of the input tensor. Must be provided if choosing Integrated Gradients attribution or XRAI attribution and the input tensor is not differentiable. An encoded tensor is generated if the input tensor is encoded by a lookup table.
	EncodedTensorName *string `pulumi:"encodedTensorName"`
	// Defines how the feature is encoded into the input tensor. Defaults to IDENTITY.
	Encoding *GoogleCloudAiplatformV1ExplanationMetadataInputMetadataEncoding `pulumi:"encoding"`
	// The domain details of the input feature value. Like min/max, original mean or standard deviation if normalized.
	FeatureValueDomain *GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomain `pulumi:"featureValueDomain"`
	// Name of the group that the input belongs to. Features with the same group name will be treated as one feature when computing attributions. Features grouped together can have different shapes in value. If provided, there will be one single attribution generated in Attribution.feature_attributions, keyed by the group name.
	GroupName *string `pulumi:"groupName"`
	// A list of feature names for each index in the input tensor. Required when the input InputMetadata.encoding is BAG_OF_FEATURES, BAG_OF_FEATURES_SPARSE, INDICATOR.
	IndexFeatureMapping []string `pulumi:"indexFeatureMapping"`
	// Specifies the index of the values of the input tensor. Required when the input tensor is a sparse representation. Refer to Tensorflow documentation for more details: https://www.tensorflow.org/api_docs/python/tf/sparse/SparseTensor.
	IndicesTensorName *string `pulumi:"indicesTensorName"`
	// Baseline inputs for this feature. If no baseline is specified, Vertex AI chooses the baseline for this feature. If multiple baselines are specified, Vertex AI returns the average attributions across them in Attribution.feature_attributions. For Vertex AI-provided Tensorflow images (both 1.x and 2.x), the shape of each baseline must match the shape of the input tensor. If a scalar is provided, we broadcast to the same shape as the input tensor. For custom images, the element of the baselines must be in the same format as the feature's input in the instance[]. The schema of any single instance may be specified via Endpoint's DeployedModels' Model's PredictSchemata's instance_schema_uri.
	InputBaselines []interface{} `pulumi:"inputBaselines"`
	// Name of the input tensor for this feature. Required and is only applicable to Vertex AI-provided images for Tensorflow.
	InputTensorName *string `pulumi:"inputTensorName"`
	// Modality of the feature. Valid values are: numeric, image. Defaults to numeric.
	Modality *string `pulumi:"modality"`
	// Visualization configurations for image explanation.
	Visualization *GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualization `pulumi:"visualization"`
}

// GoogleCloudAiplatformV1ExplanationMetadataInputMetadataInput is an input type that accepts GoogleCloudAiplatformV1ExplanationMetadataInputMetadataArgs and GoogleCloudAiplatformV1ExplanationMetadataInputMetadataOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1ExplanationMetadataInputMetadataInput` via:
//
//	GoogleCloudAiplatformV1ExplanationMetadataInputMetadataArgs{...}
type GoogleCloudAiplatformV1ExplanationMetadataInputMetadataInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1ExplanationMetadataInputMetadataOutput() GoogleCloudAiplatformV1ExplanationMetadataInputMetadataOutput
	ToGoogleCloudAiplatformV1ExplanationMetadataInputMetadataOutputWithContext(context.Context) GoogleCloudAiplatformV1ExplanationMetadataInputMetadataOutput
}

// Metadata of the input of a feature. Fields other than InputMetadata.input_baselines are applicable only for Models that are using Vertex AI-provided images for Tensorflow.
type GoogleCloudAiplatformV1ExplanationMetadataInputMetadataArgs struct {
	// Specifies the shape of the values of the input if the input is a sparse representation. Refer to Tensorflow documentation for more details: https://www.tensorflow.org/api_docs/python/tf/sparse/SparseTensor.
	DenseShapeTensorName pulumi.StringPtrInput `pulumi:"denseShapeTensorName"`
	// A list of baselines for the encoded tensor. The shape of each baseline should match the shape of the encoded tensor. If a scalar is provided, Vertex AI broadcasts to the same shape as the encoded tensor.
	EncodedBaselines pulumi.ArrayInput `pulumi:"encodedBaselines"`
	// Encoded tensor is a transformation of the input tensor. Must be provided if choosing Integrated Gradients attribution or XRAI attribution and the input tensor is not differentiable. An encoded tensor is generated if the input tensor is encoded by a lookup table.
	EncodedTensorName pulumi.StringPtrInput `pulumi:"encodedTensorName"`
	// Defines how the feature is encoded into the input tensor. Defaults to IDENTITY.
	Encoding GoogleCloudAiplatformV1ExplanationMetadataInputMetadataEncodingPtrInput `pulumi:"encoding"`
	// The domain details of the input feature value. Like min/max, original mean or standard deviation if normalized.
	FeatureValueDomain GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainPtrInput `pulumi:"featureValueDomain"`
	// Name of the group that the input belongs to. Features with the same group name will be treated as one feature when computing attributions. Features grouped together can have different shapes in value. If provided, there will be one single attribution generated in Attribution.feature_attributions, keyed by the group name.
	GroupName pulumi.StringPtrInput `pulumi:"groupName"`
	// A list of feature names for each index in the input tensor. Required when the input InputMetadata.encoding is BAG_OF_FEATURES, BAG_OF_FEATURES_SPARSE, INDICATOR.
	IndexFeatureMapping pulumi.StringArrayInput `pulumi:"indexFeatureMapping"`
	// Specifies the index of the values of the input tensor. Required when the input tensor is a sparse representation. Refer to Tensorflow documentation for more details: https://www.tensorflow.org/api_docs/python/tf/sparse/SparseTensor.
	IndicesTensorName pulumi.StringPtrInput `pulumi:"indicesTensorName"`
	// Baseline inputs for this feature. If no baseline is specified, Vertex AI chooses the baseline for this feature. If multiple baselines are specified, Vertex AI returns the average attributions across them in Attribution.feature_attributions. For Vertex AI-provided Tensorflow images (both 1.x and 2.x), the shape of each baseline must match the shape of the input tensor. If a scalar is provided, we broadcast to the same shape as the input tensor. For custom images, the element of the baselines must be in the same format as the feature's input in the instance[]. The schema of any single instance may be specified via Endpoint's DeployedModels' Model's PredictSchemata's instance_schema_uri.
	InputBaselines pulumi.ArrayInput `pulumi:"inputBaselines"`
	// Name of the input tensor for this feature. Required and is only applicable to Vertex AI-provided images for Tensorflow.
	InputTensorName pulumi.StringPtrInput `pulumi:"inputTensorName"`
	// Modality of the feature. Valid values are: numeric, image. Defaults to numeric.
	Modality pulumi.StringPtrInput `pulumi:"modality"`
	// Visualization configurations for image explanation.
	Visualization GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationPtrInput `pulumi:"visualization"`
}

func (GoogleCloudAiplatformV1ExplanationMetadataInputMetadataArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1ExplanationMetadataInputMetadata)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1ExplanationMetadataInputMetadataArgs) ToGoogleCloudAiplatformV1ExplanationMetadataInputMetadataOutput() GoogleCloudAiplatformV1ExplanationMetadataInputMetadataOutput {
	return i.ToGoogleCloudAiplatformV1ExplanationMetadataInputMetadataOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1ExplanationMetadataInputMetadataArgs) ToGoogleCloudAiplatformV1ExplanationMetadataInputMetadataOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ExplanationMetadataInputMetadataOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1ExplanationMetadataInputMetadataOutput)
}

// GoogleCloudAiplatformV1ExplanationMetadataInputMetadataMapInput is an input type that accepts GoogleCloudAiplatformV1ExplanationMetadataInputMetadataMap and GoogleCloudAiplatformV1ExplanationMetadataInputMetadataMapOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1ExplanationMetadataInputMetadataMapInput` via:
//
//	GoogleCloudAiplatformV1ExplanationMetadataInputMetadataMap{ "key": GoogleCloudAiplatformV1ExplanationMetadataInputMetadataArgs{...} }
type GoogleCloudAiplatformV1ExplanationMetadataInputMetadataMapInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1ExplanationMetadataInputMetadataMapOutput() GoogleCloudAiplatformV1ExplanationMetadataInputMetadataMapOutput
	ToGoogleCloudAiplatformV1ExplanationMetadataInputMetadataMapOutputWithContext(context.Context) GoogleCloudAiplatformV1ExplanationMetadataInputMetadataMapOutput
}

type GoogleCloudAiplatformV1ExplanationMetadataInputMetadataMap map[string]GoogleCloudAiplatformV1ExplanationMetadataInputMetadataInput

func (GoogleCloudAiplatformV1ExplanationMetadataInputMetadataMap) ElementType() reflect.Type {
	return reflect.TypeOf((*map[string]GoogleCloudAiplatformV1ExplanationMetadataInputMetadata)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1ExplanationMetadataInputMetadataMap) ToGoogleCloudAiplatformV1ExplanationMetadataInputMetadataMapOutput() GoogleCloudAiplatformV1ExplanationMetadataInputMetadataMapOutput {
	return i.ToGoogleCloudAiplatformV1ExplanationMetadataInputMetadataMapOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1ExplanationMetadataInputMetadataMap) ToGoogleCloudAiplatformV1ExplanationMetadataInputMetadataMapOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ExplanationMetadataInputMetadataMapOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1ExplanationMetadataInputMetadataMapOutput)
}

// Metadata of the input of a feature. Fields other than InputMetadata.input_baselines are applicable only for Models that are using Vertex AI-provided images for Tensorflow.
type GoogleCloudAiplatformV1ExplanationMetadataInputMetadataOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ExplanationMetadataInputMetadataOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1ExplanationMetadataInputMetadata)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ExplanationMetadataInputMetadataOutput) ToGoogleCloudAiplatformV1ExplanationMetadataInputMetadataOutput() GoogleCloudAiplatformV1ExplanationMetadataInputMetadataOutput {
	return o
}

func (o GoogleCloudAiplatformV1ExplanationMetadataInputMetadataOutput) ToGoogleCloudAiplatformV1ExplanationMetadataInputMetadataOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ExplanationMetadataInputMetadataOutput {
	return o
}

// Specifies the shape of the values of the input if the input is a sparse representation. Refer to Tensorflow documentation for more details: https://www.tensorflow.org/api_docs/python/tf/sparse/SparseTensor.
func (o GoogleCloudAiplatformV1ExplanationMetadataInputMetadataOutput) DenseShapeTensorName() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ExplanationMetadataInputMetadata) *string { return v.DenseShapeTensorName }).(pulumi.StringPtrOutput)
}

// A list of baselines for the encoded tensor. The shape of each baseline should match the shape of the encoded tensor. If a scalar is provided, Vertex AI broadcasts to the same shape as the encoded tensor.
func (o GoogleCloudAiplatformV1ExplanationMetadataInputMetadataOutput) EncodedBaselines() pulumi.ArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ExplanationMetadataInputMetadata) []interface{} {
		return v.EncodedBaselines
	}).(pulumi.ArrayOutput)
}

// Encoded tensor is a transformation of the input tensor. Must be provided if choosing Integrated Gradients attribution or XRAI attribution and the input tensor is not differentiable. An encoded tensor is generated if the input tensor is encoded by a lookup table.
func (o GoogleCloudAiplatformV1ExplanationMetadataInputMetadataOutput) EncodedTensorName() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ExplanationMetadataInputMetadata) *string { return v.EncodedTensorName }).(pulumi.StringPtrOutput)
}

// Defines how the feature is encoded into the input tensor. Defaults to IDENTITY.
func (o GoogleCloudAiplatformV1ExplanationMetadataInputMetadataOutput) Encoding() GoogleCloudAiplatformV1ExplanationMetadataInputMetadataEncodingPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ExplanationMetadataInputMetadata) *GoogleCloudAiplatformV1ExplanationMetadataInputMetadataEncoding {
		return v.Encoding
	}).(GoogleCloudAiplatformV1ExplanationMetadataInputMetadataEncodingPtrOutput)
}

// The domain details of the input feature value. Like min/max, original mean or standard deviation if normalized.
func (o GoogleCloudAiplatformV1ExplanationMetadataInputMetadataOutput) FeatureValueDomain() GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ExplanationMetadataInputMetadata) *GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomain {
		return v.FeatureValueDomain
	}).(GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainPtrOutput)
}

// Name of the group that the input belongs to. Features with the same group name will be treated as one feature when computing attributions. Features grouped together can have different shapes in value. If provided, there will be one single attribution generated in Attribution.feature_attributions, keyed by the group name.
func (o GoogleCloudAiplatformV1ExplanationMetadataInputMetadataOutput) GroupName() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ExplanationMetadataInputMetadata) *string { return v.GroupName }).(pulumi.StringPtrOutput)
}

// A list of feature names for each index in the input tensor. Required when the input InputMetadata.encoding is BAG_OF_FEATURES, BAG_OF_FEATURES_SPARSE, INDICATOR.
func (o GoogleCloudAiplatformV1ExplanationMetadataInputMetadataOutput) IndexFeatureMapping() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ExplanationMetadataInputMetadata) []string { return v.IndexFeatureMapping }).(pulumi.StringArrayOutput)
}

// Specifies the index of the values of the input tensor. Required when the input tensor is a sparse representation. Refer to Tensorflow documentation for more details: https://www.tensorflow.org/api_docs/python/tf/sparse/SparseTensor.
func (o GoogleCloudAiplatformV1ExplanationMetadataInputMetadataOutput) IndicesTensorName() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ExplanationMetadataInputMetadata) *string { return v.IndicesTensorName }).(pulumi.StringPtrOutput)
}

// Baseline inputs for this feature. If no baseline is specified, Vertex AI chooses the baseline for this feature. If multiple baselines are specified, Vertex AI returns the average attributions across them in Attribution.feature_attributions. For Vertex AI-provided Tensorflow images (both 1.x and 2.x), the shape of each baseline must match the shape of the input tensor. If a scalar is provided, we broadcast to the same shape as the input tensor. For custom images, the element of the baselines must be in the same format as the feature's input in the instance[]. The schema of any single instance may be specified via Endpoint's DeployedModels' Model's PredictSchemata's instance_schema_uri.
func (o GoogleCloudAiplatformV1ExplanationMetadataInputMetadataOutput) InputBaselines() pulumi.ArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ExplanationMetadataInputMetadata) []interface{} { return v.InputBaselines }).(pulumi.ArrayOutput)
}

// Name of the input tensor for this feature. Required and is only applicable to Vertex AI-provided images for Tensorflow.
func (o GoogleCloudAiplatformV1ExplanationMetadataInputMetadataOutput) InputTensorName() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ExplanationMetadataInputMetadata) *string { return v.InputTensorName }).(pulumi.StringPtrOutput)
}

// Modality of the feature. Valid values are: numeric, image. Defaults to numeric.
func (o GoogleCloudAiplatformV1ExplanationMetadataInputMetadataOutput) Modality() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ExplanationMetadataInputMetadata) *string { return v.Modality }).(pulumi.StringPtrOutput)
}

// Visualization configurations for image explanation.
func (o GoogleCloudAiplatformV1ExplanationMetadataInputMetadataOutput) Visualization() GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ExplanationMetadataInputMetadata) *GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualization {
		return v.Visualization
	}).(GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationPtrOutput)
}

type GoogleCloudAiplatformV1ExplanationMetadataInputMetadataMapOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ExplanationMetadataInputMetadataMapOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*map[string]GoogleCloudAiplatformV1ExplanationMetadataInputMetadata)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ExplanationMetadataInputMetadataMapOutput) ToGoogleCloudAiplatformV1ExplanationMetadataInputMetadataMapOutput() GoogleCloudAiplatformV1ExplanationMetadataInputMetadataMapOutput {
	return o
}

func (o GoogleCloudAiplatformV1ExplanationMetadataInputMetadataMapOutput) ToGoogleCloudAiplatformV1ExplanationMetadataInputMetadataMapOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ExplanationMetadataInputMetadataMapOutput {
	return o
}

func (o GoogleCloudAiplatformV1ExplanationMetadataInputMetadataMapOutput) MapIndex(k pulumi.StringInput) GoogleCloudAiplatformV1ExplanationMetadataInputMetadataOutput {
	return pulumi.All(o, k).ApplyT(func(vs []interface{}) GoogleCloudAiplatformV1ExplanationMetadataInputMetadata {
		return vs[0].(map[string]GoogleCloudAiplatformV1ExplanationMetadataInputMetadata)[vs[1].(string)]
	}).(GoogleCloudAiplatformV1ExplanationMetadataInputMetadataOutput)
}

// Domain details of the input feature value. Provides numeric information about the feature, such as its range (min, max). If the feature has been pre-processed, for example with z-scoring, then it provides information about how to recover the original feature. For example, if the input feature is an image and it has been pre-processed to obtain 0-mean and stddev = 1 values, then original_mean, and original_stddev refer to the mean and stddev of the original feature (e.g. image tensor) from which input feature (with mean = 0 and stddev = 1) was obtained.
type GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomain struct {
	// The maximum permissible value for this feature.
	MaxValue *float64 `pulumi:"maxValue"`
	// The minimum permissible value for this feature.
	MinValue *float64 `pulumi:"minValue"`
	// If this input feature has been normalized to a mean value of 0, the original_mean specifies the mean value of the domain prior to normalization.
	OriginalMean *float64 `pulumi:"originalMean"`
	// If this input feature has been normalized to a standard deviation of 1.0, the original_stddev specifies the standard deviation of the domain prior to normalization.
	OriginalStddev *float64 `pulumi:"originalStddev"`
}

// GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainInput is an input type that accepts GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainArgs and GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainInput` via:
//
//	GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainArgs{...}
type GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainOutput() GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainOutput
	ToGoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainOutputWithContext(context.Context) GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainOutput
}

// Domain details of the input feature value. Provides numeric information about the feature, such as its range (min, max). If the feature has been pre-processed, for example with z-scoring, then it provides information about how to recover the original feature. For example, if the input feature is an image and it has been pre-processed to obtain 0-mean and stddev = 1 values, then original_mean, and original_stddev refer to the mean and stddev of the original feature (e.g. image tensor) from which input feature (with mean = 0 and stddev = 1) was obtained.
type GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainArgs struct {
	// The maximum permissible value for this feature.
	MaxValue pulumi.Float64PtrInput `pulumi:"maxValue"`
	// The minimum permissible value for this feature.
	MinValue pulumi.Float64PtrInput `pulumi:"minValue"`
	// If this input feature has been normalized to a mean value of 0, the original_mean specifies the mean value of the domain prior to normalization.
	OriginalMean pulumi.Float64PtrInput `pulumi:"originalMean"`
	// If this input feature has been normalized to a standard deviation of 1.0, the original_stddev specifies the standard deviation of the domain prior to normalization.
	OriginalStddev pulumi.Float64PtrInput `pulumi:"originalStddev"`
}

func (GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomain)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainArgs) ToGoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainOutput() GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainOutput {
	return i.ToGoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainArgs) ToGoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainOutput)
}

func (i GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainArgs) ToGoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainPtrOutput() GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainPtrOutput {
	return i.ToGoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainArgs) ToGoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainOutput).ToGoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainPtrInput is an input type that accepts GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainArgs, GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainPtr and GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainPtrInput` via:
//
//	        GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainPtrOutput() GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainPtrOutput
	ToGoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainPtrOutput
}

type googleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainPtrType GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainArgs

func GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainPtr(v *GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainArgs) GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainPtrInput {
	return (*googleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainPtrType)(v)
}

func (*googleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomain)(nil)).Elem()
}

func (i *googleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainPtrType) ToGoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainPtrOutput() GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainPtrOutput {
	return i.ToGoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainPtrType) ToGoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainPtrOutput)
}

// Domain details of the input feature value. Provides numeric information about the feature, such as its range (min, max). If the feature has been pre-processed, for example with z-scoring, then it provides information about how to recover the original feature. For example, if the input feature is an image and it has been pre-processed to obtain 0-mean and stddev = 1 values, then original_mean, and original_stddev refer to the mean and stddev of the original feature (e.g. image tensor) from which input feature (with mean = 0 and stddev = 1) was obtained.
type GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomain)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainOutput) ToGoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainOutput() GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainOutput {
	return o
}

func (o GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainOutput) ToGoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainOutput {
	return o
}

func (o GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainOutput) ToGoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainPtrOutput() GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainPtrOutput {
	return o.ToGoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainOutput) ToGoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomain) *GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomain {
		return &v
	}).(GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainPtrOutput)
}

// The maximum permissible value for this feature.
func (o GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainOutput) MaxValue() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomain) *float64 {
		return v.MaxValue
	}).(pulumi.Float64PtrOutput)
}

// The minimum permissible value for this feature.
func (o GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainOutput) MinValue() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomain) *float64 {
		return v.MinValue
	}).(pulumi.Float64PtrOutput)
}

// If this input feature has been normalized to a mean value of 0, the original_mean specifies the mean value of the domain prior to normalization.
func (o GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainOutput) OriginalMean() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomain) *float64 {
		return v.OriginalMean
	}).(pulumi.Float64PtrOutput)
}

// If this input feature has been normalized to a standard deviation of 1.0, the original_stddev specifies the standard deviation of the domain prior to normalization.
func (o GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainOutput) OriginalStddev() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomain) *float64 {
		return v.OriginalStddev
	}).(pulumi.Float64PtrOutput)
}

type GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomain)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainPtrOutput) ToGoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainPtrOutput() GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainPtrOutput) ToGoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainPtrOutput) Elem() GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomain) GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomain {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomain
		return ret
	}).(GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainOutput)
}

// The maximum permissible value for this feature.
func (o GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainPtrOutput) MaxValue() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomain) *float64 {
		if v == nil {
			return nil
		}
		return v.MaxValue
	}).(pulumi.Float64PtrOutput)
}

// The minimum permissible value for this feature.
func (o GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainPtrOutput) MinValue() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomain) *float64 {
		if v == nil {
			return nil
		}
		return v.MinValue
	}).(pulumi.Float64PtrOutput)
}

// If this input feature has been normalized to a mean value of 0, the original_mean specifies the mean value of the domain prior to normalization.
func (o GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainPtrOutput) OriginalMean() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomain) *float64 {
		if v == nil {
			return nil
		}
		return v.OriginalMean
	}).(pulumi.Float64PtrOutput)
}

// If this input feature has been normalized to a standard deviation of 1.0, the original_stddev specifies the standard deviation of the domain prior to normalization.
func (o GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainPtrOutput) OriginalStddev() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomain) *float64 {
		if v == nil {
			return nil
		}
		return v.OriginalStddev
	}).(pulumi.Float64PtrOutput)
}

// Domain details of the input feature value. Provides numeric information about the feature, such as its range (min, max). If the feature has been pre-processed, for example with z-scoring, then it provides information about how to recover the original feature. For example, if the input feature is an image and it has been pre-processed to obtain 0-mean and stddev = 1 values, then original_mean, and original_stddev refer to the mean and stddev of the original feature (e.g. image tensor) from which input feature (with mean = 0 and stddev = 1) was obtained.
type GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainResponse struct {
	// The maximum permissible value for this feature.
	MaxValue float64 `pulumi:"maxValue"`
	// The minimum permissible value for this feature.
	MinValue float64 `pulumi:"minValue"`
	// If this input feature has been normalized to a mean value of 0, the original_mean specifies the mean value of the domain prior to normalization.
	OriginalMean float64 `pulumi:"originalMean"`
	// If this input feature has been normalized to a standard deviation of 1.0, the original_stddev specifies the standard deviation of the domain prior to normalization.
	OriginalStddev float64 `pulumi:"originalStddev"`
}

// Domain details of the input feature value. Provides numeric information about the feature, such as its range (min, max). If the feature has been pre-processed, for example with z-scoring, then it provides information about how to recover the original feature. For example, if the input feature is an image and it has been pre-processed to obtain 0-mean and stddev = 1 values, then original_mean, and original_stddev refer to the mean and stddev of the original feature (e.g. image tensor) from which input feature (with mean = 0 and stddev = 1) was obtained.
type GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainResponseOutput) ToGoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainResponseOutput() GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainResponseOutput) ToGoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainResponseOutput {
	return o
}

// The maximum permissible value for this feature.
func (o GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainResponseOutput) MaxValue() pulumi.Float64Output {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainResponse) float64 {
		return v.MaxValue
	}).(pulumi.Float64Output)
}

// The minimum permissible value for this feature.
func (o GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainResponseOutput) MinValue() pulumi.Float64Output {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainResponse) float64 {
		return v.MinValue
	}).(pulumi.Float64Output)
}

// If this input feature has been normalized to a mean value of 0, the original_mean specifies the mean value of the domain prior to normalization.
func (o GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainResponseOutput) OriginalMean() pulumi.Float64Output {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainResponse) float64 {
		return v.OriginalMean
	}).(pulumi.Float64Output)
}

// If this input feature has been normalized to a standard deviation of 1.0, the original_stddev specifies the standard deviation of the domain prior to normalization.
func (o GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainResponseOutput) OriginalStddev() pulumi.Float64Output {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainResponse) float64 {
		return v.OriginalStddev
	}).(pulumi.Float64Output)
}

// Metadata of the input of a feature. Fields other than InputMetadata.input_baselines are applicable only for Models that are using Vertex AI-provided images for Tensorflow.
type GoogleCloudAiplatformV1ExplanationMetadataInputMetadataResponse struct {
	// Specifies the shape of the values of the input if the input is a sparse representation. Refer to Tensorflow documentation for more details: https://www.tensorflow.org/api_docs/python/tf/sparse/SparseTensor.
	DenseShapeTensorName string `pulumi:"denseShapeTensorName"`
	// A list of baselines for the encoded tensor. The shape of each baseline should match the shape of the encoded tensor. If a scalar is provided, Vertex AI broadcasts to the same shape as the encoded tensor.
	EncodedBaselines []interface{} `pulumi:"encodedBaselines"`
	// Encoded tensor is a transformation of the input tensor. Must be provided if choosing Integrated Gradients attribution or XRAI attribution and the input tensor is not differentiable. An encoded tensor is generated if the input tensor is encoded by a lookup table.
	EncodedTensorName string `pulumi:"encodedTensorName"`
	// Defines how the feature is encoded into the input tensor. Defaults to IDENTITY.
	Encoding string `pulumi:"encoding"`
	// The domain details of the input feature value. Like min/max, original mean or standard deviation if normalized.
	FeatureValueDomain GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainResponse `pulumi:"featureValueDomain"`
	// Name of the group that the input belongs to. Features with the same group name will be treated as one feature when computing attributions. Features grouped together can have different shapes in value. If provided, there will be one single attribution generated in Attribution.feature_attributions, keyed by the group name.
	GroupName string `pulumi:"groupName"`
	// A list of feature names for each index in the input tensor. Required when the input InputMetadata.encoding is BAG_OF_FEATURES, BAG_OF_FEATURES_SPARSE, INDICATOR.
	IndexFeatureMapping []string `pulumi:"indexFeatureMapping"`
	// Specifies the index of the values of the input tensor. Required when the input tensor is a sparse representation. Refer to Tensorflow documentation for more details: https://www.tensorflow.org/api_docs/python/tf/sparse/SparseTensor.
	IndicesTensorName string `pulumi:"indicesTensorName"`
	// Baseline inputs for this feature. If no baseline is specified, Vertex AI chooses the baseline for this feature. If multiple baselines are specified, Vertex AI returns the average attributions across them in Attribution.feature_attributions. For Vertex AI-provided Tensorflow images (both 1.x and 2.x), the shape of each baseline must match the shape of the input tensor. If a scalar is provided, we broadcast to the same shape as the input tensor. For custom images, the element of the baselines must be in the same format as the feature's input in the instance[]. The schema of any single instance may be specified via Endpoint's DeployedModels' Model's PredictSchemata's instance_schema_uri.
	InputBaselines []interface{} `pulumi:"inputBaselines"`
	// Name of the input tensor for this feature. Required and is only applicable to Vertex AI-provided images for Tensorflow.
	InputTensorName string `pulumi:"inputTensorName"`
	// Modality of the feature. Valid values are: numeric, image. Defaults to numeric.
	Modality string `pulumi:"modality"`
	// Visualization configurations for image explanation.
	Visualization GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationResponse `pulumi:"visualization"`
}

// Metadata of the input of a feature. Fields other than InputMetadata.input_baselines are applicable only for Models that are using Vertex AI-provided images for Tensorflow.
type GoogleCloudAiplatformV1ExplanationMetadataInputMetadataResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ExplanationMetadataInputMetadataResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1ExplanationMetadataInputMetadataResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ExplanationMetadataInputMetadataResponseOutput) ToGoogleCloudAiplatformV1ExplanationMetadataInputMetadataResponseOutput() GoogleCloudAiplatformV1ExplanationMetadataInputMetadataResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1ExplanationMetadataInputMetadataResponseOutput) ToGoogleCloudAiplatformV1ExplanationMetadataInputMetadataResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ExplanationMetadataInputMetadataResponseOutput {
	return o
}

// Specifies the shape of the values of the input if the input is a sparse representation. Refer to Tensorflow documentation for more details: https://www.tensorflow.org/api_docs/python/tf/sparse/SparseTensor.
func (o GoogleCloudAiplatformV1ExplanationMetadataInputMetadataResponseOutput) DenseShapeTensorName() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ExplanationMetadataInputMetadataResponse) string {
		return v.DenseShapeTensorName
	}).(pulumi.StringOutput)
}

// A list of baselines for the encoded tensor. The shape of each baseline should match the shape of the encoded tensor. If a scalar is provided, Vertex AI broadcasts to the same shape as the encoded tensor.
func (o GoogleCloudAiplatformV1ExplanationMetadataInputMetadataResponseOutput) EncodedBaselines() pulumi.ArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ExplanationMetadataInputMetadataResponse) []interface{} {
		return v.EncodedBaselines
	}).(pulumi.ArrayOutput)
}

// Encoded tensor is a transformation of the input tensor. Must be provided if choosing Integrated Gradients attribution or XRAI attribution and the input tensor is not differentiable. An encoded tensor is generated if the input tensor is encoded by a lookup table.
func (o GoogleCloudAiplatformV1ExplanationMetadataInputMetadataResponseOutput) EncodedTensorName() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ExplanationMetadataInputMetadataResponse) string {
		return v.EncodedTensorName
	}).(pulumi.StringOutput)
}

// Defines how the feature is encoded into the input tensor. Defaults to IDENTITY.
func (o GoogleCloudAiplatformV1ExplanationMetadataInputMetadataResponseOutput) Encoding() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ExplanationMetadataInputMetadataResponse) string { return v.Encoding }).(pulumi.StringOutput)
}

// The domain details of the input feature value. Like min/max, original mean or standard deviation if normalized.
func (o GoogleCloudAiplatformV1ExplanationMetadataInputMetadataResponseOutput) FeatureValueDomain() GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ExplanationMetadataInputMetadataResponse) GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainResponse {
		return v.FeatureValueDomain
	}).(GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainResponseOutput)
}

// Name of the group that the input belongs to. Features with the same group name will be treated as one feature when computing attributions. Features grouped together can have different shapes in value. If provided, there will be one single attribution generated in Attribution.feature_attributions, keyed by the group name.
func (o GoogleCloudAiplatformV1ExplanationMetadataInputMetadataResponseOutput) GroupName() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ExplanationMetadataInputMetadataResponse) string { return v.GroupName }).(pulumi.StringOutput)
}

// A list of feature names for each index in the input tensor. Required when the input InputMetadata.encoding is BAG_OF_FEATURES, BAG_OF_FEATURES_SPARSE, INDICATOR.
func (o GoogleCloudAiplatformV1ExplanationMetadataInputMetadataResponseOutput) IndexFeatureMapping() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ExplanationMetadataInputMetadataResponse) []string {
		return v.IndexFeatureMapping
	}).(pulumi.StringArrayOutput)
}

// Specifies the index of the values of the input tensor. Required when the input tensor is a sparse representation. Refer to Tensorflow documentation for more details: https://www.tensorflow.org/api_docs/python/tf/sparse/SparseTensor.
func (o GoogleCloudAiplatformV1ExplanationMetadataInputMetadataResponseOutput) IndicesTensorName() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ExplanationMetadataInputMetadataResponse) string {
		return v.IndicesTensorName
	}).(pulumi.StringOutput)
}

// Baseline inputs for this feature. If no baseline is specified, Vertex AI chooses the baseline for this feature. If multiple baselines are specified, Vertex AI returns the average attributions across them in Attribution.feature_attributions. For Vertex AI-provided Tensorflow images (both 1.x and 2.x), the shape of each baseline must match the shape of the input tensor. If a scalar is provided, we broadcast to the same shape as the input tensor. For custom images, the element of the baselines must be in the same format as the feature's input in the instance[]. The schema of any single instance may be specified via Endpoint's DeployedModels' Model's PredictSchemata's instance_schema_uri.
func (o GoogleCloudAiplatformV1ExplanationMetadataInputMetadataResponseOutput) InputBaselines() pulumi.ArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ExplanationMetadataInputMetadataResponse) []interface{} {
		return v.InputBaselines
	}).(pulumi.ArrayOutput)
}

// Name of the input tensor for this feature. Required and is only applicable to Vertex AI-provided images for Tensorflow.
func (o GoogleCloudAiplatformV1ExplanationMetadataInputMetadataResponseOutput) InputTensorName() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ExplanationMetadataInputMetadataResponse) string {
		return v.InputTensorName
	}).(pulumi.StringOutput)
}

// Modality of the feature. Valid values are: numeric, image. Defaults to numeric.
func (o GoogleCloudAiplatformV1ExplanationMetadataInputMetadataResponseOutput) Modality() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ExplanationMetadataInputMetadataResponse) string { return v.Modality }).(pulumi.StringOutput)
}

// Visualization configurations for image explanation.
func (o GoogleCloudAiplatformV1ExplanationMetadataInputMetadataResponseOutput) Visualization() GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ExplanationMetadataInputMetadataResponse) GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationResponse {
		return v.Visualization
	}).(GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationResponseOutput)
}

type GoogleCloudAiplatformV1ExplanationMetadataInputMetadataResponseMapOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ExplanationMetadataInputMetadataResponseMapOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*map[string]GoogleCloudAiplatformV1ExplanationMetadataInputMetadataResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ExplanationMetadataInputMetadataResponseMapOutput) ToGoogleCloudAiplatformV1ExplanationMetadataInputMetadataResponseMapOutput() GoogleCloudAiplatformV1ExplanationMetadataInputMetadataResponseMapOutput {
	return o
}

func (o GoogleCloudAiplatformV1ExplanationMetadataInputMetadataResponseMapOutput) ToGoogleCloudAiplatformV1ExplanationMetadataInputMetadataResponseMapOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ExplanationMetadataInputMetadataResponseMapOutput {
	return o
}

func (o GoogleCloudAiplatformV1ExplanationMetadataInputMetadataResponseMapOutput) MapIndex(k pulumi.StringInput) GoogleCloudAiplatformV1ExplanationMetadataInputMetadataResponseOutput {
	return pulumi.All(o, k).ApplyT(func(vs []interface{}) GoogleCloudAiplatformV1ExplanationMetadataInputMetadataResponse {
		return vs[0].(map[string]GoogleCloudAiplatformV1ExplanationMetadataInputMetadataResponse)[vs[1].(string)]
	}).(GoogleCloudAiplatformV1ExplanationMetadataInputMetadataResponseOutput)
}

// Visualization configurations for image explanation.
type GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualization struct {
	// Excludes attributions below the specified percentile, from the highlighted areas. Defaults to 62.
	ClipPercentLowerbound *float64 `pulumi:"clipPercentLowerbound"`
	// Excludes attributions above the specified percentile from the highlighted areas. Using the clip_percent_upperbound and clip_percent_lowerbound together can be useful for filtering out noise and making it easier to see areas of strong attribution. Defaults to 99.9.
	ClipPercentUpperbound *float64 `pulumi:"clipPercentUpperbound"`
	// The color scheme used for the highlighted areas. Defaults to PINK_GREEN for Integrated Gradients attribution, which shows positive attributions in green and negative in pink. Defaults to VIRIDIS for XRAI attribution, which highlights the most influential regions in yellow and the least influential in blue.
	ColorMap *GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationColorMap `pulumi:"colorMap"`
	// How the original image is displayed in the visualization. Adjusting the overlay can help increase visual clarity if the original image makes it difficult to view the visualization. Defaults to NONE.
	OverlayType *GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationOverlayType `pulumi:"overlayType"`
	// Whether to only highlight pixels with positive contributions, negative or both. Defaults to POSITIVE.
	Polarity *GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationPolarity `pulumi:"polarity"`
	// Type of the image visualization. Only applicable to Integrated Gradients attribution. OUTLINES shows regions of attribution, while PIXELS shows per-pixel attribution. Defaults to OUTLINES.
	Type *GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationType `pulumi:"type"`
}

// GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationInput is an input type that accepts GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationArgs and GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationInput` via:
//
//	GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationArgs{...}
type GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationOutput() GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationOutput
	ToGoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationOutputWithContext(context.Context) GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationOutput
}

// Visualization configurations for image explanation.
type GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationArgs struct {
	// Excludes attributions below the specified percentile, from the highlighted areas. Defaults to 62.
	ClipPercentLowerbound pulumi.Float64PtrInput `pulumi:"clipPercentLowerbound"`
	// Excludes attributions above the specified percentile from the highlighted areas. Using the clip_percent_upperbound and clip_percent_lowerbound together can be useful for filtering out noise and making it easier to see areas of strong attribution. Defaults to 99.9.
	ClipPercentUpperbound pulumi.Float64PtrInput `pulumi:"clipPercentUpperbound"`
	// The color scheme used for the highlighted areas. Defaults to PINK_GREEN for Integrated Gradients attribution, which shows positive attributions in green and negative in pink. Defaults to VIRIDIS for XRAI attribution, which highlights the most influential regions in yellow and the least influential in blue.
	ColorMap GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationColorMapPtrInput `pulumi:"colorMap"`
	// How the original image is displayed in the visualization. Adjusting the overlay can help increase visual clarity if the original image makes it difficult to view the visualization. Defaults to NONE.
	OverlayType GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationOverlayTypePtrInput `pulumi:"overlayType"`
	// Whether to only highlight pixels with positive contributions, negative or both. Defaults to POSITIVE.
	Polarity GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationPolarityPtrInput `pulumi:"polarity"`
	// Type of the image visualization. Only applicable to Integrated Gradients attribution. OUTLINES shows regions of attribution, while PIXELS shows per-pixel attribution. Defaults to OUTLINES.
	Type GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationTypePtrInput `pulumi:"type"`
}

func (GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualization)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationArgs) ToGoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationOutput() GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationOutput {
	return i.ToGoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationArgs) ToGoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationOutput)
}

func (i GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationArgs) ToGoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationPtrOutput() GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationPtrOutput {
	return i.ToGoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationArgs) ToGoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationOutput).ToGoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationPtrInput is an input type that accepts GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationArgs, GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationPtr and GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationPtrInput` via:
//
//	        GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationPtrOutput() GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationPtrOutput
	ToGoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationPtrOutput
}

type googleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationPtrType GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationArgs

func GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationPtr(v *GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationArgs) GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationPtrInput {
	return (*googleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationPtrType)(v)
}

func (*googleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualization)(nil)).Elem()
}

func (i *googleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationPtrType) ToGoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationPtrOutput() GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationPtrOutput {
	return i.ToGoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationPtrType) ToGoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationPtrOutput)
}

// Visualization configurations for image explanation.
type GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualization)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationOutput) ToGoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationOutput() GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationOutput {
	return o
}

func (o GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationOutput) ToGoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationOutput {
	return o
}

func (o GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationOutput) ToGoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationPtrOutput() GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationPtrOutput {
	return o.ToGoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationOutput) ToGoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualization) *GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualization {
		return &v
	}).(GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationPtrOutput)
}

// Excludes attributions below the specified percentile, from the highlighted areas. Defaults to 62.
func (o GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationOutput) ClipPercentLowerbound() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualization) *float64 {
		return v.ClipPercentLowerbound
	}).(pulumi.Float64PtrOutput)
}

// Excludes attributions above the specified percentile from the highlighted areas. Using the clip_percent_upperbound and clip_percent_lowerbound together can be useful for filtering out noise and making it easier to see areas of strong attribution. Defaults to 99.9.
func (o GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationOutput) ClipPercentUpperbound() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualization) *float64 {
		return v.ClipPercentUpperbound
	}).(pulumi.Float64PtrOutput)
}

// The color scheme used for the highlighted areas. Defaults to PINK_GREEN for Integrated Gradients attribution, which shows positive attributions in green and negative in pink. Defaults to VIRIDIS for XRAI attribution, which highlights the most influential regions in yellow and the least influential in blue.
func (o GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationOutput) ColorMap() GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationColorMapPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualization) *GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationColorMap {
		return v.ColorMap
	}).(GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationColorMapPtrOutput)
}

// How the original image is displayed in the visualization. Adjusting the overlay can help increase visual clarity if the original image makes it difficult to view the visualization. Defaults to NONE.
func (o GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationOutput) OverlayType() GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationOverlayTypePtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualization) *GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationOverlayType {
		return v.OverlayType
	}).(GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationOverlayTypePtrOutput)
}

// Whether to only highlight pixels with positive contributions, negative or both. Defaults to POSITIVE.
func (o GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationOutput) Polarity() GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationPolarityPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualization) *GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationPolarity {
		return v.Polarity
	}).(GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationPolarityPtrOutput)
}

// Type of the image visualization. Only applicable to Integrated Gradients attribution. OUTLINES shows regions of attribution, while PIXELS shows per-pixel attribution. Defaults to OUTLINES.
func (o GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationOutput) Type() GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationTypePtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualization) *GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationType {
		return v.Type
	}).(GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationTypePtrOutput)
}

type GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualization)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationPtrOutput) ToGoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationPtrOutput() GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationPtrOutput) ToGoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationPtrOutput) Elem() GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualization) GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualization {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualization
		return ret
	}).(GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationOutput)
}

// Excludes attributions below the specified percentile, from the highlighted areas. Defaults to 62.
func (o GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationPtrOutput) ClipPercentLowerbound() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualization) *float64 {
		if v == nil {
			return nil
		}
		return v.ClipPercentLowerbound
	}).(pulumi.Float64PtrOutput)
}

// Excludes attributions above the specified percentile from the highlighted areas. Using the clip_percent_upperbound and clip_percent_lowerbound together can be useful for filtering out noise and making it easier to see areas of strong attribution. Defaults to 99.9.
func (o GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationPtrOutput) ClipPercentUpperbound() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualization) *float64 {
		if v == nil {
			return nil
		}
		return v.ClipPercentUpperbound
	}).(pulumi.Float64PtrOutput)
}

// The color scheme used for the highlighted areas. Defaults to PINK_GREEN for Integrated Gradients attribution, which shows positive attributions in green and negative in pink. Defaults to VIRIDIS for XRAI attribution, which highlights the most influential regions in yellow and the least influential in blue.
func (o GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationPtrOutput) ColorMap() GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationColorMapPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualization) *GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationColorMap {
		if v == nil {
			return nil
		}
		return v.ColorMap
	}).(GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationColorMapPtrOutput)
}

// How the original image is displayed in the visualization. Adjusting the overlay can help increase visual clarity if the original image makes it difficult to view the visualization. Defaults to NONE.
func (o GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationPtrOutput) OverlayType() GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationOverlayTypePtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualization) *GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationOverlayType {
		if v == nil {
			return nil
		}
		return v.OverlayType
	}).(GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationOverlayTypePtrOutput)
}

// Whether to only highlight pixels with positive contributions, negative or both. Defaults to POSITIVE.
func (o GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationPtrOutput) Polarity() GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationPolarityPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualization) *GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationPolarity {
		if v == nil {
			return nil
		}
		return v.Polarity
	}).(GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationPolarityPtrOutput)
}

// Type of the image visualization. Only applicable to Integrated Gradients attribution. OUTLINES shows regions of attribution, while PIXELS shows per-pixel attribution. Defaults to OUTLINES.
func (o GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationPtrOutput) Type() GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationTypePtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualization) *GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationType {
		if v == nil {
			return nil
		}
		return v.Type
	}).(GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationTypePtrOutput)
}

// Visualization configurations for image explanation.
type GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationResponse struct {
	// Excludes attributions below the specified percentile, from the highlighted areas. Defaults to 62.
	ClipPercentLowerbound float64 `pulumi:"clipPercentLowerbound"`
	// Excludes attributions above the specified percentile from the highlighted areas. Using the clip_percent_upperbound and clip_percent_lowerbound together can be useful for filtering out noise and making it easier to see areas of strong attribution. Defaults to 99.9.
	ClipPercentUpperbound float64 `pulumi:"clipPercentUpperbound"`
	// The color scheme used for the highlighted areas. Defaults to PINK_GREEN for Integrated Gradients attribution, which shows positive attributions in green and negative in pink. Defaults to VIRIDIS for XRAI attribution, which highlights the most influential regions in yellow and the least influential in blue.
	ColorMap string `pulumi:"colorMap"`
	// How the original image is displayed in the visualization. Adjusting the overlay can help increase visual clarity if the original image makes it difficult to view the visualization. Defaults to NONE.
	OverlayType string `pulumi:"overlayType"`
	// Whether to only highlight pixels with positive contributions, negative or both. Defaults to POSITIVE.
	Polarity string `pulumi:"polarity"`
	// Type of the image visualization. Only applicable to Integrated Gradients attribution. OUTLINES shows regions of attribution, while PIXELS shows per-pixel attribution. Defaults to OUTLINES.
	Type string `pulumi:"type"`
}

// Visualization configurations for image explanation.
type GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationResponseOutput) ToGoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationResponseOutput() GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationResponseOutput) ToGoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationResponseOutput {
	return o
}

// Excludes attributions below the specified percentile, from the highlighted areas. Defaults to 62.
func (o GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationResponseOutput) ClipPercentLowerbound() pulumi.Float64Output {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationResponse) float64 {
		return v.ClipPercentLowerbound
	}).(pulumi.Float64Output)
}

// Excludes attributions above the specified percentile from the highlighted areas. Using the clip_percent_upperbound and clip_percent_lowerbound together can be useful for filtering out noise and making it easier to see areas of strong attribution. Defaults to 99.9.
func (o GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationResponseOutput) ClipPercentUpperbound() pulumi.Float64Output {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationResponse) float64 {
		return v.ClipPercentUpperbound
	}).(pulumi.Float64Output)
}

// The color scheme used for the highlighted areas. Defaults to PINK_GREEN for Integrated Gradients attribution, which shows positive attributions in green and negative in pink. Defaults to VIRIDIS for XRAI attribution, which highlights the most influential regions in yellow and the least influential in blue.
func (o GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationResponseOutput) ColorMap() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationResponse) string {
		return v.ColorMap
	}).(pulumi.StringOutput)
}

// How the original image is displayed in the visualization. Adjusting the overlay can help increase visual clarity if the original image makes it difficult to view the visualization. Defaults to NONE.
func (o GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationResponseOutput) OverlayType() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationResponse) string {
		return v.OverlayType
	}).(pulumi.StringOutput)
}

// Whether to only highlight pixels with positive contributions, negative or both. Defaults to POSITIVE.
func (o GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationResponseOutput) Polarity() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationResponse) string {
		return v.Polarity
	}).(pulumi.StringOutput)
}

// Type of the image visualization. Only applicable to Integrated Gradients attribution. OUTLINES shows regions of attribution, while PIXELS shows per-pixel attribution. Defaults to OUTLINES.
func (o GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationResponseOutput) Type() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationResponse) string {
		return v.Type
	}).(pulumi.StringOutput)
}

// Metadata of the prediction output to be explained.
type GoogleCloudAiplatformV1ExplanationMetadataOutputMetadata struct {
	// Specify a field name in the prediction to look for the display name. Use this if the prediction contains the display names for the outputs. The display names in the prediction must have the same shape of the outputs, so that it can be located by Attribution.output_index for a specific output.
	DisplayNameMappingKey *string `pulumi:"displayNameMappingKey"`
	// Static mapping between the index and display name. Use this if the outputs are a deterministic n-dimensional array, e.g. a list of scores of all the classes in a pre-defined order for a multi-classification Model. It's not feasible if the outputs are non-deterministic, e.g. the Model produces top-k classes or sort the outputs by their values. The shape of the value must be an n-dimensional array of strings. The number of dimensions must match that of the outputs to be explained. The Attribution.output_display_name is populated by locating in the mapping with Attribution.output_index.
	IndexDisplayNameMapping interface{} `pulumi:"indexDisplayNameMapping"`
	// Name of the output tensor. Required and is only applicable to Vertex AI provided images for Tensorflow.
	OutputTensorName *string `pulumi:"outputTensorName"`
}

// GoogleCloudAiplatformV1ExplanationMetadataOutputMetadataInput is an input type that accepts GoogleCloudAiplatformV1ExplanationMetadataOutputMetadataArgs and GoogleCloudAiplatformV1ExplanationMetadataOutputMetadataOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1ExplanationMetadataOutputMetadataInput` via:
//
//	GoogleCloudAiplatformV1ExplanationMetadataOutputMetadataArgs{...}
type GoogleCloudAiplatformV1ExplanationMetadataOutputMetadataInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1ExplanationMetadataOutputMetadataOutput() GoogleCloudAiplatformV1ExplanationMetadataOutputMetadataOutput
	ToGoogleCloudAiplatformV1ExplanationMetadataOutputMetadataOutputWithContext(context.Context) GoogleCloudAiplatformV1ExplanationMetadataOutputMetadataOutput
}

// Metadata of the prediction output to be explained.
type GoogleCloudAiplatformV1ExplanationMetadataOutputMetadataArgs struct {
	// Specify a field name in the prediction to look for the display name. Use this if the prediction contains the display names for the outputs. The display names in the prediction must have the same shape of the outputs, so that it can be located by Attribution.output_index for a specific output.
	DisplayNameMappingKey pulumi.StringPtrInput `pulumi:"displayNameMappingKey"`
	// Static mapping between the index and display name. Use this if the outputs are a deterministic n-dimensional array, e.g. a list of scores of all the classes in a pre-defined order for a multi-classification Model. It's not feasible if the outputs are non-deterministic, e.g. the Model produces top-k classes or sort the outputs by their values. The shape of the value must be an n-dimensional array of strings. The number of dimensions must match that of the outputs to be explained. The Attribution.output_display_name is populated by locating in the mapping with Attribution.output_index.
	IndexDisplayNameMapping pulumi.Input `pulumi:"indexDisplayNameMapping"`
	// Name of the output tensor. Required and is only applicable to Vertex AI provided images for Tensorflow.
	OutputTensorName pulumi.StringPtrInput `pulumi:"outputTensorName"`
}

func (GoogleCloudAiplatformV1ExplanationMetadataOutputMetadataArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1ExplanationMetadataOutputMetadata)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1ExplanationMetadataOutputMetadataArgs) ToGoogleCloudAiplatformV1ExplanationMetadataOutputMetadataOutput() GoogleCloudAiplatformV1ExplanationMetadataOutputMetadataOutput {
	return i.ToGoogleCloudAiplatformV1ExplanationMetadataOutputMetadataOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1ExplanationMetadataOutputMetadataArgs) ToGoogleCloudAiplatformV1ExplanationMetadataOutputMetadataOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ExplanationMetadataOutputMetadataOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1ExplanationMetadataOutputMetadataOutput)
}

// GoogleCloudAiplatformV1ExplanationMetadataOutputMetadataMapInput is an input type that accepts GoogleCloudAiplatformV1ExplanationMetadataOutputMetadataMap and GoogleCloudAiplatformV1ExplanationMetadataOutputMetadataMapOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1ExplanationMetadataOutputMetadataMapInput` via:
//
//	GoogleCloudAiplatformV1ExplanationMetadataOutputMetadataMap{ "key": GoogleCloudAiplatformV1ExplanationMetadataOutputMetadataArgs{...} }
type GoogleCloudAiplatformV1ExplanationMetadataOutputMetadataMapInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1ExplanationMetadataOutputMetadataMapOutput() GoogleCloudAiplatformV1ExplanationMetadataOutputMetadataMapOutput
	ToGoogleCloudAiplatformV1ExplanationMetadataOutputMetadataMapOutputWithContext(context.Context) GoogleCloudAiplatformV1ExplanationMetadataOutputMetadataMapOutput
}

type GoogleCloudAiplatformV1ExplanationMetadataOutputMetadataMap map[string]GoogleCloudAiplatformV1ExplanationMetadataOutputMetadataInput

func (GoogleCloudAiplatformV1ExplanationMetadataOutputMetadataMap) ElementType() reflect.Type {
	return reflect.TypeOf((*map[string]GoogleCloudAiplatformV1ExplanationMetadataOutputMetadata)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1ExplanationMetadataOutputMetadataMap) ToGoogleCloudAiplatformV1ExplanationMetadataOutputMetadataMapOutput() GoogleCloudAiplatformV1ExplanationMetadataOutputMetadataMapOutput {
	return i.ToGoogleCloudAiplatformV1ExplanationMetadataOutputMetadataMapOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1ExplanationMetadataOutputMetadataMap) ToGoogleCloudAiplatformV1ExplanationMetadataOutputMetadataMapOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ExplanationMetadataOutputMetadataMapOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1ExplanationMetadataOutputMetadataMapOutput)
}

// Metadata of the prediction output to be explained.
type GoogleCloudAiplatformV1ExplanationMetadataOutputMetadataOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ExplanationMetadataOutputMetadataOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1ExplanationMetadataOutputMetadata)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ExplanationMetadataOutputMetadataOutput) ToGoogleCloudAiplatformV1ExplanationMetadataOutputMetadataOutput() GoogleCloudAiplatformV1ExplanationMetadataOutputMetadataOutput {
	return o
}

func (o GoogleCloudAiplatformV1ExplanationMetadataOutputMetadataOutput) ToGoogleCloudAiplatformV1ExplanationMetadataOutputMetadataOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ExplanationMetadataOutputMetadataOutput {
	return o
}

// Specify a field name in the prediction to look for the display name. Use this if the prediction contains the display names for the outputs. The display names in the prediction must have the same shape of the outputs, so that it can be located by Attribution.output_index for a specific output.
func (o GoogleCloudAiplatformV1ExplanationMetadataOutputMetadataOutput) DisplayNameMappingKey() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ExplanationMetadataOutputMetadata) *string {
		return v.DisplayNameMappingKey
	}).(pulumi.StringPtrOutput)
}

// Static mapping between the index and display name. Use this if the outputs are a deterministic n-dimensional array, e.g. a list of scores of all the classes in a pre-defined order for a multi-classification Model. It's not feasible if the outputs are non-deterministic, e.g. the Model produces top-k classes or sort the outputs by their values. The shape of the value must be an n-dimensional array of strings. The number of dimensions must match that of the outputs to be explained. The Attribution.output_display_name is populated by locating in the mapping with Attribution.output_index.
func (o GoogleCloudAiplatformV1ExplanationMetadataOutputMetadataOutput) IndexDisplayNameMapping() pulumi.AnyOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ExplanationMetadataOutputMetadata) interface{} {
		return v.IndexDisplayNameMapping
	}).(pulumi.AnyOutput)
}

// Name of the output tensor. Required and is only applicable to Vertex AI provided images for Tensorflow.
func (o GoogleCloudAiplatformV1ExplanationMetadataOutputMetadataOutput) OutputTensorName() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ExplanationMetadataOutputMetadata) *string { return v.OutputTensorName }).(pulumi.StringPtrOutput)
}

type GoogleCloudAiplatformV1ExplanationMetadataOutputMetadataMapOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ExplanationMetadataOutputMetadataMapOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*map[string]GoogleCloudAiplatformV1ExplanationMetadataOutputMetadata)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ExplanationMetadataOutputMetadataMapOutput) ToGoogleCloudAiplatformV1ExplanationMetadataOutputMetadataMapOutput() GoogleCloudAiplatformV1ExplanationMetadataOutputMetadataMapOutput {
	return o
}

func (o GoogleCloudAiplatformV1ExplanationMetadataOutputMetadataMapOutput) ToGoogleCloudAiplatformV1ExplanationMetadataOutputMetadataMapOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ExplanationMetadataOutputMetadataMapOutput {
	return o
}

func (o GoogleCloudAiplatformV1ExplanationMetadataOutputMetadataMapOutput) MapIndex(k pulumi.StringInput) GoogleCloudAiplatformV1ExplanationMetadataOutputMetadataOutput {
	return pulumi.All(o, k).ApplyT(func(vs []interface{}) GoogleCloudAiplatformV1ExplanationMetadataOutputMetadata {
		return vs[0].(map[string]GoogleCloudAiplatformV1ExplanationMetadataOutputMetadata)[vs[1].(string)]
	}).(GoogleCloudAiplatformV1ExplanationMetadataOutputMetadataOutput)
}

// Metadata of the prediction output to be explained.
type GoogleCloudAiplatformV1ExplanationMetadataOutputMetadataResponse struct {
	// Specify a field name in the prediction to look for the display name. Use this if the prediction contains the display names for the outputs. The display names in the prediction must have the same shape of the outputs, so that it can be located by Attribution.output_index for a specific output.
	DisplayNameMappingKey string `pulumi:"displayNameMappingKey"`
	// Static mapping between the index and display name. Use this if the outputs are a deterministic n-dimensional array, e.g. a list of scores of all the classes in a pre-defined order for a multi-classification Model. It's not feasible if the outputs are non-deterministic, e.g. the Model produces top-k classes or sort the outputs by their values. The shape of the value must be an n-dimensional array of strings. The number of dimensions must match that of the outputs to be explained. The Attribution.output_display_name is populated by locating in the mapping with Attribution.output_index.
	IndexDisplayNameMapping interface{} `pulumi:"indexDisplayNameMapping"`
	// Name of the output tensor. Required and is only applicable to Vertex AI provided images for Tensorflow.
	OutputTensorName string `pulumi:"outputTensorName"`
}

// Metadata of the prediction output to be explained.
type GoogleCloudAiplatformV1ExplanationMetadataOutputMetadataResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ExplanationMetadataOutputMetadataResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1ExplanationMetadataOutputMetadataResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ExplanationMetadataOutputMetadataResponseOutput) ToGoogleCloudAiplatformV1ExplanationMetadataOutputMetadataResponseOutput() GoogleCloudAiplatformV1ExplanationMetadataOutputMetadataResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1ExplanationMetadataOutputMetadataResponseOutput) ToGoogleCloudAiplatformV1ExplanationMetadataOutputMetadataResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ExplanationMetadataOutputMetadataResponseOutput {
	return o
}

// Specify a field name in the prediction to look for the display name. Use this if the prediction contains the display names for the outputs. The display names in the prediction must have the same shape of the outputs, so that it can be located by Attribution.output_index for a specific output.
func (o GoogleCloudAiplatformV1ExplanationMetadataOutputMetadataResponseOutput) DisplayNameMappingKey() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ExplanationMetadataOutputMetadataResponse) string {
		return v.DisplayNameMappingKey
	}).(pulumi.StringOutput)
}

// Static mapping between the index and display name. Use this if the outputs are a deterministic n-dimensional array, e.g. a list of scores of all the classes in a pre-defined order for a multi-classification Model. It's not feasible if the outputs are non-deterministic, e.g. the Model produces top-k classes or sort the outputs by their values. The shape of the value must be an n-dimensional array of strings. The number of dimensions must match that of the outputs to be explained. The Attribution.output_display_name is populated by locating in the mapping with Attribution.output_index.
func (o GoogleCloudAiplatformV1ExplanationMetadataOutputMetadataResponseOutput) IndexDisplayNameMapping() pulumi.AnyOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ExplanationMetadataOutputMetadataResponse) interface{} {
		return v.IndexDisplayNameMapping
	}).(pulumi.AnyOutput)
}

// Name of the output tensor. Required and is only applicable to Vertex AI provided images for Tensorflow.
func (o GoogleCloudAiplatformV1ExplanationMetadataOutputMetadataResponseOutput) OutputTensorName() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ExplanationMetadataOutputMetadataResponse) string {
		return v.OutputTensorName
	}).(pulumi.StringOutput)
}

type GoogleCloudAiplatformV1ExplanationMetadataOutputMetadataResponseMapOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ExplanationMetadataOutputMetadataResponseMapOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*map[string]GoogleCloudAiplatformV1ExplanationMetadataOutputMetadataResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ExplanationMetadataOutputMetadataResponseMapOutput) ToGoogleCloudAiplatformV1ExplanationMetadataOutputMetadataResponseMapOutput() GoogleCloudAiplatformV1ExplanationMetadataOutputMetadataResponseMapOutput {
	return o
}

func (o GoogleCloudAiplatformV1ExplanationMetadataOutputMetadataResponseMapOutput) ToGoogleCloudAiplatformV1ExplanationMetadataOutputMetadataResponseMapOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ExplanationMetadataOutputMetadataResponseMapOutput {
	return o
}

func (o GoogleCloudAiplatformV1ExplanationMetadataOutputMetadataResponseMapOutput) MapIndex(k pulumi.StringInput) GoogleCloudAiplatformV1ExplanationMetadataOutputMetadataResponseOutput {
	return pulumi.All(o, k).ApplyT(func(vs []interface{}) GoogleCloudAiplatformV1ExplanationMetadataOutputMetadataResponse {
		return vs[0].(map[string]GoogleCloudAiplatformV1ExplanationMetadataOutputMetadataResponse)[vs[1].(string)]
	}).(GoogleCloudAiplatformV1ExplanationMetadataOutputMetadataResponseOutput)
}

// Metadata describing the Model's input and output for explanation.
type GoogleCloudAiplatformV1ExplanationMetadataResponse struct {
	// Points to a YAML file stored on Google Cloud Storage describing the format of the feature attributions. The schema is defined as an OpenAPI 3.0.2 [Schema Object](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject). AutoML tabular Models always have this field populated by Vertex AI. Note: The URI given on output may be different, including the URI scheme, than the one given on input. The output URI will point to a location where the user only has a read access.
	FeatureAttributionsSchemaUri string `pulumi:"featureAttributionsSchemaUri"`
	// Map from feature names to feature input metadata. Keys are the name of the features. Values are the specification of the feature. An empty InputMetadata is valid. It describes a text feature which has the name specified as the key in ExplanationMetadata.inputs. The baseline of the empty feature is chosen by Vertex AI. For Vertex AI-provided Tensorflow images, the key can be any friendly name of the feature. Once specified, featureAttributions are keyed by this key (if not grouped with another feature). For custom images, the key must match with the key in instance.
	Inputs map[string]GoogleCloudAiplatformV1ExplanationMetadataInputMetadataResponse `pulumi:"inputs"`
	// Name of the source to generate embeddings for example based explanations.
	LatentSpaceSource string `pulumi:"latentSpaceSource"`
	// Map from output names to output metadata. For Vertex AI-provided Tensorflow images, keys can be any user defined string that consists of any UTF-8 characters. For custom images, keys are the name of the output field in the prediction to be explained. Currently only one key is allowed.
	Outputs map[string]GoogleCloudAiplatformV1ExplanationMetadataOutputMetadataResponse `pulumi:"outputs"`
}

// Metadata describing the Model's input and output for explanation.
type GoogleCloudAiplatformV1ExplanationMetadataResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ExplanationMetadataResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1ExplanationMetadataResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ExplanationMetadataResponseOutput) ToGoogleCloudAiplatformV1ExplanationMetadataResponseOutput() GoogleCloudAiplatformV1ExplanationMetadataResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1ExplanationMetadataResponseOutput) ToGoogleCloudAiplatformV1ExplanationMetadataResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ExplanationMetadataResponseOutput {
	return o
}

// Points to a YAML file stored on Google Cloud Storage describing the format of the feature attributions. The schema is defined as an OpenAPI 3.0.2 [Schema Object](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject). AutoML tabular Models always have this field populated by Vertex AI. Note: The URI given on output may be different, including the URI scheme, than the one given on input. The output URI will point to a location where the user only has a read access.
func (o GoogleCloudAiplatformV1ExplanationMetadataResponseOutput) FeatureAttributionsSchemaUri() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ExplanationMetadataResponse) string {
		return v.FeatureAttributionsSchemaUri
	}).(pulumi.StringOutput)
}

// Map from feature names to feature input metadata. Keys are the name of the features. Values are the specification of the feature. An empty InputMetadata is valid. It describes a text feature which has the name specified as the key in ExplanationMetadata.inputs. The baseline of the empty feature is chosen by Vertex AI. For Vertex AI-provided Tensorflow images, the key can be any friendly name of the feature. Once specified, featureAttributions are keyed by this key (if not grouped with another feature). For custom images, the key must match with the key in instance.
func (o GoogleCloudAiplatformV1ExplanationMetadataResponseOutput) Inputs() GoogleCloudAiplatformV1ExplanationMetadataInputMetadataResponseMapOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ExplanationMetadataResponse) map[string]GoogleCloudAiplatformV1ExplanationMetadataInputMetadataResponse {
		return v.Inputs
	}).(GoogleCloudAiplatformV1ExplanationMetadataInputMetadataResponseMapOutput)
}

// Name of the source to generate embeddings for example based explanations.
func (o GoogleCloudAiplatformV1ExplanationMetadataResponseOutput) LatentSpaceSource() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ExplanationMetadataResponse) string { return v.LatentSpaceSource }).(pulumi.StringOutput)
}

// Map from output names to output metadata. For Vertex AI-provided Tensorflow images, keys can be any user defined string that consists of any UTF-8 characters. For custom images, keys are the name of the output field in the prediction to be explained. Currently only one key is allowed.
func (o GoogleCloudAiplatformV1ExplanationMetadataResponseOutput) Outputs() GoogleCloudAiplatformV1ExplanationMetadataOutputMetadataResponseMapOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ExplanationMetadataResponse) map[string]GoogleCloudAiplatformV1ExplanationMetadataOutputMetadataResponse {
		return v.Outputs
	}).(GoogleCloudAiplatformV1ExplanationMetadataOutputMetadataResponseMapOutput)
}

// Parameters to configure explaining for Model's predictions.
type GoogleCloudAiplatformV1ExplanationParameters struct {
	// Example-based explanations that returns the nearest neighbors from the provided dataset.
	Examples *GoogleCloudAiplatformV1Examples `pulumi:"examples"`
	// An attribution method that computes Aumann-Shapley values taking advantage of the model's fully differentiable structure. Refer to this paper for more details: https://arxiv.org/abs/1703.01365
	IntegratedGradientsAttribution *GoogleCloudAiplatformV1IntegratedGradientsAttribution `pulumi:"integratedGradientsAttribution"`
	// If populated, only returns attributions that have output_index contained in output_indices. It must be an ndarray of integers, with the same shape of the output it's explaining. If not populated, returns attributions for top_k indices of outputs. If neither top_k nor output_indices is populated, returns the argmax index of the outputs. Only applicable to Models that predict multiple outputs (e,g, multi-class Models that predict multiple classes).
	OutputIndices []interface{} `pulumi:"outputIndices"`
	// An attribution method that approximates Shapley values for features that contribute to the label being predicted. A sampling strategy is used to approximate the value rather than considering all subsets of features. Refer to this paper for model details: https://arxiv.org/abs/1306.4265.
	SampledShapleyAttribution *GoogleCloudAiplatformV1SampledShapleyAttribution `pulumi:"sampledShapleyAttribution"`
	// If populated, returns attributions for top K indices of outputs (defaults to 1). Only applies to Models that predicts more than one outputs (e,g, multi-class Models). When set to -1, returns explanations for all outputs.
	TopK *int `pulumi:"topK"`
	// An attribution method that redistributes Integrated Gradients attribution to segmented regions, taking advantage of the model's fully differentiable structure. Refer to this paper for more details: https://arxiv.org/abs/1906.02825 XRAI currently performs better on natural images, like a picture of a house or an animal. If the images are taken in artificial environments, like a lab or manufacturing line, or from diagnostic equipment, like x-rays or quality-control cameras, use Integrated Gradients instead.
	XraiAttribution *GoogleCloudAiplatformV1XraiAttribution `pulumi:"xraiAttribution"`
}

// GoogleCloudAiplatformV1ExplanationParametersInput is an input type that accepts GoogleCloudAiplatformV1ExplanationParametersArgs and GoogleCloudAiplatformV1ExplanationParametersOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1ExplanationParametersInput` via:
//
//	GoogleCloudAiplatformV1ExplanationParametersArgs{...}
type GoogleCloudAiplatformV1ExplanationParametersInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1ExplanationParametersOutput() GoogleCloudAiplatformV1ExplanationParametersOutput
	ToGoogleCloudAiplatformV1ExplanationParametersOutputWithContext(context.Context) GoogleCloudAiplatformV1ExplanationParametersOutput
}

// Parameters to configure explaining for Model's predictions.
type GoogleCloudAiplatformV1ExplanationParametersArgs struct {
	// Example-based explanations that returns the nearest neighbors from the provided dataset.
	Examples GoogleCloudAiplatformV1ExamplesPtrInput `pulumi:"examples"`
	// An attribution method that computes Aumann-Shapley values taking advantage of the model's fully differentiable structure. Refer to this paper for more details: https://arxiv.org/abs/1703.01365
	IntegratedGradientsAttribution GoogleCloudAiplatformV1IntegratedGradientsAttributionPtrInput `pulumi:"integratedGradientsAttribution"`
	// If populated, only returns attributions that have output_index contained in output_indices. It must be an ndarray of integers, with the same shape of the output it's explaining. If not populated, returns attributions for top_k indices of outputs. If neither top_k nor output_indices is populated, returns the argmax index of the outputs. Only applicable to Models that predict multiple outputs (e,g, multi-class Models that predict multiple classes).
	OutputIndices pulumi.ArrayInput `pulumi:"outputIndices"`
	// An attribution method that approximates Shapley values for features that contribute to the label being predicted. A sampling strategy is used to approximate the value rather than considering all subsets of features. Refer to this paper for model details: https://arxiv.org/abs/1306.4265.
	SampledShapleyAttribution GoogleCloudAiplatformV1SampledShapleyAttributionPtrInput `pulumi:"sampledShapleyAttribution"`
	// If populated, returns attributions for top K indices of outputs (defaults to 1). Only applies to Models that predicts more than one outputs (e,g, multi-class Models). When set to -1, returns explanations for all outputs.
	TopK pulumi.IntPtrInput `pulumi:"topK"`
	// An attribution method that redistributes Integrated Gradients attribution to segmented regions, taking advantage of the model's fully differentiable structure. Refer to this paper for more details: https://arxiv.org/abs/1906.02825 XRAI currently performs better on natural images, like a picture of a house or an animal. If the images are taken in artificial environments, like a lab or manufacturing line, or from diagnostic equipment, like x-rays or quality-control cameras, use Integrated Gradients instead.
	XraiAttribution GoogleCloudAiplatformV1XraiAttributionPtrInput `pulumi:"xraiAttribution"`
}

func (GoogleCloudAiplatformV1ExplanationParametersArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1ExplanationParameters)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1ExplanationParametersArgs) ToGoogleCloudAiplatformV1ExplanationParametersOutput() GoogleCloudAiplatformV1ExplanationParametersOutput {
	return i.ToGoogleCloudAiplatformV1ExplanationParametersOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1ExplanationParametersArgs) ToGoogleCloudAiplatformV1ExplanationParametersOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ExplanationParametersOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1ExplanationParametersOutput)
}

func (i GoogleCloudAiplatformV1ExplanationParametersArgs) ToGoogleCloudAiplatformV1ExplanationParametersPtrOutput() GoogleCloudAiplatformV1ExplanationParametersPtrOutput {
	return i.ToGoogleCloudAiplatformV1ExplanationParametersPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1ExplanationParametersArgs) ToGoogleCloudAiplatformV1ExplanationParametersPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ExplanationParametersPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1ExplanationParametersOutput).ToGoogleCloudAiplatformV1ExplanationParametersPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1ExplanationParametersPtrInput is an input type that accepts GoogleCloudAiplatformV1ExplanationParametersArgs, GoogleCloudAiplatformV1ExplanationParametersPtr and GoogleCloudAiplatformV1ExplanationParametersPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1ExplanationParametersPtrInput` via:
//
//	        GoogleCloudAiplatformV1ExplanationParametersArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1ExplanationParametersPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1ExplanationParametersPtrOutput() GoogleCloudAiplatformV1ExplanationParametersPtrOutput
	ToGoogleCloudAiplatformV1ExplanationParametersPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1ExplanationParametersPtrOutput
}

type googleCloudAiplatformV1ExplanationParametersPtrType GoogleCloudAiplatformV1ExplanationParametersArgs

func GoogleCloudAiplatformV1ExplanationParametersPtr(v *GoogleCloudAiplatformV1ExplanationParametersArgs) GoogleCloudAiplatformV1ExplanationParametersPtrInput {
	return (*googleCloudAiplatformV1ExplanationParametersPtrType)(v)
}

func (*googleCloudAiplatformV1ExplanationParametersPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1ExplanationParameters)(nil)).Elem()
}

func (i *googleCloudAiplatformV1ExplanationParametersPtrType) ToGoogleCloudAiplatformV1ExplanationParametersPtrOutput() GoogleCloudAiplatformV1ExplanationParametersPtrOutput {
	return i.ToGoogleCloudAiplatformV1ExplanationParametersPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1ExplanationParametersPtrType) ToGoogleCloudAiplatformV1ExplanationParametersPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ExplanationParametersPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1ExplanationParametersPtrOutput)
}

// Parameters to configure explaining for Model's predictions.
type GoogleCloudAiplatformV1ExplanationParametersOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ExplanationParametersOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1ExplanationParameters)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ExplanationParametersOutput) ToGoogleCloudAiplatformV1ExplanationParametersOutput() GoogleCloudAiplatformV1ExplanationParametersOutput {
	return o
}

func (o GoogleCloudAiplatformV1ExplanationParametersOutput) ToGoogleCloudAiplatformV1ExplanationParametersOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ExplanationParametersOutput {
	return o
}

func (o GoogleCloudAiplatformV1ExplanationParametersOutput) ToGoogleCloudAiplatformV1ExplanationParametersPtrOutput() GoogleCloudAiplatformV1ExplanationParametersPtrOutput {
	return o.ToGoogleCloudAiplatformV1ExplanationParametersPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1ExplanationParametersOutput) ToGoogleCloudAiplatformV1ExplanationParametersPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ExplanationParametersPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1ExplanationParameters) *GoogleCloudAiplatformV1ExplanationParameters {
		return &v
	}).(GoogleCloudAiplatformV1ExplanationParametersPtrOutput)
}

// Example-based explanations that returns the nearest neighbors from the provided dataset.
func (o GoogleCloudAiplatformV1ExplanationParametersOutput) Examples() GoogleCloudAiplatformV1ExamplesPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ExplanationParameters) *GoogleCloudAiplatformV1Examples {
		return v.Examples
	}).(GoogleCloudAiplatformV1ExamplesPtrOutput)
}

// An attribution method that computes Aumann-Shapley values taking advantage of the model's fully differentiable structure. Refer to this paper for more details: https://arxiv.org/abs/1703.01365
func (o GoogleCloudAiplatformV1ExplanationParametersOutput) IntegratedGradientsAttribution() GoogleCloudAiplatformV1IntegratedGradientsAttributionPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ExplanationParameters) *GoogleCloudAiplatformV1IntegratedGradientsAttribution {
		return v.IntegratedGradientsAttribution
	}).(GoogleCloudAiplatformV1IntegratedGradientsAttributionPtrOutput)
}

// If populated, only returns attributions that have output_index contained in output_indices. It must be an ndarray of integers, with the same shape of the output it's explaining. If not populated, returns attributions for top_k indices of outputs. If neither top_k nor output_indices is populated, returns the argmax index of the outputs. Only applicable to Models that predict multiple outputs (e,g, multi-class Models that predict multiple classes).
func (o GoogleCloudAiplatformV1ExplanationParametersOutput) OutputIndices() pulumi.ArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ExplanationParameters) []interface{} { return v.OutputIndices }).(pulumi.ArrayOutput)
}

// An attribution method that approximates Shapley values for features that contribute to the label being predicted. A sampling strategy is used to approximate the value rather than considering all subsets of features. Refer to this paper for model details: https://arxiv.org/abs/1306.4265.
func (o GoogleCloudAiplatformV1ExplanationParametersOutput) SampledShapleyAttribution() GoogleCloudAiplatformV1SampledShapleyAttributionPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ExplanationParameters) *GoogleCloudAiplatformV1SampledShapleyAttribution {
		return v.SampledShapleyAttribution
	}).(GoogleCloudAiplatformV1SampledShapleyAttributionPtrOutput)
}

// If populated, returns attributions for top K indices of outputs (defaults to 1). Only applies to Models that predicts more than one outputs (e,g, multi-class Models). When set to -1, returns explanations for all outputs.
func (o GoogleCloudAiplatformV1ExplanationParametersOutput) TopK() pulumi.IntPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ExplanationParameters) *int { return v.TopK }).(pulumi.IntPtrOutput)
}

// An attribution method that redistributes Integrated Gradients attribution to segmented regions, taking advantage of the model's fully differentiable structure. Refer to this paper for more details: https://arxiv.org/abs/1906.02825 XRAI currently performs better on natural images, like a picture of a house or an animal. If the images are taken in artificial environments, like a lab or manufacturing line, or from diagnostic equipment, like x-rays or quality-control cameras, use Integrated Gradients instead.
func (o GoogleCloudAiplatformV1ExplanationParametersOutput) XraiAttribution() GoogleCloudAiplatformV1XraiAttributionPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ExplanationParameters) *GoogleCloudAiplatformV1XraiAttribution {
		return v.XraiAttribution
	}).(GoogleCloudAiplatformV1XraiAttributionPtrOutput)
}

type GoogleCloudAiplatformV1ExplanationParametersPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ExplanationParametersPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1ExplanationParameters)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ExplanationParametersPtrOutput) ToGoogleCloudAiplatformV1ExplanationParametersPtrOutput() GoogleCloudAiplatformV1ExplanationParametersPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1ExplanationParametersPtrOutput) ToGoogleCloudAiplatformV1ExplanationParametersPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ExplanationParametersPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1ExplanationParametersPtrOutput) Elem() GoogleCloudAiplatformV1ExplanationParametersOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1ExplanationParameters) GoogleCloudAiplatformV1ExplanationParameters {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1ExplanationParameters
		return ret
	}).(GoogleCloudAiplatformV1ExplanationParametersOutput)
}

// Example-based explanations that returns the nearest neighbors from the provided dataset.
func (o GoogleCloudAiplatformV1ExplanationParametersPtrOutput) Examples() GoogleCloudAiplatformV1ExamplesPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1ExplanationParameters) *GoogleCloudAiplatformV1Examples {
		if v == nil {
			return nil
		}
		return v.Examples
	}).(GoogleCloudAiplatformV1ExamplesPtrOutput)
}

// An attribution method that computes Aumann-Shapley values taking advantage of the model's fully differentiable structure. Refer to this paper for more details: https://arxiv.org/abs/1703.01365
func (o GoogleCloudAiplatformV1ExplanationParametersPtrOutput) IntegratedGradientsAttribution() GoogleCloudAiplatformV1IntegratedGradientsAttributionPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1ExplanationParameters) *GoogleCloudAiplatformV1IntegratedGradientsAttribution {
		if v == nil {
			return nil
		}
		return v.IntegratedGradientsAttribution
	}).(GoogleCloudAiplatformV1IntegratedGradientsAttributionPtrOutput)
}

// If populated, only returns attributions that have output_index contained in output_indices. It must be an ndarray of integers, with the same shape of the output it's explaining. If not populated, returns attributions for top_k indices of outputs. If neither top_k nor output_indices is populated, returns the argmax index of the outputs. Only applicable to Models that predict multiple outputs (e,g, multi-class Models that predict multiple classes).
func (o GoogleCloudAiplatformV1ExplanationParametersPtrOutput) OutputIndices() pulumi.ArrayOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1ExplanationParameters) []interface{} {
		if v == nil {
			return nil
		}
		return v.OutputIndices
	}).(pulumi.ArrayOutput)
}

// An attribution method that approximates Shapley values for features that contribute to the label being predicted. A sampling strategy is used to approximate the value rather than considering all subsets of features. Refer to this paper for model details: https://arxiv.org/abs/1306.4265.
func (o GoogleCloudAiplatformV1ExplanationParametersPtrOutput) SampledShapleyAttribution() GoogleCloudAiplatformV1SampledShapleyAttributionPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1ExplanationParameters) *GoogleCloudAiplatformV1SampledShapleyAttribution {
		if v == nil {
			return nil
		}
		return v.SampledShapleyAttribution
	}).(GoogleCloudAiplatformV1SampledShapleyAttributionPtrOutput)
}

// If populated, returns attributions for top K indices of outputs (defaults to 1). Only applies to Models that predicts more than one outputs (e,g, multi-class Models). When set to -1, returns explanations for all outputs.
func (o GoogleCloudAiplatformV1ExplanationParametersPtrOutput) TopK() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1ExplanationParameters) *int {
		if v == nil {
			return nil
		}
		return v.TopK
	}).(pulumi.IntPtrOutput)
}

// An attribution method that redistributes Integrated Gradients attribution to segmented regions, taking advantage of the model's fully differentiable structure. Refer to this paper for more details: https://arxiv.org/abs/1906.02825 XRAI currently performs better on natural images, like a picture of a house or an animal. If the images are taken in artificial environments, like a lab or manufacturing line, or from diagnostic equipment, like x-rays or quality-control cameras, use Integrated Gradients instead.
func (o GoogleCloudAiplatformV1ExplanationParametersPtrOutput) XraiAttribution() GoogleCloudAiplatformV1XraiAttributionPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1ExplanationParameters) *GoogleCloudAiplatformV1XraiAttribution {
		if v == nil {
			return nil
		}
		return v.XraiAttribution
	}).(GoogleCloudAiplatformV1XraiAttributionPtrOutput)
}

// Parameters to configure explaining for Model's predictions.
type GoogleCloudAiplatformV1ExplanationParametersResponse struct {
	// Example-based explanations that returns the nearest neighbors from the provided dataset.
	Examples GoogleCloudAiplatformV1ExamplesResponse `pulumi:"examples"`
	// An attribution method that computes Aumann-Shapley values taking advantage of the model's fully differentiable structure. Refer to this paper for more details: https://arxiv.org/abs/1703.01365
	IntegratedGradientsAttribution GoogleCloudAiplatformV1IntegratedGradientsAttributionResponse `pulumi:"integratedGradientsAttribution"`
	// If populated, only returns attributions that have output_index contained in output_indices. It must be an ndarray of integers, with the same shape of the output it's explaining. If not populated, returns attributions for top_k indices of outputs. If neither top_k nor output_indices is populated, returns the argmax index of the outputs. Only applicable to Models that predict multiple outputs (e,g, multi-class Models that predict multiple classes).
	OutputIndices []interface{} `pulumi:"outputIndices"`
	// An attribution method that approximates Shapley values for features that contribute to the label being predicted. A sampling strategy is used to approximate the value rather than considering all subsets of features. Refer to this paper for model details: https://arxiv.org/abs/1306.4265.
	SampledShapleyAttribution GoogleCloudAiplatformV1SampledShapleyAttributionResponse `pulumi:"sampledShapleyAttribution"`
	// If populated, returns attributions for top K indices of outputs (defaults to 1). Only applies to Models that predicts more than one outputs (e,g, multi-class Models). When set to -1, returns explanations for all outputs.
	TopK int `pulumi:"topK"`
	// An attribution method that redistributes Integrated Gradients attribution to segmented regions, taking advantage of the model's fully differentiable structure. Refer to this paper for more details: https://arxiv.org/abs/1906.02825 XRAI currently performs better on natural images, like a picture of a house or an animal. If the images are taken in artificial environments, like a lab or manufacturing line, or from diagnostic equipment, like x-rays or quality-control cameras, use Integrated Gradients instead.
	XraiAttribution GoogleCloudAiplatformV1XraiAttributionResponse `pulumi:"xraiAttribution"`
}

// Parameters to configure explaining for Model's predictions.
type GoogleCloudAiplatformV1ExplanationParametersResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ExplanationParametersResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1ExplanationParametersResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ExplanationParametersResponseOutput) ToGoogleCloudAiplatformV1ExplanationParametersResponseOutput() GoogleCloudAiplatformV1ExplanationParametersResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1ExplanationParametersResponseOutput) ToGoogleCloudAiplatformV1ExplanationParametersResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ExplanationParametersResponseOutput {
	return o
}

// Example-based explanations that returns the nearest neighbors from the provided dataset.
func (o GoogleCloudAiplatformV1ExplanationParametersResponseOutput) Examples() GoogleCloudAiplatformV1ExamplesResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ExplanationParametersResponse) GoogleCloudAiplatformV1ExamplesResponse {
		return v.Examples
	}).(GoogleCloudAiplatformV1ExamplesResponseOutput)
}

// An attribution method that computes Aumann-Shapley values taking advantage of the model's fully differentiable structure. Refer to this paper for more details: https://arxiv.org/abs/1703.01365
func (o GoogleCloudAiplatformV1ExplanationParametersResponseOutput) IntegratedGradientsAttribution() GoogleCloudAiplatformV1IntegratedGradientsAttributionResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ExplanationParametersResponse) GoogleCloudAiplatformV1IntegratedGradientsAttributionResponse {
		return v.IntegratedGradientsAttribution
	}).(GoogleCloudAiplatformV1IntegratedGradientsAttributionResponseOutput)
}

// If populated, only returns attributions that have output_index contained in output_indices. It must be an ndarray of integers, with the same shape of the output it's explaining. If not populated, returns attributions for top_k indices of outputs. If neither top_k nor output_indices is populated, returns the argmax index of the outputs. Only applicable to Models that predict multiple outputs (e,g, multi-class Models that predict multiple classes).
func (o GoogleCloudAiplatformV1ExplanationParametersResponseOutput) OutputIndices() pulumi.ArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ExplanationParametersResponse) []interface{} { return v.OutputIndices }).(pulumi.ArrayOutput)
}

// An attribution method that approximates Shapley values for features that contribute to the label being predicted. A sampling strategy is used to approximate the value rather than considering all subsets of features. Refer to this paper for model details: https://arxiv.org/abs/1306.4265.
func (o GoogleCloudAiplatformV1ExplanationParametersResponseOutput) SampledShapleyAttribution() GoogleCloudAiplatformV1SampledShapleyAttributionResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ExplanationParametersResponse) GoogleCloudAiplatformV1SampledShapleyAttributionResponse {
		return v.SampledShapleyAttribution
	}).(GoogleCloudAiplatformV1SampledShapleyAttributionResponseOutput)
}

// If populated, returns attributions for top K indices of outputs (defaults to 1). Only applies to Models that predicts more than one outputs (e,g, multi-class Models). When set to -1, returns explanations for all outputs.
func (o GoogleCloudAiplatformV1ExplanationParametersResponseOutput) TopK() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ExplanationParametersResponse) int { return v.TopK }).(pulumi.IntOutput)
}

// An attribution method that redistributes Integrated Gradients attribution to segmented regions, taking advantage of the model's fully differentiable structure. Refer to this paper for more details: https://arxiv.org/abs/1906.02825 XRAI currently performs better on natural images, like a picture of a house or an animal. If the images are taken in artificial environments, like a lab or manufacturing line, or from diagnostic equipment, like x-rays or quality-control cameras, use Integrated Gradients instead.
func (o GoogleCloudAiplatformV1ExplanationParametersResponseOutput) XraiAttribution() GoogleCloudAiplatformV1XraiAttributionResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ExplanationParametersResponse) GoogleCloudAiplatformV1XraiAttributionResponse {
		return v.XraiAttribution
	}).(GoogleCloudAiplatformV1XraiAttributionResponseOutput)
}

// Specification of Model explanation.
type GoogleCloudAiplatformV1ExplanationSpec struct {
	// Optional. Metadata describing the Model's input and output for explanation.
	Metadata *GoogleCloudAiplatformV1ExplanationMetadata `pulumi:"metadata"`
	// Parameters that configure explaining of the Model's predictions.
	Parameters GoogleCloudAiplatformV1ExplanationParameters `pulumi:"parameters"`
}

// GoogleCloudAiplatformV1ExplanationSpecInput is an input type that accepts GoogleCloudAiplatformV1ExplanationSpecArgs and GoogleCloudAiplatformV1ExplanationSpecOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1ExplanationSpecInput` via:
//
//	GoogleCloudAiplatformV1ExplanationSpecArgs{...}
type GoogleCloudAiplatformV1ExplanationSpecInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1ExplanationSpecOutput() GoogleCloudAiplatformV1ExplanationSpecOutput
	ToGoogleCloudAiplatformV1ExplanationSpecOutputWithContext(context.Context) GoogleCloudAiplatformV1ExplanationSpecOutput
}

// Specification of Model explanation.
type GoogleCloudAiplatformV1ExplanationSpecArgs struct {
	// Optional. Metadata describing the Model's input and output for explanation.
	Metadata GoogleCloudAiplatformV1ExplanationMetadataPtrInput `pulumi:"metadata"`
	// Parameters that configure explaining of the Model's predictions.
	Parameters GoogleCloudAiplatformV1ExplanationParametersInput `pulumi:"parameters"`
}

func (GoogleCloudAiplatformV1ExplanationSpecArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1ExplanationSpec)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1ExplanationSpecArgs) ToGoogleCloudAiplatformV1ExplanationSpecOutput() GoogleCloudAiplatformV1ExplanationSpecOutput {
	return i.ToGoogleCloudAiplatformV1ExplanationSpecOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1ExplanationSpecArgs) ToGoogleCloudAiplatformV1ExplanationSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ExplanationSpecOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1ExplanationSpecOutput)
}

func (i GoogleCloudAiplatformV1ExplanationSpecArgs) ToGoogleCloudAiplatformV1ExplanationSpecPtrOutput() GoogleCloudAiplatformV1ExplanationSpecPtrOutput {
	return i.ToGoogleCloudAiplatformV1ExplanationSpecPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1ExplanationSpecArgs) ToGoogleCloudAiplatformV1ExplanationSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ExplanationSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1ExplanationSpecOutput).ToGoogleCloudAiplatformV1ExplanationSpecPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1ExplanationSpecPtrInput is an input type that accepts GoogleCloudAiplatformV1ExplanationSpecArgs, GoogleCloudAiplatformV1ExplanationSpecPtr and GoogleCloudAiplatformV1ExplanationSpecPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1ExplanationSpecPtrInput` via:
//
//	        GoogleCloudAiplatformV1ExplanationSpecArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1ExplanationSpecPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1ExplanationSpecPtrOutput() GoogleCloudAiplatformV1ExplanationSpecPtrOutput
	ToGoogleCloudAiplatformV1ExplanationSpecPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1ExplanationSpecPtrOutput
}

type googleCloudAiplatformV1ExplanationSpecPtrType GoogleCloudAiplatformV1ExplanationSpecArgs

func GoogleCloudAiplatformV1ExplanationSpecPtr(v *GoogleCloudAiplatformV1ExplanationSpecArgs) GoogleCloudAiplatformV1ExplanationSpecPtrInput {
	return (*googleCloudAiplatformV1ExplanationSpecPtrType)(v)
}

func (*googleCloudAiplatformV1ExplanationSpecPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1ExplanationSpec)(nil)).Elem()
}

func (i *googleCloudAiplatformV1ExplanationSpecPtrType) ToGoogleCloudAiplatformV1ExplanationSpecPtrOutput() GoogleCloudAiplatformV1ExplanationSpecPtrOutput {
	return i.ToGoogleCloudAiplatformV1ExplanationSpecPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1ExplanationSpecPtrType) ToGoogleCloudAiplatformV1ExplanationSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ExplanationSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1ExplanationSpecPtrOutput)
}

// Specification of Model explanation.
type GoogleCloudAiplatformV1ExplanationSpecOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ExplanationSpecOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1ExplanationSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ExplanationSpecOutput) ToGoogleCloudAiplatformV1ExplanationSpecOutput() GoogleCloudAiplatformV1ExplanationSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1ExplanationSpecOutput) ToGoogleCloudAiplatformV1ExplanationSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ExplanationSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1ExplanationSpecOutput) ToGoogleCloudAiplatformV1ExplanationSpecPtrOutput() GoogleCloudAiplatformV1ExplanationSpecPtrOutput {
	return o.ToGoogleCloudAiplatformV1ExplanationSpecPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1ExplanationSpecOutput) ToGoogleCloudAiplatformV1ExplanationSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ExplanationSpecPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1ExplanationSpec) *GoogleCloudAiplatformV1ExplanationSpec {
		return &v
	}).(GoogleCloudAiplatformV1ExplanationSpecPtrOutput)
}

// Optional. Metadata describing the Model's input and output for explanation.
func (o GoogleCloudAiplatformV1ExplanationSpecOutput) Metadata() GoogleCloudAiplatformV1ExplanationMetadataPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ExplanationSpec) *GoogleCloudAiplatformV1ExplanationMetadata {
		return v.Metadata
	}).(GoogleCloudAiplatformV1ExplanationMetadataPtrOutput)
}

// Parameters that configure explaining of the Model's predictions.
func (o GoogleCloudAiplatformV1ExplanationSpecOutput) Parameters() GoogleCloudAiplatformV1ExplanationParametersOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ExplanationSpec) GoogleCloudAiplatformV1ExplanationParameters {
		return v.Parameters
	}).(GoogleCloudAiplatformV1ExplanationParametersOutput)
}

type GoogleCloudAiplatformV1ExplanationSpecPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ExplanationSpecPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1ExplanationSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ExplanationSpecPtrOutput) ToGoogleCloudAiplatformV1ExplanationSpecPtrOutput() GoogleCloudAiplatformV1ExplanationSpecPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1ExplanationSpecPtrOutput) ToGoogleCloudAiplatformV1ExplanationSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ExplanationSpecPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1ExplanationSpecPtrOutput) Elem() GoogleCloudAiplatformV1ExplanationSpecOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1ExplanationSpec) GoogleCloudAiplatformV1ExplanationSpec {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1ExplanationSpec
		return ret
	}).(GoogleCloudAiplatformV1ExplanationSpecOutput)
}

// Optional. Metadata describing the Model's input and output for explanation.
func (o GoogleCloudAiplatformV1ExplanationSpecPtrOutput) Metadata() GoogleCloudAiplatformV1ExplanationMetadataPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1ExplanationSpec) *GoogleCloudAiplatformV1ExplanationMetadata {
		if v == nil {
			return nil
		}
		return v.Metadata
	}).(GoogleCloudAiplatformV1ExplanationMetadataPtrOutput)
}

// Parameters that configure explaining of the Model's predictions.
func (o GoogleCloudAiplatformV1ExplanationSpecPtrOutput) Parameters() GoogleCloudAiplatformV1ExplanationParametersPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1ExplanationSpec) *GoogleCloudAiplatformV1ExplanationParameters {
		if v == nil {
			return nil
		}
		return &v.Parameters
	}).(GoogleCloudAiplatformV1ExplanationParametersPtrOutput)
}

// Specification of Model explanation.
type GoogleCloudAiplatformV1ExplanationSpecResponse struct {
	// Optional. Metadata describing the Model's input and output for explanation.
	Metadata GoogleCloudAiplatformV1ExplanationMetadataResponse `pulumi:"metadata"`
	// Parameters that configure explaining of the Model's predictions.
	Parameters GoogleCloudAiplatformV1ExplanationParametersResponse `pulumi:"parameters"`
}

// Specification of Model explanation.
type GoogleCloudAiplatformV1ExplanationSpecResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ExplanationSpecResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1ExplanationSpecResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ExplanationSpecResponseOutput) ToGoogleCloudAiplatformV1ExplanationSpecResponseOutput() GoogleCloudAiplatformV1ExplanationSpecResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1ExplanationSpecResponseOutput) ToGoogleCloudAiplatformV1ExplanationSpecResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ExplanationSpecResponseOutput {
	return o
}

// Optional. Metadata describing the Model's input and output for explanation.
func (o GoogleCloudAiplatformV1ExplanationSpecResponseOutput) Metadata() GoogleCloudAiplatformV1ExplanationMetadataResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ExplanationSpecResponse) GoogleCloudAiplatformV1ExplanationMetadataResponse {
		return v.Metadata
	}).(GoogleCloudAiplatformV1ExplanationMetadataResponseOutput)
}

// Parameters that configure explaining of the Model's predictions.
func (o GoogleCloudAiplatformV1ExplanationSpecResponseOutput) Parameters() GoogleCloudAiplatformV1ExplanationParametersResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ExplanationSpecResponse) GoogleCloudAiplatformV1ExplanationParametersResponse {
		return v.Parameters
	}).(GoogleCloudAiplatformV1ExplanationParametersResponseOutput)
}

// Input source type for BigQuery Tables and Views.
type GoogleCloudAiplatformV1FeatureGroupBigQuery struct {
	// Immutable. The BigQuery source URI that points to either a BigQuery Table or View.
	BigQuerySource GoogleCloudAiplatformV1BigQuerySource `pulumi:"bigQuerySource"`
	// Optional. Columns to construct entity_id / row keys. Currently only supports 1 entity_id_column. If not provided defaults to `entity_id`.
	EntityIdColumns []string `pulumi:"entityIdColumns"`
}

// GoogleCloudAiplatformV1FeatureGroupBigQueryInput is an input type that accepts GoogleCloudAiplatformV1FeatureGroupBigQueryArgs and GoogleCloudAiplatformV1FeatureGroupBigQueryOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1FeatureGroupBigQueryInput` via:
//
//	GoogleCloudAiplatformV1FeatureGroupBigQueryArgs{...}
type GoogleCloudAiplatformV1FeatureGroupBigQueryInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1FeatureGroupBigQueryOutput() GoogleCloudAiplatformV1FeatureGroupBigQueryOutput
	ToGoogleCloudAiplatformV1FeatureGroupBigQueryOutputWithContext(context.Context) GoogleCloudAiplatformV1FeatureGroupBigQueryOutput
}

// Input source type for BigQuery Tables and Views.
type GoogleCloudAiplatformV1FeatureGroupBigQueryArgs struct {
	// Immutable. The BigQuery source URI that points to either a BigQuery Table or View.
	BigQuerySource GoogleCloudAiplatformV1BigQuerySourceInput `pulumi:"bigQuerySource"`
	// Optional. Columns to construct entity_id / row keys. Currently only supports 1 entity_id_column. If not provided defaults to `entity_id`.
	EntityIdColumns pulumi.StringArrayInput `pulumi:"entityIdColumns"`
}

func (GoogleCloudAiplatformV1FeatureGroupBigQueryArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1FeatureGroupBigQuery)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1FeatureGroupBigQueryArgs) ToGoogleCloudAiplatformV1FeatureGroupBigQueryOutput() GoogleCloudAiplatformV1FeatureGroupBigQueryOutput {
	return i.ToGoogleCloudAiplatformV1FeatureGroupBigQueryOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1FeatureGroupBigQueryArgs) ToGoogleCloudAiplatformV1FeatureGroupBigQueryOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeatureGroupBigQueryOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1FeatureGroupBigQueryOutput)
}

func (i GoogleCloudAiplatformV1FeatureGroupBigQueryArgs) ToGoogleCloudAiplatformV1FeatureGroupBigQueryPtrOutput() GoogleCloudAiplatformV1FeatureGroupBigQueryPtrOutput {
	return i.ToGoogleCloudAiplatformV1FeatureGroupBigQueryPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1FeatureGroupBigQueryArgs) ToGoogleCloudAiplatformV1FeatureGroupBigQueryPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeatureGroupBigQueryPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1FeatureGroupBigQueryOutput).ToGoogleCloudAiplatformV1FeatureGroupBigQueryPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1FeatureGroupBigQueryPtrInput is an input type that accepts GoogleCloudAiplatformV1FeatureGroupBigQueryArgs, GoogleCloudAiplatformV1FeatureGroupBigQueryPtr and GoogleCloudAiplatformV1FeatureGroupBigQueryPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1FeatureGroupBigQueryPtrInput` via:
//
//	        GoogleCloudAiplatformV1FeatureGroupBigQueryArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1FeatureGroupBigQueryPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1FeatureGroupBigQueryPtrOutput() GoogleCloudAiplatformV1FeatureGroupBigQueryPtrOutput
	ToGoogleCloudAiplatformV1FeatureGroupBigQueryPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1FeatureGroupBigQueryPtrOutput
}

type googleCloudAiplatformV1FeatureGroupBigQueryPtrType GoogleCloudAiplatformV1FeatureGroupBigQueryArgs

func GoogleCloudAiplatformV1FeatureGroupBigQueryPtr(v *GoogleCloudAiplatformV1FeatureGroupBigQueryArgs) GoogleCloudAiplatformV1FeatureGroupBigQueryPtrInput {
	return (*googleCloudAiplatformV1FeatureGroupBigQueryPtrType)(v)
}

func (*googleCloudAiplatformV1FeatureGroupBigQueryPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1FeatureGroupBigQuery)(nil)).Elem()
}

func (i *googleCloudAiplatformV1FeatureGroupBigQueryPtrType) ToGoogleCloudAiplatformV1FeatureGroupBigQueryPtrOutput() GoogleCloudAiplatformV1FeatureGroupBigQueryPtrOutput {
	return i.ToGoogleCloudAiplatformV1FeatureGroupBigQueryPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1FeatureGroupBigQueryPtrType) ToGoogleCloudAiplatformV1FeatureGroupBigQueryPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeatureGroupBigQueryPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1FeatureGroupBigQueryPtrOutput)
}

// Input source type for BigQuery Tables and Views.
type GoogleCloudAiplatformV1FeatureGroupBigQueryOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1FeatureGroupBigQueryOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1FeatureGroupBigQuery)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1FeatureGroupBigQueryOutput) ToGoogleCloudAiplatformV1FeatureGroupBigQueryOutput() GoogleCloudAiplatformV1FeatureGroupBigQueryOutput {
	return o
}

func (o GoogleCloudAiplatformV1FeatureGroupBigQueryOutput) ToGoogleCloudAiplatformV1FeatureGroupBigQueryOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeatureGroupBigQueryOutput {
	return o
}

func (o GoogleCloudAiplatformV1FeatureGroupBigQueryOutput) ToGoogleCloudAiplatformV1FeatureGroupBigQueryPtrOutput() GoogleCloudAiplatformV1FeatureGroupBigQueryPtrOutput {
	return o.ToGoogleCloudAiplatformV1FeatureGroupBigQueryPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1FeatureGroupBigQueryOutput) ToGoogleCloudAiplatformV1FeatureGroupBigQueryPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeatureGroupBigQueryPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1FeatureGroupBigQuery) *GoogleCloudAiplatformV1FeatureGroupBigQuery {
		return &v
	}).(GoogleCloudAiplatformV1FeatureGroupBigQueryPtrOutput)
}

// Immutable. The BigQuery source URI that points to either a BigQuery Table or View.
func (o GoogleCloudAiplatformV1FeatureGroupBigQueryOutput) BigQuerySource() GoogleCloudAiplatformV1BigQuerySourceOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1FeatureGroupBigQuery) GoogleCloudAiplatformV1BigQuerySource {
		return v.BigQuerySource
	}).(GoogleCloudAiplatformV1BigQuerySourceOutput)
}

// Optional. Columns to construct entity_id / row keys. Currently only supports 1 entity_id_column. If not provided defaults to `entity_id`.
func (o GoogleCloudAiplatformV1FeatureGroupBigQueryOutput) EntityIdColumns() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1FeatureGroupBigQuery) []string { return v.EntityIdColumns }).(pulumi.StringArrayOutput)
}

type GoogleCloudAiplatformV1FeatureGroupBigQueryPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1FeatureGroupBigQueryPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1FeatureGroupBigQuery)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1FeatureGroupBigQueryPtrOutput) ToGoogleCloudAiplatformV1FeatureGroupBigQueryPtrOutput() GoogleCloudAiplatformV1FeatureGroupBigQueryPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1FeatureGroupBigQueryPtrOutput) ToGoogleCloudAiplatformV1FeatureGroupBigQueryPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeatureGroupBigQueryPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1FeatureGroupBigQueryPtrOutput) Elem() GoogleCloudAiplatformV1FeatureGroupBigQueryOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1FeatureGroupBigQuery) GoogleCloudAiplatformV1FeatureGroupBigQuery {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1FeatureGroupBigQuery
		return ret
	}).(GoogleCloudAiplatformV1FeatureGroupBigQueryOutput)
}

// Immutable. The BigQuery source URI that points to either a BigQuery Table or View.
func (o GoogleCloudAiplatformV1FeatureGroupBigQueryPtrOutput) BigQuerySource() GoogleCloudAiplatformV1BigQuerySourcePtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1FeatureGroupBigQuery) *GoogleCloudAiplatformV1BigQuerySource {
		if v == nil {
			return nil
		}
		return &v.BigQuerySource
	}).(GoogleCloudAiplatformV1BigQuerySourcePtrOutput)
}

// Optional. Columns to construct entity_id / row keys. Currently only supports 1 entity_id_column. If not provided defaults to `entity_id`.
func (o GoogleCloudAiplatformV1FeatureGroupBigQueryPtrOutput) EntityIdColumns() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1FeatureGroupBigQuery) []string {
		if v == nil {
			return nil
		}
		return v.EntityIdColumns
	}).(pulumi.StringArrayOutput)
}

// Input source type for BigQuery Tables and Views.
type GoogleCloudAiplatformV1FeatureGroupBigQueryResponse struct {
	// Immutable. The BigQuery source URI that points to either a BigQuery Table or View.
	BigQuerySource GoogleCloudAiplatformV1BigQuerySourceResponse `pulumi:"bigQuerySource"`
	// Optional. Columns to construct entity_id / row keys. Currently only supports 1 entity_id_column. If not provided defaults to `entity_id`.
	EntityIdColumns []string `pulumi:"entityIdColumns"`
}

// Input source type for BigQuery Tables and Views.
type GoogleCloudAiplatformV1FeatureGroupBigQueryResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1FeatureGroupBigQueryResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1FeatureGroupBigQueryResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1FeatureGroupBigQueryResponseOutput) ToGoogleCloudAiplatformV1FeatureGroupBigQueryResponseOutput() GoogleCloudAiplatformV1FeatureGroupBigQueryResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1FeatureGroupBigQueryResponseOutput) ToGoogleCloudAiplatformV1FeatureGroupBigQueryResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeatureGroupBigQueryResponseOutput {
	return o
}

// Immutable. The BigQuery source URI that points to either a BigQuery Table or View.
func (o GoogleCloudAiplatformV1FeatureGroupBigQueryResponseOutput) BigQuerySource() GoogleCloudAiplatformV1BigQuerySourceResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1FeatureGroupBigQueryResponse) GoogleCloudAiplatformV1BigQuerySourceResponse {
		return v.BigQuerySource
	}).(GoogleCloudAiplatformV1BigQuerySourceResponseOutput)
}

// Optional. Columns to construct entity_id / row keys. Currently only supports 1 entity_id_column. If not provided defaults to `entity_id`.
func (o GoogleCloudAiplatformV1FeatureGroupBigQueryResponseOutput) EntityIdColumns() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1FeatureGroupBigQueryResponse) []string { return v.EntityIdColumns }).(pulumi.StringArrayOutput)
}

// A list of historical SnapshotAnalysis or ImportFeaturesAnalysis stats requested by user, sorted by FeatureStatsAnomaly.start_time descending.
type GoogleCloudAiplatformV1FeatureMonitoringStatsAnomalyResponse struct {
	// The stats and anomalies generated at specific timestamp.
	FeatureStatsAnomaly GoogleCloudAiplatformV1FeatureStatsAnomalyResponse `pulumi:"featureStatsAnomaly"`
	// The objective for each stats.
	Objective string `pulumi:"objective"`
}

// A list of historical SnapshotAnalysis or ImportFeaturesAnalysis stats requested by user, sorted by FeatureStatsAnomaly.start_time descending.
type GoogleCloudAiplatformV1FeatureMonitoringStatsAnomalyResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1FeatureMonitoringStatsAnomalyResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1FeatureMonitoringStatsAnomalyResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1FeatureMonitoringStatsAnomalyResponseOutput) ToGoogleCloudAiplatformV1FeatureMonitoringStatsAnomalyResponseOutput() GoogleCloudAiplatformV1FeatureMonitoringStatsAnomalyResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1FeatureMonitoringStatsAnomalyResponseOutput) ToGoogleCloudAiplatformV1FeatureMonitoringStatsAnomalyResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeatureMonitoringStatsAnomalyResponseOutput {
	return o
}

// The stats and anomalies generated at specific timestamp.
func (o GoogleCloudAiplatformV1FeatureMonitoringStatsAnomalyResponseOutput) FeatureStatsAnomaly() GoogleCloudAiplatformV1FeatureStatsAnomalyResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1FeatureMonitoringStatsAnomalyResponse) GoogleCloudAiplatformV1FeatureStatsAnomalyResponse {
		return v.FeatureStatsAnomaly
	}).(GoogleCloudAiplatformV1FeatureStatsAnomalyResponseOutput)
}

// The objective for each stats.
func (o GoogleCloudAiplatformV1FeatureMonitoringStatsAnomalyResponseOutput) Objective() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1FeatureMonitoringStatsAnomalyResponse) string { return v.Objective }).(pulumi.StringOutput)
}

type GoogleCloudAiplatformV1FeatureMonitoringStatsAnomalyResponseArrayOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1FeatureMonitoringStatsAnomalyResponseArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1FeatureMonitoringStatsAnomalyResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1FeatureMonitoringStatsAnomalyResponseArrayOutput) ToGoogleCloudAiplatformV1FeatureMonitoringStatsAnomalyResponseArrayOutput() GoogleCloudAiplatformV1FeatureMonitoringStatsAnomalyResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1FeatureMonitoringStatsAnomalyResponseArrayOutput) ToGoogleCloudAiplatformV1FeatureMonitoringStatsAnomalyResponseArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeatureMonitoringStatsAnomalyResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1FeatureMonitoringStatsAnomalyResponseArrayOutput) Index(i pulumi.IntInput) GoogleCloudAiplatformV1FeatureMonitoringStatsAnomalyResponseOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GoogleCloudAiplatformV1FeatureMonitoringStatsAnomalyResponse {
		return vs[0].([]GoogleCloudAiplatformV1FeatureMonitoringStatsAnomalyResponse)[vs[1].(int)]
	}).(GoogleCloudAiplatformV1FeatureMonitoringStatsAnomalyResponseOutput)
}

// Noise sigma by features. Noise sigma represents the standard deviation of the gaussian kernel that will be used to add noise to interpolated inputs prior to computing gradients.
type GoogleCloudAiplatformV1FeatureNoiseSigma struct {
	// Noise sigma per feature. No noise is added to features that are not set.
	NoiseSigma []GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeature `pulumi:"noiseSigma"`
}

// GoogleCloudAiplatformV1FeatureNoiseSigmaInput is an input type that accepts GoogleCloudAiplatformV1FeatureNoiseSigmaArgs and GoogleCloudAiplatformV1FeatureNoiseSigmaOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1FeatureNoiseSigmaInput` via:
//
//	GoogleCloudAiplatformV1FeatureNoiseSigmaArgs{...}
type GoogleCloudAiplatformV1FeatureNoiseSigmaInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1FeatureNoiseSigmaOutput() GoogleCloudAiplatformV1FeatureNoiseSigmaOutput
	ToGoogleCloudAiplatformV1FeatureNoiseSigmaOutputWithContext(context.Context) GoogleCloudAiplatformV1FeatureNoiseSigmaOutput
}

// Noise sigma by features. Noise sigma represents the standard deviation of the gaussian kernel that will be used to add noise to interpolated inputs prior to computing gradients.
type GoogleCloudAiplatformV1FeatureNoiseSigmaArgs struct {
	// Noise sigma per feature. No noise is added to features that are not set.
	NoiseSigma GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureArrayInput `pulumi:"noiseSigma"`
}

func (GoogleCloudAiplatformV1FeatureNoiseSigmaArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1FeatureNoiseSigma)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1FeatureNoiseSigmaArgs) ToGoogleCloudAiplatformV1FeatureNoiseSigmaOutput() GoogleCloudAiplatformV1FeatureNoiseSigmaOutput {
	return i.ToGoogleCloudAiplatformV1FeatureNoiseSigmaOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1FeatureNoiseSigmaArgs) ToGoogleCloudAiplatformV1FeatureNoiseSigmaOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeatureNoiseSigmaOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1FeatureNoiseSigmaOutput)
}

func (i GoogleCloudAiplatformV1FeatureNoiseSigmaArgs) ToGoogleCloudAiplatformV1FeatureNoiseSigmaPtrOutput() GoogleCloudAiplatformV1FeatureNoiseSigmaPtrOutput {
	return i.ToGoogleCloudAiplatformV1FeatureNoiseSigmaPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1FeatureNoiseSigmaArgs) ToGoogleCloudAiplatformV1FeatureNoiseSigmaPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeatureNoiseSigmaPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1FeatureNoiseSigmaOutput).ToGoogleCloudAiplatformV1FeatureNoiseSigmaPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1FeatureNoiseSigmaPtrInput is an input type that accepts GoogleCloudAiplatformV1FeatureNoiseSigmaArgs, GoogleCloudAiplatformV1FeatureNoiseSigmaPtr and GoogleCloudAiplatformV1FeatureNoiseSigmaPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1FeatureNoiseSigmaPtrInput` via:
//
//	        GoogleCloudAiplatformV1FeatureNoiseSigmaArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1FeatureNoiseSigmaPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1FeatureNoiseSigmaPtrOutput() GoogleCloudAiplatformV1FeatureNoiseSigmaPtrOutput
	ToGoogleCloudAiplatformV1FeatureNoiseSigmaPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1FeatureNoiseSigmaPtrOutput
}

type googleCloudAiplatformV1FeatureNoiseSigmaPtrType GoogleCloudAiplatformV1FeatureNoiseSigmaArgs

func GoogleCloudAiplatformV1FeatureNoiseSigmaPtr(v *GoogleCloudAiplatformV1FeatureNoiseSigmaArgs) GoogleCloudAiplatformV1FeatureNoiseSigmaPtrInput {
	return (*googleCloudAiplatformV1FeatureNoiseSigmaPtrType)(v)
}

func (*googleCloudAiplatformV1FeatureNoiseSigmaPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1FeatureNoiseSigma)(nil)).Elem()
}

func (i *googleCloudAiplatformV1FeatureNoiseSigmaPtrType) ToGoogleCloudAiplatformV1FeatureNoiseSigmaPtrOutput() GoogleCloudAiplatformV1FeatureNoiseSigmaPtrOutput {
	return i.ToGoogleCloudAiplatformV1FeatureNoiseSigmaPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1FeatureNoiseSigmaPtrType) ToGoogleCloudAiplatformV1FeatureNoiseSigmaPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeatureNoiseSigmaPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1FeatureNoiseSigmaPtrOutput)
}

// Noise sigma by features. Noise sigma represents the standard deviation of the gaussian kernel that will be used to add noise to interpolated inputs prior to computing gradients.
type GoogleCloudAiplatformV1FeatureNoiseSigmaOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1FeatureNoiseSigmaOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1FeatureNoiseSigma)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1FeatureNoiseSigmaOutput) ToGoogleCloudAiplatformV1FeatureNoiseSigmaOutput() GoogleCloudAiplatformV1FeatureNoiseSigmaOutput {
	return o
}

func (o GoogleCloudAiplatformV1FeatureNoiseSigmaOutput) ToGoogleCloudAiplatformV1FeatureNoiseSigmaOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeatureNoiseSigmaOutput {
	return o
}

func (o GoogleCloudAiplatformV1FeatureNoiseSigmaOutput) ToGoogleCloudAiplatformV1FeatureNoiseSigmaPtrOutput() GoogleCloudAiplatformV1FeatureNoiseSigmaPtrOutput {
	return o.ToGoogleCloudAiplatformV1FeatureNoiseSigmaPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1FeatureNoiseSigmaOutput) ToGoogleCloudAiplatformV1FeatureNoiseSigmaPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeatureNoiseSigmaPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1FeatureNoiseSigma) *GoogleCloudAiplatformV1FeatureNoiseSigma {
		return &v
	}).(GoogleCloudAiplatformV1FeatureNoiseSigmaPtrOutput)
}

// Noise sigma per feature. No noise is added to features that are not set.
func (o GoogleCloudAiplatformV1FeatureNoiseSigmaOutput) NoiseSigma() GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1FeatureNoiseSigma) []GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeature {
		return v.NoiseSigma
	}).(GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureArrayOutput)
}

type GoogleCloudAiplatformV1FeatureNoiseSigmaPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1FeatureNoiseSigmaPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1FeatureNoiseSigma)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1FeatureNoiseSigmaPtrOutput) ToGoogleCloudAiplatformV1FeatureNoiseSigmaPtrOutput() GoogleCloudAiplatformV1FeatureNoiseSigmaPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1FeatureNoiseSigmaPtrOutput) ToGoogleCloudAiplatformV1FeatureNoiseSigmaPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeatureNoiseSigmaPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1FeatureNoiseSigmaPtrOutput) Elem() GoogleCloudAiplatformV1FeatureNoiseSigmaOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1FeatureNoiseSigma) GoogleCloudAiplatformV1FeatureNoiseSigma {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1FeatureNoiseSigma
		return ret
	}).(GoogleCloudAiplatformV1FeatureNoiseSigmaOutput)
}

// Noise sigma per feature. No noise is added to features that are not set.
func (o GoogleCloudAiplatformV1FeatureNoiseSigmaPtrOutput) NoiseSigma() GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureArrayOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1FeatureNoiseSigma) []GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeature {
		if v == nil {
			return nil
		}
		return v.NoiseSigma
	}).(GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureArrayOutput)
}

// Noise sigma for a single feature.
type GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeature struct {
	// The name of the input feature for which noise sigma is provided. The features are defined in explanation metadata inputs.
	Name *string `pulumi:"name"`
	// This represents the standard deviation of the Gaussian kernel that will be used to add noise to the feature prior to computing gradients. Similar to noise_sigma but represents the noise added to the current feature. Defaults to 0.1.
	Sigma *float64 `pulumi:"sigma"`
}

// GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureInput is an input type that accepts GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureArgs and GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureInput` via:
//
//	GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureArgs{...}
type GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureOutput() GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureOutput
	ToGoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureOutputWithContext(context.Context) GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureOutput
}

// Noise sigma for a single feature.
type GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureArgs struct {
	// The name of the input feature for which noise sigma is provided. The features are defined in explanation metadata inputs.
	Name pulumi.StringPtrInput `pulumi:"name"`
	// This represents the standard deviation of the Gaussian kernel that will be used to add noise to the feature prior to computing gradients. Similar to noise_sigma but represents the noise added to the current feature. Defaults to 0.1.
	Sigma pulumi.Float64PtrInput `pulumi:"sigma"`
}

func (GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeature)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureArgs) ToGoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureOutput() GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureOutput {
	return i.ToGoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureArgs) ToGoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureOutput)
}

// GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureArrayInput is an input type that accepts GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureArray and GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureArrayOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureArrayInput` via:
//
//	GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureArray{ GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureArgs{...} }
type GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureArrayInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureArrayOutput() GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureArrayOutput
	ToGoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureArrayOutputWithContext(context.Context) GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureArrayOutput
}

type GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureArray []GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureInput

func (GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeature)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureArray) ToGoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureArrayOutput() GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureArrayOutput {
	return i.ToGoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureArrayOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureArray) ToGoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureArrayOutput)
}

// Noise sigma for a single feature.
type GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeature)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureOutput) ToGoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureOutput() GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureOutput {
	return o
}

func (o GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureOutput) ToGoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureOutput {
	return o
}

// The name of the input feature for which noise sigma is provided. The features are defined in explanation metadata inputs.
func (o GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureOutput) Name() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeature) *string { return v.Name }).(pulumi.StringPtrOutput)
}

// This represents the standard deviation of the Gaussian kernel that will be used to add noise to the feature prior to computing gradients. Similar to noise_sigma but represents the noise added to the current feature. Defaults to 0.1.
func (o GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureOutput) Sigma() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeature) *float64 { return v.Sigma }).(pulumi.Float64PtrOutput)
}

type GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureArrayOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeature)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureArrayOutput) ToGoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureArrayOutput() GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureArrayOutput) ToGoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureArrayOutput) Index(i pulumi.IntInput) GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeature {
		return vs[0].([]GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeature)[vs[1].(int)]
	}).(GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureOutput)
}

// Noise sigma for a single feature.
type GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureResponse struct {
	// The name of the input feature for which noise sigma is provided. The features are defined in explanation metadata inputs.
	Name string `pulumi:"name"`
	// This represents the standard deviation of the Gaussian kernel that will be used to add noise to the feature prior to computing gradients. Similar to noise_sigma but represents the noise added to the current feature. Defaults to 0.1.
	Sigma float64 `pulumi:"sigma"`
}

// Noise sigma for a single feature.
type GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureResponseOutput) ToGoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureResponseOutput() GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureResponseOutput) ToGoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureResponseOutput {
	return o
}

// The name of the input feature for which noise sigma is provided. The features are defined in explanation metadata inputs.
func (o GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureResponseOutput) Name() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureResponse) string { return v.Name }).(pulumi.StringOutput)
}

// This represents the standard deviation of the Gaussian kernel that will be used to add noise to the feature prior to computing gradients. Similar to noise_sigma but represents the noise added to the current feature. Defaults to 0.1.
func (o GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureResponseOutput) Sigma() pulumi.Float64Output {
	return o.ApplyT(func(v GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureResponse) float64 { return v.Sigma }).(pulumi.Float64Output)
}

type GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureResponseArrayOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureResponseArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureResponseArrayOutput) ToGoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureResponseArrayOutput() GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureResponseArrayOutput) ToGoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureResponseArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureResponseArrayOutput) Index(i pulumi.IntInput) GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureResponseOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureResponse {
		return vs[0].([]GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureResponse)[vs[1].(int)]
	}).(GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureResponseOutput)
}

// Noise sigma by features. Noise sigma represents the standard deviation of the gaussian kernel that will be used to add noise to interpolated inputs prior to computing gradients.
type GoogleCloudAiplatformV1FeatureNoiseSigmaResponse struct {
	// Noise sigma per feature. No noise is added to features that are not set.
	NoiseSigma []GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureResponse `pulumi:"noiseSigma"`
}

// Noise sigma by features. Noise sigma represents the standard deviation of the gaussian kernel that will be used to add noise to interpolated inputs prior to computing gradients.
type GoogleCloudAiplatformV1FeatureNoiseSigmaResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1FeatureNoiseSigmaResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1FeatureNoiseSigmaResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1FeatureNoiseSigmaResponseOutput) ToGoogleCloudAiplatformV1FeatureNoiseSigmaResponseOutput() GoogleCloudAiplatformV1FeatureNoiseSigmaResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1FeatureNoiseSigmaResponseOutput) ToGoogleCloudAiplatformV1FeatureNoiseSigmaResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeatureNoiseSigmaResponseOutput {
	return o
}

// Noise sigma per feature. No noise is added to features that are not set.
func (o GoogleCloudAiplatformV1FeatureNoiseSigmaResponseOutput) NoiseSigma() GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureResponseArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1FeatureNoiseSigmaResponse) []GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureResponse {
		return v.NoiseSigma
	}).(GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureResponseArrayOutput)
}

type GoogleCloudAiplatformV1FeatureOnlineStoreBigtable struct {
	// Autoscaling config applied to Bigtable Instance.
	AutoScaling GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScaling `pulumi:"autoScaling"`
}

// GoogleCloudAiplatformV1FeatureOnlineStoreBigtableInput is an input type that accepts GoogleCloudAiplatformV1FeatureOnlineStoreBigtableArgs and GoogleCloudAiplatformV1FeatureOnlineStoreBigtableOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1FeatureOnlineStoreBigtableInput` via:
//
//	GoogleCloudAiplatformV1FeatureOnlineStoreBigtableArgs{...}
type GoogleCloudAiplatformV1FeatureOnlineStoreBigtableInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1FeatureOnlineStoreBigtableOutput() GoogleCloudAiplatformV1FeatureOnlineStoreBigtableOutput
	ToGoogleCloudAiplatformV1FeatureOnlineStoreBigtableOutputWithContext(context.Context) GoogleCloudAiplatformV1FeatureOnlineStoreBigtableOutput
}

type GoogleCloudAiplatformV1FeatureOnlineStoreBigtableArgs struct {
	// Autoscaling config applied to Bigtable Instance.
	AutoScaling GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingInput `pulumi:"autoScaling"`
}

func (GoogleCloudAiplatformV1FeatureOnlineStoreBigtableArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1FeatureOnlineStoreBigtable)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1FeatureOnlineStoreBigtableArgs) ToGoogleCloudAiplatformV1FeatureOnlineStoreBigtableOutput() GoogleCloudAiplatformV1FeatureOnlineStoreBigtableOutput {
	return i.ToGoogleCloudAiplatformV1FeatureOnlineStoreBigtableOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1FeatureOnlineStoreBigtableArgs) ToGoogleCloudAiplatformV1FeatureOnlineStoreBigtableOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeatureOnlineStoreBigtableOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1FeatureOnlineStoreBigtableOutput)
}

func (i GoogleCloudAiplatformV1FeatureOnlineStoreBigtableArgs) ToGoogleCloudAiplatformV1FeatureOnlineStoreBigtablePtrOutput() GoogleCloudAiplatformV1FeatureOnlineStoreBigtablePtrOutput {
	return i.ToGoogleCloudAiplatformV1FeatureOnlineStoreBigtablePtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1FeatureOnlineStoreBigtableArgs) ToGoogleCloudAiplatformV1FeatureOnlineStoreBigtablePtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeatureOnlineStoreBigtablePtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1FeatureOnlineStoreBigtableOutput).ToGoogleCloudAiplatformV1FeatureOnlineStoreBigtablePtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1FeatureOnlineStoreBigtablePtrInput is an input type that accepts GoogleCloudAiplatformV1FeatureOnlineStoreBigtableArgs, GoogleCloudAiplatformV1FeatureOnlineStoreBigtablePtr and GoogleCloudAiplatformV1FeatureOnlineStoreBigtablePtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1FeatureOnlineStoreBigtablePtrInput` via:
//
//	        GoogleCloudAiplatformV1FeatureOnlineStoreBigtableArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1FeatureOnlineStoreBigtablePtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1FeatureOnlineStoreBigtablePtrOutput() GoogleCloudAiplatformV1FeatureOnlineStoreBigtablePtrOutput
	ToGoogleCloudAiplatformV1FeatureOnlineStoreBigtablePtrOutputWithContext(context.Context) GoogleCloudAiplatformV1FeatureOnlineStoreBigtablePtrOutput
}

type googleCloudAiplatformV1FeatureOnlineStoreBigtablePtrType GoogleCloudAiplatformV1FeatureOnlineStoreBigtableArgs

func GoogleCloudAiplatformV1FeatureOnlineStoreBigtablePtr(v *GoogleCloudAiplatformV1FeatureOnlineStoreBigtableArgs) GoogleCloudAiplatformV1FeatureOnlineStoreBigtablePtrInput {
	return (*googleCloudAiplatformV1FeatureOnlineStoreBigtablePtrType)(v)
}

func (*googleCloudAiplatformV1FeatureOnlineStoreBigtablePtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1FeatureOnlineStoreBigtable)(nil)).Elem()
}

func (i *googleCloudAiplatformV1FeatureOnlineStoreBigtablePtrType) ToGoogleCloudAiplatformV1FeatureOnlineStoreBigtablePtrOutput() GoogleCloudAiplatformV1FeatureOnlineStoreBigtablePtrOutput {
	return i.ToGoogleCloudAiplatformV1FeatureOnlineStoreBigtablePtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1FeatureOnlineStoreBigtablePtrType) ToGoogleCloudAiplatformV1FeatureOnlineStoreBigtablePtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeatureOnlineStoreBigtablePtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1FeatureOnlineStoreBigtablePtrOutput)
}

type GoogleCloudAiplatformV1FeatureOnlineStoreBigtableOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1FeatureOnlineStoreBigtableOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1FeatureOnlineStoreBigtable)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1FeatureOnlineStoreBigtableOutput) ToGoogleCloudAiplatformV1FeatureOnlineStoreBigtableOutput() GoogleCloudAiplatformV1FeatureOnlineStoreBigtableOutput {
	return o
}

func (o GoogleCloudAiplatformV1FeatureOnlineStoreBigtableOutput) ToGoogleCloudAiplatformV1FeatureOnlineStoreBigtableOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeatureOnlineStoreBigtableOutput {
	return o
}

func (o GoogleCloudAiplatformV1FeatureOnlineStoreBigtableOutput) ToGoogleCloudAiplatformV1FeatureOnlineStoreBigtablePtrOutput() GoogleCloudAiplatformV1FeatureOnlineStoreBigtablePtrOutput {
	return o.ToGoogleCloudAiplatformV1FeatureOnlineStoreBigtablePtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1FeatureOnlineStoreBigtableOutput) ToGoogleCloudAiplatformV1FeatureOnlineStoreBigtablePtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeatureOnlineStoreBigtablePtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1FeatureOnlineStoreBigtable) *GoogleCloudAiplatformV1FeatureOnlineStoreBigtable {
		return &v
	}).(GoogleCloudAiplatformV1FeatureOnlineStoreBigtablePtrOutput)
}

// Autoscaling config applied to Bigtable Instance.
func (o GoogleCloudAiplatformV1FeatureOnlineStoreBigtableOutput) AutoScaling() GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1FeatureOnlineStoreBigtable) GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScaling {
		return v.AutoScaling
	}).(GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingOutput)
}

type GoogleCloudAiplatformV1FeatureOnlineStoreBigtablePtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1FeatureOnlineStoreBigtablePtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1FeatureOnlineStoreBigtable)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1FeatureOnlineStoreBigtablePtrOutput) ToGoogleCloudAiplatformV1FeatureOnlineStoreBigtablePtrOutput() GoogleCloudAiplatformV1FeatureOnlineStoreBigtablePtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1FeatureOnlineStoreBigtablePtrOutput) ToGoogleCloudAiplatformV1FeatureOnlineStoreBigtablePtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeatureOnlineStoreBigtablePtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1FeatureOnlineStoreBigtablePtrOutput) Elem() GoogleCloudAiplatformV1FeatureOnlineStoreBigtableOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1FeatureOnlineStoreBigtable) GoogleCloudAiplatformV1FeatureOnlineStoreBigtable {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1FeatureOnlineStoreBigtable
		return ret
	}).(GoogleCloudAiplatformV1FeatureOnlineStoreBigtableOutput)
}

// Autoscaling config applied to Bigtable Instance.
func (o GoogleCloudAiplatformV1FeatureOnlineStoreBigtablePtrOutput) AutoScaling() GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1FeatureOnlineStoreBigtable) *GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScaling {
		if v == nil {
			return nil
		}
		return &v.AutoScaling
	}).(GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingPtrOutput)
}

type GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScaling struct {
	// Optional. A percentage of the cluster's CPU capacity. Can be from 10% to 80%. When a cluster's CPU utilization exceeds the target that you have set, Bigtable immediately adds nodes to the cluster. When CPU utilization is substantially lower than the target, Bigtable removes nodes. If not set will default to 50%.
	CpuUtilizationTarget *int `pulumi:"cpuUtilizationTarget"`
	// The maximum number of nodes to scale up to. Must be greater than or equal to min_node_count, and less than or equal to 10 times of 'min_node_count'.
	MaxNodeCount int `pulumi:"maxNodeCount"`
	// The minimum number of nodes to scale down to. Must be greater than or equal to 1.
	MinNodeCount int `pulumi:"minNodeCount"`
}

// GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingInput is an input type that accepts GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingArgs and GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingInput` via:
//
//	GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingArgs{...}
type GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingOutput() GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingOutput
	ToGoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingOutputWithContext(context.Context) GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingOutput
}

type GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingArgs struct {
	// Optional. A percentage of the cluster's CPU capacity. Can be from 10% to 80%. When a cluster's CPU utilization exceeds the target that you have set, Bigtable immediately adds nodes to the cluster. When CPU utilization is substantially lower than the target, Bigtable removes nodes. If not set will default to 50%.
	CpuUtilizationTarget pulumi.IntPtrInput `pulumi:"cpuUtilizationTarget"`
	// The maximum number of nodes to scale up to. Must be greater than or equal to min_node_count, and less than or equal to 10 times of 'min_node_count'.
	MaxNodeCount pulumi.IntInput `pulumi:"maxNodeCount"`
	// The minimum number of nodes to scale down to. Must be greater than or equal to 1.
	MinNodeCount pulumi.IntInput `pulumi:"minNodeCount"`
}

func (GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScaling)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingArgs) ToGoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingOutput() GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingOutput {
	return i.ToGoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingArgs) ToGoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingOutput)
}

func (i GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingArgs) ToGoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingPtrOutput() GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingPtrOutput {
	return i.ToGoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingArgs) ToGoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingOutput).ToGoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingPtrInput is an input type that accepts GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingArgs, GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingPtr and GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingPtrInput` via:
//
//	        GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingPtrOutput() GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingPtrOutput
	ToGoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingPtrOutput
}

type googleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingPtrType GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingArgs

func GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingPtr(v *GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingArgs) GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingPtrInput {
	return (*googleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingPtrType)(v)
}

func (*googleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScaling)(nil)).Elem()
}

func (i *googleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingPtrType) ToGoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingPtrOutput() GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingPtrOutput {
	return i.ToGoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingPtrType) ToGoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingPtrOutput)
}

type GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScaling)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingOutput) ToGoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingOutput() GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingOutput {
	return o
}

func (o GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingOutput) ToGoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingOutput {
	return o
}

func (o GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingOutput) ToGoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingPtrOutput() GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingPtrOutput {
	return o.ToGoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingOutput) ToGoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScaling) *GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScaling {
		return &v
	}).(GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingPtrOutput)
}

// Optional. A percentage of the cluster's CPU capacity. Can be from 10% to 80%. When a cluster's CPU utilization exceeds the target that you have set, Bigtable immediately adds nodes to the cluster. When CPU utilization is substantially lower than the target, Bigtable removes nodes. If not set will default to 50%.
func (o GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingOutput) CpuUtilizationTarget() pulumi.IntPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScaling) *int {
		return v.CpuUtilizationTarget
	}).(pulumi.IntPtrOutput)
}

// The maximum number of nodes to scale up to. Must be greater than or equal to min_node_count, and less than or equal to 10 times of 'min_node_count'.
func (o GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingOutput) MaxNodeCount() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScaling) int { return v.MaxNodeCount }).(pulumi.IntOutput)
}

// The minimum number of nodes to scale down to. Must be greater than or equal to 1.
func (o GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingOutput) MinNodeCount() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScaling) int { return v.MinNodeCount }).(pulumi.IntOutput)
}

type GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScaling)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingPtrOutput) ToGoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingPtrOutput() GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingPtrOutput) ToGoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingPtrOutput) Elem() GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScaling) GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScaling {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScaling
		return ret
	}).(GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingOutput)
}

// Optional. A percentage of the cluster's CPU capacity. Can be from 10% to 80%. When a cluster's CPU utilization exceeds the target that you have set, Bigtable immediately adds nodes to the cluster. When CPU utilization is substantially lower than the target, Bigtable removes nodes. If not set will default to 50%.
func (o GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingPtrOutput) CpuUtilizationTarget() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScaling) *int {
		if v == nil {
			return nil
		}
		return v.CpuUtilizationTarget
	}).(pulumi.IntPtrOutput)
}

// The maximum number of nodes to scale up to. Must be greater than or equal to min_node_count, and less than or equal to 10 times of 'min_node_count'.
func (o GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingPtrOutput) MaxNodeCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScaling) *int {
		if v == nil {
			return nil
		}
		return &v.MaxNodeCount
	}).(pulumi.IntPtrOutput)
}

// The minimum number of nodes to scale down to. Must be greater than or equal to 1.
func (o GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingPtrOutput) MinNodeCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScaling) *int {
		if v == nil {
			return nil
		}
		return &v.MinNodeCount
	}).(pulumi.IntPtrOutput)
}

type GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingResponse struct {
	// Optional. A percentage of the cluster's CPU capacity. Can be from 10% to 80%. When a cluster's CPU utilization exceeds the target that you have set, Bigtable immediately adds nodes to the cluster. When CPU utilization is substantially lower than the target, Bigtable removes nodes. If not set will default to 50%.
	CpuUtilizationTarget int `pulumi:"cpuUtilizationTarget"`
	// The maximum number of nodes to scale up to. Must be greater than or equal to min_node_count, and less than or equal to 10 times of 'min_node_count'.
	MaxNodeCount int `pulumi:"maxNodeCount"`
	// The minimum number of nodes to scale down to. Must be greater than or equal to 1.
	MinNodeCount int `pulumi:"minNodeCount"`
}

type GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingResponseOutput) ToGoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingResponseOutput() GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingResponseOutput) ToGoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingResponseOutput {
	return o
}

// Optional. A percentage of the cluster's CPU capacity. Can be from 10% to 80%. When a cluster's CPU utilization exceeds the target that you have set, Bigtable immediately adds nodes to the cluster. When CPU utilization is substantially lower than the target, Bigtable removes nodes. If not set will default to 50%.
func (o GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingResponseOutput) CpuUtilizationTarget() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingResponse) int {
		return v.CpuUtilizationTarget
	}).(pulumi.IntOutput)
}

// The maximum number of nodes to scale up to. Must be greater than or equal to min_node_count, and less than or equal to 10 times of 'min_node_count'.
func (o GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingResponseOutput) MaxNodeCount() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingResponse) int {
		return v.MaxNodeCount
	}).(pulumi.IntOutput)
}

// The minimum number of nodes to scale down to. Must be greater than or equal to 1.
func (o GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingResponseOutput) MinNodeCount() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingResponse) int {
		return v.MinNodeCount
	}).(pulumi.IntOutput)
}

type GoogleCloudAiplatformV1FeatureOnlineStoreBigtableResponse struct {
	// Autoscaling config applied to Bigtable Instance.
	AutoScaling GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingResponse `pulumi:"autoScaling"`
}

type GoogleCloudAiplatformV1FeatureOnlineStoreBigtableResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1FeatureOnlineStoreBigtableResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1FeatureOnlineStoreBigtableResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1FeatureOnlineStoreBigtableResponseOutput) ToGoogleCloudAiplatformV1FeatureOnlineStoreBigtableResponseOutput() GoogleCloudAiplatformV1FeatureOnlineStoreBigtableResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1FeatureOnlineStoreBigtableResponseOutput) ToGoogleCloudAiplatformV1FeatureOnlineStoreBigtableResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeatureOnlineStoreBigtableResponseOutput {
	return o
}

// Autoscaling config applied to Bigtable Instance.
func (o GoogleCloudAiplatformV1FeatureOnlineStoreBigtableResponseOutput) AutoScaling() GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1FeatureOnlineStoreBigtableResponse) GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingResponse {
		return v.AutoScaling
	}).(GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingResponseOutput)
}

// Stats and Anomaly generated at specific timestamp for specific Feature. The start_time and end_time are used to define the time range of the dataset that current stats belongs to, e.g. prediction traffic is bucketed into prediction datasets by time window. If the Dataset is not defined by time window, start_time = end_time. Timestamp of the stats and anomalies always refers to end_time. Raw stats and anomalies are stored in stats_uri or anomaly_uri in the tensorflow defined protos. Field data_stats contains almost identical information with the raw stats in Vertex AI defined proto, for UI to display.
type GoogleCloudAiplatformV1FeatureStatsAnomalyResponse struct {
	// This is the threshold used when detecting anomalies. The threshold can be changed by user, so this one might be different from ThresholdConfig.value.
	AnomalyDetectionThreshold float64 `pulumi:"anomalyDetectionThreshold"`
	// Path of the anomaly file for current feature values in Cloud Storage bucket. Format: gs:////anomalies. Example: gs://monitoring_bucket/feature_name/anomalies. Stats are stored as binary format with Protobuf message Anoamlies are stored as binary format with Protobuf message [tensorflow.metadata.v0.AnomalyInfo] (https://github.com/tensorflow/metadata/blob/master/tensorflow_metadata/proto/v0/anomalies.proto).
	AnomalyUri string `pulumi:"anomalyUri"`
	// Deviation from the current stats to baseline stats. 1. For categorical feature, the distribution distance is calculated by L-inifinity norm. 2. For numerical feature, the distribution distance is calculated by Jensen–Shannon divergence.
	DistributionDeviation float64 `pulumi:"distributionDeviation"`
	// The end timestamp of window where stats were generated. For objectives where time window doesn't make sense (e.g. Featurestore Snapshot Monitoring), end_time indicates the timestamp of the data used to generate stats (e.g. timestamp we take snapshots for feature values).
	EndTime string `pulumi:"endTime"`
	// Feature importance score, only populated when cross-feature monitoring is enabled. For now only used to represent feature attribution score within range [0, 1] for ModelDeploymentMonitoringObjectiveType.FEATURE_ATTRIBUTION_SKEW and ModelDeploymentMonitoringObjectiveType.FEATURE_ATTRIBUTION_DRIFT.
	Score float64 `pulumi:"score"`
	// The start timestamp of window where stats were generated. For objectives where time window doesn't make sense (e.g. Featurestore Snapshot Monitoring), start_time is only used to indicate the monitoring intervals, so it always equals to (end_time - monitoring_interval).
	StartTime string `pulumi:"startTime"`
	// Path of the stats file for current feature values in Cloud Storage bucket. Format: gs:////stats. Example: gs://monitoring_bucket/feature_name/stats. Stats are stored as binary format with Protobuf message [tensorflow.metadata.v0.FeatureNameStatistics](https://github.com/tensorflow/metadata/blob/master/tensorflow_metadata/proto/v0/statistics.proto).
	StatsUri string `pulumi:"statsUri"`
}

// Stats and Anomaly generated at specific timestamp for specific Feature. The start_time and end_time are used to define the time range of the dataset that current stats belongs to, e.g. prediction traffic is bucketed into prediction datasets by time window. If the Dataset is not defined by time window, start_time = end_time. Timestamp of the stats and anomalies always refers to end_time. Raw stats and anomalies are stored in stats_uri or anomaly_uri in the tensorflow defined protos. Field data_stats contains almost identical information with the raw stats in Vertex AI defined proto, for UI to display.
type GoogleCloudAiplatformV1FeatureStatsAnomalyResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1FeatureStatsAnomalyResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1FeatureStatsAnomalyResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1FeatureStatsAnomalyResponseOutput) ToGoogleCloudAiplatformV1FeatureStatsAnomalyResponseOutput() GoogleCloudAiplatformV1FeatureStatsAnomalyResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1FeatureStatsAnomalyResponseOutput) ToGoogleCloudAiplatformV1FeatureStatsAnomalyResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeatureStatsAnomalyResponseOutput {
	return o
}

// This is the threshold used when detecting anomalies. The threshold can be changed by user, so this one might be different from ThresholdConfig.value.
func (o GoogleCloudAiplatformV1FeatureStatsAnomalyResponseOutput) AnomalyDetectionThreshold() pulumi.Float64Output {
	return o.ApplyT(func(v GoogleCloudAiplatformV1FeatureStatsAnomalyResponse) float64 { return v.AnomalyDetectionThreshold }).(pulumi.Float64Output)
}

// Path of the anomaly file for current feature values in Cloud Storage bucket. Format: gs:////anomalies. Example: gs://monitoring_bucket/feature_name/anomalies. Stats are stored as binary format with Protobuf message Anoamlies are stored as binary format with Protobuf message [tensorflow.metadata.v0.AnomalyInfo] (https://github.com/tensorflow/metadata/blob/master/tensorflow_metadata/proto/v0/anomalies.proto).
func (o GoogleCloudAiplatformV1FeatureStatsAnomalyResponseOutput) AnomalyUri() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1FeatureStatsAnomalyResponse) string { return v.AnomalyUri }).(pulumi.StringOutput)
}

// Deviation from the current stats to baseline stats. 1. For categorical feature, the distribution distance is calculated by L-inifinity norm. 2. For numerical feature, the distribution distance is calculated by Jensen–Shannon divergence.
func (o GoogleCloudAiplatformV1FeatureStatsAnomalyResponseOutput) DistributionDeviation() pulumi.Float64Output {
	return o.ApplyT(func(v GoogleCloudAiplatformV1FeatureStatsAnomalyResponse) float64 { return v.DistributionDeviation }).(pulumi.Float64Output)
}

// The end timestamp of window where stats were generated. For objectives where time window doesn't make sense (e.g. Featurestore Snapshot Monitoring), end_time indicates the timestamp of the data used to generate stats (e.g. timestamp we take snapshots for feature values).
func (o GoogleCloudAiplatformV1FeatureStatsAnomalyResponseOutput) EndTime() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1FeatureStatsAnomalyResponse) string { return v.EndTime }).(pulumi.StringOutput)
}

// Feature importance score, only populated when cross-feature monitoring is enabled. For now only used to represent feature attribution score within range [0, 1] for ModelDeploymentMonitoringObjectiveType.FEATURE_ATTRIBUTION_SKEW and ModelDeploymentMonitoringObjectiveType.FEATURE_ATTRIBUTION_DRIFT.
func (o GoogleCloudAiplatformV1FeatureStatsAnomalyResponseOutput) Score() pulumi.Float64Output {
	return o.ApplyT(func(v GoogleCloudAiplatformV1FeatureStatsAnomalyResponse) float64 { return v.Score }).(pulumi.Float64Output)
}

// The start timestamp of window where stats were generated. For objectives where time window doesn't make sense (e.g. Featurestore Snapshot Monitoring), start_time is only used to indicate the monitoring intervals, so it always equals to (end_time - monitoring_interval).
func (o GoogleCloudAiplatformV1FeatureStatsAnomalyResponseOutput) StartTime() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1FeatureStatsAnomalyResponse) string { return v.StartTime }).(pulumi.StringOutput)
}

// Path of the stats file for current feature values in Cloud Storage bucket. Format: gs:////stats. Example: gs://monitoring_bucket/feature_name/stats. Stats are stored as binary format with Protobuf message [tensorflow.metadata.v0.FeatureNameStatistics](https://github.com/tensorflow/metadata/blob/master/tensorflow_metadata/proto/v0/statistics.proto).
func (o GoogleCloudAiplatformV1FeatureStatsAnomalyResponseOutput) StatsUri() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1FeatureStatsAnomalyResponse) string { return v.StatsUri }).(pulumi.StringOutput)
}

type GoogleCloudAiplatformV1FeatureViewBigQuerySource struct {
	// Columns to construct entity_id / row keys. Start by supporting 1 only.
	EntityIdColumns []string `pulumi:"entityIdColumns"`
	// The BigQuery view URI that will be materialized on each sync trigger based on FeatureView.SyncConfig.
	Uri string `pulumi:"uri"`
}

// GoogleCloudAiplatformV1FeatureViewBigQuerySourceInput is an input type that accepts GoogleCloudAiplatformV1FeatureViewBigQuerySourceArgs and GoogleCloudAiplatformV1FeatureViewBigQuerySourceOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1FeatureViewBigQuerySourceInput` via:
//
//	GoogleCloudAiplatformV1FeatureViewBigQuerySourceArgs{...}
type GoogleCloudAiplatformV1FeatureViewBigQuerySourceInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1FeatureViewBigQuerySourceOutput() GoogleCloudAiplatformV1FeatureViewBigQuerySourceOutput
	ToGoogleCloudAiplatformV1FeatureViewBigQuerySourceOutputWithContext(context.Context) GoogleCloudAiplatformV1FeatureViewBigQuerySourceOutput
}

type GoogleCloudAiplatformV1FeatureViewBigQuerySourceArgs struct {
	// Columns to construct entity_id / row keys. Start by supporting 1 only.
	EntityIdColumns pulumi.StringArrayInput `pulumi:"entityIdColumns"`
	// The BigQuery view URI that will be materialized on each sync trigger based on FeatureView.SyncConfig.
	Uri pulumi.StringInput `pulumi:"uri"`
}

func (GoogleCloudAiplatformV1FeatureViewBigQuerySourceArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1FeatureViewBigQuerySource)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1FeatureViewBigQuerySourceArgs) ToGoogleCloudAiplatformV1FeatureViewBigQuerySourceOutput() GoogleCloudAiplatformV1FeatureViewBigQuerySourceOutput {
	return i.ToGoogleCloudAiplatformV1FeatureViewBigQuerySourceOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1FeatureViewBigQuerySourceArgs) ToGoogleCloudAiplatformV1FeatureViewBigQuerySourceOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeatureViewBigQuerySourceOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1FeatureViewBigQuerySourceOutput)
}

func (i GoogleCloudAiplatformV1FeatureViewBigQuerySourceArgs) ToGoogleCloudAiplatformV1FeatureViewBigQuerySourcePtrOutput() GoogleCloudAiplatformV1FeatureViewBigQuerySourcePtrOutput {
	return i.ToGoogleCloudAiplatformV1FeatureViewBigQuerySourcePtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1FeatureViewBigQuerySourceArgs) ToGoogleCloudAiplatformV1FeatureViewBigQuerySourcePtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeatureViewBigQuerySourcePtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1FeatureViewBigQuerySourceOutput).ToGoogleCloudAiplatformV1FeatureViewBigQuerySourcePtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1FeatureViewBigQuerySourcePtrInput is an input type that accepts GoogleCloudAiplatformV1FeatureViewBigQuerySourceArgs, GoogleCloudAiplatformV1FeatureViewBigQuerySourcePtr and GoogleCloudAiplatformV1FeatureViewBigQuerySourcePtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1FeatureViewBigQuerySourcePtrInput` via:
//
//	        GoogleCloudAiplatformV1FeatureViewBigQuerySourceArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1FeatureViewBigQuerySourcePtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1FeatureViewBigQuerySourcePtrOutput() GoogleCloudAiplatformV1FeatureViewBigQuerySourcePtrOutput
	ToGoogleCloudAiplatformV1FeatureViewBigQuerySourcePtrOutputWithContext(context.Context) GoogleCloudAiplatformV1FeatureViewBigQuerySourcePtrOutput
}

type googleCloudAiplatformV1FeatureViewBigQuerySourcePtrType GoogleCloudAiplatformV1FeatureViewBigQuerySourceArgs

func GoogleCloudAiplatformV1FeatureViewBigQuerySourcePtr(v *GoogleCloudAiplatformV1FeatureViewBigQuerySourceArgs) GoogleCloudAiplatformV1FeatureViewBigQuerySourcePtrInput {
	return (*googleCloudAiplatformV1FeatureViewBigQuerySourcePtrType)(v)
}

func (*googleCloudAiplatformV1FeatureViewBigQuerySourcePtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1FeatureViewBigQuerySource)(nil)).Elem()
}

func (i *googleCloudAiplatformV1FeatureViewBigQuerySourcePtrType) ToGoogleCloudAiplatformV1FeatureViewBigQuerySourcePtrOutput() GoogleCloudAiplatformV1FeatureViewBigQuerySourcePtrOutput {
	return i.ToGoogleCloudAiplatformV1FeatureViewBigQuerySourcePtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1FeatureViewBigQuerySourcePtrType) ToGoogleCloudAiplatformV1FeatureViewBigQuerySourcePtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeatureViewBigQuerySourcePtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1FeatureViewBigQuerySourcePtrOutput)
}

type GoogleCloudAiplatformV1FeatureViewBigQuerySourceOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1FeatureViewBigQuerySourceOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1FeatureViewBigQuerySource)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1FeatureViewBigQuerySourceOutput) ToGoogleCloudAiplatformV1FeatureViewBigQuerySourceOutput() GoogleCloudAiplatformV1FeatureViewBigQuerySourceOutput {
	return o
}

func (o GoogleCloudAiplatformV1FeatureViewBigQuerySourceOutput) ToGoogleCloudAiplatformV1FeatureViewBigQuerySourceOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeatureViewBigQuerySourceOutput {
	return o
}

func (o GoogleCloudAiplatformV1FeatureViewBigQuerySourceOutput) ToGoogleCloudAiplatformV1FeatureViewBigQuerySourcePtrOutput() GoogleCloudAiplatformV1FeatureViewBigQuerySourcePtrOutput {
	return o.ToGoogleCloudAiplatformV1FeatureViewBigQuerySourcePtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1FeatureViewBigQuerySourceOutput) ToGoogleCloudAiplatformV1FeatureViewBigQuerySourcePtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeatureViewBigQuerySourcePtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1FeatureViewBigQuerySource) *GoogleCloudAiplatformV1FeatureViewBigQuerySource {
		return &v
	}).(GoogleCloudAiplatformV1FeatureViewBigQuerySourcePtrOutput)
}

// Columns to construct entity_id / row keys. Start by supporting 1 only.
func (o GoogleCloudAiplatformV1FeatureViewBigQuerySourceOutput) EntityIdColumns() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1FeatureViewBigQuerySource) []string { return v.EntityIdColumns }).(pulumi.StringArrayOutput)
}

// The BigQuery view URI that will be materialized on each sync trigger based on FeatureView.SyncConfig.
func (o GoogleCloudAiplatformV1FeatureViewBigQuerySourceOutput) Uri() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1FeatureViewBigQuerySource) string { return v.Uri }).(pulumi.StringOutput)
}

type GoogleCloudAiplatformV1FeatureViewBigQuerySourcePtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1FeatureViewBigQuerySourcePtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1FeatureViewBigQuerySource)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1FeatureViewBigQuerySourcePtrOutput) ToGoogleCloudAiplatformV1FeatureViewBigQuerySourcePtrOutput() GoogleCloudAiplatformV1FeatureViewBigQuerySourcePtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1FeatureViewBigQuerySourcePtrOutput) ToGoogleCloudAiplatformV1FeatureViewBigQuerySourcePtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeatureViewBigQuerySourcePtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1FeatureViewBigQuerySourcePtrOutput) Elem() GoogleCloudAiplatformV1FeatureViewBigQuerySourceOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1FeatureViewBigQuerySource) GoogleCloudAiplatformV1FeatureViewBigQuerySource {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1FeatureViewBigQuerySource
		return ret
	}).(GoogleCloudAiplatformV1FeatureViewBigQuerySourceOutput)
}

// Columns to construct entity_id / row keys. Start by supporting 1 only.
func (o GoogleCloudAiplatformV1FeatureViewBigQuerySourcePtrOutput) EntityIdColumns() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1FeatureViewBigQuerySource) []string {
		if v == nil {
			return nil
		}
		return v.EntityIdColumns
	}).(pulumi.StringArrayOutput)
}

// The BigQuery view URI that will be materialized on each sync trigger based on FeatureView.SyncConfig.
func (o GoogleCloudAiplatformV1FeatureViewBigQuerySourcePtrOutput) Uri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1FeatureViewBigQuerySource) *string {
		if v == nil {
			return nil
		}
		return &v.Uri
	}).(pulumi.StringPtrOutput)
}

type GoogleCloudAiplatformV1FeatureViewBigQuerySourceResponse struct {
	// Columns to construct entity_id / row keys. Start by supporting 1 only.
	EntityIdColumns []string `pulumi:"entityIdColumns"`
	// The BigQuery view URI that will be materialized on each sync trigger based on FeatureView.SyncConfig.
	Uri string `pulumi:"uri"`
}

type GoogleCloudAiplatformV1FeatureViewBigQuerySourceResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1FeatureViewBigQuerySourceResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1FeatureViewBigQuerySourceResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1FeatureViewBigQuerySourceResponseOutput) ToGoogleCloudAiplatformV1FeatureViewBigQuerySourceResponseOutput() GoogleCloudAiplatformV1FeatureViewBigQuerySourceResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1FeatureViewBigQuerySourceResponseOutput) ToGoogleCloudAiplatformV1FeatureViewBigQuerySourceResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeatureViewBigQuerySourceResponseOutput {
	return o
}

// Columns to construct entity_id / row keys. Start by supporting 1 only.
func (o GoogleCloudAiplatformV1FeatureViewBigQuerySourceResponseOutput) EntityIdColumns() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1FeatureViewBigQuerySourceResponse) []string { return v.EntityIdColumns }).(pulumi.StringArrayOutput)
}

// The BigQuery view URI that will be materialized on each sync trigger based on FeatureView.SyncConfig.
func (o GoogleCloudAiplatformV1FeatureViewBigQuerySourceResponseOutput) Uri() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1FeatureViewBigQuerySourceResponse) string { return v.Uri }).(pulumi.StringOutput)
}

// A Feature Registry source for features that need to be synced to Online Store.
type GoogleCloudAiplatformV1FeatureViewFeatureRegistrySource struct {
	// List of features that need to be synced to Online Store.
	FeatureGroups []GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroup `pulumi:"featureGroups"`
}

// GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceInput is an input type that accepts GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceArgs and GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceInput` via:
//
//	GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceArgs{...}
type GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceOutput() GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceOutput
	ToGoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceOutputWithContext(context.Context) GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceOutput
}

// A Feature Registry source for features that need to be synced to Online Store.
type GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceArgs struct {
	// List of features that need to be synced to Online Store.
	FeatureGroups GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupArrayInput `pulumi:"featureGroups"`
}

func (GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1FeatureViewFeatureRegistrySource)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceArgs) ToGoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceOutput() GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceOutput {
	return i.ToGoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceArgs) ToGoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceOutput)
}

func (i GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceArgs) ToGoogleCloudAiplatformV1FeatureViewFeatureRegistrySourcePtrOutput() GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourcePtrOutput {
	return i.ToGoogleCloudAiplatformV1FeatureViewFeatureRegistrySourcePtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceArgs) ToGoogleCloudAiplatformV1FeatureViewFeatureRegistrySourcePtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourcePtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceOutput).ToGoogleCloudAiplatformV1FeatureViewFeatureRegistrySourcePtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourcePtrInput is an input type that accepts GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceArgs, GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourcePtr and GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourcePtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourcePtrInput` via:
//
//	        GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourcePtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1FeatureViewFeatureRegistrySourcePtrOutput() GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourcePtrOutput
	ToGoogleCloudAiplatformV1FeatureViewFeatureRegistrySourcePtrOutputWithContext(context.Context) GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourcePtrOutput
}

type googleCloudAiplatformV1FeatureViewFeatureRegistrySourcePtrType GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceArgs

func GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourcePtr(v *GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceArgs) GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourcePtrInput {
	return (*googleCloudAiplatformV1FeatureViewFeatureRegistrySourcePtrType)(v)
}

func (*googleCloudAiplatformV1FeatureViewFeatureRegistrySourcePtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1FeatureViewFeatureRegistrySource)(nil)).Elem()
}

func (i *googleCloudAiplatformV1FeatureViewFeatureRegistrySourcePtrType) ToGoogleCloudAiplatformV1FeatureViewFeatureRegistrySourcePtrOutput() GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourcePtrOutput {
	return i.ToGoogleCloudAiplatformV1FeatureViewFeatureRegistrySourcePtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1FeatureViewFeatureRegistrySourcePtrType) ToGoogleCloudAiplatformV1FeatureViewFeatureRegistrySourcePtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourcePtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourcePtrOutput)
}

// A Feature Registry source for features that need to be synced to Online Store.
type GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1FeatureViewFeatureRegistrySource)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceOutput) ToGoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceOutput() GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceOutput {
	return o
}

func (o GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceOutput) ToGoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceOutput {
	return o
}

func (o GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceOutput) ToGoogleCloudAiplatformV1FeatureViewFeatureRegistrySourcePtrOutput() GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourcePtrOutput {
	return o.ToGoogleCloudAiplatformV1FeatureViewFeatureRegistrySourcePtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceOutput) ToGoogleCloudAiplatformV1FeatureViewFeatureRegistrySourcePtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourcePtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1FeatureViewFeatureRegistrySource) *GoogleCloudAiplatformV1FeatureViewFeatureRegistrySource {
		return &v
	}).(GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourcePtrOutput)
}

// List of features that need to be synced to Online Store.
func (o GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceOutput) FeatureGroups() GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1FeatureViewFeatureRegistrySource) []GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroup {
		return v.FeatureGroups
	}).(GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupArrayOutput)
}

type GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourcePtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourcePtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1FeatureViewFeatureRegistrySource)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourcePtrOutput) ToGoogleCloudAiplatformV1FeatureViewFeatureRegistrySourcePtrOutput() GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourcePtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourcePtrOutput) ToGoogleCloudAiplatformV1FeatureViewFeatureRegistrySourcePtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourcePtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourcePtrOutput) Elem() GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1FeatureViewFeatureRegistrySource) GoogleCloudAiplatformV1FeatureViewFeatureRegistrySource {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1FeatureViewFeatureRegistrySource
		return ret
	}).(GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceOutput)
}

// List of features that need to be synced to Online Store.
func (o GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourcePtrOutput) FeatureGroups() GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupArrayOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1FeatureViewFeatureRegistrySource) []GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroup {
		if v == nil {
			return nil
		}
		return v.FeatureGroups
	}).(GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupArrayOutput)
}

// Features belonging to a single feature group that will be synced to Online Store.
type GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroup struct {
	// Identifier of the feature group.
	FeatureGroupId string `pulumi:"featureGroupId"`
	// Identifiers of features under the feature group.
	FeatureIds []string `pulumi:"featureIds"`
}

// GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupInput is an input type that accepts GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupArgs and GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupInput` via:
//
//	GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupArgs{...}
type GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupOutput() GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupOutput
	ToGoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupOutputWithContext(context.Context) GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupOutput
}

// Features belonging to a single feature group that will be synced to Online Store.
type GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupArgs struct {
	// Identifier of the feature group.
	FeatureGroupId pulumi.StringInput `pulumi:"featureGroupId"`
	// Identifiers of features under the feature group.
	FeatureIds pulumi.StringArrayInput `pulumi:"featureIds"`
}

func (GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroup)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupArgs) ToGoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupOutput() GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupOutput {
	return i.ToGoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupArgs) ToGoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupOutput)
}

// GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupArrayInput is an input type that accepts GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupArray and GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupArrayOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupArrayInput` via:
//
//	GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupArray{ GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupArgs{...} }
type GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupArrayInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupArrayOutput() GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupArrayOutput
	ToGoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupArrayOutputWithContext(context.Context) GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupArrayOutput
}

type GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupArray []GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupInput

func (GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroup)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupArray) ToGoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupArrayOutput() GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupArrayOutput {
	return i.ToGoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupArrayOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupArray) ToGoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupArrayOutput)
}

// Features belonging to a single feature group that will be synced to Online Store.
type GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroup)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupOutput) ToGoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupOutput() GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupOutput {
	return o
}

func (o GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupOutput) ToGoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupOutput {
	return o
}

// Identifier of the feature group.
func (o GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupOutput) FeatureGroupId() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroup) string {
		return v.FeatureGroupId
	}).(pulumi.StringOutput)
}

// Identifiers of features under the feature group.
func (o GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupOutput) FeatureIds() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroup) []string {
		return v.FeatureIds
	}).(pulumi.StringArrayOutput)
}

type GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupArrayOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroup)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupArrayOutput) ToGoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupArrayOutput() GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupArrayOutput) ToGoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupArrayOutput) Index(i pulumi.IntInput) GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroup {
		return vs[0].([]GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroup)[vs[1].(int)]
	}).(GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupOutput)
}

// Features belonging to a single feature group that will be synced to Online Store.
type GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupResponse struct {
	// Identifier of the feature group.
	FeatureGroupId string `pulumi:"featureGroupId"`
	// Identifiers of features under the feature group.
	FeatureIds []string `pulumi:"featureIds"`
}

// Features belonging to a single feature group that will be synced to Online Store.
type GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupResponseOutput) ToGoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupResponseOutput() GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupResponseOutput) ToGoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupResponseOutput {
	return o
}

// Identifier of the feature group.
func (o GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupResponseOutput) FeatureGroupId() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupResponse) string {
		return v.FeatureGroupId
	}).(pulumi.StringOutput)
}

// Identifiers of features under the feature group.
func (o GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupResponseOutput) FeatureIds() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupResponse) []string {
		return v.FeatureIds
	}).(pulumi.StringArrayOutput)
}

type GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupResponseArrayOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupResponseArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupResponseArrayOutput) ToGoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupResponseArrayOutput() GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupResponseArrayOutput) ToGoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupResponseArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupResponseArrayOutput) Index(i pulumi.IntInput) GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupResponseOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupResponse {
		return vs[0].([]GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupResponse)[vs[1].(int)]
	}).(GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupResponseOutput)
}

// A Feature Registry source for features that need to be synced to Online Store.
type GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceResponse struct {
	// List of features that need to be synced to Online Store.
	FeatureGroups []GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupResponse `pulumi:"featureGroups"`
}

// A Feature Registry source for features that need to be synced to Online Store.
type GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceResponseOutput) ToGoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceResponseOutput() GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceResponseOutput) ToGoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceResponseOutput {
	return o
}

// List of features that need to be synced to Online Store.
func (o GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceResponseOutput) FeatureGroups() GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupResponseArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceResponse) []GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupResponse {
		return v.FeatureGroups
	}).(GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupResponseArrayOutput)
}

type GoogleCloudAiplatformV1FeatureViewSyncConfig struct {
	// Cron schedule (https://en.wikipedia.org/wiki/Cron) to launch scheduled runs. To explicitly set a timezone to the cron tab, apply a prefix in the cron tab: "CRON_TZ=${IANA_TIME_ZONE}" or "TZ=${IANA_TIME_ZONE}". The ${IANA_TIME_ZONE} may only be a valid string from IANA time zone database. For example, "CRON_TZ=America/New_York 1 * * * *", or "TZ=America/New_York 1 * * * *".
	Cron *string `pulumi:"cron"`
}

// GoogleCloudAiplatformV1FeatureViewSyncConfigInput is an input type that accepts GoogleCloudAiplatformV1FeatureViewSyncConfigArgs and GoogleCloudAiplatformV1FeatureViewSyncConfigOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1FeatureViewSyncConfigInput` via:
//
//	GoogleCloudAiplatformV1FeatureViewSyncConfigArgs{...}
type GoogleCloudAiplatformV1FeatureViewSyncConfigInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1FeatureViewSyncConfigOutput() GoogleCloudAiplatformV1FeatureViewSyncConfigOutput
	ToGoogleCloudAiplatformV1FeatureViewSyncConfigOutputWithContext(context.Context) GoogleCloudAiplatformV1FeatureViewSyncConfigOutput
}

type GoogleCloudAiplatformV1FeatureViewSyncConfigArgs struct {
	// Cron schedule (https://en.wikipedia.org/wiki/Cron) to launch scheduled runs. To explicitly set a timezone to the cron tab, apply a prefix in the cron tab: "CRON_TZ=${IANA_TIME_ZONE}" or "TZ=${IANA_TIME_ZONE}". The ${IANA_TIME_ZONE} may only be a valid string from IANA time zone database. For example, "CRON_TZ=America/New_York 1 * * * *", or "TZ=America/New_York 1 * * * *".
	Cron pulumi.StringPtrInput `pulumi:"cron"`
}

func (GoogleCloudAiplatformV1FeatureViewSyncConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1FeatureViewSyncConfig)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1FeatureViewSyncConfigArgs) ToGoogleCloudAiplatformV1FeatureViewSyncConfigOutput() GoogleCloudAiplatformV1FeatureViewSyncConfigOutput {
	return i.ToGoogleCloudAiplatformV1FeatureViewSyncConfigOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1FeatureViewSyncConfigArgs) ToGoogleCloudAiplatformV1FeatureViewSyncConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeatureViewSyncConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1FeatureViewSyncConfigOutput)
}

func (i GoogleCloudAiplatformV1FeatureViewSyncConfigArgs) ToGoogleCloudAiplatformV1FeatureViewSyncConfigPtrOutput() GoogleCloudAiplatformV1FeatureViewSyncConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1FeatureViewSyncConfigPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1FeatureViewSyncConfigArgs) ToGoogleCloudAiplatformV1FeatureViewSyncConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeatureViewSyncConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1FeatureViewSyncConfigOutput).ToGoogleCloudAiplatformV1FeatureViewSyncConfigPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1FeatureViewSyncConfigPtrInput is an input type that accepts GoogleCloudAiplatformV1FeatureViewSyncConfigArgs, GoogleCloudAiplatformV1FeatureViewSyncConfigPtr and GoogleCloudAiplatformV1FeatureViewSyncConfigPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1FeatureViewSyncConfigPtrInput` via:
//
//	        GoogleCloudAiplatformV1FeatureViewSyncConfigArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1FeatureViewSyncConfigPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1FeatureViewSyncConfigPtrOutput() GoogleCloudAiplatformV1FeatureViewSyncConfigPtrOutput
	ToGoogleCloudAiplatformV1FeatureViewSyncConfigPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1FeatureViewSyncConfigPtrOutput
}

type googleCloudAiplatformV1FeatureViewSyncConfigPtrType GoogleCloudAiplatformV1FeatureViewSyncConfigArgs

func GoogleCloudAiplatformV1FeatureViewSyncConfigPtr(v *GoogleCloudAiplatformV1FeatureViewSyncConfigArgs) GoogleCloudAiplatformV1FeatureViewSyncConfigPtrInput {
	return (*googleCloudAiplatformV1FeatureViewSyncConfigPtrType)(v)
}

func (*googleCloudAiplatformV1FeatureViewSyncConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1FeatureViewSyncConfig)(nil)).Elem()
}

func (i *googleCloudAiplatformV1FeatureViewSyncConfigPtrType) ToGoogleCloudAiplatformV1FeatureViewSyncConfigPtrOutput() GoogleCloudAiplatformV1FeatureViewSyncConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1FeatureViewSyncConfigPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1FeatureViewSyncConfigPtrType) ToGoogleCloudAiplatformV1FeatureViewSyncConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeatureViewSyncConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1FeatureViewSyncConfigPtrOutput)
}

type GoogleCloudAiplatformV1FeatureViewSyncConfigOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1FeatureViewSyncConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1FeatureViewSyncConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1FeatureViewSyncConfigOutput) ToGoogleCloudAiplatformV1FeatureViewSyncConfigOutput() GoogleCloudAiplatformV1FeatureViewSyncConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1FeatureViewSyncConfigOutput) ToGoogleCloudAiplatformV1FeatureViewSyncConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeatureViewSyncConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1FeatureViewSyncConfigOutput) ToGoogleCloudAiplatformV1FeatureViewSyncConfigPtrOutput() GoogleCloudAiplatformV1FeatureViewSyncConfigPtrOutput {
	return o.ToGoogleCloudAiplatformV1FeatureViewSyncConfigPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1FeatureViewSyncConfigOutput) ToGoogleCloudAiplatformV1FeatureViewSyncConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeatureViewSyncConfigPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1FeatureViewSyncConfig) *GoogleCloudAiplatformV1FeatureViewSyncConfig {
		return &v
	}).(GoogleCloudAiplatformV1FeatureViewSyncConfigPtrOutput)
}

// Cron schedule (https://en.wikipedia.org/wiki/Cron) to launch scheduled runs. To explicitly set a timezone to the cron tab, apply a prefix in the cron tab: "CRON_TZ=${IANA_TIME_ZONE}" or "TZ=${IANA_TIME_ZONE}". The ${IANA_TIME_ZONE} may only be a valid string from IANA time zone database. For example, "CRON_TZ=America/New_York 1 * * * *", or "TZ=America/New_York 1 * * * *".
func (o GoogleCloudAiplatformV1FeatureViewSyncConfigOutput) Cron() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1FeatureViewSyncConfig) *string { return v.Cron }).(pulumi.StringPtrOutput)
}

type GoogleCloudAiplatformV1FeatureViewSyncConfigPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1FeatureViewSyncConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1FeatureViewSyncConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1FeatureViewSyncConfigPtrOutput) ToGoogleCloudAiplatformV1FeatureViewSyncConfigPtrOutput() GoogleCloudAiplatformV1FeatureViewSyncConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1FeatureViewSyncConfigPtrOutput) ToGoogleCloudAiplatformV1FeatureViewSyncConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeatureViewSyncConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1FeatureViewSyncConfigPtrOutput) Elem() GoogleCloudAiplatformV1FeatureViewSyncConfigOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1FeatureViewSyncConfig) GoogleCloudAiplatformV1FeatureViewSyncConfig {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1FeatureViewSyncConfig
		return ret
	}).(GoogleCloudAiplatformV1FeatureViewSyncConfigOutput)
}

// Cron schedule (https://en.wikipedia.org/wiki/Cron) to launch scheduled runs. To explicitly set a timezone to the cron tab, apply a prefix in the cron tab: "CRON_TZ=${IANA_TIME_ZONE}" or "TZ=${IANA_TIME_ZONE}". The ${IANA_TIME_ZONE} may only be a valid string from IANA time zone database. For example, "CRON_TZ=America/New_York 1 * * * *", or "TZ=America/New_York 1 * * * *".
func (o GoogleCloudAiplatformV1FeatureViewSyncConfigPtrOutput) Cron() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1FeatureViewSyncConfig) *string {
		if v == nil {
			return nil
		}
		return v.Cron
	}).(pulumi.StringPtrOutput)
}

type GoogleCloudAiplatformV1FeatureViewSyncConfigResponse struct {
	// Cron schedule (https://en.wikipedia.org/wiki/Cron) to launch scheduled runs. To explicitly set a timezone to the cron tab, apply a prefix in the cron tab: "CRON_TZ=${IANA_TIME_ZONE}" or "TZ=${IANA_TIME_ZONE}". The ${IANA_TIME_ZONE} may only be a valid string from IANA time zone database. For example, "CRON_TZ=America/New_York 1 * * * *", or "TZ=America/New_York 1 * * * *".
	Cron string `pulumi:"cron"`
}

type GoogleCloudAiplatformV1FeatureViewSyncConfigResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1FeatureViewSyncConfigResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1FeatureViewSyncConfigResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1FeatureViewSyncConfigResponseOutput) ToGoogleCloudAiplatformV1FeatureViewSyncConfigResponseOutput() GoogleCloudAiplatformV1FeatureViewSyncConfigResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1FeatureViewSyncConfigResponseOutput) ToGoogleCloudAiplatformV1FeatureViewSyncConfigResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeatureViewSyncConfigResponseOutput {
	return o
}

// Cron schedule (https://en.wikipedia.org/wiki/Cron) to launch scheduled runs. To explicitly set a timezone to the cron tab, apply a prefix in the cron tab: "CRON_TZ=${IANA_TIME_ZONE}" or "TZ=${IANA_TIME_ZONE}". The ${IANA_TIME_ZONE} may only be a valid string from IANA time zone database. For example, "CRON_TZ=America/New_York 1 * * * *", or "TZ=America/New_York 1 * * * *".
func (o GoogleCloudAiplatformV1FeatureViewSyncConfigResponseOutput) Cron() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1FeatureViewSyncConfigResponse) string { return v.Cron }).(pulumi.StringOutput)
}

// Configuration of how features in Featurestore are monitored.
type GoogleCloudAiplatformV1FeaturestoreMonitoringConfig struct {
	// Threshold for categorical features of anomaly detection. This is shared by all types of Featurestore Monitoring for categorical features (i.e. Features with type (Feature.ValueType) BOOL or STRING).
	CategoricalThresholdConfig *GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfig `pulumi:"categoricalThresholdConfig"`
	// The config for ImportFeatures Analysis Based Feature Monitoring.
	ImportFeaturesAnalysis *GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysis `pulumi:"importFeaturesAnalysis"`
	// Threshold for numerical features of anomaly detection. This is shared by all objectives of Featurestore Monitoring for numerical features (i.e. Features with type (Feature.ValueType) DOUBLE or INT64).
	NumericalThresholdConfig *GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfig `pulumi:"numericalThresholdConfig"`
	// The config for Snapshot Analysis Based Feature Monitoring.
	SnapshotAnalysis *GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysis `pulumi:"snapshotAnalysis"`
}

// GoogleCloudAiplatformV1FeaturestoreMonitoringConfigInput is an input type that accepts GoogleCloudAiplatformV1FeaturestoreMonitoringConfigArgs and GoogleCloudAiplatformV1FeaturestoreMonitoringConfigOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1FeaturestoreMonitoringConfigInput` via:
//
//	GoogleCloudAiplatformV1FeaturestoreMonitoringConfigArgs{...}
type GoogleCloudAiplatformV1FeaturestoreMonitoringConfigInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1FeaturestoreMonitoringConfigOutput() GoogleCloudAiplatformV1FeaturestoreMonitoringConfigOutput
	ToGoogleCloudAiplatformV1FeaturestoreMonitoringConfigOutputWithContext(context.Context) GoogleCloudAiplatformV1FeaturestoreMonitoringConfigOutput
}

// Configuration of how features in Featurestore are monitored.
type GoogleCloudAiplatformV1FeaturestoreMonitoringConfigArgs struct {
	// Threshold for categorical features of anomaly detection. This is shared by all types of Featurestore Monitoring for categorical features (i.e. Features with type (Feature.ValueType) BOOL or STRING).
	CategoricalThresholdConfig GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigPtrInput `pulumi:"categoricalThresholdConfig"`
	// The config for ImportFeatures Analysis Based Feature Monitoring.
	ImportFeaturesAnalysis GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrInput `pulumi:"importFeaturesAnalysis"`
	// Threshold for numerical features of anomaly detection. This is shared by all objectives of Featurestore Monitoring for numerical features (i.e. Features with type (Feature.ValueType) DOUBLE or INT64).
	NumericalThresholdConfig GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigPtrInput `pulumi:"numericalThresholdConfig"`
	// The config for Snapshot Analysis Based Feature Monitoring.
	SnapshotAnalysis GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisPtrInput `pulumi:"snapshotAnalysis"`
}

func (GoogleCloudAiplatformV1FeaturestoreMonitoringConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1FeaturestoreMonitoringConfig)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1FeaturestoreMonitoringConfigArgs) ToGoogleCloudAiplatformV1FeaturestoreMonitoringConfigOutput() GoogleCloudAiplatformV1FeaturestoreMonitoringConfigOutput {
	return i.ToGoogleCloudAiplatformV1FeaturestoreMonitoringConfigOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1FeaturestoreMonitoringConfigArgs) ToGoogleCloudAiplatformV1FeaturestoreMonitoringConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeaturestoreMonitoringConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1FeaturestoreMonitoringConfigOutput)
}

func (i GoogleCloudAiplatformV1FeaturestoreMonitoringConfigArgs) ToGoogleCloudAiplatformV1FeaturestoreMonitoringConfigPtrOutput() GoogleCloudAiplatformV1FeaturestoreMonitoringConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1FeaturestoreMonitoringConfigPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1FeaturestoreMonitoringConfigArgs) ToGoogleCloudAiplatformV1FeaturestoreMonitoringConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeaturestoreMonitoringConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1FeaturestoreMonitoringConfigOutput).ToGoogleCloudAiplatformV1FeaturestoreMonitoringConfigPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1FeaturestoreMonitoringConfigPtrInput is an input type that accepts GoogleCloudAiplatformV1FeaturestoreMonitoringConfigArgs, GoogleCloudAiplatformV1FeaturestoreMonitoringConfigPtr and GoogleCloudAiplatformV1FeaturestoreMonitoringConfigPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1FeaturestoreMonitoringConfigPtrInput` via:
//
//	        GoogleCloudAiplatformV1FeaturestoreMonitoringConfigArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1FeaturestoreMonitoringConfigPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1FeaturestoreMonitoringConfigPtrOutput() GoogleCloudAiplatformV1FeaturestoreMonitoringConfigPtrOutput
	ToGoogleCloudAiplatformV1FeaturestoreMonitoringConfigPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1FeaturestoreMonitoringConfigPtrOutput
}

type googleCloudAiplatformV1FeaturestoreMonitoringConfigPtrType GoogleCloudAiplatformV1FeaturestoreMonitoringConfigArgs

func GoogleCloudAiplatformV1FeaturestoreMonitoringConfigPtr(v *GoogleCloudAiplatformV1FeaturestoreMonitoringConfigArgs) GoogleCloudAiplatformV1FeaturestoreMonitoringConfigPtrInput {
	return (*googleCloudAiplatformV1FeaturestoreMonitoringConfigPtrType)(v)
}

func (*googleCloudAiplatformV1FeaturestoreMonitoringConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1FeaturestoreMonitoringConfig)(nil)).Elem()
}

func (i *googleCloudAiplatformV1FeaturestoreMonitoringConfigPtrType) ToGoogleCloudAiplatformV1FeaturestoreMonitoringConfigPtrOutput() GoogleCloudAiplatformV1FeaturestoreMonitoringConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1FeaturestoreMonitoringConfigPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1FeaturestoreMonitoringConfigPtrType) ToGoogleCloudAiplatformV1FeaturestoreMonitoringConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeaturestoreMonitoringConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1FeaturestoreMonitoringConfigPtrOutput)
}

// Configuration of how features in Featurestore are monitored.
type GoogleCloudAiplatformV1FeaturestoreMonitoringConfigOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1FeaturestoreMonitoringConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1FeaturestoreMonitoringConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1FeaturestoreMonitoringConfigOutput) ToGoogleCloudAiplatformV1FeaturestoreMonitoringConfigOutput() GoogleCloudAiplatformV1FeaturestoreMonitoringConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1FeaturestoreMonitoringConfigOutput) ToGoogleCloudAiplatformV1FeaturestoreMonitoringConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeaturestoreMonitoringConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1FeaturestoreMonitoringConfigOutput) ToGoogleCloudAiplatformV1FeaturestoreMonitoringConfigPtrOutput() GoogleCloudAiplatformV1FeaturestoreMonitoringConfigPtrOutput {
	return o.ToGoogleCloudAiplatformV1FeaturestoreMonitoringConfigPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1FeaturestoreMonitoringConfigOutput) ToGoogleCloudAiplatformV1FeaturestoreMonitoringConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeaturestoreMonitoringConfigPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1FeaturestoreMonitoringConfig) *GoogleCloudAiplatformV1FeaturestoreMonitoringConfig {
		return &v
	}).(GoogleCloudAiplatformV1FeaturestoreMonitoringConfigPtrOutput)
}

// Threshold for categorical features of anomaly detection. This is shared by all types of Featurestore Monitoring for categorical features (i.e. Features with type (Feature.ValueType) BOOL or STRING).
func (o GoogleCloudAiplatformV1FeaturestoreMonitoringConfigOutput) CategoricalThresholdConfig() GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1FeaturestoreMonitoringConfig) *GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfig {
		return v.CategoricalThresholdConfig
	}).(GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigPtrOutput)
}

// The config for ImportFeatures Analysis Based Feature Monitoring.
func (o GoogleCloudAiplatformV1FeaturestoreMonitoringConfigOutput) ImportFeaturesAnalysis() GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1FeaturestoreMonitoringConfig) *GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysis {
		return v.ImportFeaturesAnalysis
	}).(GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrOutput)
}

// Threshold for numerical features of anomaly detection. This is shared by all objectives of Featurestore Monitoring for numerical features (i.e. Features with type (Feature.ValueType) DOUBLE or INT64).
func (o GoogleCloudAiplatformV1FeaturestoreMonitoringConfigOutput) NumericalThresholdConfig() GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1FeaturestoreMonitoringConfig) *GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfig {
		return v.NumericalThresholdConfig
	}).(GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigPtrOutput)
}

// The config for Snapshot Analysis Based Feature Monitoring.
func (o GoogleCloudAiplatformV1FeaturestoreMonitoringConfigOutput) SnapshotAnalysis() GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1FeaturestoreMonitoringConfig) *GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysis {
		return v.SnapshotAnalysis
	}).(GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisPtrOutput)
}

type GoogleCloudAiplatformV1FeaturestoreMonitoringConfigPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1FeaturestoreMonitoringConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1FeaturestoreMonitoringConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1FeaturestoreMonitoringConfigPtrOutput) ToGoogleCloudAiplatformV1FeaturestoreMonitoringConfigPtrOutput() GoogleCloudAiplatformV1FeaturestoreMonitoringConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1FeaturestoreMonitoringConfigPtrOutput) ToGoogleCloudAiplatformV1FeaturestoreMonitoringConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeaturestoreMonitoringConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1FeaturestoreMonitoringConfigPtrOutput) Elem() GoogleCloudAiplatformV1FeaturestoreMonitoringConfigOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1FeaturestoreMonitoringConfig) GoogleCloudAiplatformV1FeaturestoreMonitoringConfig {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1FeaturestoreMonitoringConfig
		return ret
	}).(GoogleCloudAiplatformV1FeaturestoreMonitoringConfigOutput)
}

// Threshold for categorical features of anomaly detection. This is shared by all types of Featurestore Monitoring for categorical features (i.e. Features with type (Feature.ValueType) BOOL or STRING).
func (o GoogleCloudAiplatformV1FeaturestoreMonitoringConfigPtrOutput) CategoricalThresholdConfig() GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1FeaturestoreMonitoringConfig) *GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfig {
		if v == nil {
			return nil
		}
		return v.CategoricalThresholdConfig
	}).(GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigPtrOutput)
}

// The config for ImportFeatures Analysis Based Feature Monitoring.
func (o GoogleCloudAiplatformV1FeaturestoreMonitoringConfigPtrOutput) ImportFeaturesAnalysis() GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1FeaturestoreMonitoringConfig) *GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysis {
		if v == nil {
			return nil
		}
		return v.ImportFeaturesAnalysis
	}).(GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrOutput)
}

// Threshold for numerical features of anomaly detection. This is shared by all objectives of Featurestore Monitoring for numerical features (i.e. Features with type (Feature.ValueType) DOUBLE or INT64).
func (o GoogleCloudAiplatformV1FeaturestoreMonitoringConfigPtrOutput) NumericalThresholdConfig() GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1FeaturestoreMonitoringConfig) *GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfig {
		if v == nil {
			return nil
		}
		return v.NumericalThresholdConfig
	}).(GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigPtrOutput)
}

// The config for Snapshot Analysis Based Feature Monitoring.
func (o GoogleCloudAiplatformV1FeaturestoreMonitoringConfigPtrOutput) SnapshotAnalysis() GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1FeaturestoreMonitoringConfig) *GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysis {
		if v == nil {
			return nil
		}
		return v.SnapshotAnalysis
	}).(GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisPtrOutput)
}

// Configuration of the Featurestore's ImportFeature Analysis Based Monitoring. This type of analysis generates statistics for values of each Feature imported by every ImportFeatureValues operation.
type GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysis struct {
	// The baseline used to do anomaly detection for the statistics generated by import features analysis.
	AnomalyDetectionBaseline *GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisAnomalyDetectionBaseline `pulumi:"anomalyDetectionBaseline"`
	// Whether to enable / disable / inherite default hebavior for import features analysis.
	State *GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisState `pulumi:"state"`
}

// GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisInput is an input type that accepts GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisArgs and GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisInput` via:
//
//	GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisArgs{...}
type GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisOutput() GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisOutput
	ToGoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisOutputWithContext(context.Context) GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisOutput
}

// Configuration of the Featurestore's ImportFeature Analysis Based Monitoring. This type of analysis generates statistics for values of each Feature imported by every ImportFeatureValues operation.
type GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisArgs struct {
	// The baseline used to do anomaly detection for the statistics generated by import features analysis.
	AnomalyDetectionBaseline GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisAnomalyDetectionBaselinePtrInput `pulumi:"anomalyDetectionBaseline"`
	// Whether to enable / disable / inherite default hebavior for import features analysis.
	State GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisStatePtrInput `pulumi:"state"`
}

func (GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysis)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisArgs) ToGoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisOutput() GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisOutput {
	return i.ToGoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisArgs) ToGoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisOutput)
}

func (i GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisArgs) ToGoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrOutput() GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrOutput {
	return i.ToGoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisArgs) ToGoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisOutput).ToGoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrInput is an input type that accepts GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisArgs, GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtr and GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrInput` via:
//
//	        GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrOutput() GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrOutput
	ToGoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrOutput
}

type googleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrType GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisArgs

func GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtr(v *GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisArgs) GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrInput {
	return (*googleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrType)(v)
}

func (*googleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysis)(nil)).Elem()
}

func (i *googleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrType) ToGoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrOutput() GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrOutput {
	return i.ToGoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrType) ToGoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrOutput)
}

// Configuration of the Featurestore's ImportFeature Analysis Based Monitoring. This type of analysis generates statistics for values of each Feature imported by every ImportFeatureValues operation.
type GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysis)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisOutput) ToGoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisOutput() GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisOutput {
	return o
}

func (o GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisOutput) ToGoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisOutput {
	return o
}

func (o GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisOutput) ToGoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrOutput() GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrOutput {
	return o.ToGoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisOutput) ToGoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysis) *GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysis {
		return &v
	}).(GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrOutput)
}

// The baseline used to do anomaly detection for the statistics generated by import features analysis.
func (o GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisOutput) AnomalyDetectionBaseline() GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisAnomalyDetectionBaselinePtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysis) *GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisAnomalyDetectionBaseline {
		return v.AnomalyDetectionBaseline
	}).(GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisAnomalyDetectionBaselinePtrOutput)
}

// Whether to enable / disable / inherite default hebavior for import features analysis.
func (o GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisOutput) State() GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisStatePtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysis) *GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisState {
		return v.State
	}).(GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisStatePtrOutput)
}

type GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysis)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrOutput) ToGoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrOutput() GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrOutput) ToGoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrOutput) Elem() GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysis) GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysis {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysis
		return ret
	}).(GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisOutput)
}

// The baseline used to do anomaly detection for the statistics generated by import features analysis.
func (o GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrOutput) AnomalyDetectionBaseline() GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisAnomalyDetectionBaselinePtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysis) *GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisAnomalyDetectionBaseline {
		if v == nil {
			return nil
		}
		return v.AnomalyDetectionBaseline
	}).(GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisAnomalyDetectionBaselinePtrOutput)
}

// Whether to enable / disable / inherite default hebavior for import features analysis.
func (o GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrOutput) State() GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisStatePtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysis) *GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisState {
		if v == nil {
			return nil
		}
		return v.State
	}).(GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisStatePtrOutput)
}

// Configuration of the Featurestore's ImportFeature Analysis Based Monitoring. This type of analysis generates statistics for values of each Feature imported by every ImportFeatureValues operation.
type GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisResponse struct {
	// The baseline used to do anomaly detection for the statistics generated by import features analysis.
	AnomalyDetectionBaseline string `pulumi:"anomalyDetectionBaseline"`
	// Whether to enable / disable / inherite default hebavior for import features analysis.
	State string `pulumi:"state"`
}

// Configuration of the Featurestore's ImportFeature Analysis Based Monitoring. This type of analysis generates statistics for values of each Feature imported by every ImportFeatureValues operation.
type GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisResponseOutput) ToGoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisResponseOutput() GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisResponseOutput) ToGoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisResponseOutput {
	return o
}

// The baseline used to do anomaly detection for the statistics generated by import features analysis.
func (o GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisResponseOutput) AnomalyDetectionBaseline() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisResponse) string {
		return v.AnomalyDetectionBaseline
	}).(pulumi.StringOutput)
}

// Whether to enable / disable / inherite default hebavior for import features analysis.
func (o GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisResponseOutput) State() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisResponse) string {
		return v.State
	}).(pulumi.StringOutput)
}

// Configuration of how features in Featurestore are monitored.
type GoogleCloudAiplatformV1FeaturestoreMonitoringConfigResponse struct {
	// Threshold for categorical features of anomaly detection. This is shared by all types of Featurestore Monitoring for categorical features (i.e. Features with type (Feature.ValueType) BOOL or STRING).
	CategoricalThresholdConfig GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigResponse `pulumi:"categoricalThresholdConfig"`
	// The config for ImportFeatures Analysis Based Feature Monitoring.
	ImportFeaturesAnalysis GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisResponse `pulumi:"importFeaturesAnalysis"`
	// Threshold for numerical features of anomaly detection. This is shared by all objectives of Featurestore Monitoring for numerical features (i.e. Features with type (Feature.ValueType) DOUBLE or INT64).
	NumericalThresholdConfig GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigResponse `pulumi:"numericalThresholdConfig"`
	// The config for Snapshot Analysis Based Feature Monitoring.
	SnapshotAnalysis GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisResponse `pulumi:"snapshotAnalysis"`
}

// Configuration of how features in Featurestore are monitored.
type GoogleCloudAiplatformV1FeaturestoreMonitoringConfigResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1FeaturestoreMonitoringConfigResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1FeaturestoreMonitoringConfigResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1FeaturestoreMonitoringConfigResponseOutput) ToGoogleCloudAiplatformV1FeaturestoreMonitoringConfigResponseOutput() GoogleCloudAiplatformV1FeaturestoreMonitoringConfigResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1FeaturestoreMonitoringConfigResponseOutput) ToGoogleCloudAiplatformV1FeaturestoreMonitoringConfigResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeaturestoreMonitoringConfigResponseOutput {
	return o
}

// Threshold for categorical features of anomaly detection. This is shared by all types of Featurestore Monitoring for categorical features (i.e. Features with type (Feature.ValueType) BOOL or STRING).
func (o GoogleCloudAiplatformV1FeaturestoreMonitoringConfigResponseOutput) CategoricalThresholdConfig() GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1FeaturestoreMonitoringConfigResponse) GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigResponse {
		return v.CategoricalThresholdConfig
	}).(GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigResponseOutput)
}

// The config for ImportFeatures Analysis Based Feature Monitoring.
func (o GoogleCloudAiplatformV1FeaturestoreMonitoringConfigResponseOutput) ImportFeaturesAnalysis() GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1FeaturestoreMonitoringConfigResponse) GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisResponse {
		return v.ImportFeaturesAnalysis
	}).(GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisResponseOutput)
}

// Threshold for numerical features of anomaly detection. This is shared by all objectives of Featurestore Monitoring for numerical features (i.e. Features with type (Feature.ValueType) DOUBLE or INT64).
func (o GoogleCloudAiplatformV1FeaturestoreMonitoringConfigResponseOutput) NumericalThresholdConfig() GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1FeaturestoreMonitoringConfigResponse) GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigResponse {
		return v.NumericalThresholdConfig
	}).(GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigResponseOutput)
}

// The config for Snapshot Analysis Based Feature Monitoring.
func (o GoogleCloudAiplatformV1FeaturestoreMonitoringConfigResponseOutput) SnapshotAnalysis() GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1FeaturestoreMonitoringConfigResponse) GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisResponse {
		return v.SnapshotAnalysis
	}).(GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisResponseOutput)
}

// Configuration of the Featurestore's Snapshot Analysis Based Monitoring. This type of analysis generates statistics for each Feature based on a snapshot of the latest feature value of each entities every monitoring_interval.
type GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysis struct {
	// The monitoring schedule for snapshot analysis. For EntityType-level config: unset / disabled = true indicates disabled by default for Features under it; otherwise by default enable snapshot analysis monitoring with monitoring_interval for Features under it. Feature-level config: disabled = true indicates disabled regardless of the EntityType-level config; unset monitoring_interval indicates going with EntityType-level config; otherwise run snapshot analysis monitoring with monitoring_interval regardless of the EntityType-level config. Explicitly Disable the snapshot analysis based monitoring.
	Disabled *bool `pulumi:"disabled"`
	// Configuration of the snapshot analysis based monitoring pipeline running interval. The value indicates number of days.
	MonitoringIntervalDays *int `pulumi:"monitoringIntervalDays"`
	// Customized export features time window for snapshot analysis. Unit is one day. Default value is 3 weeks. Minimum value is 1 day. Maximum value is 4000 days.
	StalenessDays *int `pulumi:"stalenessDays"`
}

// GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisInput is an input type that accepts GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisArgs and GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisInput` via:
//
//	GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisArgs{...}
type GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisOutput() GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisOutput
	ToGoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisOutputWithContext(context.Context) GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisOutput
}

// Configuration of the Featurestore's Snapshot Analysis Based Monitoring. This type of analysis generates statistics for each Feature based on a snapshot of the latest feature value of each entities every monitoring_interval.
type GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisArgs struct {
	// The monitoring schedule for snapshot analysis. For EntityType-level config: unset / disabled = true indicates disabled by default for Features under it; otherwise by default enable snapshot analysis monitoring with monitoring_interval for Features under it. Feature-level config: disabled = true indicates disabled regardless of the EntityType-level config; unset monitoring_interval indicates going with EntityType-level config; otherwise run snapshot analysis monitoring with monitoring_interval regardless of the EntityType-level config. Explicitly Disable the snapshot analysis based monitoring.
	Disabled pulumi.BoolPtrInput `pulumi:"disabled"`
	// Configuration of the snapshot analysis based monitoring pipeline running interval. The value indicates number of days.
	MonitoringIntervalDays pulumi.IntPtrInput `pulumi:"monitoringIntervalDays"`
	// Customized export features time window for snapshot analysis. Unit is one day. Default value is 3 weeks. Minimum value is 1 day. Maximum value is 4000 days.
	StalenessDays pulumi.IntPtrInput `pulumi:"stalenessDays"`
}

func (GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysis)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisArgs) ToGoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisOutput() GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisOutput {
	return i.ToGoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisArgs) ToGoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisOutput)
}

func (i GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisArgs) ToGoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisPtrOutput() GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisPtrOutput {
	return i.ToGoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisArgs) ToGoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisOutput).ToGoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisPtrInput is an input type that accepts GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisArgs, GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisPtr and GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisPtrInput` via:
//
//	        GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisPtrOutput() GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisPtrOutput
	ToGoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisPtrOutput
}

type googleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisPtrType GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisArgs

func GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisPtr(v *GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisArgs) GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisPtrInput {
	return (*googleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisPtrType)(v)
}

func (*googleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysis)(nil)).Elem()
}

func (i *googleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisPtrType) ToGoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisPtrOutput() GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisPtrOutput {
	return i.ToGoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisPtrType) ToGoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisPtrOutput)
}

// Configuration of the Featurestore's Snapshot Analysis Based Monitoring. This type of analysis generates statistics for each Feature based on a snapshot of the latest feature value of each entities every monitoring_interval.
type GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysis)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisOutput) ToGoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisOutput() GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisOutput {
	return o
}

func (o GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisOutput) ToGoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisOutput {
	return o
}

func (o GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisOutput) ToGoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisPtrOutput() GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisPtrOutput {
	return o.ToGoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisOutput) ToGoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysis) *GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysis {
		return &v
	}).(GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisPtrOutput)
}

// The monitoring schedule for snapshot analysis. For EntityType-level config: unset / disabled = true indicates disabled by default for Features under it; otherwise by default enable snapshot analysis monitoring with monitoring_interval for Features under it. Feature-level config: disabled = true indicates disabled regardless of the EntityType-level config; unset monitoring_interval indicates going with EntityType-level config; otherwise run snapshot analysis monitoring with monitoring_interval regardless of the EntityType-level config. Explicitly Disable the snapshot analysis based monitoring.
func (o GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisOutput) Disabled() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysis) *bool { return v.Disabled }).(pulumi.BoolPtrOutput)
}

// Configuration of the snapshot analysis based monitoring pipeline running interval. The value indicates number of days.
func (o GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisOutput) MonitoringIntervalDays() pulumi.IntPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysis) *int {
		return v.MonitoringIntervalDays
	}).(pulumi.IntPtrOutput)
}

// Customized export features time window for snapshot analysis. Unit is one day. Default value is 3 weeks. Minimum value is 1 day. Maximum value is 4000 days.
func (o GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisOutput) StalenessDays() pulumi.IntPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysis) *int {
		return v.StalenessDays
	}).(pulumi.IntPtrOutput)
}

type GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysis)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisPtrOutput) ToGoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisPtrOutput() GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisPtrOutput) ToGoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisPtrOutput) Elem() GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysis) GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysis {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysis
		return ret
	}).(GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisOutput)
}

// The monitoring schedule for snapshot analysis. For EntityType-level config: unset / disabled = true indicates disabled by default for Features under it; otherwise by default enable snapshot analysis monitoring with monitoring_interval for Features under it. Feature-level config: disabled = true indicates disabled regardless of the EntityType-level config; unset monitoring_interval indicates going with EntityType-level config; otherwise run snapshot analysis monitoring with monitoring_interval regardless of the EntityType-level config. Explicitly Disable the snapshot analysis based monitoring.
func (o GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisPtrOutput) Disabled() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysis) *bool {
		if v == nil {
			return nil
		}
		return v.Disabled
	}).(pulumi.BoolPtrOutput)
}

// Configuration of the snapshot analysis based monitoring pipeline running interval. The value indicates number of days.
func (o GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisPtrOutput) MonitoringIntervalDays() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysis) *int {
		if v == nil {
			return nil
		}
		return v.MonitoringIntervalDays
	}).(pulumi.IntPtrOutput)
}

// Customized export features time window for snapshot analysis. Unit is one day. Default value is 3 weeks. Minimum value is 1 day. Maximum value is 4000 days.
func (o GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisPtrOutput) StalenessDays() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysis) *int {
		if v == nil {
			return nil
		}
		return v.StalenessDays
	}).(pulumi.IntPtrOutput)
}

// Configuration of the Featurestore's Snapshot Analysis Based Monitoring. This type of analysis generates statistics for each Feature based on a snapshot of the latest feature value of each entities every monitoring_interval.
type GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisResponse struct {
	// The monitoring schedule for snapshot analysis. For EntityType-level config: unset / disabled = true indicates disabled by default for Features under it; otherwise by default enable snapshot analysis monitoring with monitoring_interval for Features under it. Feature-level config: disabled = true indicates disabled regardless of the EntityType-level config; unset monitoring_interval indicates going with EntityType-level config; otherwise run snapshot analysis monitoring with monitoring_interval regardless of the EntityType-level config. Explicitly Disable the snapshot analysis based monitoring.
	Disabled bool `pulumi:"disabled"`
	// Configuration of the snapshot analysis based monitoring pipeline running interval. The value indicates number of days.
	MonitoringIntervalDays int `pulumi:"monitoringIntervalDays"`
	// Customized export features time window for snapshot analysis. Unit is one day. Default value is 3 weeks. Minimum value is 1 day. Maximum value is 4000 days.
	StalenessDays int `pulumi:"stalenessDays"`
}

// Configuration of the Featurestore's Snapshot Analysis Based Monitoring. This type of analysis generates statistics for each Feature based on a snapshot of the latest feature value of each entities every monitoring_interval.
type GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisResponseOutput) ToGoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisResponseOutput() GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisResponseOutput) ToGoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisResponseOutput {
	return o
}

// The monitoring schedule for snapshot analysis. For EntityType-level config: unset / disabled = true indicates disabled by default for Features under it; otherwise by default enable snapshot analysis monitoring with monitoring_interval for Features under it. Feature-level config: disabled = true indicates disabled regardless of the EntityType-level config; unset monitoring_interval indicates going with EntityType-level config; otherwise run snapshot analysis monitoring with monitoring_interval regardless of the EntityType-level config. Explicitly Disable the snapshot analysis based monitoring.
func (o GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisResponseOutput) Disabled() pulumi.BoolOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisResponse) bool {
		return v.Disabled
	}).(pulumi.BoolOutput)
}

// Configuration of the snapshot analysis based monitoring pipeline running interval. The value indicates number of days.
func (o GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisResponseOutput) MonitoringIntervalDays() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisResponse) int {
		return v.MonitoringIntervalDays
	}).(pulumi.IntOutput)
}

// Customized export features time window for snapshot analysis. Unit is one day. Default value is 3 weeks. Minimum value is 1 day. Maximum value is 4000 days.
func (o GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisResponseOutput) StalenessDays() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisResponse) int {
		return v.StalenessDays
	}).(pulumi.IntOutput)
}

// The config for Featurestore Monitoring threshold.
type GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfig struct {
	// Specify a threshold value that can trigger the alert. 1. For categorical feature, the distribution distance is calculated by L-inifinity norm. 2. For numerical feature, the distribution distance is calculated by Jensen–Shannon divergence. Each feature must have a non-zero threshold if they need to be monitored. Otherwise no alert will be triggered for that feature.
	Value *float64 `pulumi:"value"`
}

// GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigInput is an input type that accepts GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigArgs and GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigInput` via:
//
//	GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigArgs{...}
type GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigOutput() GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigOutput
	ToGoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigOutputWithContext(context.Context) GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigOutput
}

// The config for Featurestore Monitoring threshold.
type GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigArgs struct {
	// Specify a threshold value that can trigger the alert. 1. For categorical feature, the distribution distance is calculated by L-inifinity norm. 2. For numerical feature, the distribution distance is calculated by Jensen–Shannon divergence. Each feature must have a non-zero threshold if they need to be monitored. Otherwise no alert will be triggered for that feature.
	Value pulumi.Float64PtrInput `pulumi:"value"`
}

func (GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfig)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigArgs) ToGoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigOutput() GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigOutput {
	return i.ToGoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigArgs) ToGoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigOutput)
}

func (i GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigArgs) ToGoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigPtrOutput() GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigArgs) ToGoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigOutput).ToGoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigPtrInput is an input type that accepts GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigArgs, GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigPtr and GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigPtrInput` via:
//
//	        GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigPtrOutput() GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigPtrOutput
	ToGoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigPtrOutput
}

type googleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigPtrType GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigArgs

func GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigPtr(v *GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigArgs) GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigPtrInput {
	return (*googleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigPtrType)(v)
}

func (*googleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfig)(nil)).Elem()
}

func (i *googleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigPtrType) ToGoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigPtrOutput() GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigPtrType) ToGoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigPtrOutput)
}

// The config for Featurestore Monitoring threshold.
type GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigOutput) ToGoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigOutput() GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigOutput) ToGoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigOutput) ToGoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigPtrOutput() GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigPtrOutput {
	return o.ToGoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigOutput) ToGoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfig) *GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfig {
		return &v
	}).(GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigPtrOutput)
}

// Specify a threshold value that can trigger the alert. 1. For categorical feature, the distribution distance is calculated by L-inifinity norm. 2. For numerical feature, the distribution distance is calculated by Jensen–Shannon divergence. Each feature must have a non-zero threshold if they need to be monitored. Otherwise no alert will be triggered for that feature.
func (o GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigOutput) Value() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfig) *float64 { return v.Value }).(pulumi.Float64PtrOutput)
}

type GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigPtrOutput) ToGoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigPtrOutput() GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigPtrOutput) ToGoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigPtrOutput) Elem() GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfig) GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfig {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfig
		return ret
	}).(GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigOutput)
}

// Specify a threshold value that can trigger the alert. 1. For categorical feature, the distribution distance is calculated by L-inifinity norm. 2. For numerical feature, the distribution distance is calculated by Jensen–Shannon divergence. Each feature must have a non-zero threshold if they need to be monitored. Otherwise no alert will be triggered for that feature.
func (o GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigPtrOutput) Value() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfig) *float64 {
		if v == nil {
			return nil
		}
		return v.Value
	}).(pulumi.Float64PtrOutput)
}

// The config for Featurestore Monitoring threshold.
type GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigResponse struct {
	// Specify a threshold value that can trigger the alert. 1. For categorical feature, the distribution distance is calculated by L-inifinity norm. 2. For numerical feature, the distribution distance is calculated by Jensen–Shannon divergence. Each feature must have a non-zero threshold if they need to be monitored. Otherwise no alert will be triggered for that feature.
	Value float64 `pulumi:"value"`
}

// The config for Featurestore Monitoring threshold.
type GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigResponseOutput) ToGoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigResponseOutput() GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigResponseOutput) ToGoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigResponseOutput {
	return o
}

// Specify a threshold value that can trigger the alert. 1. For categorical feature, the distribution distance is calculated by L-inifinity norm. 2. For numerical feature, the distribution distance is calculated by Jensen–Shannon divergence. Each feature must have a non-zero threshold if they need to be monitored. Otherwise no alert will be triggered for that feature.
func (o GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigResponseOutput) Value() pulumi.Float64Output {
	return o.ApplyT(func(v GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigResponse) float64 {
		return v.Value
	}).(pulumi.Float64Output)
}

// OnlineServingConfig specifies the details for provisioning online serving resources.
type GoogleCloudAiplatformV1FeaturestoreOnlineServingConfig struct {
	// The number of nodes for the online store. The number of nodes doesn't scale automatically, but you can manually update the number of nodes. If set to 0, the featurestore will not have an online store and cannot be used for online serving.
	FixedNodeCount *int `pulumi:"fixedNodeCount"`
	// Online serving scaling configuration. Only one of `fixed_node_count` and `scaling` can be set. Setting one will reset the other.
	Scaling *GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScaling `pulumi:"scaling"`
}

// GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigInput is an input type that accepts GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigArgs and GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigInput` via:
//
//	GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigArgs{...}
type GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1FeaturestoreOnlineServingConfigOutput() GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigOutput
	ToGoogleCloudAiplatformV1FeaturestoreOnlineServingConfigOutputWithContext(context.Context) GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigOutput
}

// OnlineServingConfig specifies the details for provisioning online serving resources.
type GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigArgs struct {
	// The number of nodes for the online store. The number of nodes doesn't scale automatically, but you can manually update the number of nodes. If set to 0, the featurestore will not have an online store and cannot be used for online serving.
	FixedNodeCount pulumi.IntPtrInput `pulumi:"fixedNodeCount"`
	// Online serving scaling configuration. Only one of `fixed_node_count` and `scaling` can be set. Setting one will reset the other.
	Scaling GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingPtrInput `pulumi:"scaling"`
}

func (GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1FeaturestoreOnlineServingConfig)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigArgs) ToGoogleCloudAiplatformV1FeaturestoreOnlineServingConfigOutput() GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigOutput {
	return i.ToGoogleCloudAiplatformV1FeaturestoreOnlineServingConfigOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigArgs) ToGoogleCloudAiplatformV1FeaturestoreOnlineServingConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigOutput)
}

func (i GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigArgs) ToGoogleCloudAiplatformV1FeaturestoreOnlineServingConfigPtrOutput() GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1FeaturestoreOnlineServingConfigPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigArgs) ToGoogleCloudAiplatformV1FeaturestoreOnlineServingConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigOutput).ToGoogleCloudAiplatformV1FeaturestoreOnlineServingConfigPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigPtrInput is an input type that accepts GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigArgs, GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigPtr and GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigPtrInput` via:
//
//	        GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1FeaturestoreOnlineServingConfigPtrOutput() GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigPtrOutput
	ToGoogleCloudAiplatformV1FeaturestoreOnlineServingConfigPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigPtrOutput
}

type googleCloudAiplatformV1FeaturestoreOnlineServingConfigPtrType GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigArgs

func GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigPtr(v *GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigArgs) GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigPtrInput {
	return (*googleCloudAiplatformV1FeaturestoreOnlineServingConfigPtrType)(v)
}

func (*googleCloudAiplatformV1FeaturestoreOnlineServingConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1FeaturestoreOnlineServingConfig)(nil)).Elem()
}

func (i *googleCloudAiplatformV1FeaturestoreOnlineServingConfigPtrType) ToGoogleCloudAiplatformV1FeaturestoreOnlineServingConfigPtrOutput() GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1FeaturestoreOnlineServingConfigPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1FeaturestoreOnlineServingConfigPtrType) ToGoogleCloudAiplatformV1FeaturestoreOnlineServingConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigPtrOutput)
}

// OnlineServingConfig specifies the details for provisioning online serving resources.
type GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1FeaturestoreOnlineServingConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigOutput) ToGoogleCloudAiplatformV1FeaturestoreOnlineServingConfigOutput() GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigOutput) ToGoogleCloudAiplatformV1FeaturestoreOnlineServingConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigOutput) ToGoogleCloudAiplatformV1FeaturestoreOnlineServingConfigPtrOutput() GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigPtrOutput {
	return o.ToGoogleCloudAiplatformV1FeaturestoreOnlineServingConfigPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigOutput) ToGoogleCloudAiplatformV1FeaturestoreOnlineServingConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1FeaturestoreOnlineServingConfig) *GoogleCloudAiplatformV1FeaturestoreOnlineServingConfig {
		return &v
	}).(GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigPtrOutput)
}

// The number of nodes for the online store. The number of nodes doesn't scale automatically, but you can manually update the number of nodes. If set to 0, the featurestore will not have an online store and cannot be used for online serving.
func (o GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigOutput) FixedNodeCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1FeaturestoreOnlineServingConfig) *int { return v.FixedNodeCount }).(pulumi.IntPtrOutput)
}

// Online serving scaling configuration. Only one of `fixed_node_count` and `scaling` can be set. Setting one will reset the other.
func (o GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigOutput) Scaling() GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1FeaturestoreOnlineServingConfig) *GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScaling {
		return v.Scaling
	}).(GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingPtrOutput)
}

type GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1FeaturestoreOnlineServingConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigPtrOutput) ToGoogleCloudAiplatformV1FeaturestoreOnlineServingConfigPtrOutput() GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigPtrOutput) ToGoogleCloudAiplatformV1FeaturestoreOnlineServingConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigPtrOutput) Elem() GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1FeaturestoreOnlineServingConfig) GoogleCloudAiplatformV1FeaturestoreOnlineServingConfig {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1FeaturestoreOnlineServingConfig
		return ret
	}).(GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigOutput)
}

// The number of nodes for the online store. The number of nodes doesn't scale automatically, but you can manually update the number of nodes. If set to 0, the featurestore will not have an online store and cannot be used for online serving.
func (o GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigPtrOutput) FixedNodeCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1FeaturestoreOnlineServingConfig) *int {
		if v == nil {
			return nil
		}
		return v.FixedNodeCount
	}).(pulumi.IntPtrOutput)
}

// Online serving scaling configuration. Only one of `fixed_node_count` and `scaling` can be set. Setting one will reset the other.
func (o GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigPtrOutput) Scaling() GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1FeaturestoreOnlineServingConfig) *GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScaling {
		if v == nil {
			return nil
		}
		return v.Scaling
	}).(GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingPtrOutput)
}

// OnlineServingConfig specifies the details for provisioning online serving resources.
type GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigResponse struct {
	// The number of nodes for the online store. The number of nodes doesn't scale automatically, but you can manually update the number of nodes. If set to 0, the featurestore will not have an online store and cannot be used for online serving.
	FixedNodeCount int `pulumi:"fixedNodeCount"`
	// Online serving scaling configuration. Only one of `fixed_node_count` and `scaling` can be set. Setting one will reset the other.
	Scaling GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingResponse `pulumi:"scaling"`
}

// OnlineServingConfig specifies the details for provisioning online serving resources.
type GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigResponseOutput) ToGoogleCloudAiplatformV1FeaturestoreOnlineServingConfigResponseOutput() GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigResponseOutput) ToGoogleCloudAiplatformV1FeaturestoreOnlineServingConfigResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigResponseOutput {
	return o
}

// The number of nodes for the online store. The number of nodes doesn't scale automatically, but you can manually update the number of nodes. If set to 0, the featurestore will not have an online store and cannot be used for online serving.
func (o GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigResponseOutput) FixedNodeCount() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigResponse) int { return v.FixedNodeCount }).(pulumi.IntOutput)
}

// Online serving scaling configuration. Only one of `fixed_node_count` and `scaling` can be set. Setting one will reset the other.
func (o GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigResponseOutput) Scaling() GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigResponse) GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingResponse {
		return v.Scaling
	}).(GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingResponseOutput)
}

// Online serving scaling configuration. If min_node_count and max_node_count are set to the same value, the cluster will be configured with the fixed number of node (no auto-scaling).
type GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScaling struct {
	// Optional. The cpu utilization that the Autoscaler should be trying to achieve. This number is on a scale from 0 (no utilization) to 100 (total utilization), and is limited between 10 and 80. When a cluster's CPU utilization exceeds the target that you have set, Bigtable immediately adds nodes to the cluster. When CPU utilization is substantially lower than the target, Bigtable removes nodes. If not set or set to 0, default to 50.
	CpuUtilizationTarget *int `pulumi:"cpuUtilizationTarget"`
	// The maximum number of nodes to scale up to. Must be greater than min_node_count, and less than or equal to 10 times of 'min_node_count'.
	MaxNodeCount *int `pulumi:"maxNodeCount"`
	// The minimum number of nodes to scale down to. Must be greater than or equal to 1.
	MinNodeCount int `pulumi:"minNodeCount"`
}

// GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingInput is an input type that accepts GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingArgs and GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingInput` via:
//
//	GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingArgs{...}
type GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingOutput() GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingOutput
	ToGoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingOutputWithContext(context.Context) GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingOutput
}

// Online serving scaling configuration. If min_node_count and max_node_count are set to the same value, the cluster will be configured with the fixed number of node (no auto-scaling).
type GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingArgs struct {
	// Optional. The cpu utilization that the Autoscaler should be trying to achieve. This number is on a scale from 0 (no utilization) to 100 (total utilization), and is limited between 10 and 80. When a cluster's CPU utilization exceeds the target that you have set, Bigtable immediately adds nodes to the cluster. When CPU utilization is substantially lower than the target, Bigtable removes nodes. If not set or set to 0, default to 50.
	CpuUtilizationTarget pulumi.IntPtrInput `pulumi:"cpuUtilizationTarget"`
	// The maximum number of nodes to scale up to. Must be greater than min_node_count, and less than or equal to 10 times of 'min_node_count'.
	MaxNodeCount pulumi.IntPtrInput `pulumi:"maxNodeCount"`
	// The minimum number of nodes to scale down to. Must be greater than or equal to 1.
	MinNodeCount pulumi.IntInput `pulumi:"minNodeCount"`
}

func (GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScaling)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingArgs) ToGoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingOutput() GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingOutput {
	return i.ToGoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingArgs) ToGoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingOutput)
}

func (i GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingArgs) ToGoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingPtrOutput() GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingPtrOutput {
	return i.ToGoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingArgs) ToGoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingOutput).ToGoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingPtrInput is an input type that accepts GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingArgs, GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingPtr and GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingPtrInput` via:
//
//	        GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingPtrOutput() GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingPtrOutput
	ToGoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingPtrOutput
}

type googleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingPtrType GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingArgs

func GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingPtr(v *GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingArgs) GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingPtrInput {
	return (*googleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingPtrType)(v)
}

func (*googleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScaling)(nil)).Elem()
}

func (i *googleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingPtrType) ToGoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingPtrOutput() GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingPtrOutput {
	return i.ToGoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingPtrType) ToGoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingPtrOutput)
}

// Online serving scaling configuration. If min_node_count and max_node_count are set to the same value, the cluster will be configured with the fixed number of node (no auto-scaling).
type GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScaling)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingOutput) ToGoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingOutput() GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingOutput {
	return o
}

func (o GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingOutput) ToGoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingOutput {
	return o
}

func (o GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingOutput) ToGoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingPtrOutput() GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingPtrOutput {
	return o.ToGoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingOutput) ToGoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScaling) *GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScaling {
		return &v
	}).(GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingPtrOutput)
}

// Optional. The cpu utilization that the Autoscaler should be trying to achieve. This number is on a scale from 0 (no utilization) to 100 (total utilization), and is limited between 10 and 80. When a cluster's CPU utilization exceeds the target that you have set, Bigtable immediately adds nodes to the cluster. When CPU utilization is substantially lower than the target, Bigtable removes nodes. If not set or set to 0, default to 50.
func (o GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingOutput) CpuUtilizationTarget() pulumi.IntPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScaling) *int {
		return v.CpuUtilizationTarget
	}).(pulumi.IntPtrOutput)
}

// The maximum number of nodes to scale up to. Must be greater than min_node_count, and less than or equal to 10 times of 'min_node_count'.
func (o GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingOutput) MaxNodeCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScaling) *int { return v.MaxNodeCount }).(pulumi.IntPtrOutput)
}

// The minimum number of nodes to scale down to. Must be greater than or equal to 1.
func (o GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingOutput) MinNodeCount() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScaling) int { return v.MinNodeCount }).(pulumi.IntOutput)
}

type GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScaling)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingPtrOutput) ToGoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingPtrOutput() GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingPtrOutput) ToGoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingPtrOutput) Elem() GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScaling) GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScaling {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScaling
		return ret
	}).(GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingOutput)
}

// Optional. The cpu utilization that the Autoscaler should be trying to achieve. This number is on a scale from 0 (no utilization) to 100 (total utilization), and is limited between 10 and 80. When a cluster's CPU utilization exceeds the target that you have set, Bigtable immediately adds nodes to the cluster. When CPU utilization is substantially lower than the target, Bigtable removes nodes. If not set or set to 0, default to 50.
func (o GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingPtrOutput) CpuUtilizationTarget() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScaling) *int {
		if v == nil {
			return nil
		}
		return v.CpuUtilizationTarget
	}).(pulumi.IntPtrOutput)
}

// The maximum number of nodes to scale up to. Must be greater than min_node_count, and less than or equal to 10 times of 'min_node_count'.
func (o GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingPtrOutput) MaxNodeCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScaling) *int {
		if v == nil {
			return nil
		}
		return v.MaxNodeCount
	}).(pulumi.IntPtrOutput)
}

// The minimum number of nodes to scale down to. Must be greater than or equal to 1.
func (o GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingPtrOutput) MinNodeCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScaling) *int {
		if v == nil {
			return nil
		}
		return &v.MinNodeCount
	}).(pulumi.IntPtrOutput)
}

// Online serving scaling configuration. If min_node_count and max_node_count are set to the same value, the cluster will be configured with the fixed number of node (no auto-scaling).
type GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingResponse struct {
	// Optional. The cpu utilization that the Autoscaler should be trying to achieve. This number is on a scale from 0 (no utilization) to 100 (total utilization), and is limited between 10 and 80. When a cluster's CPU utilization exceeds the target that you have set, Bigtable immediately adds nodes to the cluster. When CPU utilization is substantially lower than the target, Bigtable removes nodes. If not set or set to 0, default to 50.
	CpuUtilizationTarget int `pulumi:"cpuUtilizationTarget"`
	// The maximum number of nodes to scale up to. Must be greater than min_node_count, and less than or equal to 10 times of 'min_node_count'.
	MaxNodeCount int `pulumi:"maxNodeCount"`
	// The minimum number of nodes to scale down to. Must be greater than or equal to 1.
	MinNodeCount int `pulumi:"minNodeCount"`
}

// Online serving scaling configuration. If min_node_count and max_node_count are set to the same value, the cluster will be configured with the fixed number of node (no auto-scaling).
type GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingResponseOutput) ToGoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingResponseOutput() GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingResponseOutput) ToGoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingResponseOutput {
	return o
}

// Optional. The cpu utilization that the Autoscaler should be trying to achieve. This number is on a scale from 0 (no utilization) to 100 (total utilization), and is limited between 10 and 80. When a cluster's CPU utilization exceeds the target that you have set, Bigtable immediately adds nodes to the cluster. When CPU utilization is substantially lower than the target, Bigtable removes nodes. If not set or set to 0, default to 50.
func (o GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingResponseOutput) CpuUtilizationTarget() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingResponse) int {
		return v.CpuUtilizationTarget
	}).(pulumi.IntOutput)
}

// The maximum number of nodes to scale up to. Must be greater than min_node_count, and less than or equal to 10 times of 'min_node_count'.
func (o GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingResponseOutput) MaxNodeCount() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingResponse) int {
		return v.MaxNodeCount
	}).(pulumi.IntOutput)
}

// The minimum number of nodes to scale down to. Must be greater than or equal to 1.
func (o GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingResponseOutput) MinNodeCount() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingResponse) int {
		return v.MinNodeCount
	}).(pulumi.IntOutput)
}

// Assigns input data to training, validation, and test sets based on the given filters, data pieces not matched by any filter are ignored. Currently only supported for Datasets containing DataItems. If any of the filters in this message are to match nothing, then they can be set as '-' (the minus sign). Supported only for unstructured Datasets.
type GoogleCloudAiplatformV1FilterSplit struct {
	// A filter on DataItems of the Dataset. DataItems that match this filter are used to test the Model. A filter with same syntax as the one used in DatasetService.ListDataItems may be used. If a single DataItem is matched by more than one of the FilterSplit filters, then it is assigned to the first set that applies to it in the training, validation, test order.
	TestFilter string `pulumi:"testFilter"`
	// A filter on DataItems of the Dataset. DataItems that match this filter are used to train the Model. A filter with same syntax as the one used in DatasetService.ListDataItems may be used. If a single DataItem is matched by more than one of the FilterSplit filters, then it is assigned to the first set that applies to it in the training, validation, test order.
	TrainingFilter string `pulumi:"trainingFilter"`
	// A filter on DataItems of the Dataset. DataItems that match this filter are used to validate the Model. A filter with same syntax as the one used in DatasetService.ListDataItems may be used. If a single DataItem is matched by more than one of the FilterSplit filters, then it is assigned to the first set that applies to it in the training, validation, test order.
	ValidationFilter string `pulumi:"validationFilter"`
}

// GoogleCloudAiplatformV1FilterSplitInput is an input type that accepts GoogleCloudAiplatformV1FilterSplitArgs and GoogleCloudAiplatformV1FilterSplitOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1FilterSplitInput` via:
//
//	GoogleCloudAiplatformV1FilterSplitArgs{...}
type GoogleCloudAiplatformV1FilterSplitInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1FilterSplitOutput() GoogleCloudAiplatformV1FilterSplitOutput
	ToGoogleCloudAiplatformV1FilterSplitOutputWithContext(context.Context) GoogleCloudAiplatformV1FilterSplitOutput
}

// Assigns input data to training, validation, and test sets based on the given filters, data pieces not matched by any filter are ignored. Currently only supported for Datasets containing DataItems. If any of the filters in this message are to match nothing, then they can be set as '-' (the minus sign). Supported only for unstructured Datasets.
type GoogleCloudAiplatformV1FilterSplitArgs struct {
	// A filter on DataItems of the Dataset. DataItems that match this filter are used to test the Model. A filter with same syntax as the one used in DatasetService.ListDataItems may be used. If a single DataItem is matched by more than one of the FilterSplit filters, then it is assigned to the first set that applies to it in the training, validation, test order.
	TestFilter pulumi.StringInput `pulumi:"testFilter"`
	// A filter on DataItems of the Dataset. DataItems that match this filter are used to train the Model. A filter with same syntax as the one used in DatasetService.ListDataItems may be used. If a single DataItem is matched by more than one of the FilterSplit filters, then it is assigned to the first set that applies to it in the training, validation, test order.
	TrainingFilter pulumi.StringInput `pulumi:"trainingFilter"`
	// A filter on DataItems of the Dataset. DataItems that match this filter are used to validate the Model. A filter with same syntax as the one used in DatasetService.ListDataItems may be used. If a single DataItem is matched by more than one of the FilterSplit filters, then it is assigned to the first set that applies to it in the training, validation, test order.
	ValidationFilter pulumi.StringInput `pulumi:"validationFilter"`
}

func (GoogleCloudAiplatformV1FilterSplitArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1FilterSplit)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1FilterSplitArgs) ToGoogleCloudAiplatformV1FilterSplitOutput() GoogleCloudAiplatformV1FilterSplitOutput {
	return i.ToGoogleCloudAiplatformV1FilterSplitOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1FilterSplitArgs) ToGoogleCloudAiplatformV1FilterSplitOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FilterSplitOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1FilterSplitOutput)
}

func (i GoogleCloudAiplatformV1FilterSplitArgs) ToGoogleCloudAiplatformV1FilterSplitPtrOutput() GoogleCloudAiplatformV1FilterSplitPtrOutput {
	return i.ToGoogleCloudAiplatformV1FilterSplitPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1FilterSplitArgs) ToGoogleCloudAiplatformV1FilterSplitPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FilterSplitPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1FilterSplitOutput).ToGoogleCloudAiplatformV1FilterSplitPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1FilterSplitPtrInput is an input type that accepts GoogleCloudAiplatformV1FilterSplitArgs, GoogleCloudAiplatformV1FilterSplitPtr and GoogleCloudAiplatformV1FilterSplitPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1FilterSplitPtrInput` via:
//
//	        GoogleCloudAiplatformV1FilterSplitArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1FilterSplitPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1FilterSplitPtrOutput() GoogleCloudAiplatformV1FilterSplitPtrOutput
	ToGoogleCloudAiplatformV1FilterSplitPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1FilterSplitPtrOutput
}

type googleCloudAiplatformV1FilterSplitPtrType GoogleCloudAiplatformV1FilterSplitArgs

func GoogleCloudAiplatformV1FilterSplitPtr(v *GoogleCloudAiplatformV1FilterSplitArgs) GoogleCloudAiplatformV1FilterSplitPtrInput {
	return (*googleCloudAiplatformV1FilterSplitPtrType)(v)
}

func (*googleCloudAiplatformV1FilterSplitPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1FilterSplit)(nil)).Elem()
}

func (i *googleCloudAiplatformV1FilterSplitPtrType) ToGoogleCloudAiplatformV1FilterSplitPtrOutput() GoogleCloudAiplatformV1FilterSplitPtrOutput {
	return i.ToGoogleCloudAiplatformV1FilterSplitPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1FilterSplitPtrType) ToGoogleCloudAiplatformV1FilterSplitPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FilterSplitPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1FilterSplitPtrOutput)
}

// Assigns input data to training, validation, and test sets based on the given filters, data pieces not matched by any filter are ignored. Currently only supported for Datasets containing DataItems. If any of the filters in this message are to match nothing, then they can be set as '-' (the minus sign). Supported only for unstructured Datasets.
type GoogleCloudAiplatformV1FilterSplitOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1FilterSplitOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1FilterSplit)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1FilterSplitOutput) ToGoogleCloudAiplatformV1FilterSplitOutput() GoogleCloudAiplatformV1FilterSplitOutput {
	return o
}

func (o GoogleCloudAiplatformV1FilterSplitOutput) ToGoogleCloudAiplatformV1FilterSplitOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FilterSplitOutput {
	return o
}

func (o GoogleCloudAiplatformV1FilterSplitOutput) ToGoogleCloudAiplatformV1FilterSplitPtrOutput() GoogleCloudAiplatformV1FilterSplitPtrOutput {
	return o.ToGoogleCloudAiplatformV1FilterSplitPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1FilterSplitOutput) ToGoogleCloudAiplatformV1FilterSplitPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FilterSplitPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1FilterSplit) *GoogleCloudAiplatformV1FilterSplit {
		return &v
	}).(GoogleCloudAiplatformV1FilterSplitPtrOutput)
}

// A filter on DataItems of the Dataset. DataItems that match this filter are used to test the Model. A filter with same syntax as the one used in DatasetService.ListDataItems may be used. If a single DataItem is matched by more than one of the FilterSplit filters, then it is assigned to the first set that applies to it in the training, validation, test order.
func (o GoogleCloudAiplatformV1FilterSplitOutput) TestFilter() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1FilterSplit) string { return v.TestFilter }).(pulumi.StringOutput)
}

// A filter on DataItems of the Dataset. DataItems that match this filter are used to train the Model. A filter with same syntax as the one used in DatasetService.ListDataItems may be used. If a single DataItem is matched by more than one of the FilterSplit filters, then it is assigned to the first set that applies to it in the training, validation, test order.
func (o GoogleCloudAiplatformV1FilterSplitOutput) TrainingFilter() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1FilterSplit) string { return v.TrainingFilter }).(pulumi.StringOutput)
}

// A filter on DataItems of the Dataset. DataItems that match this filter are used to validate the Model. A filter with same syntax as the one used in DatasetService.ListDataItems may be used. If a single DataItem is matched by more than one of the FilterSplit filters, then it is assigned to the first set that applies to it in the training, validation, test order.
func (o GoogleCloudAiplatformV1FilterSplitOutput) ValidationFilter() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1FilterSplit) string { return v.ValidationFilter }).(pulumi.StringOutput)
}

type GoogleCloudAiplatformV1FilterSplitPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1FilterSplitPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1FilterSplit)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1FilterSplitPtrOutput) ToGoogleCloudAiplatformV1FilterSplitPtrOutput() GoogleCloudAiplatformV1FilterSplitPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1FilterSplitPtrOutput) ToGoogleCloudAiplatformV1FilterSplitPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FilterSplitPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1FilterSplitPtrOutput) Elem() GoogleCloudAiplatformV1FilterSplitOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1FilterSplit) GoogleCloudAiplatformV1FilterSplit {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1FilterSplit
		return ret
	}).(GoogleCloudAiplatformV1FilterSplitOutput)
}

// A filter on DataItems of the Dataset. DataItems that match this filter are used to test the Model. A filter with same syntax as the one used in DatasetService.ListDataItems may be used. If a single DataItem is matched by more than one of the FilterSplit filters, then it is assigned to the first set that applies to it in the training, validation, test order.
func (o GoogleCloudAiplatformV1FilterSplitPtrOutput) TestFilter() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1FilterSplit) *string {
		if v == nil {
			return nil
		}
		return &v.TestFilter
	}).(pulumi.StringPtrOutput)
}

// A filter on DataItems of the Dataset. DataItems that match this filter are used to train the Model. A filter with same syntax as the one used in DatasetService.ListDataItems may be used. If a single DataItem is matched by more than one of the FilterSplit filters, then it is assigned to the first set that applies to it in the training, validation, test order.
func (o GoogleCloudAiplatformV1FilterSplitPtrOutput) TrainingFilter() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1FilterSplit) *string {
		if v == nil {
			return nil
		}
		return &v.TrainingFilter
	}).(pulumi.StringPtrOutput)
}

// A filter on DataItems of the Dataset. DataItems that match this filter are used to validate the Model. A filter with same syntax as the one used in DatasetService.ListDataItems may be used. If a single DataItem is matched by more than one of the FilterSplit filters, then it is assigned to the first set that applies to it in the training, validation, test order.
func (o GoogleCloudAiplatformV1FilterSplitPtrOutput) ValidationFilter() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1FilterSplit) *string {
		if v == nil {
			return nil
		}
		return &v.ValidationFilter
	}).(pulumi.StringPtrOutput)
}

// Assigns input data to training, validation, and test sets based on the given filters, data pieces not matched by any filter are ignored. Currently only supported for Datasets containing DataItems. If any of the filters in this message are to match nothing, then they can be set as '-' (the minus sign). Supported only for unstructured Datasets.
type GoogleCloudAiplatformV1FilterSplitResponse struct {
	// A filter on DataItems of the Dataset. DataItems that match this filter are used to test the Model. A filter with same syntax as the one used in DatasetService.ListDataItems may be used. If a single DataItem is matched by more than one of the FilterSplit filters, then it is assigned to the first set that applies to it in the training, validation, test order.
	TestFilter string `pulumi:"testFilter"`
	// A filter on DataItems of the Dataset. DataItems that match this filter are used to train the Model. A filter with same syntax as the one used in DatasetService.ListDataItems may be used. If a single DataItem is matched by more than one of the FilterSplit filters, then it is assigned to the first set that applies to it in the training, validation, test order.
	TrainingFilter string `pulumi:"trainingFilter"`
	// A filter on DataItems of the Dataset. DataItems that match this filter are used to validate the Model. A filter with same syntax as the one used in DatasetService.ListDataItems may be used. If a single DataItem is matched by more than one of the FilterSplit filters, then it is assigned to the first set that applies to it in the training, validation, test order.
	ValidationFilter string `pulumi:"validationFilter"`
}

// Assigns input data to training, validation, and test sets based on the given filters, data pieces not matched by any filter are ignored. Currently only supported for Datasets containing DataItems. If any of the filters in this message are to match nothing, then they can be set as '-' (the minus sign). Supported only for unstructured Datasets.
type GoogleCloudAiplatformV1FilterSplitResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1FilterSplitResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1FilterSplitResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1FilterSplitResponseOutput) ToGoogleCloudAiplatformV1FilterSplitResponseOutput() GoogleCloudAiplatformV1FilterSplitResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1FilterSplitResponseOutput) ToGoogleCloudAiplatformV1FilterSplitResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FilterSplitResponseOutput {
	return o
}

// A filter on DataItems of the Dataset. DataItems that match this filter are used to test the Model. A filter with same syntax as the one used in DatasetService.ListDataItems may be used. If a single DataItem is matched by more than one of the FilterSplit filters, then it is assigned to the first set that applies to it in the training, validation, test order.
func (o GoogleCloudAiplatformV1FilterSplitResponseOutput) TestFilter() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1FilterSplitResponse) string { return v.TestFilter }).(pulumi.StringOutput)
}

// A filter on DataItems of the Dataset. DataItems that match this filter are used to train the Model. A filter with same syntax as the one used in DatasetService.ListDataItems may be used. If a single DataItem is matched by more than one of the FilterSplit filters, then it is assigned to the first set that applies to it in the training, validation, test order.
func (o GoogleCloudAiplatformV1FilterSplitResponseOutput) TrainingFilter() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1FilterSplitResponse) string { return v.TrainingFilter }).(pulumi.StringOutput)
}

// A filter on DataItems of the Dataset. DataItems that match this filter are used to validate the Model. A filter with same syntax as the one used in DatasetService.ListDataItems may be used. If a single DataItem is matched by more than one of the FilterSplit filters, then it is assigned to the first set that applies to it in the training, validation, test order.
func (o GoogleCloudAiplatformV1FilterSplitResponseOutput) ValidationFilter() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1FilterSplitResponse) string { return v.ValidationFilter }).(pulumi.StringOutput)
}

// Assigns the input data to training, validation, and test sets as per the given fractions. Any of `training_fraction`, `validation_fraction` and `test_fraction` may optionally be provided, they must sum to up to 1. If the provided ones sum to less than 1, the remainder is assigned to sets as decided by Vertex AI. If none of the fractions are set, by default roughly 80% of data is used for training, 10% for validation, and 10% for test.
type GoogleCloudAiplatformV1FractionSplit struct {
	// The fraction of the input data that is to be used to evaluate the Model.
	TestFraction *float64 `pulumi:"testFraction"`
	// The fraction of the input data that is to be used to train the Model.
	TrainingFraction *float64 `pulumi:"trainingFraction"`
	// The fraction of the input data that is to be used to validate the Model.
	ValidationFraction *float64 `pulumi:"validationFraction"`
}

// GoogleCloudAiplatformV1FractionSplitInput is an input type that accepts GoogleCloudAiplatformV1FractionSplitArgs and GoogleCloudAiplatformV1FractionSplitOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1FractionSplitInput` via:
//
//	GoogleCloudAiplatformV1FractionSplitArgs{...}
type GoogleCloudAiplatformV1FractionSplitInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1FractionSplitOutput() GoogleCloudAiplatformV1FractionSplitOutput
	ToGoogleCloudAiplatformV1FractionSplitOutputWithContext(context.Context) GoogleCloudAiplatformV1FractionSplitOutput
}

// Assigns the input data to training, validation, and test sets as per the given fractions. Any of `training_fraction`, `validation_fraction` and `test_fraction` may optionally be provided, they must sum to up to 1. If the provided ones sum to less than 1, the remainder is assigned to sets as decided by Vertex AI. If none of the fractions are set, by default roughly 80% of data is used for training, 10% for validation, and 10% for test.
type GoogleCloudAiplatformV1FractionSplitArgs struct {
	// The fraction of the input data that is to be used to evaluate the Model.
	TestFraction pulumi.Float64PtrInput `pulumi:"testFraction"`
	// The fraction of the input data that is to be used to train the Model.
	TrainingFraction pulumi.Float64PtrInput `pulumi:"trainingFraction"`
	// The fraction of the input data that is to be used to validate the Model.
	ValidationFraction pulumi.Float64PtrInput `pulumi:"validationFraction"`
}

func (GoogleCloudAiplatformV1FractionSplitArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1FractionSplit)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1FractionSplitArgs) ToGoogleCloudAiplatformV1FractionSplitOutput() GoogleCloudAiplatformV1FractionSplitOutput {
	return i.ToGoogleCloudAiplatformV1FractionSplitOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1FractionSplitArgs) ToGoogleCloudAiplatformV1FractionSplitOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FractionSplitOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1FractionSplitOutput)
}

func (i GoogleCloudAiplatformV1FractionSplitArgs) ToGoogleCloudAiplatformV1FractionSplitPtrOutput() GoogleCloudAiplatformV1FractionSplitPtrOutput {
	return i.ToGoogleCloudAiplatformV1FractionSplitPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1FractionSplitArgs) ToGoogleCloudAiplatformV1FractionSplitPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FractionSplitPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1FractionSplitOutput).ToGoogleCloudAiplatformV1FractionSplitPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1FractionSplitPtrInput is an input type that accepts GoogleCloudAiplatformV1FractionSplitArgs, GoogleCloudAiplatformV1FractionSplitPtr and GoogleCloudAiplatformV1FractionSplitPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1FractionSplitPtrInput` via:
//
//	        GoogleCloudAiplatformV1FractionSplitArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1FractionSplitPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1FractionSplitPtrOutput() GoogleCloudAiplatformV1FractionSplitPtrOutput
	ToGoogleCloudAiplatformV1FractionSplitPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1FractionSplitPtrOutput
}

type googleCloudAiplatformV1FractionSplitPtrType GoogleCloudAiplatformV1FractionSplitArgs

func GoogleCloudAiplatformV1FractionSplitPtr(v *GoogleCloudAiplatformV1FractionSplitArgs) GoogleCloudAiplatformV1FractionSplitPtrInput {
	return (*googleCloudAiplatformV1FractionSplitPtrType)(v)
}

func (*googleCloudAiplatformV1FractionSplitPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1FractionSplit)(nil)).Elem()
}

func (i *googleCloudAiplatformV1FractionSplitPtrType) ToGoogleCloudAiplatformV1FractionSplitPtrOutput() GoogleCloudAiplatformV1FractionSplitPtrOutput {
	return i.ToGoogleCloudAiplatformV1FractionSplitPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1FractionSplitPtrType) ToGoogleCloudAiplatformV1FractionSplitPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FractionSplitPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1FractionSplitPtrOutput)
}

// Assigns the input data to training, validation, and test sets as per the given fractions. Any of `training_fraction`, `validation_fraction` and `test_fraction` may optionally be provided, they must sum to up to 1. If the provided ones sum to less than 1, the remainder is assigned to sets as decided by Vertex AI. If none of the fractions are set, by default roughly 80% of data is used for training, 10% for validation, and 10% for test.
type GoogleCloudAiplatformV1FractionSplitOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1FractionSplitOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1FractionSplit)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1FractionSplitOutput) ToGoogleCloudAiplatformV1FractionSplitOutput() GoogleCloudAiplatformV1FractionSplitOutput {
	return o
}

func (o GoogleCloudAiplatformV1FractionSplitOutput) ToGoogleCloudAiplatformV1FractionSplitOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FractionSplitOutput {
	return o
}

func (o GoogleCloudAiplatformV1FractionSplitOutput) ToGoogleCloudAiplatformV1FractionSplitPtrOutput() GoogleCloudAiplatformV1FractionSplitPtrOutput {
	return o.ToGoogleCloudAiplatformV1FractionSplitPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1FractionSplitOutput) ToGoogleCloudAiplatformV1FractionSplitPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FractionSplitPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1FractionSplit) *GoogleCloudAiplatformV1FractionSplit {
		return &v
	}).(GoogleCloudAiplatformV1FractionSplitPtrOutput)
}

// The fraction of the input data that is to be used to evaluate the Model.
func (o GoogleCloudAiplatformV1FractionSplitOutput) TestFraction() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1FractionSplit) *float64 { return v.TestFraction }).(pulumi.Float64PtrOutput)
}

// The fraction of the input data that is to be used to train the Model.
func (o GoogleCloudAiplatformV1FractionSplitOutput) TrainingFraction() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1FractionSplit) *float64 { return v.TrainingFraction }).(pulumi.Float64PtrOutput)
}

// The fraction of the input data that is to be used to validate the Model.
func (o GoogleCloudAiplatformV1FractionSplitOutput) ValidationFraction() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1FractionSplit) *float64 { return v.ValidationFraction }).(pulumi.Float64PtrOutput)
}

type GoogleCloudAiplatformV1FractionSplitPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1FractionSplitPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1FractionSplit)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1FractionSplitPtrOutput) ToGoogleCloudAiplatformV1FractionSplitPtrOutput() GoogleCloudAiplatformV1FractionSplitPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1FractionSplitPtrOutput) ToGoogleCloudAiplatformV1FractionSplitPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FractionSplitPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1FractionSplitPtrOutput) Elem() GoogleCloudAiplatformV1FractionSplitOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1FractionSplit) GoogleCloudAiplatformV1FractionSplit {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1FractionSplit
		return ret
	}).(GoogleCloudAiplatformV1FractionSplitOutput)
}

// The fraction of the input data that is to be used to evaluate the Model.
func (o GoogleCloudAiplatformV1FractionSplitPtrOutput) TestFraction() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1FractionSplit) *float64 {
		if v == nil {
			return nil
		}
		return v.TestFraction
	}).(pulumi.Float64PtrOutput)
}

// The fraction of the input data that is to be used to train the Model.
func (o GoogleCloudAiplatformV1FractionSplitPtrOutput) TrainingFraction() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1FractionSplit) *float64 {
		if v == nil {
			return nil
		}
		return v.TrainingFraction
	}).(pulumi.Float64PtrOutput)
}

// The fraction of the input data that is to be used to validate the Model.
func (o GoogleCloudAiplatformV1FractionSplitPtrOutput) ValidationFraction() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1FractionSplit) *float64 {
		if v == nil {
			return nil
		}
		return v.ValidationFraction
	}).(pulumi.Float64PtrOutput)
}

// Assigns the input data to training, validation, and test sets as per the given fractions. Any of `training_fraction`, `validation_fraction` and `test_fraction` may optionally be provided, they must sum to up to 1. If the provided ones sum to less than 1, the remainder is assigned to sets as decided by Vertex AI. If none of the fractions are set, by default roughly 80% of data is used for training, 10% for validation, and 10% for test.
type GoogleCloudAiplatformV1FractionSplitResponse struct {
	// The fraction of the input data that is to be used to evaluate the Model.
	TestFraction float64 `pulumi:"testFraction"`
	// The fraction of the input data that is to be used to train the Model.
	TrainingFraction float64 `pulumi:"trainingFraction"`
	// The fraction of the input data that is to be used to validate the Model.
	ValidationFraction float64 `pulumi:"validationFraction"`
}

// Assigns the input data to training, validation, and test sets as per the given fractions. Any of `training_fraction`, `validation_fraction` and `test_fraction` may optionally be provided, they must sum to up to 1. If the provided ones sum to less than 1, the remainder is assigned to sets as decided by Vertex AI. If none of the fractions are set, by default roughly 80% of data is used for training, 10% for validation, and 10% for test.
type GoogleCloudAiplatformV1FractionSplitResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1FractionSplitResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1FractionSplitResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1FractionSplitResponseOutput) ToGoogleCloudAiplatformV1FractionSplitResponseOutput() GoogleCloudAiplatformV1FractionSplitResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1FractionSplitResponseOutput) ToGoogleCloudAiplatformV1FractionSplitResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1FractionSplitResponseOutput {
	return o
}

// The fraction of the input data that is to be used to evaluate the Model.
func (o GoogleCloudAiplatformV1FractionSplitResponseOutput) TestFraction() pulumi.Float64Output {
	return o.ApplyT(func(v GoogleCloudAiplatformV1FractionSplitResponse) float64 { return v.TestFraction }).(pulumi.Float64Output)
}

// The fraction of the input data that is to be used to train the Model.
func (o GoogleCloudAiplatformV1FractionSplitResponseOutput) TrainingFraction() pulumi.Float64Output {
	return o.ApplyT(func(v GoogleCloudAiplatformV1FractionSplitResponse) float64 { return v.TrainingFraction }).(pulumi.Float64Output)
}

// The fraction of the input data that is to be used to validate the Model.
func (o GoogleCloudAiplatformV1FractionSplitResponseOutput) ValidationFraction() pulumi.Float64Output {
	return o.ApplyT(func(v GoogleCloudAiplatformV1FractionSplitResponse) float64 { return v.ValidationFraction }).(pulumi.Float64Output)
}

// The Google Cloud Storage location where the output is to be written to.
type GoogleCloudAiplatformV1GcsDestination struct {
	// Google Cloud Storage URI to output directory. If the uri doesn't end with '/', a '/' will be automatically appended. The directory is created if it doesn't exist.
	OutputUriPrefix string `pulumi:"outputUriPrefix"`
}

// GoogleCloudAiplatformV1GcsDestinationInput is an input type that accepts GoogleCloudAiplatformV1GcsDestinationArgs and GoogleCloudAiplatformV1GcsDestinationOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1GcsDestinationInput` via:
//
//	GoogleCloudAiplatformV1GcsDestinationArgs{...}
type GoogleCloudAiplatformV1GcsDestinationInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1GcsDestinationOutput() GoogleCloudAiplatformV1GcsDestinationOutput
	ToGoogleCloudAiplatformV1GcsDestinationOutputWithContext(context.Context) GoogleCloudAiplatformV1GcsDestinationOutput
}

// The Google Cloud Storage location where the output is to be written to.
type GoogleCloudAiplatformV1GcsDestinationArgs struct {
	// Google Cloud Storage URI to output directory. If the uri doesn't end with '/', a '/' will be automatically appended. The directory is created if it doesn't exist.
	OutputUriPrefix pulumi.StringInput `pulumi:"outputUriPrefix"`
}

func (GoogleCloudAiplatformV1GcsDestinationArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1GcsDestination)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1GcsDestinationArgs) ToGoogleCloudAiplatformV1GcsDestinationOutput() GoogleCloudAiplatformV1GcsDestinationOutput {
	return i.ToGoogleCloudAiplatformV1GcsDestinationOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1GcsDestinationArgs) ToGoogleCloudAiplatformV1GcsDestinationOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1GcsDestinationOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1GcsDestinationOutput)
}

func (i GoogleCloudAiplatformV1GcsDestinationArgs) ToGoogleCloudAiplatformV1GcsDestinationPtrOutput() GoogleCloudAiplatformV1GcsDestinationPtrOutput {
	return i.ToGoogleCloudAiplatformV1GcsDestinationPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1GcsDestinationArgs) ToGoogleCloudAiplatformV1GcsDestinationPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1GcsDestinationPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1GcsDestinationOutput).ToGoogleCloudAiplatformV1GcsDestinationPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1GcsDestinationPtrInput is an input type that accepts GoogleCloudAiplatformV1GcsDestinationArgs, GoogleCloudAiplatformV1GcsDestinationPtr and GoogleCloudAiplatformV1GcsDestinationPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1GcsDestinationPtrInput` via:
//
//	        GoogleCloudAiplatformV1GcsDestinationArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1GcsDestinationPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1GcsDestinationPtrOutput() GoogleCloudAiplatformV1GcsDestinationPtrOutput
	ToGoogleCloudAiplatformV1GcsDestinationPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1GcsDestinationPtrOutput
}

type googleCloudAiplatformV1GcsDestinationPtrType GoogleCloudAiplatformV1GcsDestinationArgs

func GoogleCloudAiplatformV1GcsDestinationPtr(v *GoogleCloudAiplatformV1GcsDestinationArgs) GoogleCloudAiplatformV1GcsDestinationPtrInput {
	return (*googleCloudAiplatformV1GcsDestinationPtrType)(v)
}

func (*googleCloudAiplatformV1GcsDestinationPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1GcsDestination)(nil)).Elem()
}

func (i *googleCloudAiplatformV1GcsDestinationPtrType) ToGoogleCloudAiplatformV1GcsDestinationPtrOutput() GoogleCloudAiplatformV1GcsDestinationPtrOutput {
	return i.ToGoogleCloudAiplatformV1GcsDestinationPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1GcsDestinationPtrType) ToGoogleCloudAiplatformV1GcsDestinationPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1GcsDestinationPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1GcsDestinationPtrOutput)
}

// The Google Cloud Storage location where the output is to be written to.
type GoogleCloudAiplatformV1GcsDestinationOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1GcsDestinationOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1GcsDestination)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1GcsDestinationOutput) ToGoogleCloudAiplatformV1GcsDestinationOutput() GoogleCloudAiplatformV1GcsDestinationOutput {
	return o
}

func (o GoogleCloudAiplatformV1GcsDestinationOutput) ToGoogleCloudAiplatformV1GcsDestinationOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1GcsDestinationOutput {
	return o
}

func (o GoogleCloudAiplatformV1GcsDestinationOutput) ToGoogleCloudAiplatformV1GcsDestinationPtrOutput() GoogleCloudAiplatformV1GcsDestinationPtrOutput {
	return o.ToGoogleCloudAiplatformV1GcsDestinationPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1GcsDestinationOutput) ToGoogleCloudAiplatformV1GcsDestinationPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1GcsDestinationPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1GcsDestination) *GoogleCloudAiplatformV1GcsDestination {
		return &v
	}).(GoogleCloudAiplatformV1GcsDestinationPtrOutput)
}

// Google Cloud Storage URI to output directory. If the uri doesn't end with '/', a '/' will be automatically appended. The directory is created if it doesn't exist.
func (o GoogleCloudAiplatformV1GcsDestinationOutput) OutputUriPrefix() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1GcsDestination) string { return v.OutputUriPrefix }).(pulumi.StringOutput)
}

type GoogleCloudAiplatformV1GcsDestinationPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1GcsDestinationPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1GcsDestination)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1GcsDestinationPtrOutput) ToGoogleCloudAiplatformV1GcsDestinationPtrOutput() GoogleCloudAiplatformV1GcsDestinationPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1GcsDestinationPtrOutput) ToGoogleCloudAiplatformV1GcsDestinationPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1GcsDestinationPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1GcsDestinationPtrOutput) Elem() GoogleCloudAiplatformV1GcsDestinationOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1GcsDestination) GoogleCloudAiplatformV1GcsDestination {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1GcsDestination
		return ret
	}).(GoogleCloudAiplatformV1GcsDestinationOutput)
}

// Google Cloud Storage URI to output directory. If the uri doesn't end with '/', a '/' will be automatically appended. The directory is created if it doesn't exist.
func (o GoogleCloudAiplatformV1GcsDestinationPtrOutput) OutputUriPrefix() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1GcsDestination) *string {
		if v == nil {
			return nil
		}
		return &v.OutputUriPrefix
	}).(pulumi.StringPtrOutput)
}

// The Google Cloud Storage location where the output is to be written to.
type GoogleCloudAiplatformV1GcsDestinationResponse struct {
	// Google Cloud Storage URI to output directory. If the uri doesn't end with '/', a '/' will be automatically appended. The directory is created if it doesn't exist.
	OutputUriPrefix string `pulumi:"outputUriPrefix"`
}

// The Google Cloud Storage location where the output is to be written to.
type GoogleCloudAiplatformV1GcsDestinationResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1GcsDestinationResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1GcsDestinationResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1GcsDestinationResponseOutput) ToGoogleCloudAiplatformV1GcsDestinationResponseOutput() GoogleCloudAiplatformV1GcsDestinationResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1GcsDestinationResponseOutput) ToGoogleCloudAiplatformV1GcsDestinationResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1GcsDestinationResponseOutput {
	return o
}

// Google Cloud Storage URI to output directory. If the uri doesn't end with '/', a '/' will be automatically appended. The directory is created if it doesn't exist.
func (o GoogleCloudAiplatformV1GcsDestinationResponseOutput) OutputUriPrefix() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1GcsDestinationResponse) string { return v.OutputUriPrefix }).(pulumi.StringOutput)
}

// The Google Cloud Storage location for the input content.
type GoogleCloudAiplatformV1GcsSource struct {
	// Google Cloud Storage URI(-s) to the input file(s). May contain wildcards. For more information on wildcards, see https://cloud.google.com/storage/docs/gsutil/addlhelp/WildcardNames.
	Uris []string `pulumi:"uris"`
}

// GoogleCloudAiplatformV1GcsSourceInput is an input type that accepts GoogleCloudAiplatformV1GcsSourceArgs and GoogleCloudAiplatformV1GcsSourceOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1GcsSourceInput` via:
//
//	GoogleCloudAiplatformV1GcsSourceArgs{...}
type GoogleCloudAiplatformV1GcsSourceInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1GcsSourceOutput() GoogleCloudAiplatformV1GcsSourceOutput
	ToGoogleCloudAiplatformV1GcsSourceOutputWithContext(context.Context) GoogleCloudAiplatformV1GcsSourceOutput
}

// The Google Cloud Storage location for the input content.
type GoogleCloudAiplatformV1GcsSourceArgs struct {
	// Google Cloud Storage URI(-s) to the input file(s). May contain wildcards. For more information on wildcards, see https://cloud.google.com/storage/docs/gsutil/addlhelp/WildcardNames.
	Uris pulumi.StringArrayInput `pulumi:"uris"`
}

func (GoogleCloudAiplatformV1GcsSourceArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1GcsSource)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1GcsSourceArgs) ToGoogleCloudAiplatformV1GcsSourceOutput() GoogleCloudAiplatformV1GcsSourceOutput {
	return i.ToGoogleCloudAiplatformV1GcsSourceOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1GcsSourceArgs) ToGoogleCloudAiplatformV1GcsSourceOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1GcsSourceOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1GcsSourceOutput)
}

func (i GoogleCloudAiplatformV1GcsSourceArgs) ToGoogleCloudAiplatformV1GcsSourcePtrOutput() GoogleCloudAiplatformV1GcsSourcePtrOutput {
	return i.ToGoogleCloudAiplatformV1GcsSourcePtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1GcsSourceArgs) ToGoogleCloudAiplatformV1GcsSourcePtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1GcsSourcePtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1GcsSourceOutput).ToGoogleCloudAiplatformV1GcsSourcePtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1GcsSourcePtrInput is an input type that accepts GoogleCloudAiplatformV1GcsSourceArgs, GoogleCloudAiplatformV1GcsSourcePtr and GoogleCloudAiplatformV1GcsSourcePtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1GcsSourcePtrInput` via:
//
//	        GoogleCloudAiplatformV1GcsSourceArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1GcsSourcePtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1GcsSourcePtrOutput() GoogleCloudAiplatformV1GcsSourcePtrOutput
	ToGoogleCloudAiplatformV1GcsSourcePtrOutputWithContext(context.Context) GoogleCloudAiplatformV1GcsSourcePtrOutput
}

type googleCloudAiplatformV1GcsSourcePtrType GoogleCloudAiplatformV1GcsSourceArgs

func GoogleCloudAiplatformV1GcsSourcePtr(v *GoogleCloudAiplatformV1GcsSourceArgs) GoogleCloudAiplatformV1GcsSourcePtrInput {
	return (*googleCloudAiplatformV1GcsSourcePtrType)(v)
}

func (*googleCloudAiplatformV1GcsSourcePtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1GcsSource)(nil)).Elem()
}

func (i *googleCloudAiplatformV1GcsSourcePtrType) ToGoogleCloudAiplatformV1GcsSourcePtrOutput() GoogleCloudAiplatformV1GcsSourcePtrOutput {
	return i.ToGoogleCloudAiplatformV1GcsSourcePtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1GcsSourcePtrType) ToGoogleCloudAiplatformV1GcsSourcePtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1GcsSourcePtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1GcsSourcePtrOutput)
}

// The Google Cloud Storage location for the input content.
type GoogleCloudAiplatformV1GcsSourceOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1GcsSourceOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1GcsSource)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1GcsSourceOutput) ToGoogleCloudAiplatformV1GcsSourceOutput() GoogleCloudAiplatformV1GcsSourceOutput {
	return o
}

func (o GoogleCloudAiplatformV1GcsSourceOutput) ToGoogleCloudAiplatformV1GcsSourceOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1GcsSourceOutput {
	return o
}

func (o GoogleCloudAiplatformV1GcsSourceOutput) ToGoogleCloudAiplatformV1GcsSourcePtrOutput() GoogleCloudAiplatformV1GcsSourcePtrOutput {
	return o.ToGoogleCloudAiplatformV1GcsSourcePtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1GcsSourceOutput) ToGoogleCloudAiplatformV1GcsSourcePtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1GcsSourcePtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1GcsSource) *GoogleCloudAiplatformV1GcsSource {
		return &v
	}).(GoogleCloudAiplatformV1GcsSourcePtrOutput)
}

// Google Cloud Storage URI(-s) to the input file(s). May contain wildcards. For more information on wildcards, see https://cloud.google.com/storage/docs/gsutil/addlhelp/WildcardNames.
func (o GoogleCloudAiplatformV1GcsSourceOutput) Uris() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1GcsSource) []string { return v.Uris }).(pulumi.StringArrayOutput)
}

type GoogleCloudAiplatformV1GcsSourcePtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1GcsSourcePtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1GcsSource)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1GcsSourcePtrOutput) ToGoogleCloudAiplatformV1GcsSourcePtrOutput() GoogleCloudAiplatformV1GcsSourcePtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1GcsSourcePtrOutput) ToGoogleCloudAiplatformV1GcsSourcePtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1GcsSourcePtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1GcsSourcePtrOutput) Elem() GoogleCloudAiplatformV1GcsSourceOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1GcsSource) GoogleCloudAiplatformV1GcsSource {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1GcsSource
		return ret
	}).(GoogleCloudAiplatformV1GcsSourceOutput)
}

// Google Cloud Storage URI(-s) to the input file(s). May contain wildcards. For more information on wildcards, see https://cloud.google.com/storage/docs/gsutil/addlhelp/WildcardNames.
func (o GoogleCloudAiplatformV1GcsSourcePtrOutput) Uris() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1GcsSource) []string {
		if v == nil {
			return nil
		}
		return v.Uris
	}).(pulumi.StringArrayOutput)
}

// The Google Cloud Storage location for the input content.
type GoogleCloudAiplatformV1GcsSourceResponse struct {
	// Google Cloud Storage URI(-s) to the input file(s). May contain wildcards. For more information on wildcards, see https://cloud.google.com/storage/docs/gsutil/addlhelp/WildcardNames.
	Uris []string `pulumi:"uris"`
}

// The Google Cloud Storage location for the input content.
type GoogleCloudAiplatformV1GcsSourceResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1GcsSourceResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1GcsSourceResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1GcsSourceResponseOutput) ToGoogleCloudAiplatformV1GcsSourceResponseOutput() GoogleCloudAiplatformV1GcsSourceResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1GcsSourceResponseOutput) ToGoogleCloudAiplatformV1GcsSourceResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1GcsSourceResponseOutput {
	return o
}

// Google Cloud Storage URI(-s) to the input file(s). May contain wildcards. For more information on wildcards, see https://cloud.google.com/storage/docs/gsutil/addlhelp/WildcardNames.
func (o GoogleCloudAiplatformV1GcsSourceResponseOutput) Uris() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1GcsSourceResponse) []string { return v.Uris }).(pulumi.StringArrayOutput)
}

// IndexPrivateEndpoints proto is used to provide paths for users to send requests via private endpoints (e.g. private service access, private service connect). To send request via private service access, use match_grpc_address. To send request via private service connect, use service_attachment.
type GoogleCloudAiplatformV1IndexPrivateEndpointsResponse struct {
	// The ip address used to send match gRPC requests.
	MatchGrpcAddress string `pulumi:"matchGrpcAddress"`
	// The name of the service attachment resource. Populated if private service connect is enabled.
	ServiceAttachment string `pulumi:"serviceAttachment"`
}

// IndexPrivateEndpoints proto is used to provide paths for users to send requests via private endpoints (e.g. private service access, private service connect). To send request via private service access, use match_grpc_address. To send request via private service connect, use service_attachment.
type GoogleCloudAiplatformV1IndexPrivateEndpointsResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1IndexPrivateEndpointsResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1IndexPrivateEndpointsResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1IndexPrivateEndpointsResponseOutput) ToGoogleCloudAiplatformV1IndexPrivateEndpointsResponseOutput() GoogleCloudAiplatformV1IndexPrivateEndpointsResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1IndexPrivateEndpointsResponseOutput) ToGoogleCloudAiplatformV1IndexPrivateEndpointsResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1IndexPrivateEndpointsResponseOutput {
	return o
}

// The ip address used to send match gRPC requests.
func (o GoogleCloudAiplatformV1IndexPrivateEndpointsResponseOutput) MatchGrpcAddress() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1IndexPrivateEndpointsResponse) string { return v.MatchGrpcAddress }).(pulumi.StringOutput)
}

// The name of the service attachment resource. Populated if private service connect is enabled.
func (o GoogleCloudAiplatformV1IndexPrivateEndpointsResponseOutput) ServiceAttachment() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1IndexPrivateEndpointsResponse) string { return v.ServiceAttachment }).(pulumi.StringOutput)
}

// Stats of the Index.
type GoogleCloudAiplatformV1IndexStatsResponse struct {
	// The number of shards in the Index.
	ShardsCount int `pulumi:"shardsCount"`
	// The number of vectors in the Index.
	VectorsCount string `pulumi:"vectorsCount"`
}

// Stats of the Index.
type GoogleCloudAiplatformV1IndexStatsResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1IndexStatsResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1IndexStatsResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1IndexStatsResponseOutput) ToGoogleCloudAiplatformV1IndexStatsResponseOutput() GoogleCloudAiplatformV1IndexStatsResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1IndexStatsResponseOutput) ToGoogleCloudAiplatformV1IndexStatsResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1IndexStatsResponseOutput {
	return o
}

// The number of shards in the Index.
func (o GoogleCloudAiplatformV1IndexStatsResponseOutput) ShardsCount() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1IndexStatsResponse) int { return v.ShardsCount }).(pulumi.IntOutput)
}

// The number of vectors in the Index.
func (o GoogleCloudAiplatformV1IndexStatsResponseOutput) VectorsCount() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1IndexStatsResponse) string { return v.VectorsCount }).(pulumi.StringOutput)
}

// Specifies Vertex AI owned input data to be used for training, and possibly evaluating, the Model.
type GoogleCloudAiplatformV1InputDataConfig struct {
	// Applicable only to custom training with Datasets that have DataItems and Annotations. Cloud Storage URI that points to a YAML file describing the annotation schema. The schema is defined as an OpenAPI 3.0.2 [Schema Object](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject). The schema files that can be used here are found in gs://google-cloud-aiplatform/schema/dataset/annotation/ , note that the chosen schema must be consistent with metadata of the Dataset specified by dataset_id. Only Annotations that both match this schema and belong to DataItems not ignored by the split method are used in respectively training, validation or test role, depending on the role of the DataItem they are on. When used in conjunction with annotations_filter, the Annotations used for training are filtered by both annotations_filter and annotation_schema_uri.
	AnnotationSchemaUri *string `pulumi:"annotationSchemaUri"`
	// Applicable only to Datasets that have DataItems and Annotations. A filter on Annotations of the Dataset. Only Annotations that both match this filter and belong to DataItems not ignored by the split method are used in respectively training, validation or test role, depending on the role of the DataItem they are on (for the auto-assigned that role is decided by Vertex AI). A filter with same syntax as the one used in ListAnnotations may be used, but note here it filters across all Annotations of the Dataset, and not just within a single DataItem.
	AnnotationsFilter *string `pulumi:"annotationsFilter"`
	// Only applicable to custom training with tabular Dataset with BigQuery source. The BigQuery project location where the training data is to be written to. In the given project a new dataset is created with name `dataset___` where timestamp is in YYYY_MM_DDThh_mm_ss_sssZ format. All training input data is written into that dataset. In the dataset three tables are created, `training`, `validation` and `test`. * AIP_DATA_FORMAT = "bigquery". * AIP_TRAINING_DATA_URI = "bigquery_destination.dataset___.training" * AIP_VALIDATION_DATA_URI = "bigquery_destination.dataset___.validation" * AIP_TEST_DATA_URI = "bigquery_destination.dataset___.test"
	BigqueryDestination *GoogleCloudAiplatformV1BigQueryDestination `pulumi:"bigqueryDestination"`
	// The ID of the Dataset in the same Project and Location which data will be used to train the Model. The Dataset must use schema compatible with Model being trained, and what is compatible should be described in the used TrainingPipeline's training_task_definition. For tabular Datasets, all their data is exported to training, to pick and choose from.
	DatasetId string `pulumi:"datasetId"`
	// Split based on the provided filters for each set.
	FilterSplit *GoogleCloudAiplatformV1FilterSplit `pulumi:"filterSplit"`
	// Split based on fractions defining the size of each set.
	FractionSplit *GoogleCloudAiplatformV1FractionSplit `pulumi:"fractionSplit"`
	// The Cloud Storage location where the training data is to be written to. In the given directory a new directory is created with name: `dataset---` where timestamp is in YYYY-MM-DDThh:mm:ss.sssZ ISO-8601 format. All training input data is written into that directory. The Vertex AI environment variables representing Cloud Storage data URIs are represented in the Cloud Storage wildcard format to support sharded data. e.g.: "gs://.../training-*.jsonl" * AIP_DATA_FORMAT = "jsonl" for non-tabular data, "csv" for tabular data * AIP_TRAINING_DATA_URI = "gcs_destination/dataset---/training-*.${AIP_DATA_FORMAT}" * AIP_VALIDATION_DATA_URI = "gcs_destination/dataset---/validation-*.${AIP_DATA_FORMAT}" * AIP_TEST_DATA_URI = "gcs_destination/dataset---/test-*.${AIP_DATA_FORMAT}"
	GcsDestination *GoogleCloudAiplatformV1GcsDestination `pulumi:"gcsDestination"`
	// Whether to persist the ML use assignment to data item system labels.
	PersistMlUseAssignment *bool `pulumi:"persistMlUseAssignment"`
	// Supported only for tabular Datasets. Split based on a predefined key.
	PredefinedSplit *GoogleCloudAiplatformV1PredefinedSplit `pulumi:"predefinedSplit"`
	// Only applicable to Datasets that have SavedQueries. The ID of a SavedQuery (annotation set) under the Dataset specified by dataset_id used for filtering Annotations for training. Only Annotations that are associated with this SavedQuery are used in respectively training. When used in conjunction with annotations_filter, the Annotations used for training are filtered by both saved_query_id and annotations_filter. Only one of saved_query_id and annotation_schema_uri should be specified as both of them represent the same thing: problem type.
	SavedQueryId *string `pulumi:"savedQueryId"`
	// Supported only for tabular Datasets. Split based on the distribution of the specified column.
	StratifiedSplit *GoogleCloudAiplatformV1StratifiedSplit `pulumi:"stratifiedSplit"`
	// Supported only for tabular Datasets. Split based on the timestamp of the input data pieces.
	TimestampSplit *GoogleCloudAiplatformV1TimestampSplit `pulumi:"timestampSplit"`
}

// GoogleCloudAiplatformV1InputDataConfigInput is an input type that accepts GoogleCloudAiplatformV1InputDataConfigArgs and GoogleCloudAiplatformV1InputDataConfigOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1InputDataConfigInput` via:
//
//	GoogleCloudAiplatformV1InputDataConfigArgs{...}
type GoogleCloudAiplatformV1InputDataConfigInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1InputDataConfigOutput() GoogleCloudAiplatformV1InputDataConfigOutput
	ToGoogleCloudAiplatformV1InputDataConfigOutputWithContext(context.Context) GoogleCloudAiplatformV1InputDataConfigOutput
}

// Specifies Vertex AI owned input data to be used for training, and possibly evaluating, the Model.
type GoogleCloudAiplatformV1InputDataConfigArgs struct {
	// Applicable only to custom training with Datasets that have DataItems and Annotations. Cloud Storage URI that points to a YAML file describing the annotation schema. The schema is defined as an OpenAPI 3.0.2 [Schema Object](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject). The schema files that can be used here are found in gs://google-cloud-aiplatform/schema/dataset/annotation/ , note that the chosen schema must be consistent with metadata of the Dataset specified by dataset_id. Only Annotations that both match this schema and belong to DataItems not ignored by the split method are used in respectively training, validation or test role, depending on the role of the DataItem they are on. When used in conjunction with annotations_filter, the Annotations used for training are filtered by both annotations_filter and annotation_schema_uri.
	AnnotationSchemaUri pulumi.StringPtrInput `pulumi:"annotationSchemaUri"`
	// Applicable only to Datasets that have DataItems and Annotations. A filter on Annotations of the Dataset. Only Annotations that both match this filter and belong to DataItems not ignored by the split method are used in respectively training, validation or test role, depending on the role of the DataItem they are on (for the auto-assigned that role is decided by Vertex AI). A filter with same syntax as the one used in ListAnnotations may be used, but note here it filters across all Annotations of the Dataset, and not just within a single DataItem.
	AnnotationsFilter pulumi.StringPtrInput `pulumi:"annotationsFilter"`
	// Only applicable to custom training with tabular Dataset with BigQuery source. The BigQuery project location where the training data is to be written to. In the given project a new dataset is created with name `dataset___` where timestamp is in YYYY_MM_DDThh_mm_ss_sssZ format. All training input data is written into that dataset. In the dataset three tables are created, `training`, `validation` and `test`. * AIP_DATA_FORMAT = "bigquery". * AIP_TRAINING_DATA_URI = "bigquery_destination.dataset___.training" * AIP_VALIDATION_DATA_URI = "bigquery_destination.dataset___.validation" * AIP_TEST_DATA_URI = "bigquery_destination.dataset___.test"
	BigqueryDestination GoogleCloudAiplatformV1BigQueryDestinationPtrInput `pulumi:"bigqueryDestination"`
	// The ID of the Dataset in the same Project and Location which data will be used to train the Model. The Dataset must use schema compatible with Model being trained, and what is compatible should be described in the used TrainingPipeline's training_task_definition. For tabular Datasets, all their data is exported to training, to pick and choose from.
	DatasetId pulumi.StringInput `pulumi:"datasetId"`
	// Split based on the provided filters for each set.
	FilterSplit GoogleCloudAiplatformV1FilterSplitPtrInput `pulumi:"filterSplit"`
	// Split based on fractions defining the size of each set.
	FractionSplit GoogleCloudAiplatformV1FractionSplitPtrInput `pulumi:"fractionSplit"`
	// The Cloud Storage location where the training data is to be written to. In the given directory a new directory is created with name: `dataset---` where timestamp is in YYYY-MM-DDThh:mm:ss.sssZ ISO-8601 format. All training input data is written into that directory. The Vertex AI environment variables representing Cloud Storage data URIs are represented in the Cloud Storage wildcard format to support sharded data. e.g.: "gs://.../training-*.jsonl" * AIP_DATA_FORMAT = "jsonl" for non-tabular data, "csv" for tabular data * AIP_TRAINING_DATA_URI = "gcs_destination/dataset---/training-*.${AIP_DATA_FORMAT}" * AIP_VALIDATION_DATA_URI = "gcs_destination/dataset---/validation-*.${AIP_DATA_FORMAT}" * AIP_TEST_DATA_URI = "gcs_destination/dataset---/test-*.${AIP_DATA_FORMAT}"
	GcsDestination GoogleCloudAiplatformV1GcsDestinationPtrInput `pulumi:"gcsDestination"`
	// Whether to persist the ML use assignment to data item system labels.
	PersistMlUseAssignment pulumi.BoolPtrInput `pulumi:"persistMlUseAssignment"`
	// Supported only for tabular Datasets. Split based on a predefined key.
	PredefinedSplit GoogleCloudAiplatformV1PredefinedSplitPtrInput `pulumi:"predefinedSplit"`
	// Only applicable to Datasets that have SavedQueries. The ID of a SavedQuery (annotation set) under the Dataset specified by dataset_id used for filtering Annotations for training. Only Annotations that are associated with this SavedQuery are used in respectively training. When used in conjunction with annotations_filter, the Annotations used for training are filtered by both saved_query_id and annotations_filter. Only one of saved_query_id and annotation_schema_uri should be specified as both of them represent the same thing: problem type.
	SavedQueryId pulumi.StringPtrInput `pulumi:"savedQueryId"`
	// Supported only for tabular Datasets. Split based on the distribution of the specified column.
	StratifiedSplit GoogleCloudAiplatformV1StratifiedSplitPtrInput `pulumi:"stratifiedSplit"`
	// Supported only for tabular Datasets. Split based on the timestamp of the input data pieces.
	TimestampSplit GoogleCloudAiplatformV1TimestampSplitPtrInput `pulumi:"timestampSplit"`
}

func (GoogleCloudAiplatformV1InputDataConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1InputDataConfig)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1InputDataConfigArgs) ToGoogleCloudAiplatformV1InputDataConfigOutput() GoogleCloudAiplatformV1InputDataConfigOutput {
	return i.ToGoogleCloudAiplatformV1InputDataConfigOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1InputDataConfigArgs) ToGoogleCloudAiplatformV1InputDataConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1InputDataConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1InputDataConfigOutput)
}

func (i GoogleCloudAiplatformV1InputDataConfigArgs) ToGoogleCloudAiplatformV1InputDataConfigPtrOutput() GoogleCloudAiplatformV1InputDataConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1InputDataConfigPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1InputDataConfigArgs) ToGoogleCloudAiplatformV1InputDataConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1InputDataConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1InputDataConfigOutput).ToGoogleCloudAiplatformV1InputDataConfigPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1InputDataConfigPtrInput is an input type that accepts GoogleCloudAiplatformV1InputDataConfigArgs, GoogleCloudAiplatformV1InputDataConfigPtr and GoogleCloudAiplatformV1InputDataConfigPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1InputDataConfigPtrInput` via:
//
//	        GoogleCloudAiplatformV1InputDataConfigArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1InputDataConfigPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1InputDataConfigPtrOutput() GoogleCloudAiplatformV1InputDataConfigPtrOutput
	ToGoogleCloudAiplatformV1InputDataConfigPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1InputDataConfigPtrOutput
}

type googleCloudAiplatformV1InputDataConfigPtrType GoogleCloudAiplatformV1InputDataConfigArgs

func GoogleCloudAiplatformV1InputDataConfigPtr(v *GoogleCloudAiplatformV1InputDataConfigArgs) GoogleCloudAiplatformV1InputDataConfigPtrInput {
	return (*googleCloudAiplatformV1InputDataConfigPtrType)(v)
}

func (*googleCloudAiplatformV1InputDataConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1InputDataConfig)(nil)).Elem()
}

func (i *googleCloudAiplatformV1InputDataConfigPtrType) ToGoogleCloudAiplatformV1InputDataConfigPtrOutput() GoogleCloudAiplatformV1InputDataConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1InputDataConfigPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1InputDataConfigPtrType) ToGoogleCloudAiplatformV1InputDataConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1InputDataConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1InputDataConfigPtrOutput)
}

// Specifies Vertex AI owned input data to be used for training, and possibly evaluating, the Model.
type GoogleCloudAiplatformV1InputDataConfigOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1InputDataConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1InputDataConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1InputDataConfigOutput) ToGoogleCloudAiplatformV1InputDataConfigOutput() GoogleCloudAiplatformV1InputDataConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1InputDataConfigOutput) ToGoogleCloudAiplatformV1InputDataConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1InputDataConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1InputDataConfigOutput) ToGoogleCloudAiplatformV1InputDataConfigPtrOutput() GoogleCloudAiplatformV1InputDataConfigPtrOutput {
	return o.ToGoogleCloudAiplatformV1InputDataConfigPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1InputDataConfigOutput) ToGoogleCloudAiplatformV1InputDataConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1InputDataConfigPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1InputDataConfig) *GoogleCloudAiplatformV1InputDataConfig {
		return &v
	}).(GoogleCloudAiplatformV1InputDataConfigPtrOutput)
}

// Applicable only to custom training with Datasets that have DataItems and Annotations. Cloud Storage URI that points to a YAML file describing the annotation schema. The schema is defined as an OpenAPI 3.0.2 [Schema Object](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject). The schema files that can be used here are found in gs://google-cloud-aiplatform/schema/dataset/annotation/ , note that the chosen schema must be consistent with metadata of the Dataset specified by dataset_id. Only Annotations that both match this schema and belong to DataItems not ignored by the split method are used in respectively training, validation or test role, depending on the role of the DataItem they are on. When used in conjunction with annotations_filter, the Annotations used for training are filtered by both annotations_filter and annotation_schema_uri.
func (o GoogleCloudAiplatformV1InputDataConfigOutput) AnnotationSchemaUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1InputDataConfig) *string { return v.AnnotationSchemaUri }).(pulumi.StringPtrOutput)
}

// Applicable only to Datasets that have DataItems and Annotations. A filter on Annotations of the Dataset. Only Annotations that both match this filter and belong to DataItems not ignored by the split method are used in respectively training, validation or test role, depending on the role of the DataItem they are on (for the auto-assigned that role is decided by Vertex AI). A filter with same syntax as the one used in ListAnnotations may be used, but note here it filters across all Annotations of the Dataset, and not just within a single DataItem.
func (o GoogleCloudAiplatformV1InputDataConfigOutput) AnnotationsFilter() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1InputDataConfig) *string { return v.AnnotationsFilter }).(pulumi.StringPtrOutput)
}

// Only applicable to custom training with tabular Dataset with BigQuery source. The BigQuery project location where the training data is to be written to. In the given project a new dataset is created with name `dataset___` where timestamp is in YYYY_MM_DDThh_mm_ss_sssZ format. All training input data is written into that dataset. In the dataset three tables are created, `training`, `validation` and `test`. * AIP_DATA_FORMAT = "bigquery". * AIP_TRAINING_DATA_URI = "bigquery_destination.dataset___.training" * AIP_VALIDATION_DATA_URI = "bigquery_destination.dataset___.validation" * AIP_TEST_DATA_URI = "bigquery_destination.dataset___.test"
func (o GoogleCloudAiplatformV1InputDataConfigOutput) BigqueryDestination() GoogleCloudAiplatformV1BigQueryDestinationPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1InputDataConfig) *GoogleCloudAiplatformV1BigQueryDestination {
		return v.BigqueryDestination
	}).(GoogleCloudAiplatformV1BigQueryDestinationPtrOutput)
}

// The ID of the Dataset in the same Project and Location which data will be used to train the Model. The Dataset must use schema compatible with Model being trained, and what is compatible should be described in the used TrainingPipeline's training_task_definition. For tabular Datasets, all their data is exported to training, to pick and choose from.
func (o GoogleCloudAiplatformV1InputDataConfigOutput) DatasetId() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1InputDataConfig) string { return v.DatasetId }).(pulumi.StringOutput)
}

// Split based on the provided filters for each set.
func (o GoogleCloudAiplatformV1InputDataConfigOutput) FilterSplit() GoogleCloudAiplatformV1FilterSplitPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1InputDataConfig) *GoogleCloudAiplatformV1FilterSplit {
		return v.FilterSplit
	}).(GoogleCloudAiplatformV1FilterSplitPtrOutput)
}

// Split based on fractions defining the size of each set.
func (o GoogleCloudAiplatformV1InputDataConfigOutput) FractionSplit() GoogleCloudAiplatformV1FractionSplitPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1InputDataConfig) *GoogleCloudAiplatformV1FractionSplit {
		return v.FractionSplit
	}).(GoogleCloudAiplatformV1FractionSplitPtrOutput)
}

// The Cloud Storage location where the training data is to be written to. In the given directory a new directory is created with name: `dataset---` where timestamp is in YYYY-MM-DDThh:mm:ss.sssZ ISO-8601 format. All training input data is written into that directory. The Vertex AI environment variables representing Cloud Storage data URIs are represented in the Cloud Storage wildcard format to support sharded data. e.g.: "gs://.../training-*.jsonl" * AIP_DATA_FORMAT = "jsonl" for non-tabular data, "csv" for tabular data * AIP_TRAINING_DATA_URI = "gcs_destination/dataset---/training-*.${AIP_DATA_FORMAT}" * AIP_VALIDATION_DATA_URI = "gcs_destination/dataset---/validation-*.${AIP_DATA_FORMAT}" * AIP_TEST_DATA_URI = "gcs_destination/dataset---/test-*.${AIP_DATA_FORMAT}"
func (o GoogleCloudAiplatformV1InputDataConfigOutput) GcsDestination() GoogleCloudAiplatformV1GcsDestinationPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1InputDataConfig) *GoogleCloudAiplatformV1GcsDestination {
		return v.GcsDestination
	}).(GoogleCloudAiplatformV1GcsDestinationPtrOutput)
}

// Whether to persist the ML use assignment to data item system labels.
func (o GoogleCloudAiplatformV1InputDataConfigOutput) PersistMlUseAssignment() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1InputDataConfig) *bool { return v.PersistMlUseAssignment }).(pulumi.BoolPtrOutput)
}

// Supported only for tabular Datasets. Split based on a predefined key.
func (o GoogleCloudAiplatformV1InputDataConfigOutput) PredefinedSplit() GoogleCloudAiplatformV1PredefinedSplitPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1InputDataConfig) *GoogleCloudAiplatformV1PredefinedSplit {
		return v.PredefinedSplit
	}).(GoogleCloudAiplatformV1PredefinedSplitPtrOutput)
}

// Only applicable to Datasets that have SavedQueries. The ID of a SavedQuery (annotation set) under the Dataset specified by dataset_id used for filtering Annotations for training. Only Annotations that are associated with this SavedQuery are used in respectively training. When used in conjunction with annotations_filter, the Annotations used for training are filtered by both saved_query_id and annotations_filter. Only one of saved_query_id and annotation_schema_uri should be specified as both of them represent the same thing: problem type.
func (o GoogleCloudAiplatformV1InputDataConfigOutput) SavedQueryId() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1InputDataConfig) *string { return v.SavedQueryId }).(pulumi.StringPtrOutput)
}

// Supported only for tabular Datasets. Split based on the distribution of the specified column.
func (o GoogleCloudAiplatformV1InputDataConfigOutput) StratifiedSplit() GoogleCloudAiplatformV1StratifiedSplitPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1InputDataConfig) *GoogleCloudAiplatformV1StratifiedSplit {
		return v.StratifiedSplit
	}).(GoogleCloudAiplatformV1StratifiedSplitPtrOutput)
}

// Supported only for tabular Datasets. Split based on the timestamp of the input data pieces.
func (o GoogleCloudAiplatformV1InputDataConfigOutput) TimestampSplit() GoogleCloudAiplatformV1TimestampSplitPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1InputDataConfig) *GoogleCloudAiplatformV1TimestampSplit {
		return v.TimestampSplit
	}).(GoogleCloudAiplatformV1TimestampSplitPtrOutput)
}

type GoogleCloudAiplatformV1InputDataConfigPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1InputDataConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1InputDataConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1InputDataConfigPtrOutput) ToGoogleCloudAiplatformV1InputDataConfigPtrOutput() GoogleCloudAiplatformV1InputDataConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1InputDataConfigPtrOutput) ToGoogleCloudAiplatformV1InputDataConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1InputDataConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1InputDataConfigPtrOutput) Elem() GoogleCloudAiplatformV1InputDataConfigOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1InputDataConfig) GoogleCloudAiplatformV1InputDataConfig {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1InputDataConfig
		return ret
	}).(GoogleCloudAiplatformV1InputDataConfigOutput)
}

// Applicable only to custom training with Datasets that have DataItems and Annotations. Cloud Storage URI that points to a YAML file describing the annotation schema. The schema is defined as an OpenAPI 3.0.2 [Schema Object](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject). The schema files that can be used here are found in gs://google-cloud-aiplatform/schema/dataset/annotation/ , note that the chosen schema must be consistent with metadata of the Dataset specified by dataset_id. Only Annotations that both match this schema and belong to DataItems not ignored by the split method are used in respectively training, validation or test role, depending on the role of the DataItem they are on. When used in conjunction with annotations_filter, the Annotations used for training are filtered by both annotations_filter and annotation_schema_uri.
func (o GoogleCloudAiplatformV1InputDataConfigPtrOutput) AnnotationSchemaUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1InputDataConfig) *string {
		if v == nil {
			return nil
		}
		return v.AnnotationSchemaUri
	}).(pulumi.StringPtrOutput)
}

// Applicable only to Datasets that have DataItems and Annotations. A filter on Annotations of the Dataset. Only Annotations that both match this filter and belong to DataItems not ignored by the split method are used in respectively training, validation or test role, depending on the role of the DataItem they are on (for the auto-assigned that role is decided by Vertex AI). A filter with same syntax as the one used in ListAnnotations may be used, but note here it filters across all Annotations of the Dataset, and not just within a single DataItem.
func (o GoogleCloudAiplatformV1InputDataConfigPtrOutput) AnnotationsFilter() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1InputDataConfig) *string {
		if v == nil {
			return nil
		}
		return v.AnnotationsFilter
	}).(pulumi.StringPtrOutput)
}

// Only applicable to custom training with tabular Dataset with BigQuery source. The BigQuery project location where the training data is to be written to. In the given project a new dataset is created with name `dataset___` where timestamp is in YYYY_MM_DDThh_mm_ss_sssZ format. All training input data is written into that dataset. In the dataset three tables are created, `training`, `validation` and `test`. * AIP_DATA_FORMAT = "bigquery". * AIP_TRAINING_DATA_URI = "bigquery_destination.dataset___.training" * AIP_VALIDATION_DATA_URI = "bigquery_destination.dataset___.validation" * AIP_TEST_DATA_URI = "bigquery_destination.dataset___.test"
func (o GoogleCloudAiplatformV1InputDataConfigPtrOutput) BigqueryDestination() GoogleCloudAiplatformV1BigQueryDestinationPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1InputDataConfig) *GoogleCloudAiplatformV1BigQueryDestination {
		if v == nil {
			return nil
		}
		return v.BigqueryDestination
	}).(GoogleCloudAiplatformV1BigQueryDestinationPtrOutput)
}

// The ID of the Dataset in the same Project and Location which data will be used to train the Model. The Dataset must use schema compatible with Model being trained, and what is compatible should be described in the used TrainingPipeline's training_task_definition. For tabular Datasets, all their data is exported to training, to pick and choose from.
func (o GoogleCloudAiplatformV1InputDataConfigPtrOutput) DatasetId() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1InputDataConfig) *string {
		if v == nil {
			return nil
		}
		return &v.DatasetId
	}).(pulumi.StringPtrOutput)
}

// Split based on the provided filters for each set.
func (o GoogleCloudAiplatformV1InputDataConfigPtrOutput) FilterSplit() GoogleCloudAiplatformV1FilterSplitPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1InputDataConfig) *GoogleCloudAiplatformV1FilterSplit {
		if v == nil {
			return nil
		}
		return v.FilterSplit
	}).(GoogleCloudAiplatformV1FilterSplitPtrOutput)
}

// Split based on fractions defining the size of each set.
func (o GoogleCloudAiplatformV1InputDataConfigPtrOutput) FractionSplit() GoogleCloudAiplatformV1FractionSplitPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1InputDataConfig) *GoogleCloudAiplatformV1FractionSplit {
		if v == nil {
			return nil
		}
		return v.FractionSplit
	}).(GoogleCloudAiplatformV1FractionSplitPtrOutput)
}

// The Cloud Storage location where the training data is to be written to. In the given directory a new directory is created with name: `dataset---` where timestamp is in YYYY-MM-DDThh:mm:ss.sssZ ISO-8601 format. All training input data is written into that directory. The Vertex AI environment variables representing Cloud Storage data URIs are represented in the Cloud Storage wildcard format to support sharded data. e.g.: "gs://.../training-*.jsonl" * AIP_DATA_FORMAT = "jsonl" for non-tabular data, "csv" for tabular data * AIP_TRAINING_DATA_URI = "gcs_destination/dataset---/training-*.${AIP_DATA_FORMAT}" * AIP_VALIDATION_DATA_URI = "gcs_destination/dataset---/validation-*.${AIP_DATA_FORMAT}" * AIP_TEST_DATA_URI = "gcs_destination/dataset---/test-*.${AIP_DATA_FORMAT}"
func (o GoogleCloudAiplatformV1InputDataConfigPtrOutput) GcsDestination() GoogleCloudAiplatformV1GcsDestinationPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1InputDataConfig) *GoogleCloudAiplatformV1GcsDestination {
		if v == nil {
			return nil
		}
		return v.GcsDestination
	}).(GoogleCloudAiplatformV1GcsDestinationPtrOutput)
}

// Whether to persist the ML use assignment to data item system labels.
func (o GoogleCloudAiplatformV1InputDataConfigPtrOutput) PersistMlUseAssignment() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1InputDataConfig) *bool {
		if v == nil {
			return nil
		}
		return v.PersistMlUseAssignment
	}).(pulumi.BoolPtrOutput)
}

// Supported only for tabular Datasets. Split based on a predefined key.
func (o GoogleCloudAiplatformV1InputDataConfigPtrOutput) PredefinedSplit() GoogleCloudAiplatformV1PredefinedSplitPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1InputDataConfig) *GoogleCloudAiplatformV1PredefinedSplit {
		if v == nil {
			return nil
		}
		return v.PredefinedSplit
	}).(GoogleCloudAiplatformV1PredefinedSplitPtrOutput)
}

// Only applicable to Datasets that have SavedQueries. The ID of a SavedQuery (annotation set) under the Dataset specified by dataset_id used for filtering Annotations for training. Only Annotations that are associated with this SavedQuery are used in respectively training. When used in conjunction with annotations_filter, the Annotations used for training are filtered by both saved_query_id and annotations_filter. Only one of saved_query_id and annotation_schema_uri should be specified as both of them represent the same thing: problem type.
func (o GoogleCloudAiplatformV1InputDataConfigPtrOutput) SavedQueryId() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1InputDataConfig) *string {
		if v == nil {
			return nil
		}
		return v.SavedQueryId
	}).(pulumi.StringPtrOutput)
}

// Supported only for tabular Datasets. Split based on the distribution of the specified column.
func (o GoogleCloudAiplatformV1InputDataConfigPtrOutput) StratifiedSplit() GoogleCloudAiplatformV1StratifiedSplitPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1InputDataConfig) *GoogleCloudAiplatformV1StratifiedSplit {
		if v == nil {
			return nil
		}
		return v.StratifiedSplit
	}).(GoogleCloudAiplatformV1StratifiedSplitPtrOutput)
}

// Supported only for tabular Datasets. Split based on the timestamp of the input data pieces.
func (o GoogleCloudAiplatformV1InputDataConfigPtrOutput) TimestampSplit() GoogleCloudAiplatformV1TimestampSplitPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1InputDataConfig) *GoogleCloudAiplatformV1TimestampSplit {
		if v == nil {
			return nil
		}
		return v.TimestampSplit
	}).(GoogleCloudAiplatformV1TimestampSplitPtrOutput)
}

// Specifies Vertex AI owned input data to be used for training, and possibly evaluating, the Model.
type GoogleCloudAiplatformV1InputDataConfigResponse struct {
	// Applicable only to custom training with Datasets that have DataItems and Annotations. Cloud Storage URI that points to a YAML file describing the annotation schema. The schema is defined as an OpenAPI 3.0.2 [Schema Object](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject). The schema files that can be used here are found in gs://google-cloud-aiplatform/schema/dataset/annotation/ , note that the chosen schema must be consistent with metadata of the Dataset specified by dataset_id. Only Annotations that both match this schema and belong to DataItems not ignored by the split method are used in respectively training, validation or test role, depending on the role of the DataItem they are on. When used in conjunction with annotations_filter, the Annotations used for training are filtered by both annotations_filter and annotation_schema_uri.
	AnnotationSchemaUri string `pulumi:"annotationSchemaUri"`
	// Applicable only to Datasets that have DataItems and Annotations. A filter on Annotations of the Dataset. Only Annotations that both match this filter and belong to DataItems not ignored by the split method are used in respectively training, validation or test role, depending on the role of the DataItem they are on (for the auto-assigned that role is decided by Vertex AI). A filter with same syntax as the one used in ListAnnotations may be used, but note here it filters across all Annotations of the Dataset, and not just within a single DataItem.
	AnnotationsFilter string `pulumi:"annotationsFilter"`
	// Only applicable to custom training with tabular Dataset with BigQuery source. The BigQuery project location where the training data is to be written to. In the given project a new dataset is created with name `dataset___` where timestamp is in YYYY_MM_DDThh_mm_ss_sssZ format. All training input data is written into that dataset. In the dataset three tables are created, `training`, `validation` and `test`. * AIP_DATA_FORMAT = "bigquery". * AIP_TRAINING_DATA_URI = "bigquery_destination.dataset___.training" * AIP_VALIDATION_DATA_URI = "bigquery_destination.dataset___.validation" * AIP_TEST_DATA_URI = "bigquery_destination.dataset___.test"
	BigqueryDestination GoogleCloudAiplatformV1BigQueryDestinationResponse `pulumi:"bigqueryDestination"`
	// The ID of the Dataset in the same Project and Location which data will be used to train the Model. The Dataset must use schema compatible with Model being trained, and what is compatible should be described in the used TrainingPipeline's training_task_definition. For tabular Datasets, all their data is exported to training, to pick and choose from.
	DatasetId string `pulumi:"datasetId"`
	// Split based on the provided filters for each set.
	FilterSplit GoogleCloudAiplatformV1FilterSplitResponse `pulumi:"filterSplit"`
	// Split based on fractions defining the size of each set.
	FractionSplit GoogleCloudAiplatformV1FractionSplitResponse `pulumi:"fractionSplit"`
	// The Cloud Storage location where the training data is to be written to. In the given directory a new directory is created with name: `dataset---` where timestamp is in YYYY-MM-DDThh:mm:ss.sssZ ISO-8601 format. All training input data is written into that directory. The Vertex AI environment variables representing Cloud Storage data URIs are represented in the Cloud Storage wildcard format to support sharded data. e.g.: "gs://.../training-*.jsonl" * AIP_DATA_FORMAT = "jsonl" for non-tabular data, "csv" for tabular data * AIP_TRAINING_DATA_URI = "gcs_destination/dataset---/training-*.${AIP_DATA_FORMAT}" * AIP_VALIDATION_DATA_URI = "gcs_destination/dataset---/validation-*.${AIP_DATA_FORMAT}" * AIP_TEST_DATA_URI = "gcs_destination/dataset---/test-*.${AIP_DATA_FORMAT}"
	GcsDestination GoogleCloudAiplatformV1GcsDestinationResponse `pulumi:"gcsDestination"`
	// Whether to persist the ML use assignment to data item system labels.
	PersistMlUseAssignment bool `pulumi:"persistMlUseAssignment"`
	// Supported only for tabular Datasets. Split based on a predefined key.
	PredefinedSplit GoogleCloudAiplatformV1PredefinedSplitResponse `pulumi:"predefinedSplit"`
	// Only applicable to Datasets that have SavedQueries. The ID of a SavedQuery (annotation set) under the Dataset specified by dataset_id used for filtering Annotations for training. Only Annotations that are associated with this SavedQuery are used in respectively training. When used in conjunction with annotations_filter, the Annotations used for training are filtered by both saved_query_id and annotations_filter. Only one of saved_query_id and annotation_schema_uri should be specified as both of them represent the same thing: problem type.
	SavedQueryId string `pulumi:"savedQueryId"`
	// Supported only for tabular Datasets. Split based on the distribution of the specified column.
	StratifiedSplit GoogleCloudAiplatformV1StratifiedSplitResponse `pulumi:"stratifiedSplit"`
	// Supported only for tabular Datasets. Split based on the timestamp of the input data pieces.
	TimestampSplit GoogleCloudAiplatformV1TimestampSplitResponse `pulumi:"timestampSplit"`
}

// Specifies Vertex AI owned input data to be used for training, and possibly evaluating, the Model.
type GoogleCloudAiplatformV1InputDataConfigResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1InputDataConfigResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1InputDataConfigResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1InputDataConfigResponseOutput) ToGoogleCloudAiplatformV1InputDataConfigResponseOutput() GoogleCloudAiplatformV1InputDataConfigResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1InputDataConfigResponseOutput) ToGoogleCloudAiplatformV1InputDataConfigResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1InputDataConfigResponseOutput {
	return o
}

// Applicable only to custom training with Datasets that have DataItems and Annotations. Cloud Storage URI that points to a YAML file describing the annotation schema. The schema is defined as an OpenAPI 3.0.2 [Schema Object](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject). The schema files that can be used here are found in gs://google-cloud-aiplatform/schema/dataset/annotation/ , note that the chosen schema must be consistent with metadata of the Dataset specified by dataset_id. Only Annotations that both match this schema and belong to DataItems not ignored by the split method are used in respectively training, validation or test role, depending on the role of the DataItem they are on. When used in conjunction with annotations_filter, the Annotations used for training are filtered by both annotations_filter and annotation_schema_uri.
func (o GoogleCloudAiplatformV1InputDataConfigResponseOutput) AnnotationSchemaUri() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1InputDataConfigResponse) string { return v.AnnotationSchemaUri }).(pulumi.StringOutput)
}

// Applicable only to Datasets that have DataItems and Annotations. A filter on Annotations of the Dataset. Only Annotations that both match this filter and belong to DataItems not ignored by the split method are used in respectively training, validation or test role, depending on the role of the DataItem they are on (for the auto-assigned that role is decided by Vertex AI). A filter with same syntax as the one used in ListAnnotations may be used, but note here it filters across all Annotations of the Dataset, and not just within a single DataItem.
func (o GoogleCloudAiplatformV1InputDataConfigResponseOutput) AnnotationsFilter() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1InputDataConfigResponse) string { return v.AnnotationsFilter }).(pulumi.StringOutput)
}

// Only applicable to custom training with tabular Dataset with BigQuery source. The BigQuery project location where the training data is to be written to. In the given project a new dataset is created with name `dataset___` where timestamp is in YYYY_MM_DDThh_mm_ss_sssZ format. All training input data is written into that dataset. In the dataset three tables are created, `training`, `validation` and `test`. * AIP_DATA_FORMAT = "bigquery". * AIP_TRAINING_DATA_URI = "bigquery_destination.dataset___.training" * AIP_VALIDATION_DATA_URI = "bigquery_destination.dataset___.validation" * AIP_TEST_DATA_URI = "bigquery_destination.dataset___.test"
func (o GoogleCloudAiplatformV1InputDataConfigResponseOutput) BigqueryDestination() GoogleCloudAiplatformV1BigQueryDestinationResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1InputDataConfigResponse) GoogleCloudAiplatformV1BigQueryDestinationResponse {
		return v.BigqueryDestination
	}).(GoogleCloudAiplatformV1BigQueryDestinationResponseOutput)
}

// The ID of the Dataset in the same Project and Location which data will be used to train the Model. The Dataset must use schema compatible with Model being trained, and what is compatible should be described in the used TrainingPipeline's training_task_definition. For tabular Datasets, all their data is exported to training, to pick and choose from.
func (o GoogleCloudAiplatformV1InputDataConfigResponseOutput) DatasetId() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1InputDataConfigResponse) string { return v.DatasetId }).(pulumi.StringOutput)
}

// Split based on the provided filters for each set.
func (o GoogleCloudAiplatformV1InputDataConfigResponseOutput) FilterSplit() GoogleCloudAiplatformV1FilterSplitResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1InputDataConfigResponse) GoogleCloudAiplatformV1FilterSplitResponse {
		return v.FilterSplit
	}).(GoogleCloudAiplatformV1FilterSplitResponseOutput)
}

// Split based on fractions defining the size of each set.
func (o GoogleCloudAiplatformV1InputDataConfigResponseOutput) FractionSplit() GoogleCloudAiplatformV1FractionSplitResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1InputDataConfigResponse) GoogleCloudAiplatformV1FractionSplitResponse {
		return v.FractionSplit
	}).(GoogleCloudAiplatformV1FractionSplitResponseOutput)
}

// The Cloud Storage location where the training data is to be written to. In the given directory a new directory is created with name: `dataset---` where timestamp is in YYYY-MM-DDThh:mm:ss.sssZ ISO-8601 format. All training input data is written into that directory. The Vertex AI environment variables representing Cloud Storage data URIs are represented in the Cloud Storage wildcard format to support sharded data. e.g.: "gs://.../training-*.jsonl" * AIP_DATA_FORMAT = "jsonl" for non-tabular data, "csv" for tabular data * AIP_TRAINING_DATA_URI = "gcs_destination/dataset---/training-*.${AIP_DATA_FORMAT}" * AIP_VALIDATION_DATA_URI = "gcs_destination/dataset---/validation-*.${AIP_DATA_FORMAT}" * AIP_TEST_DATA_URI = "gcs_destination/dataset---/test-*.${AIP_DATA_FORMAT}"
func (o GoogleCloudAiplatformV1InputDataConfigResponseOutput) GcsDestination() GoogleCloudAiplatformV1GcsDestinationResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1InputDataConfigResponse) GoogleCloudAiplatformV1GcsDestinationResponse {
		return v.GcsDestination
	}).(GoogleCloudAiplatformV1GcsDestinationResponseOutput)
}

// Whether to persist the ML use assignment to data item system labels.
func (o GoogleCloudAiplatformV1InputDataConfigResponseOutput) PersistMlUseAssignment() pulumi.BoolOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1InputDataConfigResponse) bool { return v.PersistMlUseAssignment }).(pulumi.BoolOutput)
}

// Supported only for tabular Datasets. Split based on a predefined key.
func (o GoogleCloudAiplatformV1InputDataConfigResponseOutput) PredefinedSplit() GoogleCloudAiplatformV1PredefinedSplitResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1InputDataConfigResponse) GoogleCloudAiplatformV1PredefinedSplitResponse {
		return v.PredefinedSplit
	}).(GoogleCloudAiplatformV1PredefinedSplitResponseOutput)
}

// Only applicable to Datasets that have SavedQueries. The ID of a SavedQuery (annotation set) under the Dataset specified by dataset_id used for filtering Annotations for training. Only Annotations that are associated with this SavedQuery are used in respectively training. When used in conjunction with annotations_filter, the Annotations used for training are filtered by both saved_query_id and annotations_filter. Only one of saved_query_id and annotation_schema_uri should be specified as both of them represent the same thing: problem type.
func (o GoogleCloudAiplatformV1InputDataConfigResponseOutput) SavedQueryId() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1InputDataConfigResponse) string { return v.SavedQueryId }).(pulumi.StringOutput)
}

// Supported only for tabular Datasets. Split based on the distribution of the specified column.
func (o GoogleCloudAiplatformV1InputDataConfigResponseOutput) StratifiedSplit() GoogleCloudAiplatformV1StratifiedSplitResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1InputDataConfigResponse) GoogleCloudAiplatformV1StratifiedSplitResponse {
		return v.StratifiedSplit
	}).(GoogleCloudAiplatformV1StratifiedSplitResponseOutput)
}

// Supported only for tabular Datasets. Split based on the timestamp of the input data pieces.
func (o GoogleCloudAiplatformV1InputDataConfigResponseOutput) TimestampSplit() GoogleCloudAiplatformV1TimestampSplitResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1InputDataConfigResponse) GoogleCloudAiplatformV1TimestampSplitResponse {
		return v.TimestampSplit
	}).(GoogleCloudAiplatformV1TimestampSplitResponseOutput)
}

// An attribution method that computes the Aumann-Shapley value taking advantage of the model's fully differentiable structure. Refer to this paper for more details: https://arxiv.org/abs/1703.01365
type GoogleCloudAiplatformV1IntegratedGradientsAttribution struct {
	// Config for IG with blur baseline. When enabled, a linear path from the maximally blurred image to the input image is created. Using a blurred baseline instead of zero (black image) is motivated by the BlurIG approach explained here: https://arxiv.org/abs/2004.03383
	BlurBaselineConfig *GoogleCloudAiplatformV1BlurBaselineConfig `pulumi:"blurBaselineConfig"`
	// Config for SmoothGrad approximation of gradients. When enabled, the gradients are approximated by averaging the gradients from noisy samples in the vicinity of the inputs. Adding noise can help improve the computed gradients. Refer to this paper for more details: https://arxiv.org/pdf/1706.03825.pdf
	SmoothGradConfig *GoogleCloudAiplatformV1SmoothGradConfig `pulumi:"smoothGradConfig"`
	// The number of steps for approximating the path integral. A good value to start is 50 and gradually increase until the sum to diff property is within the desired error range. Valid range of its value is [1, 100], inclusively.
	StepCount int `pulumi:"stepCount"`
}

// GoogleCloudAiplatformV1IntegratedGradientsAttributionInput is an input type that accepts GoogleCloudAiplatformV1IntegratedGradientsAttributionArgs and GoogleCloudAiplatformV1IntegratedGradientsAttributionOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1IntegratedGradientsAttributionInput` via:
//
//	GoogleCloudAiplatformV1IntegratedGradientsAttributionArgs{...}
type GoogleCloudAiplatformV1IntegratedGradientsAttributionInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1IntegratedGradientsAttributionOutput() GoogleCloudAiplatformV1IntegratedGradientsAttributionOutput
	ToGoogleCloudAiplatformV1IntegratedGradientsAttributionOutputWithContext(context.Context) GoogleCloudAiplatformV1IntegratedGradientsAttributionOutput
}

// An attribution method that computes the Aumann-Shapley value taking advantage of the model's fully differentiable structure. Refer to this paper for more details: https://arxiv.org/abs/1703.01365
type GoogleCloudAiplatformV1IntegratedGradientsAttributionArgs struct {
	// Config for IG with blur baseline. When enabled, a linear path from the maximally blurred image to the input image is created. Using a blurred baseline instead of zero (black image) is motivated by the BlurIG approach explained here: https://arxiv.org/abs/2004.03383
	BlurBaselineConfig GoogleCloudAiplatformV1BlurBaselineConfigPtrInput `pulumi:"blurBaselineConfig"`
	// Config for SmoothGrad approximation of gradients. When enabled, the gradients are approximated by averaging the gradients from noisy samples in the vicinity of the inputs. Adding noise can help improve the computed gradients. Refer to this paper for more details: https://arxiv.org/pdf/1706.03825.pdf
	SmoothGradConfig GoogleCloudAiplatformV1SmoothGradConfigPtrInput `pulumi:"smoothGradConfig"`
	// The number of steps for approximating the path integral. A good value to start is 50 and gradually increase until the sum to diff property is within the desired error range. Valid range of its value is [1, 100], inclusively.
	StepCount pulumi.IntInput `pulumi:"stepCount"`
}

func (GoogleCloudAiplatformV1IntegratedGradientsAttributionArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1IntegratedGradientsAttribution)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1IntegratedGradientsAttributionArgs) ToGoogleCloudAiplatformV1IntegratedGradientsAttributionOutput() GoogleCloudAiplatformV1IntegratedGradientsAttributionOutput {
	return i.ToGoogleCloudAiplatformV1IntegratedGradientsAttributionOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1IntegratedGradientsAttributionArgs) ToGoogleCloudAiplatformV1IntegratedGradientsAttributionOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1IntegratedGradientsAttributionOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1IntegratedGradientsAttributionOutput)
}

func (i GoogleCloudAiplatformV1IntegratedGradientsAttributionArgs) ToGoogleCloudAiplatformV1IntegratedGradientsAttributionPtrOutput() GoogleCloudAiplatformV1IntegratedGradientsAttributionPtrOutput {
	return i.ToGoogleCloudAiplatformV1IntegratedGradientsAttributionPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1IntegratedGradientsAttributionArgs) ToGoogleCloudAiplatformV1IntegratedGradientsAttributionPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1IntegratedGradientsAttributionPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1IntegratedGradientsAttributionOutput).ToGoogleCloudAiplatformV1IntegratedGradientsAttributionPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1IntegratedGradientsAttributionPtrInput is an input type that accepts GoogleCloudAiplatformV1IntegratedGradientsAttributionArgs, GoogleCloudAiplatformV1IntegratedGradientsAttributionPtr and GoogleCloudAiplatformV1IntegratedGradientsAttributionPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1IntegratedGradientsAttributionPtrInput` via:
//
//	        GoogleCloudAiplatformV1IntegratedGradientsAttributionArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1IntegratedGradientsAttributionPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1IntegratedGradientsAttributionPtrOutput() GoogleCloudAiplatformV1IntegratedGradientsAttributionPtrOutput
	ToGoogleCloudAiplatformV1IntegratedGradientsAttributionPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1IntegratedGradientsAttributionPtrOutput
}

type googleCloudAiplatformV1IntegratedGradientsAttributionPtrType GoogleCloudAiplatformV1IntegratedGradientsAttributionArgs

func GoogleCloudAiplatformV1IntegratedGradientsAttributionPtr(v *GoogleCloudAiplatformV1IntegratedGradientsAttributionArgs) GoogleCloudAiplatformV1IntegratedGradientsAttributionPtrInput {
	return (*googleCloudAiplatformV1IntegratedGradientsAttributionPtrType)(v)
}

func (*googleCloudAiplatformV1IntegratedGradientsAttributionPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1IntegratedGradientsAttribution)(nil)).Elem()
}

func (i *googleCloudAiplatformV1IntegratedGradientsAttributionPtrType) ToGoogleCloudAiplatformV1IntegratedGradientsAttributionPtrOutput() GoogleCloudAiplatformV1IntegratedGradientsAttributionPtrOutput {
	return i.ToGoogleCloudAiplatformV1IntegratedGradientsAttributionPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1IntegratedGradientsAttributionPtrType) ToGoogleCloudAiplatformV1IntegratedGradientsAttributionPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1IntegratedGradientsAttributionPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1IntegratedGradientsAttributionPtrOutput)
}

// An attribution method that computes the Aumann-Shapley value taking advantage of the model's fully differentiable structure. Refer to this paper for more details: https://arxiv.org/abs/1703.01365
type GoogleCloudAiplatformV1IntegratedGradientsAttributionOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1IntegratedGradientsAttributionOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1IntegratedGradientsAttribution)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1IntegratedGradientsAttributionOutput) ToGoogleCloudAiplatformV1IntegratedGradientsAttributionOutput() GoogleCloudAiplatformV1IntegratedGradientsAttributionOutput {
	return o
}

func (o GoogleCloudAiplatformV1IntegratedGradientsAttributionOutput) ToGoogleCloudAiplatformV1IntegratedGradientsAttributionOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1IntegratedGradientsAttributionOutput {
	return o
}

func (o GoogleCloudAiplatformV1IntegratedGradientsAttributionOutput) ToGoogleCloudAiplatformV1IntegratedGradientsAttributionPtrOutput() GoogleCloudAiplatformV1IntegratedGradientsAttributionPtrOutput {
	return o.ToGoogleCloudAiplatformV1IntegratedGradientsAttributionPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1IntegratedGradientsAttributionOutput) ToGoogleCloudAiplatformV1IntegratedGradientsAttributionPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1IntegratedGradientsAttributionPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1IntegratedGradientsAttribution) *GoogleCloudAiplatformV1IntegratedGradientsAttribution {
		return &v
	}).(GoogleCloudAiplatformV1IntegratedGradientsAttributionPtrOutput)
}

// Config for IG with blur baseline. When enabled, a linear path from the maximally blurred image to the input image is created. Using a blurred baseline instead of zero (black image) is motivated by the BlurIG approach explained here: https://arxiv.org/abs/2004.03383
func (o GoogleCloudAiplatformV1IntegratedGradientsAttributionOutput) BlurBaselineConfig() GoogleCloudAiplatformV1BlurBaselineConfigPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1IntegratedGradientsAttribution) *GoogleCloudAiplatformV1BlurBaselineConfig {
		return v.BlurBaselineConfig
	}).(GoogleCloudAiplatformV1BlurBaselineConfigPtrOutput)
}

// Config for SmoothGrad approximation of gradients. When enabled, the gradients are approximated by averaging the gradients from noisy samples in the vicinity of the inputs. Adding noise can help improve the computed gradients. Refer to this paper for more details: https://arxiv.org/pdf/1706.03825.pdf
func (o GoogleCloudAiplatformV1IntegratedGradientsAttributionOutput) SmoothGradConfig() GoogleCloudAiplatformV1SmoothGradConfigPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1IntegratedGradientsAttribution) *GoogleCloudAiplatformV1SmoothGradConfig {
		return v.SmoothGradConfig
	}).(GoogleCloudAiplatformV1SmoothGradConfigPtrOutput)
}

// The number of steps for approximating the path integral. A good value to start is 50 and gradually increase until the sum to diff property is within the desired error range. Valid range of its value is [1, 100], inclusively.
func (o GoogleCloudAiplatformV1IntegratedGradientsAttributionOutput) StepCount() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1IntegratedGradientsAttribution) int { return v.StepCount }).(pulumi.IntOutput)
}

type GoogleCloudAiplatformV1IntegratedGradientsAttributionPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1IntegratedGradientsAttributionPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1IntegratedGradientsAttribution)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1IntegratedGradientsAttributionPtrOutput) ToGoogleCloudAiplatformV1IntegratedGradientsAttributionPtrOutput() GoogleCloudAiplatformV1IntegratedGradientsAttributionPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1IntegratedGradientsAttributionPtrOutput) ToGoogleCloudAiplatformV1IntegratedGradientsAttributionPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1IntegratedGradientsAttributionPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1IntegratedGradientsAttributionPtrOutput) Elem() GoogleCloudAiplatformV1IntegratedGradientsAttributionOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1IntegratedGradientsAttribution) GoogleCloudAiplatformV1IntegratedGradientsAttribution {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1IntegratedGradientsAttribution
		return ret
	}).(GoogleCloudAiplatformV1IntegratedGradientsAttributionOutput)
}

// Config for IG with blur baseline. When enabled, a linear path from the maximally blurred image to the input image is created. Using a blurred baseline instead of zero (black image) is motivated by the BlurIG approach explained here: https://arxiv.org/abs/2004.03383
func (o GoogleCloudAiplatformV1IntegratedGradientsAttributionPtrOutput) BlurBaselineConfig() GoogleCloudAiplatformV1BlurBaselineConfigPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1IntegratedGradientsAttribution) *GoogleCloudAiplatformV1BlurBaselineConfig {
		if v == nil {
			return nil
		}
		return v.BlurBaselineConfig
	}).(GoogleCloudAiplatformV1BlurBaselineConfigPtrOutput)
}

// Config for SmoothGrad approximation of gradients. When enabled, the gradients are approximated by averaging the gradients from noisy samples in the vicinity of the inputs. Adding noise can help improve the computed gradients. Refer to this paper for more details: https://arxiv.org/pdf/1706.03825.pdf
func (o GoogleCloudAiplatformV1IntegratedGradientsAttributionPtrOutput) SmoothGradConfig() GoogleCloudAiplatformV1SmoothGradConfigPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1IntegratedGradientsAttribution) *GoogleCloudAiplatformV1SmoothGradConfig {
		if v == nil {
			return nil
		}
		return v.SmoothGradConfig
	}).(GoogleCloudAiplatformV1SmoothGradConfigPtrOutput)
}

// The number of steps for approximating the path integral. A good value to start is 50 and gradually increase until the sum to diff property is within the desired error range. Valid range of its value is [1, 100], inclusively.
func (o GoogleCloudAiplatformV1IntegratedGradientsAttributionPtrOutput) StepCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1IntegratedGradientsAttribution) *int {
		if v == nil {
			return nil
		}
		return &v.StepCount
	}).(pulumi.IntPtrOutput)
}

// An attribution method that computes the Aumann-Shapley value taking advantage of the model's fully differentiable structure. Refer to this paper for more details: https://arxiv.org/abs/1703.01365
type GoogleCloudAiplatformV1IntegratedGradientsAttributionResponse struct {
	// Config for IG with blur baseline. When enabled, a linear path from the maximally blurred image to the input image is created. Using a blurred baseline instead of zero (black image) is motivated by the BlurIG approach explained here: https://arxiv.org/abs/2004.03383
	BlurBaselineConfig GoogleCloudAiplatformV1BlurBaselineConfigResponse `pulumi:"blurBaselineConfig"`
	// Config for SmoothGrad approximation of gradients. When enabled, the gradients are approximated by averaging the gradients from noisy samples in the vicinity of the inputs. Adding noise can help improve the computed gradients. Refer to this paper for more details: https://arxiv.org/pdf/1706.03825.pdf
	SmoothGradConfig GoogleCloudAiplatformV1SmoothGradConfigResponse `pulumi:"smoothGradConfig"`
	// The number of steps for approximating the path integral. A good value to start is 50 and gradually increase until the sum to diff property is within the desired error range. Valid range of its value is [1, 100], inclusively.
	StepCount int `pulumi:"stepCount"`
}

// An attribution method that computes the Aumann-Shapley value taking advantage of the model's fully differentiable structure. Refer to this paper for more details: https://arxiv.org/abs/1703.01365
type GoogleCloudAiplatformV1IntegratedGradientsAttributionResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1IntegratedGradientsAttributionResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1IntegratedGradientsAttributionResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1IntegratedGradientsAttributionResponseOutput) ToGoogleCloudAiplatformV1IntegratedGradientsAttributionResponseOutput() GoogleCloudAiplatformV1IntegratedGradientsAttributionResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1IntegratedGradientsAttributionResponseOutput) ToGoogleCloudAiplatformV1IntegratedGradientsAttributionResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1IntegratedGradientsAttributionResponseOutput {
	return o
}

// Config for IG with blur baseline. When enabled, a linear path from the maximally blurred image to the input image is created. Using a blurred baseline instead of zero (black image) is motivated by the BlurIG approach explained here: https://arxiv.org/abs/2004.03383
func (o GoogleCloudAiplatformV1IntegratedGradientsAttributionResponseOutput) BlurBaselineConfig() GoogleCloudAiplatformV1BlurBaselineConfigResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1IntegratedGradientsAttributionResponse) GoogleCloudAiplatformV1BlurBaselineConfigResponse {
		return v.BlurBaselineConfig
	}).(GoogleCloudAiplatformV1BlurBaselineConfigResponseOutput)
}

// Config for SmoothGrad approximation of gradients. When enabled, the gradients are approximated by averaging the gradients from noisy samples in the vicinity of the inputs. Adding noise can help improve the computed gradients. Refer to this paper for more details: https://arxiv.org/pdf/1706.03825.pdf
func (o GoogleCloudAiplatformV1IntegratedGradientsAttributionResponseOutput) SmoothGradConfig() GoogleCloudAiplatformV1SmoothGradConfigResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1IntegratedGradientsAttributionResponse) GoogleCloudAiplatformV1SmoothGradConfigResponse {
		return v.SmoothGradConfig
	}).(GoogleCloudAiplatformV1SmoothGradConfigResponseOutput)
}

// The number of steps for approximating the path integral. A good value to start is 50 and gradually increase until the sum to diff property is within the desired error range. Valid range of its value is [1, 100], inclusively.
func (o GoogleCloudAiplatformV1IntegratedGradientsAttributionResponseOutput) StepCount() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1IntegratedGradientsAttributionResponse) int { return v.StepCount }).(pulumi.IntOutput)
}

// Specification of a single machine.
type GoogleCloudAiplatformV1MachineSpec struct {
	// The number of accelerators to attach to the machine.
	AcceleratorCount *int `pulumi:"acceleratorCount"`
	// Immutable. The type of accelerator(s) that may be attached to the machine as per accelerator_count.
	AcceleratorType *GoogleCloudAiplatformV1MachineSpecAcceleratorType `pulumi:"acceleratorType"`
	// Immutable. The type of the machine. See the [list of machine types supported for prediction](https://cloud.google.com/vertex-ai/docs/predictions/configure-compute#machine-types) See the [list of machine types supported for custom training](https://cloud.google.com/vertex-ai/docs/training/configure-compute#machine-types). For DeployedModel this field is optional, and the default value is `n1-standard-2`. For BatchPredictionJob or as part of WorkerPoolSpec this field is required.
	MachineType *string `pulumi:"machineType"`
	// Immutable. The topology of the TPUs. Corresponds to the TPU topologies available from GKE. (Example: tpu_topology: "2x2x1").
	TpuTopology *string `pulumi:"tpuTopology"`
}

// GoogleCloudAiplatformV1MachineSpecInput is an input type that accepts GoogleCloudAiplatformV1MachineSpecArgs and GoogleCloudAiplatformV1MachineSpecOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1MachineSpecInput` via:
//
//	GoogleCloudAiplatformV1MachineSpecArgs{...}
type GoogleCloudAiplatformV1MachineSpecInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1MachineSpecOutput() GoogleCloudAiplatformV1MachineSpecOutput
	ToGoogleCloudAiplatformV1MachineSpecOutputWithContext(context.Context) GoogleCloudAiplatformV1MachineSpecOutput
}

// Specification of a single machine.
type GoogleCloudAiplatformV1MachineSpecArgs struct {
	// The number of accelerators to attach to the machine.
	AcceleratorCount pulumi.IntPtrInput `pulumi:"acceleratorCount"`
	// Immutable. The type of accelerator(s) that may be attached to the machine as per accelerator_count.
	AcceleratorType GoogleCloudAiplatformV1MachineSpecAcceleratorTypePtrInput `pulumi:"acceleratorType"`
	// Immutable. The type of the machine. See the [list of machine types supported for prediction](https://cloud.google.com/vertex-ai/docs/predictions/configure-compute#machine-types) See the [list of machine types supported for custom training](https://cloud.google.com/vertex-ai/docs/training/configure-compute#machine-types). For DeployedModel this field is optional, and the default value is `n1-standard-2`. For BatchPredictionJob or as part of WorkerPoolSpec this field is required.
	MachineType pulumi.StringPtrInput `pulumi:"machineType"`
	// Immutable. The topology of the TPUs. Corresponds to the TPU topologies available from GKE. (Example: tpu_topology: "2x2x1").
	TpuTopology pulumi.StringPtrInput `pulumi:"tpuTopology"`
}

func (GoogleCloudAiplatformV1MachineSpecArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1MachineSpec)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1MachineSpecArgs) ToGoogleCloudAiplatformV1MachineSpecOutput() GoogleCloudAiplatformV1MachineSpecOutput {
	return i.ToGoogleCloudAiplatformV1MachineSpecOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1MachineSpecArgs) ToGoogleCloudAiplatformV1MachineSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1MachineSpecOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1MachineSpecOutput)
}

func (i GoogleCloudAiplatformV1MachineSpecArgs) ToGoogleCloudAiplatformV1MachineSpecPtrOutput() GoogleCloudAiplatformV1MachineSpecPtrOutput {
	return i.ToGoogleCloudAiplatformV1MachineSpecPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1MachineSpecArgs) ToGoogleCloudAiplatformV1MachineSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1MachineSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1MachineSpecOutput).ToGoogleCloudAiplatformV1MachineSpecPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1MachineSpecPtrInput is an input type that accepts GoogleCloudAiplatformV1MachineSpecArgs, GoogleCloudAiplatformV1MachineSpecPtr and GoogleCloudAiplatformV1MachineSpecPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1MachineSpecPtrInput` via:
//
//	        GoogleCloudAiplatformV1MachineSpecArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1MachineSpecPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1MachineSpecPtrOutput() GoogleCloudAiplatformV1MachineSpecPtrOutput
	ToGoogleCloudAiplatformV1MachineSpecPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1MachineSpecPtrOutput
}

type googleCloudAiplatformV1MachineSpecPtrType GoogleCloudAiplatformV1MachineSpecArgs

func GoogleCloudAiplatformV1MachineSpecPtr(v *GoogleCloudAiplatformV1MachineSpecArgs) GoogleCloudAiplatformV1MachineSpecPtrInput {
	return (*googleCloudAiplatformV1MachineSpecPtrType)(v)
}

func (*googleCloudAiplatformV1MachineSpecPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1MachineSpec)(nil)).Elem()
}

func (i *googleCloudAiplatformV1MachineSpecPtrType) ToGoogleCloudAiplatformV1MachineSpecPtrOutput() GoogleCloudAiplatformV1MachineSpecPtrOutput {
	return i.ToGoogleCloudAiplatformV1MachineSpecPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1MachineSpecPtrType) ToGoogleCloudAiplatformV1MachineSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1MachineSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1MachineSpecPtrOutput)
}

// Specification of a single machine.
type GoogleCloudAiplatformV1MachineSpecOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1MachineSpecOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1MachineSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1MachineSpecOutput) ToGoogleCloudAiplatformV1MachineSpecOutput() GoogleCloudAiplatformV1MachineSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1MachineSpecOutput) ToGoogleCloudAiplatformV1MachineSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1MachineSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1MachineSpecOutput) ToGoogleCloudAiplatformV1MachineSpecPtrOutput() GoogleCloudAiplatformV1MachineSpecPtrOutput {
	return o.ToGoogleCloudAiplatformV1MachineSpecPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1MachineSpecOutput) ToGoogleCloudAiplatformV1MachineSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1MachineSpecPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1MachineSpec) *GoogleCloudAiplatformV1MachineSpec {
		return &v
	}).(GoogleCloudAiplatformV1MachineSpecPtrOutput)
}

// The number of accelerators to attach to the machine.
func (o GoogleCloudAiplatformV1MachineSpecOutput) AcceleratorCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1MachineSpec) *int { return v.AcceleratorCount }).(pulumi.IntPtrOutput)
}

// Immutable. The type of accelerator(s) that may be attached to the machine as per accelerator_count.
func (o GoogleCloudAiplatformV1MachineSpecOutput) AcceleratorType() GoogleCloudAiplatformV1MachineSpecAcceleratorTypePtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1MachineSpec) *GoogleCloudAiplatformV1MachineSpecAcceleratorType {
		return v.AcceleratorType
	}).(GoogleCloudAiplatformV1MachineSpecAcceleratorTypePtrOutput)
}

// Immutable. The type of the machine. See the [list of machine types supported for prediction](https://cloud.google.com/vertex-ai/docs/predictions/configure-compute#machine-types) See the [list of machine types supported for custom training](https://cloud.google.com/vertex-ai/docs/training/configure-compute#machine-types). For DeployedModel this field is optional, and the default value is `n1-standard-2`. For BatchPredictionJob or as part of WorkerPoolSpec this field is required.
func (o GoogleCloudAiplatformV1MachineSpecOutput) MachineType() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1MachineSpec) *string { return v.MachineType }).(pulumi.StringPtrOutput)
}

// Immutable. The topology of the TPUs. Corresponds to the TPU topologies available from GKE. (Example: tpu_topology: "2x2x1").
func (o GoogleCloudAiplatformV1MachineSpecOutput) TpuTopology() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1MachineSpec) *string { return v.TpuTopology }).(pulumi.StringPtrOutput)
}

type GoogleCloudAiplatformV1MachineSpecPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1MachineSpecPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1MachineSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1MachineSpecPtrOutput) ToGoogleCloudAiplatformV1MachineSpecPtrOutput() GoogleCloudAiplatformV1MachineSpecPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1MachineSpecPtrOutput) ToGoogleCloudAiplatformV1MachineSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1MachineSpecPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1MachineSpecPtrOutput) Elem() GoogleCloudAiplatformV1MachineSpecOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1MachineSpec) GoogleCloudAiplatformV1MachineSpec {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1MachineSpec
		return ret
	}).(GoogleCloudAiplatformV1MachineSpecOutput)
}

// The number of accelerators to attach to the machine.
func (o GoogleCloudAiplatformV1MachineSpecPtrOutput) AcceleratorCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1MachineSpec) *int {
		if v == nil {
			return nil
		}
		return v.AcceleratorCount
	}).(pulumi.IntPtrOutput)
}

// Immutable. The type of accelerator(s) that may be attached to the machine as per accelerator_count.
func (o GoogleCloudAiplatformV1MachineSpecPtrOutput) AcceleratorType() GoogleCloudAiplatformV1MachineSpecAcceleratorTypePtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1MachineSpec) *GoogleCloudAiplatformV1MachineSpecAcceleratorType {
		if v == nil {
			return nil
		}
		return v.AcceleratorType
	}).(GoogleCloudAiplatformV1MachineSpecAcceleratorTypePtrOutput)
}

// Immutable. The type of the machine. See the [list of machine types supported for prediction](https://cloud.google.com/vertex-ai/docs/predictions/configure-compute#machine-types) See the [list of machine types supported for custom training](https://cloud.google.com/vertex-ai/docs/training/configure-compute#machine-types). For DeployedModel this field is optional, and the default value is `n1-standard-2`. For BatchPredictionJob or as part of WorkerPoolSpec this field is required.
func (o GoogleCloudAiplatformV1MachineSpecPtrOutput) MachineType() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1MachineSpec) *string {
		if v == nil {
			return nil
		}
		return v.MachineType
	}).(pulumi.StringPtrOutput)
}

// Immutable. The topology of the TPUs. Corresponds to the TPU topologies available from GKE. (Example: tpu_topology: "2x2x1").
func (o GoogleCloudAiplatformV1MachineSpecPtrOutput) TpuTopology() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1MachineSpec) *string {
		if v == nil {
			return nil
		}
		return v.TpuTopology
	}).(pulumi.StringPtrOutput)
}

// Specification of a single machine.
type GoogleCloudAiplatformV1MachineSpecResponse struct {
	// The number of accelerators to attach to the machine.
	AcceleratorCount int `pulumi:"acceleratorCount"`
	// Immutable. The type of accelerator(s) that may be attached to the machine as per accelerator_count.
	AcceleratorType string `pulumi:"acceleratorType"`
	// Immutable. The type of the machine. See the [list of machine types supported for prediction](https://cloud.google.com/vertex-ai/docs/predictions/configure-compute#machine-types) See the [list of machine types supported for custom training](https://cloud.google.com/vertex-ai/docs/training/configure-compute#machine-types). For DeployedModel this field is optional, and the default value is `n1-standard-2`. For BatchPredictionJob or as part of WorkerPoolSpec this field is required.
	MachineType string `pulumi:"machineType"`
	// Immutable. The topology of the TPUs. Corresponds to the TPU topologies available from GKE. (Example: tpu_topology: "2x2x1").
	TpuTopology string `pulumi:"tpuTopology"`
}

// Specification of a single machine.
type GoogleCloudAiplatformV1MachineSpecResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1MachineSpecResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1MachineSpecResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1MachineSpecResponseOutput) ToGoogleCloudAiplatformV1MachineSpecResponseOutput() GoogleCloudAiplatformV1MachineSpecResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1MachineSpecResponseOutput) ToGoogleCloudAiplatformV1MachineSpecResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1MachineSpecResponseOutput {
	return o
}

// The number of accelerators to attach to the machine.
func (o GoogleCloudAiplatformV1MachineSpecResponseOutput) AcceleratorCount() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1MachineSpecResponse) int { return v.AcceleratorCount }).(pulumi.IntOutput)
}

// Immutable. The type of accelerator(s) that may be attached to the machine as per accelerator_count.
func (o GoogleCloudAiplatformV1MachineSpecResponseOutput) AcceleratorType() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1MachineSpecResponse) string { return v.AcceleratorType }).(pulumi.StringOutput)
}

// Immutable. The type of the machine. See the [list of machine types supported for prediction](https://cloud.google.com/vertex-ai/docs/predictions/configure-compute#machine-types) See the [list of machine types supported for custom training](https://cloud.google.com/vertex-ai/docs/training/configure-compute#machine-types). For DeployedModel this field is optional, and the default value is `n1-standard-2`. For BatchPredictionJob or as part of WorkerPoolSpec this field is required.
func (o GoogleCloudAiplatformV1MachineSpecResponseOutput) MachineType() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1MachineSpecResponse) string { return v.MachineType }).(pulumi.StringOutput)
}

// Immutable. The topology of the TPUs. Corresponds to the TPU topologies available from GKE. (Example: tpu_topology: "2x2x1").
func (o GoogleCloudAiplatformV1MachineSpecResponseOutput) TpuTopology() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1MachineSpecResponse) string { return v.TpuTopology }).(pulumi.StringOutput)
}

// Manual batch tuning parameters.
type GoogleCloudAiplatformV1ManualBatchTuningParameters struct {
	// Immutable. The number of the records (e.g. instances) of the operation given in each batch to a machine replica. Machine type, and size of a single record should be considered when setting this parameter, higher value speeds up the batch operation's execution, but too high value will result in a whole batch not fitting in a machine's memory, and the whole operation will fail. The default value is 64.
	BatchSize *int `pulumi:"batchSize"`
}

// GoogleCloudAiplatformV1ManualBatchTuningParametersInput is an input type that accepts GoogleCloudAiplatformV1ManualBatchTuningParametersArgs and GoogleCloudAiplatformV1ManualBatchTuningParametersOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1ManualBatchTuningParametersInput` via:
//
//	GoogleCloudAiplatformV1ManualBatchTuningParametersArgs{...}
type GoogleCloudAiplatformV1ManualBatchTuningParametersInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1ManualBatchTuningParametersOutput() GoogleCloudAiplatformV1ManualBatchTuningParametersOutput
	ToGoogleCloudAiplatformV1ManualBatchTuningParametersOutputWithContext(context.Context) GoogleCloudAiplatformV1ManualBatchTuningParametersOutput
}

// Manual batch tuning parameters.
type GoogleCloudAiplatformV1ManualBatchTuningParametersArgs struct {
	// Immutable. The number of the records (e.g. instances) of the operation given in each batch to a machine replica. Machine type, and size of a single record should be considered when setting this parameter, higher value speeds up the batch operation's execution, but too high value will result in a whole batch not fitting in a machine's memory, and the whole operation will fail. The default value is 64.
	BatchSize pulumi.IntPtrInput `pulumi:"batchSize"`
}

func (GoogleCloudAiplatformV1ManualBatchTuningParametersArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1ManualBatchTuningParameters)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1ManualBatchTuningParametersArgs) ToGoogleCloudAiplatformV1ManualBatchTuningParametersOutput() GoogleCloudAiplatformV1ManualBatchTuningParametersOutput {
	return i.ToGoogleCloudAiplatformV1ManualBatchTuningParametersOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1ManualBatchTuningParametersArgs) ToGoogleCloudAiplatformV1ManualBatchTuningParametersOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ManualBatchTuningParametersOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1ManualBatchTuningParametersOutput)
}

func (i GoogleCloudAiplatformV1ManualBatchTuningParametersArgs) ToGoogleCloudAiplatformV1ManualBatchTuningParametersPtrOutput() GoogleCloudAiplatformV1ManualBatchTuningParametersPtrOutput {
	return i.ToGoogleCloudAiplatformV1ManualBatchTuningParametersPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1ManualBatchTuningParametersArgs) ToGoogleCloudAiplatformV1ManualBatchTuningParametersPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ManualBatchTuningParametersPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1ManualBatchTuningParametersOutput).ToGoogleCloudAiplatformV1ManualBatchTuningParametersPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1ManualBatchTuningParametersPtrInput is an input type that accepts GoogleCloudAiplatformV1ManualBatchTuningParametersArgs, GoogleCloudAiplatformV1ManualBatchTuningParametersPtr and GoogleCloudAiplatformV1ManualBatchTuningParametersPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1ManualBatchTuningParametersPtrInput` via:
//
//	        GoogleCloudAiplatformV1ManualBatchTuningParametersArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1ManualBatchTuningParametersPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1ManualBatchTuningParametersPtrOutput() GoogleCloudAiplatformV1ManualBatchTuningParametersPtrOutput
	ToGoogleCloudAiplatformV1ManualBatchTuningParametersPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1ManualBatchTuningParametersPtrOutput
}

type googleCloudAiplatformV1ManualBatchTuningParametersPtrType GoogleCloudAiplatformV1ManualBatchTuningParametersArgs

func GoogleCloudAiplatformV1ManualBatchTuningParametersPtr(v *GoogleCloudAiplatformV1ManualBatchTuningParametersArgs) GoogleCloudAiplatformV1ManualBatchTuningParametersPtrInput {
	return (*googleCloudAiplatformV1ManualBatchTuningParametersPtrType)(v)
}

func (*googleCloudAiplatformV1ManualBatchTuningParametersPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1ManualBatchTuningParameters)(nil)).Elem()
}

func (i *googleCloudAiplatformV1ManualBatchTuningParametersPtrType) ToGoogleCloudAiplatformV1ManualBatchTuningParametersPtrOutput() GoogleCloudAiplatformV1ManualBatchTuningParametersPtrOutput {
	return i.ToGoogleCloudAiplatformV1ManualBatchTuningParametersPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1ManualBatchTuningParametersPtrType) ToGoogleCloudAiplatformV1ManualBatchTuningParametersPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ManualBatchTuningParametersPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1ManualBatchTuningParametersPtrOutput)
}

// Manual batch tuning parameters.
type GoogleCloudAiplatformV1ManualBatchTuningParametersOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ManualBatchTuningParametersOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1ManualBatchTuningParameters)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ManualBatchTuningParametersOutput) ToGoogleCloudAiplatformV1ManualBatchTuningParametersOutput() GoogleCloudAiplatformV1ManualBatchTuningParametersOutput {
	return o
}

func (o GoogleCloudAiplatformV1ManualBatchTuningParametersOutput) ToGoogleCloudAiplatformV1ManualBatchTuningParametersOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ManualBatchTuningParametersOutput {
	return o
}

func (o GoogleCloudAiplatformV1ManualBatchTuningParametersOutput) ToGoogleCloudAiplatformV1ManualBatchTuningParametersPtrOutput() GoogleCloudAiplatformV1ManualBatchTuningParametersPtrOutput {
	return o.ToGoogleCloudAiplatformV1ManualBatchTuningParametersPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1ManualBatchTuningParametersOutput) ToGoogleCloudAiplatformV1ManualBatchTuningParametersPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ManualBatchTuningParametersPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1ManualBatchTuningParameters) *GoogleCloudAiplatformV1ManualBatchTuningParameters {
		return &v
	}).(GoogleCloudAiplatformV1ManualBatchTuningParametersPtrOutput)
}

// Immutable. The number of the records (e.g. instances) of the operation given in each batch to a machine replica. Machine type, and size of a single record should be considered when setting this parameter, higher value speeds up the batch operation's execution, but too high value will result in a whole batch not fitting in a machine's memory, and the whole operation will fail. The default value is 64.
func (o GoogleCloudAiplatformV1ManualBatchTuningParametersOutput) BatchSize() pulumi.IntPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ManualBatchTuningParameters) *int { return v.BatchSize }).(pulumi.IntPtrOutput)
}

type GoogleCloudAiplatformV1ManualBatchTuningParametersPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ManualBatchTuningParametersPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1ManualBatchTuningParameters)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ManualBatchTuningParametersPtrOutput) ToGoogleCloudAiplatformV1ManualBatchTuningParametersPtrOutput() GoogleCloudAiplatformV1ManualBatchTuningParametersPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1ManualBatchTuningParametersPtrOutput) ToGoogleCloudAiplatformV1ManualBatchTuningParametersPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ManualBatchTuningParametersPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1ManualBatchTuningParametersPtrOutput) Elem() GoogleCloudAiplatformV1ManualBatchTuningParametersOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1ManualBatchTuningParameters) GoogleCloudAiplatformV1ManualBatchTuningParameters {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1ManualBatchTuningParameters
		return ret
	}).(GoogleCloudAiplatformV1ManualBatchTuningParametersOutput)
}

// Immutable. The number of the records (e.g. instances) of the operation given in each batch to a machine replica. Machine type, and size of a single record should be considered when setting this parameter, higher value speeds up the batch operation's execution, but too high value will result in a whole batch not fitting in a machine's memory, and the whole operation will fail. The default value is 64.
func (o GoogleCloudAiplatformV1ManualBatchTuningParametersPtrOutput) BatchSize() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1ManualBatchTuningParameters) *int {
		if v == nil {
			return nil
		}
		return v.BatchSize
	}).(pulumi.IntPtrOutput)
}

// Manual batch tuning parameters.
type GoogleCloudAiplatformV1ManualBatchTuningParametersResponse struct {
	// Immutable. The number of the records (e.g. instances) of the operation given in each batch to a machine replica. Machine type, and size of a single record should be considered when setting this parameter, higher value speeds up the batch operation's execution, but too high value will result in a whole batch not fitting in a machine's memory, and the whole operation will fail. The default value is 64.
	BatchSize int `pulumi:"batchSize"`
}

// Manual batch tuning parameters.
type GoogleCloudAiplatformV1ManualBatchTuningParametersResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ManualBatchTuningParametersResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1ManualBatchTuningParametersResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ManualBatchTuningParametersResponseOutput) ToGoogleCloudAiplatformV1ManualBatchTuningParametersResponseOutput() GoogleCloudAiplatformV1ManualBatchTuningParametersResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1ManualBatchTuningParametersResponseOutput) ToGoogleCloudAiplatformV1ManualBatchTuningParametersResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ManualBatchTuningParametersResponseOutput {
	return o
}

// Immutable. The number of the records (e.g. instances) of the operation given in each batch to a machine replica. Machine type, and size of a single record should be considered when setting this parameter, higher value speeds up the batch operation's execution, but too high value will result in a whole batch not fitting in a machine's memory, and the whole operation will fail. The default value is 64.
func (o GoogleCloudAiplatformV1ManualBatchTuningParametersResponseOutput) BatchSize() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ManualBatchTuningParametersResponse) int { return v.BatchSize }).(pulumi.IntOutput)
}

// A message representing a metric in the measurement.
type GoogleCloudAiplatformV1MeasurementMetricResponse struct {
	// The ID of the Metric. The Metric should be defined in StudySpec's Metrics.
	MetricId string `pulumi:"metricId"`
	// The value for this metric.
	Value float64 `pulumi:"value"`
}

// A message representing a metric in the measurement.
type GoogleCloudAiplatformV1MeasurementMetricResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1MeasurementMetricResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1MeasurementMetricResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1MeasurementMetricResponseOutput) ToGoogleCloudAiplatformV1MeasurementMetricResponseOutput() GoogleCloudAiplatformV1MeasurementMetricResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1MeasurementMetricResponseOutput) ToGoogleCloudAiplatformV1MeasurementMetricResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1MeasurementMetricResponseOutput {
	return o
}

// The ID of the Metric. The Metric should be defined in StudySpec's Metrics.
func (o GoogleCloudAiplatformV1MeasurementMetricResponseOutput) MetricId() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1MeasurementMetricResponse) string { return v.MetricId }).(pulumi.StringOutput)
}

// The value for this metric.
func (o GoogleCloudAiplatformV1MeasurementMetricResponseOutput) Value() pulumi.Float64Output {
	return o.ApplyT(func(v GoogleCloudAiplatformV1MeasurementMetricResponse) float64 { return v.Value }).(pulumi.Float64Output)
}

type GoogleCloudAiplatformV1MeasurementMetricResponseArrayOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1MeasurementMetricResponseArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1MeasurementMetricResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1MeasurementMetricResponseArrayOutput) ToGoogleCloudAiplatformV1MeasurementMetricResponseArrayOutput() GoogleCloudAiplatformV1MeasurementMetricResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1MeasurementMetricResponseArrayOutput) ToGoogleCloudAiplatformV1MeasurementMetricResponseArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1MeasurementMetricResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1MeasurementMetricResponseArrayOutput) Index(i pulumi.IntInput) GoogleCloudAiplatformV1MeasurementMetricResponseOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GoogleCloudAiplatformV1MeasurementMetricResponse {
		return vs[0].([]GoogleCloudAiplatformV1MeasurementMetricResponse)[vs[1].(int)]
	}).(GoogleCloudAiplatformV1MeasurementMetricResponseOutput)
}

// A message representing a Measurement of a Trial. A Measurement contains the Metrics got by executing a Trial using suggested hyperparameter values.
type GoogleCloudAiplatformV1MeasurementResponse struct {
	// Time that the Trial has been running at the point of this Measurement.
	ElapsedDuration string `pulumi:"elapsedDuration"`
	// A list of metrics got by evaluating the objective functions using suggested Parameter values.
	Metrics []GoogleCloudAiplatformV1MeasurementMetricResponse `pulumi:"metrics"`
	// The number of steps the machine learning model has been trained for. Must be non-negative.
	StepCount string `pulumi:"stepCount"`
}

// A message representing a Measurement of a Trial. A Measurement contains the Metrics got by executing a Trial using suggested hyperparameter values.
type GoogleCloudAiplatformV1MeasurementResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1MeasurementResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1MeasurementResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1MeasurementResponseOutput) ToGoogleCloudAiplatformV1MeasurementResponseOutput() GoogleCloudAiplatformV1MeasurementResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1MeasurementResponseOutput) ToGoogleCloudAiplatformV1MeasurementResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1MeasurementResponseOutput {
	return o
}

// Time that the Trial has been running at the point of this Measurement.
func (o GoogleCloudAiplatformV1MeasurementResponseOutput) ElapsedDuration() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1MeasurementResponse) string { return v.ElapsedDuration }).(pulumi.StringOutput)
}

// A list of metrics got by evaluating the objective functions using suggested Parameter values.
func (o GoogleCloudAiplatformV1MeasurementResponseOutput) Metrics() GoogleCloudAiplatformV1MeasurementMetricResponseArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1MeasurementResponse) []GoogleCloudAiplatformV1MeasurementMetricResponse {
		return v.Metrics
	}).(GoogleCloudAiplatformV1MeasurementMetricResponseArrayOutput)
}

// The number of steps the machine learning model has been trained for. Must be non-negative.
func (o GoogleCloudAiplatformV1MeasurementResponseOutput) StepCount() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1MeasurementResponse) string { return v.StepCount }).(pulumi.StringOutput)
}

type GoogleCloudAiplatformV1MeasurementResponseArrayOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1MeasurementResponseArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1MeasurementResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1MeasurementResponseArrayOutput) ToGoogleCloudAiplatformV1MeasurementResponseArrayOutput() GoogleCloudAiplatformV1MeasurementResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1MeasurementResponseArrayOutput) ToGoogleCloudAiplatformV1MeasurementResponseArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1MeasurementResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1MeasurementResponseArrayOutput) Index(i pulumi.IntInput) GoogleCloudAiplatformV1MeasurementResponseOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GoogleCloudAiplatformV1MeasurementResponse {
		return vs[0].([]GoogleCloudAiplatformV1MeasurementResponse)[vs[1].(int)]
	}).(GoogleCloudAiplatformV1MeasurementResponseOutput)
}

// Represents state information for a MetadataStore.
type GoogleCloudAiplatformV1MetadataStoreMetadataStoreStateResponse struct {
	// The disk utilization of the MetadataStore in bytes.
	DiskUtilizationBytes string `pulumi:"diskUtilizationBytes"`
}

// Represents state information for a MetadataStore.
type GoogleCloudAiplatformV1MetadataStoreMetadataStoreStateResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1MetadataStoreMetadataStoreStateResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1MetadataStoreMetadataStoreStateResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1MetadataStoreMetadataStoreStateResponseOutput) ToGoogleCloudAiplatformV1MetadataStoreMetadataStoreStateResponseOutput() GoogleCloudAiplatformV1MetadataStoreMetadataStoreStateResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1MetadataStoreMetadataStoreStateResponseOutput) ToGoogleCloudAiplatformV1MetadataStoreMetadataStoreStateResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1MetadataStoreMetadataStoreStateResponseOutput {
	return o
}

// The disk utilization of the MetadataStore in bytes.
func (o GoogleCloudAiplatformV1MetadataStoreMetadataStoreStateResponseOutput) DiskUtilizationBytes() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1MetadataStoreMetadataStoreStateResponse) string {
		return v.DiskUtilizationBytes
	}).(pulumi.StringOutput)
}

// A trained machine learning Model.
type GoogleCloudAiplatformV1Model struct {
	// Immutable. The path to the directory containing the Model artifact and any of its supporting files. Not present for AutoML Models or Large Models.
	ArtifactUri *string `pulumi:"artifactUri"`
	// Input only. The specification of the container that is to be used when deploying this Model. The specification is ingested upon ModelService.UploadModel, and all binaries it contains are copied and stored internally by Vertex AI. Not present for AutoML Models or Large Models.
	ContainerSpec *GoogleCloudAiplatformV1ModelContainerSpec `pulumi:"containerSpec"`
	// The description of the Model.
	Description *string `pulumi:"description"`
	// The display name of the Model. The name can be up to 128 characters long and can consist of any UTF-8 characters.
	DisplayName string `pulumi:"displayName"`
	// Customer-managed encryption key spec for a Model. If set, this Model and all sub-resources of this Model will be secured by this key.
	EncryptionSpec *GoogleCloudAiplatformV1EncryptionSpec `pulumi:"encryptionSpec"`
	// Used to perform consistent read-modify-write updates. If not set, a blind "overwrite" update happens.
	Etag *string `pulumi:"etag"`
	// The default explanation specification for this Model. The Model can be used for requesting explanation after being deployed if it is populated. The Model can be used for batch explanation if it is populated. All fields of the explanation_spec can be overridden by explanation_spec of DeployModelRequest.deployed_model, or explanation_spec of BatchPredictionJob. If the default explanation specification is not set for this Model, this Model can still be used for requesting explanation by setting explanation_spec of DeployModelRequest.deployed_model and for batch explanation by setting explanation_spec of BatchPredictionJob.
	ExplanationSpec *GoogleCloudAiplatformV1ExplanationSpec `pulumi:"explanationSpec"`
	// The labels with user-defined metadata to organize your Models. Label keys and values can be no longer than 64 characters (Unicode codepoints), can only contain lowercase letters, numeric characters, underscores and dashes. International characters are allowed. See https://goo.gl/xmQnxf for more information and examples of labels.
	Labels map[string]string `pulumi:"labels"`
	// Immutable. An additional information about the Model; the schema of the metadata can be found in metadata_schema. Unset if the Model does not have any additional information.
	Metadata interface{} `pulumi:"metadata"`
	// Immutable. Points to a YAML file stored on Google Cloud Storage describing additional information about the Model, that is specific to it. Unset if the Model does not have any additional information. The schema is defined as an OpenAPI 3.0.2 [Schema Object](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject). AutoML Models always have this field populated by Vertex AI, if no additional metadata is needed, this field is set to an empty string. Note: The URI given on output will be immutable and probably different, including the URI scheme, than the one given on input. The output URI will point to a location where the user only has a read access.
	MetadataSchemaUri *string `pulumi:"metadataSchemaUri"`
	// The resource name of the Model.
	Name *string `pulumi:"name"`
	// Optional. This field is populated if the model is produced by a pipeline job.
	PipelineJob *string `pulumi:"pipelineJob"`
	// The schemata that describe formats of the Model's predictions and explanations as given and returned via PredictionService.Predict and PredictionService.Explain.
	PredictSchemata *GoogleCloudAiplatformV1PredictSchemata `pulumi:"predictSchemata"`
	// User provided version aliases so that a model version can be referenced via alias (i.e. `projects/{project}/locations/{location}/models/{model_id}@{version_alias}` instead of auto-generated version id (i.e. `projects/{project}/locations/{location}/models/{model_id}@{version_id})`. The format is a-z{0,126}[a-z0-9] to distinguish from version_id. A default version alias will be created for the first version of the model, and there must be exactly one default version alias for a model.
	VersionAliases []string `pulumi:"versionAliases"`
	// The description of this version.
	VersionDescription *string `pulumi:"versionDescription"`
}

// GoogleCloudAiplatformV1ModelInput is an input type that accepts GoogleCloudAiplatformV1ModelArgs and GoogleCloudAiplatformV1ModelOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1ModelInput` via:
//
//	GoogleCloudAiplatformV1ModelArgs{...}
type GoogleCloudAiplatformV1ModelInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1ModelOutput() GoogleCloudAiplatformV1ModelOutput
	ToGoogleCloudAiplatformV1ModelOutputWithContext(context.Context) GoogleCloudAiplatformV1ModelOutput
}

// A trained machine learning Model.
type GoogleCloudAiplatformV1ModelArgs struct {
	// Immutable. The path to the directory containing the Model artifact and any of its supporting files. Not present for AutoML Models or Large Models.
	ArtifactUri pulumi.StringPtrInput `pulumi:"artifactUri"`
	// Input only. The specification of the container that is to be used when deploying this Model. The specification is ingested upon ModelService.UploadModel, and all binaries it contains are copied and stored internally by Vertex AI. Not present for AutoML Models or Large Models.
	ContainerSpec GoogleCloudAiplatformV1ModelContainerSpecPtrInput `pulumi:"containerSpec"`
	// The description of the Model.
	Description pulumi.StringPtrInput `pulumi:"description"`
	// The display name of the Model. The name can be up to 128 characters long and can consist of any UTF-8 characters.
	DisplayName pulumi.StringInput `pulumi:"displayName"`
	// Customer-managed encryption key spec for a Model. If set, this Model and all sub-resources of this Model will be secured by this key.
	EncryptionSpec GoogleCloudAiplatformV1EncryptionSpecPtrInput `pulumi:"encryptionSpec"`
	// Used to perform consistent read-modify-write updates. If not set, a blind "overwrite" update happens.
	Etag pulumi.StringPtrInput `pulumi:"etag"`
	// The default explanation specification for this Model. The Model can be used for requesting explanation after being deployed if it is populated. The Model can be used for batch explanation if it is populated. All fields of the explanation_spec can be overridden by explanation_spec of DeployModelRequest.deployed_model, or explanation_spec of BatchPredictionJob. If the default explanation specification is not set for this Model, this Model can still be used for requesting explanation by setting explanation_spec of DeployModelRequest.deployed_model and for batch explanation by setting explanation_spec of BatchPredictionJob.
	ExplanationSpec GoogleCloudAiplatformV1ExplanationSpecPtrInput `pulumi:"explanationSpec"`
	// The labels with user-defined metadata to organize your Models. Label keys and values can be no longer than 64 characters (Unicode codepoints), can only contain lowercase letters, numeric characters, underscores and dashes. International characters are allowed. See https://goo.gl/xmQnxf for more information and examples of labels.
	Labels pulumi.StringMapInput `pulumi:"labels"`
	// Immutable. An additional information about the Model; the schema of the metadata can be found in metadata_schema. Unset if the Model does not have any additional information.
	Metadata pulumi.Input `pulumi:"metadata"`
	// Immutable. Points to a YAML file stored on Google Cloud Storage describing additional information about the Model, that is specific to it. Unset if the Model does not have any additional information. The schema is defined as an OpenAPI 3.0.2 [Schema Object](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject). AutoML Models always have this field populated by Vertex AI, if no additional metadata is needed, this field is set to an empty string. Note: The URI given on output will be immutable and probably different, including the URI scheme, than the one given on input. The output URI will point to a location where the user only has a read access.
	MetadataSchemaUri pulumi.StringPtrInput `pulumi:"metadataSchemaUri"`
	// The resource name of the Model.
	Name pulumi.StringPtrInput `pulumi:"name"`
	// Optional. This field is populated if the model is produced by a pipeline job.
	PipelineJob pulumi.StringPtrInput `pulumi:"pipelineJob"`
	// The schemata that describe formats of the Model's predictions and explanations as given and returned via PredictionService.Predict and PredictionService.Explain.
	PredictSchemata GoogleCloudAiplatformV1PredictSchemataPtrInput `pulumi:"predictSchemata"`
	// User provided version aliases so that a model version can be referenced via alias (i.e. `projects/{project}/locations/{location}/models/{model_id}@{version_alias}` instead of auto-generated version id (i.e. `projects/{project}/locations/{location}/models/{model_id}@{version_id})`. The format is a-z{0,126}[a-z0-9] to distinguish from version_id. A default version alias will be created for the first version of the model, and there must be exactly one default version alias for a model.
	VersionAliases pulumi.StringArrayInput `pulumi:"versionAliases"`
	// The description of this version.
	VersionDescription pulumi.StringPtrInput `pulumi:"versionDescription"`
}

func (GoogleCloudAiplatformV1ModelArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1Model)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1ModelArgs) ToGoogleCloudAiplatformV1ModelOutput() GoogleCloudAiplatformV1ModelOutput {
	return i.ToGoogleCloudAiplatformV1ModelOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1ModelArgs) ToGoogleCloudAiplatformV1ModelOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ModelOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1ModelOutput)
}

func (i GoogleCloudAiplatformV1ModelArgs) ToGoogleCloudAiplatformV1ModelPtrOutput() GoogleCloudAiplatformV1ModelPtrOutput {
	return i.ToGoogleCloudAiplatformV1ModelPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1ModelArgs) ToGoogleCloudAiplatformV1ModelPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ModelPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1ModelOutput).ToGoogleCloudAiplatformV1ModelPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1ModelPtrInput is an input type that accepts GoogleCloudAiplatformV1ModelArgs, GoogleCloudAiplatformV1ModelPtr and GoogleCloudAiplatformV1ModelPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1ModelPtrInput` via:
//
//	        GoogleCloudAiplatformV1ModelArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1ModelPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1ModelPtrOutput() GoogleCloudAiplatformV1ModelPtrOutput
	ToGoogleCloudAiplatformV1ModelPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1ModelPtrOutput
}

type googleCloudAiplatformV1ModelPtrType GoogleCloudAiplatformV1ModelArgs

func GoogleCloudAiplatformV1ModelPtr(v *GoogleCloudAiplatformV1ModelArgs) GoogleCloudAiplatformV1ModelPtrInput {
	return (*googleCloudAiplatformV1ModelPtrType)(v)
}

func (*googleCloudAiplatformV1ModelPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1Model)(nil)).Elem()
}

func (i *googleCloudAiplatformV1ModelPtrType) ToGoogleCloudAiplatformV1ModelPtrOutput() GoogleCloudAiplatformV1ModelPtrOutput {
	return i.ToGoogleCloudAiplatformV1ModelPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1ModelPtrType) ToGoogleCloudAiplatformV1ModelPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ModelPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1ModelPtrOutput)
}

// A trained machine learning Model.
type GoogleCloudAiplatformV1ModelOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ModelOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1Model)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ModelOutput) ToGoogleCloudAiplatformV1ModelOutput() GoogleCloudAiplatformV1ModelOutput {
	return o
}

func (o GoogleCloudAiplatformV1ModelOutput) ToGoogleCloudAiplatformV1ModelOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ModelOutput {
	return o
}

func (o GoogleCloudAiplatformV1ModelOutput) ToGoogleCloudAiplatformV1ModelPtrOutput() GoogleCloudAiplatformV1ModelPtrOutput {
	return o.ToGoogleCloudAiplatformV1ModelPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1ModelOutput) ToGoogleCloudAiplatformV1ModelPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ModelPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1Model) *GoogleCloudAiplatformV1Model {
		return &v
	}).(GoogleCloudAiplatformV1ModelPtrOutput)
}

// Immutable. The path to the directory containing the Model artifact and any of its supporting files. Not present for AutoML Models or Large Models.
func (o GoogleCloudAiplatformV1ModelOutput) ArtifactUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1Model) *string { return v.ArtifactUri }).(pulumi.StringPtrOutput)
}

// Input only. The specification of the container that is to be used when deploying this Model. The specification is ingested upon ModelService.UploadModel, and all binaries it contains are copied and stored internally by Vertex AI. Not present for AutoML Models or Large Models.
func (o GoogleCloudAiplatformV1ModelOutput) ContainerSpec() GoogleCloudAiplatformV1ModelContainerSpecPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1Model) *GoogleCloudAiplatformV1ModelContainerSpec {
		return v.ContainerSpec
	}).(GoogleCloudAiplatformV1ModelContainerSpecPtrOutput)
}

// The description of the Model.
func (o GoogleCloudAiplatformV1ModelOutput) Description() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1Model) *string { return v.Description }).(pulumi.StringPtrOutput)
}

// The display name of the Model. The name can be up to 128 characters long and can consist of any UTF-8 characters.
func (o GoogleCloudAiplatformV1ModelOutput) DisplayName() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1Model) string { return v.DisplayName }).(pulumi.StringOutput)
}

// Customer-managed encryption key spec for a Model. If set, this Model and all sub-resources of this Model will be secured by this key.
func (o GoogleCloudAiplatformV1ModelOutput) EncryptionSpec() GoogleCloudAiplatformV1EncryptionSpecPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1Model) *GoogleCloudAiplatformV1EncryptionSpec { return v.EncryptionSpec }).(GoogleCloudAiplatformV1EncryptionSpecPtrOutput)
}

// Used to perform consistent read-modify-write updates. If not set, a blind "overwrite" update happens.
func (o GoogleCloudAiplatformV1ModelOutput) Etag() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1Model) *string { return v.Etag }).(pulumi.StringPtrOutput)
}

// The default explanation specification for this Model. The Model can be used for requesting explanation after being deployed if it is populated. The Model can be used for batch explanation if it is populated. All fields of the explanation_spec can be overridden by explanation_spec of DeployModelRequest.deployed_model, or explanation_spec of BatchPredictionJob. If the default explanation specification is not set for this Model, this Model can still be used for requesting explanation by setting explanation_spec of DeployModelRequest.deployed_model and for batch explanation by setting explanation_spec of BatchPredictionJob.
func (o GoogleCloudAiplatformV1ModelOutput) ExplanationSpec() GoogleCloudAiplatformV1ExplanationSpecPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1Model) *GoogleCloudAiplatformV1ExplanationSpec { return v.ExplanationSpec }).(GoogleCloudAiplatformV1ExplanationSpecPtrOutput)
}

// The labels with user-defined metadata to organize your Models. Label keys and values can be no longer than 64 characters (Unicode codepoints), can only contain lowercase letters, numeric characters, underscores and dashes. International characters are allowed. See https://goo.gl/xmQnxf for more information and examples of labels.
func (o GoogleCloudAiplatformV1ModelOutput) Labels() pulumi.StringMapOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1Model) map[string]string { return v.Labels }).(pulumi.StringMapOutput)
}

// Immutable. An additional information about the Model; the schema of the metadata can be found in metadata_schema. Unset if the Model does not have any additional information.
func (o GoogleCloudAiplatformV1ModelOutput) Metadata() pulumi.AnyOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1Model) interface{} { return v.Metadata }).(pulumi.AnyOutput)
}

// Immutable. Points to a YAML file stored on Google Cloud Storage describing additional information about the Model, that is specific to it. Unset if the Model does not have any additional information. The schema is defined as an OpenAPI 3.0.2 [Schema Object](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject). AutoML Models always have this field populated by Vertex AI, if no additional metadata is needed, this field is set to an empty string. Note: The URI given on output will be immutable and probably different, including the URI scheme, than the one given on input. The output URI will point to a location where the user only has a read access.
func (o GoogleCloudAiplatformV1ModelOutput) MetadataSchemaUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1Model) *string { return v.MetadataSchemaUri }).(pulumi.StringPtrOutput)
}

// The resource name of the Model.
func (o GoogleCloudAiplatformV1ModelOutput) Name() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1Model) *string { return v.Name }).(pulumi.StringPtrOutput)
}

// Optional. This field is populated if the model is produced by a pipeline job.
func (o GoogleCloudAiplatformV1ModelOutput) PipelineJob() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1Model) *string { return v.PipelineJob }).(pulumi.StringPtrOutput)
}

// The schemata that describe formats of the Model's predictions and explanations as given and returned via PredictionService.Predict and PredictionService.Explain.
func (o GoogleCloudAiplatformV1ModelOutput) PredictSchemata() GoogleCloudAiplatformV1PredictSchemataPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1Model) *GoogleCloudAiplatformV1PredictSchemata { return v.PredictSchemata }).(GoogleCloudAiplatformV1PredictSchemataPtrOutput)
}

// User provided version aliases so that a model version can be referenced via alias (i.e. `projects/{project}/locations/{location}/models/{model_id}@{version_alias}` instead of auto-generated version id (i.e. `projects/{project}/locations/{location}/models/{model_id}@{version_id})`. The format is a-z{0,126}[a-z0-9] to distinguish from version_id. A default version alias will be created for the first version of the model, and there must be exactly one default version alias for a model.
func (o GoogleCloudAiplatformV1ModelOutput) VersionAliases() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1Model) []string { return v.VersionAliases }).(pulumi.StringArrayOutput)
}

// The description of this version.
func (o GoogleCloudAiplatformV1ModelOutput) VersionDescription() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1Model) *string { return v.VersionDescription }).(pulumi.StringPtrOutput)
}

type GoogleCloudAiplatformV1ModelPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ModelPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1Model)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ModelPtrOutput) ToGoogleCloudAiplatformV1ModelPtrOutput() GoogleCloudAiplatformV1ModelPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1ModelPtrOutput) ToGoogleCloudAiplatformV1ModelPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ModelPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1ModelPtrOutput) Elem() GoogleCloudAiplatformV1ModelOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1Model) GoogleCloudAiplatformV1Model {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1Model
		return ret
	}).(GoogleCloudAiplatformV1ModelOutput)
}

// Immutable. The path to the directory containing the Model artifact and any of its supporting files. Not present for AutoML Models or Large Models.
func (o GoogleCloudAiplatformV1ModelPtrOutput) ArtifactUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1Model) *string {
		if v == nil {
			return nil
		}
		return v.ArtifactUri
	}).(pulumi.StringPtrOutput)
}

// Input only. The specification of the container that is to be used when deploying this Model. The specification is ingested upon ModelService.UploadModel, and all binaries it contains are copied and stored internally by Vertex AI. Not present for AutoML Models or Large Models.
func (o GoogleCloudAiplatformV1ModelPtrOutput) ContainerSpec() GoogleCloudAiplatformV1ModelContainerSpecPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1Model) *GoogleCloudAiplatformV1ModelContainerSpec {
		if v == nil {
			return nil
		}
		return v.ContainerSpec
	}).(GoogleCloudAiplatformV1ModelContainerSpecPtrOutput)
}

// The description of the Model.
func (o GoogleCloudAiplatformV1ModelPtrOutput) Description() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1Model) *string {
		if v == nil {
			return nil
		}
		return v.Description
	}).(pulumi.StringPtrOutput)
}

// The display name of the Model. The name can be up to 128 characters long and can consist of any UTF-8 characters.
func (o GoogleCloudAiplatformV1ModelPtrOutput) DisplayName() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1Model) *string {
		if v == nil {
			return nil
		}
		return &v.DisplayName
	}).(pulumi.StringPtrOutput)
}

// Customer-managed encryption key spec for a Model. If set, this Model and all sub-resources of this Model will be secured by this key.
func (o GoogleCloudAiplatformV1ModelPtrOutput) EncryptionSpec() GoogleCloudAiplatformV1EncryptionSpecPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1Model) *GoogleCloudAiplatformV1EncryptionSpec {
		if v == nil {
			return nil
		}
		return v.EncryptionSpec
	}).(GoogleCloudAiplatformV1EncryptionSpecPtrOutput)
}

// Used to perform consistent read-modify-write updates. If not set, a blind "overwrite" update happens.
func (o GoogleCloudAiplatformV1ModelPtrOutput) Etag() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1Model) *string {
		if v == nil {
			return nil
		}
		return v.Etag
	}).(pulumi.StringPtrOutput)
}

// The default explanation specification for this Model. The Model can be used for requesting explanation after being deployed if it is populated. The Model can be used for batch explanation if it is populated. All fields of the explanation_spec can be overridden by explanation_spec of DeployModelRequest.deployed_model, or explanation_spec of BatchPredictionJob. If the default explanation specification is not set for this Model, this Model can still be used for requesting explanation by setting explanation_spec of DeployModelRequest.deployed_model and for batch explanation by setting explanation_spec of BatchPredictionJob.
func (o GoogleCloudAiplatformV1ModelPtrOutput) ExplanationSpec() GoogleCloudAiplatformV1ExplanationSpecPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1Model) *GoogleCloudAiplatformV1ExplanationSpec {
		if v == nil {
			return nil
		}
		return v.ExplanationSpec
	}).(GoogleCloudAiplatformV1ExplanationSpecPtrOutput)
}

// The labels with user-defined metadata to organize your Models. Label keys and values can be no longer than 64 characters (Unicode codepoints), can only contain lowercase letters, numeric characters, underscores and dashes. International characters are allowed. See https://goo.gl/xmQnxf for more information and examples of labels.
func (o GoogleCloudAiplatformV1ModelPtrOutput) Labels() pulumi.StringMapOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1Model) map[string]string {
		if v == nil {
			return nil
		}
		return v.Labels
	}).(pulumi.StringMapOutput)
}

// Immutable. An additional information about the Model; the schema of the metadata can be found in metadata_schema. Unset if the Model does not have any additional information.
func (o GoogleCloudAiplatformV1ModelPtrOutput) Metadata() pulumi.AnyOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1Model) interface{} {
		if v == nil {
			return nil
		}
		return v.Metadata
	}).(pulumi.AnyOutput)
}

// Immutable. Points to a YAML file stored on Google Cloud Storage describing additional information about the Model, that is specific to it. Unset if the Model does not have any additional information. The schema is defined as an OpenAPI 3.0.2 [Schema Object](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject). AutoML Models always have this field populated by Vertex AI, if no additional metadata is needed, this field is set to an empty string. Note: The URI given on output will be immutable and probably different, including the URI scheme, than the one given on input. The output URI will point to a location where the user only has a read access.
func (o GoogleCloudAiplatformV1ModelPtrOutput) MetadataSchemaUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1Model) *string {
		if v == nil {
			return nil
		}
		return v.MetadataSchemaUri
	}).(pulumi.StringPtrOutput)
}

// The resource name of the Model.
func (o GoogleCloudAiplatformV1ModelPtrOutput) Name() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1Model) *string {
		if v == nil {
			return nil
		}
		return v.Name
	}).(pulumi.StringPtrOutput)
}

// Optional. This field is populated if the model is produced by a pipeline job.
func (o GoogleCloudAiplatformV1ModelPtrOutput) PipelineJob() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1Model) *string {
		if v == nil {
			return nil
		}
		return v.PipelineJob
	}).(pulumi.StringPtrOutput)
}

// The schemata that describe formats of the Model's predictions and explanations as given and returned via PredictionService.Predict and PredictionService.Explain.
func (o GoogleCloudAiplatformV1ModelPtrOutput) PredictSchemata() GoogleCloudAiplatformV1PredictSchemataPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1Model) *GoogleCloudAiplatformV1PredictSchemata {
		if v == nil {
			return nil
		}
		return v.PredictSchemata
	}).(GoogleCloudAiplatformV1PredictSchemataPtrOutput)
}

// User provided version aliases so that a model version can be referenced via alias (i.e. `projects/{project}/locations/{location}/models/{model_id}@{version_alias}` instead of auto-generated version id (i.e. `projects/{project}/locations/{location}/models/{model_id}@{version_id})`. The format is a-z{0,126}[a-z0-9] to distinguish from version_id. A default version alias will be created for the first version of the model, and there must be exactly one default version alias for a model.
func (o GoogleCloudAiplatformV1ModelPtrOutput) VersionAliases() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1Model) []string {
		if v == nil {
			return nil
		}
		return v.VersionAliases
	}).(pulumi.StringArrayOutput)
}

// The description of this version.
func (o GoogleCloudAiplatformV1ModelPtrOutput) VersionDescription() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1Model) *string {
		if v == nil {
			return nil
		}
		return v.VersionDescription
	}).(pulumi.StringPtrOutput)
}

// Specification of a container for serving predictions. Some fields in this message correspond to fields in the [Kubernetes Container v1 core specification](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
type GoogleCloudAiplatformV1ModelContainerSpec struct {
	// Immutable. Specifies arguments for the command that runs when the container starts. This overrides the container's [`CMD`](https://docs.docker.com/engine/reference/builder/#cmd). Specify this field as an array of executable and arguments, similar to a Docker `CMD`'s "default parameters" form. If you don't specify this field but do specify the command field, then the command from the `command` field runs without any additional arguments. See the [Kubernetes documentation about how the `command` and `args` fields interact with a container's `ENTRYPOINT` and `CMD`](https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#notes). If you don't specify this field and don't specify the `command` field, then the container's [`ENTRYPOINT`](https://docs.docker.com/engine/reference/builder/#cmd) and `CMD` determine what runs based on their default behavior. See the Docker documentation about [how `CMD` and `ENTRYPOINT` interact](https://docs.docker.com/engine/reference/builder/#understand-how-cmd-and-entrypoint-interact). In this field, you can reference [environment variables set by Vertex AI](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables) and environment variables set in the env field. You cannot reference environment variables set in the Docker image. In order for environment variables to be expanded, reference them by using the following syntax: $( VARIABLE_NAME) Note that this differs from Bash variable expansion, which does not use parentheses. If a variable cannot be resolved, the reference in the input string is used unchanged. To avoid variable expansion, you can escape this syntax with `$$`; for example: $$(VARIABLE_NAME) This field corresponds to the `args` field of the Kubernetes Containers [v1 core API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
	Args []string `pulumi:"args"`
	// Immutable. Specifies the command that runs when the container starts. This overrides the container's [ENTRYPOINT](https://docs.docker.com/engine/reference/builder/#entrypoint). Specify this field as an array of executable and arguments, similar to a Docker `ENTRYPOINT`'s "exec" form, not its "shell" form. If you do not specify this field, then the container's `ENTRYPOINT` runs, in conjunction with the args field or the container's [`CMD`](https://docs.docker.com/engine/reference/builder/#cmd), if either exists. If this field is not specified and the container does not have an `ENTRYPOINT`, then refer to the Docker documentation about [how `CMD` and `ENTRYPOINT` interact](https://docs.docker.com/engine/reference/builder/#understand-how-cmd-and-entrypoint-interact). If you specify this field, then you can also specify the `args` field to provide additional arguments for this command. However, if you specify this field, then the container's `CMD` is ignored. See the [Kubernetes documentation about how the `command` and `args` fields interact with a container's `ENTRYPOINT` and `CMD`](https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#notes). In this field, you can reference [environment variables set by Vertex AI](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables) and environment variables set in the env field. You cannot reference environment variables set in the Docker image. In order for environment variables to be expanded, reference them by using the following syntax: $( VARIABLE_NAME) Note that this differs from Bash variable expansion, which does not use parentheses. If a variable cannot be resolved, the reference in the input string is used unchanged. To avoid variable expansion, you can escape this syntax with `$$`; for example: $$(VARIABLE_NAME) This field corresponds to the `command` field of the Kubernetes Containers [v1 core API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
	Command []string `pulumi:"command"`
	// Immutable. Deployment timeout. TODO (b/306244185): Revise documentation before exposing.
	DeploymentTimeout *string `pulumi:"deploymentTimeout"`
	// Immutable. List of environment variables to set in the container. After the container starts running, code running in the container can read these environment variables. Additionally, the command and args fields can reference these variables. Later entries in this list can also reference earlier entries. For example, the following example sets the variable `VAR_2` to have the value `foo bar`: ``` json [ { "name": "VAR_1", "value": "foo" }, { "name": "VAR_2", "value": "$(VAR_1) bar" } ]  ``` If you switch the order of the variables in the example, then the expansion does not occur. This field corresponds to the `env` field of the Kubernetes Containers [v1 core API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
	Env []GoogleCloudAiplatformV1EnvVar `pulumi:"env"`
	// Immutable. Specification for Kubernetes readiness probe. TODO (b/306244185): Revise documentation before exposing.
	HealthProbe *GoogleCloudAiplatformV1Probe `pulumi:"healthProbe"`
	// Immutable. HTTP path on the container to send health checks to. Vertex AI intermittently sends GET requests to this path on the container's IP address and port to check that the container is healthy. Read more about [health checks](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#health). For example, if you set this field to `/bar`, then Vertex AI intermittently sends a GET request to the `/bar` path on the port of your container specified by the first value of this `ModelContainerSpec`'s ports field. If you don't specify this field, it defaults to the following value when you deploy this Model to an Endpoint: /v1/endpoints/ENDPOINT/deployedModels/ DEPLOYED_MODEL:predict The placeholders in this value are replaced as follows: * ENDPOINT: The last segment (following `endpoints/`)of the Endpoint.name][] field of the Endpoint where this Model has been deployed. (Vertex AI makes this value available to your container code as the [`AIP_ENDPOINT_ID` environment variable](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables).) * DEPLOYED_MODEL: DeployedModel.id of the `DeployedModel`. (Vertex AI makes this value available to your container code as the [`AIP_DEPLOYED_MODEL_ID` environment variable](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables).)
	HealthRoute *string `pulumi:"healthRoute"`
	// Immutable. URI of the Docker image to be used as the custom container for serving predictions. This URI must identify an image in Artifact Registry or Container Registry. Learn more about the [container publishing requirements](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#publishing), including permissions requirements for the Vertex AI Service Agent. The container image is ingested upon ModelService.UploadModel, stored internally, and this original path is afterwards not used. To learn about the requirements for the Docker image itself, see [Custom container requirements](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#). You can use the URI to one of Vertex AI's [pre-built container images for prediction](https://cloud.google.com/vertex-ai/docs/predictions/pre-built-containers) in this field.
	ImageUri string `pulumi:"imageUri"`
	// Immutable. List of ports to expose from the container. Vertex AI sends any prediction requests that it receives to the first port on this list. Vertex AI also sends [liveness and health checks](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#liveness) to this port. If you do not specify this field, it defaults to following value: ``` json [ { "containerPort": 8080 } ]  ``` Vertex AI does not use ports other than the first one listed. This field corresponds to the `ports` field of the Kubernetes Containers [v1 core API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
	Ports []GoogleCloudAiplatformV1Port `pulumi:"ports"`
	// Immutable. HTTP path on the container to send prediction requests to. Vertex AI forwards requests sent using projects.locations.endpoints.predict to this path on the container's IP address and port. Vertex AI then returns the container's response in the API response. For example, if you set this field to `/foo`, then when Vertex AI receives a prediction request, it forwards the request body in a POST request to the `/foo` path on the port of your container specified by the first value of this `ModelContainerSpec`'s ports field. If you don't specify this field, it defaults to the following value when you deploy this Model to an Endpoint: /v1/endpoints/ENDPOINT/deployedModels/DEPLOYED_MODEL:predict The placeholders in this value are replaced as follows: * ENDPOINT: The last segment (following `endpoints/`)of the Endpoint.name][] field of the Endpoint where this Model has been deployed. (Vertex AI makes this value available to your container code as the [`AIP_ENDPOINT_ID` environment variable](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables).) * DEPLOYED_MODEL: DeployedModel.id of the `DeployedModel`. (Vertex AI makes this value available to your container code as the [`AIP_DEPLOYED_MODEL_ID` environment variable](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables).)
	PredictRoute *string `pulumi:"predictRoute"`
	// Immutable. The amount of the VM memory to reserve as the shared memory for the model in megabytes. TODO (b/306244185): Revise documentation before exposing.
	SharedMemorySizeMb *string `pulumi:"sharedMemorySizeMb"`
	// Immutable. Specification for Kubernetes startup probe. TODO (b/306244185): Revise documentation before exposing.
	StartupProbe *GoogleCloudAiplatformV1Probe `pulumi:"startupProbe"`
}

// GoogleCloudAiplatformV1ModelContainerSpecInput is an input type that accepts GoogleCloudAiplatformV1ModelContainerSpecArgs and GoogleCloudAiplatformV1ModelContainerSpecOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1ModelContainerSpecInput` via:
//
//	GoogleCloudAiplatformV1ModelContainerSpecArgs{...}
type GoogleCloudAiplatformV1ModelContainerSpecInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1ModelContainerSpecOutput() GoogleCloudAiplatformV1ModelContainerSpecOutput
	ToGoogleCloudAiplatformV1ModelContainerSpecOutputWithContext(context.Context) GoogleCloudAiplatformV1ModelContainerSpecOutput
}

// Specification of a container for serving predictions. Some fields in this message correspond to fields in the [Kubernetes Container v1 core specification](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
type GoogleCloudAiplatformV1ModelContainerSpecArgs struct {
	// Immutable. Specifies arguments for the command that runs when the container starts. This overrides the container's [`CMD`](https://docs.docker.com/engine/reference/builder/#cmd). Specify this field as an array of executable and arguments, similar to a Docker `CMD`'s "default parameters" form. If you don't specify this field but do specify the command field, then the command from the `command` field runs without any additional arguments. See the [Kubernetes documentation about how the `command` and `args` fields interact with a container's `ENTRYPOINT` and `CMD`](https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#notes). If you don't specify this field and don't specify the `command` field, then the container's [`ENTRYPOINT`](https://docs.docker.com/engine/reference/builder/#cmd) and `CMD` determine what runs based on their default behavior. See the Docker documentation about [how `CMD` and `ENTRYPOINT` interact](https://docs.docker.com/engine/reference/builder/#understand-how-cmd-and-entrypoint-interact). In this field, you can reference [environment variables set by Vertex AI](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables) and environment variables set in the env field. You cannot reference environment variables set in the Docker image. In order for environment variables to be expanded, reference them by using the following syntax: $( VARIABLE_NAME) Note that this differs from Bash variable expansion, which does not use parentheses. If a variable cannot be resolved, the reference in the input string is used unchanged. To avoid variable expansion, you can escape this syntax with `$$`; for example: $$(VARIABLE_NAME) This field corresponds to the `args` field of the Kubernetes Containers [v1 core API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
	Args pulumi.StringArrayInput `pulumi:"args"`
	// Immutable. Specifies the command that runs when the container starts. This overrides the container's [ENTRYPOINT](https://docs.docker.com/engine/reference/builder/#entrypoint). Specify this field as an array of executable and arguments, similar to a Docker `ENTRYPOINT`'s "exec" form, not its "shell" form. If you do not specify this field, then the container's `ENTRYPOINT` runs, in conjunction with the args field or the container's [`CMD`](https://docs.docker.com/engine/reference/builder/#cmd), if either exists. If this field is not specified and the container does not have an `ENTRYPOINT`, then refer to the Docker documentation about [how `CMD` and `ENTRYPOINT` interact](https://docs.docker.com/engine/reference/builder/#understand-how-cmd-and-entrypoint-interact). If you specify this field, then you can also specify the `args` field to provide additional arguments for this command. However, if you specify this field, then the container's `CMD` is ignored. See the [Kubernetes documentation about how the `command` and `args` fields interact with a container's `ENTRYPOINT` and `CMD`](https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#notes). In this field, you can reference [environment variables set by Vertex AI](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables) and environment variables set in the env field. You cannot reference environment variables set in the Docker image. In order for environment variables to be expanded, reference them by using the following syntax: $( VARIABLE_NAME) Note that this differs from Bash variable expansion, which does not use parentheses. If a variable cannot be resolved, the reference in the input string is used unchanged. To avoid variable expansion, you can escape this syntax with `$$`; for example: $$(VARIABLE_NAME) This field corresponds to the `command` field of the Kubernetes Containers [v1 core API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
	Command pulumi.StringArrayInput `pulumi:"command"`
	// Immutable. Deployment timeout. TODO (b/306244185): Revise documentation before exposing.
	DeploymentTimeout pulumi.StringPtrInput `pulumi:"deploymentTimeout"`
	// Immutable. List of environment variables to set in the container. After the container starts running, code running in the container can read these environment variables. Additionally, the command and args fields can reference these variables. Later entries in this list can also reference earlier entries. For example, the following example sets the variable `VAR_2` to have the value `foo bar`: ``` json [ { "name": "VAR_1", "value": "foo" }, { "name": "VAR_2", "value": "$(VAR_1) bar" } ]  ``` If you switch the order of the variables in the example, then the expansion does not occur. This field corresponds to the `env` field of the Kubernetes Containers [v1 core API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
	Env GoogleCloudAiplatformV1EnvVarArrayInput `pulumi:"env"`
	// Immutable. Specification for Kubernetes readiness probe. TODO (b/306244185): Revise documentation before exposing.
	HealthProbe GoogleCloudAiplatformV1ProbePtrInput `pulumi:"healthProbe"`
	// Immutable. HTTP path on the container to send health checks to. Vertex AI intermittently sends GET requests to this path on the container's IP address and port to check that the container is healthy. Read more about [health checks](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#health). For example, if you set this field to `/bar`, then Vertex AI intermittently sends a GET request to the `/bar` path on the port of your container specified by the first value of this `ModelContainerSpec`'s ports field. If you don't specify this field, it defaults to the following value when you deploy this Model to an Endpoint: /v1/endpoints/ENDPOINT/deployedModels/ DEPLOYED_MODEL:predict The placeholders in this value are replaced as follows: * ENDPOINT: The last segment (following `endpoints/`)of the Endpoint.name][] field of the Endpoint where this Model has been deployed. (Vertex AI makes this value available to your container code as the [`AIP_ENDPOINT_ID` environment variable](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables).) * DEPLOYED_MODEL: DeployedModel.id of the `DeployedModel`. (Vertex AI makes this value available to your container code as the [`AIP_DEPLOYED_MODEL_ID` environment variable](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables).)
	HealthRoute pulumi.StringPtrInput `pulumi:"healthRoute"`
	// Immutable. URI of the Docker image to be used as the custom container for serving predictions. This URI must identify an image in Artifact Registry or Container Registry. Learn more about the [container publishing requirements](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#publishing), including permissions requirements for the Vertex AI Service Agent. The container image is ingested upon ModelService.UploadModel, stored internally, and this original path is afterwards not used. To learn about the requirements for the Docker image itself, see [Custom container requirements](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#). You can use the URI to one of Vertex AI's [pre-built container images for prediction](https://cloud.google.com/vertex-ai/docs/predictions/pre-built-containers) in this field.
	ImageUri pulumi.StringInput `pulumi:"imageUri"`
	// Immutable. List of ports to expose from the container. Vertex AI sends any prediction requests that it receives to the first port on this list. Vertex AI also sends [liveness and health checks](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#liveness) to this port. If you do not specify this field, it defaults to following value: ``` json [ { "containerPort": 8080 } ]  ``` Vertex AI does not use ports other than the first one listed. This field corresponds to the `ports` field of the Kubernetes Containers [v1 core API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
	Ports GoogleCloudAiplatformV1PortArrayInput `pulumi:"ports"`
	// Immutable. HTTP path on the container to send prediction requests to. Vertex AI forwards requests sent using projects.locations.endpoints.predict to this path on the container's IP address and port. Vertex AI then returns the container's response in the API response. For example, if you set this field to `/foo`, then when Vertex AI receives a prediction request, it forwards the request body in a POST request to the `/foo` path on the port of your container specified by the first value of this `ModelContainerSpec`'s ports field. If you don't specify this field, it defaults to the following value when you deploy this Model to an Endpoint: /v1/endpoints/ENDPOINT/deployedModels/DEPLOYED_MODEL:predict The placeholders in this value are replaced as follows: * ENDPOINT: The last segment (following `endpoints/`)of the Endpoint.name][] field of the Endpoint where this Model has been deployed. (Vertex AI makes this value available to your container code as the [`AIP_ENDPOINT_ID` environment variable](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables).) * DEPLOYED_MODEL: DeployedModel.id of the `DeployedModel`. (Vertex AI makes this value available to your container code as the [`AIP_DEPLOYED_MODEL_ID` environment variable](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables).)
	PredictRoute pulumi.StringPtrInput `pulumi:"predictRoute"`
	// Immutable. The amount of the VM memory to reserve as the shared memory for the model in megabytes. TODO (b/306244185): Revise documentation before exposing.
	SharedMemorySizeMb pulumi.StringPtrInput `pulumi:"sharedMemorySizeMb"`
	// Immutable. Specification for Kubernetes startup probe. TODO (b/306244185): Revise documentation before exposing.
	StartupProbe GoogleCloudAiplatformV1ProbePtrInput `pulumi:"startupProbe"`
}

func (GoogleCloudAiplatformV1ModelContainerSpecArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1ModelContainerSpec)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1ModelContainerSpecArgs) ToGoogleCloudAiplatformV1ModelContainerSpecOutput() GoogleCloudAiplatformV1ModelContainerSpecOutput {
	return i.ToGoogleCloudAiplatformV1ModelContainerSpecOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1ModelContainerSpecArgs) ToGoogleCloudAiplatformV1ModelContainerSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ModelContainerSpecOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1ModelContainerSpecOutput)
}

func (i GoogleCloudAiplatformV1ModelContainerSpecArgs) ToGoogleCloudAiplatformV1ModelContainerSpecPtrOutput() GoogleCloudAiplatformV1ModelContainerSpecPtrOutput {
	return i.ToGoogleCloudAiplatformV1ModelContainerSpecPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1ModelContainerSpecArgs) ToGoogleCloudAiplatformV1ModelContainerSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ModelContainerSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1ModelContainerSpecOutput).ToGoogleCloudAiplatformV1ModelContainerSpecPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1ModelContainerSpecPtrInput is an input type that accepts GoogleCloudAiplatformV1ModelContainerSpecArgs, GoogleCloudAiplatformV1ModelContainerSpecPtr and GoogleCloudAiplatformV1ModelContainerSpecPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1ModelContainerSpecPtrInput` via:
//
//	        GoogleCloudAiplatformV1ModelContainerSpecArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1ModelContainerSpecPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1ModelContainerSpecPtrOutput() GoogleCloudAiplatformV1ModelContainerSpecPtrOutput
	ToGoogleCloudAiplatformV1ModelContainerSpecPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1ModelContainerSpecPtrOutput
}

type googleCloudAiplatformV1ModelContainerSpecPtrType GoogleCloudAiplatformV1ModelContainerSpecArgs

func GoogleCloudAiplatformV1ModelContainerSpecPtr(v *GoogleCloudAiplatformV1ModelContainerSpecArgs) GoogleCloudAiplatformV1ModelContainerSpecPtrInput {
	return (*googleCloudAiplatformV1ModelContainerSpecPtrType)(v)
}

func (*googleCloudAiplatformV1ModelContainerSpecPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1ModelContainerSpec)(nil)).Elem()
}

func (i *googleCloudAiplatformV1ModelContainerSpecPtrType) ToGoogleCloudAiplatformV1ModelContainerSpecPtrOutput() GoogleCloudAiplatformV1ModelContainerSpecPtrOutput {
	return i.ToGoogleCloudAiplatformV1ModelContainerSpecPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1ModelContainerSpecPtrType) ToGoogleCloudAiplatformV1ModelContainerSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ModelContainerSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1ModelContainerSpecPtrOutput)
}

// Specification of a container for serving predictions. Some fields in this message correspond to fields in the [Kubernetes Container v1 core specification](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
type GoogleCloudAiplatformV1ModelContainerSpecOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ModelContainerSpecOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1ModelContainerSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ModelContainerSpecOutput) ToGoogleCloudAiplatformV1ModelContainerSpecOutput() GoogleCloudAiplatformV1ModelContainerSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1ModelContainerSpecOutput) ToGoogleCloudAiplatformV1ModelContainerSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ModelContainerSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1ModelContainerSpecOutput) ToGoogleCloudAiplatformV1ModelContainerSpecPtrOutput() GoogleCloudAiplatformV1ModelContainerSpecPtrOutput {
	return o.ToGoogleCloudAiplatformV1ModelContainerSpecPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1ModelContainerSpecOutput) ToGoogleCloudAiplatformV1ModelContainerSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ModelContainerSpecPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1ModelContainerSpec) *GoogleCloudAiplatformV1ModelContainerSpec {
		return &v
	}).(GoogleCloudAiplatformV1ModelContainerSpecPtrOutput)
}

// Immutable. Specifies arguments for the command that runs when the container starts. This overrides the container's [`CMD`](https://docs.docker.com/engine/reference/builder/#cmd). Specify this field as an array of executable and arguments, similar to a Docker `CMD`'s "default parameters" form. If you don't specify this field but do specify the command field, then the command from the `command` field runs without any additional arguments. See the [Kubernetes documentation about how the `command` and `args` fields interact with a container's `ENTRYPOINT` and `CMD`](https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#notes). If you don't specify this field and don't specify the `command` field, then the container's [`ENTRYPOINT`](https://docs.docker.com/engine/reference/builder/#cmd) and `CMD` determine what runs based on their default behavior. See the Docker documentation about [how `CMD` and `ENTRYPOINT` interact](https://docs.docker.com/engine/reference/builder/#understand-how-cmd-and-entrypoint-interact). In this field, you can reference [environment variables set by Vertex AI](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables) and environment variables set in the env field. You cannot reference environment variables set in the Docker image. In order for environment variables to be expanded, reference them by using the following syntax: $( VARIABLE_NAME) Note that this differs from Bash variable expansion, which does not use parentheses. If a variable cannot be resolved, the reference in the input string is used unchanged. To avoid variable expansion, you can escape this syntax with `$$`; for example: $$(VARIABLE_NAME) This field corresponds to the `args` field of the Kubernetes Containers [v1 core API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
func (o GoogleCloudAiplatformV1ModelContainerSpecOutput) Args() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelContainerSpec) []string { return v.Args }).(pulumi.StringArrayOutput)
}

// Immutable. Specifies the command that runs when the container starts. This overrides the container's [ENTRYPOINT](https://docs.docker.com/engine/reference/builder/#entrypoint). Specify this field as an array of executable and arguments, similar to a Docker `ENTRYPOINT`'s "exec" form, not its "shell" form. If you do not specify this field, then the container's `ENTRYPOINT` runs, in conjunction with the args field or the container's [`CMD`](https://docs.docker.com/engine/reference/builder/#cmd), if either exists. If this field is not specified and the container does not have an `ENTRYPOINT`, then refer to the Docker documentation about [how `CMD` and `ENTRYPOINT` interact](https://docs.docker.com/engine/reference/builder/#understand-how-cmd-and-entrypoint-interact). If you specify this field, then you can also specify the `args` field to provide additional arguments for this command. However, if you specify this field, then the container's `CMD` is ignored. See the [Kubernetes documentation about how the `command` and `args` fields interact with a container's `ENTRYPOINT` and `CMD`](https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#notes). In this field, you can reference [environment variables set by Vertex AI](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables) and environment variables set in the env field. You cannot reference environment variables set in the Docker image. In order for environment variables to be expanded, reference them by using the following syntax: $( VARIABLE_NAME) Note that this differs from Bash variable expansion, which does not use parentheses. If a variable cannot be resolved, the reference in the input string is used unchanged. To avoid variable expansion, you can escape this syntax with `$$`; for example: $$(VARIABLE_NAME) This field corresponds to the `command` field of the Kubernetes Containers [v1 core API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
func (o GoogleCloudAiplatformV1ModelContainerSpecOutput) Command() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelContainerSpec) []string { return v.Command }).(pulumi.StringArrayOutput)
}

// Immutable. Deployment timeout. TODO (b/306244185): Revise documentation before exposing.
func (o GoogleCloudAiplatformV1ModelContainerSpecOutput) DeploymentTimeout() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelContainerSpec) *string { return v.DeploymentTimeout }).(pulumi.StringPtrOutput)
}

// Immutable. List of environment variables to set in the container. After the container starts running, code running in the container can read these environment variables. Additionally, the command and args fields can reference these variables. Later entries in this list can also reference earlier entries. For example, the following example sets the variable `VAR_2` to have the value `foo bar`: ``` json [ { "name": "VAR_1", "value": "foo" }, { "name": "VAR_2", "value": "$(VAR_1) bar" } ]  ``` If you switch the order of the variables in the example, then the expansion does not occur. This field corresponds to the `env` field of the Kubernetes Containers [v1 core API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
func (o GoogleCloudAiplatformV1ModelContainerSpecOutput) Env() GoogleCloudAiplatformV1EnvVarArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelContainerSpec) []GoogleCloudAiplatformV1EnvVar { return v.Env }).(GoogleCloudAiplatformV1EnvVarArrayOutput)
}

// Immutable. Specification for Kubernetes readiness probe. TODO (b/306244185): Revise documentation before exposing.
func (o GoogleCloudAiplatformV1ModelContainerSpecOutput) HealthProbe() GoogleCloudAiplatformV1ProbePtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelContainerSpec) *GoogleCloudAiplatformV1Probe { return v.HealthProbe }).(GoogleCloudAiplatformV1ProbePtrOutput)
}

// Immutable. HTTP path on the container to send health checks to. Vertex AI intermittently sends GET requests to this path on the container's IP address and port to check that the container is healthy. Read more about [health checks](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#health). For example, if you set this field to `/bar`, then Vertex AI intermittently sends a GET request to the `/bar` path on the port of your container specified by the first value of this `ModelContainerSpec`'s ports field. If you don't specify this field, it defaults to the following value when you deploy this Model to an Endpoint: /v1/endpoints/ENDPOINT/deployedModels/ DEPLOYED_MODEL:predict The placeholders in this value are replaced as follows: * ENDPOINT: The last segment (following `endpoints/`)of the Endpoint.name][] field of the Endpoint where this Model has been deployed. (Vertex AI makes this value available to your container code as the [`AIP_ENDPOINT_ID` environment variable](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables).) * DEPLOYED_MODEL: DeployedModel.id of the `DeployedModel`. (Vertex AI makes this value available to your container code as the [`AIP_DEPLOYED_MODEL_ID` environment variable](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables).)
func (o GoogleCloudAiplatformV1ModelContainerSpecOutput) HealthRoute() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelContainerSpec) *string { return v.HealthRoute }).(pulumi.StringPtrOutput)
}

// Immutable. URI of the Docker image to be used as the custom container for serving predictions. This URI must identify an image in Artifact Registry or Container Registry. Learn more about the [container publishing requirements](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#publishing), including permissions requirements for the Vertex AI Service Agent. The container image is ingested upon ModelService.UploadModel, stored internally, and this original path is afterwards not used. To learn about the requirements for the Docker image itself, see [Custom container requirements](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#). You can use the URI to one of Vertex AI's [pre-built container images for prediction](https://cloud.google.com/vertex-ai/docs/predictions/pre-built-containers) in this field.
func (o GoogleCloudAiplatformV1ModelContainerSpecOutput) ImageUri() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelContainerSpec) string { return v.ImageUri }).(pulumi.StringOutput)
}

// Immutable. List of ports to expose from the container. Vertex AI sends any prediction requests that it receives to the first port on this list. Vertex AI also sends [liveness and health checks](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#liveness) to this port. If you do not specify this field, it defaults to following value: ``` json [ { "containerPort": 8080 } ]  ``` Vertex AI does not use ports other than the first one listed. This field corresponds to the `ports` field of the Kubernetes Containers [v1 core API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
func (o GoogleCloudAiplatformV1ModelContainerSpecOutput) Ports() GoogleCloudAiplatformV1PortArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelContainerSpec) []GoogleCloudAiplatformV1Port { return v.Ports }).(GoogleCloudAiplatformV1PortArrayOutput)
}

// Immutable. HTTP path on the container to send prediction requests to. Vertex AI forwards requests sent using projects.locations.endpoints.predict to this path on the container's IP address and port. Vertex AI then returns the container's response in the API response. For example, if you set this field to `/foo`, then when Vertex AI receives a prediction request, it forwards the request body in a POST request to the `/foo` path on the port of your container specified by the first value of this `ModelContainerSpec`'s ports field. If you don't specify this field, it defaults to the following value when you deploy this Model to an Endpoint: /v1/endpoints/ENDPOINT/deployedModels/DEPLOYED_MODEL:predict The placeholders in this value are replaced as follows: * ENDPOINT: The last segment (following `endpoints/`)of the Endpoint.name][] field of the Endpoint where this Model has been deployed. (Vertex AI makes this value available to your container code as the [`AIP_ENDPOINT_ID` environment variable](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables).) * DEPLOYED_MODEL: DeployedModel.id of the `DeployedModel`. (Vertex AI makes this value available to your container code as the [`AIP_DEPLOYED_MODEL_ID` environment variable](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables).)
func (o GoogleCloudAiplatformV1ModelContainerSpecOutput) PredictRoute() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelContainerSpec) *string { return v.PredictRoute }).(pulumi.StringPtrOutput)
}

// Immutable. The amount of the VM memory to reserve as the shared memory for the model in megabytes. TODO (b/306244185): Revise documentation before exposing.
func (o GoogleCloudAiplatformV1ModelContainerSpecOutput) SharedMemorySizeMb() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelContainerSpec) *string { return v.SharedMemorySizeMb }).(pulumi.StringPtrOutput)
}

// Immutable. Specification for Kubernetes startup probe. TODO (b/306244185): Revise documentation before exposing.
func (o GoogleCloudAiplatformV1ModelContainerSpecOutput) StartupProbe() GoogleCloudAiplatformV1ProbePtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelContainerSpec) *GoogleCloudAiplatformV1Probe { return v.StartupProbe }).(GoogleCloudAiplatformV1ProbePtrOutput)
}

type GoogleCloudAiplatformV1ModelContainerSpecPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ModelContainerSpecPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1ModelContainerSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ModelContainerSpecPtrOutput) ToGoogleCloudAiplatformV1ModelContainerSpecPtrOutput() GoogleCloudAiplatformV1ModelContainerSpecPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1ModelContainerSpecPtrOutput) ToGoogleCloudAiplatformV1ModelContainerSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ModelContainerSpecPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1ModelContainerSpecPtrOutput) Elem() GoogleCloudAiplatformV1ModelContainerSpecOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1ModelContainerSpec) GoogleCloudAiplatformV1ModelContainerSpec {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1ModelContainerSpec
		return ret
	}).(GoogleCloudAiplatformV1ModelContainerSpecOutput)
}

// Immutable. Specifies arguments for the command that runs when the container starts. This overrides the container's [`CMD`](https://docs.docker.com/engine/reference/builder/#cmd). Specify this field as an array of executable and arguments, similar to a Docker `CMD`'s "default parameters" form. If you don't specify this field but do specify the command field, then the command from the `command` field runs without any additional arguments. See the [Kubernetes documentation about how the `command` and `args` fields interact with a container's `ENTRYPOINT` and `CMD`](https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#notes). If you don't specify this field and don't specify the `command` field, then the container's [`ENTRYPOINT`](https://docs.docker.com/engine/reference/builder/#cmd) and `CMD` determine what runs based on their default behavior. See the Docker documentation about [how `CMD` and `ENTRYPOINT` interact](https://docs.docker.com/engine/reference/builder/#understand-how-cmd-and-entrypoint-interact). In this field, you can reference [environment variables set by Vertex AI](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables) and environment variables set in the env field. You cannot reference environment variables set in the Docker image. In order for environment variables to be expanded, reference them by using the following syntax: $( VARIABLE_NAME) Note that this differs from Bash variable expansion, which does not use parentheses. If a variable cannot be resolved, the reference in the input string is used unchanged. To avoid variable expansion, you can escape this syntax with `$$`; for example: $$(VARIABLE_NAME) This field corresponds to the `args` field of the Kubernetes Containers [v1 core API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
func (o GoogleCloudAiplatformV1ModelContainerSpecPtrOutput) Args() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1ModelContainerSpec) []string {
		if v == nil {
			return nil
		}
		return v.Args
	}).(pulumi.StringArrayOutput)
}

// Immutable. Specifies the command that runs when the container starts. This overrides the container's [ENTRYPOINT](https://docs.docker.com/engine/reference/builder/#entrypoint). Specify this field as an array of executable and arguments, similar to a Docker `ENTRYPOINT`'s "exec" form, not its "shell" form. If you do not specify this field, then the container's `ENTRYPOINT` runs, in conjunction with the args field or the container's [`CMD`](https://docs.docker.com/engine/reference/builder/#cmd), if either exists. If this field is not specified and the container does not have an `ENTRYPOINT`, then refer to the Docker documentation about [how `CMD` and `ENTRYPOINT` interact](https://docs.docker.com/engine/reference/builder/#understand-how-cmd-and-entrypoint-interact). If you specify this field, then you can also specify the `args` field to provide additional arguments for this command. However, if you specify this field, then the container's `CMD` is ignored. See the [Kubernetes documentation about how the `command` and `args` fields interact with a container's `ENTRYPOINT` and `CMD`](https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#notes). In this field, you can reference [environment variables set by Vertex AI](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables) and environment variables set in the env field. You cannot reference environment variables set in the Docker image. In order for environment variables to be expanded, reference them by using the following syntax: $( VARIABLE_NAME) Note that this differs from Bash variable expansion, which does not use parentheses. If a variable cannot be resolved, the reference in the input string is used unchanged. To avoid variable expansion, you can escape this syntax with `$$`; for example: $$(VARIABLE_NAME) This field corresponds to the `command` field of the Kubernetes Containers [v1 core API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
func (o GoogleCloudAiplatformV1ModelContainerSpecPtrOutput) Command() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1ModelContainerSpec) []string {
		if v == nil {
			return nil
		}
		return v.Command
	}).(pulumi.StringArrayOutput)
}

// Immutable. Deployment timeout. TODO (b/306244185): Revise documentation before exposing.
func (o GoogleCloudAiplatformV1ModelContainerSpecPtrOutput) DeploymentTimeout() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1ModelContainerSpec) *string {
		if v == nil {
			return nil
		}
		return v.DeploymentTimeout
	}).(pulumi.StringPtrOutput)
}

// Immutable. List of environment variables to set in the container. After the container starts running, code running in the container can read these environment variables. Additionally, the command and args fields can reference these variables. Later entries in this list can also reference earlier entries. For example, the following example sets the variable `VAR_2` to have the value `foo bar`: ``` json [ { "name": "VAR_1", "value": "foo" }, { "name": "VAR_2", "value": "$(VAR_1) bar" } ]  ``` If you switch the order of the variables in the example, then the expansion does not occur. This field corresponds to the `env` field of the Kubernetes Containers [v1 core API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
func (o GoogleCloudAiplatformV1ModelContainerSpecPtrOutput) Env() GoogleCloudAiplatformV1EnvVarArrayOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1ModelContainerSpec) []GoogleCloudAiplatformV1EnvVar {
		if v == nil {
			return nil
		}
		return v.Env
	}).(GoogleCloudAiplatformV1EnvVarArrayOutput)
}

// Immutable. Specification for Kubernetes readiness probe. TODO (b/306244185): Revise documentation before exposing.
func (o GoogleCloudAiplatformV1ModelContainerSpecPtrOutput) HealthProbe() GoogleCloudAiplatformV1ProbePtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1ModelContainerSpec) *GoogleCloudAiplatformV1Probe {
		if v == nil {
			return nil
		}
		return v.HealthProbe
	}).(GoogleCloudAiplatformV1ProbePtrOutput)
}

// Immutable. HTTP path on the container to send health checks to. Vertex AI intermittently sends GET requests to this path on the container's IP address and port to check that the container is healthy. Read more about [health checks](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#health). For example, if you set this field to `/bar`, then Vertex AI intermittently sends a GET request to the `/bar` path on the port of your container specified by the first value of this `ModelContainerSpec`'s ports field. If you don't specify this field, it defaults to the following value when you deploy this Model to an Endpoint: /v1/endpoints/ENDPOINT/deployedModels/ DEPLOYED_MODEL:predict The placeholders in this value are replaced as follows: * ENDPOINT: The last segment (following `endpoints/`)of the Endpoint.name][] field of the Endpoint where this Model has been deployed. (Vertex AI makes this value available to your container code as the [`AIP_ENDPOINT_ID` environment variable](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables).) * DEPLOYED_MODEL: DeployedModel.id of the `DeployedModel`. (Vertex AI makes this value available to your container code as the [`AIP_DEPLOYED_MODEL_ID` environment variable](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables).)
func (o GoogleCloudAiplatformV1ModelContainerSpecPtrOutput) HealthRoute() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1ModelContainerSpec) *string {
		if v == nil {
			return nil
		}
		return v.HealthRoute
	}).(pulumi.StringPtrOutput)
}

// Immutable. URI of the Docker image to be used as the custom container for serving predictions. This URI must identify an image in Artifact Registry or Container Registry. Learn more about the [container publishing requirements](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#publishing), including permissions requirements for the Vertex AI Service Agent. The container image is ingested upon ModelService.UploadModel, stored internally, and this original path is afterwards not used. To learn about the requirements for the Docker image itself, see [Custom container requirements](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#). You can use the URI to one of Vertex AI's [pre-built container images for prediction](https://cloud.google.com/vertex-ai/docs/predictions/pre-built-containers) in this field.
func (o GoogleCloudAiplatformV1ModelContainerSpecPtrOutput) ImageUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1ModelContainerSpec) *string {
		if v == nil {
			return nil
		}
		return &v.ImageUri
	}).(pulumi.StringPtrOutput)
}

// Immutable. List of ports to expose from the container. Vertex AI sends any prediction requests that it receives to the first port on this list. Vertex AI also sends [liveness and health checks](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#liveness) to this port. If you do not specify this field, it defaults to following value: ``` json [ { "containerPort": 8080 } ]  ``` Vertex AI does not use ports other than the first one listed. This field corresponds to the `ports` field of the Kubernetes Containers [v1 core API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
func (o GoogleCloudAiplatformV1ModelContainerSpecPtrOutput) Ports() GoogleCloudAiplatformV1PortArrayOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1ModelContainerSpec) []GoogleCloudAiplatformV1Port {
		if v == nil {
			return nil
		}
		return v.Ports
	}).(GoogleCloudAiplatformV1PortArrayOutput)
}

// Immutable. HTTP path on the container to send prediction requests to. Vertex AI forwards requests sent using projects.locations.endpoints.predict to this path on the container's IP address and port. Vertex AI then returns the container's response in the API response. For example, if you set this field to `/foo`, then when Vertex AI receives a prediction request, it forwards the request body in a POST request to the `/foo` path on the port of your container specified by the first value of this `ModelContainerSpec`'s ports field. If you don't specify this field, it defaults to the following value when you deploy this Model to an Endpoint: /v1/endpoints/ENDPOINT/deployedModels/DEPLOYED_MODEL:predict The placeholders in this value are replaced as follows: * ENDPOINT: The last segment (following `endpoints/`)of the Endpoint.name][] field of the Endpoint where this Model has been deployed. (Vertex AI makes this value available to your container code as the [`AIP_ENDPOINT_ID` environment variable](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables).) * DEPLOYED_MODEL: DeployedModel.id of the `DeployedModel`. (Vertex AI makes this value available to your container code as the [`AIP_DEPLOYED_MODEL_ID` environment variable](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables).)
func (o GoogleCloudAiplatformV1ModelContainerSpecPtrOutput) PredictRoute() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1ModelContainerSpec) *string {
		if v == nil {
			return nil
		}
		return v.PredictRoute
	}).(pulumi.StringPtrOutput)
}

// Immutable. The amount of the VM memory to reserve as the shared memory for the model in megabytes. TODO (b/306244185): Revise documentation before exposing.
func (o GoogleCloudAiplatformV1ModelContainerSpecPtrOutput) SharedMemorySizeMb() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1ModelContainerSpec) *string {
		if v == nil {
			return nil
		}
		return v.SharedMemorySizeMb
	}).(pulumi.StringPtrOutput)
}

// Immutable. Specification for Kubernetes startup probe. TODO (b/306244185): Revise documentation before exposing.
func (o GoogleCloudAiplatformV1ModelContainerSpecPtrOutput) StartupProbe() GoogleCloudAiplatformV1ProbePtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1ModelContainerSpec) *GoogleCloudAiplatformV1Probe {
		if v == nil {
			return nil
		}
		return v.StartupProbe
	}).(GoogleCloudAiplatformV1ProbePtrOutput)
}

// Specification of a container for serving predictions. Some fields in this message correspond to fields in the [Kubernetes Container v1 core specification](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
type GoogleCloudAiplatformV1ModelContainerSpecResponse struct {
	// Immutable. Specifies arguments for the command that runs when the container starts. This overrides the container's [`CMD`](https://docs.docker.com/engine/reference/builder/#cmd). Specify this field as an array of executable and arguments, similar to a Docker `CMD`'s "default parameters" form. If you don't specify this field but do specify the command field, then the command from the `command` field runs without any additional arguments. See the [Kubernetes documentation about how the `command` and `args` fields interact with a container's `ENTRYPOINT` and `CMD`](https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#notes). If you don't specify this field and don't specify the `command` field, then the container's [`ENTRYPOINT`](https://docs.docker.com/engine/reference/builder/#cmd) and `CMD` determine what runs based on their default behavior. See the Docker documentation about [how `CMD` and `ENTRYPOINT` interact](https://docs.docker.com/engine/reference/builder/#understand-how-cmd-and-entrypoint-interact). In this field, you can reference [environment variables set by Vertex AI](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables) and environment variables set in the env field. You cannot reference environment variables set in the Docker image. In order for environment variables to be expanded, reference them by using the following syntax: $( VARIABLE_NAME) Note that this differs from Bash variable expansion, which does not use parentheses. If a variable cannot be resolved, the reference in the input string is used unchanged. To avoid variable expansion, you can escape this syntax with `$$`; for example: $$(VARIABLE_NAME) This field corresponds to the `args` field of the Kubernetes Containers [v1 core API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
	Args []string `pulumi:"args"`
	// Immutable. Specifies the command that runs when the container starts. This overrides the container's [ENTRYPOINT](https://docs.docker.com/engine/reference/builder/#entrypoint). Specify this field as an array of executable and arguments, similar to a Docker `ENTRYPOINT`'s "exec" form, not its "shell" form. If you do not specify this field, then the container's `ENTRYPOINT` runs, in conjunction with the args field or the container's [`CMD`](https://docs.docker.com/engine/reference/builder/#cmd), if either exists. If this field is not specified and the container does not have an `ENTRYPOINT`, then refer to the Docker documentation about [how `CMD` and `ENTRYPOINT` interact](https://docs.docker.com/engine/reference/builder/#understand-how-cmd-and-entrypoint-interact). If you specify this field, then you can also specify the `args` field to provide additional arguments for this command. However, if you specify this field, then the container's `CMD` is ignored. See the [Kubernetes documentation about how the `command` and `args` fields interact with a container's `ENTRYPOINT` and `CMD`](https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#notes). In this field, you can reference [environment variables set by Vertex AI](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables) and environment variables set in the env field. You cannot reference environment variables set in the Docker image. In order for environment variables to be expanded, reference them by using the following syntax: $( VARIABLE_NAME) Note that this differs from Bash variable expansion, which does not use parentheses. If a variable cannot be resolved, the reference in the input string is used unchanged. To avoid variable expansion, you can escape this syntax with `$$`; for example: $$(VARIABLE_NAME) This field corresponds to the `command` field of the Kubernetes Containers [v1 core API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
	Command []string `pulumi:"command"`
	// Immutable. Deployment timeout. TODO (b/306244185): Revise documentation before exposing.
	DeploymentTimeout string `pulumi:"deploymentTimeout"`
	// Immutable. List of environment variables to set in the container. After the container starts running, code running in the container can read these environment variables. Additionally, the command and args fields can reference these variables. Later entries in this list can also reference earlier entries. For example, the following example sets the variable `VAR_2` to have the value `foo bar`: ``` json [ { "name": "VAR_1", "value": "foo" }, { "name": "VAR_2", "value": "$(VAR_1) bar" } ]  ``` If you switch the order of the variables in the example, then the expansion does not occur. This field corresponds to the `env` field of the Kubernetes Containers [v1 core API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
	Env []GoogleCloudAiplatformV1EnvVarResponse `pulumi:"env"`
	// Immutable. Specification for Kubernetes readiness probe. TODO (b/306244185): Revise documentation before exposing.
	HealthProbe GoogleCloudAiplatformV1ProbeResponse `pulumi:"healthProbe"`
	// Immutable. HTTP path on the container to send health checks to. Vertex AI intermittently sends GET requests to this path on the container's IP address and port to check that the container is healthy. Read more about [health checks](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#health). For example, if you set this field to `/bar`, then Vertex AI intermittently sends a GET request to the `/bar` path on the port of your container specified by the first value of this `ModelContainerSpec`'s ports field. If you don't specify this field, it defaults to the following value when you deploy this Model to an Endpoint: /v1/endpoints/ENDPOINT/deployedModels/ DEPLOYED_MODEL:predict The placeholders in this value are replaced as follows: * ENDPOINT: The last segment (following `endpoints/`)of the Endpoint.name][] field of the Endpoint where this Model has been deployed. (Vertex AI makes this value available to your container code as the [`AIP_ENDPOINT_ID` environment variable](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables).) * DEPLOYED_MODEL: DeployedModel.id of the `DeployedModel`. (Vertex AI makes this value available to your container code as the [`AIP_DEPLOYED_MODEL_ID` environment variable](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables).)
	HealthRoute string `pulumi:"healthRoute"`
	// Immutable. URI of the Docker image to be used as the custom container for serving predictions. This URI must identify an image in Artifact Registry or Container Registry. Learn more about the [container publishing requirements](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#publishing), including permissions requirements for the Vertex AI Service Agent. The container image is ingested upon ModelService.UploadModel, stored internally, and this original path is afterwards not used. To learn about the requirements for the Docker image itself, see [Custom container requirements](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#). You can use the URI to one of Vertex AI's [pre-built container images for prediction](https://cloud.google.com/vertex-ai/docs/predictions/pre-built-containers) in this field.
	ImageUri string `pulumi:"imageUri"`
	// Immutable. List of ports to expose from the container. Vertex AI sends any prediction requests that it receives to the first port on this list. Vertex AI also sends [liveness and health checks](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#liveness) to this port. If you do not specify this field, it defaults to following value: ``` json [ { "containerPort": 8080 } ]  ``` Vertex AI does not use ports other than the first one listed. This field corresponds to the `ports` field of the Kubernetes Containers [v1 core API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
	Ports []GoogleCloudAiplatformV1PortResponse `pulumi:"ports"`
	// Immutable. HTTP path on the container to send prediction requests to. Vertex AI forwards requests sent using projects.locations.endpoints.predict to this path on the container's IP address and port. Vertex AI then returns the container's response in the API response. For example, if you set this field to `/foo`, then when Vertex AI receives a prediction request, it forwards the request body in a POST request to the `/foo` path on the port of your container specified by the first value of this `ModelContainerSpec`'s ports field. If you don't specify this field, it defaults to the following value when you deploy this Model to an Endpoint: /v1/endpoints/ENDPOINT/deployedModels/DEPLOYED_MODEL:predict The placeholders in this value are replaced as follows: * ENDPOINT: The last segment (following `endpoints/`)of the Endpoint.name][] field of the Endpoint where this Model has been deployed. (Vertex AI makes this value available to your container code as the [`AIP_ENDPOINT_ID` environment variable](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables).) * DEPLOYED_MODEL: DeployedModel.id of the `DeployedModel`. (Vertex AI makes this value available to your container code as the [`AIP_DEPLOYED_MODEL_ID` environment variable](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables).)
	PredictRoute string `pulumi:"predictRoute"`
	// Immutable. The amount of the VM memory to reserve as the shared memory for the model in megabytes. TODO (b/306244185): Revise documentation before exposing.
	SharedMemorySizeMb string `pulumi:"sharedMemorySizeMb"`
	// Immutable. Specification for Kubernetes startup probe. TODO (b/306244185): Revise documentation before exposing.
	StartupProbe GoogleCloudAiplatformV1ProbeResponse `pulumi:"startupProbe"`
}

// Specification of a container for serving predictions. Some fields in this message correspond to fields in the [Kubernetes Container v1 core specification](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
type GoogleCloudAiplatformV1ModelContainerSpecResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ModelContainerSpecResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1ModelContainerSpecResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ModelContainerSpecResponseOutput) ToGoogleCloudAiplatformV1ModelContainerSpecResponseOutput() GoogleCloudAiplatformV1ModelContainerSpecResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1ModelContainerSpecResponseOutput) ToGoogleCloudAiplatformV1ModelContainerSpecResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ModelContainerSpecResponseOutput {
	return o
}

// Immutable. Specifies arguments for the command that runs when the container starts. This overrides the container's [`CMD`](https://docs.docker.com/engine/reference/builder/#cmd). Specify this field as an array of executable and arguments, similar to a Docker `CMD`'s "default parameters" form. If you don't specify this field but do specify the command field, then the command from the `command` field runs without any additional arguments. See the [Kubernetes documentation about how the `command` and `args` fields interact with a container's `ENTRYPOINT` and `CMD`](https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#notes). If you don't specify this field and don't specify the `command` field, then the container's [`ENTRYPOINT`](https://docs.docker.com/engine/reference/builder/#cmd) and `CMD` determine what runs based on their default behavior. See the Docker documentation about [how `CMD` and `ENTRYPOINT` interact](https://docs.docker.com/engine/reference/builder/#understand-how-cmd-and-entrypoint-interact). In this field, you can reference [environment variables set by Vertex AI](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables) and environment variables set in the env field. You cannot reference environment variables set in the Docker image. In order for environment variables to be expanded, reference them by using the following syntax: $( VARIABLE_NAME) Note that this differs from Bash variable expansion, which does not use parentheses. If a variable cannot be resolved, the reference in the input string is used unchanged. To avoid variable expansion, you can escape this syntax with `$$`; for example: $$(VARIABLE_NAME) This field corresponds to the `args` field of the Kubernetes Containers [v1 core API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
func (o GoogleCloudAiplatformV1ModelContainerSpecResponseOutput) Args() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelContainerSpecResponse) []string { return v.Args }).(pulumi.StringArrayOutput)
}

// Immutable. Specifies the command that runs when the container starts. This overrides the container's [ENTRYPOINT](https://docs.docker.com/engine/reference/builder/#entrypoint). Specify this field as an array of executable and arguments, similar to a Docker `ENTRYPOINT`'s "exec" form, not its "shell" form. If you do not specify this field, then the container's `ENTRYPOINT` runs, in conjunction with the args field or the container's [`CMD`](https://docs.docker.com/engine/reference/builder/#cmd), if either exists. If this field is not specified and the container does not have an `ENTRYPOINT`, then refer to the Docker documentation about [how `CMD` and `ENTRYPOINT` interact](https://docs.docker.com/engine/reference/builder/#understand-how-cmd-and-entrypoint-interact). If you specify this field, then you can also specify the `args` field to provide additional arguments for this command. However, if you specify this field, then the container's `CMD` is ignored. See the [Kubernetes documentation about how the `command` and `args` fields interact with a container's `ENTRYPOINT` and `CMD`](https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#notes). In this field, you can reference [environment variables set by Vertex AI](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables) and environment variables set in the env field. You cannot reference environment variables set in the Docker image. In order for environment variables to be expanded, reference them by using the following syntax: $( VARIABLE_NAME) Note that this differs from Bash variable expansion, which does not use parentheses. If a variable cannot be resolved, the reference in the input string is used unchanged. To avoid variable expansion, you can escape this syntax with `$$`; for example: $$(VARIABLE_NAME) This field corresponds to the `command` field of the Kubernetes Containers [v1 core API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
func (o GoogleCloudAiplatformV1ModelContainerSpecResponseOutput) Command() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelContainerSpecResponse) []string { return v.Command }).(pulumi.StringArrayOutput)
}

// Immutable. Deployment timeout. TODO (b/306244185): Revise documentation before exposing.
func (o GoogleCloudAiplatformV1ModelContainerSpecResponseOutput) DeploymentTimeout() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelContainerSpecResponse) string { return v.DeploymentTimeout }).(pulumi.StringOutput)
}

// Immutable. List of environment variables to set in the container. After the container starts running, code running in the container can read these environment variables. Additionally, the command and args fields can reference these variables. Later entries in this list can also reference earlier entries. For example, the following example sets the variable `VAR_2` to have the value `foo bar`: ``` json [ { "name": "VAR_1", "value": "foo" }, { "name": "VAR_2", "value": "$(VAR_1) bar" } ]  ``` If you switch the order of the variables in the example, then the expansion does not occur. This field corresponds to the `env` field of the Kubernetes Containers [v1 core API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
func (o GoogleCloudAiplatformV1ModelContainerSpecResponseOutput) Env() GoogleCloudAiplatformV1EnvVarResponseArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelContainerSpecResponse) []GoogleCloudAiplatformV1EnvVarResponse {
		return v.Env
	}).(GoogleCloudAiplatformV1EnvVarResponseArrayOutput)
}

// Immutable. Specification for Kubernetes readiness probe. TODO (b/306244185): Revise documentation before exposing.
func (o GoogleCloudAiplatformV1ModelContainerSpecResponseOutput) HealthProbe() GoogleCloudAiplatformV1ProbeResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelContainerSpecResponse) GoogleCloudAiplatformV1ProbeResponse {
		return v.HealthProbe
	}).(GoogleCloudAiplatformV1ProbeResponseOutput)
}

// Immutable. HTTP path on the container to send health checks to. Vertex AI intermittently sends GET requests to this path on the container's IP address and port to check that the container is healthy. Read more about [health checks](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#health). For example, if you set this field to `/bar`, then Vertex AI intermittently sends a GET request to the `/bar` path on the port of your container specified by the first value of this `ModelContainerSpec`'s ports field. If you don't specify this field, it defaults to the following value when you deploy this Model to an Endpoint: /v1/endpoints/ENDPOINT/deployedModels/ DEPLOYED_MODEL:predict The placeholders in this value are replaced as follows: * ENDPOINT: The last segment (following `endpoints/`)of the Endpoint.name][] field of the Endpoint where this Model has been deployed. (Vertex AI makes this value available to your container code as the [`AIP_ENDPOINT_ID` environment variable](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables).) * DEPLOYED_MODEL: DeployedModel.id of the `DeployedModel`. (Vertex AI makes this value available to your container code as the [`AIP_DEPLOYED_MODEL_ID` environment variable](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables).)
func (o GoogleCloudAiplatformV1ModelContainerSpecResponseOutput) HealthRoute() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelContainerSpecResponse) string { return v.HealthRoute }).(pulumi.StringOutput)
}

// Immutable. URI of the Docker image to be used as the custom container for serving predictions. This URI must identify an image in Artifact Registry or Container Registry. Learn more about the [container publishing requirements](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#publishing), including permissions requirements for the Vertex AI Service Agent. The container image is ingested upon ModelService.UploadModel, stored internally, and this original path is afterwards not used. To learn about the requirements for the Docker image itself, see [Custom container requirements](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#). You can use the URI to one of Vertex AI's [pre-built container images for prediction](https://cloud.google.com/vertex-ai/docs/predictions/pre-built-containers) in this field.
func (o GoogleCloudAiplatformV1ModelContainerSpecResponseOutput) ImageUri() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelContainerSpecResponse) string { return v.ImageUri }).(pulumi.StringOutput)
}

// Immutable. List of ports to expose from the container. Vertex AI sends any prediction requests that it receives to the first port on this list. Vertex AI also sends [liveness and health checks](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#liveness) to this port. If you do not specify this field, it defaults to following value: ``` json [ { "containerPort": 8080 } ]  ``` Vertex AI does not use ports other than the first one listed. This field corresponds to the `ports` field of the Kubernetes Containers [v1 core API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
func (o GoogleCloudAiplatformV1ModelContainerSpecResponseOutput) Ports() GoogleCloudAiplatformV1PortResponseArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelContainerSpecResponse) []GoogleCloudAiplatformV1PortResponse {
		return v.Ports
	}).(GoogleCloudAiplatformV1PortResponseArrayOutput)
}

// Immutable. HTTP path on the container to send prediction requests to. Vertex AI forwards requests sent using projects.locations.endpoints.predict to this path on the container's IP address and port. Vertex AI then returns the container's response in the API response. For example, if you set this field to `/foo`, then when Vertex AI receives a prediction request, it forwards the request body in a POST request to the `/foo` path on the port of your container specified by the first value of this `ModelContainerSpec`'s ports field. If you don't specify this field, it defaults to the following value when you deploy this Model to an Endpoint: /v1/endpoints/ENDPOINT/deployedModels/DEPLOYED_MODEL:predict The placeholders in this value are replaced as follows: * ENDPOINT: The last segment (following `endpoints/`)of the Endpoint.name][] field of the Endpoint where this Model has been deployed. (Vertex AI makes this value available to your container code as the [`AIP_ENDPOINT_ID` environment variable](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables).) * DEPLOYED_MODEL: DeployedModel.id of the `DeployedModel`. (Vertex AI makes this value available to your container code as the [`AIP_DEPLOYED_MODEL_ID` environment variable](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables).)
func (o GoogleCloudAiplatformV1ModelContainerSpecResponseOutput) PredictRoute() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelContainerSpecResponse) string { return v.PredictRoute }).(pulumi.StringOutput)
}

// Immutable. The amount of the VM memory to reserve as the shared memory for the model in megabytes. TODO (b/306244185): Revise documentation before exposing.
func (o GoogleCloudAiplatformV1ModelContainerSpecResponseOutput) SharedMemorySizeMb() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelContainerSpecResponse) string { return v.SharedMemorySizeMb }).(pulumi.StringOutput)
}

// Immutable. Specification for Kubernetes startup probe. TODO (b/306244185): Revise documentation before exposing.
func (o GoogleCloudAiplatformV1ModelContainerSpecResponseOutput) StartupProbe() GoogleCloudAiplatformV1ProbeResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelContainerSpecResponse) GoogleCloudAiplatformV1ProbeResponse {
		return v.StartupProbe
	}).(GoogleCloudAiplatformV1ProbeResponseOutput)
}

// ModelDeploymentMonitoringBigQueryTable specifies the BigQuery table name as well as some information of the logs stored in this table.
type GoogleCloudAiplatformV1ModelDeploymentMonitoringBigQueryTableResponse struct {
	// The created BigQuery table to store logs. Customer could do their own query & analysis. Format: `bq://.model_deployment_monitoring_._`
	BigqueryTablePath string `pulumi:"bigqueryTablePath"`
	// The source of log.
	LogSource string `pulumi:"logSource"`
	// The type of log.
	LogType string `pulumi:"logType"`
}

// ModelDeploymentMonitoringBigQueryTable specifies the BigQuery table name as well as some information of the logs stored in this table.
type GoogleCloudAiplatformV1ModelDeploymentMonitoringBigQueryTableResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ModelDeploymentMonitoringBigQueryTableResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1ModelDeploymentMonitoringBigQueryTableResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ModelDeploymentMonitoringBigQueryTableResponseOutput) ToGoogleCloudAiplatformV1ModelDeploymentMonitoringBigQueryTableResponseOutput() GoogleCloudAiplatformV1ModelDeploymentMonitoringBigQueryTableResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1ModelDeploymentMonitoringBigQueryTableResponseOutput) ToGoogleCloudAiplatformV1ModelDeploymentMonitoringBigQueryTableResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ModelDeploymentMonitoringBigQueryTableResponseOutput {
	return o
}

// The created BigQuery table to store logs. Customer could do their own query & analysis. Format: `bq://.model_deployment_monitoring_._`
func (o GoogleCloudAiplatformV1ModelDeploymentMonitoringBigQueryTableResponseOutput) BigqueryTablePath() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelDeploymentMonitoringBigQueryTableResponse) string {
		return v.BigqueryTablePath
	}).(pulumi.StringOutput)
}

// The source of log.
func (o GoogleCloudAiplatformV1ModelDeploymentMonitoringBigQueryTableResponseOutput) LogSource() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelDeploymentMonitoringBigQueryTableResponse) string {
		return v.LogSource
	}).(pulumi.StringOutput)
}

// The type of log.
func (o GoogleCloudAiplatformV1ModelDeploymentMonitoringBigQueryTableResponseOutput) LogType() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelDeploymentMonitoringBigQueryTableResponse) string { return v.LogType }).(pulumi.StringOutput)
}

type GoogleCloudAiplatformV1ModelDeploymentMonitoringBigQueryTableResponseArrayOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ModelDeploymentMonitoringBigQueryTableResponseArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1ModelDeploymentMonitoringBigQueryTableResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ModelDeploymentMonitoringBigQueryTableResponseArrayOutput) ToGoogleCloudAiplatformV1ModelDeploymentMonitoringBigQueryTableResponseArrayOutput() GoogleCloudAiplatformV1ModelDeploymentMonitoringBigQueryTableResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1ModelDeploymentMonitoringBigQueryTableResponseArrayOutput) ToGoogleCloudAiplatformV1ModelDeploymentMonitoringBigQueryTableResponseArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ModelDeploymentMonitoringBigQueryTableResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1ModelDeploymentMonitoringBigQueryTableResponseArrayOutput) Index(i pulumi.IntInput) GoogleCloudAiplatformV1ModelDeploymentMonitoringBigQueryTableResponseOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GoogleCloudAiplatformV1ModelDeploymentMonitoringBigQueryTableResponse {
		return vs[0].([]GoogleCloudAiplatformV1ModelDeploymentMonitoringBigQueryTableResponse)[vs[1].(int)]
	}).(GoogleCloudAiplatformV1ModelDeploymentMonitoringBigQueryTableResponseOutput)
}

// All metadata of most recent monitoring pipelines.
type GoogleCloudAiplatformV1ModelDeploymentMonitoringJobLatestMonitoringPipelineMetadataResponse struct {
	// The time that most recent monitoring pipelines that is related to this run.
	RunTime string `pulumi:"runTime"`
	// The status of the most recent monitoring pipeline.
	Status GoogleRpcStatusResponse `pulumi:"status"`
}

// All metadata of most recent monitoring pipelines.
type GoogleCloudAiplatformV1ModelDeploymentMonitoringJobLatestMonitoringPipelineMetadataResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ModelDeploymentMonitoringJobLatestMonitoringPipelineMetadataResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1ModelDeploymentMonitoringJobLatestMonitoringPipelineMetadataResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ModelDeploymentMonitoringJobLatestMonitoringPipelineMetadataResponseOutput) ToGoogleCloudAiplatformV1ModelDeploymentMonitoringJobLatestMonitoringPipelineMetadataResponseOutput() GoogleCloudAiplatformV1ModelDeploymentMonitoringJobLatestMonitoringPipelineMetadataResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1ModelDeploymentMonitoringJobLatestMonitoringPipelineMetadataResponseOutput) ToGoogleCloudAiplatformV1ModelDeploymentMonitoringJobLatestMonitoringPipelineMetadataResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ModelDeploymentMonitoringJobLatestMonitoringPipelineMetadataResponseOutput {
	return o
}

// The time that most recent monitoring pipelines that is related to this run.
func (o GoogleCloudAiplatformV1ModelDeploymentMonitoringJobLatestMonitoringPipelineMetadataResponseOutput) RunTime() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelDeploymentMonitoringJobLatestMonitoringPipelineMetadataResponse) string {
		return v.RunTime
	}).(pulumi.StringOutput)
}

// The status of the most recent monitoring pipeline.
func (o GoogleCloudAiplatformV1ModelDeploymentMonitoringJobLatestMonitoringPipelineMetadataResponseOutput) Status() GoogleRpcStatusResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelDeploymentMonitoringJobLatestMonitoringPipelineMetadataResponse) GoogleRpcStatusResponse {
		return v.Status
	}).(GoogleRpcStatusResponseOutput)
}

// ModelDeploymentMonitoringObjectiveConfig contains the pair of deployed_model_id to ModelMonitoringObjectiveConfig.
type GoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfig struct {
	// The DeployedModel ID of the objective config.
	DeployedModelId *string `pulumi:"deployedModelId"`
	// The objective config of for the modelmonitoring job of this deployed model.
	ObjectiveConfig *GoogleCloudAiplatformV1ModelMonitoringObjectiveConfig `pulumi:"objectiveConfig"`
}

// GoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigInput is an input type that accepts GoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigArgs and GoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigInput` via:
//
//	GoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigArgs{...}
type GoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigOutput() GoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigOutput
	ToGoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigOutputWithContext(context.Context) GoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigOutput
}

// ModelDeploymentMonitoringObjectiveConfig contains the pair of deployed_model_id to ModelMonitoringObjectiveConfig.
type GoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigArgs struct {
	// The DeployedModel ID of the objective config.
	DeployedModelId pulumi.StringPtrInput `pulumi:"deployedModelId"`
	// The objective config of for the modelmonitoring job of this deployed model.
	ObjectiveConfig GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPtrInput `pulumi:"objectiveConfig"`
}

func (GoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfig)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigArgs) ToGoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigOutput() GoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigOutput {
	return i.ToGoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigArgs) ToGoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigOutput)
}

// GoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigArrayInput is an input type that accepts GoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigArray and GoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigArrayOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigArrayInput` via:
//
//	GoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigArray{ GoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigArgs{...} }
type GoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigArrayInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigArrayOutput() GoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigArrayOutput
	ToGoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigArrayOutputWithContext(context.Context) GoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigArrayOutput
}

type GoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigArray []GoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigInput

func (GoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfig)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigArray) ToGoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigArrayOutput() GoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigArrayOutput {
	return i.ToGoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigArrayOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigArray) ToGoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigArrayOutput)
}

// ModelDeploymentMonitoringObjectiveConfig contains the pair of deployed_model_id to ModelMonitoringObjectiveConfig.
type GoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigOutput) ToGoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigOutput() GoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigOutput) ToGoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigOutput {
	return o
}

// The DeployedModel ID of the objective config.
func (o GoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigOutput) DeployedModelId() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfig) *string {
		return v.DeployedModelId
	}).(pulumi.StringPtrOutput)
}

// The objective config of for the modelmonitoring job of this deployed model.
func (o GoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigOutput) ObjectiveConfig() GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfig) *GoogleCloudAiplatformV1ModelMonitoringObjectiveConfig {
		return v.ObjectiveConfig
	}).(GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPtrOutput)
}

type GoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigArrayOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigArrayOutput) ToGoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigArrayOutput() GoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigArrayOutput) ToGoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigArrayOutput) Index(i pulumi.IntInput) GoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfig {
		return vs[0].([]GoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfig)[vs[1].(int)]
	}).(GoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigOutput)
}

// ModelDeploymentMonitoringObjectiveConfig contains the pair of deployed_model_id to ModelMonitoringObjectiveConfig.
type GoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigResponse struct {
	// The DeployedModel ID of the objective config.
	DeployedModelId string `pulumi:"deployedModelId"`
	// The objective config of for the modelmonitoring job of this deployed model.
	ObjectiveConfig GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigResponse `pulumi:"objectiveConfig"`
}

// ModelDeploymentMonitoringObjectiveConfig contains the pair of deployed_model_id to ModelMonitoringObjectiveConfig.
type GoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigResponseOutput) ToGoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigResponseOutput() GoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigResponseOutput) ToGoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigResponseOutput {
	return o
}

// The DeployedModel ID of the objective config.
func (o GoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigResponseOutput) DeployedModelId() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigResponse) string {
		return v.DeployedModelId
	}).(pulumi.StringOutput)
}

// The objective config of for the modelmonitoring job of this deployed model.
func (o GoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigResponseOutput) ObjectiveConfig() GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigResponse) GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigResponse {
		return v.ObjectiveConfig
	}).(GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigResponseOutput)
}

type GoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigResponseArrayOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigResponseArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigResponseArrayOutput) ToGoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigResponseArrayOutput() GoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigResponseArrayOutput) ToGoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigResponseArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigResponseArrayOutput) Index(i pulumi.IntInput) GoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigResponseOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigResponse {
		return vs[0].([]GoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigResponse)[vs[1].(int)]
	}).(GoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigResponseOutput)
}

// The config for scheduling monitoring job.
type GoogleCloudAiplatformV1ModelDeploymentMonitoringScheduleConfig struct {
	// The model monitoring job scheduling interval. It will be rounded up to next full hour. This defines how often the monitoring jobs are triggered.
	MonitorInterval string `pulumi:"monitorInterval"`
	// The time window of the prediction data being included in each prediction dataset. This window specifies how long the data should be collected from historical model results for each run. If not set, ModelDeploymentMonitoringScheduleConfig.monitor_interval will be used. e.g. If currently the cutoff time is 2022-01-08 14:30:00 and the monitor_window is set to be 3600, then data from 2022-01-08 13:30:00 to 2022-01-08 14:30:00 will be retrieved and aggregated to calculate the monitoring statistics.
	MonitorWindow *string `pulumi:"monitorWindow"`
}

// GoogleCloudAiplatformV1ModelDeploymentMonitoringScheduleConfigInput is an input type that accepts GoogleCloudAiplatformV1ModelDeploymentMonitoringScheduleConfigArgs and GoogleCloudAiplatformV1ModelDeploymentMonitoringScheduleConfigOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1ModelDeploymentMonitoringScheduleConfigInput` via:
//
//	GoogleCloudAiplatformV1ModelDeploymentMonitoringScheduleConfigArgs{...}
type GoogleCloudAiplatformV1ModelDeploymentMonitoringScheduleConfigInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1ModelDeploymentMonitoringScheduleConfigOutput() GoogleCloudAiplatformV1ModelDeploymentMonitoringScheduleConfigOutput
	ToGoogleCloudAiplatformV1ModelDeploymentMonitoringScheduleConfigOutputWithContext(context.Context) GoogleCloudAiplatformV1ModelDeploymentMonitoringScheduleConfigOutput
}

// The config for scheduling monitoring job.
type GoogleCloudAiplatformV1ModelDeploymentMonitoringScheduleConfigArgs struct {
	// The model monitoring job scheduling interval. It will be rounded up to next full hour. This defines how often the monitoring jobs are triggered.
	MonitorInterval pulumi.StringInput `pulumi:"monitorInterval"`
	// The time window of the prediction data being included in each prediction dataset. This window specifies how long the data should be collected from historical model results for each run. If not set, ModelDeploymentMonitoringScheduleConfig.monitor_interval will be used. e.g. If currently the cutoff time is 2022-01-08 14:30:00 and the monitor_window is set to be 3600, then data from 2022-01-08 13:30:00 to 2022-01-08 14:30:00 will be retrieved and aggregated to calculate the monitoring statistics.
	MonitorWindow pulumi.StringPtrInput `pulumi:"monitorWindow"`
}

func (GoogleCloudAiplatformV1ModelDeploymentMonitoringScheduleConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1ModelDeploymentMonitoringScheduleConfig)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1ModelDeploymentMonitoringScheduleConfigArgs) ToGoogleCloudAiplatformV1ModelDeploymentMonitoringScheduleConfigOutput() GoogleCloudAiplatformV1ModelDeploymentMonitoringScheduleConfigOutput {
	return i.ToGoogleCloudAiplatformV1ModelDeploymentMonitoringScheduleConfigOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1ModelDeploymentMonitoringScheduleConfigArgs) ToGoogleCloudAiplatformV1ModelDeploymentMonitoringScheduleConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ModelDeploymentMonitoringScheduleConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1ModelDeploymentMonitoringScheduleConfigOutput)
}

// The config for scheduling monitoring job.
type GoogleCloudAiplatformV1ModelDeploymentMonitoringScheduleConfigOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ModelDeploymentMonitoringScheduleConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1ModelDeploymentMonitoringScheduleConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ModelDeploymentMonitoringScheduleConfigOutput) ToGoogleCloudAiplatformV1ModelDeploymentMonitoringScheduleConfigOutput() GoogleCloudAiplatformV1ModelDeploymentMonitoringScheduleConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1ModelDeploymentMonitoringScheduleConfigOutput) ToGoogleCloudAiplatformV1ModelDeploymentMonitoringScheduleConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ModelDeploymentMonitoringScheduleConfigOutput {
	return o
}

// The model monitoring job scheduling interval. It will be rounded up to next full hour. This defines how often the monitoring jobs are triggered.
func (o GoogleCloudAiplatformV1ModelDeploymentMonitoringScheduleConfigOutput) MonitorInterval() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelDeploymentMonitoringScheduleConfig) string {
		return v.MonitorInterval
	}).(pulumi.StringOutput)
}

// The time window of the prediction data being included in each prediction dataset. This window specifies how long the data should be collected from historical model results for each run. If not set, ModelDeploymentMonitoringScheduleConfig.monitor_interval will be used. e.g. If currently the cutoff time is 2022-01-08 14:30:00 and the monitor_window is set to be 3600, then data from 2022-01-08 13:30:00 to 2022-01-08 14:30:00 will be retrieved and aggregated to calculate the monitoring statistics.
func (o GoogleCloudAiplatformV1ModelDeploymentMonitoringScheduleConfigOutput) MonitorWindow() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelDeploymentMonitoringScheduleConfig) *string { return v.MonitorWindow }).(pulumi.StringPtrOutput)
}

// The config for scheduling monitoring job.
type GoogleCloudAiplatformV1ModelDeploymentMonitoringScheduleConfigResponse struct {
	// The model monitoring job scheduling interval. It will be rounded up to next full hour. This defines how often the monitoring jobs are triggered.
	MonitorInterval string `pulumi:"monitorInterval"`
	// The time window of the prediction data being included in each prediction dataset. This window specifies how long the data should be collected from historical model results for each run. If not set, ModelDeploymentMonitoringScheduleConfig.monitor_interval will be used. e.g. If currently the cutoff time is 2022-01-08 14:30:00 and the monitor_window is set to be 3600, then data from 2022-01-08 13:30:00 to 2022-01-08 14:30:00 will be retrieved and aggregated to calculate the monitoring statistics.
	MonitorWindow string `pulumi:"monitorWindow"`
}

// The config for scheduling monitoring job.
type GoogleCloudAiplatformV1ModelDeploymentMonitoringScheduleConfigResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ModelDeploymentMonitoringScheduleConfigResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1ModelDeploymentMonitoringScheduleConfigResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ModelDeploymentMonitoringScheduleConfigResponseOutput) ToGoogleCloudAiplatformV1ModelDeploymentMonitoringScheduleConfigResponseOutput() GoogleCloudAiplatformV1ModelDeploymentMonitoringScheduleConfigResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1ModelDeploymentMonitoringScheduleConfigResponseOutput) ToGoogleCloudAiplatformV1ModelDeploymentMonitoringScheduleConfigResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ModelDeploymentMonitoringScheduleConfigResponseOutput {
	return o
}

// The model monitoring job scheduling interval. It will be rounded up to next full hour. This defines how often the monitoring jobs are triggered.
func (o GoogleCloudAiplatformV1ModelDeploymentMonitoringScheduleConfigResponseOutput) MonitorInterval() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelDeploymentMonitoringScheduleConfigResponse) string {
		return v.MonitorInterval
	}).(pulumi.StringOutput)
}

// The time window of the prediction data being included in each prediction dataset. This window specifies how long the data should be collected from historical model results for each run. If not set, ModelDeploymentMonitoringScheduleConfig.monitor_interval will be used. e.g. If currently the cutoff time is 2022-01-08 14:30:00 and the monitor_window is set to be 3600, then data from 2022-01-08 13:30:00 to 2022-01-08 14:30:00 will be retrieved and aggregated to calculate the monitoring statistics.
func (o GoogleCloudAiplatformV1ModelDeploymentMonitoringScheduleConfigResponseOutput) MonitorWindow() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelDeploymentMonitoringScheduleConfigResponse) string {
		return v.MonitorWindow
	}).(pulumi.StringOutput)
}

// Represents export format supported by the Model. All formats export to Google Cloud Storage.
type GoogleCloudAiplatformV1ModelExportFormatResponse struct {
	// The content of this Model that may be exported.
	ExportableContents []string `pulumi:"exportableContents"`
}

// Represents export format supported by the Model. All formats export to Google Cloud Storage.
type GoogleCloudAiplatformV1ModelExportFormatResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ModelExportFormatResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1ModelExportFormatResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ModelExportFormatResponseOutput) ToGoogleCloudAiplatformV1ModelExportFormatResponseOutput() GoogleCloudAiplatformV1ModelExportFormatResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1ModelExportFormatResponseOutput) ToGoogleCloudAiplatformV1ModelExportFormatResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ModelExportFormatResponseOutput {
	return o
}

// The content of this Model that may be exported.
func (o GoogleCloudAiplatformV1ModelExportFormatResponseOutput) ExportableContents() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelExportFormatResponse) []string { return v.ExportableContents }).(pulumi.StringArrayOutput)
}

type GoogleCloudAiplatformV1ModelExportFormatResponseArrayOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ModelExportFormatResponseArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1ModelExportFormatResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ModelExportFormatResponseArrayOutput) ToGoogleCloudAiplatformV1ModelExportFormatResponseArrayOutput() GoogleCloudAiplatformV1ModelExportFormatResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1ModelExportFormatResponseArrayOutput) ToGoogleCloudAiplatformV1ModelExportFormatResponseArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ModelExportFormatResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1ModelExportFormatResponseArrayOutput) Index(i pulumi.IntInput) GoogleCloudAiplatformV1ModelExportFormatResponseOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GoogleCloudAiplatformV1ModelExportFormatResponse {
		return vs[0].([]GoogleCloudAiplatformV1ModelExportFormatResponse)[vs[1].(int)]
	}).(GoogleCloudAiplatformV1ModelExportFormatResponseOutput)
}

type GoogleCloudAiplatformV1ModelMonitoringAlertConfig struct {
	// Email alert config.
	EmailAlertConfig *GoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfig `pulumi:"emailAlertConfig"`
	// Dump the anomalies to Cloud Logging. The anomalies will be put to json payload encoded from proto google.cloud.aiplatform.logging.ModelMonitoringAnomaliesLogEntry. This can be further sinked to Pub/Sub or any other services supported by Cloud Logging.
	EnableLogging *bool `pulumi:"enableLogging"`
	// Resource names of the NotificationChannels to send alert. Must be of the format `projects//notificationChannels/`
	NotificationChannels []string `pulumi:"notificationChannels"`
}

// GoogleCloudAiplatformV1ModelMonitoringAlertConfigInput is an input type that accepts GoogleCloudAiplatformV1ModelMonitoringAlertConfigArgs and GoogleCloudAiplatformV1ModelMonitoringAlertConfigOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1ModelMonitoringAlertConfigInput` via:
//
//	GoogleCloudAiplatformV1ModelMonitoringAlertConfigArgs{...}
type GoogleCloudAiplatformV1ModelMonitoringAlertConfigInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1ModelMonitoringAlertConfigOutput() GoogleCloudAiplatformV1ModelMonitoringAlertConfigOutput
	ToGoogleCloudAiplatformV1ModelMonitoringAlertConfigOutputWithContext(context.Context) GoogleCloudAiplatformV1ModelMonitoringAlertConfigOutput
}

type GoogleCloudAiplatformV1ModelMonitoringAlertConfigArgs struct {
	// Email alert config.
	EmailAlertConfig GoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigPtrInput `pulumi:"emailAlertConfig"`
	// Dump the anomalies to Cloud Logging. The anomalies will be put to json payload encoded from proto google.cloud.aiplatform.logging.ModelMonitoringAnomaliesLogEntry. This can be further sinked to Pub/Sub or any other services supported by Cloud Logging.
	EnableLogging pulumi.BoolPtrInput `pulumi:"enableLogging"`
	// Resource names of the NotificationChannels to send alert. Must be of the format `projects//notificationChannels/`
	NotificationChannels pulumi.StringArrayInput `pulumi:"notificationChannels"`
}

func (GoogleCloudAiplatformV1ModelMonitoringAlertConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1ModelMonitoringAlertConfig)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1ModelMonitoringAlertConfigArgs) ToGoogleCloudAiplatformV1ModelMonitoringAlertConfigOutput() GoogleCloudAiplatformV1ModelMonitoringAlertConfigOutput {
	return i.ToGoogleCloudAiplatformV1ModelMonitoringAlertConfigOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1ModelMonitoringAlertConfigArgs) ToGoogleCloudAiplatformV1ModelMonitoringAlertConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ModelMonitoringAlertConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1ModelMonitoringAlertConfigOutput)
}

func (i GoogleCloudAiplatformV1ModelMonitoringAlertConfigArgs) ToGoogleCloudAiplatformV1ModelMonitoringAlertConfigPtrOutput() GoogleCloudAiplatformV1ModelMonitoringAlertConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1ModelMonitoringAlertConfigPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1ModelMonitoringAlertConfigArgs) ToGoogleCloudAiplatformV1ModelMonitoringAlertConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ModelMonitoringAlertConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1ModelMonitoringAlertConfigOutput).ToGoogleCloudAiplatformV1ModelMonitoringAlertConfigPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1ModelMonitoringAlertConfigPtrInput is an input type that accepts GoogleCloudAiplatformV1ModelMonitoringAlertConfigArgs, GoogleCloudAiplatformV1ModelMonitoringAlertConfigPtr and GoogleCloudAiplatformV1ModelMonitoringAlertConfigPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1ModelMonitoringAlertConfigPtrInput` via:
//
//	        GoogleCloudAiplatformV1ModelMonitoringAlertConfigArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1ModelMonitoringAlertConfigPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1ModelMonitoringAlertConfigPtrOutput() GoogleCloudAiplatformV1ModelMonitoringAlertConfigPtrOutput
	ToGoogleCloudAiplatformV1ModelMonitoringAlertConfigPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1ModelMonitoringAlertConfigPtrOutput
}

type googleCloudAiplatformV1ModelMonitoringAlertConfigPtrType GoogleCloudAiplatformV1ModelMonitoringAlertConfigArgs

func GoogleCloudAiplatformV1ModelMonitoringAlertConfigPtr(v *GoogleCloudAiplatformV1ModelMonitoringAlertConfigArgs) GoogleCloudAiplatformV1ModelMonitoringAlertConfigPtrInput {
	return (*googleCloudAiplatformV1ModelMonitoringAlertConfigPtrType)(v)
}

func (*googleCloudAiplatformV1ModelMonitoringAlertConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1ModelMonitoringAlertConfig)(nil)).Elem()
}

func (i *googleCloudAiplatformV1ModelMonitoringAlertConfigPtrType) ToGoogleCloudAiplatformV1ModelMonitoringAlertConfigPtrOutput() GoogleCloudAiplatformV1ModelMonitoringAlertConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1ModelMonitoringAlertConfigPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1ModelMonitoringAlertConfigPtrType) ToGoogleCloudAiplatformV1ModelMonitoringAlertConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ModelMonitoringAlertConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1ModelMonitoringAlertConfigPtrOutput)
}

type GoogleCloudAiplatformV1ModelMonitoringAlertConfigOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ModelMonitoringAlertConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1ModelMonitoringAlertConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ModelMonitoringAlertConfigOutput) ToGoogleCloudAiplatformV1ModelMonitoringAlertConfigOutput() GoogleCloudAiplatformV1ModelMonitoringAlertConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1ModelMonitoringAlertConfigOutput) ToGoogleCloudAiplatformV1ModelMonitoringAlertConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ModelMonitoringAlertConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1ModelMonitoringAlertConfigOutput) ToGoogleCloudAiplatformV1ModelMonitoringAlertConfigPtrOutput() GoogleCloudAiplatformV1ModelMonitoringAlertConfigPtrOutput {
	return o.ToGoogleCloudAiplatformV1ModelMonitoringAlertConfigPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1ModelMonitoringAlertConfigOutput) ToGoogleCloudAiplatformV1ModelMonitoringAlertConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ModelMonitoringAlertConfigPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1ModelMonitoringAlertConfig) *GoogleCloudAiplatformV1ModelMonitoringAlertConfig {
		return &v
	}).(GoogleCloudAiplatformV1ModelMonitoringAlertConfigPtrOutput)
}

// Email alert config.
func (o GoogleCloudAiplatformV1ModelMonitoringAlertConfigOutput) EmailAlertConfig() GoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelMonitoringAlertConfig) *GoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfig {
		return v.EmailAlertConfig
	}).(GoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigPtrOutput)
}

// Dump the anomalies to Cloud Logging. The anomalies will be put to json payload encoded from proto google.cloud.aiplatform.logging.ModelMonitoringAnomaliesLogEntry. This can be further sinked to Pub/Sub or any other services supported by Cloud Logging.
func (o GoogleCloudAiplatformV1ModelMonitoringAlertConfigOutput) EnableLogging() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelMonitoringAlertConfig) *bool { return v.EnableLogging }).(pulumi.BoolPtrOutput)
}

// Resource names of the NotificationChannels to send alert. Must be of the format `projects//notificationChannels/`
func (o GoogleCloudAiplatformV1ModelMonitoringAlertConfigOutput) NotificationChannels() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelMonitoringAlertConfig) []string { return v.NotificationChannels }).(pulumi.StringArrayOutput)
}

type GoogleCloudAiplatformV1ModelMonitoringAlertConfigPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ModelMonitoringAlertConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1ModelMonitoringAlertConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ModelMonitoringAlertConfigPtrOutput) ToGoogleCloudAiplatformV1ModelMonitoringAlertConfigPtrOutput() GoogleCloudAiplatformV1ModelMonitoringAlertConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1ModelMonitoringAlertConfigPtrOutput) ToGoogleCloudAiplatformV1ModelMonitoringAlertConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ModelMonitoringAlertConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1ModelMonitoringAlertConfigPtrOutput) Elem() GoogleCloudAiplatformV1ModelMonitoringAlertConfigOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1ModelMonitoringAlertConfig) GoogleCloudAiplatformV1ModelMonitoringAlertConfig {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1ModelMonitoringAlertConfig
		return ret
	}).(GoogleCloudAiplatformV1ModelMonitoringAlertConfigOutput)
}

// Email alert config.
func (o GoogleCloudAiplatformV1ModelMonitoringAlertConfigPtrOutput) EmailAlertConfig() GoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1ModelMonitoringAlertConfig) *GoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfig {
		if v == nil {
			return nil
		}
		return v.EmailAlertConfig
	}).(GoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigPtrOutput)
}

// Dump the anomalies to Cloud Logging. The anomalies will be put to json payload encoded from proto google.cloud.aiplatform.logging.ModelMonitoringAnomaliesLogEntry. This can be further sinked to Pub/Sub or any other services supported by Cloud Logging.
func (o GoogleCloudAiplatformV1ModelMonitoringAlertConfigPtrOutput) EnableLogging() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1ModelMonitoringAlertConfig) *bool {
		if v == nil {
			return nil
		}
		return v.EnableLogging
	}).(pulumi.BoolPtrOutput)
}

// Resource names of the NotificationChannels to send alert. Must be of the format `projects//notificationChannels/`
func (o GoogleCloudAiplatformV1ModelMonitoringAlertConfigPtrOutput) NotificationChannels() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1ModelMonitoringAlertConfig) []string {
		if v == nil {
			return nil
		}
		return v.NotificationChannels
	}).(pulumi.StringArrayOutput)
}

// The config for email alert.
type GoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfig struct {
	// The email addresses to send the alert.
	UserEmails []string `pulumi:"userEmails"`
}

// GoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigInput is an input type that accepts GoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigArgs and GoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigInput` via:
//
//	GoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigArgs{...}
type GoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigOutput() GoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigOutput
	ToGoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigOutputWithContext(context.Context) GoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigOutput
}

// The config for email alert.
type GoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigArgs struct {
	// The email addresses to send the alert.
	UserEmails pulumi.StringArrayInput `pulumi:"userEmails"`
}

func (GoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfig)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigArgs) ToGoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigOutput() GoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigOutput {
	return i.ToGoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigArgs) ToGoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigOutput)
}

func (i GoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigArgs) ToGoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigPtrOutput() GoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigArgs) ToGoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigOutput).ToGoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigPtrInput is an input type that accepts GoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigArgs, GoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigPtr and GoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigPtrInput` via:
//
//	        GoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigPtrOutput() GoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigPtrOutput
	ToGoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigPtrOutput
}

type googleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigPtrType GoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigArgs

func GoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigPtr(v *GoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigArgs) GoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigPtrInput {
	return (*googleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigPtrType)(v)
}

func (*googleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfig)(nil)).Elem()
}

func (i *googleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigPtrType) ToGoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigPtrOutput() GoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigPtrType) ToGoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigPtrOutput)
}

// The config for email alert.
type GoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigOutput) ToGoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigOutput() GoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigOutput) ToGoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigOutput) ToGoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigPtrOutput() GoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigPtrOutput {
	return o.ToGoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigOutput) ToGoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfig) *GoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfig {
		return &v
	}).(GoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigPtrOutput)
}

// The email addresses to send the alert.
func (o GoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigOutput) UserEmails() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfig) []string {
		return v.UserEmails
	}).(pulumi.StringArrayOutput)
}

type GoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigPtrOutput) ToGoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigPtrOutput() GoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigPtrOutput) ToGoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigPtrOutput) Elem() GoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfig) GoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfig {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfig
		return ret
	}).(GoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigOutput)
}

// The email addresses to send the alert.
func (o GoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigPtrOutput) UserEmails() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfig) []string {
		if v == nil {
			return nil
		}
		return v.UserEmails
	}).(pulumi.StringArrayOutput)
}

// The config for email alert.
type GoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigResponse struct {
	// The email addresses to send the alert.
	UserEmails []string `pulumi:"userEmails"`
}

// The config for email alert.
type GoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigResponseOutput) ToGoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigResponseOutput() GoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigResponseOutput) ToGoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigResponseOutput {
	return o
}

// The email addresses to send the alert.
func (o GoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigResponseOutput) UserEmails() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigResponse) []string {
		return v.UserEmails
	}).(pulumi.StringArrayOutput)
}

type GoogleCloudAiplatformV1ModelMonitoringAlertConfigResponse struct {
	// Email alert config.
	EmailAlertConfig GoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigResponse `pulumi:"emailAlertConfig"`
	// Dump the anomalies to Cloud Logging. The anomalies will be put to json payload encoded from proto google.cloud.aiplatform.logging.ModelMonitoringAnomaliesLogEntry. This can be further sinked to Pub/Sub or any other services supported by Cloud Logging.
	EnableLogging bool `pulumi:"enableLogging"`
	// Resource names of the NotificationChannels to send alert. Must be of the format `projects//notificationChannels/`
	NotificationChannels []string `pulumi:"notificationChannels"`
}

type GoogleCloudAiplatformV1ModelMonitoringAlertConfigResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ModelMonitoringAlertConfigResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1ModelMonitoringAlertConfigResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ModelMonitoringAlertConfigResponseOutput) ToGoogleCloudAiplatformV1ModelMonitoringAlertConfigResponseOutput() GoogleCloudAiplatformV1ModelMonitoringAlertConfigResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1ModelMonitoringAlertConfigResponseOutput) ToGoogleCloudAiplatformV1ModelMonitoringAlertConfigResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ModelMonitoringAlertConfigResponseOutput {
	return o
}

// Email alert config.
func (o GoogleCloudAiplatformV1ModelMonitoringAlertConfigResponseOutput) EmailAlertConfig() GoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelMonitoringAlertConfigResponse) GoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigResponse {
		return v.EmailAlertConfig
	}).(GoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigResponseOutput)
}

// Dump the anomalies to Cloud Logging. The anomalies will be put to json payload encoded from proto google.cloud.aiplatform.logging.ModelMonitoringAnomaliesLogEntry. This can be further sinked to Pub/Sub or any other services supported by Cloud Logging.
func (o GoogleCloudAiplatformV1ModelMonitoringAlertConfigResponseOutput) EnableLogging() pulumi.BoolOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelMonitoringAlertConfigResponse) bool { return v.EnableLogging }).(pulumi.BoolOutput)
}

// Resource names of the NotificationChannels to send alert. Must be of the format `projects//notificationChannels/`
func (o GoogleCloudAiplatformV1ModelMonitoringAlertConfigResponseOutput) NotificationChannels() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelMonitoringAlertConfigResponse) []string {
		return v.NotificationChannels
	}).(pulumi.StringArrayOutput)
}

// The objective configuration for model monitoring, including the information needed to detect anomalies for one particular model.
type GoogleCloudAiplatformV1ModelMonitoringObjectiveConfig struct {
	// The config for integrating with Vertex Explainable AI.
	ExplanationConfig *GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfig `pulumi:"explanationConfig"`
	// The config for drift of prediction data.
	PredictionDriftDetectionConfig *GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfig `pulumi:"predictionDriftDetectionConfig"`
	// Training dataset for models. This field has to be set only if TrainingPredictionSkewDetectionConfig is specified.
	TrainingDataset *GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDataset `pulumi:"trainingDataset"`
	// The config for skew between training data and prediction data.
	TrainingPredictionSkewDetectionConfig *GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfig `pulumi:"trainingPredictionSkewDetectionConfig"`
}

// GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigInput is an input type that accepts GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigArgs and GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigInput` via:
//
//	GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigArgs{...}
type GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigOutput() GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigOutput
	ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigOutputWithContext(context.Context) GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigOutput
}

// The objective configuration for model monitoring, including the information needed to detect anomalies for one particular model.
type GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigArgs struct {
	// The config for integrating with Vertex Explainable AI.
	ExplanationConfig GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigPtrInput `pulumi:"explanationConfig"`
	// The config for drift of prediction data.
	PredictionDriftDetectionConfig GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrInput `pulumi:"predictionDriftDetectionConfig"`
	// Training dataset for models. This field has to be set only if TrainingPredictionSkewDetectionConfig is specified.
	TrainingDataset GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetPtrInput `pulumi:"trainingDataset"`
	// The config for skew between training data and prediction data.
	TrainingPredictionSkewDetectionConfig GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrInput `pulumi:"trainingPredictionSkewDetectionConfig"`
}

func (GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1ModelMonitoringObjectiveConfig)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigArgs) ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigOutput() GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigOutput {
	return i.ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigArgs) ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigOutput)
}

func (i GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigArgs) ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPtrOutput() GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigArgs) ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigOutput).ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPtrInput is an input type that accepts GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigArgs, GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPtr and GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPtrInput` via:
//
//	        GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPtrOutput() GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPtrOutput
	ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPtrOutput
}

type googleCloudAiplatformV1ModelMonitoringObjectiveConfigPtrType GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigArgs

func GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPtr(v *GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigArgs) GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPtrInput {
	return (*googleCloudAiplatformV1ModelMonitoringObjectiveConfigPtrType)(v)
}

func (*googleCloudAiplatformV1ModelMonitoringObjectiveConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1ModelMonitoringObjectiveConfig)(nil)).Elem()
}

func (i *googleCloudAiplatformV1ModelMonitoringObjectiveConfigPtrType) ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPtrOutput() GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1ModelMonitoringObjectiveConfigPtrType) ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPtrOutput)
}

// The objective configuration for model monitoring, including the information needed to detect anomalies for one particular model.
type GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1ModelMonitoringObjectiveConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigOutput) ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigOutput() GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigOutput) ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigOutput) ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPtrOutput() GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPtrOutput {
	return o.ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigOutput) ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1ModelMonitoringObjectiveConfig) *GoogleCloudAiplatformV1ModelMonitoringObjectiveConfig {
		return &v
	}).(GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPtrOutput)
}

// The config for integrating with Vertex Explainable AI.
func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigOutput) ExplanationConfig() GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelMonitoringObjectiveConfig) *GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfig {
		return v.ExplanationConfig
	}).(GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigPtrOutput)
}

// The config for drift of prediction data.
func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigOutput) PredictionDriftDetectionConfig() GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelMonitoringObjectiveConfig) *GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfig {
		return v.PredictionDriftDetectionConfig
	}).(GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrOutput)
}

// Training dataset for models. This field has to be set only if TrainingPredictionSkewDetectionConfig is specified.
func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigOutput) TrainingDataset() GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelMonitoringObjectiveConfig) *GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDataset {
		return v.TrainingDataset
	}).(GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetPtrOutput)
}

// The config for skew between training data and prediction data.
func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigOutput) TrainingPredictionSkewDetectionConfig() GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelMonitoringObjectiveConfig) *GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfig {
		return v.TrainingPredictionSkewDetectionConfig
	}).(GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrOutput)
}

type GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1ModelMonitoringObjectiveConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPtrOutput) ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPtrOutput() GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPtrOutput) ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPtrOutput) Elem() GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1ModelMonitoringObjectiveConfig) GoogleCloudAiplatformV1ModelMonitoringObjectiveConfig {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1ModelMonitoringObjectiveConfig
		return ret
	}).(GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigOutput)
}

// The config for integrating with Vertex Explainable AI.
func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPtrOutput) ExplanationConfig() GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1ModelMonitoringObjectiveConfig) *GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfig {
		if v == nil {
			return nil
		}
		return v.ExplanationConfig
	}).(GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigPtrOutput)
}

// The config for drift of prediction data.
func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPtrOutput) PredictionDriftDetectionConfig() GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1ModelMonitoringObjectiveConfig) *GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfig {
		if v == nil {
			return nil
		}
		return v.PredictionDriftDetectionConfig
	}).(GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrOutput)
}

// Training dataset for models. This field has to be set only if TrainingPredictionSkewDetectionConfig is specified.
func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPtrOutput) TrainingDataset() GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1ModelMonitoringObjectiveConfig) *GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDataset {
		if v == nil {
			return nil
		}
		return v.TrainingDataset
	}).(GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetPtrOutput)
}

// The config for skew between training data and prediction data.
func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPtrOutput) TrainingPredictionSkewDetectionConfig() GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1ModelMonitoringObjectiveConfig) *GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfig {
		if v == nil {
			return nil
		}
		return v.TrainingPredictionSkewDetectionConfig
	}).(GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrOutput)
}

// The config for integrating with Vertex Explainable AI. Only applicable if the Model has explanation_spec populated.
type GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfig struct {
	// If want to analyze the Vertex Explainable AI feature attribute scores or not. If set to true, Vertex AI will log the feature attributions from explain response and do the skew/drift detection for them.
	EnableFeatureAttributes *bool `pulumi:"enableFeatureAttributes"`
	// Predictions generated by the BatchPredictionJob using baseline dataset.
	ExplanationBaseline *GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaseline `pulumi:"explanationBaseline"`
}

// GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigInput is an input type that accepts GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigArgs and GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigInput` via:
//
//	GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigArgs{...}
type GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigOutput() GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigOutput
	ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigOutputWithContext(context.Context) GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigOutput
}

// The config for integrating with Vertex Explainable AI. Only applicable if the Model has explanation_spec populated.
type GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigArgs struct {
	// If want to analyze the Vertex Explainable AI feature attribute scores or not. If set to true, Vertex AI will log the feature attributions from explain response and do the skew/drift detection for them.
	EnableFeatureAttributes pulumi.BoolPtrInput `pulumi:"enableFeatureAttributes"`
	// Predictions generated by the BatchPredictionJob using baseline dataset.
	ExplanationBaseline GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrInput `pulumi:"explanationBaseline"`
}

func (GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfig)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigArgs) ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigOutput() GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigOutput {
	return i.ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigArgs) ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigOutput)
}

func (i GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigArgs) ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigPtrOutput() GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigArgs) ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigOutput).ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigPtrInput is an input type that accepts GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigArgs, GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigPtr and GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigPtrInput` via:
//
//	        GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigPtrOutput() GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigPtrOutput
	ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigPtrOutput
}

type googleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigPtrType GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigArgs

func GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigPtr(v *GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigArgs) GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigPtrInput {
	return (*googleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigPtrType)(v)
}

func (*googleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfig)(nil)).Elem()
}

func (i *googleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigPtrType) ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigPtrOutput() GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigPtrType) ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigPtrOutput)
}

// The config for integrating with Vertex Explainable AI. Only applicable if the Model has explanation_spec populated.
type GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigOutput) ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigOutput() GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigOutput) ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigOutput) ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigPtrOutput() GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigPtrOutput {
	return o.ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigOutput) ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfig) *GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfig {
		return &v
	}).(GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigPtrOutput)
}

// If want to analyze the Vertex Explainable AI feature attribute scores or not. If set to true, Vertex AI will log the feature attributions from explain response and do the skew/drift detection for them.
func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigOutput) EnableFeatureAttributes() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfig) *bool {
		return v.EnableFeatureAttributes
	}).(pulumi.BoolPtrOutput)
}

// Predictions generated by the BatchPredictionJob using baseline dataset.
func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigOutput) ExplanationBaseline() GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfig) *GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaseline {
		return v.ExplanationBaseline
	}).(GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrOutput)
}

type GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigPtrOutput) ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigPtrOutput() GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigPtrOutput) ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigPtrOutput) Elem() GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfig) GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfig {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfig
		return ret
	}).(GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigOutput)
}

// If want to analyze the Vertex Explainable AI feature attribute scores or not. If set to true, Vertex AI will log the feature attributions from explain response and do the skew/drift detection for them.
func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigPtrOutput) EnableFeatureAttributes() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfig) *bool {
		if v == nil {
			return nil
		}
		return v.EnableFeatureAttributes
	}).(pulumi.BoolPtrOutput)
}

// Predictions generated by the BatchPredictionJob using baseline dataset.
func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigPtrOutput) ExplanationBaseline() GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfig) *GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaseline {
		if v == nil {
			return nil
		}
		return v.ExplanationBaseline
	}).(GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrOutput)
}

// Output from BatchPredictionJob for Model Monitoring baseline dataset, which can be used to generate baseline attribution scores.
type GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaseline struct {
	// BigQuery location for BatchExplain output.
	Bigquery *GoogleCloudAiplatformV1BigQueryDestination `pulumi:"bigquery"`
	// Cloud Storage location for BatchExplain output.
	Gcs *GoogleCloudAiplatformV1GcsDestination `pulumi:"gcs"`
	// The storage format of the predictions generated BatchPrediction job.
	PredictionFormat *GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePredictionFormat `pulumi:"predictionFormat"`
}

// GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineInput is an input type that accepts GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineArgs and GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineInput` via:
//
//	GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineArgs{...}
type GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineOutput() GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineOutput
	ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineOutputWithContext(context.Context) GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineOutput
}

// Output from BatchPredictionJob for Model Monitoring baseline dataset, which can be used to generate baseline attribution scores.
type GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineArgs struct {
	// BigQuery location for BatchExplain output.
	Bigquery GoogleCloudAiplatformV1BigQueryDestinationPtrInput `pulumi:"bigquery"`
	// Cloud Storage location for BatchExplain output.
	Gcs GoogleCloudAiplatformV1GcsDestinationPtrInput `pulumi:"gcs"`
	// The storage format of the predictions generated BatchPrediction job.
	PredictionFormat GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePredictionFormatPtrInput `pulumi:"predictionFormat"`
}

func (GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaseline)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineArgs) ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineOutput() GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineOutput {
	return i.ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineArgs) ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineOutput)
}

func (i GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineArgs) ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrOutput() GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrOutput {
	return i.ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineArgs) ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineOutput).ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrInput is an input type that accepts GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineArgs, GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtr and GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrInput` via:
//
//	        GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrOutput() GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrOutput
	ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrOutputWithContext(context.Context) GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrOutput
}

type googleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrType GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineArgs

func GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtr(v *GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineArgs) GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrInput {
	return (*googleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrType)(v)
}

func (*googleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaseline)(nil)).Elem()
}

func (i *googleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrType) ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrOutput() GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrOutput {
	return i.ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrType) ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrOutput)
}

// Output from BatchPredictionJob for Model Monitoring baseline dataset, which can be used to generate baseline attribution scores.
type GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaseline)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineOutput) ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineOutput() GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineOutput {
	return o
}

func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineOutput) ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineOutput {
	return o
}

func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineOutput) ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrOutput() GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrOutput {
	return o.ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineOutput) ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaseline) *GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaseline {
		return &v
	}).(GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrOutput)
}

// BigQuery location for BatchExplain output.
func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineOutput) Bigquery() GoogleCloudAiplatformV1BigQueryDestinationPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaseline) *GoogleCloudAiplatformV1BigQueryDestination {
		return v.Bigquery
	}).(GoogleCloudAiplatformV1BigQueryDestinationPtrOutput)
}

// Cloud Storage location for BatchExplain output.
func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineOutput) Gcs() GoogleCloudAiplatformV1GcsDestinationPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaseline) *GoogleCloudAiplatformV1GcsDestination {
		return v.Gcs
	}).(GoogleCloudAiplatformV1GcsDestinationPtrOutput)
}

// The storage format of the predictions generated BatchPrediction job.
func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineOutput) PredictionFormat() GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePredictionFormatPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaseline) *GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePredictionFormat {
		return v.PredictionFormat
	}).(GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePredictionFormatPtrOutput)
}

type GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaseline)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrOutput) ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrOutput() GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrOutput) ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrOutput) Elem() GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaseline) GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaseline {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaseline
		return ret
	}).(GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineOutput)
}

// BigQuery location for BatchExplain output.
func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrOutput) Bigquery() GoogleCloudAiplatformV1BigQueryDestinationPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaseline) *GoogleCloudAiplatformV1BigQueryDestination {
		if v == nil {
			return nil
		}
		return v.Bigquery
	}).(GoogleCloudAiplatformV1BigQueryDestinationPtrOutput)
}

// Cloud Storage location for BatchExplain output.
func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrOutput) Gcs() GoogleCloudAiplatformV1GcsDestinationPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaseline) *GoogleCloudAiplatformV1GcsDestination {
		if v == nil {
			return nil
		}
		return v.Gcs
	}).(GoogleCloudAiplatformV1GcsDestinationPtrOutput)
}

// The storage format of the predictions generated BatchPrediction job.
func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrOutput) PredictionFormat() GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePredictionFormatPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaseline) *GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePredictionFormat {
		if v == nil {
			return nil
		}
		return v.PredictionFormat
	}).(GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePredictionFormatPtrOutput)
}

// Output from BatchPredictionJob for Model Monitoring baseline dataset, which can be used to generate baseline attribution scores.
type GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineResponse struct {
	// BigQuery location for BatchExplain output.
	Bigquery GoogleCloudAiplatformV1BigQueryDestinationResponse `pulumi:"bigquery"`
	// Cloud Storage location for BatchExplain output.
	Gcs GoogleCloudAiplatformV1GcsDestinationResponse `pulumi:"gcs"`
	// The storage format of the predictions generated BatchPrediction job.
	PredictionFormat string `pulumi:"predictionFormat"`
}

// Output from BatchPredictionJob for Model Monitoring baseline dataset, which can be used to generate baseline attribution scores.
type GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineResponseOutput) ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineResponseOutput() GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineResponseOutput) ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineResponseOutput {
	return o
}

// BigQuery location for BatchExplain output.
func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineResponseOutput) Bigquery() GoogleCloudAiplatformV1BigQueryDestinationResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineResponse) GoogleCloudAiplatformV1BigQueryDestinationResponse {
		return v.Bigquery
	}).(GoogleCloudAiplatformV1BigQueryDestinationResponseOutput)
}

// Cloud Storage location for BatchExplain output.
func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineResponseOutput) Gcs() GoogleCloudAiplatformV1GcsDestinationResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineResponse) GoogleCloudAiplatformV1GcsDestinationResponse {
		return v.Gcs
	}).(GoogleCloudAiplatformV1GcsDestinationResponseOutput)
}

// The storage format of the predictions generated BatchPrediction job.
func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineResponseOutput) PredictionFormat() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineResponse) string {
		return v.PredictionFormat
	}).(pulumi.StringOutput)
}

// The config for integrating with Vertex Explainable AI. Only applicable if the Model has explanation_spec populated.
type GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigResponse struct {
	// If want to analyze the Vertex Explainable AI feature attribute scores or not. If set to true, Vertex AI will log the feature attributions from explain response and do the skew/drift detection for them.
	EnableFeatureAttributes bool `pulumi:"enableFeatureAttributes"`
	// Predictions generated by the BatchPredictionJob using baseline dataset.
	ExplanationBaseline GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineResponse `pulumi:"explanationBaseline"`
}

// The config for integrating with Vertex Explainable AI. Only applicable if the Model has explanation_spec populated.
type GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigResponseOutput) ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigResponseOutput() GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigResponseOutput) ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigResponseOutput {
	return o
}

// If want to analyze the Vertex Explainable AI feature attribute scores or not. If set to true, Vertex AI will log the feature attributions from explain response and do the skew/drift detection for them.
func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigResponseOutput) EnableFeatureAttributes() pulumi.BoolOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigResponse) bool {
		return v.EnableFeatureAttributes
	}).(pulumi.BoolOutput)
}

// Predictions generated by the BatchPredictionJob using baseline dataset.
func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigResponseOutput) ExplanationBaseline() GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigResponse) GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineResponse {
		return v.ExplanationBaseline
	}).(GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineResponseOutput)
}

// The config for Prediction data drift detection.
type GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfig struct {
	// Key is the feature name and value is the threshold. The threshold here is against attribution score distance between different time windows.
	AttributionScoreDriftThresholds map[string]GoogleCloudAiplatformV1ThresholdConfig `pulumi:"attributionScoreDriftThresholds"`
	// Drift anomaly detection threshold used by all features. When the per-feature thresholds are not set, this field can be used to specify a threshold for all features.
	DefaultDriftThreshold *GoogleCloudAiplatformV1ThresholdConfig `pulumi:"defaultDriftThreshold"`
	// Key is the feature name and value is the threshold. If a feature needs to be monitored for drift, a value threshold must be configured for that feature. The threshold here is against feature distribution distance between different time windws.
	DriftThresholds map[string]GoogleCloudAiplatformV1ThresholdConfig `pulumi:"driftThresholds"`
}

// GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigInput is an input type that accepts GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigArgs and GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigInput` via:
//
//	GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigArgs{...}
type GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigOutput() GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigOutput
	ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigOutputWithContext(context.Context) GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigOutput
}

// The config for Prediction data drift detection.
type GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigArgs struct {
	// Key is the feature name and value is the threshold. The threshold here is against attribution score distance between different time windows.
	AttributionScoreDriftThresholds GoogleCloudAiplatformV1ThresholdConfigMapInput `pulumi:"attributionScoreDriftThresholds"`
	// Drift anomaly detection threshold used by all features. When the per-feature thresholds are not set, this field can be used to specify a threshold for all features.
	DefaultDriftThreshold GoogleCloudAiplatformV1ThresholdConfigPtrInput `pulumi:"defaultDriftThreshold"`
	// Key is the feature name and value is the threshold. If a feature needs to be monitored for drift, a value threshold must be configured for that feature. The threshold here is against feature distribution distance between different time windws.
	DriftThresholds GoogleCloudAiplatformV1ThresholdConfigMapInput `pulumi:"driftThresholds"`
}

func (GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfig)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigArgs) ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigOutput() GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigOutput {
	return i.ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigArgs) ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigOutput)
}

func (i GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigArgs) ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrOutput() GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigArgs) ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigOutput).ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrInput is an input type that accepts GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigArgs, GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtr and GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrInput` via:
//
//	        GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrOutput() GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrOutput
	ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrOutput
}

type googleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrType GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigArgs

func GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtr(v *GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigArgs) GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrInput {
	return (*googleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrType)(v)
}

func (*googleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfig)(nil)).Elem()
}

func (i *googleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrType) ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrOutput() GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrType) ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrOutput)
}

// The config for Prediction data drift detection.
type GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigOutput) ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigOutput() GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigOutput) ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigOutput) ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrOutput() GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrOutput {
	return o.ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigOutput) ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfig) *GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfig {
		return &v
	}).(GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrOutput)
}

// Key is the feature name and value is the threshold. The threshold here is against attribution score distance between different time windows.
func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigOutput) AttributionScoreDriftThresholds() GoogleCloudAiplatformV1ThresholdConfigMapOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfig) map[string]GoogleCloudAiplatformV1ThresholdConfig {
		return v.AttributionScoreDriftThresholds
	}).(GoogleCloudAiplatformV1ThresholdConfigMapOutput)
}

// Drift anomaly detection threshold used by all features. When the per-feature thresholds are not set, this field can be used to specify a threshold for all features.
func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigOutput) DefaultDriftThreshold() GoogleCloudAiplatformV1ThresholdConfigPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfig) *GoogleCloudAiplatformV1ThresholdConfig {
		return v.DefaultDriftThreshold
	}).(GoogleCloudAiplatformV1ThresholdConfigPtrOutput)
}

// Key is the feature name and value is the threshold. If a feature needs to be monitored for drift, a value threshold must be configured for that feature. The threshold here is against feature distribution distance between different time windws.
func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigOutput) DriftThresholds() GoogleCloudAiplatformV1ThresholdConfigMapOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfig) map[string]GoogleCloudAiplatformV1ThresholdConfig {
		return v.DriftThresholds
	}).(GoogleCloudAiplatformV1ThresholdConfigMapOutput)
}

type GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrOutput) ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrOutput() GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrOutput) ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrOutput) Elem() GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfig) GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfig {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfig
		return ret
	}).(GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigOutput)
}

// Key is the feature name and value is the threshold. The threshold here is against attribution score distance between different time windows.
func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrOutput) AttributionScoreDriftThresholds() GoogleCloudAiplatformV1ThresholdConfigMapOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfig) map[string]GoogleCloudAiplatformV1ThresholdConfig {
		if v == nil {
			return nil
		}
		return v.AttributionScoreDriftThresholds
	}).(GoogleCloudAiplatformV1ThresholdConfigMapOutput)
}

// Drift anomaly detection threshold used by all features. When the per-feature thresholds are not set, this field can be used to specify a threshold for all features.
func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrOutput) DefaultDriftThreshold() GoogleCloudAiplatformV1ThresholdConfigPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfig) *GoogleCloudAiplatformV1ThresholdConfig {
		if v == nil {
			return nil
		}
		return v.DefaultDriftThreshold
	}).(GoogleCloudAiplatformV1ThresholdConfigPtrOutput)
}

// Key is the feature name and value is the threshold. If a feature needs to be monitored for drift, a value threshold must be configured for that feature. The threshold here is against feature distribution distance between different time windws.
func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrOutput) DriftThresholds() GoogleCloudAiplatformV1ThresholdConfigMapOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfig) map[string]GoogleCloudAiplatformV1ThresholdConfig {
		if v == nil {
			return nil
		}
		return v.DriftThresholds
	}).(GoogleCloudAiplatformV1ThresholdConfigMapOutput)
}

// The config for Prediction data drift detection.
type GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigResponse struct {
	// Key is the feature name and value is the threshold. The threshold here is against attribution score distance between different time windows.
	AttributionScoreDriftThresholds map[string]GoogleCloudAiplatformV1ThresholdConfigResponse `pulumi:"attributionScoreDriftThresholds"`
	// Drift anomaly detection threshold used by all features. When the per-feature thresholds are not set, this field can be used to specify a threshold for all features.
	DefaultDriftThreshold GoogleCloudAiplatformV1ThresholdConfigResponse `pulumi:"defaultDriftThreshold"`
	// Key is the feature name and value is the threshold. If a feature needs to be monitored for drift, a value threshold must be configured for that feature. The threshold here is against feature distribution distance between different time windws.
	DriftThresholds map[string]GoogleCloudAiplatformV1ThresholdConfigResponse `pulumi:"driftThresholds"`
}

// The config for Prediction data drift detection.
type GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigResponseOutput) ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigResponseOutput() GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigResponseOutput) ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigResponseOutput {
	return o
}

// Key is the feature name and value is the threshold. The threshold here is against attribution score distance between different time windows.
func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigResponseOutput) AttributionScoreDriftThresholds() GoogleCloudAiplatformV1ThresholdConfigResponseMapOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigResponse) map[string]GoogleCloudAiplatformV1ThresholdConfigResponse {
		return v.AttributionScoreDriftThresholds
	}).(GoogleCloudAiplatformV1ThresholdConfigResponseMapOutput)
}

// Drift anomaly detection threshold used by all features. When the per-feature thresholds are not set, this field can be used to specify a threshold for all features.
func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigResponseOutput) DefaultDriftThreshold() GoogleCloudAiplatformV1ThresholdConfigResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigResponse) GoogleCloudAiplatformV1ThresholdConfigResponse {
		return v.DefaultDriftThreshold
	}).(GoogleCloudAiplatformV1ThresholdConfigResponseOutput)
}

// Key is the feature name and value is the threshold. If a feature needs to be monitored for drift, a value threshold must be configured for that feature. The threshold here is against feature distribution distance between different time windws.
func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigResponseOutput) DriftThresholds() GoogleCloudAiplatformV1ThresholdConfigResponseMapOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigResponse) map[string]GoogleCloudAiplatformV1ThresholdConfigResponse {
		return v.DriftThresholds
	}).(GoogleCloudAiplatformV1ThresholdConfigResponseMapOutput)
}

// The objective configuration for model monitoring, including the information needed to detect anomalies for one particular model.
type GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigResponse struct {
	// The config for integrating with Vertex Explainable AI.
	ExplanationConfig GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigResponse `pulumi:"explanationConfig"`
	// The config for drift of prediction data.
	PredictionDriftDetectionConfig GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigResponse `pulumi:"predictionDriftDetectionConfig"`
	// Training dataset for models. This field has to be set only if TrainingPredictionSkewDetectionConfig is specified.
	TrainingDataset GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetResponse `pulumi:"trainingDataset"`
	// The config for skew between training data and prediction data.
	TrainingPredictionSkewDetectionConfig GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigResponse `pulumi:"trainingPredictionSkewDetectionConfig"`
}

// The objective configuration for model monitoring, including the information needed to detect anomalies for one particular model.
type GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigResponseOutput) ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigResponseOutput() GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigResponseOutput) ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigResponseOutput {
	return o
}

// The config for integrating with Vertex Explainable AI.
func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigResponseOutput) ExplanationConfig() GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigResponse) GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigResponse {
		return v.ExplanationConfig
	}).(GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigResponseOutput)
}

// The config for drift of prediction data.
func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigResponseOutput) PredictionDriftDetectionConfig() GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigResponse) GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigResponse {
		return v.PredictionDriftDetectionConfig
	}).(GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigResponseOutput)
}

// Training dataset for models. This field has to be set only if TrainingPredictionSkewDetectionConfig is specified.
func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigResponseOutput) TrainingDataset() GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigResponse) GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetResponse {
		return v.TrainingDataset
	}).(GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetResponseOutput)
}

// The config for skew between training data and prediction data.
func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigResponseOutput) TrainingPredictionSkewDetectionConfig() GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigResponse) GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigResponse {
		return v.TrainingPredictionSkewDetectionConfig
	}).(GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigResponseOutput)
}

// Training Dataset information.
type GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDataset struct {
	// The BigQuery table of the unmanaged Dataset used to train this Model.
	BigquerySource *GoogleCloudAiplatformV1BigQuerySource `pulumi:"bigquerySource"`
	// Data format of the dataset, only applicable if the input is from Google Cloud Storage. The possible formats are: "tf-record" The source file is a TFRecord file. "csv" The source file is a CSV file. "jsonl" The source file is a JSONL file.
	DataFormat *string `pulumi:"dataFormat"`
	// The resource name of the Dataset used to train this Model.
	Dataset *string `pulumi:"dataset"`
	// The Google Cloud Storage uri of the unmanaged Dataset used to train this Model.
	GcsSource *GoogleCloudAiplatformV1GcsSource `pulumi:"gcsSource"`
	// Strategy to sample data from Training Dataset. If not set, we process the whole dataset.
	LoggingSamplingStrategy *GoogleCloudAiplatformV1SamplingStrategy `pulumi:"loggingSamplingStrategy"`
	// The target field name the model is to predict. This field will be excluded when doing Predict and (or) Explain for the training data.
	TargetField *string `pulumi:"targetField"`
}

// GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetInput is an input type that accepts GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetArgs and GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetInput` via:
//
//	GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetArgs{...}
type GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetOutput() GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetOutput
	ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetOutputWithContext(context.Context) GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetOutput
}

// Training Dataset information.
type GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetArgs struct {
	// The BigQuery table of the unmanaged Dataset used to train this Model.
	BigquerySource GoogleCloudAiplatformV1BigQuerySourcePtrInput `pulumi:"bigquerySource"`
	// Data format of the dataset, only applicable if the input is from Google Cloud Storage. The possible formats are: "tf-record" The source file is a TFRecord file. "csv" The source file is a CSV file. "jsonl" The source file is a JSONL file.
	DataFormat pulumi.StringPtrInput `pulumi:"dataFormat"`
	// The resource name of the Dataset used to train this Model.
	Dataset pulumi.StringPtrInput `pulumi:"dataset"`
	// The Google Cloud Storage uri of the unmanaged Dataset used to train this Model.
	GcsSource GoogleCloudAiplatformV1GcsSourcePtrInput `pulumi:"gcsSource"`
	// Strategy to sample data from Training Dataset. If not set, we process the whole dataset.
	LoggingSamplingStrategy GoogleCloudAiplatformV1SamplingStrategyPtrInput `pulumi:"loggingSamplingStrategy"`
	// The target field name the model is to predict. This field will be excluded when doing Predict and (or) Explain for the training data.
	TargetField pulumi.StringPtrInput `pulumi:"targetField"`
}

func (GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDataset)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetArgs) ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetOutput() GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetOutput {
	return i.ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetArgs) ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetOutput)
}

func (i GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetArgs) ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetPtrOutput() GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetPtrOutput {
	return i.ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetArgs) ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetOutput).ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetPtrInput is an input type that accepts GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetArgs, GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetPtr and GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetPtrInput` via:
//
//	        GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetPtrOutput() GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetPtrOutput
	ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetPtrOutput
}

type googleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetPtrType GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetArgs

func GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetPtr(v *GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetArgs) GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetPtrInput {
	return (*googleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetPtrType)(v)
}

func (*googleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDataset)(nil)).Elem()
}

func (i *googleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetPtrType) ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetPtrOutput() GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetPtrOutput {
	return i.ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetPtrType) ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetPtrOutput)
}

// Training Dataset information.
type GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDataset)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetOutput) ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetOutput() GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetOutput {
	return o
}

func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetOutput) ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetOutput {
	return o
}

func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetOutput) ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetPtrOutput() GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetPtrOutput {
	return o.ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetOutput) ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDataset) *GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDataset {
		return &v
	}).(GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetPtrOutput)
}

// The BigQuery table of the unmanaged Dataset used to train this Model.
func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetOutput) BigquerySource() GoogleCloudAiplatformV1BigQuerySourcePtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDataset) *GoogleCloudAiplatformV1BigQuerySource {
		return v.BigquerySource
	}).(GoogleCloudAiplatformV1BigQuerySourcePtrOutput)
}

// Data format of the dataset, only applicable if the input is from Google Cloud Storage. The possible formats are: "tf-record" The source file is a TFRecord file. "csv" The source file is a CSV file. "jsonl" The source file is a JSONL file.
func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetOutput) DataFormat() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDataset) *string {
		return v.DataFormat
	}).(pulumi.StringPtrOutput)
}

// The resource name of the Dataset used to train this Model.
func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetOutput) Dataset() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDataset) *string { return v.Dataset }).(pulumi.StringPtrOutput)
}

// The Google Cloud Storage uri of the unmanaged Dataset used to train this Model.
func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetOutput) GcsSource() GoogleCloudAiplatformV1GcsSourcePtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDataset) *GoogleCloudAiplatformV1GcsSource {
		return v.GcsSource
	}).(GoogleCloudAiplatformV1GcsSourcePtrOutput)
}

// Strategy to sample data from Training Dataset. If not set, we process the whole dataset.
func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetOutput) LoggingSamplingStrategy() GoogleCloudAiplatformV1SamplingStrategyPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDataset) *GoogleCloudAiplatformV1SamplingStrategy {
		return v.LoggingSamplingStrategy
	}).(GoogleCloudAiplatformV1SamplingStrategyPtrOutput)
}

// The target field name the model is to predict. This field will be excluded when doing Predict and (or) Explain for the training data.
func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetOutput) TargetField() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDataset) *string {
		return v.TargetField
	}).(pulumi.StringPtrOutput)
}

type GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDataset)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetPtrOutput) ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetPtrOutput() GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetPtrOutput) ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetPtrOutput) Elem() GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDataset) GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDataset {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDataset
		return ret
	}).(GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetOutput)
}

// The BigQuery table of the unmanaged Dataset used to train this Model.
func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetPtrOutput) BigquerySource() GoogleCloudAiplatformV1BigQuerySourcePtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDataset) *GoogleCloudAiplatformV1BigQuerySource {
		if v == nil {
			return nil
		}
		return v.BigquerySource
	}).(GoogleCloudAiplatformV1BigQuerySourcePtrOutput)
}

// Data format of the dataset, only applicable if the input is from Google Cloud Storage. The possible formats are: "tf-record" The source file is a TFRecord file. "csv" The source file is a CSV file. "jsonl" The source file is a JSONL file.
func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetPtrOutput) DataFormat() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDataset) *string {
		if v == nil {
			return nil
		}
		return v.DataFormat
	}).(pulumi.StringPtrOutput)
}

// The resource name of the Dataset used to train this Model.
func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetPtrOutput) Dataset() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDataset) *string {
		if v == nil {
			return nil
		}
		return v.Dataset
	}).(pulumi.StringPtrOutput)
}

// The Google Cloud Storage uri of the unmanaged Dataset used to train this Model.
func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetPtrOutput) GcsSource() GoogleCloudAiplatformV1GcsSourcePtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDataset) *GoogleCloudAiplatformV1GcsSource {
		if v == nil {
			return nil
		}
		return v.GcsSource
	}).(GoogleCloudAiplatformV1GcsSourcePtrOutput)
}

// Strategy to sample data from Training Dataset. If not set, we process the whole dataset.
func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetPtrOutput) LoggingSamplingStrategy() GoogleCloudAiplatformV1SamplingStrategyPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDataset) *GoogleCloudAiplatformV1SamplingStrategy {
		if v == nil {
			return nil
		}
		return v.LoggingSamplingStrategy
	}).(GoogleCloudAiplatformV1SamplingStrategyPtrOutput)
}

// The target field name the model is to predict. This field will be excluded when doing Predict and (or) Explain for the training data.
func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetPtrOutput) TargetField() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDataset) *string {
		if v == nil {
			return nil
		}
		return v.TargetField
	}).(pulumi.StringPtrOutput)
}

// Training Dataset information.
type GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetResponse struct {
	// The BigQuery table of the unmanaged Dataset used to train this Model.
	BigquerySource GoogleCloudAiplatformV1BigQuerySourceResponse `pulumi:"bigquerySource"`
	// Data format of the dataset, only applicable if the input is from Google Cloud Storage. The possible formats are: "tf-record" The source file is a TFRecord file. "csv" The source file is a CSV file. "jsonl" The source file is a JSONL file.
	DataFormat string `pulumi:"dataFormat"`
	// The resource name of the Dataset used to train this Model.
	Dataset string `pulumi:"dataset"`
	// The Google Cloud Storage uri of the unmanaged Dataset used to train this Model.
	GcsSource GoogleCloudAiplatformV1GcsSourceResponse `pulumi:"gcsSource"`
	// Strategy to sample data from Training Dataset. If not set, we process the whole dataset.
	LoggingSamplingStrategy GoogleCloudAiplatformV1SamplingStrategyResponse `pulumi:"loggingSamplingStrategy"`
	// The target field name the model is to predict. This field will be excluded when doing Predict and (or) Explain for the training data.
	TargetField string `pulumi:"targetField"`
}

// Training Dataset information.
type GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetResponseOutput) ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetResponseOutput() GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetResponseOutput) ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetResponseOutput {
	return o
}

// The BigQuery table of the unmanaged Dataset used to train this Model.
func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetResponseOutput) BigquerySource() GoogleCloudAiplatformV1BigQuerySourceResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetResponse) GoogleCloudAiplatformV1BigQuerySourceResponse {
		return v.BigquerySource
	}).(GoogleCloudAiplatformV1BigQuerySourceResponseOutput)
}

// Data format of the dataset, only applicable if the input is from Google Cloud Storage. The possible formats are: "tf-record" The source file is a TFRecord file. "csv" The source file is a CSV file. "jsonl" The source file is a JSONL file.
func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetResponseOutput) DataFormat() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetResponse) string {
		return v.DataFormat
	}).(pulumi.StringOutput)
}

// The resource name of the Dataset used to train this Model.
func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetResponseOutput) Dataset() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetResponse) string {
		return v.Dataset
	}).(pulumi.StringOutput)
}

// The Google Cloud Storage uri of the unmanaged Dataset used to train this Model.
func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetResponseOutput) GcsSource() GoogleCloudAiplatformV1GcsSourceResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetResponse) GoogleCloudAiplatformV1GcsSourceResponse {
		return v.GcsSource
	}).(GoogleCloudAiplatformV1GcsSourceResponseOutput)
}

// Strategy to sample data from Training Dataset. If not set, we process the whole dataset.
func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetResponseOutput) LoggingSamplingStrategy() GoogleCloudAiplatformV1SamplingStrategyResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetResponse) GoogleCloudAiplatformV1SamplingStrategyResponse {
		return v.LoggingSamplingStrategy
	}).(GoogleCloudAiplatformV1SamplingStrategyResponseOutput)
}

// The target field name the model is to predict. This field will be excluded when doing Predict and (or) Explain for the training data.
func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetResponseOutput) TargetField() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetResponse) string {
		return v.TargetField
	}).(pulumi.StringOutput)
}

// The config for Training & Prediction data skew detection. It specifies the training dataset sources and the skew detection parameters.
type GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfig struct {
	// Key is the feature name and value is the threshold. The threshold here is against attribution score distance between the training and prediction feature.
	AttributionScoreSkewThresholds map[string]GoogleCloudAiplatformV1ThresholdConfig `pulumi:"attributionScoreSkewThresholds"`
	// Skew anomaly detection threshold used by all features. When the per-feature thresholds are not set, this field can be used to specify a threshold for all features.
	DefaultSkewThreshold *GoogleCloudAiplatformV1ThresholdConfig `pulumi:"defaultSkewThreshold"`
	// Key is the feature name and value is the threshold. If a feature needs to be monitored for skew, a value threshold must be configured for that feature. The threshold here is against feature distribution distance between the training and prediction feature.
	SkewThresholds map[string]GoogleCloudAiplatformV1ThresholdConfig `pulumi:"skewThresholds"`
}

// GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigInput is an input type that accepts GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigArgs and GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigInput` via:
//
//	GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigArgs{...}
type GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigOutput() GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigOutput
	ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigOutputWithContext(context.Context) GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigOutput
}

// The config for Training & Prediction data skew detection. It specifies the training dataset sources and the skew detection parameters.
type GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigArgs struct {
	// Key is the feature name and value is the threshold. The threshold here is against attribution score distance between the training and prediction feature.
	AttributionScoreSkewThresholds GoogleCloudAiplatformV1ThresholdConfigMapInput `pulumi:"attributionScoreSkewThresholds"`
	// Skew anomaly detection threshold used by all features. When the per-feature thresholds are not set, this field can be used to specify a threshold for all features.
	DefaultSkewThreshold GoogleCloudAiplatformV1ThresholdConfigPtrInput `pulumi:"defaultSkewThreshold"`
	// Key is the feature name and value is the threshold. If a feature needs to be monitored for skew, a value threshold must be configured for that feature. The threshold here is against feature distribution distance between the training and prediction feature.
	SkewThresholds GoogleCloudAiplatformV1ThresholdConfigMapInput `pulumi:"skewThresholds"`
}

func (GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfig)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigArgs) ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigOutput() GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigOutput {
	return i.ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigArgs) ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigOutput)
}

func (i GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigArgs) ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrOutput() GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigArgs) ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigOutput).ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrInput is an input type that accepts GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigArgs, GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtr and GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrInput` via:
//
//	        GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrOutput() GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrOutput
	ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrOutput
}

type googleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrType GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigArgs

func GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtr(v *GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigArgs) GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrInput {
	return (*googleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrType)(v)
}

func (*googleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfig)(nil)).Elem()
}

func (i *googleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrType) ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrOutput() GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrType) ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrOutput)
}

// The config for Training & Prediction data skew detection. It specifies the training dataset sources and the skew detection parameters.
type GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigOutput) ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigOutput() GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigOutput) ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigOutput) ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrOutput() GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrOutput {
	return o.ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigOutput) ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfig) *GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfig {
		return &v
	}).(GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrOutput)
}

// Key is the feature name and value is the threshold. The threshold here is against attribution score distance between the training and prediction feature.
func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigOutput) AttributionScoreSkewThresholds() GoogleCloudAiplatformV1ThresholdConfigMapOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfig) map[string]GoogleCloudAiplatformV1ThresholdConfig {
		return v.AttributionScoreSkewThresholds
	}).(GoogleCloudAiplatformV1ThresholdConfigMapOutput)
}

// Skew anomaly detection threshold used by all features. When the per-feature thresholds are not set, this field can be used to specify a threshold for all features.
func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigOutput) DefaultSkewThreshold() GoogleCloudAiplatformV1ThresholdConfigPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfig) *GoogleCloudAiplatformV1ThresholdConfig {
		return v.DefaultSkewThreshold
	}).(GoogleCloudAiplatformV1ThresholdConfigPtrOutput)
}

// Key is the feature name and value is the threshold. If a feature needs to be monitored for skew, a value threshold must be configured for that feature. The threshold here is against feature distribution distance between the training and prediction feature.
func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigOutput) SkewThresholds() GoogleCloudAiplatformV1ThresholdConfigMapOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfig) map[string]GoogleCloudAiplatformV1ThresholdConfig {
		return v.SkewThresholds
	}).(GoogleCloudAiplatformV1ThresholdConfigMapOutput)
}

type GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrOutput) ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrOutput() GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrOutput) ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrOutput) Elem() GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfig) GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfig {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfig
		return ret
	}).(GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigOutput)
}

// Key is the feature name and value is the threshold. The threshold here is against attribution score distance between the training and prediction feature.
func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrOutput) AttributionScoreSkewThresholds() GoogleCloudAiplatformV1ThresholdConfigMapOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfig) map[string]GoogleCloudAiplatformV1ThresholdConfig {
		if v == nil {
			return nil
		}
		return v.AttributionScoreSkewThresholds
	}).(GoogleCloudAiplatformV1ThresholdConfigMapOutput)
}

// Skew anomaly detection threshold used by all features. When the per-feature thresholds are not set, this field can be used to specify a threshold for all features.
func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrOutput) DefaultSkewThreshold() GoogleCloudAiplatformV1ThresholdConfigPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfig) *GoogleCloudAiplatformV1ThresholdConfig {
		if v == nil {
			return nil
		}
		return v.DefaultSkewThreshold
	}).(GoogleCloudAiplatformV1ThresholdConfigPtrOutput)
}

// Key is the feature name and value is the threshold. If a feature needs to be monitored for skew, a value threshold must be configured for that feature. The threshold here is against feature distribution distance between the training and prediction feature.
func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrOutput) SkewThresholds() GoogleCloudAiplatformV1ThresholdConfigMapOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfig) map[string]GoogleCloudAiplatformV1ThresholdConfig {
		if v == nil {
			return nil
		}
		return v.SkewThresholds
	}).(GoogleCloudAiplatformV1ThresholdConfigMapOutput)
}

// The config for Training & Prediction data skew detection. It specifies the training dataset sources and the skew detection parameters.
type GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigResponse struct {
	// Key is the feature name and value is the threshold. The threshold here is against attribution score distance between the training and prediction feature.
	AttributionScoreSkewThresholds map[string]GoogleCloudAiplatformV1ThresholdConfigResponse `pulumi:"attributionScoreSkewThresholds"`
	// Skew anomaly detection threshold used by all features. When the per-feature thresholds are not set, this field can be used to specify a threshold for all features.
	DefaultSkewThreshold GoogleCloudAiplatformV1ThresholdConfigResponse `pulumi:"defaultSkewThreshold"`
	// Key is the feature name and value is the threshold. If a feature needs to be monitored for skew, a value threshold must be configured for that feature. The threshold here is against feature distribution distance between the training and prediction feature.
	SkewThresholds map[string]GoogleCloudAiplatformV1ThresholdConfigResponse `pulumi:"skewThresholds"`
}

// The config for Training & Prediction data skew detection. It specifies the training dataset sources and the skew detection parameters.
type GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigResponseOutput) ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigResponseOutput() GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigResponseOutput) ToGoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigResponseOutput {
	return o
}

// Key is the feature name and value is the threshold. The threshold here is against attribution score distance between the training and prediction feature.
func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigResponseOutput) AttributionScoreSkewThresholds() GoogleCloudAiplatformV1ThresholdConfigResponseMapOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigResponse) map[string]GoogleCloudAiplatformV1ThresholdConfigResponse {
		return v.AttributionScoreSkewThresholds
	}).(GoogleCloudAiplatformV1ThresholdConfigResponseMapOutput)
}

// Skew anomaly detection threshold used by all features. When the per-feature thresholds are not set, this field can be used to specify a threshold for all features.
func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigResponseOutput) DefaultSkewThreshold() GoogleCloudAiplatformV1ThresholdConfigResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigResponse) GoogleCloudAiplatformV1ThresholdConfigResponse {
		return v.DefaultSkewThreshold
	}).(GoogleCloudAiplatformV1ThresholdConfigResponseOutput)
}

// Key is the feature name and value is the threshold. If a feature needs to be monitored for skew, a value threshold must be configured for that feature. The threshold here is against feature distribution distance between the training and prediction feature.
func (o GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigResponseOutput) SkewThresholds() GoogleCloudAiplatformV1ThresholdConfigResponseMapOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigResponse) map[string]GoogleCloudAiplatformV1ThresholdConfigResponse {
		return v.SkewThresholds
	}).(GoogleCloudAiplatformV1ThresholdConfigResponseMapOutput)
}

// Contains information about the original Model if this Model is a copy.
type GoogleCloudAiplatformV1ModelOriginalModelInfoResponse struct {
	// The resource name of the Model this Model is a copy of, including the revision. Format: `projects/{project}/locations/{location}/models/{model_id}@{version_id}`
	Model string `pulumi:"model"`
}

// Contains information about the original Model if this Model is a copy.
type GoogleCloudAiplatformV1ModelOriginalModelInfoResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ModelOriginalModelInfoResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1ModelOriginalModelInfoResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ModelOriginalModelInfoResponseOutput) ToGoogleCloudAiplatformV1ModelOriginalModelInfoResponseOutput() GoogleCloudAiplatformV1ModelOriginalModelInfoResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1ModelOriginalModelInfoResponseOutput) ToGoogleCloudAiplatformV1ModelOriginalModelInfoResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ModelOriginalModelInfoResponseOutput {
	return o
}

// The resource name of the Model this Model is a copy of, including the revision. Format: `projects/{project}/locations/{location}/models/{model_id}@{version_id}`
func (o GoogleCloudAiplatformV1ModelOriginalModelInfoResponseOutput) Model() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelOriginalModelInfoResponse) string { return v.Model }).(pulumi.StringOutput)
}

// A trained machine learning Model.
type GoogleCloudAiplatformV1ModelResponse struct {
	// Immutable. The path to the directory containing the Model artifact and any of its supporting files. Not present for AutoML Models or Large Models.
	ArtifactUri string `pulumi:"artifactUri"`
	// Input only. The specification of the container that is to be used when deploying this Model. The specification is ingested upon ModelService.UploadModel, and all binaries it contains are copied and stored internally by Vertex AI. Not present for AutoML Models or Large Models.
	ContainerSpec GoogleCloudAiplatformV1ModelContainerSpecResponse `pulumi:"containerSpec"`
	// Timestamp when this Model was uploaded into Vertex AI.
	CreateTime string `pulumi:"createTime"`
	// The pointers to DeployedModels created from this Model. Note that Model could have been deployed to Endpoints in different Locations.
	DeployedModels []GoogleCloudAiplatformV1DeployedModelRefResponse `pulumi:"deployedModels"`
	// The description of the Model.
	Description string `pulumi:"description"`
	// The display name of the Model. The name can be up to 128 characters long and can consist of any UTF-8 characters.
	DisplayName string `pulumi:"displayName"`
	// Customer-managed encryption key spec for a Model. If set, this Model and all sub-resources of this Model will be secured by this key.
	EncryptionSpec GoogleCloudAiplatformV1EncryptionSpecResponse `pulumi:"encryptionSpec"`
	// Used to perform consistent read-modify-write updates. If not set, a blind "overwrite" update happens.
	Etag string `pulumi:"etag"`
	// The default explanation specification for this Model. The Model can be used for requesting explanation after being deployed if it is populated. The Model can be used for batch explanation if it is populated. All fields of the explanation_spec can be overridden by explanation_spec of DeployModelRequest.deployed_model, or explanation_spec of BatchPredictionJob. If the default explanation specification is not set for this Model, this Model can still be used for requesting explanation by setting explanation_spec of DeployModelRequest.deployed_model and for batch explanation by setting explanation_spec of BatchPredictionJob.
	ExplanationSpec GoogleCloudAiplatformV1ExplanationSpecResponse `pulumi:"explanationSpec"`
	// The labels with user-defined metadata to organize your Models. Label keys and values can be no longer than 64 characters (Unicode codepoints), can only contain lowercase letters, numeric characters, underscores and dashes. International characters are allowed. See https://goo.gl/xmQnxf for more information and examples of labels.
	Labels map[string]string `pulumi:"labels"`
	// Immutable. An additional information about the Model; the schema of the metadata can be found in metadata_schema. Unset if the Model does not have any additional information.
	Metadata interface{} `pulumi:"metadata"`
	// The resource name of the Artifact that was created in MetadataStore when creating the Model. The Artifact resource name pattern is `projects/{project}/locations/{location}/metadataStores/{metadata_store}/artifacts/{artifact}`.
	MetadataArtifact string `pulumi:"metadataArtifact"`
	// Immutable. Points to a YAML file stored on Google Cloud Storage describing additional information about the Model, that is specific to it. Unset if the Model does not have any additional information. The schema is defined as an OpenAPI 3.0.2 [Schema Object](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject). AutoML Models always have this field populated by Vertex AI, if no additional metadata is needed, this field is set to an empty string. Note: The URI given on output will be immutable and probably different, including the URI scheme, than the one given on input. The output URI will point to a location where the user only has a read access.
	MetadataSchemaUri string `pulumi:"metadataSchemaUri"`
	// Source of a model. It can either be automl training pipeline, custom training pipeline, BigQuery ML, or existing Vertex AI Model.
	ModelSourceInfo GoogleCloudAiplatformV1ModelSourceInfoResponse `pulumi:"modelSourceInfo"`
	// The resource name of the Model.
	Name string `pulumi:"name"`
	// If this Model is a copy of another Model, this contains info about the original.
	OriginalModelInfo GoogleCloudAiplatformV1ModelOriginalModelInfoResponse `pulumi:"originalModelInfo"`
	// Optional. This field is populated if the model is produced by a pipeline job.
	PipelineJob string `pulumi:"pipelineJob"`
	// The schemata that describe formats of the Model's predictions and explanations as given and returned via PredictionService.Predict and PredictionService.Explain.
	PredictSchemata GoogleCloudAiplatformV1PredictSchemataResponse `pulumi:"predictSchemata"`
	// When this Model is deployed, its prediction resources are described by the `prediction_resources` field of the Endpoint.deployed_models object. Because not all Models support all resource configuration types, the configuration types this Model supports are listed here. If no configuration types are listed, the Model cannot be deployed to an Endpoint and does not support online predictions (PredictionService.Predict or PredictionService.Explain). Such a Model can serve predictions by using a BatchPredictionJob, if it has at least one entry each in supported_input_storage_formats and supported_output_storage_formats.
	SupportedDeploymentResourcesTypes []string `pulumi:"supportedDeploymentResourcesTypes"`
	// The formats in which this Model may be exported. If empty, this Model is not available for export.
	SupportedExportFormats []GoogleCloudAiplatformV1ModelExportFormatResponse `pulumi:"supportedExportFormats"`
	// The formats this Model supports in BatchPredictionJob.input_config. If PredictSchemata.instance_schema_uri exists, the instances should be given as per that schema. The possible formats are: * `jsonl` The JSON Lines format, where each instance is a single line. Uses GcsSource. * `csv` The CSV format, where each instance is a single comma-separated line. The first line in the file is the header, containing comma-separated field names. Uses GcsSource. * `tf-record` The TFRecord format, where each instance is a single record in tfrecord syntax. Uses GcsSource. * `tf-record-gzip` Similar to `tf-record`, but the file is gzipped. Uses GcsSource. * `bigquery` Each instance is a single row in BigQuery. Uses BigQuerySource. * `file-list` Each line of the file is the location of an instance to process, uses `gcs_source` field of the InputConfig object. If this Model doesn't support any of these formats it means it cannot be used with a BatchPredictionJob. However, if it has supported_deployment_resources_types, it could serve online predictions by using PredictionService.Predict or PredictionService.Explain.
	SupportedInputStorageFormats []string `pulumi:"supportedInputStorageFormats"`
	// The formats this Model supports in BatchPredictionJob.output_config. If both PredictSchemata.instance_schema_uri and PredictSchemata.prediction_schema_uri exist, the predictions are returned together with their instances. In other words, the prediction has the original instance data first, followed by the actual prediction content (as per the schema). The possible formats are: * `jsonl` The JSON Lines format, where each prediction is a single line. Uses GcsDestination. * `csv` The CSV format, where each prediction is a single comma-separated line. The first line in the file is the header, containing comma-separated field names. Uses GcsDestination. * `bigquery` Each prediction is a single row in a BigQuery table, uses BigQueryDestination . If this Model doesn't support any of these formats it means it cannot be used with a BatchPredictionJob. However, if it has supported_deployment_resources_types, it could serve online predictions by using PredictionService.Predict or PredictionService.Explain.
	SupportedOutputStorageFormats []string `pulumi:"supportedOutputStorageFormats"`
	// The resource name of the TrainingPipeline that uploaded this Model, if any.
	TrainingPipeline string `pulumi:"trainingPipeline"`
	// Timestamp when this Model was most recently updated.
	UpdateTime string `pulumi:"updateTime"`
	// User provided version aliases so that a model version can be referenced via alias (i.e. `projects/{project}/locations/{location}/models/{model_id}@{version_alias}` instead of auto-generated version id (i.e. `projects/{project}/locations/{location}/models/{model_id}@{version_id})`. The format is a-z{0,126}[a-z0-9] to distinguish from version_id. A default version alias will be created for the first version of the model, and there must be exactly one default version alias for a model.
	VersionAliases []string `pulumi:"versionAliases"`
	// Timestamp when this version was created.
	VersionCreateTime string `pulumi:"versionCreateTime"`
	// The description of this version.
	VersionDescription string `pulumi:"versionDescription"`
	// Immutable. The version ID of the model. A new version is committed when a new model version is uploaded or trained under an existing model id. It is an auto-incrementing decimal number in string representation.
	VersionId string `pulumi:"versionId"`
	// Timestamp when this version was most recently updated.
	VersionUpdateTime string `pulumi:"versionUpdateTime"`
}

// A trained machine learning Model.
type GoogleCloudAiplatformV1ModelResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ModelResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1ModelResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ModelResponseOutput) ToGoogleCloudAiplatformV1ModelResponseOutput() GoogleCloudAiplatformV1ModelResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1ModelResponseOutput) ToGoogleCloudAiplatformV1ModelResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ModelResponseOutput {
	return o
}

// Immutable. The path to the directory containing the Model artifact and any of its supporting files. Not present for AutoML Models or Large Models.
func (o GoogleCloudAiplatformV1ModelResponseOutput) ArtifactUri() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelResponse) string { return v.ArtifactUri }).(pulumi.StringOutput)
}

// Input only. The specification of the container that is to be used when deploying this Model. The specification is ingested upon ModelService.UploadModel, and all binaries it contains are copied and stored internally by Vertex AI. Not present for AutoML Models or Large Models.
func (o GoogleCloudAiplatformV1ModelResponseOutput) ContainerSpec() GoogleCloudAiplatformV1ModelContainerSpecResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelResponse) GoogleCloudAiplatformV1ModelContainerSpecResponse {
		return v.ContainerSpec
	}).(GoogleCloudAiplatformV1ModelContainerSpecResponseOutput)
}

// Timestamp when this Model was uploaded into Vertex AI.
func (o GoogleCloudAiplatformV1ModelResponseOutput) CreateTime() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelResponse) string { return v.CreateTime }).(pulumi.StringOutput)
}

// The pointers to DeployedModels created from this Model. Note that Model could have been deployed to Endpoints in different Locations.
func (o GoogleCloudAiplatformV1ModelResponseOutput) DeployedModels() GoogleCloudAiplatformV1DeployedModelRefResponseArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelResponse) []GoogleCloudAiplatformV1DeployedModelRefResponse {
		return v.DeployedModels
	}).(GoogleCloudAiplatformV1DeployedModelRefResponseArrayOutput)
}

// The description of the Model.
func (o GoogleCloudAiplatformV1ModelResponseOutput) Description() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelResponse) string { return v.Description }).(pulumi.StringOutput)
}

// The display name of the Model. The name can be up to 128 characters long and can consist of any UTF-8 characters.
func (o GoogleCloudAiplatformV1ModelResponseOutput) DisplayName() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelResponse) string { return v.DisplayName }).(pulumi.StringOutput)
}

// Customer-managed encryption key spec for a Model. If set, this Model and all sub-resources of this Model will be secured by this key.
func (o GoogleCloudAiplatformV1ModelResponseOutput) EncryptionSpec() GoogleCloudAiplatformV1EncryptionSpecResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelResponse) GoogleCloudAiplatformV1EncryptionSpecResponse {
		return v.EncryptionSpec
	}).(GoogleCloudAiplatformV1EncryptionSpecResponseOutput)
}

// Used to perform consistent read-modify-write updates. If not set, a blind "overwrite" update happens.
func (o GoogleCloudAiplatformV1ModelResponseOutput) Etag() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelResponse) string { return v.Etag }).(pulumi.StringOutput)
}

// The default explanation specification for this Model. The Model can be used for requesting explanation after being deployed if it is populated. The Model can be used for batch explanation if it is populated. All fields of the explanation_spec can be overridden by explanation_spec of DeployModelRequest.deployed_model, or explanation_spec of BatchPredictionJob. If the default explanation specification is not set for this Model, this Model can still be used for requesting explanation by setting explanation_spec of DeployModelRequest.deployed_model and for batch explanation by setting explanation_spec of BatchPredictionJob.
func (o GoogleCloudAiplatformV1ModelResponseOutput) ExplanationSpec() GoogleCloudAiplatformV1ExplanationSpecResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelResponse) GoogleCloudAiplatformV1ExplanationSpecResponse {
		return v.ExplanationSpec
	}).(GoogleCloudAiplatformV1ExplanationSpecResponseOutput)
}

// The labels with user-defined metadata to organize your Models. Label keys and values can be no longer than 64 characters (Unicode codepoints), can only contain lowercase letters, numeric characters, underscores and dashes. International characters are allowed. See https://goo.gl/xmQnxf for more information and examples of labels.
func (o GoogleCloudAiplatformV1ModelResponseOutput) Labels() pulumi.StringMapOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelResponse) map[string]string { return v.Labels }).(pulumi.StringMapOutput)
}

// Immutable. An additional information about the Model; the schema of the metadata can be found in metadata_schema. Unset if the Model does not have any additional information.
func (o GoogleCloudAiplatformV1ModelResponseOutput) Metadata() pulumi.AnyOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelResponse) interface{} { return v.Metadata }).(pulumi.AnyOutput)
}

// The resource name of the Artifact that was created in MetadataStore when creating the Model. The Artifact resource name pattern is `projects/{project}/locations/{location}/metadataStores/{metadata_store}/artifacts/{artifact}`.
func (o GoogleCloudAiplatformV1ModelResponseOutput) MetadataArtifact() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelResponse) string { return v.MetadataArtifact }).(pulumi.StringOutput)
}

// Immutable. Points to a YAML file stored on Google Cloud Storage describing additional information about the Model, that is specific to it. Unset if the Model does not have any additional information. The schema is defined as an OpenAPI 3.0.2 [Schema Object](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject). AutoML Models always have this field populated by Vertex AI, if no additional metadata is needed, this field is set to an empty string. Note: The URI given on output will be immutable and probably different, including the URI scheme, than the one given on input. The output URI will point to a location where the user only has a read access.
func (o GoogleCloudAiplatformV1ModelResponseOutput) MetadataSchemaUri() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelResponse) string { return v.MetadataSchemaUri }).(pulumi.StringOutput)
}

// Source of a model. It can either be automl training pipeline, custom training pipeline, BigQuery ML, or existing Vertex AI Model.
func (o GoogleCloudAiplatformV1ModelResponseOutput) ModelSourceInfo() GoogleCloudAiplatformV1ModelSourceInfoResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelResponse) GoogleCloudAiplatformV1ModelSourceInfoResponse {
		return v.ModelSourceInfo
	}).(GoogleCloudAiplatformV1ModelSourceInfoResponseOutput)
}

// The resource name of the Model.
func (o GoogleCloudAiplatformV1ModelResponseOutput) Name() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelResponse) string { return v.Name }).(pulumi.StringOutput)
}

// If this Model is a copy of another Model, this contains info about the original.
func (o GoogleCloudAiplatformV1ModelResponseOutput) OriginalModelInfo() GoogleCloudAiplatformV1ModelOriginalModelInfoResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelResponse) GoogleCloudAiplatformV1ModelOriginalModelInfoResponse {
		return v.OriginalModelInfo
	}).(GoogleCloudAiplatformV1ModelOriginalModelInfoResponseOutput)
}

// Optional. This field is populated if the model is produced by a pipeline job.
func (o GoogleCloudAiplatformV1ModelResponseOutput) PipelineJob() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelResponse) string { return v.PipelineJob }).(pulumi.StringOutput)
}

// The schemata that describe formats of the Model's predictions and explanations as given and returned via PredictionService.Predict and PredictionService.Explain.
func (o GoogleCloudAiplatformV1ModelResponseOutput) PredictSchemata() GoogleCloudAiplatformV1PredictSchemataResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelResponse) GoogleCloudAiplatformV1PredictSchemataResponse {
		return v.PredictSchemata
	}).(GoogleCloudAiplatformV1PredictSchemataResponseOutput)
}

// When this Model is deployed, its prediction resources are described by the `prediction_resources` field of the Endpoint.deployed_models object. Because not all Models support all resource configuration types, the configuration types this Model supports are listed here. If no configuration types are listed, the Model cannot be deployed to an Endpoint and does not support online predictions (PredictionService.Predict or PredictionService.Explain). Such a Model can serve predictions by using a BatchPredictionJob, if it has at least one entry each in supported_input_storage_formats and supported_output_storage_formats.
func (o GoogleCloudAiplatformV1ModelResponseOutput) SupportedDeploymentResourcesTypes() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelResponse) []string { return v.SupportedDeploymentResourcesTypes }).(pulumi.StringArrayOutput)
}

// The formats in which this Model may be exported. If empty, this Model is not available for export.
func (o GoogleCloudAiplatformV1ModelResponseOutput) SupportedExportFormats() GoogleCloudAiplatformV1ModelExportFormatResponseArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelResponse) []GoogleCloudAiplatformV1ModelExportFormatResponse {
		return v.SupportedExportFormats
	}).(GoogleCloudAiplatformV1ModelExportFormatResponseArrayOutput)
}

// The formats this Model supports in BatchPredictionJob.input_config. If PredictSchemata.instance_schema_uri exists, the instances should be given as per that schema. The possible formats are: * `jsonl` The JSON Lines format, where each instance is a single line. Uses GcsSource. * `csv` The CSV format, where each instance is a single comma-separated line. The first line in the file is the header, containing comma-separated field names. Uses GcsSource. * `tf-record` The TFRecord format, where each instance is a single record in tfrecord syntax. Uses GcsSource. * `tf-record-gzip` Similar to `tf-record`, but the file is gzipped. Uses GcsSource. * `bigquery` Each instance is a single row in BigQuery. Uses BigQuerySource. * `file-list` Each line of the file is the location of an instance to process, uses `gcs_source` field of the InputConfig object. If this Model doesn't support any of these formats it means it cannot be used with a BatchPredictionJob. However, if it has supported_deployment_resources_types, it could serve online predictions by using PredictionService.Predict or PredictionService.Explain.
func (o GoogleCloudAiplatformV1ModelResponseOutput) SupportedInputStorageFormats() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelResponse) []string { return v.SupportedInputStorageFormats }).(pulumi.StringArrayOutput)
}

// The formats this Model supports in BatchPredictionJob.output_config. If both PredictSchemata.instance_schema_uri and PredictSchemata.prediction_schema_uri exist, the predictions are returned together with their instances. In other words, the prediction has the original instance data first, followed by the actual prediction content (as per the schema). The possible formats are: * `jsonl` The JSON Lines format, where each prediction is a single line. Uses GcsDestination. * `csv` The CSV format, where each prediction is a single comma-separated line. The first line in the file is the header, containing comma-separated field names. Uses GcsDestination. * `bigquery` Each prediction is a single row in a BigQuery table, uses BigQueryDestination . If this Model doesn't support any of these formats it means it cannot be used with a BatchPredictionJob. However, if it has supported_deployment_resources_types, it could serve online predictions by using PredictionService.Predict or PredictionService.Explain.
func (o GoogleCloudAiplatformV1ModelResponseOutput) SupportedOutputStorageFormats() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelResponse) []string { return v.SupportedOutputStorageFormats }).(pulumi.StringArrayOutput)
}

// The resource name of the TrainingPipeline that uploaded this Model, if any.
func (o GoogleCloudAiplatformV1ModelResponseOutput) TrainingPipeline() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelResponse) string { return v.TrainingPipeline }).(pulumi.StringOutput)
}

// Timestamp when this Model was most recently updated.
func (o GoogleCloudAiplatformV1ModelResponseOutput) UpdateTime() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelResponse) string { return v.UpdateTime }).(pulumi.StringOutput)
}

// User provided version aliases so that a model version can be referenced via alias (i.e. `projects/{project}/locations/{location}/models/{model_id}@{version_alias}` instead of auto-generated version id (i.e. `projects/{project}/locations/{location}/models/{model_id}@{version_id})`. The format is a-z{0,126}[a-z0-9] to distinguish from version_id. A default version alias will be created for the first version of the model, and there must be exactly one default version alias for a model.
func (o GoogleCloudAiplatformV1ModelResponseOutput) VersionAliases() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelResponse) []string { return v.VersionAliases }).(pulumi.StringArrayOutput)
}

// Timestamp when this version was created.
func (o GoogleCloudAiplatformV1ModelResponseOutput) VersionCreateTime() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelResponse) string { return v.VersionCreateTime }).(pulumi.StringOutput)
}

// The description of this version.
func (o GoogleCloudAiplatformV1ModelResponseOutput) VersionDescription() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelResponse) string { return v.VersionDescription }).(pulumi.StringOutput)
}

// Immutable. The version ID of the model. A new version is committed when a new model version is uploaded or trained under an existing model id. It is an auto-incrementing decimal number in string representation.
func (o GoogleCloudAiplatformV1ModelResponseOutput) VersionId() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelResponse) string { return v.VersionId }).(pulumi.StringOutput)
}

// Timestamp when this version was most recently updated.
func (o GoogleCloudAiplatformV1ModelResponseOutput) VersionUpdateTime() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelResponse) string { return v.VersionUpdateTime }).(pulumi.StringOutput)
}

// Detail description of the source information of the model.
type GoogleCloudAiplatformV1ModelSourceInfoResponse struct {
	// If this Model is copy of another Model. If true then source_type pertains to the original.
	Copy bool `pulumi:"copy"`
	// Type of the model source.
	SourceType string `pulumi:"sourceType"`
}

// Detail description of the source information of the model.
type GoogleCloudAiplatformV1ModelSourceInfoResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ModelSourceInfoResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1ModelSourceInfoResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ModelSourceInfoResponseOutput) ToGoogleCloudAiplatformV1ModelSourceInfoResponseOutput() GoogleCloudAiplatformV1ModelSourceInfoResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1ModelSourceInfoResponseOutput) ToGoogleCloudAiplatformV1ModelSourceInfoResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ModelSourceInfoResponseOutput {
	return o
}

// If this Model is copy of another Model. If true then source_type pertains to the original.
func (o GoogleCloudAiplatformV1ModelSourceInfoResponseOutput) Copy() pulumi.BoolOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelSourceInfoResponse) bool { return v.Copy }).(pulumi.BoolOutput)
}

// Type of the model source.
func (o GoogleCloudAiplatformV1ModelSourceInfoResponseOutput) SourceType() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ModelSourceInfoResponse) string { return v.SourceType }).(pulumi.StringOutput)
}

// The output of a multi-trial Neural Architecture Search (NAS) jobs.
type GoogleCloudAiplatformV1NasJobOutputMultiTrialJobOutputResponse struct {
	// List of NasTrials that were started as part of search stage.
	SearchTrials []GoogleCloudAiplatformV1NasTrialResponse `pulumi:"searchTrials"`
	// List of NasTrials that were started as part of train stage.
	TrainTrials []GoogleCloudAiplatformV1NasTrialResponse `pulumi:"trainTrials"`
}

// The output of a multi-trial Neural Architecture Search (NAS) jobs.
type GoogleCloudAiplatformV1NasJobOutputMultiTrialJobOutputResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1NasJobOutputMultiTrialJobOutputResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1NasJobOutputMultiTrialJobOutputResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1NasJobOutputMultiTrialJobOutputResponseOutput) ToGoogleCloudAiplatformV1NasJobOutputMultiTrialJobOutputResponseOutput() GoogleCloudAiplatformV1NasJobOutputMultiTrialJobOutputResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1NasJobOutputMultiTrialJobOutputResponseOutput) ToGoogleCloudAiplatformV1NasJobOutputMultiTrialJobOutputResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1NasJobOutputMultiTrialJobOutputResponseOutput {
	return o
}

// List of NasTrials that were started as part of search stage.
func (o GoogleCloudAiplatformV1NasJobOutputMultiTrialJobOutputResponseOutput) SearchTrials() GoogleCloudAiplatformV1NasTrialResponseArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1NasJobOutputMultiTrialJobOutputResponse) []GoogleCloudAiplatformV1NasTrialResponse {
		return v.SearchTrials
	}).(GoogleCloudAiplatformV1NasTrialResponseArrayOutput)
}

// List of NasTrials that were started as part of train stage.
func (o GoogleCloudAiplatformV1NasJobOutputMultiTrialJobOutputResponseOutput) TrainTrials() GoogleCloudAiplatformV1NasTrialResponseArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1NasJobOutputMultiTrialJobOutputResponse) []GoogleCloudAiplatformV1NasTrialResponse {
		return v.TrainTrials
	}).(GoogleCloudAiplatformV1NasTrialResponseArrayOutput)
}

// Represents a uCAIP NasJob output.
type GoogleCloudAiplatformV1NasJobOutputResponse struct {
	// The output of this multi-trial Neural Architecture Search (NAS) job.
	MultiTrialJobOutput GoogleCloudAiplatformV1NasJobOutputMultiTrialJobOutputResponse `pulumi:"multiTrialJobOutput"`
}

// Represents a uCAIP NasJob output.
type GoogleCloudAiplatformV1NasJobOutputResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1NasJobOutputResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1NasJobOutputResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1NasJobOutputResponseOutput) ToGoogleCloudAiplatformV1NasJobOutputResponseOutput() GoogleCloudAiplatformV1NasJobOutputResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1NasJobOutputResponseOutput) ToGoogleCloudAiplatformV1NasJobOutputResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1NasJobOutputResponseOutput {
	return o
}

// The output of this multi-trial Neural Architecture Search (NAS) job.
func (o GoogleCloudAiplatformV1NasJobOutputResponseOutput) MultiTrialJobOutput() GoogleCloudAiplatformV1NasJobOutputMultiTrialJobOutputResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1NasJobOutputResponse) GoogleCloudAiplatformV1NasJobOutputMultiTrialJobOutputResponse {
		return v.MultiTrialJobOutput
	}).(GoogleCloudAiplatformV1NasJobOutputMultiTrialJobOutputResponseOutput)
}

// Represents the spec of a NasJob.
type GoogleCloudAiplatformV1NasJobSpec struct {
	// The spec of multi-trial algorithms.
	MultiTrialAlgorithmSpec *GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpec `pulumi:"multiTrialAlgorithmSpec"`
	// The ID of the existing NasJob in the same Project and Location which will be used to resume search. search_space_spec and nas_algorithm_spec are obtained from previous NasJob hence should not provide them again for this NasJob.
	ResumeNasJobId *string `pulumi:"resumeNasJobId"`
	// It defines the search space for Neural Architecture Search (NAS).
	SearchSpaceSpec *string `pulumi:"searchSpaceSpec"`
}

// GoogleCloudAiplatformV1NasJobSpecInput is an input type that accepts GoogleCloudAiplatformV1NasJobSpecArgs and GoogleCloudAiplatformV1NasJobSpecOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1NasJobSpecInput` via:
//
//	GoogleCloudAiplatformV1NasJobSpecArgs{...}
type GoogleCloudAiplatformV1NasJobSpecInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1NasJobSpecOutput() GoogleCloudAiplatformV1NasJobSpecOutput
	ToGoogleCloudAiplatformV1NasJobSpecOutputWithContext(context.Context) GoogleCloudAiplatformV1NasJobSpecOutput
}

// Represents the spec of a NasJob.
type GoogleCloudAiplatformV1NasJobSpecArgs struct {
	// The spec of multi-trial algorithms.
	MultiTrialAlgorithmSpec GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecPtrInput `pulumi:"multiTrialAlgorithmSpec"`
	// The ID of the existing NasJob in the same Project and Location which will be used to resume search. search_space_spec and nas_algorithm_spec are obtained from previous NasJob hence should not provide them again for this NasJob.
	ResumeNasJobId pulumi.StringPtrInput `pulumi:"resumeNasJobId"`
	// It defines the search space for Neural Architecture Search (NAS).
	SearchSpaceSpec pulumi.StringPtrInput `pulumi:"searchSpaceSpec"`
}

func (GoogleCloudAiplatformV1NasJobSpecArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1NasJobSpec)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1NasJobSpecArgs) ToGoogleCloudAiplatformV1NasJobSpecOutput() GoogleCloudAiplatformV1NasJobSpecOutput {
	return i.ToGoogleCloudAiplatformV1NasJobSpecOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1NasJobSpecArgs) ToGoogleCloudAiplatformV1NasJobSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1NasJobSpecOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1NasJobSpecOutput)
}

// Represents the spec of a NasJob.
type GoogleCloudAiplatformV1NasJobSpecOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1NasJobSpecOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1NasJobSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1NasJobSpecOutput) ToGoogleCloudAiplatformV1NasJobSpecOutput() GoogleCloudAiplatformV1NasJobSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1NasJobSpecOutput) ToGoogleCloudAiplatformV1NasJobSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1NasJobSpecOutput {
	return o
}

// The spec of multi-trial algorithms.
func (o GoogleCloudAiplatformV1NasJobSpecOutput) MultiTrialAlgorithmSpec() GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1NasJobSpec) *GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpec {
		return v.MultiTrialAlgorithmSpec
	}).(GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecPtrOutput)
}

// The ID of the existing NasJob in the same Project and Location which will be used to resume search. search_space_spec and nas_algorithm_spec are obtained from previous NasJob hence should not provide them again for this NasJob.
func (o GoogleCloudAiplatformV1NasJobSpecOutput) ResumeNasJobId() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1NasJobSpec) *string { return v.ResumeNasJobId }).(pulumi.StringPtrOutput)
}

// It defines the search space for Neural Architecture Search (NAS).
func (o GoogleCloudAiplatformV1NasJobSpecOutput) SearchSpaceSpec() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1NasJobSpec) *string { return v.SearchSpaceSpec }).(pulumi.StringPtrOutput)
}

// The spec of multi-trial Neural Architecture Search (NAS).
type GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpec struct {
	// Metric specs for the NAS job. Validation for this field is done at `multi_trial_algorithm_spec` field.
	Metric *GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpec `pulumi:"metric"`
	// The multi-trial Neural Architecture Search (NAS) algorithm type. Defaults to `REINFORCEMENT_LEARNING`.
	MultiTrialAlgorithm *GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMultiTrialAlgorithm `pulumi:"multiTrialAlgorithm"`
	// Spec for search trials.
	SearchTrialSpec GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpec `pulumi:"searchTrialSpec"`
	// Spec for train trials. Top N [TrainTrialSpec.max_parallel_trial_count] search trials will be trained for every M [TrainTrialSpec.frequency] trials searched.
	TrainTrialSpec *GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpec `pulumi:"trainTrialSpec"`
}

// GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecInput is an input type that accepts GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecArgs and GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecInput` via:
//
//	GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecArgs{...}
type GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecOutput() GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecOutput
	ToGoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecOutputWithContext(context.Context) GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecOutput
}

// The spec of multi-trial Neural Architecture Search (NAS).
type GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecArgs struct {
	// Metric specs for the NAS job. Validation for this field is done at `multi_trial_algorithm_spec` field.
	Metric GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrInput `pulumi:"metric"`
	// The multi-trial Neural Architecture Search (NAS) algorithm type. Defaults to `REINFORCEMENT_LEARNING`.
	MultiTrialAlgorithm GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMultiTrialAlgorithmPtrInput `pulumi:"multiTrialAlgorithm"`
	// Spec for search trials.
	SearchTrialSpec GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecInput `pulumi:"searchTrialSpec"`
	// Spec for train trials. Top N [TrainTrialSpec.max_parallel_trial_count] search trials will be trained for every M [TrainTrialSpec.frequency] trials searched.
	TrainTrialSpec GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrInput `pulumi:"trainTrialSpec"`
}

func (GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpec)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecArgs) ToGoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecOutput() GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecOutput {
	return i.ToGoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecArgs) ToGoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecOutput)
}

func (i GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecArgs) ToGoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecPtrOutput() GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecPtrOutput {
	return i.ToGoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecArgs) ToGoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecOutput).ToGoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecPtrInput is an input type that accepts GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecArgs, GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecPtr and GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecPtrInput` via:
//
//	        GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecPtrOutput() GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecPtrOutput
	ToGoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecPtrOutput
}

type googleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecPtrType GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecArgs

func GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecPtr(v *GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecArgs) GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecPtrInput {
	return (*googleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecPtrType)(v)
}

func (*googleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpec)(nil)).Elem()
}

func (i *googleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecPtrType) ToGoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecPtrOutput() GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecPtrOutput {
	return i.ToGoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecPtrType) ToGoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecPtrOutput)
}

// The spec of multi-trial Neural Architecture Search (NAS).
type GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecOutput) ToGoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecOutput() GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecOutput) ToGoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecOutput) ToGoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecPtrOutput() GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecPtrOutput {
	return o.ToGoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecOutput) ToGoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpec) *GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpec {
		return &v
	}).(GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecPtrOutput)
}

// Metric specs for the NAS job. Validation for this field is done at `multi_trial_algorithm_spec` field.
func (o GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecOutput) Metric() GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpec) *GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpec {
		return v.Metric
	}).(GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrOutput)
}

// The multi-trial Neural Architecture Search (NAS) algorithm type. Defaults to `REINFORCEMENT_LEARNING`.
func (o GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecOutput) MultiTrialAlgorithm() GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMultiTrialAlgorithmPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpec) *GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMultiTrialAlgorithm {
		return v.MultiTrialAlgorithm
	}).(GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMultiTrialAlgorithmPtrOutput)
}

// Spec for search trials.
func (o GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecOutput) SearchTrialSpec() GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpec) GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpec {
		return v.SearchTrialSpec
	}).(GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecOutput)
}

// Spec for train trials. Top N [TrainTrialSpec.max_parallel_trial_count] search trials will be trained for every M [TrainTrialSpec.frequency] trials searched.
func (o GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecOutput) TrainTrialSpec() GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpec) *GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpec {
		return v.TrainTrialSpec
	}).(GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrOutput)
}

type GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecPtrOutput) ToGoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecPtrOutput() GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecPtrOutput) ToGoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecPtrOutput) Elem() GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpec) GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpec {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpec
		return ret
	}).(GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecOutput)
}

// Metric specs for the NAS job. Validation for this field is done at `multi_trial_algorithm_spec` field.
func (o GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecPtrOutput) Metric() GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpec) *GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpec {
		if v == nil {
			return nil
		}
		return v.Metric
	}).(GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrOutput)
}

// The multi-trial Neural Architecture Search (NAS) algorithm type. Defaults to `REINFORCEMENT_LEARNING`.
func (o GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecPtrOutput) MultiTrialAlgorithm() GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMultiTrialAlgorithmPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpec) *GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMultiTrialAlgorithm {
		if v == nil {
			return nil
		}
		return v.MultiTrialAlgorithm
	}).(GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMultiTrialAlgorithmPtrOutput)
}

// Spec for search trials.
func (o GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecPtrOutput) SearchTrialSpec() GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpec) *GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpec {
		if v == nil {
			return nil
		}
		return &v.SearchTrialSpec
	}).(GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtrOutput)
}

// Spec for train trials. Top N [TrainTrialSpec.max_parallel_trial_count] search trials will be trained for every M [TrainTrialSpec.frequency] trials searched.
func (o GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecPtrOutput) TrainTrialSpec() GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpec) *GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpec {
		if v == nil {
			return nil
		}
		return v.TrainTrialSpec
	}).(GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrOutput)
}

// Represents a metric to optimize.
type GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpec struct {
	// The optimization goal of the metric.
	Goal GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecGoal `pulumi:"goal"`
	// The ID of the metric. Must not contain whitespaces.
	MetricId string `pulumi:"metricId"`
}

// GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecInput is an input type that accepts GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecArgs and GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecInput` via:
//
//	GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecArgs{...}
type GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecOutput() GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecOutput
	ToGoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecOutputWithContext(context.Context) GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecOutput
}

// Represents a metric to optimize.
type GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecArgs struct {
	// The optimization goal of the metric.
	Goal GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecGoalInput `pulumi:"goal"`
	// The ID of the metric. Must not contain whitespaces.
	MetricId pulumi.StringInput `pulumi:"metricId"`
}

func (GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpec)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecArgs) ToGoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecOutput() GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecOutput {
	return i.ToGoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecArgs) ToGoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecOutput)
}

func (i GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecArgs) ToGoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrOutput() GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrOutput {
	return i.ToGoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecArgs) ToGoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecOutput).ToGoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrInput is an input type that accepts GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecArgs, GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtr and GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrInput` via:
//
//	        GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrOutput() GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrOutput
	ToGoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrOutput
}

type googleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrType GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecArgs

func GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtr(v *GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecArgs) GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrInput {
	return (*googleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrType)(v)
}

func (*googleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpec)(nil)).Elem()
}

func (i *googleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrType) ToGoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrOutput() GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrOutput {
	return i.ToGoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrType) ToGoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrOutput)
}

// Represents a metric to optimize.
type GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecOutput) ToGoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecOutput() GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecOutput) ToGoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecOutput) ToGoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrOutput() GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrOutput {
	return o.ToGoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecOutput) ToGoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpec) *GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpec {
		return &v
	}).(GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrOutput)
}

// The optimization goal of the metric.
func (o GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecOutput) Goal() GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecGoalOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpec) GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecGoal {
		return v.Goal
	}).(GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecGoalOutput)
}

// The ID of the metric. Must not contain whitespaces.
func (o GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecOutput) MetricId() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpec) string { return v.MetricId }).(pulumi.StringOutput)
}

type GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrOutput) ToGoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrOutput() GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrOutput) ToGoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrOutput) Elem() GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpec) GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpec {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpec
		return ret
	}).(GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecOutput)
}

// The optimization goal of the metric.
func (o GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrOutput) Goal() GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecGoalPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpec) *GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecGoal {
		if v == nil {
			return nil
		}
		return &v.Goal
	}).(GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecGoalPtrOutput)
}

// The ID of the metric. Must not contain whitespaces.
func (o GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrOutput) MetricId() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpec) *string {
		if v == nil {
			return nil
		}
		return &v.MetricId
	}).(pulumi.StringPtrOutput)
}

// Represents a metric to optimize.
type GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecResponse struct {
	// The optimization goal of the metric.
	Goal string `pulumi:"goal"`
	// The ID of the metric. Must not contain whitespaces.
	MetricId string `pulumi:"metricId"`
}

// Represents a metric to optimize.
type GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecResponseOutput) ToGoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecResponseOutput() GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecResponseOutput) ToGoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecResponseOutput {
	return o
}

// The optimization goal of the metric.
func (o GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecResponseOutput) Goal() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecResponse) string {
		return v.Goal
	}).(pulumi.StringOutput)
}

// The ID of the metric. Must not contain whitespaces.
func (o GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecResponseOutput) MetricId() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecResponse) string {
		return v.MetricId
	}).(pulumi.StringOutput)
}

// The spec of multi-trial Neural Architecture Search (NAS).
type GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecResponse struct {
	// Metric specs for the NAS job. Validation for this field is done at `multi_trial_algorithm_spec` field.
	Metric GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecResponse `pulumi:"metric"`
	// The multi-trial Neural Architecture Search (NAS) algorithm type. Defaults to `REINFORCEMENT_LEARNING`.
	MultiTrialAlgorithm string `pulumi:"multiTrialAlgorithm"`
	// Spec for search trials.
	SearchTrialSpec GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecResponse `pulumi:"searchTrialSpec"`
	// Spec for train trials. Top N [TrainTrialSpec.max_parallel_trial_count] search trials will be trained for every M [TrainTrialSpec.frequency] trials searched.
	TrainTrialSpec GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecResponse `pulumi:"trainTrialSpec"`
}

// The spec of multi-trial Neural Architecture Search (NAS).
type GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecResponseOutput) ToGoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecResponseOutput() GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecResponseOutput) ToGoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecResponseOutput {
	return o
}

// Metric specs for the NAS job. Validation for this field is done at `multi_trial_algorithm_spec` field.
func (o GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecResponseOutput) Metric() GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecResponse) GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecResponse {
		return v.Metric
	}).(GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecResponseOutput)
}

// The multi-trial Neural Architecture Search (NAS) algorithm type. Defaults to `REINFORCEMENT_LEARNING`.
func (o GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecResponseOutput) MultiTrialAlgorithm() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecResponse) string {
		return v.MultiTrialAlgorithm
	}).(pulumi.StringOutput)
}

// Spec for search trials.
func (o GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecResponseOutput) SearchTrialSpec() GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecResponse) GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecResponse {
		return v.SearchTrialSpec
	}).(GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecResponseOutput)
}

// Spec for train trials. Top N [TrainTrialSpec.max_parallel_trial_count] search trials will be trained for every M [TrainTrialSpec.frequency] trials searched.
func (o GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecResponseOutput) TrainTrialSpec() GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecResponse) GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecResponse {
		return v.TrainTrialSpec
	}).(GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecResponseOutput)
}

// Represent spec for search trials.
type GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpec struct {
	// The number of failed trials that need to be seen before failing the NasJob. If set to 0, Vertex AI decides how many trials must fail before the whole job fails.
	MaxFailedTrialCount *int `pulumi:"maxFailedTrialCount"`
	// The maximum number of trials to run in parallel.
	MaxParallelTrialCount int `pulumi:"maxParallelTrialCount"`
	// The maximum number of Neural Architecture Search (NAS) trials to run.
	MaxTrialCount int `pulumi:"maxTrialCount"`
	// The spec of a search trial job. The same spec applies to all search trials.
	SearchTrialJobSpec GoogleCloudAiplatformV1CustomJobSpec `pulumi:"searchTrialJobSpec"`
}

// GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecInput is an input type that accepts GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecArgs and GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecInput` via:
//
//	GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecArgs{...}
type GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecOutput() GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecOutput
	ToGoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecOutputWithContext(context.Context) GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecOutput
}

// Represent spec for search trials.
type GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecArgs struct {
	// The number of failed trials that need to be seen before failing the NasJob. If set to 0, Vertex AI decides how many trials must fail before the whole job fails.
	MaxFailedTrialCount pulumi.IntPtrInput `pulumi:"maxFailedTrialCount"`
	// The maximum number of trials to run in parallel.
	MaxParallelTrialCount pulumi.IntInput `pulumi:"maxParallelTrialCount"`
	// The maximum number of Neural Architecture Search (NAS) trials to run.
	MaxTrialCount pulumi.IntInput `pulumi:"maxTrialCount"`
	// The spec of a search trial job. The same spec applies to all search trials.
	SearchTrialJobSpec GoogleCloudAiplatformV1CustomJobSpecInput `pulumi:"searchTrialJobSpec"`
}

func (GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpec)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecArgs) ToGoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecOutput() GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecOutput {
	return i.ToGoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecArgs) ToGoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecOutput)
}

func (i GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecArgs) ToGoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtrOutput() GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtrOutput {
	return i.ToGoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecArgs) ToGoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecOutput).ToGoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtrInput is an input type that accepts GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecArgs, GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtr and GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtrInput` via:
//
//	        GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtrOutput() GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtrOutput
	ToGoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtrOutput
}

type googleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtrType GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecArgs

func GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtr(v *GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecArgs) GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtrInput {
	return (*googleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtrType)(v)
}

func (*googleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpec)(nil)).Elem()
}

func (i *googleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtrType) ToGoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtrOutput() GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtrOutput {
	return i.ToGoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtrType) ToGoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtrOutput)
}

// Represent spec for search trials.
type GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecOutput) ToGoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecOutput() GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecOutput) ToGoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecOutput) ToGoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtrOutput() GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtrOutput {
	return o.ToGoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecOutput) ToGoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpec) *GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpec {
		return &v
	}).(GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtrOutput)
}

// The number of failed trials that need to be seen before failing the NasJob. If set to 0, Vertex AI decides how many trials must fail before the whole job fails.
func (o GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecOutput) MaxFailedTrialCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpec) *int {
		return v.MaxFailedTrialCount
	}).(pulumi.IntPtrOutput)
}

// The maximum number of trials to run in parallel.
func (o GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecOutput) MaxParallelTrialCount() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpec) int {
		return v.MaxParallelTrialCount
	}).(pulumi.IntOutput)
}

// The maximum number of Neural Architecture Search (NAS) trials to run.
func (o GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecOutput) MaxTrialCount() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpec) int {
		return v.MaxTrialCount
	}).(pulumi.IntOutput)
}

// The spec of a search trial job. The same spec applies to all search trials.
func (o GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecOutput) SearchTrialJobSpec() GoogleCloudAiplatformV1CustomJobSpecOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpec) GoogleCloudAiplatformV1CustomJobSpec {
		return v.SearchTrialJobSpec
	}).(GoogleCloudAiplatformV1CustomJobSpecOutput)
}

type GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtrOutput) ToGoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtrOutput() GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtrOutput) ToGoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtrOutput) Elem() GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpec) GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpec {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpec
		return ret
	}).(GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecOutput)
}

// The number of failed trials that need to be seen before failing the NasJob. If set to 0, Vertex AI decides how many trials must fail before the whole job fails.
func (o GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtrOutput) MaxFailedTrialCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpec) *int {
		if v == nil {
			return nil
		}
		return v.MaxFailedTrialCount
	}).(pulumi.IntPtrOutput)
}

// The maximum number of trials to run in parallel.
func (o GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtrOutput) MaxParallelTrialCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpec) *int {
		if v == nil {
			return nil
		}
		return &v.MaxParallelTrialCount
	}).(pulumi.IntPtrOutput)
}

// The maximum number of Neural Architecture Search (NAS) trials to run.
func (o GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtrOutput) MaxTrialCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpec) *int {
		if v == nil {
			return nil
		}
		return &v.MaxTrialCount
	}).(pulumi.IntPtrOutput)
}

// The spec of a search trial job. The same spec applies to all search trials.
func (o GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtrOutput) SearchTrialJobSpec() GoogleCloudAiplatformV1CustomJobSpecPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpec) *GoogleCloudAiplatformV1CustomJobSpec {
		if v == nil {
			return nil
		}
		return &v.SearchTrialJobSpec
	}).(GoogleCloudAiplatformV1CustomJobSpecPtrOutput)
}

// Represent spec for search trials.
type GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecResponse struct {
	// The number of failed trials that need to be seen before failing the NasJob. If set to 0, Vertex AI decides how many trials must fail before the whole job fails.
	MaxFailedTrialCount int `pulumi:"maxFailedTrialCount"`
	// The maximum number of trials to run in parallel.
	MaxParallelTrialCount int `pulumi:"maxParallelTrialCount"`
	// The maximum number of Neural Architecture Search (NAS) trials to run.
	MaxTrialCount int `pulumi:"maxTrialCount"`
	// The spec of a search trial job. The same spec applies to all search trials.
	SearchTrialJobSpec GoogleCloudAiplatformV1CustomJobSpecResponse `pulumi:"searchTrialJobSpec"`
}

// Represent spec for search trials.
type GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecResponseOutput) ToGoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecResponseOutput() GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecResponseOutput) ToGoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecResponseOutput {
	return o
}

// The number of failed trials that need to be seen before failing the NasJob. If set to 0, Vertex AI decides how many trials must fail before the whole job fails.
func (o GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecResponseOutput) MaxFailedTrialCount() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecResponse) int {
		return v.MaxFailedTrialCount
	}).(pulumi.IntOutput)
}

// The maximum number of trials to run in parallel.
func (o GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecResponseOutput) MaxParallelTrialCount() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecResponse) int {
		return v.MaxParallelTrialCount
	}).(pulumi.IntOutput)
}

// The maximum number of Neural Architecture Search (NAS) trials to run.
func (o GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecResponseOutput) MaxTrialCount() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecResponse) int {
		return v.MaxTrialCount
	}).(pulumi.IntOutput)
}

// The spec of a search trial job. The same spec applies to all search trials.
func (o GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecResponseOutput) SearchTrialJobSpec() GoogleCloudAiplatformV1CustomJobSpecResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecResponse) GoogleCloudAiplatformV1CustomJobSpecResponse {
		return v.SearchTrialJobSpec
	}).(GoogleCloudAiplatformV1CustomJobSpecResponseOutput)
}

// Represent spec for train trials.
type GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpec struct {
	// Frequency of search trials to start train stage. Top N [TrainTrialSpec.max_parallel_trial_count] search trials will be trained for every M [TrainTrialSpec.frequency] trials searched.
	Frequency int `pulumi:"frequency"`
	// The maximum number of trials to run in parallel.
	MaxParallelTrialCount int `pulumi:"maxParallelTrialCount"`
	// The spec of a train trial job. The same spec applies to all train trials.
	TrainTrialJobSpec GoogleCloudAiplatformV1CustomJobSpec `pulumi:"trainTrialJobSpec"`
}

// GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecInput is an input type that accepts GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecArgs and GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecInput` via:
//
//	GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecArgs{...}
type GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecOutput() GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecOutput
	ToGoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecOutputWithContext(context.Context) GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecOutput
}

// Represent spec for train trials.
type GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecArgs struct {
	// Frequency of search trials to start train stage. Top N [TrainTrialSpec.max_parallel_trial_count] search trials will be trained for every M [TrainTrialSpec.frequency] trials searched.
	Frequency pulumi.IntInput `pulumi:"frequency"`
	// The maximum number of trials to run in parallel.
	MaxParallelTrialCount pulumi.IntInput `pulumi:"maxParallelTrialCount"`
	// The spec of a train trial job. The same spec applies to all train trials.
	TrainTrialJobSpec GoogleCloudAiplatformV1CustomJobSpecInput `pulumi:"trainTrialJobSpec"`
}

func (GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpec)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecArgs) ToGoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecOutput() GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecOutput {
	return i.ToGoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecArgs) ToGoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecOutput)
}

func (i GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecArgs) ToGoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrOutput() GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrOutput {
	return i.ToGoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecArgs) ToGoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecOutput).ToGoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrInput is an input type that accepts GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecArgs, GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtr and GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrInput` via:
//
//	        GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrOutput() GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrOutput
	ToGoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrOutput
}

type googleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrType GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecArgs

func GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtr(v *GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecArgs) GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrInput {
	return (*googleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrType)(v)
}

func (*googleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpec)(nil)).Elem()
}

func (i *googleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrType) ToGoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrOutput() GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrOutput {
	return i.ToGoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrType) ToGoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrOutput)
}

// Represent spec for train trials.
type GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecOutput) ToGoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecOutput() GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecOutput) ToGoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecOutput) ToGoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrOutput() GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrOutput {
	return o.ToGoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecOutput) ToGoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpec) *GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpec {
		return &v
	}).(GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrOutput)
}

// Frequency of search trials to start train stage. Top N [TrainTrialSpec.max_parallel_trial_count] search trials will be trained for every M [TrainTrialSpec.frequency] trials searched.
func (o GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecOutput) Frequency() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpec) int { return v.Frequency }).(pulumi.IntOutput)
}

// The maximum number of trials to run in parallel.
func (o GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecOutput) MaxParallelTrialCount() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpec) int {
		return v.MaxParallelTrialCount
	}).(pulumi.IntOutput)
}

// The spec of a train trial job. The same spec applies to all train trials.
func (o GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecOutput) TrainTrialJobSpec() GoogleCloudAiplatformV1CustomJobSpecOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpec) GoogleCloudAiplatformV1CustomJobSpec {
		return v.TrainTrialJobSpec
	}).(GoogleCloudAiplatformV1CustomJobSpecOutput)
}

type GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrOutput) ToGoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrOutput() GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrOutput) ToGoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrOutput) Elem() GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpec) GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpec {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpec
		return ret
	}).(GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecOutput)
}

// Frequency of search trials to start train stage. Top N [TrainTrialSpec.max_parallel_trial_count] search trials will be trained for every M [TrainTrialSpec.frequency] trials searched.
func (o GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrOutput) Frequency() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpec) *int {
		if v == nil {
			return nil
		}
		return &v.Frequency
	}).(pulumi.IntPtrOutput)
}

// The maximum number of trials to run in parallel.
func (o GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrOutput) MaxParallelTrialCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpec) *int {
		if v == nil {
			return nil
		}
		return &v.MaxParallelTrialCount
	}).(pulumi.IntPtrOutput)
}

// The spec of a train trial job. The same spec applies to all train trials.
func (o GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrOutput) TrainTrialJobSpec() GoogleCloudAiplatformV1CustomJobSpecPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpec) *GoogleCloudAiplatformV1CustomJobSpec {
		if v == nil {
			return nil
		}
		return &v.TrainTrialJobSpec
	}).(GoogleCloudAiplatformV1CustomJobSpecPtrOutput)
}

// Represent spec for train trials.
type GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecResponse struct {
	// Frequency of search trials to start train stage. Top N [TrainTrialSpec.max_parallel_trial_count] search trials will be trained for every M [TrainTrialSpec.frequency] trials searched.
	Frequency int `pulumi:"frequency"`
	// The maximum number of trials to run in parallel.
	MaxParallelTrialCount int `pulumi:"maxParallelTrialCount"`
	// The spec of a train trial job. The same spec applies to all train trials.
	TrainTrialJobSpec GoogleCloudAiplatformV1CustomJobSpecResponse `pulumi:"trainTrialJobSpec"`
}

// Represent spec for train trials.
type GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecResponseOutput) ToGoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecResponseOutput() GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecResponseOutput) ToGoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecResponseOutput {
	return o
}

// Frequency of search trials to start train stage. Top N [TrainTrialSpec.max_parallel_trial_count] search trials will be trained for every M [TrainTrialSpec.frequency] trials searched.
func (o GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecResponseOutput) Frequency() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecResponse) int {
		return v.Frequency
	}).(pulumi.IntOutput)
}

// The maximum number of trials to run in parallel.
func (o GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecResponseOutput) MaxParallelTrialCount() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecResponse) int {
		return v.MaxParallelTrialCount
	}).(pulumi.IntOutput)
}

// The spec of a train trial job. The same spec applies to all train trials.
func (o GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecResponseOutput) TrainTrialJobSpec() GoogleCloudAiplatformV1CustomJobSpecResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecResponse) GoogleCloudAiplatformV1CustomJobSpecResponse {
		return v.TrainTrialJobSpec
	}).(GoogleCloudAiplatformV1CustomJobSpecResponseOutput)
}

// Represents the spec of a NasJob.
type GoogleCloudAiplatformV1NasJobSpecResponse struct {
	// The spec of multi-trial algorithms.
	MultiTrialAlgorithmSpec GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecResponse `pulumi:"multiTrialAlgorithmSpec"`
	// The ID of the existing NasJob in the same Project and Location which will be used to resume search. search_space_spec and nas_algorithm_spec are obtained from previous NasJob hence should not provide them again for this NasJob.
	ResumeNasJobId string `pulumi:"resumeNasJobId"`
	// It defines the search space for Neural Architecture Search (NAS).
	SearchSpaceSpec string `pulumi:"searchSpaceSpec"`
}

// Represents the spec of a NasJob.
type GoogleCloudAiplatformV1NasJobSpecResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1NasJobSpecResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1NasJobSpecResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1NasJobSpecResponseOutput) ToGoogleCloudAiplatformV1NasJobSpecResponseOutput() GoogleCloudAiplatformV1NasJobSpecResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1NasJobSpecResponseOutput) ToGoogleCloudAiplatformV1NasJobSpecResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1NasJobSpecResponseOutput {
	return o
}

// The spec of multi-trial algorithms.
func (o GoogleCloudAiplatformV1NasJobSpecResponseOutput) MultiTrialAlgorithmSpec() GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1NasJobSpecResponse) GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecResponse {
		return v.MultiTrialAlgorithmSpec
	}).(GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecResponseOutput)
}

// The ID of the existing NasJob in the same Project and Location which will be used to resume search. search_space_spec and nas_algorithm_spec are obtained from previous NasJob hence should not provide them again for this NasJob.
func (o GoogleCloudAiplatformV1NasJobSpecResponseOutput) ResumeNasJobId() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1NasJobSpecResponse) string { return v.ResumeNasJobId }).(pulumi.StringOutput)
}

// It defines the search space for Neural Architecture Search (NAS).
func (o GoogleCloudAiplatformV1NasJobSpecResponseOutput) SearchSpaceSpec() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1NasJobSpecResponse) string { return v.SearchSpaceSpec }).(pulumi.StringOutput)
}

// Represents a uCAIP NasJob trial.
type GoogleCloudAiplatformV1NasTrialResponse struct {
	// Time when the NasTrial's status changed to `SUCCEEDED` or `INFEASIBLE`.
	EndTime string `pulumi:"endTime"`
	// The final measurement containing the objective value.
	FinalMeasurement GoogleCloudAiplatformV1MeasurementResponse `pulumi:"finalMeasurement"`
	// Time when the NasTrial was started.
	StartTime string `pulumi:"startTime"`
	// The detailed state of the NasTrial.
	State string `pulumi:"state"`
}

// Represents a uCAIP NasJob trial.
type GoogleCloudAiplatformV1NasTrialResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1NasTrialResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1NasTrialResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1NasTrialResponseOutput) ToGoogleCloudAiplatformV1NasTrialResponseOutput() GoogleCloudAiplatformV1NasTrialResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1NasTrialResponseOutput) ToGoogleCloudAiplatformV1NasTrialResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1NasTrialResponseOutput {
	return o
}

// Time when the NasTrial's status changed to `SUCCEEDED` or `INFEASIBLE`.
func (o GoogleCloudAiplatformV1NasTrialResponseOutput) EndTime() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1NasTrialResponse) string { return v.EndTime }).(pulumi.StringOutput)
}

// The final measurement containing the objective value.
func (o GoogleCloudAiplatformV1NasTrialResponseOutput) FinalMeasurement() GoogleCloudAiplatformV1MeasurementResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1NasTrialResponse) GoogleCloudAiplatformV1MeasurementResponse {
		return v.FinalMeasurement
	}).(GoogleCloudAiplatformV1MeasurementResponseOutput)
}

// Time when the NasTrial was started.
func (o GoogleCloudAiplatformV1NasTrialResponseOutput) StartTime() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1NasTrialResponse) string { return v.StartTime }).(pulumi.StringOutput)
}

// The detailed state of the NasTrial.
func (o GoogleCloudAiplatformV1NasTrialResponseOutput) State() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1NasTrialResponse) string { return v.State }).(pulumi.StringOutput)
}

type GoogleCloudAiplatformV1NasTrialResponseArrayOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1NasTrialResponseArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1NasTrialResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1NasTrialResponseArrayOutput) ToGoogleCloudAiplatformV1NasTrialResponseArrayOutput() GoogleCloudAiplatformV1NasTrialResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1NasTrialResponseArrayOutput) ToGoogleCloudAiplatformV1NasTrialResponseArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1NasTrialResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1NasTrialResponseArrayOutput) Index(i pulumi.IntInput) GoogleCloudAiplatformV1NasTrialResponseOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GoogleCloudAiplatformV1NasTrialResponse {
		return vs[0].([]GoogleCloudAiplatformV1NasTrialResponse)[vs[1].(int)]
	}).(GoogleCloudAiplatformV1NasTrialResponseOutput)
}

// Network spec.
type GoogleCloudAiplatformV1NetworkSpec struct {
	// Whether to enable public internet access. Default false.
	EnableInternetAccess *bool `pulumi:"enableInternetAccess"`
	// The full name of the Google Compute Engine [network](https://cloud.google.com//compute/docs/networks-and-firewalls#networks)
	Network *string `pulumi:"network"`
	// The name of the subnet that this instance is in. Format: `projects/{project_id_or_number}/regions/{region}/subnetworks/{subnetwork_id}`
	Subnetwork *string `pulumi:"subnetwork"`
}

// GoogleCloudAiplatformV1NetworkSpecInput is an input type that accepts GoogleCloudAiplatformV1NetworkSpecArgs and GoogleCloudAiplatformV1NetworkSpecOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1NetworkSpecInput` via:
//
//	GoogleCloudAiplatformV1NetworkSpecArgs{...}
type GoogleCloudAiplatformV1NetworkSpecInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1NetworkSpecOutput() GoogleCloudAiplatformV1NetworkSpecOutput
	ToGoogleCloudAiplatformV1NetworkSpecOutputWithContext(context.Context) GoogleCloudAiplatformV1NetworkSpecOutput
}

// Network spec.
type GoogleCloudAiplatformV1NetworkSpecArgs struct {
	// Whether to enable public internet access. Default false.
	EnableInternetAccess pulumi.BoolPtrInput `pulumi:"enableInternetAccess"`
	// The full name of the Google Compute Engine [network](https://cloud.google.com//compute/docs/networks-and-firewalls#networks)
	Network pulumi.StringPtrInput `pulumi:"network"`
	// The name of the subnet that this instance is in. Format: `projects/{project_id_or_number}/regions/{region}/subnetworks/{subnetwork_id}`
	Subnetwork pulumi.StringPtrInput `pulumi:"subnetwork"`
}

func (GoogleCloudAiplatformV1NetworkSpecArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1NetworkSpec)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1NetworkSpecArgs) ToGoogleCloudAiplatformV1NetworkSpecOutput() GoogleCloudAiplatformV1NetworkSpecOutput {
	return i.ToGoogleCloudAiplatformV1NetworkSpecOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1NetworkSpecArgs) ToGoogleCloudAiplatformV1NetworkSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1NetworkSpecOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1NetworkSpecOutput)
}

func (i GoogleCloudAiplatformV1NetworkSpecArgs) ToGoogleCloudAiplatformV1NetworkSpecPtrOutput() GoogleCloudAiplatformV1NetworkSpecPtrOutput {
	return i.ToGoogleCloudAiplatformV1NetworkSpecPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1NetworkSpecArgs) ToGoogleCloudAiplatformV1NetworkSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1NetworkSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1NetworkSpecOutput).ToGoogleCloudAiplatformV1NetworkSpecPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1NetworkSpecPtrInput is an input type that accepts GoogleCloudAiplatformV1NetworkSpecArgs, GoogleCloudAiplatformV1NetworkSpecPtr and GoogleCloudAiplatformV1NetworkSpecPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1NetworkSpecPtrInput` via:
//
//	        GoogleCloudAiplatformV1NetworkSpecArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1NetworkSpecPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1NetworkSpecPtrOutput() GoogleCloudAiplatformV1NetworkSpecPtrOutput
	ToGoogleCloudAiplatformV1NetworkSpecPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1NetworkSpecPtrOutput
}

type googleCloudAiplatformV1NetworkSpecPtrType GoogleCloudAiplatformV1NetworkSpecArgs

func GoogleCloudAiplatformV1NetworkSpecPtr(v *GoogleCloudAiplatformV1NetworkSpecArgs) GoogleCloudAiplatformV1NetworkSpecPtrInput {
	return (*googleCloudAiplatformV1NetworkSpecPtrType)(v)
}

func (*googleCloudAiplatformV1NetworkSpecPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1NetworkSpec)(nil)).Elem()
}

func (i *googleCloudAiplatformV1NetworkSpecPtrType) ToGoogleCloudAiplatformV1NetworkSpecPtrOutput() GoogleCloudAiplatformV1NetworkSpecPtrOutput {
	return i.ToGoogleCloudAiplatformV1NetworkSpecPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1NetworkSpecPtrType) ToGoogleCloudAiplatformV1NetworkSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1NetworkSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1NetworkSpecPtrOutput)
}

// Network spec.
type GoogleCloudAiplatformV1NetworkSpecOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1NetworkSpecOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1NetworkSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1NetworkSpecOutput) ToGoogleCloudAiplatformV1NetworkSpecOutput() GoogleCloudAiplatformV1NetworkSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1NetworkSpecOutput) ToGoogleCloudAiplatformV1NetworkSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1NetworkSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1NetworkSpecOutput) ToGoogleCloudAiplatformV1NetworkSpecPtrOutput() GoogleCloudAiplatformV1NetworkSpecPtrOutput {
	return o.ToGoogleCloudAiplatformV1NetworkSpecPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1NetworkSpecOutput) ToGoogleCloudAiplatformV1NetworkSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1NetworkSpecPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1NetworkSpec) *GoogleCloudAiplatformV1NetworkSpec {
		return &v
	}).(GoogleCloudAiplatformV1NetworkSpecPtrOutput)
}

// Whether to enable public internet access. Default false.
func (o GoogleCloudAiplatformV1NetworkSpecOutput) EnableInternetAccess() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1NetworkSpec) *bool { return v.EnableInternetAccess }).(pulumi.BoolPtrOutput)
}

// The full name of the Google Compute Engine [network](https://cloud.google.com//compute/docs/networks-and-firewalls#networks)
func (o GoogleCloudAiplatformV1NetworkSpecOutput) Network() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1NetworkSpec) *string { return v.Network }).(pulumi.StringPtrOutput)
}

// The name of the subnet that this instance is in. Format: `projects/{project_id_or_number}/regions/{region}/subnetworks/{subnetwork_id}`
func (o GoogleCloudAiplatformV1NetworkSpecOutput) Subnetwork() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1NetworkSpec) *string { return v.Subnetwork }).(pulumi.StringPtrOutput)
}

type GoogleCloudAiplatformV1NetworkSpecPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1NetworkSpecPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1NetworkSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1NetworkSpecPtrOutput) ToGoogleCloudAiplatformV1NetworkSpecPtrOutput() GoogleCloudAiplatformV1NetworkSpecPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1NetworkSpecPtrOutput) ToGoogleCloudAiplatformV1NetworkSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1NetworkSpecPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1NetworkSpecPtrOutput) Elem() GoogleCloudAiplatformV1NetworkSpecOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1NetworkSpec) GoogleCloudAiplatformV1NetworkSpec {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1NetworkSpec
		return ret
	}).(GoogleCloudAiplatformV1NetworkSpecOutput)
}

// Whether to enable public internet access. Default false.
func (o GoogleCloudAiplatformV1NetworkSpecPtrOutput) EnableInternetAccess() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1NetworkSpec) *bool {
		if v == nil {
			return nil
		}
		return v.EnableInternetAccess
	}).(pulumi.BoolPtrOutput)
}

// The full name of the Google Compute Engine [network](https://cloud.google.com//compute/docs/networks-and-firewalls#networks)
func (o GoogleCloudAiplatformV1NetworkSpecPtrOutput) Network() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1NetworkSpec) *string {
		if v == nil {
			return nil
		}
		return v.Network
	}).(pulumi.StringPtrOutput)
}

// The name of the subnet that this instance is in. Format: `projects/{project_id_or_number}/regions/{region}/subnetworks/{subnetwork_id}`
func (o GoogleCloudAiplatformV1NetworkSpecPtrOutput) Subnetwork() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1NetworkSpec) *string {
		if v == nil {
			return nil
		}
		return v.Subnetwork
	}).(pulumi.StringPtrOutput)
}

// Network spec.
type GoogleCloudAiplatformV1NetworkSpecResponse struct {
	// Whether to enable public internet access. Default false.
	EnableInternetAccess bool `pulumi:"enableInternetAccess"`
	// The full name of the Google Compute Engine [network](https://cloud.google.com//compute/docs/networks-and-firewalls#networks)
	Network string `pulumi:"network"`
	// The name of the subnet that this instance is in. Format: `projects/{project_id_or_number}/regions/{region}/subnetworks/{subnetwork_id}`
	Subnetwork string `pulumi:"subnetwork"`
}

// Network spec.
type GoogleCloudAiplatformV1NetworkSpecResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1NetworkSpecResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1NetworkSpecResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1NetworkSpecResponseOutput) ToGoogleCloudAiplatformV1NetworkSpecResponseOutput() GoogleCloudAiplatformV1NetworkSpecResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1NetworkSpecResponseOutput) ToGoogleCloudAiplatformV1NetworkSpecResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1NetworkSpecResponseOutput {
	return o
}

// Whether to enable public internet access. Default false.
func (o GoogleCloudAiplatformV1NetworkSpecResponseOutput) EnableInternetAccess() pulumi.BoolOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1NetworkSpecResponse) bool { return v.EnableInternetAccess }).(pulumi.BoolOutput)
}

// The full name of the Google Compute Engine [network](https://cloud.google.com//compute/docs/networks-and-firewalls#networks)
func (o GoogleCloudAiplatformV1NetworkSpecResponseOutput) Network() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1NetworkSpecResponse) string { return v.Network }).(pulumi.StringOutput)
}

// The name of the subnet that this instance is in. Format: `projects/{project_id_or_number}/regions/{region}/subnetworks/{subnetwork_id}`
func (o GoogleCloudAiplatformV1NetworkSpecResponseOutput) Subnetwork() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1NetworkSpecResponse) string { return v.Subnetwork }).(pulumi.StringOutput)
}

// Represents a mount configuration for Network File System (NFS) to mount.
type GoogleCloudAiplatformV1NfsMount struct {
	// Destination mount path. The NFS will be mounted for the user under /mnt/nfs/
	MountPoint string `pulumi:"mountPoint"`
	// Source path exported from NFS server. Has to start with '/', and combined with the ip address, it indicates the source mount path in the form of `server:path`
	Path string `pulumi:"path"`
	// IP address of the NFS server.
	Server string `pulumi:"server"`
}

// GoogleCloudAiplatformV1NfsMountInput is an input type that accepts GoogleCloudAiplatformV1NfsMountArgs and GoogleCloudAiplatformV1NfsMountOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1NfsMountInput` via:
//
//	GoogleCloudAiplatformV1NfsMountArgs{...}
type GoogleCloudAiplatformV1NfsMountInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1NfsMountOutput() GoogleCloudAiplatformV1NfsMountOutput
	ToGoogleCloudAiplatformV1NfsMountOutputWithContext(context.Context) GoogleCloudAiplatformV1NfsMountOutput
}

// Represents a mount configuration for Network File System (NFS) to mount.
type GoogleCloudAiplatformV1NfsMountArgs struct {
	// Destination mount path. The NFS will be mounted for the user under /mnt/nfs/
	MountPoint pulumi.StringInput `pulumi:"mountPoint"`
	// Source path exported from NFS server. Has to start with '/', and combined with the ip address, it indicates the source mount path in the form of `server:path`
	Path pulumi.StringInput `pulumi:"path"`
	// IP address of the NFS server.
	Server pulumi.StringInput `pulumi:"server"`
}

func (GoogleCloudAiplatformV1NfsMountArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1NfsMount)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1NfsMountArgs) ToGoogleCloudAiplatformV1NfsMountOutput() GoogleCloudAiplatformV1NfsMountOutput {
	return i.ToGoogleCloudAiplatformV1NfsMountOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1NfsMountArgs) ToGoogleCloudAiplatformV1NfsMountOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1NfsMountOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1NfsMountOutput)
}

// GoogleCloudAiplatformV1NfsMountArrayInput is an input type that accepts GoogleCloudAiplatformV1NfsMountArray and GoogleCloudAiplatformV1NfsMountArrayOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1NfsMountArrayInput` via:
//
//	GoogleCloudAiplatformV1NfsMountArray{ GoogleCloudAiplatformV1NfsMountArgs{...} }
type GoogleCloudAiplatformV1NfsMountArrayInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1NfsMountArrayOutput() GoogleCloudAiplatformV1NfsMountArrayOutput
	ToGoogleCloudAiplatformV1NfsMountArrayOutputWithContext(context.Context) GoogleCloudAiplatformV1NfsMountArrayOutput
}

type GoogleCloudAiplatformV1NfsMountArray []GoogleCloudAiplatformV1NfsMountInput

func (GoogleCloudAiplatformV1NfsMountArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1NfsMount)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1NfsMountArray) ToGoogleCloudAiplatformV1NfsMountArrayOutput() GoogleCloudAiplatformV1NfsMountArrayOutput {
	return i.ToGoogleCloudAiplatformV1NfsMountArrayOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1NfsMountArray) ToGoogleCloudAiplatformV1NfsMountArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1NfsMountArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1NfsMountArrayOutput)
}

// Represents a mount configuration for Network File System (NFS) to mount.
type GoogleCloudAiplatformV1NfsMountOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1NfsMountOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1NfsMount)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1NfsMountOutput) ToGoogleCloudAiplatformV1NfsMountOutput() GoogleCloudAiplatformV1NfsMountOutput {
	return o
}

func (o GoogleCloudAiplatformV1NfsMountOutput) ToGoogleCloudAiplatformV1NfsMountOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1NfsMountOutput {
	return o
}

// Destination mount path. The NFS will be mounted for the user under /mnt/nfs/
func (o GoogleCloudAiplatformV1NfsMountOutput) MountPoint() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1NfsMount) string { return v.MountPoint }).(pulumi.StringOutput)
}

// Source path exported from NFS server. Has to start with '/', and combined with the ip address, it indicates the source mount path in the form of `server:path`
func (o GoogleCloudAiplatformV1NfsMountOutput) Path() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1NfsMount) string { return v.Path }).(pulumi.StringOutput)
}

// IP address of the NFS server.
func (o GoogleCloudAiplatformV1NfsMountOutput) Server() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1NfsMount) string { return v.Server }).(pulumi.StringOutput)
}

type GoogleCloudAiplatformV1NfsMountArrayOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1NfsMountArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1NfsMount)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1NfsMountArrayOutput) ToGoogleCloudAiplatformV1NfsMountArrayOutput() GoogleCloudAiplatformV1NfsMountArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1NfsMountArrayOutput) ToGoogleCloudAiplatformV1NfsMountArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1NfsMountArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1NfsMountArrayOutput) Index(i pulumi.IntInput) GoogleCloudAiplatformV1NfsMountOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GoogleCloudAiplatformV1NfsMount {
		return vs[0].([]GoogleCloudAiplatformV1NfsMount)[vs[1].(int)]
	}).(GoogleCloudAiplatformV1NfsMountOutput)
}

// Represents a mount configuration for Network File System (NFS) to mount.
type GoogleCloudAiplatformV1NfsMountResponse struct {
	// Destination mount path. The NFS will be mounted for the user under /mnt/nfs/
	MountPoint string `pulumi:"mountPoint"`
	// Source path exported from NFS server. Has to start with '/', and combined with the ip address, it indicates the source mount path in the form of `server:path`
	Path string `pulumi:"path"`
	// IP address of the NFS server.
	Server string `pulumi:"server"`
}

// Represents a mount configuration for Network File System (NFS) to mount.
type GoogleCloudAiplatformV1NfsMountResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1NfsMountResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1NfsMountResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1NfsMountResponseOutput) ToGoogleCloudAiplatformV1NfsMountResponseOutput() GoogleCloudAiplatformV1NfsMountResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1NfsMountResponseOutput) ToGoogleCloudAiplatformV1NfsMountResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1NfsMountResponseOutput {
	return o
}

// Destination mount path. The NFS will be mounted for the user under /mnt/nfs/
func (o GoogleCloudAiplatformV1NfsMountResponseOutput) MountPoint() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1NfsMountResponse) string { return v.MountPoint }).(pulumi.StringOutput)
}

// Source path exported from NFS server. Has to start with '/', and combined with the ip address, it indicates the source mount path in the form of `server:path`
func (o GoogleCloudAiplatformV1NfsMountResponseOutput) Path() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1NfsMountResponse) string { return v.Path }).(pulumi.StringOutput)
}

// IP address of the NFS server.
func (o GoogleCloudAiplatformV1NfsMountResponseOutput) Server() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1NfsMountResponse) string { return v.Server }).(pulumi.StringOutput)
}

type GoogleCloudAiplatformV1NfsMountResponseArrayOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1NfsMountResponseArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1NfsMountResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1NfsMountResponseArrayOutput) ToGoogleCloudAiplatformV1NfsMountResponseArrayOutput() GoogleCloudAiplatformV1NfsMountResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1NfsMountResponseArrayOutput) ToGoogleCloudAiplatformV1NfsMountResponseArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1NfsMountResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1NfsMountResponseArrayOutput) Index(i pulumi.IntInput) GoogleCloudAiplatformV1NfsMountResponseOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GoogleCloudAiplatformV1NfsMountResponse {
		return vs[0].([]GoogleCloudAiplatformV1NfsMountResponse)[vs[1].(int)]
	}).(GoogleCloudAiplatformV1NfsMountResponseOutput)
}

// The euc configuration of NotebookRuntimeTemplate.
type GoogleCloudAiplatformV1NotebookEucConfig struct {
	// Input only. Whether EUC is disabled in this NotebookRuntimeTemplate. In proto3, the default value of a boolean is false. In this way, by default EUC will be enabled for NotebookRuntimeTemplate.
	EucDisabled *bool `pulumi:"eucDisabled"`
}

// GoogleCloudAiplatformV1NotebookEucConfigInput is an input type that accepts GoogleCloudAiplatformV1NotebookEucConfigArgs and GoogleCloudAiplatformV1NotebookEucConfigOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1NotebookEucConfigInput` via:
//
//	GoogleCloudAiplatformV1NotebookEucConfigArgs{...}
type GoogleCloudAiplatformV1NotebookEucConfigInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1NotebookEucConfigOutput() GoogleCloudAiplatformV1NotebookEucConfigOutput
	ToGoogleCloudAiplatformV1NotebookEucConfigOutputWithContext(context.Context) GoogleCloudAiplatformV1NotebookEucConfigOutput
}

// The euc configuration of NotebookRuntimeTemplate.
type GoogleCloudAiplatformV1NotebookEucConfigArgs struct {
	// Input only. Whether EUC is disabled in this NotebookRuntimeTemplate. In proto3, the default value of a boolean is false. In this way, by default EUC will be enabled for NotebookRuntimeTemplate.
	EucDisabled pulumi.BoolPtrInput `pulumi:"eucDisabled"`
}

func (GoogleCloudAiplatformV1NotebookEucConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1NotebookEucConfig)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1NotebookEucConfigArgs) ToGoogleCloudAiplatformV1NotebookEucConfigOutput() GoogleCloudAiplatformV1NotebookEucConfigOutput {
	return i.ToGoogleCloudAiplatformV1NotebookEucConfigOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1NotebookEucConfigArgs) ToGoogleCloudAiplatformV1NotebookEucConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1NotebookEucConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1NotebookEucConfigOutput)
}

func (i GoogleCloudAiplatformV1NotebookEucConfigArgs) ToGoogleCloudAiplatformV1NotebookEucConfigPtrOutput() GoogleCloudAiplatformV1NotebookEucConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1NotebookEucConfigPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1NotebookEucConfigArgs) ToGoogleCloudAiplatformV1NotebookEucConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1NotebookEucConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1NotebookEucConfigOutput).ToGoogleCloudAiplatformV1NotebookEucConfigPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1NotebookEucConfigPtrInput is an input type that accepts GoogleCloudAiplatformV1NotebookEucConfigArgs, GoogleCloudAiplatformV1NotebookEucConfigPtr and GoogleCloudAiplatformV1NotebookEucConfigPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1NotebookEucConfigPtrInput` via:
//
//	        GoogleCloudAiplatformV1NotebookEucConfigArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1NotebookEucConfigPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1NotebookEucConfigPtrOutput() GoogleCloudAiplatformV1NotebookEucConfigPtrOutput
	ToGoogleCloudAiplatformV1NotebookEucConfigPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1NotebookEucConfigPtrOutput
}

type googleCloudAiplatformV1NotebookEucConfigPtrType GoogleCloudAiplatformV1NotebookEucConfigArgs

func GoogleCloudAiplatformV1NotebookEucConfigPtr(v *GoogleCloudAiplatformV1NotebookEucConfigArgs) GoogleCloudAiplatformV1NotebookEucConfigPtrInput {
	return (*googleCloudAiplatformV1NotebookEucConfigPtrType)(v)
}

func (*googleCloudAiplatformV1NotebookEucConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1NotebookEucConfig)(nil)).Elem()
}

func (i *googleCloudAiplatformV1NotebookEucConfigPtrType) ToGoogleCloudAiplatformV1NotebookEucConfigPtrOutput() GoogleCloudAiplatformV1NotebookEucConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1NotebookEucConfigPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1NotebookEucConfigPtrType) ToGoogleCloudAiplatformV1NotebookEucConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1NotebookEucConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1NotebookEucConfigPtrOutput)
}

// The euc configuration of NotebookRuntimeTemplate.
type GoogleCloudAiplatformV1NotebookEucConfigOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1NotebookEucConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1NotebookEucConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1NotebookEucConfigOutput) ToGoogleCloudAiplatformV1NotebookEucConfigOutput() GoogleCloudAiplatformV1NotebookEucConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1NotebookEucConfigOutput) ToGoogleCloudAiplatformV1NotebookEucConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1NotebookEucConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1NotebookEucConfigOutput) ToGoogleCloudAiplatformV1NotebookEucConfigPtrOutput() GoogleCloudAiplatformV1NotebookEucConfigPtrOutput {
	return o.ToGoogleCloudAiplatformV1NotebookEucConfigPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1NotebookEucConfigOutput) ToGoogleCloudAiplatformV1NotebookEucConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1NotebookEucConfigPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1NotebookEucConfig) *GoogleCloudAiplatformV1NotebookEucConfig {
		return &v
	}).(GoogleCloudAiplatformV1NotebookEucConfigPtrOutput)
}

// Input only. Whether EUC is disabled in this NotebookRuntimeTemplate. In proto3, the default value of a boolean is false. In this way, by default EUC will be enabled for NotebookRuntimeTemplate.
func (o GoogleCloudAiplatformV1NotebookEucConfigOutput) EucDisabled() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1NotebookEucConfig) *bool { return v.EucDisabled }).(pulumi.BoolPtrOutput)
}

type GoogleCloudAiplatformV1NotebookEucConfigPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1NotebookEucConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1NotebookEucConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1NotebookEucConfigPtrOutput) ToGoogleCloudAiplatformV1NotebookEucConfigPtrOutput() GoogleCloudAiplatformV1NotebookEucConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1NotebookEucConfigPtrOutput) ToGoogleCloudAiplatformV1NotebookEucConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1NotebookEucConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1NotebookEucConfigPtrOutput) Elem() GoogleCloudAiplatformV1NotebookEucConfigOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1NotebookEucConfig) GoogleCloudAiplatformV1NotebookEucConfig {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1NotebookEucConfig
		return ret
	}).(GoogleCloudAiplatformV1NotebookEucConfigOutput)
}

// Input only. Whether EUC is disabled in this NotebookRuntimeTemplate. In proto3, the default value of a boolean is false. In this way, by default EUC will be enabled for NotebookRuntimeTemplate.
func (o GoogleCloudAiplatformV1NotebookEucConfigPtrOutput) EucDisabled() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1NotebookEucConfig) *bool {
		if v == nil {
			return nil
		}
		return v.EucDisabled
	}).(pulumi.BoolPtrOutput)
}

// The euc configuration of NotebookRuntimeTemplate.
type GoogleCloudAiplatformV1NotebookEucConfigResponse struct {
	// Whether ActAs check is bypassed for service account attached to the VM. If false, we need ActAs check for the default Compute Engine Service account. When a Runtime is created, a VM is allocated using Default Compute Engine Service Account. Any user requesting to use this Runtime requires Service Account User (ActAs) permission over this SA. If true, Runtime owner is using EUC and does not require the above permission as VM no longer use default Compute Engine SA, but a P4SA.
	BypassActasCheck bool `pulumi:"bypassActasCheck"`
	// Input only. Whether EUC is disabled in this NotebookRuntimeTemplate. In proto3, the default value of a boolean is false. In this way, by default EUC will be enabled for NotebookRuntimeTemplate.
	EucDisabled bool `pulumi:"eucDisabled"`
}

// The euc configuration of NotebookRuntimeTemplate.
type GoogleCloudAiplatformV1NotebookEucConfigResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1NotebookEucConfigResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1NotebookEucConfigResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1NotebookEucConfigResponseOutput) ToGoogleCloudAiplatformV1NotebookEucConfigResponseOutput() GoogleCloudAiplatformV1NotebookEucConfigResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1NotebookEucConfigResponseOutput) ToGoogleCloudAiplatformV1NotebookEucConfigResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1NotebookEucConfigResponseOutput {
	return o
}

// Whether ActAs check is bypassed for service account attached to the VM. If false, we need ActAs check for the default Compute Engine Service account. When a Runtime is created, a VM is allocated using Default Compute Engine Service Account. Any user requesting to use this Runtime requires Service Account User (ActAs) permission over this SA. If true, Runtime owner is using EUC and does not require the above permission as VM no longer use default Compute Engine SA, but a P4SA.
func (o GoogleCloudAiplatformV1NotebookEucConfigResponseOutput) BypassActasCheck() pulumi.BoolOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1NotebookEucConfigResponse) bool { return v.BypassActasCheck }).(pulumi.BoolOutput)
}

// Input only. Whether EUC is disabled in this NotebookRuntimeTemplate. In proto3, the default value of a boolean is false. In this way, by default EUC will be enabled for NotebookRuntimeTemplate.
func (o GoogleCloudAiplatformV1NotebookEucConfigResponseOutput) EucDisabled() pulumi.BoolOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1NotebookEucConfigResponse) bool { return v.EucDisabled }).(pulumi.BoolOutput)
}

// The idle shutdown configuration of NotebookRuntimeTemplate, which contains the idle_timeout as required field.
type GoogleCloudAiplatformV1NotebookIdleShutdownConfig struct {
	// Whether Idle Shutdown is disabled in this NotebookRuntimeTemplate.
	IdleShutdownDisabled *bool `pulumi:"idleShutdownDisabled"`
	// Duration is accurate to the second. In Notebook, Idle Timeout is accurate to minute so the range of idle_timeout (second) is: 10 * 60 ~ 1440 * 60.
	IdleTimeout string `pulumi:"idleTimeout"`
}

// GoogleCloudAiplatformV1NotebookIdleShutdownConfigInput is an input type that accepts GoogleCloudAiplatformV1NotebookIdleShutdownConfigArgs and GoogleCloudAiplatformV1NotebookIdleShutdownConfigOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1NotebookIdleShutdownConfigInput` via:
//
//	GoogleCloudAiplatformV1NotebookIdleShutdownConfigArgs{...}
type GoogleCloudAiplatformV1NotebookIdleShutdownConfigInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1NotebookIdleShutdownConfigOutput() GoogleCloudAiplatformV1NotebookIdleShutdownConfigOutput
	ToGoogleCloudAiplatformV1NotebookIdleShutdownConfigOutputWithContext(context.Context) GoogleCloudAiplatformV1NotebookIdleShutdownConfigOutput
}

// The idle shutdown configuration of NotebookRuntimeTemplate, which contains the idle_timeout as required field.
type GoogleCloudAiplatformV1NotebookIdleShutdownConfigArgs struct {
	// Whether Idle Shutdown is disabled in this NotebookRuntimeTemplate.
	IdleShutdownDisabled pulumi.BoolPtrInput `pulumi:"idleShutdownDisabled"`
	// Duration is accurate to the second. In Notebook, Idle Timeout is accurate to minute so the range of idle_timeout (second) is: 10 * 60 ~ 1440 * 60.
	IdleTimeout pulumi.StringInput `pulumi:"idleTimeout"`
}

func (GoogleCloudAiplatformV1NotebookIdleShutdownConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1NotebookIdleShutdownConfig)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1NotebookIdleShutdownConfigArgs) ToGoogleCloudAiplatformV1NotebookIdleShutdownConfigOutput() GoogleCloudAiplatformV1NotebookIdleShutdownConfigOutput {
	return i.ToGoogleCloudAiplatformV1NotebookIdleShutdownConfigOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1NotebookIdleShutdownConfigArgs) ToGoogleCloudAiplatformV1NotebookIdleShutdownConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1NotebookIdleShutdownConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1NotebookIdleShutdownConfigOutput)
}

func (i GoogleCloudAiplatformV1NotebookIdleShutdownConfigArgs) ToGoogleCloudAiplatformV1NotebookIdleShutdownConfigPtrOutput() GoogleCloudAiplatformV1NotebookIdleShutdownConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1NotebookIdleShutdownConfigPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1NotebookIdleShutdownConfigArgs) ToGoogleCloudAiplatformV1NotebookIdleShutdownConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1NotebookIdleShutdownConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1NotebookIdleShutdownConfigOutput).ToGoogleCloudAiplatformV1NotebookIdleShutdownConfigPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1NotebookIdleShutdownConfigPtrInput is an input type that accepts GoogleCloudAiplatformV1NotebookIdleShutdownConfigArgs, GoogleCloudAiplatformV1NotebookIdleShutdownConfigPtr and GoogleCloudAiplatformV1NotebookIdleShutdownConfigPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1NotebookIdleShutdownConfigPtrInput` via:
//
//	        GoogleCloudAiplatformV1NotebookIdleShutdownConfigArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1NotebookIdleShutdownConfigPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1NotebookIdleShutdownConfigPtrOutput() GoogleCloudAiplatformV1NotebookIdleShutdownConfigPtrOutput
	ToGoogleCloudAiplatformV1NotebookIdleShutdownConfigPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1NotebookIdleShutdownConfigPtrOutput
}

type googleCloudAiplatformV1NotebookIdleShutdownConfigPtrType GoogleCloudAiplatformV1NotebookIdleShutdownConfigArgs

func GoogleCloudAiplatformV1NotebookIdleShutdownConfigPtr(v *GoogleCloudAiplatformV1NotebookIdleShutdownConfigArgs) GoogleCloudAiplatformV1NotebookIdleShutdownConfigPtrInput {
	return (*googleCloudAiplatformV1NotebookIdleShutdownConfigPtrType)(v)
}

func (*googleCloudAiplatformV1NotebookIdleShutdownConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1NotebookIdleShutdownConfig)(nil)).Elem()
}

func (i *googleCloudAiplatformV1NotebookIdleShutdownConfigPtrType) ToGoogleCloudAiplatformV1NotebookIdleShutdownConfigPtrOutput() GoogleCloudAiplatformV1NotebookIdleShutdownConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1NotebookIdleShutdownConfigPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1NotebookIdleShutdownConfigPtrType) ToGoogleCloudAiplatformV1NotebookIdleShutdownConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1NotebookIdleShutdownConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1NotebookIdleShutdownConfigPtrOutput)
}

// The idle shutdown configuration of NotebookRuntimeTemplate, which contains the idle_timeout as required field.
type GoogleCloudAiplatformV1NotebookIdleShutdownConfigOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1NotebookIdleShutdownConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1NotebookIdleShutdownConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1NotebookIdleShutdownConfigOutput) ToGoogleCloudAiplatformV1NotebookIdleShutdownConfigOutput() GoogleCloudAiplatformV1NotebookIdleShutdownConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1NotebookIdleShutdownConfigOutput) ToGoogleCloudAiplatformV1NotebookIdleShutdownConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1NotebookIdleShutdownConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1NotebookIdleShutdownConfigOutput) ToGoogleCloudAiplatformV1NotebookIdleShutdownConfigPtrOutput() GoogleCloudAiplatformV1NotebookIdleShutdownConfigPtrOutput {
	return o.ToGoogleCloudAiplatformV1NotebookIdleShutdownConfigPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1NotebookIdleShutdownConfigOutput) ToGoogleCloudAiplatformV1NotebookIdleShutdownConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1NotebookIdleShutdownConfigPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1NotebookIdleShutdownConfig) *GoogleCloudAiplatformV1NotebookIdleShutdownConfig {
		return &v
	}).(GoogleCloudAiplatformV1NotebookIdleShutdownConfigPtrOutput)
}

// Whether Idle Shutdown is disabled in this NotebookRuntimeTemplate.
func (o GoogleCloudAiplatformV1NotebookIdleShutdownConfigOutput) IdleShutdownDisabled() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1NotebookIdleShutdownConfig) *bool { return v.IdleShutdownDisabled }).(pulumi.BoolPtrOutput)
}

// Duration is accurate to the second. In Notebook, Idle Timeout is accurate to minute so the range of idle_timeout (second) is: 10 * 60 ~ 1440 * 60.
func (o GoogleCloudAiplatformV1NotebookIdleShutdownConfigOutput) IdleTimeout() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1NotebookIdleShutdownConfig) string { return v.IdleTimeout }).(pulumi.StringOutput)
}

type GoogleCloudAiplatformV1NotebookIdleShutdownConfigPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1NotebookIdleShutdownConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1NotebookIdleShutdownConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1NotebookIdleShutdownConfigPtrOutput) ToGoogleCloudAiplatformV1NotebookIdleShutdownConfigPtrOutput() GoogleCloudAiplatformV1NotebookIdleShutdownConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1NotebookIdleShutdownConfigPtrOutput) ToGoogleCloudAiplatformV1NotebookIdleShutdownConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1NotebookIdleShutdownConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1NotebookIdleShutdownConfigPtrOutput) Elem() GoogleCloudAiplatformV1NotebookIdleShutdownConfigOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1NotebookIdleShutdownConfig) GoogleCloudAiplatformV1NotebookIdleShutdownConfig {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1NotebookIdleShutdownConfig
		return ret
	}).(GoogleCloudAiplatformV1NotebookIdleShutdownConfigOutput)
}

// Whether Idle Shutdown is disabled in this NotebookRuntimeTemplate.
func (o GoogleCloudAiplatformV1NotebookIdleShutdownConfigPtrOutput) IdleShutdownDisabled() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1NotebookIdleShutdownConfig) *bool {
		if v == nil {
			return nil
		}
		return v.IdleShutdownDisabled
	}).(pulumi.BoolPtrOutput)
}

// Duration is accurate to the second. In Notebook, Idle Timeout is accurate to minute so the range of idle_timeout (second) is: 10 * 60 ~ 1440 * 60.
func (o GoogleCloudAiplatformV1NotebookIdleShutdownConfigPtrOutput) IdleTimeout() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1NotebookIdleShutdownConfig) *string {
		if v == nil {
			return nil
		}
		return &v.IdleTimeout
	}).(pulumi.StringPtrOutput)
}

// The idle shutdown configuration of NotebookRuntimeTemplate, which contains the idle_timeout as required field.
type GoogleCloudAiplatformV1NotebookIdleShutdownConfigResponse struct {
	// Whether Idle Shutdown is disabled in this NotebookRuntimeTemplate.
	IdleShutdownDisabled bool `pulumi:"idleShutdownDisabled"`
	// Duration is accurate to the second. In Notebook, Idle Timeout is accurate to minute so the range of idle_timeout (second) is: 10 * 60 ~ 1440 * 60.
	IdleTimeout string `pulumi:"idleTimeout"`
}

// The idle shutdown configuration of NotebookRuntimeTemplate, which contains the idle_timeout as required field.
type GoogleCloudAiplatformV1NotebookIdleShutdownConfigResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1NotebookIdleShutdownConfigResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1NotebookIdleShutdownConfigResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1NotebookIdleShutdownConfigResponseOutput) ToGoogleCloudAiplatformV1NotebookIdleShutdownConfigResponseOutput() GoogleCloudAiplatformV1NotebookIdleShutdownConfigResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1NotebookIdleShutdownConfigResponseOutput) ToGoogleCloudAiplatformV1NotebookIdleShutdownConfigResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1NotebookIdleShutdownConfigResponseOutput {
	return o
}

// Whether Idle Shutdown is disabled in this NotebookRuntimeTemplate.
func (o GoogleCloudAiplatformV1NotebookIdleShutdownConfigResponseOutput) IdleShutdownDisabled() pulumi.BoolOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1NotebookIdleShutdownConfigResponse) bool { return v.IdleShutdownDisabled }).(pulumi.BoolOutput)
}

// Duration is accurate to the second. In Notebook, Idle Timeout is accurate to minute so the range of idle_timeout (second) is: 10 * 60 ~ 1440 * 60.
func (o GoogleCloudAiplatformV1NotebookIdleShutdownConfigResponseOutput) IdleTimeout() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1NotebookIdleShutdownConfigResponse) string { return v.IdleTimeout }).(pulumi.StringOutput)
}

// Represents the spec of persistent disk options.
type GoogleCloudAiplatformV1PersistentDiskSpec struct {
	// Size in GB of the disk (default is 100GB).
	DiskSizeGb *string `pulumi:"diskSizeGb"`
	// Type of the disk (default is "pd-standard"). Valid values: "pd-ssd" (Persistent Disk Solid State Drive) "pd-standard" (Persistent Disk Hard Disk Drive) "pd-balanced" (Balanced Persistent Disk) "pd-extreme" (Extreme Persistent Disk)
	DiskType *string `pulumi:"diskType"`
}

// GoogleCloudAiplatformV1PersistentDiskSpecInput is an input type that accepts GoogleCloudAiplatformV1PersistentDiskSpecArgs and GoogleCloudAiplatformV1PersistentDiskSpecOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1PersistentDiskSpecInput` via:
//
//	GoogleCloudAiplatformV1PersistentDiskSpecArgs{...}
type GoogleCloudAiplatformV1PersistentDiskSpecInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1PersistentDiskSpecOutput() GoogleCloudAiplatformV1PersistentDiskSpecOutput
	ToGoogleCloudAiplatformV1PersistentDiskSpecOutputWithContext(context.Context) GoogleCloudAiplatformV1PersistentDiskSpecOutput
}

// Represents the spec of persistent disk options.
type GoogleCloudAiplatformV1PersistentDiskSpecArgs struct {
	// Size in GB of the disk (default is 100GB).
	DiskSizeGb pulumi.StringPtrInput `pulumi:"diskSizeGb"`
	// Type of the disk (default is "pd-standard"). Valid values: "pd-ssd" (Persistent Disk Solid State Drive) "pd-standard" (Persistent Disk Hard Disk Drive) "pd-balanced" (Balanced Persistent Disk) "pd-extreme" (Extreme Persistent Disk)
	DiskType pulumi.StringPtrInput `pulumi:"diskType"`
}

func (GoogleCloudAiplatformV1PersistentDiskSpecArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1PersistentDiskSpec)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1PersistentDiskSpecArgs) ToGoogleCloudAiplatformV1PersistentDiskSpecOutput() GoogleCloudAiplatformV1PersistentDiskSpecOutput {
	return i.ToGoogleCloudAiplatformV1PersistentDiskSpecOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1PersistentDiskSpecArgs) ToGoogleCloudAiplatformV1PersistentDiskSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1PersistentDiskSpecOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1PersistentDiskSpecOutput)
}

func (i GoogleCloudAiplatformV1PersistentDiskSpecArgs) ToGoogleCloudAiplatformV1PersistentDiskSpecPtrOutput() GoogleCloudAiplatformV1PersistentDiskSpecPtrOutput {
	return i.ToGoogleCloudAiplatformV1PersistentDiskSpecPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1PersistentDiskSpecArgs) ToGoogleCloudAiplatformV1PersistentDiskSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1PersistentDiskSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1PersistentDiskSpecOutput).ToGoogleCloudAiplatformV1PersistentDiskSpecPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1PersistentDiskSpecPtrInput is an input type that accepts GoogleCloudAiplatformV1PersistentDiskSpecArgs, GoogleCloudAiplatformV1PersistentDiskSpecPtr and GoogleCloudAiplatformV1PersistentDiskSpecPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1PersistentDiskSpecPtrInput` via:
//
//	        GoogleCloudAiplatformV1PersistentDiskSpecArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1PersistentDiskSpecPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1PersistentDiskSpecPtrOutput() GoogleCloudAiplatformV1PersistentDiskSpecPtrOutput
	ToGoogleCloudAiplatformV1PersistentDiskSpecPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1PersistentDiskSpecPtrOutput
}

type googleCloudAiplatformV1PersistentDiskSpecPtrType GoogleCloudAiplatformV1PersistentDiskSpecArgs

func GoogleCloudAiplatformV1PersistentDiskSpecPtr(v *GoogleCloudAiplatformV1PersistentDiskSpecArgs) GoogleCloudAiplatformV1PersistentDiskSpecPtrInput {
	return (*googleCloudAiplatformV1PersistentDiskSpecPtrType)(v)
}

func (*googleCloudAiplatformV1PersistentDiskSpecPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1PersistentDiskSpec)(nil)).Elem()
}

func (i *googleCloudAiplatformV1PersistentDiskSpecPtrType) ToGoogleCloudAiplatformV1PersistentDiskSpecPtrOutput() GoogleCloudAiplatformV1PersistentDiskSpecPtrOutput {
	return i.ToGoogleCloudAiplatformV1PersistentDiskSpecPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1PersistentDiskSpecPtrType) ToGoogleCloudAiplatformV1PersistentDiskSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1PersistentDiskSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1PersistentDiskSpecPtrOutput)
}

// Represents the spec of persistent disk options.
type GoogleCloudAiplatformV1PersistentDiskSpecOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1PersistentDiskSpecOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1PersistentDiskSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1PersistentDiskSpecOutput) ToGoogleCloudAiplatformV1PersistentDiskSpecOutput() GoogleCloudAiplatformV1PersistentDiskSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1PersistentDiskSpecOutput) ToGoogleCloudAiplatformV1PersistentDiskSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1PersistentDiskSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1PersistentDiskSpecOutput) ToGoogleCloudAiplatformV1PersistentDiskSpecPtrOutput() GoogleCloudAiplatformV1PersistentDiskSpecPtrOutput {
	return o.ToGoogleCloudAiplatformV1PersistentDiskSpecPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1PersistentDiskSpecOutput) ToGoogleCloudAiplatformV1PersistentDiskSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1PersistentDiskSpecPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1PersistentDiskSpec) *GoogleCloudAiplatformV1PersistentDiskSpec {
		return &v
	}).(GoogleCloudAiplatformV1PersistentDiskSpecPtrOutput)
}

// Size in GB of the disk (default is 100GB).
func (o GoogleCloudAiplatformV1PersistentDiskSpecOutput) DiskSizeGb() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PersistentDiskSpec) *string { return v.DiskSizeGb }).(pulumi.StringPtrOutput)
}

// Type of the disk (default is "pd-standard"). Valid values: "pd-ssd" (Persistent Disk Solid State Drive) "pd-standard" (Persistent Disk Hard Disk Drive) "pd-balanced" (Balanced Persistent Disk) "pd-extreme" (Extreme Persistent Disk)
func (o GoogleCloudAiplatformV1PersistentDiskSpecOutput) DiskType() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PersistentDiskSpec) *string { return v.DiskType }).(pulumi.StringPtrOutput)
}

type GoogleCloudAiplatformV1PersistentDiskSpecPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1PersistentDiskSpecPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1PersistentDiskSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1PersistentDiskSpecPtrOutput) ToGoogleCloudAiplatformV1PersistentDiskSpecPtrOutput() GoogleCloudAiplatformV1PersistentDiskSpecPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1PersistentDiskSpecPtrOutput) ToGoogleCloudAiplatformV1PersistentDiskSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1PersistentDiskSpecPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1PersistentDiskSpecPtrOutput) Elem() GoogleCloudAiplatformV1PersistentDiskSpecOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1PersistentDiskSpec) GoogleCloudAiplatformV1PersistentDiskSpec {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1PersistentDiskSpec
		return ret
	}).(GoogleCloudAiplatformV1PersistentDiskSpecOutput)
}

// Size in GB of the disk (default is 100GB).
func (o GoogleCloudAiplatformV1PersistentDiskSpecPtrOutput) DiskSizeGb() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1PersistentDiskSpec) *string {
		if v == nil {
			return nil
		}
		return v.DiskSizeGb
	}).(pulumi.StringPtrOutput)
}

// Type of the disk (default is "pd-standard"). Valid values: "pd-ssd" (Persistent Disk Solid State Drive) "pd-standard" (Persistent Disk Hard Disk Drive) "pd-balanced" (Balanced Persistent Disk) "pd-extreme" (Extreme Persistent Disk)
func (o GoogleCloudAiplatformV1PersistentDiskSpecPtrOutput) DiskType() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1PersistentDiskSpec) *string {
		if v == nil {
			return nil
		}
		return v.DiskType
	}).(pulumi.StringPtrOutput)
}

// Represents the spec of persistent disk options.
type GoogleCloudAiplatformV1PersistentDiskSpecResponse struct {
	// Size in GB of the disk (default is 100GB).
	DiskSizeGb string `pulumi:"diskSizeGb"`
	// Type of the disk (default is "pd-standard"). Valid values: "pd-ssd" (Persistent Disk Solid State Drive) "pd-standard" (Persistent Disk Hard Disk Drive) "pd-balanced" (Balanced Persistent Disk) "pd-extreme" (Extreme Persistent Disk)
	DiskType string `pulumi:"diskType"`
}

// Represents the spec of persistent disk options.
type GoogleCloudAiplatformV1PersistentDiskSpecResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1PersistentDiskSpecResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1PersistentDiskSpecResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1PersistentDiskSpecResponseOutput) ToGoogleCloudAiplatformV1PersistentDiskSpecResponseOutput() GoogleCloudAiplatformV1PersistentDiskSpecResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1PersistentDiskSpecResponseOutput) ToGoogleCloudAiplatformV1PersistentDiskSpecResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1PersistentDiskSpecResponseOutput {
	return o
}

// Size in GB of the disk (default is 100GB).
func (o GoogleCloudAiplatformV1PersistentDiskSpecResponseOutput) DiskSizeGb() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PersistentDiskSpecResponse) string { return v.DiskSizeGb }).(pulumi.StringOutput)
}

// Type of the disk (default is "pd-standard"). Valid values: "pd-ssd" (Persistent Disk Solid State Drive) "pd-standard" (Persistent Disk Hard Disk Drive) "pd-balanced" (Balanced Persistent Disk) "pd-extreme" (Extreme Persistent Disk)
func (o GoogleCloudAiplatformV1PersistentDiskSpecResponseOutput) DiskType() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PersistentDiskSpecResponse) string { return v.DiskType }).(pulumi.StringOutput)
}

// An instance of a machine learning PipelineJob.
type GoogleCloudAiplatformV1PipelineJob struct {
	// The display name of the Pipeline. The name can be up to 128 characters long and can consist of any UTF-8 characters.
	DisplayName *string `pulumi:"displayName"`
	// Customer-managed encryption key spec for a pipelineJob. If set, this PipelineJob and all of its sub-resources will be secured by this key.
	EncryptionSpec *GoogleCloudAiplatformV1EncryptionSpec `pulumi:"encryptionSpec"`
	// The labels with user-defined metadata to organize PipelineJob. Label keys and values can be no longer than 64 characters (Unicode codepoints), can only contain lowercase letters, numeric characters, underscores and dashes. International characters are allowed. See https://goo.gl/xmQnxf for more information and examples of labels. Note there is some reserved label key for Vertex AI Pipelines. - `vertex-ai-pipelines-run-billing-id`, user set value will get overrided.
	Labels map[string]string `pulumi:"labels"`
	// The full name of the Compute Engine [network](/compute/docs/networks-and-firewalls#networks) to which the Pipeline Job's workload should be peered. For example, `projects/12345/global/networks/myVPC`. [Format](/compute/docs/reference/rest/v1/networks/insert) is of the form `projects/{project}/global/networks/{network}`. Where {project} is a project number, as in `12345`, and {network} is a network name. Private services access must already be configured for the network. Pipeline job will apply the network configuration to the Google Cloud resources being launched, if applied, such as Vertex AI Training or Dataflow job. If left unspecified, the workload is not peered with any network.
	Network *string `pulumi:"network"`
	// The spec of the pipeline.
	PipelineSpec map[string]interface{} `pulumi:"pipelineSpec"`
	// A list of names for the reserved ip ranges under the VPC network that can be used for this Pipeline Job's workload. If set, we will deploy the Pipeline Job's workload within the provided ip ranges. Otherwise, the job will be deployed to any ip ranges under the provided VPC network. Example: ['vertex-ai-ip-range'].
	ReservedIpRanges []string `pulumi:"reservedIpRanges"`
	// Runtime config of the pipeline.
	RuntimeConfig *GoogleCloudAiplatformV1PipelineJobRuntimeConfig `pulumi:"runtimeConfig"`
	// The service account that the pipeline workload runs as. If not specified, the Compute Engine default service account in the project will be used. See https://cloud.google.com/compute/docs/access/service-accounts#default_service_account Users starting the pipeline must have the `iam.serviceAccounts.actAs` permission on this service account.
	ServiceAccount *string `pulumi:"serviceAccount"`
	// A template uri from where the PipelineJob.pipeline_spec, if empty, will be downloaded. Currently, only uri from Vertex Template Registry & Gallery is supported. Reference to https://cloud.google.com/vertex-ai/docs/pipelines/create-pipeline-template.
	TemplateUri *string `pulumi:"templateUri"`
}

// GoogleCloudAiplatformV1PipelineJobInput is an input type that accepts GoogleCloudAiplatformV1PipelineJobArgs and GoogleCloudAiplatformV1PipelineJobOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1PipelineJobInput` via:
//
//	GoogleCloudAiplatformV1PipelineJobArgs{...}
type GoogleCloudAiplatformV1PipelineJobInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1PipelineJobOutput() GoogleCloudAiplatformV1PipelineJobOutput
	ToGoogleCloudAiplatformV1PipelineJobOutputWithContext(context.Context) GoogleCloudAiplatformV1PipelineJobOutput
}

// An instance of a machine learning PipelineJob.
type GoogleCloudAiplatformV1PipelineJobArgs struct {
	// The display name of the Pipeline. The name can be up to 128 characters long and can consist of any UTF-8 characters.
	DisplayName pulumi.StringPtrInput `pulumi:"displayName"`
	// Customer-managed encryption key spec for a pipelineJob. If set, this PipelineJob and all of its sub-resources will be secured by this key.
	EncryptionSpec GoogleCloudAiplatformV1EncryptionSpecPtrInput `pulumi:"encryptionSpec"`
	// The labels with user-defined metadata to organize PipelineJob. Label keys and values can be no longer than 64 characters (Unicode codepoints), can only contain lowercase letters, numeric characters, underscores and dashes. International characters are allowed. See https://goo.gl/xmQnxf for more information and examples of labels. Note there is some reserved label key for Vertex AI Pipelines. - `vertex-ai-pipelines-run-billing-id`, user set value will get overrided.
	Labels pulumi.StringMapInput `pulumi:"labels"`
	// The full name of the Compute Engine [network](/compute/docs/networks-and-firewalls#networks) to which the Pipeline Job's workload should be peered. For example, `projects/12345/global/networks/myVPC`. [Format](/compute/docs/reference/rest/v1/networks/insert) is of the form `projects/{project}/global/networks/{network}`. Where {project} is a project number, as in `12345`, and {network} is a network name. Private services access must already be configured for the network. Pipeline job will apply the network configuration to the Google Cloud resources being launched, if applied, such as Vertex AI Training or Dataflow job. If left unspecified, the workload is not peered with any network.
	Network pulumi.StringPtrInput `pulumi:"network"`
	// The spec of the pipeline.
	PipelineSpec pulumi.MapInput `pulumi:"pipelineSpec"`
	// A list of names for the reserved ip ranges under the VPC network that can be used for this Pipeline Job's workload. If set, we will deploy the Pipeline Job's workload within the provided ip ranges. Otherwise, the job will be deployed to any ip ranges under the provided VPC network. Example: ['vertex-ai-ip-range'].
	ReservedIpRanges pulumi.StringArrayInput `pulumi:"reservedIpRanges"`
	// Runtime config of the pipeline.
	RuntimeConfig GoogleCloudAiplatformV1PipelineJobRuntimeConfigPtrInput `pulumi:"runtimeConfig"`
	// The service account that the pipeline workload runs as. If not specified, the Compute Engine default service account in the project will be used. See https://cloud.google.com/compute/docs/access/service-accounts#default_service_account Users starting the pipeline must have the `iam.serviceAccounts.actAs` permission on this service account.
	ServiceAccount pulumi.StringPtrInput `pulumi:"serviceAccount"`
	// A template uri from where the PipelineJob.pipeline_spec, if empty, will be downloaded. Currently, only uri from Vertex Template Registry & Gallery is supported. Reference to https://cloud.google.com/vertex-ai/docs/pipelines/create-pipeline-template.
	TemplateUri pulumi.StringPtrInput `pulumi:"templateUri"`
}

func (GoogleCloudAiplatformV1PipelineJobArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1PipelineJob)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1PipelineJobArgs) ToGoogleCloudAiplatformV1PipelineJobOutput() GoogleCloudAiplatformV1PipelineJobOutput {
	return i.ToGoogleCloudAiplatformV1PipelineJobOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1PipelineJobArgs) ToGoogleCloudAiplatformV1PipelineJobOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1PipelineJobOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1PipelineJobOutput)
}

func (i GoogleCloudAiplatformV1PipelineJobArgs) ToGoogleCloudAiplatformV1PipelineJobPtrOutput() GoogleCloudAiplatformV1PipelineJobPtrOutput {
	return i.ToGoogleCloudAiplatformV1PipelineJobPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1PipelineJobArgs) ToGoogleCloudAiplatformV1PipelineJobPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1PipelineJobPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1PipelineJobOutput).ToGoogleCloudAiplatformV1PipelineJobPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1PipelineJobPtrInput is an input type that accepts GoogleCloudAiplatformV1PipelineJobArgs, GoogleCloudAiplatformV1PipelineJobPtr and GoogleCloudAiplatformV1PipelineJobPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1PipelineJobPtrInput` via:
//
//	        GoogleCloudAiplatformV1PipelineJobArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1PipelineJobPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1PipelineJobPtrOutput() GoogleCloudAiplatformV1PipelineJobPtrOutput
	ToGoogleCloudAiplatformV1PipelineJobPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1PipelineJobPtrOutput
}

type googleCloudAiplatformV1PipelineJobPtrType GoogleCloudAiplatformV1PipelineJobArgs

func GoogleCloudAiplatformV1PipelineJobPtr(v *GoogleCloudAiplatformV1PipelineJobArgs) GoogleCloudAiplatformV1PipelineJobPtrInput {
	return (*googleCloudAiplatformV1PipelineJobPtrType)(v)
}

func (*googleCloudAiplatformV1PipelineJobPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1PipelineJob)(nil)).Elem()
}

func (i *googleCloudAiplatformV1PipelineJobPtrType) ToGoogleCloudAiplatformV1PipelineJobPtrOutput() GoogleCloudAiplatformV1PipelineJobPtrOutput {
	return i.ToGoogleCloudAiplatformV1PipelineJobPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1PipelineJobPtrType) ToGoogleCloudAiplatformV1PipelineJobPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1PipelineJobPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1PipelineJobPtrOutput)
}

// An instance of a machine learning PipelineJob.
type GoogleCloudAiplatformV1PipelineJobOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1PipelineJobOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1PipelineJob)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1PipelineJobOutput) ToGoogleCloudAiplatformV1PipelineJobOutput() GoogleCloudAiplatformV1PipelineJobOutput {
	return o
}

func (o GoogleCloudAiplatformV1PipelineJobOutput) ToGoogleCloudAiplatformV1PipelineJobOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1PipelineJobOutput {
	return o
}

func (o GoogleCloudAiplatformV1PipelineJobOutput) ToGoogleCloudAiplatformV1PipelineJobPtrOutput() GoogleCloudAiplatformV1PipelineJobPtrOutput {
	return o.ToGoogleCloudAiplatformV1PipelineJobPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1PipelineJobOutput) ToGoogleCloudAiplatformV1PipelineJobPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1PipelineJobPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1PipelineJob) *GoogleCloudAiplatformV1PipelineJob {
		return &v
	}).(GoogleCloudAiplatformV1PipelineJobPtrOutput)
}

// The display name of the Pipeline. The name can be up to 128 characters long and can consist of any UTF-8 characters.
func (o GoogleCloudAiplatformV1PipelineJobOutput) DisplayName() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PipelineJob) *string { return v.DisplayName }).(pulumi.StringPtrOutput)
}

// Customer-managed encryption key spec for a pipelineJob. If set, this PipelineJob and all of its sub-resources will be secured by this key.
func (o GoogleCloudAiplatformV1PipelineJobOutput) EncryptionSpec() GoogleCloudAiplatformV1EncryptionSpecPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PipelineJob) *GoogleCloudAiplatformV1EncryptionSpec {
		return v.EncryptionSpec
	}).(GoogleCloudAiplatformV1EncryptionSpecPtrOutput)
}

// The labels with user-defined metadata to organize PipelineJob. Label keys and values can be no longer than 64 characters (Unicode codepoints), can only contain lowercase letters, numeric characters, underscores and dashes. International characters are allowed. See https://goo.gl/xmQnxf for more information and examples of labels. Note there is some reserved label key for Vertex AI Pipelines. - `vertex-ai-pipelines-run-billing-id`, user set value will get overrided.
func (o GoogleCloudAiplatformV1PipelineJobOutput) Labels() pulumi.StringMapOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PipelineJob) map[string]string { return v.Labels }).(pulumi.StringMapOutput)
}

// The full name of the Compute Engine [network](/compute/docs/networks-and-firewalls#networks) to which the Pipeline Job's workload should be peered. For example, `projects/12345/global/networks/myVPC`. [Format](/compute/docs/reference/rest/v1/networks/insert) is of the form `projects/{project}/global/networks/{network}`. Where {project} is a project number, as in `12345`, and {network} is a network name. Private services access must already be configured for the network. Pipeline job will apply the network configuration to the Google Cloud resources being launched, if applied, such as Vertex AI Training or Dataflow job. If left unspecified, the workload is not peered with any network.
func (o GoogleCloudAiplatformV1PipelineJobOutput) Network() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PipelineJob) *string { return v.Network }).(pulumi.StringPtrOutput)
}

// The spec of the pipeline.
func (o GoogleCloudAiplatformV1PipelineJobOutput) PipelineSpec() pulumi.MapOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PipelineJob) map[string]interface{} { return v.PipelineSpec }).(pulumi.MapOutput)
}

// A list of names for the reserved ip ranges under the VPC network that can be used for this Pipeline Job's workload. If set, we will deploy the Pipeline Job's workload within the provided ip ranges. Otherwise, the job will be deployed to any ip ranges under the provided VPC network. Example: ['vertex-ai-ip-range'].
func (o GoogleCloudAiplatformV1PipelineJobOutput) ReservedIpRanges() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PipelineJob) []string { return v.ReservedIpRanges }).(pulumi.StringArrayOutput)
}

// Runtime config of the pipeline.
func (o GoogleCloudAiplatformV1PipelineJobOutput) RuntimeConfig() GoogleCloudAiplatformV1PipelineJobRuntimeConfigPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PipelineJob) *GoogleCloudAiplatformV1PipelineJobRuntimeConfig {
		return v.RuntimeConfig
	}).(GoogleCloudAiplatformV1PipelineJobRuntimeConfigPtrOutput)
}

// The service account that the pipeline workload runs as. If not specified, the Compute Engine default service account in the project will be used. See https://cloud.google.com/compute/docs/access/service-accounts#default_service_account Users starting the pipeline must have the `iam.serviceAccounts.actAs` permission on this service account.
func (o GoogleCloudAiplatformV1PipelineJobOutput) ServiceAccount() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PipelineJob) *string { return v.ServiceAccount }).(pulumi.StringPtrOutput)
}

// A template uri from where the PipelineJob.pipeline_spec, if empty, will be downloaded. Currently, only uri from Vertex Template Registry & Gallery is supported. Reference to https://cloud.google.com/vertex-ai/docs/pipelines/create-pipeline-template.
func (o GoogleCloudAiplatformV1PipelineJobOutput) TemplateUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PipelineJob) *string { return v.TemplateUri }).(pulumi.StringPtrOutput)
}

type GoogleCloudAiplatformV1PipelineJobPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1PipelineJobPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1PipelineJob)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1PipelineJobPtrOutput) ToGoogleCloudAiplatformV1PipelineJobPtrOutput() GoogleCloudAiplatformV1PipelineJobPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1PipelineJobPtrOutput) ToGoogleCloudAiplatformV1PipelineJobPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1PipelineJobPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1PipelineJobPtrOutput) Elem() GoogleCloudAiplatformV1PipelineJobOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1PipelineJob) GoogleCloudAiplatformV1PipelineJob {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1PipelineJob
		return ret
	}).(GoogleCloudAiplatformV1PipelineJobOutput)
}

// The display name of the Pipeline. The name can be up to 128 characters long and can consist of any UTF-8 characters.
func (o GoogleCloudAiplatformV1PipelineJobPtrOutput) DisplayName() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1PipelineJob) *string {
		if v == nil {
			return nil
		}
		return v.DisplayName
	}).(pulumi.StringPtrOutput)
}

// Customer-managed encryption key spec for a pipelineJob. If set, this PipelineJob and all of its sub-resources will be secured by this key.
func (o GoogleCloudAiplatformV1PipelineJobPtrOutput) EncryptionSpec() GoogleCloudAiplatformV1EncryptionSpecPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1PipelineJob) *GoogleCloudAiplatformV1EncryptionSpec {
		if v == nil {
			return nil
		}
		return v.EncryptionSpec
	}).(GoogleCloudAiplatformV1EncryptionSpecPtrOutput)
}

// The labels with user-defined metadata to organize PipelineJob. Label keys and values can be no longer than 64 characters (Unicode codepoints), can only contain lowercase letters, numeric characters, underscores and dashes. International characters are allowed. See https://goo.gl/xmQnxf for more information and examples of labels. Note there is some reserved label key for Vertex AI Pipelines. - `vertex-ai-pipelines-run-billing-id`, user set value will get overrided.
func (o GoogleCloudAiplatformV1PipelineJobPtrOutput) Labels() pulumi.StringMapOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1PipelineJob) map[string]string {
		if v == nil {
			return nil
		}
		return v.Labels
	}).(pulumi.StringMapOutput)
}

// The full name of the Compute Engine [network](/compute/docs/networks-and-firewalls#networks) to which the Pipeline Job's workload should be peered. For example, `projects/12345/global/networks/myVPC`. [Format](/compute/docs/reference/rest/v1/networks/insert) is of the form `projects/{project}/global/networks/{network}`. Where {project} is a project number, as in `12345`, and {network} is a network name. Private services access must already be configured for the network. Pipeline job will apply the network configuration to the Google Cloud resources being launched, if applied, such as Vertex AI Training or Dataflow job. If left unspecified, the workload is not peered with any network.
func (o GoogleCloudAiplatformV1PipelineJobPtrOutput) Network() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1PipelineJob) *string {
		if v == nil {
			return nil
		}
		return v.Network
	}).(pulumi.StringPtrOutput)
}

// The spec of the pipeline.
func (o GoogleCloudAiplatformV1PipelineJobPtrOutput) PipelineSpec() pulumi.MapOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1PipelineJob) map[string]interface{} {
		if v == nil {
			return nil
		}
		return v.PipelineSpec
	}).(pulumi.MapOutput)
}

// A list of names for the reserved ip ranges under the VPC network that can be used for this Pipeline Job's workload. If set, we will deploy the Pipeline Job's workload within the provided ip ranges. Otherwise, the job will be deployed to any ip ranges under the provided VPC network. Example: ['vertex-ai-ip-range'].
func (o GoogleCloudAiplatformV1PipelineJobPtrOutput) ReservedIpRanges() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1PipelineJob) []string {
		if v == nil {
			return nil
		}
		return v.ReservedIpRanges
	}).(pulumi.StringArrayOutput)
}

// Runtime config of the pipeline.
func (o GoogleCloudAiplatformV1PipelineJobPtrOutput) RuntimeConfig() GoogleCloudAiplatformV1PipelineJobRuntimeConfigPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1PipelineJob) *GoogleCloudAiplatformV1PipelineJobRuntimeConfig {
		if v == nil {
			return nil
		}
		return v.RuntimeConfig
	}).(GoogleCloudAiplatformV1PipelineJobRuntimeConfigPtrOutput)
}

// The service account that the pipeline workload runs as. If not specified, the Compute Engine default service account in the project will be used. See https://cloud.google.com/compute/docs/access/service-accounts#default_service_account Users starting the pipeline must have the `iam.serviceAccounts.actAs` permission on this service account.
func (o GoogleCloudAiplatformV1PipelineJobPtrOutput) ServiceAccount() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1PipelineJob) *string {
		if v == nil {
			return nil
		}
		return v.ServiceAccount
	}).(pulumi.StringPtrOutput)
}

// A template uri from where the PipelineJob.pipeline_spec, if empty, will be downloaded. Currently, only uri from Vertex Template Registry & Gallery is supported. Reference to https://cloud.google.com/vertex-ai/docs/pipelines/create-pipeline-template.
func (o GoogleCloudAiplatformV1PipelineJobPtrOutput) TemplateUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1PipelineJob) *string {
		if v == nil {
			return nil
		}
		return v.TemplateUri
	}).(pulumi.StringPtrOutput)
}

// The runtime detail of PipelineJob.
type GoogleCloudAiplatformV1PipelineJobDetailResponse struct {
	// The context of the pipeline.
	PipelineContext GoogleCloudAiplatformV1ContextResponse `pulumi:"pipelineContext"`
	// The context of the current pipeline run.
	PipelineRunContext GoogleCloudAiplatformV1ContextResponse `pulumi:"pipelineRunContext"`
	// The runtime details of the tasks under the pipeline.
	TaskDetails []GoogleCloudAiplatformV1PipelineTaskDetailResponse `pulumi:"taskDetails"`
}

// The runtime detail of PipelineJob.
type GoogleCloudAiplatformV1PipelineJobDetailResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1PipelineJobDetailResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1PipelineJobDetailResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1PipelineJobDetailResponseOutput) ToGoogleCloudAiplatformV1PipelineJobDetailResponseOutput() GoogleCloudAiplatformV1PipelineJobDetailResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1PipelineJobDetailResponseOutput) ToGoogleCloudAiplatformV1PipelineJobDetailResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1PipelineJobDetailResponseOutput {
	return o
}

// The context of the pipeline.
func (o GoogleCloudAiplatformV1PipelineJobDetailResponseOutput) PipelineContext() GoogleCloudAiplatformV1ContextResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PipelineJobDetailResponse) GoogleCloudAiplatformV1ContextResponse {
		return v.PipelineContext
	}).(GoogleCloudAiplatformV1ContextResponseOutput)
}

// The context of the current pipeline run.
func (o GoogleCloudAiplatformV1PipelineJobDetailResponseOutput) PipelineRunContext() GoogleCloudAiplatformV1ContextResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PipelineJobDetailResponse) GoogleCloudAiplatformV1ContextResponse {
		return v.PipelineRunContext
	}).(GoogleCloudAiplatformV1ContextResponseOutput)
}

// The runtime details of the tasks under the pipeline.
func (o GoogleCloudAiplatformV1PipelineJobDetailResponseOutput) TaskDetails() GoogleCloudAiplatformV1PipelineTaskDetailResponseArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PipelineJobDetailResponse) []GoogleCloudAiplatformV1PipelineTaskDetailResponse {
		return v.TaskDetails
	}).(GoogleCloudAiplatformV1PipelineTaskDetailResponseArrayOutput)
}

// An instance of a machine learning PipelineJob.
type GoogleCloudAiplatformV1PipelineJobResponse struct {
	// Pipeline creation time.
	CreateTime string `pulumi:"createTime"`
	// The display name of the Pipeline. The name can be up to 128 characters long and can consist of any UTF-8 characters.
	DisplayName string `pulumi:"displayName"`
	// Customer-managed encryption key spec for a pipelineJob. If set, this PipelineJob and all of its sub-resources will be secured by this key.
	EncryptionSpec GoogleCloudAiplatformV1EncryptionSpecResponse `pulumi:"encryptionSpec"`
	// Pipeline end time.
	EndTime string `pulumi:"endTime"`
	// The error that occurred during pipeline execution. Only populated when the pipeline's state is FAILED or CANCELLED.
	Error GoogleRpcStatusResponse `pulumi:"error"`
	// The details of pipeline run. Not available in the list view.
	JobDetail GoogleCloudAiplatformV1PipelineJobDetailResponse `pulumi:"jobDetail"`
	// The labels with user-defined metadata to organize PipelineJob. Label keys and values can be no longer than 64 characters (Unicode codepoints), can only contain lowercase letters, numeric characters, underscores and dashes. International characters are allowed. See https://goo.gl/xmQnxf for more information and examples of labels. Note there is some reserved label key for Vertex AI Pipelines. - `vertex-ai-pipelines-run-billing-id`, user set value will get overrided.
	Labels map[string]string `pulumi:"labels"`
	// The resource name of the PipelineJob.
	Name string `pulumi:"name"`
	// The full name of the Compute Engine [network](/compute/docs/networks-and-firewalls#networks) to which the Pipeline Job's workload should be peered. For example, `projects/12345/global/networks/myVPC`. [Format](/compute/docs/reference/rest/v1/networks/insert) is of the form `projects/{project}/global/networks/{network}`. Where {project} is a project number, as in `12345`, and {network} is a network name. Private services access must already be configured for the network. Pipeline job will apply the network configuration to the Google Cloud resources being launched, if applied, such as Vertex AI Training or Dataflow job. If left unspecified, the workload is not peered with any network.
	Network string `pulumi:"network"`
	// The spec of the pipeline.
	PipelineSpec map[string]interface{} `pulumi:"pipelineSpec"`
	// A list of names for the reserved ip ranges under the VPC network that can be used for this Pipeline Job's workload. If set, we will deploy the Pipeline Job's workload within the provided ip ranges. Otherwise, the job will be deployed to any ip ranges under the provided VPC network. Example: ['vertex-ai-ip-range'].
	ReservedIpRanges []string `pulumi:"reservedIpRanges"`
	// Runtime config of the pipeline.
	RuntimeConfig GoogleCloudAiplatformV1PipelineJobRuntimeConfigResponse `pulumi:"runtimeConfig"`
	// The schedule resource name. Only returned if the Pipeline is created by Schedule API.
	ScheduleName string `pulumi:"scheduleName"`
	// The service account that the pipeline workload runs as. If not specified, the Compute Engine default service account in the project will be used. See https://cloud.google.com/compute/docs/access/service-accounts#default_service_account Users starting the pipeline must have the `iam.serviceAccounts.actAs` permission on this service account.
	ServiceAccount string `pulumi:"serviceAccount"`
	// Pipeline start time.
	StartTime string `pulumi:"startTime"`
	// The detailed state of the job.
	State string `pulumi:"state"`
	// Pipeline template metadata. Will fill up fields if PipelineJob.template_uri is from supported template registry.
	TemplateMetadata GoogleCloudAiplatformV1PipelineTemplateMetadataResponse `pulumi:"templateMetadata"`
	// A template uri from where the PipelineJob.pipeline_spec, if empty, will be downloaded. Currently, only uri from Vertex Template Registry & Gallery is supported. Reference to https://cloud.google.com/vertex-ai/docs/pipelines/create-pipeline-template.
	TemplateUri string `pulumi:"templateUri"`
	// Timestamp when this PipelineJob was most recently updated.
	UpdateTime string `pulumi:"updateTime"`
}

// An instance of a machine learning PipelineJob.
type GoogleCloudAiplatformV1PipelineJobResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1PipelineJobResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1PipelineJobResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1PipelineJobResponseOutput) ToGoogleCloudAiplatformV1PipelineJobResponseOutput() GoogleCloudAiplatformV1PipelineJobResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1PipelineJobResponseOutput) ToGoogleCloudAiplatformV1PipelineJobResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1PipelineJobResponseOutput {
	return o
}

// Pipeline creation time.
func (o GoogleCloudAiplatformV1PipelineJobResponseOutput) CreateTime() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PipelineJobResponse) string { return v.CreateTime }).(pulumi.StringOutput)
}

// The display name of the Pipeline. The name can be up to 128 characters long and can consist of any UTF-8 characters.
func (o GoogleCloudAiplatformV1PipelineJobResponseOutput) DisplayName() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PipelineJobResponse) string { return v.DisplayName }).(pulumi.StringOutput)
}

// Customer-managed encryption key spec for a pipelineJob. If set, this PipelineJob and all of its sub-resources will be secured by this key.
func (o GoogleCloudAiplatformV1PipelineJobResponseOutput) EncryptionSpec() GoogleCloudAiplatformV1EncryptionSpecResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PipelineJobResponse) GoogleCloudAiplatformV1EncryptionSpecResponse {
		return v.EncryptionSpec
	}).(GoogleCloudAiplatformV1EncryptionSpecResponseOutput)
}

// Pipeline end time.
func (o GoogleCloudAiplatformV1PipelineJobResponseOutput) EndTime() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PipelineJobResponse) string { return v.EndTime }).(pulumi.StringOutput)
}

// The error that occurred during pipeline execution. Only populated when the pipeline's state is FAILED or CANCELLED.
func (o GoogleCloudAiplatformV1PipelineJobResponseOutput) Error() GoogleRpcStatusResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PipelineJobResponse) GoogleRpcStatusResponse { return v.Error }).(GoogleRpcStatusResponseOutput)
}

// The details of pipeline run. Not available in the list view.
func (o GoogleCloudAiplatformV1PipelineJobResponseOutput) JobDetail() GoogleCloudAiplatformV1PipelineJobDetailResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PipelineJobResponse) GoogleCloudAiplatformV1PipelineJobDetailResponse {
		return v.JobDetail
	}).(GoogleCloudAiplatformV1PipelineJobDetailResponseOutput)
}

// The labels with user-defined metadata to organize PipelineJob. Label keys and values can be no longer than 64 characters (Unicode codepoints), can only contain lowercase letters, numeric characters, underscores and dashes. International characters are allowed. See https://goo.gl/xmQnxf for more information and examples of labels. Note there is some reserved label key for Vertex AI Pipelines. - `vertex-ai-pipelines-run-billing-id`, user set value will get overrided.
func (o GoogleCloudAiplatformV1PipelineJobResponseOutput) Labels() pulumi.StringMapOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PipelineJobResponse) map[string]string { return v.Labels }).(pulumi.StringMapOutput)
}

// The resource name of the PipelineJob.
func (o GoogleCloudAiplatformV1PipelineJobResponseOutput) Name() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PipelineJobResponse) string { return v.Name }).(pulumi.StringOutput)
}

// The full name of the Compute Engine [network](/compute/docs/networks-and-firewalls#networks) to which the Pipeline Job's workload should be peered. For example, `projects/12345/global/networks/myVPC`. [Format](/compute/docs/reference/rest/v1/networks/insert) is of the form `projects/{project}/global/networks/{network}`. Where {project} is a project number, as in `12345`, and {network} is a network name. Private services access must already be configured for the network. Pipeline job will apply the network configuration to the Google Cloud resources being launched, if applied, such as Vertex AI Training or Dataflow job. If left unspecified, the workload is not peered with any network.
func (o GoogleCloudAiplatformV1PipelineJobResponseOutput) Network() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PipelineJobResponse) string { return v.Network }).(pulumi.StringOutput)
}

// The spec of the pipeline.
func (o GoogleCloudAiplatformV1PipelineJobResponseOutput) PipelineSpec() pulumi.MapOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PipelineJobResponse) map[string]interface{} { return v.PipelineSpec }).(pulumi.MapOutput)
}

// A list of names for the reserved ip ranges under the VPC network that can be used for this Pipeline Job's workload. If set, we will deploy the Pipeline Job's workload within the provided ip ranges. Otherwise, the job will be deployed to any ip ranges under the provided VPC network. Example: ['vertex-ai-ip-range'].
func (o GoogleCloudAiplatformV1PipelineJobResponseOutput) ReservedIpRanges() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PipelineJobResponse) []string { return v.ReservedIpRanges }).(pulumi.StringArrayOutput)
}

// Runtime config of the pipeline.
func (o GoogleCloudAiplatformV1PipelineJobResponseOutput) RuntimeConfig() GoogleCloudAiplatformV1PipelineJobRuntimeConfigResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PipelineJobResponse) GoogleCloudAiplatformV1PipelineJobRuntimeConfigResponse {
		return v.RuntimeConfig
	}).(GoogleCloudAiplatformV1PipelineJobRuntimeConfigResponseOutput)
}

// The schedule resource name. Only returned if the Pipeline is created by Schedule API.
func (o GoogleCloudAiplatformV1PipelineJobResponseOutput) ScheduleName() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PipelineJobResponse) string { return v.ScheduleName }).(pulumi.StringOutput)
}

// The service account that the pipeline workload runs as. If not specified, the Compute Engine default service account in the project will be used. See https://cloud.google.com/compute/docs/access/service-accounts#default_service_account Users starting the pipeline must have the `iam.serviceAccounts.actAs` permission on this service account.
func (o GoogleCloudAiplatformV1PipelineJobResponseOutput) ServiceAccount() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PipelineJobResponse) string { return v.ServiceAccount }).(pulumi.StringOutput)
}

// Pipeline start time.
func (o GoogleCloudAiplatformV1PipelineJobResponseOutput) StartTime() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PipelineJobResponse) string { return v.StartTime }).(pulumi.StringOutput)
}

// The detailed state of the job.
func (o GoogleCloudAiplatformV1PipelineJobResponseOutput) State() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PipelineJobResponse) string { return v.State }).(pulumi.StringOutput)
}

// Pipeline template metadata. Will fill up fields if PipelineJob.template_uri is from supported template registry.
func (o GoogleCloudAiplatformV1PipelineJobResponseOutput) TemplateMetadata() GoogleCloudAiplatformV1PipelineTemplateMetadataResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PipelineJobResponse) GoogleCloudAiplatformV1PipelineTemplateMetadataResponse {
		return v.TemplateMetadata
	}).(GoogleCloudAiplatformV1PipelineTemplateMetadataResponseOutput)
}

// A template uri from where the PipelineJob.pipeline_spec, if empty, will be downloaded. Currently, only uri from Vertex Template Registry & Gallery is supported. Reference to https://cloud.google.com/vertex-ai/docs/pipelines/create-pipeline-template.
func (o GoogleCloudAiplatformV1PipelineJobResponseOutput) TemplateUri() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PipelineJobResponse) string { return v.TemplateUri }).(pulumi.StringOutput)
}

// Timestamp when this PipelineJob was most recently updated.
func (o GoogleCloudAiplatformV1PipelineJobResponseOutput) UpdateTime() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PipelineJobResponse) string { return v.UpdateTime }).(pulumi.StringOutput)
}

// The runtime config of a PipelineJob.
type GoogleCloudAiplatformV1PipelineJobRuntimeConfig struct {
	// Represents the failure policy of a pipeline. Currently, the default of a pipeline is that the pipeline will continue to run until no more tasks can be executed, also known as PIPELINE_FAILURE_POLICY_FAIL_SLOW. However, if a pipeline is set to PIPELINE_FAILURE_POLICY_FAIL_FAST, it will stop scheduling any new tasks when a task has failed. Any scheduled tasks will continue to completion.
	FailurePolicy *GoogleCloudAiplatformV1PipelineJobRuntimeConfigFailurePolicy `pulumi:"failurePolicy"`
	// A path in a Cloud Storage bucket, which will be treated as the root output directory of the pipeline. It is used by the system to generate the paths of output artifacts. The artifact paths are generated with a sub-path pattern `{job_id}/{task_id}/{output_key}` under the specified output directory. The service account specified in this pipeline must have the `storage.objects.get` and `storage.objects.create` permissions for this bucket.
	GcsOutputDirectory string `pulumi:"gcsOutputDirectory"`
	// The runtime artifacts of the PipelineJob. The key will be the input artifact name and the value would be one of the InputArtifact.
	InputArtifacts map[string]GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifact `pulumi:"inputArtifacts"`
	// The runtime parameters of the PipelineJob. The parameters will be passed into PipelineJob.pipeline_spec to replace the placeholders at runtime. This field is used by pipelines built using `PipelineJob.pipeline_spec.schema_version` 2.1.0, such as pipelines built using Kubeflow Pipelines SDK 1.9 or higher and the v2 DSL.
	ParameterValues map[string]interface{} `pulumi:"parameterValues"`
	// Deprecated. Use RuntimeConfig.parameter_values instead. The runtime parameters of the PipelineJob. The parameters will be passed into PipelineJob.pipeline_spec to replace the placeholders at runtime. This field is used by pipelines built using `PipelineJob.pipeline_spec.schema_version` 2.0.0 or lower, such as pipelines built using Kubeflow Pipelines SDK 1.8 or lower.
	//
	// Deprecated: Deprecated. Use RuntimeConfig.parameter_values instead. The runtime parameters of the PipelineJob. The parameters will be passed into PipelineJob.pipeline_spec to replace the placeholders at runtime. This field is used by pipelines built using `PipelineJob.pipeline_spec.schema_version` 2.0.0 or lower, such as pipelines built using Kubeflow Pipelines SDK 1.8 or lower.
	Parameters map[string]GoogleCloudAiplatformV1Value `pulumi:"parameters"`
}

// GoogleCloudAiplatformV1PipelineJobRuntimeConfigInput is an input type that accepts GoogleCloudAiplatformV1PipelineJobRuntimeConfigArgs and GoogleCloudAiplatformV1PipelineJobRuntimeConfigOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1PipelineJobRuntimeConfigInput` via:
//
//	GoogleCloudAiplatformV1PipelineJobRuntimeConfigArgs{...}
type GoogleCloudAiplatformV1PipelineJobRuntimeConfigInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1PipelineJobRuntimeConfigOutput() GoogleCloudAiplatformV1PipelineJobRuntimeConfigOutput
	ToGoogleCloudAiplatformV1PipelineJobRuntimeConfigOutputWithContext(context.Context) GoogleCloudAiplatformV1PipelineJobRuntimeConfigOutput
}

// The runtime config of a PipelineJob.
type GoogleCloudAiplatformV1PipelineJobRuntimeConfigArgs struct {
	// Represents the failure policy of a pipeline. Currently, the default of a pipeline is that the pipeline will continue to run until no more tasks can be executed, also known as PIPELINE_FAILURE_POLICY_FAIL_SLOW. However, if a pipeline is set to PIPELINE_FAILURE_POLICY_FAIL_FAST, it will stop scheduling any new tasks when a task has failed. Any scheduled tasks will continue to completion.
	FailurePolicy GoogleCloudAiplatformV1PipelineJobRuntimeConfigFailurePolicyPtrInput `pulumi:"failurePolicy"`
	// A path in a Cloud Storage bucket, which will be treated as the root output directory of the pipeline. It is used by the system to generate the paths of output artifacts. The artifact paths are generated with a sub-path pattern `{job_id}/{task_id}/{output_key}` under the specified output directory. The service account specified in this pipeline must have the `storage.objects.get` and `storage.objects.create` permissions for this bucket.
	GcsOutputDirectory pulumi.StringInput `pulumi:"gcsOutputDirectory"`
	// The runtime artifacts of the PipelineJob. The key will be the input artifact name and the value would be one of the InputArtifact.
	InputArtifacts GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactMapInput `pulumi:"inputArtifacts"`
	// The runtime parameters of the PipelineJob. The parameters will be passed into PipelineJob.pipeline_spec to replace the placeholders at runtime. This field is used by pipelines built using `PipelineJob.pipeline_spec.schema_version` 2.1.0, such as pipelines built using Kubeflow Pipelines SDK 1.9 or higher and the v2 DSL.
	ParameterValues pulumi.MapInput `pulumi:"parameterValues"`
	// Deprecated. Use RuntimeConfig.parameter_values instead. The runtime parameters of the PipelineJob. The parameters will be passed into PipelineJob.pipeline_spec to replace the placeholders at runtime. This field is used by pipelines built using `PipelineJob.pipeline_spec.schema_version` 2.0.0 or lower, such as pipelines built using Kubeflow Pipelines SDK 1.8 or lower.
	//
	// Deprecated: Deprecated. Use RuntimeConfig.parameter_values instead. The runtime parameters of the PipelineJob. The parameters will be passed into PipelineJob.pipeline_spec to replace the placeholders at runtime. This field is used by pipelines built using `PipelineJob.pipeline_spec.schema_version` 2.0.0 or lower, such as pipelines built using Kubeflow Pipelines SDK 1.8 or lower.
	Parameters GoogleCloudAiplatformV1ValueMapInput `pulumi:"parameters"`
}

func (GoogleCloudAiplatformV1PipelineJobRuntimeConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1PipelineJobRuntimeConfig)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1PipelineJobRuntimeConfigArgs) ToGoogleCloudAiplatformV1PipelineJobRuntimeConfigOutput() GoogleCloudAiplatformV1PipelineJobRuntimeConfigOutput {
	return i.ToGoogleCloudAiplatformV1PipelineJobRuntimeConfigOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1PipelineJobRuntimeConfigArgs) ToGoogleCloudAiplatformV1PipelineJobRuntimeConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1PipelineJobRuntimeConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1PipelineJobRuntimeConfigOutput)
}

func (i GoogleCloudAiplatformV1PipelineJobRuntimeConfigArgs) ToGoogleCloudAiplatformV1PipelineJobRuntimeConfigPtrOutput() GoogleCloudAiplatformV1PipelineJobRuntimeConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1PipelineJobRuntimeConfigPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1PipelineJobRuntimeConfigArgs) ToGoogleCloudAiplatformV1PipelineJobRuntimeConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1PipelineJobRuntimeConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1PipelineJobRuntimeConfigOutput).ToGoogleCloudAiplatformV1PipelineJobRuntimeConfigPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1PipelineJobRuntimeConfigPtrInput is an input type that accepts GoogleCloudAiplatformV1PipelineJobRuntimeConfigArgs, GoogleCloudAiplatformV1PipelineJobRuntimeConfigPtr and GoogleCloudAiplatformV1PipelineJobRuntimeConfigPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1PipelineJobRuntimeConfigPtrInput` via:
//
//	        GoogleCloudAiplatformV1PipelineJobRuntimeConfigArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1PipelineJobRuntimeConfigPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1PipelineJobRuntimeConfigPtrOutput() GoogleCloudAiplatformV1PipelineJobRuntimeConfigPtrOutput
	ToGoogleCloudAiplatformV1PipelineJobRuntimeConfigPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1PipelineJobRuntimeConfigPtrOutput
}

type googleCloudAiplatformV1PipelineJobRuntimeConfigPtrType GoogleCloudAiplatformV1PipelineJobRuntimeConfigArgs

func GoogleCloudAiplatformV1PipelineJobRuntimeConfigPtr(v *GoogleCloudAiplatformV1PipelineJobRuntimeConfigArgs) GoogleCloudAiplatformV1PipelineJobRuntimeConfigPtrInput {
	return (*googleCloudAiplatformV1PipelineJobRuntimeConfigPtrType)(v)
}

func (*googleCloudAiplatformV1PipelineJobRuntimeConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1PipelineJobRuntimeConfig)(nil)).Elem()
}

func (i *googleCloudAiplatformV1PipelineJobRuntimeConfigPtrType) ToGoogleCloudAiplatformV1PipelineJobRuntimeConfigPtrOutput() GoogleCloudAiplatformV1PipelineJobRuntimeConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1PipelineJobRuntimeConfigPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1PipelineJobRuntimeConfigPtrType) ToGoogleCloudAiplatformV1PipelineJobRuntimeConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1PipelineJobRuntimeConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1PipelineJobRuntimeConfigPtrOutput)
}

// The runtime config of a PipelineJob.
type GoogleCloudAiplatformV1PipelineJobRuntimeConfigOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1PipelineJobRuntimeConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1PipelineJobRuntimeConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1PipelineJobRuntimeConfigOutput) ToGoogleCloudAiplatformV1PipelineJobRuntimeConfigOutput() GoogleCloudAiplatformV1PipelineJobRuntimeConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1PipelineJobRuntimeConfigOutput) ToGoogleCloudAiplatformV1PipelineJobRuntimeConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1PipelineJobRuntimeConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1PipelineJobRuntimeConfigOutput) ToGoogleCloudAiplatformV1PipelineJobRuntimeConfigPtrOutput() GoogleCloudAiplatformV1PipelineJobRuntimeConfigPtrOutput {
	return o.ToGoogleCloudAiplatformV1PipelineJobRuntimeConfigPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1PipelineJobRuntimeConfigOutput) ToGoogleCloudAiplatformV1PipelineJobRuntimeConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1PipelineJobRuntimeConfigPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1PipelineJobRuntimeConfig) *GoogleCloudAiplatformV1PipelineJobRuntimeConfig {
		return &v
	}).(GoogleCloudAiplatformV1PipelineJobRuntimeConfigPtrOutput)
}

// Represents the failure policy of a pipeline. Currently, the default of a pipeline is that the pipeline will continue to run until no more tasks can be executed, also known as PIPELINE_FAILURE_POLICY_FAIL_SLOW. However, if a pipeline is set to PIPELINE_FAILURE_POLICY_FAIL_FAST, it will stop scheduling any new tasks when a task has failed. Any scheduled tasks will continue to completion.
func (o GoogleCloudAiplatformV1PipelineJobRuntimeConfigOutput) FailurePolicy() GoogleCloudAiplatformV1PipelineJobRuntimeConfigFailurePolicyPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PipelineJobRuntimeConfig) *GoogleCloudAiplatformV1PipelineJobRuntimeConfigFailurePolicy {
		return v.FailurePolicy
	}).(GoogleCloudAiplatformV1PipelineJobRuntimeConfigFailurePolicyPtrOutput)
}

// A path in a Cloud Storage bucket, which will be treated as the root output directory of the pipeline. It is used by the system to generate the paths of output artifacts. The artifact paths are generated with a sub-path pattern `{job_id}/{task_id}/{output_key}` under the specified output directory. The service account specified in this pipeline must have the `storage.objects.get` and `storage.objects.create` permissions for this bucket.
func (o GoogleCloudAiplatformV1PipelineJobRuntimeConfigOutput) GcsOutputDirectory() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PipelineJobRuntimeConfig) string { return v.GcsOutputDirectory }).(pulumi.StringOutput)
}

// The runtime artifacts of the PipelineJob. The key will be the input artifact name and the value would be one of the InputArtifact.
func (o GoogleCloudAiplatformV1PipelineJobRuntimeConfigOutput) InputArtifacts() GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactMapOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PipelineJobRuntimeConfig) map[string]GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifact {
		return v.InputArtifacts
	}).(GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactMapOutput)
}

// The runtime parameters of the PipelineJob. The parameters will be passed into PipelineJob.pipeline_spec to replace the placeholders at runtime. This field is used by pipelines built using `PipelineJob.pipeline_spec.schema_version` 2.1.0, such as pipelines built using Kubeflow Pipelines SDK 1.9 or higher and the v2 DSL.
func (o GoogleCloudAiplatformV1PipelineJobRuntimeConfigOutput) ParameterValues() pulumi.MapOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PipelineJobRuntimeConfig) map[string]interface{} {
		return v.ParameterValues
	}).(pulumi.MapOutput)
}

// Deprecated. Use RuntimeConfig.parameter_values instead. The runtime parameters of the PipelineJob. The parameters will be passed into PipelineJob.pipeline_spec to replace the placeholders at runtime. This field is used by pipelines built using `PipelineJob.pipeline_spec.schema_version` 2.0.0 or lower, such as pipelines built using Kubeflow Pipelines SDK 1.8 or lower.
//
// Deprecated: Deprecated. Use RuntimeConfig.parameter_values instead. The runtime parameters of the PipelineJob. The parameters will be passed into PipelineJob.pipeline_spec to replace the placeholders at runtime. This field is used by pipelines built using `PipelineJob.pipeline_spec.schema_version` 2.0.0 or lower, such as pipelines built using Kubeflow Pipelines SDK 1.8 or lower.
func (o GoogleCloudAiplatformV1PipelineJobRuntimeConfigOutput) Parameters() GoogleCloudAiplatformV1ValueMapOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PipelineJobRuntimeConfig) map[string]GoogleCloudAiplatformV1Value {
		return v.Parameters
	}).(GoogleCloudAiplatformV1ValueMapOutput)
}

type GoogleCloudAiplatformV1PipelineJobRuntimeConfigPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1PipelineJobRuntimeConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1PipelineJobRuntimeConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1PipelineJobRuntimeConfigPtrOutput) ToGoogleCloudAiplatformV1PipelineJobRuntimeConfigPtrOutput() GoogleCloudAiplatformV1PipelineJobRuntimeConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1PipelineJobRuntimeConfigPtrOutput) ToGoogleCloudAiplatformV1PipelineJobRuntimeConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1PipelineJobRuntimeConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1PipelineJobRuntimeConfigPtrOutput) Elem() GoogleCloudAiplatformV1PipelineJobRuntimeConfigOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1PipelineJobRuntimeConfig) GoogleCloudAiplatformV1PipelineJobRuntimeConfig {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1PipelineJobRuntimeConfig
		return ret
	}).(GoogleCloudAiplatformV1PipelineJobRuntimeConfigOutput)
}

// Represents the failure policy of a pipeline. Currently, the default of a pipeline is that the pipeline will continue to run until no more tasks can be executed, also known as PIPELINE_FAILURE_POLICY_FAIL_SLOW. However, if a pipeline is set to PIPELINE_FAILURE_POLICY_FAIL_FAST, it will stop scheduling any new tasks when a task has failed. Any scheduled tasks will continue to completion.
func (o GoogleCloudAiplatformV1PipelineJobRuntimeConfigPtrOutput) FailurePolicy() GoogleCloudAiplatformV1PipelineJobRuntimeConfigFailurePolicyPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1PipelineJobRuntimeConfig) *GoogleCloudAiplatformV1PipelineJobRuntimeConfigFailurePolicy {
		if v == nil {
			return nil
		}
		return v.FailurePolicy
	}).(GoogleCloudAiplatformV1PipelineJobRuntimeConfigFailurePolicyPtrOutput)
}

// A path in a Cloud Storage bucket, which will be treated as the root output directory of the pipeline. It is used by the system to generate the paths of output artifacts. The artifact paths are generated with a sub-path pattern `{job_id}/{task_id}/{output_key}` under the specified output directory. The service account specified in this pipeline must have the `storage.objects.get` and `storage.objects.create` permissions for this bucket.
func (o GoogleCloudAiplatformV1PipelineJobRuntimeConfigPtrOutput) GcsOutputDirectory() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1PipelineJobRuntimeConfig) *string {
		if v == nil {
			return nil
		}
		return &v.GcsOutputDirectory
	}).(pulumi.StringPtrOutput)
}

// The runtime artifacts of the PipelineJob. The key will be the input artifact name and the value would be one of the InputArtifact.
func (o GoogleCloudAiplatformV1PipelineJobRuntimeConfigPtrOutput) InputArtifacts() GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactMapOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1PipelineJobRuntimeConfig) map[string]GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifact {
		if v == nil {
			return nil
		}
		return v.InputArtifacts
	}).(GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactMapOutput)
}

// The runtime parameters of the PipelineJob. The parameters will be passed into PipelineJob.pipeline_spec to replace the placeholders at runtime. This field is used by pipelines built using `PipelineJob.pipeline_spec.schema_version` 2.1.0, such as pipelines built using Kubeflow Pipelines SDK 1.9 or higher and the v2 DSL.
func (o GoogleCloudAiplatformV1PipelineJobRuntimeConfigPtrOutput) ParameterValues() pulumi.MapOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1PipelineJobRuntimeConfig) map[string]interface{} {
		if v == nil {
			return nil
		}
		return v.ParameterValues
	}).(pulumi.MapOutput)
}

// Deprecated. Use RuntimeConfig.parameter_values instead. The runtime parameters of the PipelineJob. The parameters will be passed into PipelineJob.pipeline_spec to replace the placeholders at runtime. This field is used by pipelines built using `PipelineJob.pipeline_spec.schema_version` 2.0.0 or lower, such as pipelines built using Kubeflow Pipelines SDK 1.8 or lower.
//
// Deprecated: Deprecated. Use RuntimeConfig.parameter_values instead. The runtime parameters of the PipelineJob. The parameters will be passed into PipelineJob.pipeline_spec to replace the placeholders at runtime. This field is used by pipelines built using `PipelineJob.pipeline_spec.schema_version` 2.0.0 or lower, such as pipelines built using Kubeflow Pipelines SDK 1.8 or lower.
func (o GoogleCloudAiplatformV1PipelineJobRuntimeConfigPtrOutput) Parameters() GoogleCloudAiplatformV1ValueMapOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1PipelineJobRuntimeConfig) map[string]GoogleCloudAiplatformV1Value {
		if v == nil {
			return nil
		}
		return v.Parameters
	}).(GoogleCloudAiplatformV1ValueMapOutput)
}

// The type of an input artifact.
type GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifact struct {
	// Artifact resource id from MLMD. Which is the last portion of an artifact resource name: `projects/{project}/locations/{location}/metadataStores/default/artifacts/{artifact_id}`. The artifact must stay within the same project, location and default metadatastore as the pipeline.
	ArtifactId *string `pulumi:"artifactId"`
}

// GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactInput is an input type that accepts GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactArgs and GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactInput` via:
//
//	GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactArgs{...}
type GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactOutput() GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactOutput
	ToGoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactOutputWithContext(context.Context) GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactOutput
}

// The type of an input artifact.
type GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactArgs struct {
	// Artifact resource id from MLMD. Which is the last portion of an artifact resource name: `projects/{project}/locations/{location}/metadataStores/default/artifacts/{artifact_id}`. The artifact must stay within the same project, location and default metadatastore as the pipeline.
	ArtifactId pulumi.StringPtrInput `pulumi:"artifactId"`
}

func (GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifact)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactArgs) ToGoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactOutput() GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactOutput {
	return i.ToGoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactArgs) ToGoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactOutput)
}

// GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactMapInput is an input type that accepts GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactMap and GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactMapOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactMapInput` via:
//
//	GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactMap{ "key": GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactArgs{...} }
type GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactMapInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactMapOutput() GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactMapOutput
	ToGoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactMapOutputWithContext(context.Context) GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactMapOutput
}

type GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactMap map[string]GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactInput

func (GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactMap) ElementType() reflect.Type {
	return reflect.TypeOf((*map[string]GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifact)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactMap) ToGoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactMapOutput() GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactMapOutput {
	return i.ToGoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactMapOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactMap) ToGoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactMapOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactMapOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactMapOutput)
}

// The type of an input artifact.
type GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifact)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactOutput) ToGoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactOutput() GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactOutput {
	return o
}

func (o GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactOutput) ToGoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactOutput {
	return o
}

// Artifact resource id from MLMD. Which is the last portion of an artifact resource name: `projects/{project}/locations/{location}/metadataStores/default/artifacts/{artifact_id}`. The artifact must stay within the same project, location and default metadatastore as the pipeline.
func (o GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactOutput) ArtifactId() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifact) *string { return v.ArtifactId }).(pulumi.StringPtrOutput)
}

type GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactMapOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactMapOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*map[string]GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifact)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactMapOutput) ToGoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactMapOutput() GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactMapOutput {
	return o
}

func (o GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactMapOutput) ToGoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactMapOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactMapOutput {
	return o
}

func (o GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactMapOutput) MapIndex(k pulumi.StringInput) GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactOutput {
	return pulumi.All(o, k).ApplyT(func(vs []interface{}) GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifact {
		return vs[0].(map[string]GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifact)[vs[1].(string)]
	}).(GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactOutput)
}

// The type of an input artifact.
type GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactResponse struct {
	// Artifact resource id from MLMD. Which is the last portion of an artifact resource name: `projects/{project}/locations/{location}/metadataStores/default/artifacts/{artifact_id}`. The artifact must stay within the same project, location and default metadatastore as the pipeline.
	ArtifactId string `pulumi:"artifactId"`
}

// The type of an input artifact.
type GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactResponseOutput) ToGoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactResponseOutput() GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactResponseOutput) ToGoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactResponseOutput {
	return o
}

// Artifact resource id from MLMD. Which is the last portion of an artifact resource name: `projects/{project}/locations/{location}/metadataStores/default/artifacts/{artifact_id}`. The artifact must stay within the same project, location and default metadatastore as the pipeline.
func (o GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactResponseOutput) ArtifactId() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactResponse) string {
		return v.ArtifactId
	}).(pulumi.StringOutput)
}

type GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactResponseMapOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactResponseMapOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*map[string]GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactResponseMapOutput) ToGoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactResponseMapOutput() GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactResponseMapOutput {
	return o
}

func (o GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactResponseMapOutput) ToGoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactResponseMapOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactResponseMapOutput {
	return o
}

func (o GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactResponseMapOutput) MapIndex(k pulumi.StringInput) GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactResponseOutput {
	return pulumi.All(o, k).ApplyT(func(vs []interface{}) GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactResponse {
		return vs[0].(map[string]GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactResponse)[vs[1].(string)]
	}).(GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactResponseOutput)
}

// The runtime config of a PipelineJob.
type GoogleCloudAiplatformV1PipelineJobRuntimeConfigResponse struct {
	// Represents the failure policy of a pipeline. Currently, the default of a pipeline is that the pipeline will continue to run until no more tasks can be executed, also known as PIPELINE_FAILURE_POLICY_FAIL_SLOW. However, if a pipeline is set to PIPELINE_FAILURE_POLICY_FAIL_FAST, it will stop scheduling any new tasks when a task has failed. Any scheduled tasks will continue to completion.
	FailurePolicy string `pulumi:"failurePolicy"`
	// A path in a Cloud Storage bucket, which will be treated as the root output directory of the pipeline. It is used by the system to generate the paths of output artifacts. The artifact paths are generated with a sub-path pattern `{job_id}/{task_id}/{output_key}` under the specified output directory. The service account specified in this pipeline must have the `storage.objects.get` and `storage.objects.create` permissions for this bucket.
	GcsOutputDirectory string `pulumi:"gcsOutputDirectory"`
	// The runtime artifacts of the PipelineJob. The key will be the input artifact name and the value would be one of the InputArtifact.
	InputArtifacts map[string]GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactResponse `pulumi:"inputArtifacts"`
	// The runtime parameters of the PipelineJob. The parameters will be passed into PipelineJob.pipeline_spec to replace the placeholders at runtime. This field is used by pipelines built using `PipelineJob.pipeline_spec.schema_version` 2.1.0, such as pipelines built using Kubeflow Pipelines SDK 1.9 or higher and the v2 DSL.
	ParameterValues map[string]interface{} `pulumi:"parameterValues"`
	// Deprecated. Use RuntimeConfig.parameter_values instead. The runtime parameters of the PipelineJob. The parameters will be passed into PipelineJob.pipeline_spec to replace the placeholders at runtime. This field is used by pipelines built using `PipelineJob.pipeline_spec.schema_version` 2.0.0 or lower, such as pipelines built using Kubeflow Pipelines SDK 1.8 or lower.
	//
	// Deprecated: Deprecated. Use RuntimeConfig.parameter_values instead. The runtime parameters of the PipelineJob. The parameters will be passed into PipelineJob.pipeline_spec to replace the placeholders at runtime. This field is used by pipelines built using `PipelineJob.pipeline_spec.schema_version` 2.0.0 or lower, such as pipelines built using Kubeflow Pipelines SDK 1.8 or lower.
	Parameters map[string]GoogleCloudAiplatformV1ValueResponse `pulumi:"parameters"`
}

// The runtime config of a PipelineJob.
type GoogleCloudAiplatformV1PipelineJobRuntimeConfigResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1PipelineJobRuntimeConfigResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1PipelineJobRuntimeConfigResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1PipelineJobRuntimeConfigResponseOutput) ToGoogleCloudAiplatformV1PipelineJobRuntimeConfigResponseOutput() GoogleCloudAiplatformV1PipelineJobRuntimeConfigResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1PipelineJobRuntimeConfigResponseOutput) ToGoogleCloudAiplatformV1PipelineJobRuntimeConfigResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1PipelineJobRuntimeConfigResponseOutput {
	return o
}

// Represents the failure policy of a pipeline. Currently, the default of a pipeline is that the pipeline will continue to run until no more tasks can be executed, also known as PIPELINE_FAILURE_POLICY_FAIL_SLOW. However, if a pipeline is set to PIPELINE_FAILURE_POLICY_FAIL_FAST, it will stop scheduling any new tasks when a task has failed. Any scheduled tasks will continue to completion.
func (o GoogleCloudAiplatformV1PipelineJobRuntimeConfigResponseOutput) FailurePolicy() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PipelineJobRuntimeConfigResponse) string { return v.FailurePolicy }).(pulumi.StringOutput)
}

// A path in a Cloud Storage bucket, which will be treated as the root output directory of the pipeline. It is used by the system to generate the paths of output artifacts. The artifact paths are generated with a sub-path pattern `{job_id}/{task_id}/{output_key}` under the specified output directory. The service account specified in this pipeline must have the `storage.objects.get` and `storage.objects.create` permissions for this bucket.
func (o GoogleCloudAiplatformV1PipelineJobRuntimeConfigResponseOutput) GcsOutputDirectory() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PipelineJobRuntimeConfigResponse) string { return v.GcsOutputDirectory }).(pulumi.StringOutput)
}

// The runtime artifacts of the PipelineJob. The key will be the input artifact name and the value would be one of the InputArtifact.
func (o GoogleCloudAiplatformV1PipelineJobRuntimeConfigResponseOutput) InputArtifacts() GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactResponseMapOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PipelineJobRuntimeConfigResponse) map[string]GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactResponse {
		return v.InputArtifacts
	}).(GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactResponseMapOutput)
}

// The runtime parameters of the PipelineJob. The parameters will be passed into PipelineJob.pipeline_spec to replace the placeholders at runtime. This field is used by pipelines built using `PipelineJob.pipeline_spec.schema_version` 2.1.0, such as pipelines built using Kubeflow Pipelines SDK 1.9 or higher and the v2 DSL.
func (o GoogleCloudAiplatformV1PipelineJobRuntimeConfigResponseOutput) ParameterValues() pulumi.MapOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PipelineJobRuntimeConfigResponse) map[string]interface{} {
		return v.ParameterValues
	}).(pulumi.MapOutput)
}

// Deprecated. Use RuntimeConfig.parameter_values instead. The runtime parameters of the PipelineJob. The parameters will be passed into PipelineJob.pipeline_spec to replace the placeholders at runtime. This field is used by pipelines built using `PipelineJob.pipeline_spec.schema_version` 2.0.0 or lower, such as pipelines built using Kubeflow Pipelines SDK 1.8 or lower.
//
// Deprecated: Deprecated. Use RuntimeConfig.parameter_values instead. The runtime parameters of the PipelineJob. The parameters will be passed into PipelineJob.pipeline_spec to replace the placeholders at runtime. This field is used by pipelines built using `PipelineJob.pipeline_spec.schema_version` 2.0.0 or lower, such as pipelines built using Kubeflow Pipelines SDK 1.8 or lower.
func (o GoogleCloudAiplatformV1PipelineJobRuntimeConfigResponseOutput) Parameters() GoogleCloudAiplatformV1ValueResponseMapOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PipelineJobRuntimeConfigResponse) map[string]GoogleCloudAiplatformV1ValueResponse {
		return v.Parameters
	}).(GoogleCloudAiplatformV1ValueResponseMapOutput)
}

// A list of artifact metadata.
type GoogleCloudAiplatformV1PipelineTaskDetailArtifactListResponse struct {
	// A list of artifact metadata.
	Artifacts []GoogleCloudAiplatformV1ArtifactResponse `pulumi:"artifacts"`
}

// A list of artifact metadata.
type GoogleCloudAiplatformV1PipelineTaskDetailArtifactListResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1PipelineTaskDetailArtifactListResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1PipelineTaskDetailArtifactListResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1PipelineTaskDetailArtifactListResponseOutput) ToGoogleCloudAiplatformV1PipelineTaskDetailArtifactListResponseOutput() GoogleCloudAiplatformV1PipelineTaskDetailArtifactListResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1PipelineTaskDetailArtifactListResponseOutput) ToGoogleCloudAiplatformV1PipelineTaskDetailArtifactListResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1PipelineTaskDetailArtifactListResponseOutput {
	return o
}

// A list of artifact metadata.
func (o GoogleCloudAiplatformV1PipelineTaskDetailArtifactListResponseOutput) Artifacts() GoogleCloudAiplatformV1ArtifactResponseArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PipelineTaskDetailArtifactListResponse) []GoogleCloudAiplatformV1ArtifactResponse {
		return v.Artifacts
	}).(GoogleCloudAiplatformV1ArtifactResponseArrayOutput)
}

type GoogleCloudAiplatformV1PipelineTaskDetailArtifactListResponseMapOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1PipelineTaskDetailArtifactListResponseMapOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*map[string]GoogleCloudAiplatformV1PipelineTaskDetailArtifactListResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1PipelineTaskDetailArtifactListResponseMapOutput) ToGoogleCloudAiplatformV1PipelineTaskDetailArtifactListResponseMapOutput() GoogleCloudAiplatformV1PipelineTaskDetailArtifactListResponseMapOutput {
	return o
}

func (o GoogleCloudAiplatformV1PipelineTaskDetailArtifactListResponseMapOutput) ToGoogleCloudAiplatformV1PipelineTaskDetailArtifactListResponseMapOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1PipelineTaskDetailArtifactListResponseMapOutput {
	return o
}

func (o GoogleCloudAiplatformV1PipelineTaskDetailArtifactListResponseMapOutput) MapIndex(k pulumi.StringInput) GoogleCloudAiplatformV1PipelineTaskDetailArtifactListResponseOutput {
	return pulumi.All(o, k).ApplyT(func(vs []interface{}) GoogleCloudAiplatformV1PipelineTaskDetailArtifactListResponse {
		return vs[0].(map[string]GoogleCloudAiplatformV1PipelineTaskDetailArtifactListResponse)[vs[1].(string)]
	}).(GoogleCloudAiplatformV1PipelineTaskDetailArtifactListResponseOutput)
}

// A single record of the task status.
type GoogleCloudAiplatformV1PipelineTaskDetailPipelineTaskStatusResponse struct {
	// The error that occurred during the state. May be set when the state is any of the non-final state (PENDING/RUNNING/CANCELLING) or FAILED state. If the state is FAILED, the error here is final and not going to be retried. If the state is a non-final state, the error indicates a system-error being retried.
	Error GoogleRpcStatusResponse `pulumi:"error"`
	// The state of the task.
	State string `pulumi:"state"`
	// Update time of this status.
	UpdateTime string `pulumi:"updateTime"`
}

// A single record of the task status.
type GoogleCloudAiplatformV1PipelineTaskDetailPipelineTaskStatusResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1PipelineTaskDetailPipelineTaskStatusResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1PipelineTaskDetailPipelineTaskStatusResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1PipelineTaskDetailPipelineTaskStatusResponseOutput) ToGoogleCloudAiplatformV1PipelineTaskDetailPipelineTaskStatusResponseOutput() GoogleCloudAiplatformV1PipelineTaskDetailPipelineTaskStatusResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1PipelineTaskDetailPipelineTaskStatusResponseOutput) ToGoogleCloudAiplatformV1PipelineTaskDetailPipelineTaskStatusResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1PipelineTaskDetailPipelineTaskStatusResponseOutput {
	return o
}

// The error that occurred during the state. May be set when the state is any of the non-final state (PENDING/RUNNING/CANCELLING) or FAILED state. If the state is FAILED, the error here is final and not going to be retried. If the state is a non-final state, the error indicates a system-error being retried.
func (o GoogleCloudAiplatformV1PipelineTaskDetailPipelineTaskStatusResponseOutput) Error() GoogleRpcStatusResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PipelineTaskDetailPipelineTaskStatusResponse) GoogleRpcStatusResponse {
		return v.Error
	}).(GoogleRpcStatusResponseOutput)
}

// The state of the task.
func (o GoogleCloudAiplatformV1PipelineTaskDetailPipelineTaskStatusResponseOutput) State() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PipelineTaskDetailPipelineTaskStatusResponse) string { return v.State }).(pulumi.StringOutput)
}

// Update time of this status.
func (o GoogleCloudAiplatformV1PipelineTaskDetailPipelineTaskStatusResponseOutput) UpdateTime() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PipelineTaskDetailPipelineTaskStatusResponse) string {
		return v.UpdateTime
	}).(pulumi.StringOutput)
}

type GoogleCloudAiplatformV1PipelineTaskDetailPipelineTaskStatusResponseArrayOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1PipelineTaskDetailPipelineTaskStatusResponseArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1PipelineTaskDetailPipelineTaskStatusResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1PipelineTaskDetailPipelineTaskStatusResponseArrayOutput) ToGoogleCloudAiplatformV1PipelineTaskDetailPipelineTaskStatusResponseArrayOutput() GoogleCloudAiplatformV1PipelineTaskDetailPipelineTaskStatusResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1PipelineTaskDetailPipelineTaskStatusResponseArrayOutput) ToGoogleCloudAiplatformV1PipelineTaskDetailPipelineTaskStatusResponseArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1PipelineTaskDetailPipelineTaskStatusResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1PipelineTaskDetailPipelineTaskStatusResponseArrayOutput) Index(i pulumi.IntInput) GoogleCloudAiplatformV1PipelineTaskDetailPipelineTaskStatusResponseOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GoogleCloudAiplatformV1PipelineTaskDetailPipelineTaskStatusResponse {
		return vs[0].([]GoogleCloudAiplatformV1PipelineTaskDetailPipelineTaskStatusResponse)[vs[1].(int)]
	}).(GoogleCloudAiplatformV1PipelineTaskDetailPipelineTaskStatusResponseOutput)
}

// The runtime detail of a task execution.
type GoogleCloudAiplatformV1PipelineTaskDetailResponse struct {
	// Task create time.
	CreateTime string `pulumi:"createTime"`
	// Task end time.
	EndTime string `pulumi:"endTime"`
	// The error that occurred during task execution. Only populated when the task's state is FAILED or CANCELLED.
	Error GoogleRpcStatusResponse `pulumi:"error"`
	// The execution metadata of the task.
	Execution GoogleCloudAiplatformV1ExecutionResponse `pulumi:"execution"`
	// The detailed execution info.
	ExecutorDetail GoogleCloudAiplatformV1PipelineTaskExecutorDetailResponse `pulumi:"executorDetail"`
	// The runtime input artifacts of the task.
	Inputs map[string]GoogleCloudAiplatformV1PipelineTaskDetailArtifactListResponse `pulumi:"inputs"`
	// The runtime output artifacts of the task.
	Outputs map[string]GoogleCloudAiplatformV1PipelineTaskDetailArtifactListResponse `pulumi:"outputs"`
	// The id of the parent task if the task is within a component scope. Empty if the task is at the root level.
	ParentTaskId string `pulumi:"parentTaskId"`
	// A list of task status. This field keeps a record of task status evolving over time.
	PipelineTaskStatus []GoogleCloudAiplatformV1PipelineTaskDetailPipelineTaskStatusResponse `pulumi:"pipelineTaskStatus"`
	// Task start time.
	StartTime string `pulumi:"startTime"`
	// State of the task.
	State string `pulumi:"state"`
	// The system generated ID of the task.
	TaskId string `pulumi:"taskId"`
	// The user specified name of the task that is defined in pipeline_spec.
	TaskName string `pulumi:"taskName"`
}

// The runtime detail of a task execution.
type GoogleCloudAiplatformV1PipelineTaskDetailResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1PipelineTaskDetailResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1PipelineTaskDetailResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1PipelineTaskDetailResponseOutput) ToGoogleCloudAiplatformV1PipelineTaskDetailResponseOutput() GoogleCloudAiplatformV1PipelineTaskDetailResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1PipelineTaskDetailResponseOutput) ToGoogleCloudAiplatformV1PipelineTaskDetailResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1PipelineTaskDetailResponseOutput {
	return o
}

// Task create time.
func (o GoogleCloudAiplatformV1PipelineTaskDetailResponseOutput) CreateTime() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PipelineTaskDetailResponse) string { return v.CreateTime }).(pulumi.StringOutput)
}

// Task end time.
func (o GoogleCloudAiplatformV1PipelineTaskDetailResponseOutput) EndTime() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PipelineTaskDetailResponse) string { return v.EndTime }).(pulumi.StringOutput)
}

// The error that occurred during task execution. Only populated when the task's state is FAILED or CANCELLED.
func (o GoogleCloudAiplatformV1PipelineTaskDetailResponseOutput) Error() GoogleRpcStatusResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PipelineTaskDetailResponse) GoogleRpcStatusResponse { return v.Error }).(GoogleRpcStatusResponseOutput)
}

// The execution metadata of the task.
func (o GoogleCloudAiplatformV1PipelineTaskDetailResponseOutput) Execution() GoogleCloudAiplatformV1ExecutionResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PipelineTaskDetailResponse) GoogleCloudAiplatformV1ExecutionResponse {
		return v.Execution
	}).(GoogleCloudAiplatformV1ExecutionResponseOutput)
}

// The detailed execution info.
func (o GoogleCloudAiplatformV1PipelineTaskDetailResponseOutput) ExecutorDetail() GoogleCloudAiplatformV1PipelineTaskExecutorDetailResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PipelineTaskDetailResponse) GoogleCloudAiplatformV1PipelineTaskExecutorDetailResponse {
		return v.ExecutorDetail
	}).(GoogleCloudAiplatformV1PipelineTaskExecutorDetailResponseOutput)
}

// The runtime input artifacts of the task.
func (o GoogleCloudAiplatformV1PipelineTaskDetailResponseOutput) Inputs() GoogleCloudAiplatformV1PipelineTaskDetailArtifactListResponseMapOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PipelineTaskDetailResponse) map[string]GoogleCloudAiplatformV1PipelineTaskDetailArtifactListResponse {
		return v.Inputs
	}).(GoogleCloudAiplatformV1PipelineTaskDetailArtifactListResponseMapOutput)
}

// The runtime output artifacts of the task.
func (o GoogleCloudAiplatformV1PipelineTaskDetailResponseOutput) Outputs() GoogleCloudAiplatformV1PipelineTaskDetailArtifactListResponseMapOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PipelineTaskDetailResponse) map[string]GoogleCloudAiplatformV1PipelineTaskDetailArtifactListResponse {
		return v.Outputs
	}).(GoogleCloudAiplatformV1PipelineTaskDetailArtifactListResponseMapOutput)
}

// The id of the parent task if the task is within a component scope. Empty if the task is at the root level.
func (o GoogleCloudAiplatformV1PipelineTaskDetailResponseOutput) ParentTaskId() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PipelineTaskDetailResponse) string { return v.ParentTaskId }).(pulumi.StringOutput)
}

// A list of task status. This field keeps a record of task status evolving over time.
func (o GoogleCloudAiplatformV1PipelineTaskDetailResponseOutput) PipelineTaskStatus() GoogleCloudAiplatformV1PipelineTaskDetailPipelineTaskStatusResponseArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PipelineTaskDetailResponse) []GoogleCloudAiplatformV1PipelineTaskDetailPipelineTaskStatusResponse {
		return v.PipelineTaskStatus
	}).(GoogleCloudAiplatformV1PipelineTaskDetailPipelineTaskStatusResponseArrayOutput)
}

// Task start time.
func (o GoogleCloudAiplatformV1PipelineTaskDetailResponseOutput) StartTime() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PipelineTaskDetailResponse) string { return v.StartTime }).(pulumi.StringOutput)
}

// State of the task.
func (o GoogleCloudAiplatformV1PipelineTaskDetailResponseOutput) State() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PipelineTaskDetailResponse) string { return v.State }).(pulumi.StringOutput)
}

// The system generated ID of the task.
func (o GoogleCloudAiplatformV1PipelineTaskDetailResponseOutput) TaskId() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PipelineTaskDetailResponse) string { return v.TaskId }).(pulumi.StringOutput)
}

// The user specified name of the task that is defined in pipeline_spec.
func (o GoogleCloudAiplatformV1PipelineTaskDetailResponseOutput) TaskName() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PipelineTaskDetailResponse) string { return v.TaskName }).(pulumi.StringOutput)
}

type GoogleCloudAiplatformV1PipelineTaskDetailResponseArrayOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1PipelineTaskDetailResponseArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1PipelineTaskDetailResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1PipelineTaskDetailResponseArrayOutput) ToGoogleCloudAiplatformV1PipelineTaskDetailResponseArrayOutput() GoogleCloudAiplatformV1PipelineTaskDetailResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1PipelineTaskDetailResponseArrayOutput) ToGoogleCloudAiplatformV1PipelineTaskDetailResponseArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1PipelineTaskDetailResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1PipelineTaskDetailResponseArrayOutput) Index(i pulumi.IntInput) GoogleCloudAiplatformV1PipelineTaskDetailResponseOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GoogleCloudAiplatformV1PipelineTaskDetailResponse {
		return vs[0].([]GoogleCloudAiplatformV1PipelineTaskDetailResponse)[vs[1].(int)]
	}).(GoogleCloudAiplatformV1PipelineTaskDetailResponseOutput)
}

// The detail of a container execution. It contains the job names of the lifecycle of a container execution.
type GoogleCloudAiplatformV1PipelineTaskExecutorDetailContainerDetailResponse struct {
	// The names of the previously failed CustomJob for the main container executions. The list includes the all attempts in chronological order.
	FailedMainJobs []string `pulumi:"failedMainJobs"`
	// The names of the previously failed CustomJob for the pre-caching-check container executions. This job will be available if the PipelineJob.pipeline_spec specifies the `pre_caching_check` hook in the lifecycle events. The list includes the all attempts in chronological order.
	FailedPreCachingCheckJobs []string `pulumi:"failedPreCachingCheckJobs"`
	// The name of the CustomJob for the main container execution.
	MainJob string `pulumi:"mainJob"`
	// The name of the CustomJob for the pre-caching-check container execution. This job will be available if the PipelineJob.pipeline_spec specifies the `pre_caching_check` hook in the lifecycle events.
	PreCachingCheckJob string `pulumi:"preCachingCheckJob"`
}

// The detail of a container execution. It contains the job names of the lifecycle of a container execution.
type GoogleCloudAiplatformV1PipelineTaskExecutorDetailContainerDetailResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1PipelineTaskExecutorDetailContainerDetailResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1PipelineTaskExecutorDetailContainerDetailResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1PipelineTaskExecutorDetailContainerDetailResponseOutput) ToGoogleCloudAiplatformV1PipelineTaskExecutorDetailContainerDetailResponseOutput() GoogleCloudAiplatformV1PipelineTaskExecutorDetailContainerDetailResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1PipelineTaskExecutorDetailContainerDetailResponseOutput) ToGoogleCloudAiplatformV1PipelineTaskExecutorDetailContainerDetailResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1PipelineTaskExecutorDetailContainerDetailResponseOutput {
	return o
}

// The names of the previously failed CustomJob for the main container executions. The list includes the all attempts in chronological order.
func (o GoogleCloudAiplatformV1PipelineTaskExecutorDetailContainerDetailResponseOutput) FailedMainJobs() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PipelineTaskExecutorDetailContainerDetailResponse) []string {
		return v.FailedMainJobs
	}).(pulumi.StringArrayOutput)
}

// The names of the previously failed CustomJob for the pre-caching-check container executions. This job will be available if the PipelineJob.pipeline_spec specifies the `pre_caching_check` hook in the lifecycle events. The list includes the all attempts in chronological order.
func (o GoogleCloudAiplatformV1PipelineTaskExecutorDetailContainerDetailResponseOutput) FailedPreCachingCheckJobs() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PipelineTaskExecutorDetailContainerDetailResponse) []string {
		return v.FailedPreCachingCheckJobs
	}).(pulumi.StringArrayOutput)
}

// The name of the CustomJob for the main container execution.
func (o GoogleCloudAiplatformV1PipelineTaskExecutorDetailContainerDetailResponseOutput) MainJob() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PipelineTaskExecutorDetailContainerDetailResponse) string {
		return v.MainJob
	}).(pulumi.StringOutput)
}

// The name of the CustomJob for the pre-caching-check container execution. This job will be available if the PipelineJob.pipeline_spec specifies the `pre_caching_check` hook in the lifecycle events.
func (o GoogleCloudAiplatformV1PipelineTaskExecutorDetailContainerDetailResponseOutput) PreCachingCheckJob() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PipelineTaskExecutorDetailContainerDetailResponse) string {
		return v.PreCachingCheckJob
	}).(pulumi.StringOutput)
}

// The detailed info for a custom job executor.
type GoogleCloudAiplatformV1PipelineTaskExecutorDetailCustomJobDetailResponse struct {
	// The names of the previously failed CustomJob. The list includes the all attempts in chronological order.
	FailedJobs []string `pulumi:"failedJobs"`
	// The name of the CustomJob.
	Job string `pulumi:"job"`
}

// The detailed info for a custom job executor.
type GoogleCloudAiplatformV1PipelineTaskExecutorDetailCustomJobDetailResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1PipelineTaskExecutorDetailCustomJobDetailResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1PipelineTaskExecutorDetailCustomJobDetailResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1PipelineTaskExecutorDetailCustomJobDetailResponseOutput) ToGoogleCloudAiplatformV1PipelineTaskExecutorDetailCustomJobDetailResponseOutput() GoogleCloudAiplatformV1PipelineTaskExecutorDetailCustomJobDetailResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1PipelineTaskExecutorDetailCustomJobDetailResponseOutput) ToGoogleCloudAiplatformV1PipelineTaskExecutorDetailCustomJobDetailResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1PipelineTaskExecutorDetailCustomJobDetailResponseOutput {
	return o
}

// The names of the previously failed CustomJob. The list includes the all attempts in chronological order.
func (o GoogleCloudAiplatformV1PipelineTaskExecutorDetailCustomJobDetailResponseOutput) FailedJobs() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PipelineTaskExecutorDetailCustomJobDetailResponse) []string {
		return v.FailedJobs
	}).(pulumi.StringArrayOutput)
}

// The name of the CustomJob.
func (o GoogleCloudAiplatformV1PipelineTaskExecutorDetailCustomJobDetailResponseOutput) Job() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PipelineTaskExecutorDetailCustomJobDetailResponse) string { return v.Job }).(pulumi.StringOutput)
}

// The runtime detail of a pipeline executor.
type GoogleCloudAiplatformV1PipelineTaskExecutorDetailResponse struct {
	// The detailed info for a container executor.
	ContainerDetail GoogleCloudAiplatformV1PipelineTaskExecutorDetailContainerDetailResponse `pulumi:"containerDetail"`
	// The detailed info for a custom job executor.
	CustomJobDetail GoogleCloudAiplatformV1PipelineTaskExecutorDetailCustomJobDetailResponse `pulumi:"customJobDetail"`
}

// The runtime detail of a pipeline executor.
type GoogleCloudAiplatformV1PipelineTaskExecutorDetailResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1PipelineTaskExecutorDetailResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1PipelineTaskExecutorDetailResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1PipelineTaskExecutorDetailResponseOutput) ToGoogleCloudAiplatformV1PipelineTaskExecutorDetailResponseOutput() GoogleCloudAiplatformV1PipelineTaskExecutorDetailResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1PipelineTaskExecutorDetailResponseOutput) ToGoogleCloudAiplatformV1PipelineTaskExecutorDetailResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1PipelineTaskExecutorDetailResponseOutput {
	return o
}

// The detailed info for a container executor.
func (o GoogleCloudAiplatformV1PipelineTaskExecutorDetailResponseOutput) ContainerDetail() GoogleCloudAiplatformV1PipelineTaskExecutorDetailContainerDetailResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PipelineTaskExecutorDetailResponse) GoogleCloudAiplatformV1PipelineTaskExecutorDetailContainerDetailResponse {
		return v.ContainerDetail
	}).(GoogleCloudAiplatformV1PipelineTaskExecutorDetailContainerDetailResponseOutput)
}

// The detailed info for a custom job executor.
func (o GoogleCloudAiplatformV1PipelineTaskExecutorDetailResponseOutput) CustomJobDetail() GoogleCloudAiplatformV1PipelineTaskExecutorDetailCustomJobDetailResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PipelineTaskExecutorDetailResponse) GoogleCloudAiplatformV1PipelineTaskExecutorDetailCustomJobDetailResponse {
		return v.CustomJobDetail
	}).(GoogleCloudAiplatformV1PipelineTaskExecutorDetailCustomJobDetailResponseOutput)
}

// Pipeline template metadata if PipelineJob.template_uri is from supported template registry. Currently, the only supported registry is Artifact Registry.
type GoogleCloudAiplatformV1PipelineTemplateMetadataResponse struct {
	// The version_name in artifact registry. Will always be presented in output if the PipelineJob.template_uri is from supported template registry. Format is "sha256:abcdef123456...".
	Version string `pulumi:"version"`
}

// Pipeline template metadata if PipelineJob.template_uri is from supported template registry. Currently, the only supported registry is Artifact Registry.
type GoogleCloudAiplatformV1PipelineTemplateMetadataResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1PipelineTemplateMetadataResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1PipelineTemplateMetadataResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1PipelineTemplateMetadataResponseOutput) ToGoogleCloudAiplatformV1PipelineTemplateMetadataResponseOutput() GoogleCloudAiplatformV1PipelineTemplateMetadataResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1PipelineTemplateMetadataResponseOutput) ToGoogleCloudAiplatformV1PipelineTemplateMetadataResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1PipelineTemplateMetadataResponseOutput {
	return o
}

// The version_name in artifact registry. Will always be presented in output if the PipelineJob.template_uri is from supported template registry. Format is "sha256:abcdef123456...".
func (o GoogleCloudAiplatformV1PipelineTemplateMetadataResponseOutput) Version() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PipelineTemplateMetadataResponse) string { return v.Version }).(pulumi.StringOutput)
}

// Represents a network port in a container.
type GoogleCloudAiplatformV1Port struct {
	// The number of the port to expose on the pod's IP address. Must be a valid port number, between 1 and 65535 inclusive.
	ContainerPort *int `pulumi:"containerPort"`
}

// GoogleCloudAiplatformV1PortInput is an input type that accepts GoogleCloudAiplatformV1PortArgs and GoogleCloudAiplatformV1PortOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1PortInput` via:
//
//	GoogleCloudAiplatformV1PortArgs{...}
type GoogleCloudAiplatformV1PortInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1PortOutput() GoogleCloudAiplatformV1PortOutput
	ToGoogleCloudAiplatformV1PortOutputWithContext(context.Context) GoogleCloudAiplatformV1PortOutput
}

// Represents a network port in a container.
type GoogleCloudAiplatformV1PortArgs struct {
	// The number of the port to expose on the pod's IP address. Must be a valid port number, between 1 and 65535 inclusive.
	ContainerPort pulumi.IntPtrInput `pulumi:"containerPort"`
}

func (GoogleCloudAiplatformV1PortArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1Port)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1PortArgs) ToGoogleCloudAiplatformV1PortOutput() GoogleCloudAiplatformV1PortOutput {
	return i.ToGoogleCloudAiplatformV1PortOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1PortArgs) ToGoogleCloudAiplatformV1PortOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1PortOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1PortOutput)
}

// GoogleCloudAiplatformV1PortArrayInput is an input type that accepts GoogleCloudAiplatformV1PortArray and GoogleCloudAiplatformV1PortArrayOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1PortArrayInput` via:
//
//	GoogleCloudAiplatformV1PortArray{ GoogleCloudAiplatformV1PortArgs{...} }
type GoogleCloudAiplatformV1PortArrayInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1PortArrayOutput() GoogleCloudAiplatformV1PortArrayOutput
	ToGoogleCloudAiplatformV1PortArrayOutputWithContext(context.Context) GoogleCloudAiplatformV1PortArrayOutput
}

type GoogleCloudAiplatformV1PortArray []GoogleCloudAiplatformV1PortInput

func (GoogleCloudAiplatformV1PortArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1Port)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1PortArray) ToGoogleCloudAiplatformV1PortArrayOutput() GoogleCloudAiplatformV1PortArrayOutput {
	return i.ToGoogleCloudAiplatformV1PortArrayOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1PortArray) ToGoogleCloudAiplatformV1PortArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1PortArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1PortArrayOutput)
}

// Represents a network port in a container.
type GoogleCloudAiplatformV1PortOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1PortOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1Port)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1PortOutput) ToGoogleCloudAiplatformV1PortOutput() GoogleCloudAiplatformV1PortOutput {
	return o
}

func (o GoogleCloudAiplatformV1PortOutput) ToGoogleCloudAiplatformV1PortOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1PortOutput {
	return o
}

// The number of the port to expose on the pod's IP address. Must be a valid port number, between 1 and 65535 inclusive.
func (o GoogleCloudAiplatformV1PortOutput) ContainerPort() pulumi.IntPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1Port) *int { return v.ContainerPort }).(pulumi.IntPtrOutput)
}

type GoogleCloudAiplatformV1PortArrayOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1PortArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1Port)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1PortArrayOutput) ToGoogleCloudAiplatformV1PortArrayOutput() GoogleCloudAiplatformV1PortArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1PortArrayOutput) ToGoogleCloudAiplatformV1PortArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1PortArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1PortArrayOutput) Index(i pulumi.IntInput) GoogleCloudAiplatformV1PortOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GoogleCloudAiplatformV1Port {
		return vs[0].([]GoogleCloudAiplatformV1Port)[vs[1].(int)]
	}).(GoogleCloudAiplatformV1PortOutput)
}

// Represents a network port in a container.
type GoogleCloudAiplatformV1PortResponse struct {
	// The number of the port to expose on the pod's IP address. Must be a valid port number, between 1 and 65535 inclusive.
	ContainerPort int `pulumi:"containerPort"`
}

// Represents a network port in a container.
type GoogleCloudAiplatformV1PortResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1PortResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1PortResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1PortResponseOutput) ToGoogleCloudAiplatformV1PortResponseOutput() GoogleCloudAiplatformV1PortResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1PortResponseOutput) ToGoogleCloudAiplatformV1PortResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1PortResponseOutput {
	return o
}

// The number of the port to expose on the pod's IP address. Must be a valid port number, between 1 and 65535 inclusive.
func (o GoogleCloudAiplatformV1PortResponseOutput) ContainerPort() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PortResponse) int { return v.ContainerPort }).(pulumi.IntOutput)
}

type GoogleCloudAiplatformV1PortResponseArrayOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1PortResponseArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1PortResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1PortResponseArrayOutput) ToGoogleCloudAiplatformV1PortResponseArrayOutput() GoogleCloudAiplatformV1PortResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1PortResponseArrayOutput) ToGoogleCloudAiplatformV1PortResponseArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1PortResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1PortResponseArrayOutput) Index(i pulumi.IntInput) GoogleCloudAiplatformV1PortResponseOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GoogleCloudAiplatformV1PortResponse {
		return vs[0].([]GoogleCloudAiplatformV1PortResponse)[vs[1].(int)]
	}).(GoogleCloudAiplatformV1PortResponseOutput)
}

// Assigns input data to training, validation, and test sets based on the value of a provided key. Supported only for tabular Datasets.
type GoogleCloudAiplatformV1PredefinedSplit struct {
	// The key is a name of one of the Dataset's data columns. The value of the key (either the label's value or value in the column) must be one of {`training`, `validation`, `test`}, and it defines to which set the given piece of data is assigned. If for a piece of data the key is not present or has an invalid value, that piece is ignored by the pipeline.
	Key string `pulumi:"key"`
}

// GoogleCloudAiplatformV1PredefinedSplitInput is an input type that accepts GoogleCloudAiplatformV1PredefinedSplitArgs and GoogleCloudAiplatformV1PredefinedSplitOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1PredefinedSplitInput` via:
//
//	GoogleCloudAiplatformV1PredefinedSplitArgs{...}
type GoogleCloudAiplatformV1PredefinedSplitInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1PredefinedSplitOutput() GoogleCloudAiplatformV1PredefinedSplitOutput
	ToGoogleCloudAiplatformV1PredefinedSplitOutputWithContext(context.Context) GoogleCloudAiplatformV1PredefinedSplitOutput
}

// Assigns input data to training, validation, and test sets based on the value of a provided key. Supported only for tabular Datasets.
type GoogleCloudAiplatformV1PredefinedSplitArgs struct {
	// The key is a name of one of the Dataset's data columns. The value of the key (either the label's value or value in the column) must be one of {`training`, `validation`, `test`}, and it defines to which set the given piece of data is assigned. If for a piece of data the key is not present or has an invalid value, that piece is ignored by the pipeline.
	Key pulumi.StringInput `pulumi:"key"`
}

func (GoogleCloudAiplatformV1PredefinedSplitArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1PredefinedSplit)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1PredefinedSplitArgs) ToGoogleCloudAiplatformV1PredefinedSplitOutput() GoogleCloudAiplatformV1PredefinedSplitOutput {
	return i.ToGoogleCloudAiplatformV1PredefinedSplitOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1PredefinedSplitArgs) ToGoogleCloudAiplatformV1PredefinedSplitOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1PredefinedSplitOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1PredefinedSplitOutput)
}

func (i GoogleCloudAiplatformV1PredefinedSplitArgs) ToGoogleCloudAiplatformV1PredefinedSplitPtrOutput() GoogleCloudAiplatformV1PredefinedSplitPtrOutput {
	return i.ToGoogleCloudAiplatformV1PredefinedSplitPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1PredefinedSplitArgs) ToGoogleCloudAiplatformV1PredefinedSplitPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1PredefinedSplitPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1PredefinedSplitOutput).ToGoogleCloudAiplatformV1PredefinedSplitPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1PredefinedSplitPtrInput is an input type that accepts GoogleCloudAiplatformV1PredefinedSplitArgs, GoogleCloudAiplatformV1PredefinedSplitPtr and GoogleCloudAiplatformV1PredefinedSplitPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1PredefinedSplitPtrInput` via:
//
//	        GoogleCloudAiplatformV1PredefinedSplitArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1PredefinedSplitPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1PredefinedSplitPtrOutput() GoogleCloudAiplatformV1PredefinedSplitPtrOutput
	ToGoogleCloudAiplatformV1PredefinedSplitPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1PredefinedSplitPtrOutput
}

type googleCloudAiplatformV1PredefinedSplitPtrType GoogleCloudAiplatformV1PredefinedSplitArgs

func GoogleCloudAiplatformV1PredefinedSplitPtr(v *GoogleCloudAiplatformV1PredefinedSplitArgs) GoogleCloudAiplatformV1PredefinedSplitPtrInput {
	return (*googleCloudAiplatformV1PredefinedSplitPtrType)(v)
}

func (*googleCloudAiplatformV1PredefinedSplitPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1PredefinedSplit)(nil)).Elem()
}

func (i *googleCloudAiplatformV1PredefinedSplitPtrType) ToGoogleCloudAiplatformV1PredefinedSplitPtrOutput() GoogleCloudAiplatformV1PredefinedSplitPtrOutput {
	return i.ToGoogleCloudAiplatformV1PredefinedSplitPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1PredefinedSplitPtrType) ToGoogleCloudAiplatformV1PredefinedSplitPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1PredefinedSplitPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1PredefinedSplitPtrOutput)
}

// Assigns input data to training, validation, and test sets based on the value of a provided key. Supported only for tabular Datasets.
type GoogleCloudAiplatformV1PredefinedSplitOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1PredefinedSplitOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1PredefinedSplit)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1PredefinedSplitOutput) ToGoogleCloudAiplatformV1PredefinedSplitOutput() GoogleCloudAiplatformV1PredefinedSplitOutput {
	return o
}

func (o GoogleCloudAiplatformV1PredefinedSplitOutput) ToGoogleCloudAiplatformV1PredefinedSplitOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1PredefinedSplitOutput {
	return o
}

func (o GoogleCloudAiplatformV1PredefinedSplitOutput) ToGoogleCloudAiplatformV1PredefinedSplitPtrOutput() GoogleCloudAiplatformV1PredefinedSplitPtrOutput {
	return o.ToGoogleCloudAiplatformV1PredefinedSplitPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1PredefinedSplitOutput) ToGoogleCloudAiplatformV1PredefinedSplitPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1PredefinedSplitPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1PredefinedSplit) *GoogleCloudAiplatformV1PredefinedSplit {
		return &v
	}).(GoogleCloudAiplatformV1PredefinedSplitPtrOutput)
}

// The key is a name of one of the Dataset's data columns. The value of the key (either the label's value or value in the column) must be one of {`training`, `validation`, `test`}, and it defines to which set the given piece of data is assigned. If for a piece of data the key is not present or has an invalid value, that piece is ignored by the pipeline.
func (o GoogleCloudAiplatformV1PredefinedSplitOutput) Key() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PredefinedSplit) string { return v.Key }).(pulumi.StringOutput)
}

type GoogleCloudAiplatformV1PredefinedSplitPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1PredefinedSplitPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1PredefinedSplit)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1PredefinedSplitPtrOutput) ToGoogleCloudAiplatformV1PredefinedSplitPtrOutput() GoogleCloudAiplatformV1PredefinedSplitPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1PredefinedSplitPtrOutput) ToGoogleCloudAiplatformV1PredefinedSplitPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1PredefinedSplitPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1PredefinedSplitPtrOutput) Elem() GoogleCloudAiplatformV1PredefinedSplitOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1PredefinedSplit) GoogleCloudAiplatformV1PredefinedSplit {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1PredefinedSplit
		return ret
	}).(GoogleCloudAiplatformV1PredefinedSplitOutput)
}

// The key is a name of one of the Dataset's data columns. The value of the key (either the label's value or value in the column) must be one of {`training`, `validation`, `test`}, and it defines to which set the given piece of data is assigned. If for a piece of data the key is not present or has an invalid value, that piece is ignored by the pipeline.
func (o GoogleCloudAiplatformV1PredefinedSplitPtrOutput) Key() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1PredefinedSplit) *string {
		if v == nil {
			return nil
		}
		return &v.Key
	}).(pulumi.StringPtrOutput)
}

// Assigns input data to training, validation, and test sets based on the value of a provided key. Supported only for tabular Datasets.
type GoogleCloudAiplatformV1PredefinedSplitResponse struct {
	// The key is a name of one of the Dataset's data columns. The value of the key (either the label's value or value in the column) must be one of {`training`, `validation`, `test`}, and it defines to which set the given piece of data is assigned. If for a piece of data the key is not present or has an invalid value, that piece is ignored by the pipeline.
	Key string `pulumi:"key"`
}

// Assigns input data to training, validation, and test sets based on the value of a provided key. Supported only for tabular Datasets.
type GoogleCloudAiplatformV1PredefinedSplitResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1PredefinedSplitResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1PredefinedSplitResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1PredefinedSplitResponseOutput) ToGoogleCloudAiplatformV1PredefinedSplitResponseOutput() GoogleCloudAiplatformV1PredefinedSplitResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1PredefinedSplitResponseOutput) ToGoogleCloudAiplatformV1PredefinedSplitResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1PredefinedSplitResponseOutput {
	return o
}

// The key is a name of one of the Dataset's data columns. The value of the key (either the label's value or value in the column) must be one of {`training`, `validation`, `test`}, and it defines to which set the given piece of data is assigned. If for a piece of data the key is not present or has an invalid value, that piece is ignored by the pipeline.
func (o GoogleCloudAiplatformV1PredefinedSplitResponseOutput) Key() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PredefinedSplitResponse) string { return v.Key }).(pulumi.StringOutput)
}

// Configuration for logging request-response to a BigQuery table.
type GoogleCloudAiplatformV1PredictRequestResponseLoggingConfig struct {
	// BigQuery table for logging. If only given a project, a new dataset will be created with name `logging__` where will be made BigQuery-dataset-name compatible (e.g. most special characters will become underscores). If no table name is given, a new table will be created with name `request_response_logging`
	BigqueryDestination *GoogleCloudAiplatformV1BigQueryDestination `pulumi:"bigqueryDestination"`
	// If logging is enabled or not.
	Enabled *bool `pulumi:"enabled"`
	// Percentage of requests to be logged, expressed as a fraction in range(0,1].
	SamplingRate *float64 `pulumi:"samplingRate"`
}

// GoogleCloudAiplatformV1PredictRequestResponseLoggingConfigInput is an input type that accepts GoogleCloudAiplatformV1PredictRequestResponseLoggingConfigArgs and GoogleCloudAiplatformV1PredictRequestResponseLoggingConfigOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1PredictRequestResponseLoggingConfigInput` via:
//
//	GoogleCloudAiplatformV1PredictRequestResponseLoggingConfigArgs{...}
type GoogleCloudAiplatformV1PredictRequestResponseLoggingConfigInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1PredictRequestResponseLoggingConfigOutput() GoogleCloudAiplatformV1PredictRequestResponseLoggingConfigOutput
	ToGoogleCloudAiplatformV1PredictRequestResponseLoggingConfigOutputWithContext(context.Context) GoogleCloudAiplatformV1PredictRequestResponseLoggingConfigOutput
}

// Configuration for logging request-response to a BigQuery table.
type GoogleCloudAiplatformV1PredictRequestResponseLoggingConfigArgs struct {
	// BigQuery table for logging. If only given a project, a new dataset will be created with name `logging__` where will be made BigQuery-dataset-name compatible (e.g. most special characters will become underscores). If no table name is given, a new table will be created with name `request_response_logging`
	BigqueryDestination GoogleCloudAiplatformV1BigQueryDestinationPtrInput `pulumi:"bigqueryDestination"`
	// If logging is enabled or not.
	Enabled pulumi.BoolPtrInput `pulumi:"enabled"`
	// Percentage of requests to be logged, expressed as a fraction in range(0,1].
	SamplingRate pulumi.Float64PtrInput `pulumi:"samplingRate"`
}

func (GoogleCloudAiplatformV1PredictRequestResponseLoggingConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1PredictRequestResponseLoggingConfig)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1PredictRequestResponseLoggingConfigArgs) ToGoogleCloudAiplatformV1PredictRequestResponseLoggingConfigOutput() GoogleCloudAiplatformV1PredictRequestResponseLoggingConfigOutput {
	return i.ToGoogleCloudAiplatformV1PredictRequestResponseLoggingConfigOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1PredictRequestResponseLoggingConfigArgs) ToGoogleCloudAiplatformV1PredictRequestResponseLoggingConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1PredictRequestResponseLoggingConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1PredictRequestResponseLoggingConfigOutput)
}

func (i GoogleCloudAiplatformV1PredictRequestResponseLoggingConfigArgs) ToGoogleCloudAiplatformV1PredictRequestResponseLoggingConfigPtrOutput() GoogleCloudAiplatformV1PredictRequestResponseLoggingConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1PredictRequestResponseLoggingConfigPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1PredictRequestResponseLoggingConfigArgs) ToGoogleCloudAiplatformV1PredictRequestResponseLoggingConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1PredictRequestResponseLoggingConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1PredictRequestResponseLoggingConfigOutput).ToGoogleCloudAiplatformV1PredictRequestResponseLoggingConfigPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1PredictRequestResponseLoggingConfigPtrInput is an input type that accepts GoogleCloudAiplatformV1PredictRequestResponseLoggingConfigArgs, GoogleCloudAiplatformV1PredictRequestResponseLoggingConfigPtr and GoogleCloudAiplatformV1PredictRequestResponseLoggingConfigPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1PredictRequestResponseLoggingConfigPtrInput` via:
//
//	        GoogleCloudAiplatformV1PredictRequestResponseLoggingConfigArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1PredictRequestResponseLoggingConfigPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1PredictRequestResponseLoggingConfigPtrOutput() GoogleCloudAiplatformV1PredictRequestResponseLoggingConfigPtrOutput
	ToGoogleCloudAiplatformV1PredictRequestResponseLoggingConfigPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1PredictRequestResponseLoggingConfigPtrOutput
}

type googleCloudAiplatformV1PredictRequestResponseLoggingConfigPtrType GoogleCloudAiplatformV1PredictRequestResponseLoggingConfigArgs

func GoogleCloudAiplatformV1PredictRequestResponseLoggingConfigPtr(v *GoogleCloudAiplatformV1PredictRequestResponseLoggingConfigArgs) GoogleCloudAiplatformV1PredictRequestResponseLoggingConfigPtrInput {
	return (*googleCloudAiplatformV1PredictRequestResponseLoggingConfigPtrType)(v)
}

func (*googleCloudAiplatformV1PredictRequestResponseLoggingConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1PredictRequestResponseLoggingConfig)(nil)).Elem()
}

func (i *googleCloudAiplatformV1PredictRequestResponseLoggingConfigPtrType) ToGoogleCloudAiplatformV1PredictRequestResponseLoggingConfigPtrOutput() GoogleCloudAiplatformV1PredictRequestResponseLoggingConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1PredictRequestResponseLoggingConfigPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1PredictRequestResponseLoggingConfigPtrType) ToGoogleCloudAiplatformV1PredictRequestResponseLoggingConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1PredictRequestResponseLoggingConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1PredictRequestResponseLoggingConfigPtrOutput)
}

// Configuration for logging request-response to a BigQuery table.
type GoogleCloudAiplatformV1PredictRequestResponseLoggingConfigOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1PredictRequestResponseLoggingConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1PredictRequestResponseLoggingConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1PredictRequestResponseLoggingConfigOutput) ToGoogleCloudAiplatformV1PredictRequestResponseLoggingConfigOutput() GoogleCloudAiplatformV1PredictRequestResponseLoggingConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1PredictRequestResponseLoggingConfigOutput) ToGoogleCloudAiplatformV1PredictRequestResponseLoggingConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1PredictRequestResponseLoggingConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1PredictRequestResponseLoggingConfigOutput) ToGoogleCloudAiplatformV1PredictRequestResponseLoggingConfigPtrOutput() GoogleCloudAiplatformV1PredictRequestResponseLoggingConfigPtrOutput {
	return o.ToGoogleCloudAiplatformV1PredictRequestResponseLoggingConfigPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1PredictRequestResponseLoggingConfigOutput) ToGoogleCloudAiplatformV1PredictRequestResponseLoggingConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1PredictRequestResponseLoggingConfigPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1PredictRequestResponseLoggingConfig) *GoogleCloudAiplatformV1PredictRequestResponseLoggingConfig {
		return &v
	}).(GoogleCloudAiplatformV1PredictRequestResponseLoggingConfigPtrOutput)
}

// BigQuery table for logging. If only given a project, a new dataset will be created with name `logging__` where will be made BigQuery-dataset-name compatible (e.g. most special characters will become underscores). If no table name is given, a new table will be created with name `request_response_logging`
func (o GoogleCloudAiplatformV1PredictRequestResponseLoggingConfigOutput) BigqueryDestination() GoogleCloudAiplatformV1BigQueryDestinationPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PredictRequestResponseLoggingConfig) *GoogleCloudAiplatformV1BigQueryDestination {
		return v.BigqueryDestination
	}).(GoogleCloudAiplatformV1BigQueryDestinationPtrOutput)
}

// If logging is enabled or not.
func (o GoogleCloudAiplatformV1PredictRequestResponseLoggingConfigOutput) Enabled() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PredictRequestResponseLoggingConfig) *bool { return v.Enabled }).(pulumi.BoolPtrOutput)
}

// Percentage of requests to be logged, expressed as a fraction in range(0,1].
func (o GoogleCloudAiplatformV1PredictRequestResponseLoggingConfigOutput) SamplingRate() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PredictRequestResponseLoggingConfig) *float64 { return v.SamplingRate }).(pulumi.Float64PtrOutput)
}

type GoogleCloudAiplatformV1PredictRequestResponseLoggingConfigPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1PredictRequestResponseLoggingConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1PredictRequestResponseLoggingConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1PredictRequestResponseLoggingConfigPtrOutput) ToGoogleCloudAiplatformV1PredictRequestResponseLoggingConfigPtrOutput() GoogleCloudAiplatformV1PredictRequestResponseLoggingConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1PredictRequestResponseLoggingConfigPtrOutput) ToGoogleCloudAiplatformV1PredictRequestResponseLoggingConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1PredictRequestResponseLoggingConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1PredictRequestResponseLoggingConfigPtrOutput) Elem() GoogleCloudAiplatformV1PredictRequestResponseLoggingConfigOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1PredictRequestResponseLoggingConfig) GoogleCloudAiplatformV1PredictRequestResponseLoggingConfig {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1PredictRequestResponseLoggingConfig
		return ret
	}).(GoogleCloudAiplatformV1PredictRequestResponseLoggingConfigOutput)
}

// BigQuery table for logging. If only given a project, a new dataset will be created with name `logging__` where will be made BigQuery-dataset-name compatible (e.g. most special characters will become underscores). If no table name is given, a new table will be created with name `request_response_logging`
func (o GoogleCloudAiplatformV1PredictRequestResponseLoggingConfigPtrOutput) BigqueryDestination() GoogleCloudAiplatformV1BigQueryDestinationPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1PredictRequestResponseLoggingConfig) *GoogleCloudAiplatformV1BigQueryDestination {
		if v == nil {
			return nil
		}
		return v.BigqueryDestination
	}).(GoogleCloudAiplatformV1BigQueryDestinationPtrOutput)
}

// If logging is enabled or not.
func (o GoogleCloudAiplatformV1PredictRequestResponseLoggingConfigPtrOutput) Enabled() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1PredictRequestResponseLoggingConfig) *bool {
		if v == nil {
			return nil
		}
		return v.Enabled
	}).(pulumi.BoolPtrOutput)
}

// Percentage of requests to be logged, expressed as a fraction in range(0,1].
func (o GoogleCloudAiplatformV1PredictRequestResponseLoggingConfigPtrOutput) SamplingRate() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1PredictRequestResponseLoggingConfig) *float64 {
		if v == nil {
			return nil
		}
		return v.SamplingRate
	}).(pulumi.Float64PtrOutput)
}

// Configuration for logging request-response to a BigQuery table.
type GoogleCloudAiplatformV1PredictRequestResponseLoggingConfigResponse struct {
	// BigQuery table for logging. If only given a project, a new dataset will be created with name `logging__` where will be made BigQuery-dataset-name compatible (e.g. most special characters will become underscores). If no table name is given, a new table will be created with name `request_response_logging`
	BigqueryDestination GoogleCloudAiplatformV1BigQueryDestinationResponse `pulumi:"bigqueryDestination"`
	// If logging is enabled or not.
	Enabled bool `pulumi:"enabled"`
	// Percentage of requests to be logged, expressed as a fraction in range(0,1].
	SamplingRate float64 `pulumi:"samplingRate"`
}

// Configuration for logging request-response to a BigQuery table.
type GoogleCloudAiplatformV1PredictRequestResponseLoggingConfigResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1PredictRequestResponseLoggingConfigResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1PredictRequestResponseLoggingConfigResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1PredictRequestResponseLoggingConfigResponseOutput) ToGoogleCloudAiplatformV1PredictRequestResponseLoggingConfigResponseOutput() GoogleCloudAiplatformV1PredictRequestResponseLoggingConfigResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1PredictRequestResponseLoggingConfigResponseOutput) ToGoogleCloudAiplatformV1PredictRequestResponseLoggingConfigResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1PredictRequestResponseLoggingConfigResponseOutput {
	return o
}

// BigQuery table for logging. If only given a project, a new dataset will be created with name `logging__` where will be made BigQuery-dataset-name compatible (e.g. most special characters will become underscores). If no table name is given, a new table will be created with name `request_response_logging`
func (o GoogleCloudAiplatformV1PredictRequestResponseLoggingConfigResponseOutput) BigqueryDestination() GoogleCloudAiplatformV1BigQueryDestinationResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PredictRequestResponseLoggingConfigResponse) GoogleCloudAiplatformV1BigQueryDestinationResponse {
		return v.BigqueryDestination
	}).(GoogleCloudAiplatformV1BigQueryDestinationResponseOutput)
}

// If logging is enabled or not.
func (o GoogleCloudAiplatformV1PredictRequestResponseLoggingConfigResponseOutput) Enabled() pulumi.BoolOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PredictRequestResponseLoggingConfigResponse) bool { return v.Enabled }).(pulumi.BoolOutput)
}

// Percentage of requests to be logged, expressed as a fraction in range(0,1].
func (o GoogleCloudAiplatformV1PredictRequestResponseLoggingConfigResponseOutput) SamplingRate() pulumi.Float64Output {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PredictRequestResponseLoggingConfigResponse) float64 {
		return v.SamplingRate
	}).(pulumi.Float64Output)
}

// Contains the schemata used in Model's predictions and explanations via PredictionService.Predict, PredictionService.Explain and BatchPredictionJob.
type GoogleCloudAiplatformV1PredictSchemata struct {
	// Immutable. Points to a YAML file stored on Google Cloud Storage describing the format of a single instance, which are used in PredictRequest.instances, ExplainRequest.instances and BatchPredictionJob.input_config. The schema is defined as an OpenAPI 3.0.2 [Schema Object](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject). AutoML Models always have this field populated by Vertex AI. Note: The URI given on output will be immutable and probably different, including the URI scheme, than the one given on input. The output URI will point to a location where the user only has a read access.
	InstanceSchemaUri *string `pulumi:"instanceSchemaUri"`
	// Immutable. Points to a YAML file stored on Google Cloud Storage describing the parameters of prediction and explanation via PredictRequest.parameters, ExplainRequest.parameters and BatchPredictionJob.model_parameters. The schema is defined as an OpenAPI 3.0.2 [Schema Object](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject). AutoML Models always have this field populated by Vertex AI, if no parameters are supported, then it is set to an empty string. Note: The URI given on output will be immutable and probably different, including the URI scheme, than the one given on input. The output URI will point to a location where the user only has a read access.
	ParametersSchemaUri *string `pulumi:"parametersSchemaUri"`
	// Immutable. Points to a YAML file stored on Google Cloud Storage describing the format of a single prediction produced by this Model, which are returned via PredictResponse.predictions, ExplainResponse.explanations, and BatchPredictionJob.output_config. The schema is defined as an OpenAPI 3.0.2 [Schema Object](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject). AutoML Models always have this field populated by Vertex AI. Note: The URI given on output will be immutable and probably different, including the URI scheme, than the one given on input. The output URI will point to a location where the user only has a read access.
	PredictionSchemaUri *string `pulumi:"predictionSchemaUri"`
}

// GoogleCloudAiplatformV1PredictSchemataInput is an input type that accepts GoogleCloudAiplatformV1PredictSchemataArgs and GoogleCloudAiplatformV1PredictSchemataOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1PredictSchemataInput` via:
//
//	GoogleCloudAiplatformV1PredictSchemataArgs{...}
type GoogleCloudAiplatformV1PredictSchemataInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1PredictSchemataOutput() GoogleCloudAiplatformV1PredictSchemataOutput
	ToGoogleCloudAiplatformV1PredictSchemataOutputWithContext(context.Context) GoogleCloudAiplatformV1PredictSchemataOutput
}

// Contains the schemata used in Model's predictions and explanations via PredictionService.Predict, PredictionService.Explain and BatchPredictionJob.
type GoogleCloudAiplatformV1PredictSchemataArgs struct {
	// Immutable. Points to a YAML file stored on Google Cloud Storage describing the format of a single instance, which are used in PredictRequest.instances, ExplainRequest.instances and BatchPredictionJob.input_config. The schema is defined as an OpenAPI 3.0.2 [Schema Object](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject). AutoML Models always have this field populated by Vertex AI. Note: The URI given on output will be immutable and probably different, including the URI scheme, than the one given on input. The output URI will point to a location where the user only has a read access.
	InstanceSchemaUri pulumi.StringPtrInput `pulumi:"instanceSchemaUri"`
	// Immutable. Points to a YAML file stored on Google Cloud Storage describing the parameters of prediction and explanation via PredictRequest.parameters, ExplainRequest.parameters and BatchPredictionJob.model_parameters. The schema is defined as an OpenAPI 3.0.2 [Schema Object](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject). AutoML Models always have this field populated by Vertex AI, if no parameters are supported, then it is set to an empty string. Note: The URI given on output will be immutable and probably different, including the URI scheme, than the one given on input. The output URI will point to a location where the user only has a read access.
	ParametersSchemaUri pulumi.StringPtrInput `pulumi:"parametersSchemaUri"`
	// Immutable. Points to a YAML file stored on Google Cloud Storage describing the format of a single prediction produced by this Model, which are returned via PredictResponse.predictions, ExplainResponse.explanations, and BatchPredictionJob.output_config. The schema is defined as an OpenAPI 3.0.2 [Schema Object](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject). AutoML Models always have this field populated by Vertex AI. Note: The URI given on output will be immutable and probably different, including the URI scheme, than the one given on input. The output URI will point to a location where the user only has a read access.
	PredictionSchemaUri pulumi.StringPtrInput `pulumi:"predictionSchemaUri"`
}

func (GoogleCloudAiplatformV1PredictSchemataArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1PredictSchemata)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1PredictSchemataArgs) ToGoogleCloudAiplatformV1PredictSchemataOutput() GoogleCloudAiplatformV1PredictSchemataOutput {
	return i.ToGoogleCloudAiplatformV1PredictSchemataOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1PredictSchemataArgs) ToGoogleCloudAiplatformV1PredictSchemataOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1PredictSchemataOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1PredictSchemataOutput)
}

func (i GoogleCloudAiplatformV1PredictSchemataArgs) ToGoogleCloudAiplatformV1PredictSchemataPtrOutput() GoogleCloudAiplatformV1PredictSchemataPtrOutput {
	return i.ToGoogleCloudAiplatformV1PredictSchemataPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1PredictSchemataArgs) ToGoogleCloudAiplatformV1PredictSchemataPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1PredictSchemataPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1PredictSchemataOutput).ToGoogleCloudAiplatformV1PredictSchemataPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1PredictSchemataPtrInput is an input type that accepts GoogleCloudAiplatformV1PredictSchemataArgs, GoogleCloudAiplatformV1PredictSchemataPtr and GoogleCloudAiplatformV1PredictSchemataPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1PredictSchemataPtrInput` via:
//
//	        GoogleCloudAiplatformV1PredictSchemataArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1PredictSchemataPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1PredictSchemataPtrOutput() GoogleCloudAiplatformV1PredictSchemataPtrOutput
	ToGoogleCloudAiplatformV1PredictSchemataPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1PredictSchemataPtrOutput
}

type googleCloudAiplatformV1PredictSchemataPtrType GoogleCloudAiplatformV1PredictSchemataArgs

func GoogleCloudAiplatformV1PredictSchemataPtr(v *GoogleCloudAiplatformV1PredictSchemataArgs) GoogleCloudAiplatformV1PredictSchemataPtrInput {
	return (*googleCloudAiplatformV1PredictSchemataPtrType)(v)
}

func (*googleCloudAiplatformV1PredictSchemataPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1PredictSchemata)(nil)).Elem()
}

func (i *googleCloudAiplatformV1PredictSchemataPtrType) ToGoogleCloudAiplatformV1PredictSchemataPtrOutput() GoogleCloudAiplatformV1PredictSchemataPtrOutput {
	return i.ToGoogleCloudAiplatformV1PredictSchemataPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1PredictSchemataPtrType) ToGoogleCloudAiplatformV1PredictSchemataPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1PredictSchemataPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1PredictSchemataPtrOutput)
}

// Contains the schemata used in Model's predictions and explanations via PredictionService.Predict, PredictionService.Explain and BatchPredictionJob.
type GoogleCloudAiplatformV1PredictSchemataOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1PredictSchemataOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1PredictSchemata)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1PredictSchemataOutput) ToGoogleCloudAiplatformV1PredictSchemataOutput() GoogleCloudAiplatformV1PredictSchemataOutput {
	return o
}

func (o GoogleCloudAiplatformV1PredictSchemataOutput) ToGoogleCloudAiplatformV1PredictSchemataOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1PredictSchemataOutput {
	return o
}

func (o GoogleCloudAiplatformV1PredictSchemataOutput) ToGoogleCloudAiplatformV1PredictSchemataPtrOutput() GoogleCloudAiplatformV1PredictSchemataPtrOutput {
	return o.ToGoogleCloudAiplatformV1PredictSchemataPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1PredictSchemataOutput) ToGoogleCloudAiplatformV1PredictSchemataPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1PredictSchemataPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1PredictSchemata) *GoogleCloudAiplatformV1PredictSchemata {
		return &v
	}).(GoogleCloudAiplatformV1PredictSchemataPtrOutput)
}

// Immutable. Points to a YAML file stored on Google Cloud Storage describing the format of a single instance, which are used in PredictRequest.instances, ExplainRequest.instances and BatchPredictionJob.input_config. The schema is defined as an OpenAPI 3.0.2 [Schema Object](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject). AutoML Models always have this field populated by Vertex AI. Note: The URI given on output will be immutable and probably different, including the URI scheme, than the one given on input. The output URI will point to a location where the user only has a read access.
func (o GoogleCloudAiplatformV1PredictSchemataOutput) InstanceSchemaUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PredictSchemata) *string { return v.InstanceSchemaUri }).(pulumi.StringPtrOutput)
}

// Immutable. Points to a YAML file stored on Google Cloud Storage describing the parameters of prediction and explanation via PredictRequest.parameters, ExplainRequest.parameters and BatchPredictionJob.model_parameters. The schema is defined as an OpenAPI 3.0.2 [Schema Object](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject). AutoML Models always have this field populated by Vertex AI, if no parameters are supported, then it is set to an empty string. Note: The URI given on output will be immutable and probably different, including the URI scheme, than the one given on input. The output URI will point to a location where the user only has a read access.
func (o GoogleCloudAiplatformV1PredictSchemataOutput) ParametersSchemaUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PredictSchemata) *string { return v.ParametersSchemaUri }).(pulumi.StringPtrOutput)
}

// Immutable. Points to a YAML file stored on Google Cloud Storage describing the format of a single prediction produced by this Model, which are returned via PredictResponse.predictions, ExplainResponse.explanations, and BatchPredictionJob.output_config. The schema is defined as an OpenAPI 3.0.2 [Schema Object](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject). AutoML Models always have this field populated by Vertex AI. Note: The URI given on output will be immutable and probably different, including the URI scheme, than the one given on input. The output URI will point to a location where the user only has a read access.
func (o GoogleCloudAiplatformV1PredictSchemataOutput) PredictionSchemaUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PredictSchemata) *string { return v.PredictionSchemaUri }).(pulumi.StringPtrOutput)
}

type GoogleCloudAiplatformV1PredictSchemataPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1PredictSchemataPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1PredictSchemata)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1PredictSchemataPtrOutput) ToGoogleCloudAiplatformV1PredictSchemataPtrOutput() GoogleCloudAiplatformV1PredictSchemataPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1PredictSchemataPtrOutput) ToGoogleCloudAiplatformV1PredictSchemataPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1PredictSchemataPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1PredictSchemataPtrOutput) Elem() GoogleCloudAiplatformV1PredictSchemataOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1PredictSchemata) GoogleCloudAiplatformV1PredictSchemata {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1PredictSchemata
		return ret
	}).(GoogleCloudAiplatformV1PredictSchemataOutput)
}

// Immutable. Points to a YAML file stored on Google Cloud Storage describing the format of a single instance, which are used in PredictRequest.instances, ExplainRequest.instances and BatchPredictionJob.input_config. The schema is defined as an OpenAPI 3.0.2 [Schema Object](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject). AutoML Models always have this field populated by Vertex AI. Note: The URI given on output will be immutable and probably different, including the URI scheme, than the one given on input. The output URI will point to a location where the user only has a read access.
func (o GoogleCloudAiplatformV1PredictSchemataPtrOutput) InstanceSchemaUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1PredictSchemata) *string {
		if v == nil {
			return nil
		}
		return v.InstanceSchemaUri
	}).(pulumi.StringPtrOutput)
}

// Immutable. Points to a YAML file stored on Google Cloud Storage describing the parameters of prediction and explanation via PredictRequest.parameters, ExplainRequest.parameters and BatchPredictionJob.model_parameters. The schema is defined as an OpenAPI 3.0.2 [Schema Object](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject). AutoML Models always have this field populated by Vertex AI, if no parameters are supported, then it is set to an empty string. Note: The URI given on output will be immutable and probably different, including the URI scheme, than the one given on input. The output URI will point to a location where the user only has a read access.
func (o GoogleCloudAiplatformV1PredictSchemataPtrOutput) ParametersSchemaUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1PredictSchemata) *string {
		if v == nil {
			return nil
		}
		return v.ParametersSchemaUri
	}).(pulumi.StringPtrOutput)
}

// Immutable. Points to a YAML file stored on Google Cloud Storage describing the format of a single prediction produced by this Model, which are returned via PredictResponse.predictions, ExplainResponse.explanations, and BatchPredictionJob.output_config. The schema is defined as an OpenAPI 3.0.2 [Schema Object](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject). AutoML Models always have this field populated by Vertex AI. Note: The URI given on output will be immutable and probably different, including the URI scheme, than the one given on input. The output URI will point to a location where the user only has a read access.
func (o GoogleCloudAiplatformV1PredictSchemataPtrOutput) PredictionSchemaUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1PredictSchemata) *string {
		if v == nil {
			return nil
		}
		return v.PredictionSchemaUri
	}).(pulumi.StringPtrOutput)
}

// Contains the schemata used in Model's predictions and explanations via PredictionService.Predict, PredictionService.Explain and BatchPredictionJob.
type GoogleCloudAiplatformV1PredictSchemataResponse struct {
	// Immutable. Points to a YAML file stored on Google Cloud Storage describing the format of a single instance, which are used in PredictRequest.instances, ExplainRequest.instances and BatchPredictionJob.input_config. The schema is defined as an OpenAPI 3.0.2 [Schema Object](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject). AutoML Models always have this field populated by Vertex AI. Note: The URI given on output will be immutable and probably different, including the URI scheme, than the one given on input. The output URI will point to a location where the user only has a read access.
	InstanceSchemaUri string `pulumi:"instanceSchemaUri"`
	// Immutable. Points to a YAML file stored on Google Cloud Storage describing the parameters of prediction and explanation via PredictRequest.parameters, ExplainRequest.parameters and BatchPredictionJob.model_parameters. The schema is defined as an OpenAPI 3.0.2 [Schema Object](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject). AutoML Models always have this field populated by Vertex AI, if no parameters are supported, then it is set to an empty string. Note: The URI given on output will be immutable and probably different, including the URI scheme, than the one given on input. The output URI will point to a location where the user only has a read access.
	ParametersSchemaUri string `pulumi:"parametersSchemaUri"`
	// Immutable. Points to a YAML file stored on Google Cloud Storage describing the format of a single prediction produced by this Model, which are returned via PredictResponse.predictions, ExplainResponse.explanations, and BatchPredictionJob.output_config. The schema is defined as an OpenAPI 3.0.2 [Schema Object](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject). AutoML Models always have this field populated by Vertex AI. Note: The URI given on output will be immutable and probably different, including the URI scheme, than the one given on input. The output URI will point to a location where the user only has a read access.
	PredictionSchemaUri string `pulumi:"predictionSchemaUri"`
}

// Contains the schemata used in Model's predictions and explanations via PredictionService.Predict, PredictionService.Explain and BatchPredictionJob.
type GoogleCloudAiplatformV1PredictSchemataResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1PredictSchemataResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1PredictSchemataResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1PredictSchemataResponseOutput) ToGoogleCloudAiplatformV1PredictSchemataResponseOutput() GoogleCloudAiplatformV1PredictSchemataResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1PredictSchemataResponseOutput) ToGoogleCloudAiplatformV1PredictSchemataResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1PredictSchemataResponseOutput {
	return o
}

// Immutable. Points to a YAML file stored on Google Cloud Storage describing the format of a single instance, which are used in PredictRequest.instances, ExplainRequest.instances and BatchPredictionJob.input_config. The schema is defined as an OpenAPI 3.0.2 [Schema Object](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject). AutoML Models always have this field populated by Vertex AI. Note: The URI given on output will be immutable and probably different, including the URI scheme, than the one given on input. The output URI will point to a location where the user only has a read access.
func (o GoogleCloudAiplatformV1PredictSchemataResponseOutput) InstanceSchemaUri() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PredictSchemataResponse) string { return v.InstanceSchemaUri }).(pulumi.StringOutput)
}

// Immutable. Points to a YAML file stored on Google Cloud Storage describing the parameters of prediction and explanation via PredictRequest.parameters, ExplainRequest.parameters and BatchPredictionJob.model_parameters. The schema is defined as an OpenAPI 3.0.2 [Schema Object](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject). AutoML Models always have this field populated by Vertex AI, if no parameters are supported, then it is set to an empty string. Note: The URI given on output will be immutable and probably different, including the URI scheme, than the one given on input. The output URI will point to a location where the user only has a read access.
func (o GoogleCloudAiplatformV1PredictSchemataResponseOutput) ParametersSchemaUri() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PredictSchemataResponse) string { return v.ParametersSchemaUri }).(pulumi.StringOutput)
}

// Immutable. Points to a YAML file stored on Google Cloud Storage describing the format of a single prediction produced by this Model, which are returned via PredictResponse.predictions, ExplainResponse.explanations, and BatchPredictionJob.output_config. The schema is defined as an OpenAPI 3.0.2 [Schema Object](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject). AutoML Models always have this field populated by Vertex AI. Note: The URI given on output will be immutable and probably different, including the URI scheme, than the one given on input. The output URI will point to a location where the user only has a read access.
func (o GoogleCloudAiplatformV1PredictSchemataResponseOutput) PredictionSchemaUri() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PredictSchemataResponse) string { return v.PredictionSchemaUri }).(pulumi.StringOutput)
}

// Preset configuration for example-based explanations
type GoogleCloudAiplatformV1Presets struct {
	// The modality of the uploaded model, which automatically configures the distance measurement and feature normalization for the underlying example index and queries. If your model does not precisely fit one of these types, it is okay to choose the closest type.
	Modality *GoogleCloudAiplatformV1PresetsModality `pulumi:"modality"`
	// Preset option controlling parameters for speed-precision trade-off when querying for examples. If omitted, defaults to `PRECISE`.
	Query *GoogleCloudAiplatformV1PresetsQuery `pulumi:"query"`
}

// GoogleCloudAiplatformV1PresetsInput is an input type that accepts GoogleCloudAiplatformV1PresetsArgs and GoogleCloudAiplatformV1PresetsOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1PresetsInput` via:
//
//	GoogleCloudAiplatformV1PresetsArgs{...}
type GoogleCloudAiplatformV1PresetsInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1PresetsOutput() GoogleCloudAiplatformV1PresetsOutput
	ToGoogleCloudAiplatformV1PresetsOutputWithContext(context.Context) GoogleCloudAiplatformV1PresetsOutput
}

// Preset configuration for example-based explanations
type GoogleCloudAiplatformV1PresetsArgs struct {
	// The modality of the uploaded model, which automatically configures the distance measurement and feature normalization for the underlying example index and queries. If your model does not precisely fit one of these types, it is okay to choose the closest type.
	Modality GoogleCloudAiplatformV1PresetsModalityPtrInput `pulumi:"modality"`
	// Preset option controlling parameters for speed-precision trade-off when querying for examples. If omitted, defaults to `PRECISE`.
	Query GoogleCloudAiplatformV1PresetsQueryPtrInput `pulumi:"query"`
}

func (GoogleCloudAiplatformV1PresetsArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1Presets)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1PresetsArgs) ToGoogleCloudAiplatformV1PresetsOutput() GoogleCloudAiplatformV1PresetsOutput {
	return i.ToGoogleCloudAiplatformV1PresetsOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1PresetsArgs) ToGoogleCloudAiplatformV1PresetsOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1PresetsOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1PresetsOutput)
}

func (i GoogleCloudAiplatformV1PresetsArgs) ToGoogleCloudAiplatformV1PresetsPtrOutput() GoogleCloudAiplatformV1PresetsPtrOutput {
	return i.ToGoogleCloudAiplatformV1PresetsPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1PresetsArgs) ToGoogleCloudAiplatformV1PresetsPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1PresetsPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1PresetsOutput).ToGoogleCloudAiplatformV1PresetsPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1PresetsPtrInput is an input type that accepts GoogleCloudAiplatformV1PresetsArgs, GoogleCloudAiplatformV1PresetsPtr and GoogleCloudAiplatformV1PresetsPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1PresetsPtrInput` via:
//
//	        GoogleCloudAiplatformV1PresetsArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1PresetsPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1PresetsPtrOutput() GoogleCloudAiplatformV1PresetsPtrOutput
	ToGoogleCloudAiplatformV1PresetsPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1PresetsPtrOutput
}

type googleCloudAiplatformV1PresetsPtrType GoogleCloudAiplatformV1PresetsArgs

func GoogleCloudAiplatformV1PresetsPtr(v *GoogleCloudAiplatformV1PresetsArgs) GoogleCloudAiplatformV1PresetsPtrInput {
	return (*googleCloudAiplatformV1PresetsPtrType)(v)
}

func (*googleCloudAiplatformV1PresetsPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1Presets)(nil)).Elem()
}

func (i *googleCloudAiplatformV1PresetsPtrType) ToGoogleCloudAiplatformV1PresetsPtrOutput() GoogleCloudAiplatformV1PresetsPtrOutput {
	return i.ToGoogleCloudAiplatformV1PresetsPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1PresetsPtrType) ToGoogleCloudAiplatformV1PresetsPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1PresetsPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1PresetsPtrOutput)
}

// Preset configuration for example-based explanations
type GoogleCloudAiplatformV1PresetsOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1PresetsOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1Presets)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1PresetsOutput) ToGoogleCloudAiplatformV1PresetsOutput() GoogleCloudAiplatformV1PresetsOutput {
	return o
}

func (o GoogleCloudAiplatformV1PresetsOutput) ToGoogleCloudAiplatformV1PresetsOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1PresetsOutput {
	return o
}

func (o GoogleCloudAiplatformV1PresetsOutput) ToGoogleCloudAiplatformV1PresetsPtrOutput() GoogleCloudAiplatformV1PresetsPtrOutput {
	return o.ToGoogleCloudAiplatformV1PresetsPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1PresetsOutput) ToGoogleCloudAiplatformV1PresetsPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1PresetsPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1Presets) *GoogleCloudAiplatformV1Presets {
		return &v
	}).(GoogleCloudAiplatformV1PresetsPtrOutput)
}

// The modality of the uploaded model, which automatically configures the distance measurement and feature normalization for the underlying example index and queries. If your model does not precisely fit one of these types, it is okay to choose the closest type.
func (o GoogleCloudAiplatformV1PresetsOutput) Modality() GoogleCloudAiplatformV1PresetsModalityPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1Presets) *GoogleCloudAiplatformV1PresetsModality { return v.Modality }).(GoogleCloudAiplatformV1PresetsModalityPtrOutput)
}

// Preset option controlling parameters for speed-precision trade-off when querying for examples. If omitted, defaults to `PRECISE`.
func (o GoogleCloudAiplatformV1PresetsOutput) Query() GoogleCloudAiplatformV1PresetsQueryPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1Presets) *GoogleCloudAiplatformV1PresetsQuery { return v.Query }).(GoogleCloudAiplatformV1PresetsQueryPtrOutput)
}

type GoogleCloudAiplatformV1PresetsPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1PresetsPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1Presets)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1PresetsPtrOutput) ToGoogleCloudAiplatformV1PresetsPtrOutput() GoogleCloudAiplatformV1PresetsPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1PresetsPtrOutput) ToGoogleCloudAiplatformV1PresetsPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1PresetsPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1PresetsPtrOutput) Elem() GoogleCloudAiplatformV1PresetsOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1Presets) GoogleCloudAiplatformV1Presets {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1Presets
		return ret
	}).(GoogleCloudAiplatformV1PresetsOutput)
}

// The modality of the uploaded model, which automatically configures the distance measurement and feature normalization for the underlying example index and queries. If your model does not precisely fit one of these types, it is okay to choose the closest type.
func (o GoogleCloudAiplatformV1PresetsPtrOutput) Modality() GoogleCloudAiplatformV1PresetsModalityPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1Presets) *GoogleCloudAiplatformV1PresetsModality {
		if v == nil {
			return nil
		}
		return v.Modality
	}).(GoogleCloudAiplatformV1PresetsModalityPtrOutput)
}

// Preset option controlling parameters for speed-precision trade-off when querying for examples. If omitted, defaults to `PRECISE`.
func (o GoogleCloudAiplatformV1PresetsPtrOutput) Query() GoogleCloudAiplatformV1PresetsQueryPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1Presets) *GoogleCloudAiplatformV1PresetsQuery {
		if v == nil {
			return nil
		}
		return v.Query
	}).(GoogleCloudAiplatformV1PresetsQueryPtrOutput)
}

// Preset configuration for example-based explanations
type GoogleCloudAiplatformV1PresetsResponse struct {
	// The modality of the uploaded model, which automatically configures the distance measurement and feature normalization for the underlying example index and queries. If your model does not precisely fit one of these types, it is okay to choose the closest type.
	Modality string `pulumi:"modality"`
	// Preset option controlling parameters for speed-precision trade-off when querying for examples. If omitted, defaults to `PRECISE`.
	Query string `pulumi:"query"`
}

// Preset configuration for example-based explanations
type GoogleCloudAiplatformV1PresetsResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1PresetsResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1PresetsResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1PresetsResponseOutput) ToGoogleCloudAiplatformV1PresetsResponseOutput() GoogleCloudAiplatformV1PresetsResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1PresetsResponseOutput) ToGoogleCloudAiplatformV1PresetsResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1PresetsResponseOutput {
	return o
}

// The modality of the uploaded model, which automatically configures the distance measurement and feature normalization for the underlying example index and queries. If your model does not precisely fit one of these types, it is okay to choose the closest type.
func (o GoogleCloudAiplatformV1PresetsResponseOutput) Modality() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PresetsResponse) string { return v.Modality }).(pulumi.StringOutput)
}

// Preset option controlling parameters for speed-precision trade-off when querying for examples. If omitted, defaults to `PRECISE`.
func (o GoogleCloudAiplatformV1PresetsResponseOutput) Query() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PresetsResponse) string { return v.Query }).(pulumi.StringOutput)
}

// PrivateEndpoints proto is used to provide paths for users to send requests privately. To send request via private service access, use predict_http_uri, explain_http_uri or health_http_uri. To send request via private service connect, use service_attachment.
type GoogleCloudAiplatformV1PrivateEndpointsResponse struct {
	// Http(s) path to send explain requests.
	ExplainHttpUri string `pulumi:"explainHttpUri"`
	// Http(s) path to send health check requests.
	HealthHttpUri string `pulumi:"healthHttpUri"`
	// Http(s) path to send prediction requests.
	PredictHttpUri string `pulumi:"predictHttpUri"`
	// The name of the service attachment resource. Populated if private service connect is enabled.
	ServiceAttachment string `pulumi:"serviceAttachment"`
}

// PrivateEndpoints proto is used to provide paths for users to send requests privately. To send request via private service access, use predict_http_uri, explain_http_uri or health_http_uri. To send request via private service connect, use service_attachment.
type GoogleCloudAiplatformV1PrivateEndpointsResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1PrivateEndpointsResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1PrivateEndpointsResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1PrivateEndpointsResponseOutput) ToGoogleCloudAiplatformV1PrivateEndpointsResponseOutput() GoogleCloudAiplatformV1PrivateEndpointsResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1PrivateEndpointsResponseOutput) ToGoogleCloudAiplatformV1PrivateEndpointsResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1PrivateEndpointsResponseOutput {
	return o
}

// Http(s) path to send explain requests.
func (o GoogleCloudAiplatformV1PrivateEndpointsResponseOutput) ExplainHttpUri() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PrivateEndpointsResponse) string { return v.ExplainHttpUri }).(pulumi.StringOutput)
}

// Http(s) path to send health check requests.
func (o GoogleCloudAiplatformV1PrivateEndpointsResponseOutput) HealthHttpUri() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PrivateEndpointsResponse) string { return v.HealthHttpUri }).(pulumi.StringOutput)
}

// Http(s) path to send prediction requests.
func (o GoogleCloudAiplatformV1PrivateEndpointsResponseOutput) PredictHttpUri() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PrivateEndpointsResponse) string { return v.PredictHttpUri }).(pulumi.StringOutput)
}

// The name of the service attachment resource. Populated if private service connect is enabled.
func (o GoogleCloudAiplatformV1PrivateEndpointsResponseOutput) ServiceAttachment() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PrivateEndpointsResponse) string { return v.ServiceAttachment }).(pulumi.StringOutput)
}

// Represents configuration for private service connect.
type GoogleCloudAiplatformV1PrivateServiceConnectConfig struct {
	// If true, expose the IndexEndpoint via private service connect.
	EnablePrivateServiceConnect bool `pulumi:"enablePrivateServiceConnect"`
	// A list of Projects from which the forwarding rule will target the service attachment.
	ProjectAllowlist []string `pulumi:"projectAllowlist"`
}

// GoogleCloudAiplatformV1PrivateServiceConnectConfigInput is an input type that accepts GoogleCloudAiplatformV1PrivateServiceConnectConfigArgs and GoogleCloudAiplatformV1PrivateServiceConnectConfigOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1PrivateServiceConnectConfigInput` via:
//
//	GoogleCloudAiplatformV1PrivateServiceConnectConfigArgs{...}
type GoogleCloudAiplatformV1PrivateServiceConnectConfigInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1PrivateServiceConnectConfigOutput() GoogleCloudAiplatformV1PrivateServiceConnectConfigOutput
	ToGoogleCloudAiplatformV1PrivateServiceConnectConfigOutputWithContext(context.Context) GoogleCloudAiplatformV1PrivateServiceConnectConfigOutput
}

// Represents configuration for private service connect.
type GoogleCloudAiplatformV1PrivateServiceConnectConfigArgs struct {
	// If true, expose the IndexEndpoint via private service connect.
	EnablePrivateServiceConnect pulumi.BoolInput `pulumi:"enablePrivateServiceConnect"`
	// A list of Projects from which the forwarding rule will target the service attachment.
	ProjectAllowlist pulumi.StringArrayInput `pulumi:"projectAllowlist"`
}

func (GoogleCloudAiplatformV1PrivateServiceConnectConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1PrivateServiceConnectConfig)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1PrivateServiceConnectConfigArgs) ToGoogleCloudAiplatformV1PrivateServiceConnectConfigOutput() GoogleCloudAiplatformV1PrivateServiceConnectConfigOutput {
	return i.ToGoogleCloudAiplatformV1PrivateServiceConnectConfigOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1PrivateServiceConnectConfigArgs) ToGoogleCloudAiplatformV1PrivateServiceConnectConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1PrivateServiceConnectConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1PrivateServiceConnectConfigOutput)
}

func (i GoogleCloudAiplatformV1PrivateServiceConnectConfigArgs) ToGoogleCloudAiplatformV1PrivateServiceConnectConfigPtrOutput() GoogleCloudAiplatformV1PrivateServiceConnectConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1PrivateServiceConnectConfigPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1PrivateServiceConnectConfigArgs) ToGoogleCloudAiplatformV1PrivateServiceConnectConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1PrivateServiceConnectConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1PrivateServiceConnectConfigOutput).ToGoogleCloudAiplatformV1PrivateServiceConnectConfigPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1PrivateServiceConnectConfigPtrInput is an input type that accepts GoogleCloudAiplatformV1PrivateServiceConnectConfigArgs, GoogleCloudAiplatformV1PrivateServiceConnectConfigPtr and GoogleCloudAiplatformV1PrivateServiceConnectConfigPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1PrivateServiceConnectConfigPtrInput` via:
//
//	        GoogleCloudAiplatformV1PrivateServiceConnectConfigArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1PrivateServiceConnectConfigPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1PrivateServiceConnectConfigPtrOutput() GoogleCloudAiplatformV1PrivateServiceConnectConfigPtrOutput
	ToGoogleCloudAiplatformV1PrivateServiceConnectConfigPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1PrivateServiceConnectConfigPtrOutput
}

type googleCloudAiplatformV1PrivateServiceConnectConfigPtrType GoogleCloudAiplatformV1PrivateServiceConnectConfigArgs

func GoogleCloudAiplatformV1PrivateServiceConnectConfigPtr(v *GoogleCloudAiplatformV1PrivateServiceConnectConfigArgs) GoogleCloudAiplatformV1PrivateServiceConnectConfigPtrInput {
	return (*googleCloudAiplatformV1PrivateServiceConnectConfigPtrType)(v)
}

func (*googleCloudAiplatformV1PrivateServiceConnectConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1PrivateServiceConnectConfig)(nil)).Elem()
}

func (i *googleCloudAiplatformV1PrivateServiceConnectConfigPtrType) ToGoogleCloudAiplatformV1PrivateServiceConnectConfigPtrOutput() GoogleCloudAiplatformV1PrivateServiceConnectConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1PrivateServiceConnectConfigPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1PrivateServiceConnectConfigPtrType) ToGoogleCloudAiplatformV1PrivateServiceConnectConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1PrivateServiceConnectConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1PrivateServiceConnectConfigPtrOutput)
}

// Represents configuration for private service connect.
type GoogleCloudAiplatformV1PrivateServiceConnectConfigOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1PrivateServiceConnectConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1PrivateServiceConnectConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1PrivateServiceConnectConfigOutput) ToGoogleCloudAiplatformV1PrivateServiceConnectConfigOutput() GoogleCloudAiplatformV1PrivateServiceConnectConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1PrivateServiceConnectConfigOutput) ToGoogleCloudAiplatformV1PrivateServiceConnectConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1PrivateServiceConnectConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1PrivateServiceConnectConfigOutput) ToGoogleCloudAiplatformV1PrivateServiceConnectConfigPtrOutput() GoogleCloudAiplatformV1PrivateServiceConnectConfigPtrOutput {
	return o.ToGoogleCloudAiplatformV1PrivateServiceConnectConfigPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1PrivateServiceConnectConfigOutput) ToGoogleCloudAiplatformV1PrivateServiceConnectConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1PrivateServiceConnectConfigPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1PrivateServiceConnectConfig) *GoogleCloudAiplatformV1PrivateServiceConnectConfig {
		return &v
	}).(GoogleCloudAiplatformV1PrivateServiceConnectConfigPtrOutput)
}

// If true, expose the IndexEndpoint via private service connect.
func (o GoogleCloudAiplatformV1PrivateServiceConnectConfigOutput) EnablePrivateServiceConnect() pulumi.BoolOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PrivateServiceConnectConfig) bool { return v.EnablePrivateServiceConnect }).(pulumi.BoolOutput)
}

// A list of Projects from which the forwarding rule will target the service attachment.
func (o GoogleCloudAiplatformV1PrivateServiceConnectConfigOutput) ProjectAllowlist() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PrivateServiceConnectConfig) []string { return v.ProjectAllowlist }).(pulumi.StringArrayOutput)
}

type GoogleCloudAiplatformV1PrivateServiceConnectConfigPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1PrivateServiceConnectConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1PrivateServiceConnectConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1PrivateServiceConnectConfigPtrOutput) ToGoogleCloudAiplatformV1PrivateServiceConnectConfigPtrOutput() GoogleCloudAiplatformV1PrivateServiceConnectConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1PrivateServiceConnectConfigPtrOutput) ToGoogleCloudAiplatformV1PrivateServiceConnectConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1PrivateServiceConnectConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1PrivateServiceConnectConfigPtrOutput) Elem() GoogleCloudAiplatformV1PrivateServiceConnectConfigOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1PrivateServiceConnectConfig) GoogleCloudAiplatformV1PrivateServiceConnectConfig {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1PrivateServiceConnectConfig
		return ret
	}).(GoogleCloudAiplatformV1PrivateServiceConnectConfigOutput)
}

// If true, expose the IndexEndpoint via private service connect.
func (o GoogleCloudAiplatformV1PrivateServiceConnectConfigPtrOutput) EnablePrivateServiceConnect() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1PrivateServiceConnectConfig) *bool {
		if v == nil {
			return nil
		}
		return &v.EnablePrivateServiceConnect
	}).(pulumi.BoolPtrOutput)
}

// A list of Projects from which the forwarding rule will target the service attachment.
func (o GoogleCloudAiplatformV1PrivateServiceConnectConfigPtrOutput) ProjectAllowlist() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1PrivateServiceConnectConfig) []string {
		if v == nil {
			return nil
		}
		return v.ProjectAllowlist
	}).(pulumi.StringArrayOutput)
}

// Represents configuration for private service connect.
type GoogleCloudAiplatformV1PrivateServiceConnectConfigResponse struct {
	// If true, expose the IndexEndpoint via private service connect.
	EnablePrivateServiceConnect bool `pulumi:"enablePrivateServiceConnect"`
	// A list of Projects from which the forwarding rule will target the service attachment.
	ProjectAllowlist []string `pulumi:"projectAllowlist"`
}

// Represents configuration for private service connect.
type GoogleCloudAiplatformV1PrivateServiceConnectConfigResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1PrivateServiceConnectConfigResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1PrivateServiceConnectConfigResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1PrivateServiceConnectConfigResponseOutput) ToGoogleCloudAiplatformV1PrivateServiceConnectConfigResponseOutput() GoogleCloudAiplatformV1PrivateServiceConnectConfigResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1PrivateServiceConnectConfigResponseOutput) ToGoogleCloudAiplatformV1PrivateServiceConnectConfigResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1PrivateServiceConnectConfigResponseOutput {
	return o
}

// If true, expose the IndexEndpoint via private service connect.
func (o GoogleCloudAiplatformV1PrivateServiceConnectConfigResponseOutput) EnablePrivateServiceConnect() pulumi.BoolOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PrivateServiceConnectConfigResponse) bool {
		return v.EnablePrivateServiceConnect
	}).(pulumi.BoolOutput)
}

// A list of Projects from which the forwarding rule will target the service attachment.
func (o GoogleCloudAiplatformV1PrivateServiceConnectConfigResponseOutput) ProjectAllowlist() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PrivateServiceConnectConfigResponse) []string { return v.ProjectAllowlist }).(pulumi.StringArrayOutput)
}

// Probe describes a health check to be performed against a container to determine whether it is alive or ready to receive traffic.
type GoogleCloudAiplatformV1Probe struct {
	// Exec specifies the action to take.
	Exec *GoogleCloudAiplatformV1ProbeExecAction `pulumi:"exec"`
	// How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1. Must be less than timeout_seconds. Maps to Kubernetes probe argument 'periodSeconds'.
	PeriodSeconds *int `pulumi:"periodSeconds"`
	// Number of seconds after which the probe times out. Defaults to 1 second. Minimum value is 1. Must be greater or equal to period_seconds. Maps to Kubernetes probe argument 'timeoutSeconds'.
	TimeoutSeconds *int `pulumi:"timeoutSeconds"`
}

// GoogleCloudAiplatformV1ProbeInput is an input type that accepts GoogleCloudAiplatformV1ProbeArgs and GoogleCloudAiplatformV1ProbeOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1ProbeInput` via:
//
//	GoogleCloudAiplatformV1ProbeArgs{...}
type GoogleCloudAiplatformV1ProbeInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1ProbeOutput() GoogleCloudAiplatformV1ProbeOutput
	ToGoogleCloudAiplatformV1ProbeOutputWithContext(context.Context) GoogleCloudAiplatformV1ProbeOutput
}

// Probe describes a health check to be performed against a container to determine whether it is alive or ready to receive traffic.
type GoogleCloudAiplatformV1ProbeArgs struct {
	// Exec specifies the action to take.
	Exec GoogleCloudAiplatformV1ProbeExecActionPtrInput `pulumi:"exec"`
	// How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1. Must be less than timeout_seconds. Maps to Kubernetes probe argument 'periodSeconds'.
	PeriodSeconds pulumi.IntPtrInput `pulumi:"periodSeconds"`
	// Number of seconds after which the probe times out. Defaults to 1 second. Minimum value is 1. Must be greater or equal to period_seconds. Maps to Kubernetes probe argument 'timeoutSeconds'.
	TimeoutSeconds pulumi.IntPtrInput `pulumi:"timeoutSeconds"`
}

func (GoogleCloudAiplatformV1ProbeArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1Probe)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1ProbeArgs) ToGoogleCloudAiplatformV1ProbeOutput() GoogleCloudAiplatformV1ProbeOutput {
	return i.ToGoogleCloudAiplatformV1ProbeOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1ProbeArgs) ToGoogleCloudAiplatformV1ProbeOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ProbeOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1ProbeOutput)
}

func (i GoogleCloudAiplatformV1ProbeArgs) ToGoogleCloudAiplatformV1ProbePtrOutput() GoogleCloudAiplatformV1ProbePtrOutput {
	return i.ToGoogleCloudAiplatformV1ProbePtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1ProbeArgs) ToGoogleCloudAiplatformV1ProbePtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ProbePtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1ProbeOutput).ToGoogleCloudAiplatformV1ProbePtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1ProbePtrInput is an input type that accepts GoogleCloudAiplatformV1ProbeArgs, GoogleCloudAiplatformV1ProbePtr and GoogleCloudAiplatformV1ProbePtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1ProbePtrInput` via:
//
//	        GoogleCloudAiplatformV1ProbeArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1ProbePtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1ProbePtrOutput() GoogleCloudAiplatformV1ProbePtrOutput
	ToGoogleCloudAiplatformV1ProbePtrOutputWithContext(context.Context) GoogleCloudAiplatformV1ProbePtrOutput
}

type googleCloudAiplatformV1ProbePtrType GoogleCloudAiplatformV1ProbeArgs

func GoogleCloudAiplatformV1ProbePtr(v *GoogleCloudAiplatformV1ProbeArgs) GoogleCloudAiplatformV1ProbePtrInput {
	return (*googleCloudAiplatformV1ProbePtrType)(v)
}

func (*googleCloudAiplatformV1ProbePtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1Probe)(nil)).Elem()
}

func (i *googleCloudAiplatformV1ProbePtrType) ToGoogleCloudAiplatformV1ProbePtrOutput() GoogleCloudAiplatformV1ProbePtrOutput {
	return i.ToGoogleCloudAiplatformV1ProbePtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1ProbePtrType) ToGoogleCloudAiplatformV1ProbePtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ProbePtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1ProbePtrOutput)
}

// Probe describes a health check to be performed against a container to determine whether it is alive or ready to receive traffic.
type GoogleCloudAiplatformV1ProbeOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ProbeOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1Probe)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ProbeOutput) ToGoogleCloudAiplatformV1ProbeOutput() GoogleCloudAiplatformV1ProbeOutput {
	return o
}

func (o GoogleCloudAiplatformV1ProbeOutput) ToGoogleCloudAiplatformV1ProbeOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ProbeOutput {
	return o
}

func (o GoogleCloudAiplatformV1ProbeOutput) ToGoogleCloudAiplatformV1ProbePtrOutput() GoogleCloudAiplatformV1ProbePtrOutput {
	return o.ToGoogleCloudAiplatformV1ProbePtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1ProbeOutput) ToGoogleCloudAiplatformV1ProbePtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ProbePtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1Probe) *GoogleCloudAiplatformV1Probe {
		return &v
	}).(GoogleCloudAiplatformV1ProbePtrOutput)
}

// Exec specifies the action to take.
func (o GoogleCloudAiplatformV1ProbeOutput) Exec() GoogleCloudAiplatformV1ProbeExecActionPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1Probe) *GoogleCloudAiplatformV1ProbeExecAction { return v.Exec }).(GoogleCloudAiplatformV1ProbeExecActionPtrOutput)
}

// How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1. Must be less than timeout_seconds. Maps to Kubernetes probe argument 'periodSeconds'.
func (o GoogleCloudAiplatformV1ProbeOutput) PeriodSeconds() pulumi.IntPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1Probe) *int { return v.PeriodSeconds }).(pulumi.IntPtrOutput)
}

// Number of seconds after which the probe times out. Defaults to 1 second. Minimum value is 1. Must be greater or equal to period_seconds. Maps to Kubernetes probe argument 'timeoutSeconds'.
func (o GoogleCloudAiplatformV1ProbeOutput) TimeoutSeconds() pulumi.IntPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1Probe) *int { return v.TimeoutSeconds }).(pulumi.IntPtrOutput)
}

type GoogleCloudAiplatformV1ProbePtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ProbePtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1Probe)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ProbePtrOutput) ToGoogleCloudAiplatformV1ProbePtrOutput() GoogleCloudAiplatformV1ProbePtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1ProbePtrOutput) ToGoogleCloudAiplatformV1ProbePtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ProbePtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1ProbePtrOutput) Elem() GoogleCloudAiplatformV1ProbeOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1Probe) GoogleCloudAiplatformV1Probe {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1Probe
		return ret
	}).(GoogleCloudAiplatformV1ProbeOutput)
}

// Exec specifies the action to take.
func (o GoogleCloudAiplatformV1ProbePtrOutput) Exec() GoogleCloudAiplatformV1ProbeExecActionPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1Probe) *GoogleCloudAiplatformV1ProbeExecAction {
		if v == nil {
			return nil
		}
		return v.Exec
	}).(GoogleCloudAiplatformV1ProbeExecActionPtrOutput)
}

// How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1. Must be less than timeout_seconds. Maps to Kubernetes probe argument 'periodSeconds'.
func (o GoogleCloudAiplatformV1ProbePtrOutput) PeriodSeconds() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1Probe) *int {
		if v == nil {
			return nil
		}
		return v.PeriodSeconds
	}).(pulumi.IntPtrOutput)
}

// Number of seconds after which the probe times out. Defaults to 1 second. Minimum value is 1. Must be greater or equal to period_seconds. Maps to Kubernetes probe argument 'timeoutSeconds'.
func (o GoogleCloudAiplatformV1ProbePtrOutput) TimeoutSeconds() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1Probe) *int {
		if v == nil {
			return nil
		}
		return v.TimeoutSeconds
	}).(pulumi.IntPtrOutput)
}

// ExecAction specifies a command to execute.
type GoogleCloudAiplatformV1ProbeExecAction struct {
	// Command is the command line to execute inside the container, the working directory for the command is root ('/') in the container's filesystem. The command is simply exec'd, it is not run inside a shell, so traditional shell instructions ('|', etc) won't work. To use a shell, you need to explicitly call out to that shell. Exit status of 0 is treated as live/healthy and non-zero is unhealthy.
	Command []string `pulumi:"command"`
}

// GoogleCloudAiplatformV1ProbeExecActionInput is an input type that accepts GoogleCloudAiplatformV1ProbeExecActionArgs and GoogleCloudAiplatformV1ProbeExecActionOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1ProbeExecActionInput` via:
//
//	GoogleCloudAiplatformV1ProbeExecActionArgs{...}
type GoogleCloudAiplatformV1ProbeExecActionInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1ProbeExecActionOutput() GoogleCloudAiplatformV1ProbeExecActionOutput
	ToGoogleCloudAiplatformV1ProbeExecActionOutputWithContext(context.Context) GoogleCloudAiplatformV1ProbeExecActionOutput
}

// ExecAction specifies a command to execute.
type GoogleCloudAiplatformV1ProbeExecActionArgs struct {
	// Command is the command line to execute inside the container, the working directory for the command is root ('/') in the container's filesystem. The command is simply exec'd, it is not run inside a shell, so traditional shell instructions ('|', etc) won't work. To use a shell, you need to explicitly call out to that shell. Exit status of 0 is treated as live/healthy and non-zero is unhealthy.
	Command pulumi.StringArrayInput `pulumi:"command"`
}

func (GoogleCloudAiplatformV1ProbeExecActionArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1ProbeExecAction)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1ProbeExecActionArgs) ToGoogleCloudAiplatformV1ProbeExecActionOutput() GoogleCloudAiplatformV1ProbeExecActionOutput {
	return i.ToGoogleCloudAiplatformV1ProbeExecActionOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1ProbeExecActionArgs) ToGoogleCloudAiplatformV1ProbeExecActionOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ProbeExecActionOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1ProbeExecActionOutput)
}

func (i GoogleCloudAiplatformV1ProbeExecActionArgs) ToGoogleCloudAiplatformV1ProbeExecActionPtrOutput() GoogleCloudAiplatformV1ProbeExecActionPtrOutput {
	return i.ToGoogleCloudAiplatformV1ProbeExecActionPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1ProbeExecActionArgs) ToGoogleCloudAiplatformV1ProbeExecActionPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ProbeExecActionPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1ProbeExecActionOutput).ToGoogleCloudAiplatformV1ProbeExecActionPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1ProbeExecActionPtrInput is an input type that accepts GoogleCloudAiplatformV1ProbeExecActionArgs, GoogleCloudAiplatformV1ProbeExecActionPtr and GoogleCloudAiplatformV1ProbeExecActionPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1ProbeExecActionPtrInput` via:
//
//	        GoogleCloudAiplatformV1ProbeExecActionArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1ProbeExecActionPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1ProbeExecActionPtrOutput() GoogleCloudAiplatformV1ProbeExecActionPtrOutput
	ToGoogleCloudAiplatformV1ProbeExecActionPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1ProbeExecActionPtrOutput
}

type googleCloudAiplatformV1ProbeExecActionPtrType GoogleCloudAiplatformV1ProbeExecActionArgs

func GoogleCloudAiplatformV1ProbeExecActionPtr(v *GoogleCloudAiplatformV1ProbeExecActionArgs) GoogleCloudAiplatformV1ProbeExecActionPtrInput {
	return (*googleCloudAiplatformV1ProbeExecActionPtrType)(v)
}

func (*googleCloudAiplatformV1ProbeExecActionPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1ProbeExecAction)(nil)).Elem()
}

func (i *googleCloudAiplatformV1ProbeExecActionPtrType) ToGoogleCloudAiplatformV1ProbeExecActionPtrOutput() GoogleCloudAiplatformV1ProbeExecActionPtrOutput {
	return i.ToGoogleCloudAiplatformV1ProbeExecActionPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1ProbeExecActionPtrType) ToGoogleCloudAiplatformV1ProbeExecActionPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ProbeExecActionPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1ProbeExecActionPtrOutput)
}

// ExecAction specifies a command to execute.
type GoogleCloudAiplatformV1ProbeExecActionOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ProbeExecActionOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1ProbeExecAction)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ProbeExecActionOutput) ToGoogleCloudAiplatformV1ProbeExecActionOutput() GoogleCloudAiplatformV1ProbeExecActionOutput {
	return o
}

func (o GoogleCloudAiplatformV1ProbeExecActionOutput) ToGoogleCloudAiplatformV1ProbeExecActionOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ProbeExecActionOutput {
	return o
}

func (o GoogleCloudAiplatformV1ProbeExecActionOutput) ToGoogleCloudAiplatformV1ProbeExecActionPtrOutput() GoogleCloudAiplatformV1ProbeExecActionPtrOutput {
	return o.ToGoogleCloudAiplatformV1ProbeExecActionPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1ProbeExecActionOutput) ToGoogleCloudAiplatformV1ProbeExecActionPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ProbeExecActionPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1ProbeExecAction) *GoogleCloudAiplatformV1ProbeExecAction {
		return &v
	}).(GoogleCloudAiplatformV1ProbeExecActionPtrOutput)
}

// Command is the command line to execute inside the container, the working directory for the command is root ('/') in the container's filesystem. The command is simply exec'd, it is not run inside a shell, so traditional shell instructions ('|', etc) won't work. To use a shell, you need to explicitly call out to that shell. Exit status of 0 is treated as live/healthy and non-zero is unhealthy.
func (o GoogleCloudAiplatformV1ProbeExecActionOutput) Command() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ProbeExecAction) []string { return v.Command }).(pulumi.StringArrayOutput)
}

type GoogleCloudAiplatformV1ProbeExecActionPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ProbeExecActionPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1ProbeExecAction)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ProbeExecActionPtrOutput) ToGoogleCloudAiplatformV1ProbeExecActionPtrOutput() GoogleCloudAiplatformV1ProbeExecActionPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1ProbeExecActionPtrOutput) ToGoogleCloudAiplatformV1ProbeExecActionPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ProbeExecActionPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1ProbeExecActionPtrOutput) Elem() GoogleCloudAiplatformV1ProbeExecActionOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1ProbeExecAction) GoogleCloudAiplatformV1ProbeExecAction {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1ProbeExecAction
		return ret
	}).(GoogleCloudAiplatformV1ProbeExecActionOutput)
}

// Command is the command line to execute inside the container, the working directory for the command is root ('/') in the container's filesystem. The command is simply exec'd, it is not run inside a shell, so traditional shell instructions ('|', etc) won't work. To use a shell, you need to explicitly call out to that shell. Exit status of 0 is treated as live/healthy and non-zero is unhealthy.
func (o GoogleCloudAiplatformV1ProbeExecActionPtrOutput) Command() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1ProbeExecAction) []string {
		if v == nil {
			return nil
		}
		return v.Command
	}).(pulumi.StringArrayOutput)
}

// ExecAction specifies a command to execute.
type GoogleCloudAiplatformV1ProbeExecActionResponse struct {
	// Command is the command line to execute inside the container, the working directory for the command is root ('/') in the container's filesystem. The command is simply exec'd, it is not run inside a shell, so traditional shell instructions ('|', etc) won't work. To use a shell, you need to explicitly call out to that shell. Exit status of 0 is treated as live/healthy and non-zero is unhealthy.
	Command []string `pulumi:"command"`
}

// ExecAction specifies a command to execute.
type GoogleCloudAiplatformV1ProbeExecActionResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ProbeExecActionResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1ProbeExecActionResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ProbeExecActionResponseOutput) ToGoogleCloudAiplatformV1ProbeExecActionResponseOutput() GoogleCloudAiplatformV1ProbeExecActionResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1ProbeExecActionResponseOutput) ToGoogleCloudAiplatformV1ProbeExecActionResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ProbeExecActionResponseOutput {
	return o
}

// Command is the command line to execute inside the container, the working directory for the command is root ('/') in the container's filesystem. The command is simply exec'd, it is not run inside a shell, so traditional shell instructions ('|', etc) won't work. To use a shell, you need to explicitly call out to that shell. Exit status of 0 is treated as live/healthy and non-zero is unhealthy.
func (o GoogleCloudAiplatformV1ProbeExecActionResponseOutput) Command() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ProbeExecActionResponse) []string { return v.Command }).(pulumi.StringArrayOutput)
}

// Probe describes a health check to be performed against a container to determine whether it is alive or ready to receive traffic.
type GoogleCloudAiplatformV1ProbeResponse struct {
	// Exec specifies the action to take.
	Exec GoogleCloudAiplatformV1ProbeExecActionResponse `pulumi:"exec"`
	// How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1. Must be less than timeout_seconds. Maps to Kubernetes probe argument 'periodSeconds'.
	PeriodSeconds int `pulumi:"periodSeconds"`
	// Number of seconds after which the probe times out. Defaults to 1 second. Minimum value is 1. Must be greater or equal to period_seconds. Maps to Kubernetes probe argument 'timeoutSeconds'.
	TimeoutSeconds int `pulumi:"timeoutSeconds"`
}

// Probe describes a health check to be performed against a container to determine whether it is alive or ready to receive traffic.
type GoogleCloudAiplatformV1ProbeResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ProbeResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1ProbeResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ProbeResponseOutput) ToGoogleCloudAiplatformV1ProbeResponseOutput() GoogleCloudAiplatformV1ProbeResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1ProbeResponseOutput) ToGoogleCloudAiplatformV1ProbeResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ProbeResponseOutput {
	return o
}

// Exec specifies the action to take.
func (o GoogleCloudAiplatformV1ProbeResponseOutput) Exec() GoogleCloudAiplatformV1ProbeExecActionResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ProbeResponse) GoogleCloudAiplatformV1ProbeExecActionResponse {
		return v.Exec
	}).(GoogleCloudAiplatformV1ProbeExecActionResponseOutput)
}

// How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1. Must be less than timeout_seconds. Maps to Kubernetes probe argument 'periodSeconds'.
func (o GoogleCloudAiplatformV1ProbeResponseOutput) PeriodSeconds() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ProbeResponse) int { return v.PeriodSeconds }).(pulumi.IntOutput)
}

// Number of seconds after which the probe times out. Defaults to 1 second. Minimum value is 1. Must be greater or equal to period_seconds. Maps to Kubernetes probe argument 'timeoutSeconds'.
func (o GoogleCloudAiplatformV1ProbeResponseOutput) TimeoutSeconds() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ProbeResponse) int { return v.TimeoutSeconds }).(pulumi.IntOutput)
}

// The spec of a Python packaged code.
type GoogleCloudAiplatformV1PythonPackageSpec struct {
	// Command line arguments to be passed to the Python task.
	Args []string `pulumi:"args"`
	// Environment variables to be passed to the python module. Maximum limit is 100.
	Env []GoogleCloudAiplatformV1EnvVar `pulumi:"env"`
	// The URI of a container image in Artifact Registry that will run the provided Python package. Vertex AI provides a wide range of executor images with pre-installed packages to meet users' various use cases. See the list of [pre-built containers for training](https://cloud.google.com/vertex-ai/docs/training/pre-built-containers). You must use an image from this list.
	ExecutorImageUri string `pulumi:"executorImageUri"`
	// The Google Cloud Storage location of the Python package files which are the training program and its dependent packages. The maximum number of package URIs is 100.
	PackageUris []string `pulumi:"packageUris"`
	// The Python module name to run after installing the packages.
	PythonModule string `pulumi:"pythonModule"`
}

// GoogleCloudAiplatformV1PythonPackageSpecInput is an input type that accepts GoogleCloudAiplatformV1PythonPackageSpecArgs and GoogleCloudAiplatformV1PythonPackageSpecOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1PythonPackageSpecInput` via:
//
//	GoogleCloudAiplatformV1PythonPackageSpecArgs{...}
type GoogleCloudAiplatformV1PythonPackageSpecInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1PythonPackageSpecOutput() GoogleCloudAiplatformV1PythonPackageSpecOutput
	ToGoogleCloudAiplatformV1PythonPackageSpecOutputWithContext(context.Context) GoogleCloudAiplatformV1PythonPackageSpecOutput
}

// The spec of a Python packaged code.
type GoogleCloudAiplatformV1PythonPackageSpecArgs struct {
	// Command line arguments to be passed to the Python task.
	Args pulumi.StringArrayInput `pulumi:"args"`
	// Environment variables to be passed to the python module. Maximum limit is 100.
	Env GoogleCloudAiplatformV1EnvVarArrayInput `pulumi:"env"`
	// The URI of a container image in Artifact Registry that will run the provided Python package. Vertex AI provides a wide range of executor images with pre-installed packages to meet users' various use cases. See the list of [pre-built containers for training](https://cloud.google.com/vertex-ai/docs/training/pre-built-containers). You must use an image from this list.
	ExecutorImageUri pulumi.StringInput `pulumi:"executorImageUri"`
	// The Google Cloud Storage location of the Python package files which are the training program and its dependent packages. The maximum number of package URIs is 100.
	PackageUris pulumi.StringArrayInput `pulumi:"packageUris"`
	// The Python module name to run after installing the packages.
	PythonModule pulumi.StringInput `pulumi:"pythonModule"`
}

func (GoogleCloudAiplatformV1PythonPackageSpecArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1PythonPackageSpec)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1PythonPackageSpecArgs) ToGoogleCloudAiplatformV1PythonPackageSpecOutput() GoogleCloudAiplatformV1PythonPackageSpecOutput {
	return i.ToGoogleCloudAiplatformV1PythonPackageSpecOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1PythonPackageSpecArgs) ToGoogleCloudAiplatformV1PythonPackageSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1PythonPackageSpecOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1PythonPackageSpecOutput)
}

func (i GoogleCloudAiplatformV1PythonPackageSpecArgs) ToGoogleCloudAiplatformV1PythonPackageSpecPtrOutput() GoogleCloudAiplatformV1PythonPackageSpecPtrOutput {
	return i.ToGoogleCloudAiplatformV1PythonPackageSpecPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1PythonPackageSpecArgs) ToGoogleCloudAiplatformV1PythonPackageSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1PythonPackageSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1PythonPackageSpecOutput).ToGoogleCloudAiplatformV1PythonPackageSpecPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1PythonPackageSpecPtrInput is an input type that accepts GoogleCloudAiplatformV1PythonPackageSpecArgs, GoogleCloudAiplatformV1PythonPackageSpecPtr and GoogleCloudAiplatformV1PythonPackageSpecPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1PythonPackageSpecPtrInput` via:
//
//	        GoogleCloudAiplatformV1PythonPackageSpecArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1PythonPackageSpecPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1PythonPackageSpecPtrOutput() GoogleCloudAiplatformV1PythonPackageSpecPtrOutput
	ToGoogleCloudAiplatformV1PythonPackageSpecPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1PythonPackageSpecPtrOutput
}

type googleCloudAiplatformV1PythonPackageSpecPtrType GoogleCloudAiplatformV1PythonPackageSpecArgs

func GoogleCloudAiplatformV1PythonPackageSpecPtr(v *GoogleCloudAiplatformV1PythonPackageSpecArgs) GoogleCloudAiplatformV1PythonPackageSpecPtrInput {
	return (*googleCloudAiplatformV1PythonPackageSpecPtrType)(v)
}

func (*googleCloudAiplatformV1PythonPackageSpecPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1PythonPackageSpec)(nil)).Elem()
}

func (i *googleCloudAiplatformV1PythonPackageSpecPtrType) ToGoogleCloudAiplatformV1PythonPackageSpecPtrOutput() GoogleCloudAiplatformV1PythonPackageSpecPtrOutput {
	return i.ToGoogleCloudAiplatformV1PythonPackageSpecPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1PythonPackageSpecPtrType) ToGoogleCloudAiplatformV1PythonPackageSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1PythonPackageSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1PythonPackageSpecPtrOutput)
}

// The spec of a Python packaged code.
type GoogleCloudAiplatformV1PythonPackageSpecOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1PythonPackageSpecOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1PythonPackageSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1PythonPackageSpecOutput) ToGoogleCloudAiplatformV1PythonPackageSpecOutput() GoogleCloudAiplatformV1PythonPackageSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1PythonPackageSpecOutput) ToGoogleCloudAiplatformV1PythonPackageSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1PythonPackageSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1PythonPackageSpecOutput) ToGoogleCloudAiplatformV1PythonPackageSpecPtrOutput() GoogleCloudAiplatformV1PythonPackageSpecPtrOutput {
	return o.ToGoogleCloudAiplatformV1PythonPackageSpecPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1PythonPackageSpecOutput) ToGoogleCloudAiplatformV1PythonPackageSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1PythonPackageSpecPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1PythonPackageSpec) *GoogleCloudAiplatformV1PythonPackageSpec {
		return &v
	}).(GoogleCloudAiplatformV1PythonPackageSpecPtrOutput)
}

// Command line arguments to be passed to the Python task.
func (o GoogleCloudAiplatformV1PythonPackageSpecOutput) Args() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PythonPackageSpec) []string { return v.Args }).(pulumi.StringArrayOutput)
}

// Environment variables to be passed to the python module. Maximum limit is 100.
func (o GoogleCloudAiplatformV1PythonPackageSpecOutput) Env() GoogleCloudAiplatformV1EnvVarArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PythonPackageSpec) []GoogleCloudAiplatformV1EnvVar { return v.Env }).(GoogleCloudAiplatformV1EnvVarArrayOutput)
}

// The URI of a container image in Artifact Registry that will run the provided Python package. Vertex AI provides a wide range of executor images with pre-installed packages to meet users' various use cases. See the list of [pre-built containers for training](https://cloud.google.com/vertex-ai/docs/training/pre-built-containers). You must use an image from this list.
func (o GoogleCloudAiplatformV1PythonPackageSpecOutput) ExecutorImageUri() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PythonPackageSpec) string { return v.ExecutorImageUri }).(pulumi.StringOutput)
}

// The Google Cloud Storage location of the Python package files which are the training program and its dependent packages. The maximum number of package URIs is 100.
func (o GoogleCloudAiplatformV1PythonPackageSpecOutput) PackageUris() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PythonPackageSpec) []string { return v.PackageUris }).(pulumi.StringArrayOutput)
}

// The Python module name to run after installing the packages.
func (o GoogleCloudAiplatformV1PythonPackageSpecOutput) PythonModule() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PythonPackageSpec) string { return v.PythonModule }).(pulumi.StringOutput)
}

type GoogleCloudAiplatformV1PythonPackageSpecPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1PythonPackageSpecPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1PythonPackageSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1PythonPackageSpecPtrOutput) ToGoogleCloudAiplatformV1PythonPackageSpecPtrOutput() GoogleCloudAiplatformV1PythonPackageSpecPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1PythonPackageSpecPtrOutput) ToGoogleCloudAiplatformV1PythonPackageSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1PythonPackageSpecPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1PythonPackageSpecPtrOutput) Elem() GoogleCloudAiplatformV1PythonPackageSpecOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1PythonPackageSpec) GoogleCloudAiplatformV1PythonPackageSpec {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1PythonPackageSpec
		return ret
	}).(GoogleCloudAiplatformV1PythonPackageSpecOutput)
}

// Command line arguments to be passed to the Python task.
func (o GoogleCloudAiplatformV1PythonPackageSpecPtrOutput) Args() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1PythonPackageSpec) []string {
		if v == nil {
			return nil
		}
		return v.Args
	}).(pulumi.StringArrayOutput)
}

// Environment variables to be passed to the python module. Maximum limit is 100.
func (o GoogleCloudAiplatformV1PythonPackageSpecPtrOutput) Env() GoogleCloudAiplatformV1EnvVarArrayOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1PythonPackageSpec) []GoogleCloudAiplatformV1EnvVar {
		if v == nil {
			return nil
		}
		return v.Env
	}).(GoogleCloudAiplatformV1EnvVarArrayOutput)
}

// The URI of a container image in Artifact Registry that will run the provided Python package. Vertex AI provides a wide range of executor images with pre-installed packages to meet users' various use cases. See the list of [pre-built containers for training](https://cloud.google.com/vertex-ai/docs/training/pre-built-containers). You must use an image from this list.
func (o GoogleCloudAiplatformV1PythonPackageSpecPtrOutput) ExecutorImageUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1PythonPackageSpec) *string {
		if v == nil {
			return nil
		}
		return &v.ExecutorImageUri
	}).(pulumi.StringPtrOutput)
}

// The Google Cloud Storage location of the Python package files which are the training program and its dependent packages. The maximum number of package URIs is 100.
func (o GoogleCloudAiplatformV1PythonPackageSpecPtrOutput) PackageUris() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1PythonPackageSpec) []string {
		if v == nil {
			return nil
		}
		return v.PackageUris
	}).(pulumi.StringArrayOutput)
}

// The Python module name to run after installing the packages.
func (o GoogleCloudAiplatformV1PythonPackageSpecPtrOutput) PythonModule() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1PythonPackageSpec) *string {
		if v == nil {
			return nil
		}
		return &v.PythonModule
	}).(pulumi.StringPtrOutput)
}

// The spec of a Python packaged code.
type GoogleCloudAiplatformV1PythonPackageSpecResponse struct {
	// Command line arguments to be passed to the Python task.
	Args []string `pulumi:"args"`
	// Environment variables to be passed to the python module. Maximum limit is 100.
	Env []GoogleCloudAiplatformV1EnvVarResponse `pulumi:"env"`
	// The URI of a container image in Artifact Registry that will run the provided Python package. Vertex AI provides a wide range of executor images with pre-installed packages to meet users' various use cases. See the list of [pre-built containers for training](https://cloud.google.com/vertex-ai/docs/training/pre-built-containers). You must use an image from this list.
	ExecutorImageUri string `pulumi:"executorImageUri"`
	// The Google Cloud Storage location of the Python package files which are the training program and its dependent packages. The maximum number of package URIs is 100.
	PackageUris []string `pulumi:"packageUris"`
	// The Python module name to run after installing the packages.
	PythonModule string `pulumi:"pythonModule"`
}

// The spec of a Python packaged code.
type GoogleCloudAiplatformV1PythonPackageSpecResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1PythonPackageSpecResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1PythonPackageSpecResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1PythonPackageSpecResponseOutput) ToGoogleCloudAiplatformV1PythonPackageSpecResponseOutput() GoogleCloudAiplatformV1PythonPackageSpecResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1PythonPackageSpecResponseOutput) ToGoogleCloudAiplatformV1PythonPackageSpecResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1PythonPackageSpecResponseOutput {
	return o
}

// Command line arguments to be passed to the Python task.
func (o GoogleCloudAiplatformV1PythonPackageSpecResponseOutput) Args() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PythonPackageSpecResponse) []string { return v.Args }).(pulumi.StringArrayOutput)
}

// Environment variables to be passed to the python module. Maximum limit is 100.
func (o GoogleCloudAiplatformV1PythonPackageSpecResponseOutput) Env() GoogleCloudAiplatformV1EnvVarResponseArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PythonPackageSpecResponse) []GoogleCloudAiplatformV1EnvVarResponse {
		return v.Env
	}).(GoogleCloudAiplatformV1EnvVarResponseArrayOutput)
}

// The URI of a container image in Artifact Registry that will run the provided Python package. Vertex AI provides a wide range of executor images with pre-installed packages to meet users' various use cases. See the list of [pre-built containers for training](https://cloud.google.com/vertex-ai/docs/training/pre-built-containers). You must use an image from this list.
func (o GoogleCloudAiplatformV1PythonPackageSpecResponseOutput) ExecutorImageUri() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PythonPackageSpecResponse) string { return v.ExecutorImageUri }).(pulumi.StringOutput)
}

// The Google Cloud Storage location of the Python package files which are the training program and its dependent packages. The maximum number of package URIs is 100.
func (o GoogleCloudAiplatformV1PythonPackageSpecResponseOutput) PackageUris() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PythonPackageSpecResponse) []string { return v.PackageUris }).(pulumi.StringArrayOutput)
}

// The Python module name to run after installing the packages.
func (o GoogleCloudAiplatformV1PythonPackageSpecResponseOutput) PythonModule() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1PythonPackageSpecResponse) string { return v.PythonModule }).(pulumi.StringOutput)
}

// Statistics information about resource consumption.
type GoogleCloudAiplatformV1ResourcesConsumedResponse struct {
	// The number of replica hours used. Note that many replicas may run in parallel, and additionally any given work may be queued for some time. Therefore this value is not strictly related to wall time.
	ReplicaHours float64 `pulumi:"replicaHours"`
}

// Statistics information about resource consumption.
type GoogleCloudAiplatformV1ResourcesConsumedResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ResourcesConsumedResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1ResourcesConsumedResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ResourcesConsumedResponseOutput) ToGoogleCloudAiplatformV1ResourcesConsumedResponseOutput() GoogleCloudAiplatformV1ResourcesConsumedResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1ResourcesConsumedResponseOutput) ToGoogleCloudAiplatformV1ResourcesConsumedResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ResourcesConsumedResponseOutput {
	return o
}

// The number of replica hours used. Note that many replicas may run in parallel, and additionally any given work may be queued for some time. Therefore this value is not strictly related to wall time.
func (o GoogleCloudAiplatformV1ResourcesConsumedResponseOutput) ReplicaHours() pulumi.Float64Output {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ResourcesConsumedResponse) float64 { return v.ReplicaHours }).(pulumi.Float64Output)
}

// Active learning data sampling config. For every active learning labeling iteration, it will select a batch of data based on the sampling strategy.
type GoogleCloudAiplatformV1SampleConfig struct {
	// The percentage of data needed to be labeled in each following batch (except the first batch).
	FollowingBatchSamplePercentage *int `pulumi:"followingBatchSamplePercentage"`
	// The percentage of data needed to be labeled in the first batch.
	InitialBatchSamplePercentage *int `pulumi:"initialBatchSamplePercentage"`
	// Field to choose sampling strategy. Sampling strategy will decide which data should be selected for human labeling in every batch.
	SampleStrategy *GoogleCloudAiplatformV1SampleConfigSampleStrategy `pulumi:"sampleStrategy"`
}

// GoogleCloudAiplatformV1SampleConfigInput is an input type that accepts GoogleCloudAiplatformV1SampleConfigArgs and GoogleCloudAiplatformV1SampleConfigOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1SampleConfigInput` via:
//
//	GoogleCloudAiplatformV1SampleConfigArgs{...}
type GoogleCloudAiplatformV1SampleConfigInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1SampleConfigOutput() GoogleCloudAiplatformV1SampleConfigOutput
	ToGoogleCloudAiplatformV1SampleConfigOutputWithContext(context.Context) GoogleCloudAiplatformV1SampleConfigOutput
}

// Active learning data sampling config. For every active learning labeling iteration, it will select a batch of data based on the sampling strategy.
type GoogleCloudAiplatformV1SampleConfigArgs struct {
	// The percentage of data needed to be labeled in each following batch (except the first batch).
	FollowingBatchSamplePercentage pulumi.IntPtrInput `pulumi:"followingBatchSamplePercentage"`
	// The percentage of data needed to be labeled in the first batch.
	InitialBatchSamplePercentage pulumi.IntPtrInput `pulumi:"initialBatchSamplePercentage"`
	// Field to choose sampling strategy. Sampling strategy will decide which data should be selected for human labeling in every batch.
	SampleStrategy GoogleCloudAiplatformV1SampleConfigSampleStrategyPtrInput `pulumi:"sampleStrategy"`
}

func (GoogleCloudAiplatformV1SampleConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1SampleConfig)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1SampleConfigArgs) ToGoogleCloudAiplatformV1SampleConfigOutput() GoogleCloudAiplatformV1SampleConfigOutput {
	return i.ToGoogleCloudAiplatformV1SampleConfigOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1SampleConfigArgs) ToGoogleCloudAiplatformV1SampleConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1SampleConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1SampleConfigOutput)
}

func (i GoogleCloudAiplatformV1SampleConfigArgs) ToGoogleCloudAiplatformV1SampleConfigPtrOutput() GoogleCloudAiplatformV1SampleConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1SampleConfigPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1SampleConfigArgs) ToGoogleCloudAiplatformV1SampleConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1SampleConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1SampleConfigOutput).ToGoogleCloudAiplatformV1SampleConfigPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1SampleConfigPtrInput is an input type that accepts GoogleCloudAiplatformV1SampleConfigArgs, GoogleCloudAiplatformV1SampleConfigPtr and GoogleCloudAiplatformV1SampleConfigPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1SampleConfigPtrInput` via:
//
//	        GoogleCloudAiplatformV1SampleConfigArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1SampleConfigPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1SampleConfigPtrOutput() GoogleCloudAiplatformV1SampleConfigPtrOutput
	ToGoogleCloudAiplatformV1SampleConfigPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1SampleConfigPtrOutput
}

type googleCloudAiplatformV1SampleConfigPtrType GoogleCloudAiplatformV1SampleConfigArgs

func GoogleCloudAiplatformV1SampleConfigPtr(v *GoogleCloudAiplatformV1SampleConfigArgs) GoogleCloudAiplatformV1SampleConfigPtrInput {
	return (*googleCloudAiplatformV1SampleConfigPtrType)(v)
}

func (*googleCloudAiplatformV1SampleConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1SampleConfig)(nil)).Elem()
}

func (i *googleCloudAiplatformV1SampleConfigPtrType) ToGoogleCloudAiplatformV1SampleConfigPtrOutput() GoogleCloudAiplatformV1SampleConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1SampleConfigPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1SampleConfigPtrType) ToGoogleCloudAiplatformV1SampleConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1SampleConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1SampleConfigPtrOutput)
}

// Active learning data sampling config. For every active learning labeling iteration, it will select a batch of data based on the sampling strategy.
type GoogleCloudAiplatformV1SampleConfigOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1SampleConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1SampleConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1SampleConfigOutput) ToGoogleCloudAiplatformV1SampleConfigOutput() GoogleCloudAiplatformV1SampleConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1SampleConfigOutput) ToGoogleCloudAiplatformV1SampleConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1SampleConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1SampleConfigOutput) ToGoogleCloudAiplatformV1SampleConfigPtrOutput() GoogleCloudAiplatformV1SampleConfigPtrOutput {
	return o.ToGoogleCloudAiplatformV1SampleConfigPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1SampleConfigOutput) ToGoogleCloudAiplatformV1SampleConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1SampleConfigPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1SampleConfig) *GoogleCloudAiplatformV1SampleConfig {
		return &v
	}).(GoogleCloudAiplatformV1SampleConfigPtrOutput)
}

// The percentage of data needed to be labeled in each following batch (except the first batch).
func (o GoogleCloudAiplatformV1SampleConfigOutput) FollowingBatchSamplePercentage() pulumi.IntPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1SampleConfig) *int { return v.FollowingBatchSamplePercentage }).(pulumi.IntPtrOutput)
}

// The percentage of data needed to be labeled in the first batch.
func (o GoogleCloudAiplatformV1SampleConfigOutput) InitialBatchSamplePercentage() pulumi.IntPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1SampleConfig) *int { return v.InitialBatchSamplePercentage }).(pulumi.IntPtrOutput)
}

// Field to choose sampling strategy. Sampling strategy will decide which data should be selected for human labeling in every batch.
func (o GoogleCloudAiplatformV1SampleConfigOutput) SampleStrategy() GoogleCloudAiplatformV1SampleConfigSampleStrategyPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1SampleConfig) *GoogleCloudAiplatformV1SampleConfigSampleStrategy {
		return v.SampleStrategy
	}).(GoogleCloudAiplatformV1SampleConfigSampleStrategyPtrOutput)
}

type GoogleCloudAiplatformV1SampleConfigPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1SampleConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1SampleConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1SampleConfigPtrOutput) ToGoogleCloudAiplatformV1SampleConfigPtrOutput() GoogleCloudAiplatformV1SampleConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1SampleConfigPtrOutput) ToGoogleCloudAiplatformV1SampleConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1SampleConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1SampleConfigPtrOutput) Elem() GoogleCloudAiplatformV1SampleConfigOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1SampleConfig) GoogleCloudAiplatformV1SampleConfig {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1SampleConfig
		return ret
	}).(GoogleCloudAiplatformV1SampleConfigOutput)
}

// The percentage of data needed to be labeled in each following batch (except the first batch).
func (o GoogleCloudAiplatformV1SampleConfigPtrOutput) FollowingBatchSamplePercentage() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1SampleConfig) *int {
		if v == nil {
			return nil
		}
		return v.FollowingBatchSamplePercentage
	}).(pulumi.IntPtrOutput)
}

// The percentage of data needed to be labeled in the first batch.
func (o GoogleCloudAiplatformV1SampleConfigPtrOutput) InitialBatchSamplePercentage() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1SampleConfig) *int {
		if v == nil {
			return nil
		}
		return v.InitialBatchSamplePercentage
	}).(pulumi.IntPtrOutput)
}

// Field to choose sampling strategy. Sampling strategy will decide which data should be selected for human labeling in every batch.
func (o GoogleCloudAiplatformV1SampleConfigPtrOutput) SampleStrategy() GoogleCloudAiplatformV1SampleConfigSampleStrategyPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1SampleConfig) *GoogleCloudAiplatformV1SampleConfigSampleStrategy {
		if v == nil {
			return nil
		}
		return v.SampleStrategy
	}).(GoogleCloudAiplatformV1SampleConfigSampleStrategyPtrOutput)
}

// Active learning data sampling config. For every active learning labeling iteration, it will select a batch of data based on the sampling strategy.
type GoogleCloudAiplatformV1SampleConfigResponse struct {
	// The percentage of data needed to be labeled in each following batch (except the first batch).
	FollowingBatchSamplePercentage int `pulumi:"followingBatchSamplePercentage"`
	// The percentage of data needed to be labeled in the first batch.
	InitialBatchSamplePercentage int `pulumi:"initialBatchSamplePercentage"`
	// Field to choose sampling strategy. Sampling strategy will decide which data should be selected for human labeling in every batch.
	SampleStrategy string `pulumi:"sampleStrategy"`
}

// Active learning data sampling config. For every active learning labeling iteration, it will select a batch of data based on the sampling strategy.
type GoogleCloudAiplatformV1SampleConfigResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1SampleConfigResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1SampleConfigResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1SampleConfigResponseOutput) ToGoogleCloudAiplatformV1SampleConfigResponseOutput() GoogleCloudAiplatformV1SampleConfigResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1SampleConfigResponseOutput) ToGoogleCloudAiplatformV1SampleConfigResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1SampleConfigResponseOutput {
	return o
}

// The percentage of data needed to be labeled in each following batch (except the first batch).
func (o GoogleCloudAiplatformV1SampleConfigResponseOutput) FollowingBatchSamplePercentage() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1SampleConfigResponse) int { return v.FollowingBatchSamplePercentage }).(pulumi.IntOutput)
}

// The percentage of data needed to be labeled in the first batch.
func (o GoogleCloudAiplatformV1SampleConfigResponseOutput) InitialBatchSamplePercentage() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1SampleConfigResponse) int { return v.InitialBatchSamplePercentage }).(pulumi.IntOutput)
}

// Field to choose sampling strategy. Sampling strategy will decide which data should be selected for human labeling in every batch.
func (o GoogleCloudAiplatformV1SampleConfigResponseOutput) SampleStrategy() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1SampleConfigResponse) string { return v.SampleStrategy }).(pulumi.StringOutput)
}

// An attribution method that approximates Shapley values for features that contribute to the label being predicted. A sampling strategy is used to approximate the value rather than considering all subsets of features.
type GoogleCloudAiplatformV1SampledShapleyAttribution struct {
	// The number of feature permutations to consider when approximating the Shapley values. Valid range of its value is [1, 50], inclusively.
	PathCount int `pulumi:"pathCount"`
}

// GoogleCloudAiplatformV1SampledShapleyAttributionInput is an input type that accepts GoogleCloudAiplatformV1SampledShapleyAttributionArgs and GoogleCloudAiplatformV1SampledShapleyAttributionOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1SampledShapleyAttributionInput` via:
//
//	GoogleCloudAiplatformV1SampledShapleyAttributionArgs{...}
type GoogleCloudAiplatformV1SampledShapleyAttributionInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1SampledShapleyAttributionOutput() GoogleCloudAiplatformV1SampledShapleyAttributionOutput
	ToGoogleCloudAiplatformV1SampledShapleyAttributionOutputWithContext(context.Context) GoogleCloudAiplatformV1SampledShapleyAttributionOutput
}

// An attribution method that approximates Shapley values for features that contribute to the label being predicted. A sampling strategy is used to approximate the value rather than considering all subsets of features.
type GoogleCloudAiplatformV1SampledShapleyAttributionArgs struct {
	// The number of feature permutations to consider when approximating the Shapley values. Valid range of its value is [1, 50], inclusively.
	PathCount pulumi.IntInput `pulumi:"pathCount"`
}

func (GoogleCloudAiplatformV1SampledShapleyAttributionArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1SampledShapleyAttribution)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1SampledShapleyAttributionArgs) ToGoogleCloudAiplatformV1SampledShapleyAttributionOutput() GoogleCloudAiplatformV1SampledShapleyAttributionOutput {
	return i.ToGoogleCloudAiplatformV1SampledShapleyAttributionOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1SampledShapleyAttributionArgs) ToGoogleCloudAiplatformV1SampledShapleyAttributionOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1SampledShapleyAttributionOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1SampledShapleyAttributionOutput)
}

func (i GoogleCloudAiplatformV1SampledShapleyAttributionArgs) ToGoogleCloudAiplatformV1SampledShapleyAttributionPtrOutput() GoogleCloudAiplatformV1SampledShapleyAttributionPtrOutput {
	return i.ToGoogleCloudAiplatformV1SampledShapleyAttributionPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1SampledShapleyAttributionArgs) ToGoogleCloudAiplatformV1SampledShapleyAttributionPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1SampledShapleyAttributionPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1SampledShapleyAttributionOutput).ToGoogleCloudAiplatformV1SampledShapleyAttributionPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1SampledShapleyAttributionPtrInput is an input type that accepts GoogleCloudAiplatformV1SampledShapleyAttributionArgs, GoogleCloudAiplatformV1SampledShapleyAttributionPtr and GoogleCloudAiplatformV1SampledShapleyAttributionPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1SampledShapleyAttributionPtrInput` via:
//
//	        GoogleCloudAiplatformV1SampledShapleyAttributionArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1SampledShapleyAttributionPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1SampledShapleyAttributionPtrOutput() GoogleCloudAiplatformV1SampledShapleyAttributionPtrOutput
	ToGoogleCloudAiplatformV1SampledShapleyAttributionPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1SampledShapleyAttributionPtrOutput
}

type googleCloudAiplatformV1SampledShapleyAttributionPtrType GoogleCloudAiplatformV1SampledShapleyAttributionArgs

func GoogleCloudAiplatformV1SampledShapleyAttributionPtr(v *GoogleCloudAiplatformV1SampledShapleyAttributionArgs) GoogleCloudAiplatformV1SampledShapleyAttributionPtrInput {
	return (*googleCloudAiplatformV1SampledShapleyAttributionPtrType)(v)
}

func (*googleCloudAiplatformV1SampledShapleyAttributionPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1SampledShapleyAttribution)(nil)).Elem()
}

func (i *googleCloudAiplatformV1SampledShapleyAttributionPtrType) ToGoogleCloudAiplatformV1SampledShapleyAttributionPtrOutput() GoogleCloudAiplatformV1SampledShapleyAttributionPtrOutput {
	return i.ToGoogleCloudAiplatformV1SampledShapleyAttributionPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1SampledShapleyAttributionPtrType) ToGoogleCloudAiplatformV1SampledShapleyAttributionPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1SampledShapleyAttributionPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1SampledShapleyAttributionPtrOutput)
}

// An attribution method that approximates Shapley values for features that contribute to the label being predicted. A sampling strategy is used to approximate the value rather than considering all subsets of features.
type GoogleCloudAiplatformV1SampledShapleyAttributionOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1SampledShapleyAttributionOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1SampledShapleyAttribution)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1SampledShapleyAttributionOutput) ToGoogleCloudAiplatformV1SampledShapleyAttributionOutput() GoogleCloudAiplatformV1SampledShapleyAttributionOutput {
	return o
}

func (o GoogleCloudAiplatformV1SampledShapleyAttributionOutput) ToGoogleCloudAiplatformV1SampledShapleyAttributionOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1SampledShapleyAttributionOutput {
	return o
}

func (o GoogleCloudAiplatformV1SampledShapleyAttributionOutput) ToGoogleCloudAiplatformV1SampledShapleyAttributionPtrOutput() GoogleCloudAiplatformV1SampledShapleyAttributionPtrOutput {
	return o.ToGoogleCloudAiplatformV1SampledShapleyAttributionPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1SampledShapleyAttributionOutput) ToGoogleCloudAiplatformV1SampledShapleyAttributionPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1SampledShapleyAttributionPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1SampledShapleyAttribution) *GoogleCloudAiplatformV1SampledShapleyAttribution {
		return &v
	}).(GoogleCloudAiplatformV1SampledShapleyAttributionPtrOutput)
}

// The number of feature permutations to consider when approximating the Shapley values. Valid range of its value is [1, 50], inclusively.
func (o GoogleCloudAiplatformV1SampledShapleyAttributionOutput) PathCount() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1SampledShapleyAttribution) int { return v.PathCount }).(pulumi.IntOutput)
}

type GoogleCloudAiplatformV1SampledShapleyAttributionPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1SampledShapleyAttributionPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1SampledShapleyAttribution)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1SampledShapleyAttributionPtrOutput) ToGoogleCloudAiplatformV1SampledShapleyAttributionPtrOutput() GoogleCloudAiplatformV1SampledShapleyAttributionPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1SampledShapleyAttributionPtrOutput) ToGoogleCloudAiplatformV1SampledShapleyAttributionPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1SampledShapleyAttributionPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1SampledShapleyAttributionPtrOutput) Elem() GoogleCloudAiplatformV1SampledShapleyAttributionOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1SampledShapleyAttribution) GoogleCloudAiplatformV1SampledShapleyAttribution {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1SampledShapleyAttribution
		return ret
	}).(GoogleCloudAiplatformV1SampledShapleyAttributionOutput)
}

// The number of feature permutations to consider when approximating the Shapley values. Valid range of its value is [1, 50], inclusively.
func (o GoogleCloudAiplatformV1SampledShapleyAttributionPtrOutput) PathCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1SampledShapleyAttribution) *int {
		if v == nil {
			return nil
		}
		return &v.PathCount
	}).(pulumi.IntPtrOutput)
}

// An attribution method that approximates Shapley values for features that contribute to the label being predicted. A sampling strategy is used to approximate the value rather than considering all subsets of features.
type GoogleCloudAiplatformV1SampledShapleyAttributionResponse struct {
	// The number of feature permutations to consider when approximating the Shapley values. Valid range of its value is [1, 50], inclusively.
	PathCount int `pulumi:"pathCount"`
}

// An attribution method that approximates Shapley values for features that contribute to the label being predicted. A sampling strategy is used to approximate the value rather than considering all subsets of features.
type GoogleCloudAiplatformV1SampledShapleyAttributionResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1SampledShapleyAttributionResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1SampledShapleyAttributionResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1SampledShapleyAttributionResponseOutput) ToGoogleCloudAiplatformV1SampledShapleyAttributionResponseOutput() GoogleCloudAiplatformV1SampledShapleyAttributionResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1SampledShapleyAttributionResponseOutput) ToGoogleCloudAiplatformV1SampledShapleyAttributionResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1SampledShapleyAttributionResponseOutput {
	return o
}

// The number of feature permutations to consider when approximating the Shapley values. Valid range of its value is [1, 50], inclusively.
func (o GoogleCloudAiplatformV1SampledShapleyAttributionResponseOutput) PathCount() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1SampledShapleyAttributionResponse) int { return v.PathCount }).(pulumi.IntOutput)
}

// Sampling Strategy for logging, can be for both training and prediction dataset.
type GoogleCloudAiplatformV1SamplingStrategy struct {
	// Random sample config. Will support more sampling strategies later.
	RandomSampleConfig *GoogleCloudAiplatformV1SamplingStrategyRandomSampleConfig `pulumi:"randomSampleConfig"`
}

// GoogleCloudAiplatformV1SamplingStrategyInput is an input type that accepts GoogleCloudAiplatformV1SamplingStrategyArgs and GoogleCloudAiplatformV1SamplingStrategyOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1SamplingStrategyInput` via:
//
//	GoogleCloudAiplatformV1SamplingStrategyArgs{...}
type GoogleCloudAiplatformV1SamplingStrategyInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1SamplingStrategyOutput() GoogleCloudAiplatformV1SamplingStrategyOutput
	ToGoogleCloudAiplatformV1SamplingStrategyOutputWithContext(context.Context) GoogleCloudAiplatformV1SamplingStrategyOutput
}

// Sampling Strategy for logging, can be for both training and prediction dataset.
type GoogleCloudAiplatformV1SamplingStrategyArgs struct {
	// Random sample config. Will support more sampling strategies later.
	RandomSampleConfig GoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigPtrInput `pulumi:"randomSampleConfig"`
}

func (GoogleCloudAiplatformV1SamplingStrategyArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1SamplingStrategy)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1SamplingStrategyArgs) ToGoogleCloudAiplatformV1SamplingStrategyOutput() GoogleCloudAiplatformV1SamplingStrategyOutput {
	return i.ToGoogleCloudAiplatformV1SamplingStrategyOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1SamplingStrategyArgs) ToGoogleCloudAiplatformV1SamplingStrategyOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1SamplingStrategyOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1SamplingStrategyOutput)
}

func (i GoogleCloudAiplatformV1SamplingStrategyArgs) ToGoogleCloudAiplatformV1SamplingStrategyPtrOutput() GoogleCloudAiplatformV1SamplingStrategyPtrOutput {
	return i.ToGoogleCloudAiplatformV1SamplingStrategyPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1SamplingStrategyArgs) ToGoogleCloudAiplatformV1SamplingStrategyPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1SamplingStrategyPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1SamplingStrategyOutput).ToGoogleCloudAiplatformV1SamplingStrategyPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1SamplingStrategyPtrInput is an input type that accepts GoogleCloudAiplatformV1SamplingStrategyArgs, GoogleCloudAiplatformV1SamplingStrategyPtr and GoogleCloudAiplatformV1SamplingStrategyPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1SamplingStrategyPtrInput` via:
//
//	        GoogleCloudAiplatformV1SamplingStrategyArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1SamplingStrategyPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1SamplingStrategyPtrOutput() GoogleCloudAiplatformV1SamplingStrategyPtrOutput
	ToGoogleCloudAiplatformV1SamplingStrategyPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1SamplingStrategyPtrOutput
}

type googleCloudAiplatformV1SamplingStrategyPtrType GoogleCloudAiplatformV1SamplingStrategyArgs

func GoogleCloudAiplatformV1SamplingStrategyPtr(v *GoogleCloudAiplatformV1SamplingStrategyArgs) GoogleCloudAiplatformV1SamplingStrategyPtrInput {
	return (*googleCloudAiplatformV1SamplingStrategyPtrType)(v)
}

func (*googleCloudAiplatformV1SamplingStrategyPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1SamplingStrategy)(nil)).Elem()
}

func (i *googleCloudAiplatformV1SamplingStrategyPtrType) ToGoogleCloudAiplatformV1SamplingStrategyPtrOutput() GoogleCloudAiplatformV1SamplingStrategyPtrOutput {
	return i.ToGoogleCloudAiplatformV1SamplingStrategyPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1SamplingStrategyPtrType) ToGoogleCloudAiplatformV1SamplingStrategyPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1SamplingStrategyPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1SamplingStrategyPtrOutput)
}

// Sampling Strategy for logging, can be for both training and prediction dataset.
type GoogleCloudAiplatformV1SamplingStrategyOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1SamplingStrategyOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1SamplingStrategy)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1SamplingStrategyOutput) ToGoogleCloudAiplatformV1SamplingStrategyOutput() GoogleCloudAiplatformV1SamplingStrategyOutput {
	return o
}

func (o GoogleCloudAiplatformV1SamplingStrategyOutput) ToGoogleCloudAiplatformV1SamplingStrategyOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1SamplingStrategyOutput {
	return o
}

func (o GoogleCloudAiplatformV1SamplingStrategyOutput) ToGoogleCloudAiplatformV1SamplingStrategyPtrOutput() GoogleCloudAiplatformV1SamplingStrategyPtrOutput {
	return o.ToGoogleCloudAiplatformV1SamplingStrategyPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1SamplingStrategyOutput) ToGoogleCloudAiplatformV1SamplingStrategyPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1SamplingStrategyPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1SamplingStrategy) *GoogleCloudAiplatformV1SamplingStrategy {
		return &v
	}).(GoogleCloudAiplatformV1SamplingStrategyPtrOutput)
}

// Random sample config. Will support more sampling strategies later.
func (o GoogleCloudAiplatformV1SamplingStrategyOutput) RandomSampleConfig() GoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1SamplingStrategy) *GoogleCloudAiplatformV1SamplingStrategyRandomSampleConfig {
		return v.RandomSampleConfig
	}).(GoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigPtrOutput)
}

type GoogleCloudAiplatformV1SamplingStrategyPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1SamplingStrategyPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1SamplingStrategy)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1SamplingStrategyPtrOutput) ToGoogleCloudAiplatformV1SamplingStrategyPtrOutput() GoogleCloudAiplatformV1SamplingStrategyPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1SamplingStrategyPtrOutput) ToGoogleCloudAiplatformV1SamplingStrategyPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1SamplingStrategyPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1SamplingStrategyPtrOutput) Elem() GoogleCloudAiplatformV1SamplingStrategyOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1SamplingStrategy) GoogleCloudAiplatformV1SamplingStrategy {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1SamplingStrategy
		return ret
	}).(GoogleCloudAiplatformV1SamplingStrategyOutput)
}

// Random sample config. Will support more sampling strategies later.
func (o GoogleCloudAiplatformV1SamplingStrategyPtrOutput) RandomSampleConfig() GoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1SamplingStrategy) *GoogleCloudAiplatformV1SamplingStrategyRandomSampleConfig {
		if v == nil {
			return nil
		}
		return v.RandomSampleConfig
	}).(GoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigPtrOutput)
}

// Requests are randomly selected.
type GoogleCloudAiplatformV1SamplingStrategyRandomSampleConfig struct {
	// Sample rate (0, 1]
	SampleRate *float64 `pulumi:"sampleRate"`
}

// GoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigInput is an input type that accepts GoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigArgs and GoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigInput` via:
//
//	GoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigArgs{...}
type GoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigOutput() GoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigOutput
	ToGoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigOutputWithContext(context.Context) GoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigOutput
}

// Requests are randomly selected.
type GoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigArgs struct {
	// Sample rate (0, 1]
	SampleRate pulumi.Float64PtrInput `pulumi:"sampleRate"`
}

func (GoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1SamplingStrategyRandomSampleConfig)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigArgs) ToGoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigOutput() GoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigOutput {
	return i.ToGoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigArgs) ToGoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigOutput)
}

func (i GoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigArgs) ToGoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigPtrOutput() GoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigArgs) ToGoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigOutput).ToGoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigPtrInput is an input type that accepts GoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigArgs, GoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigPtr and GoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigPtrInput` via:
//
//	        GoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigPtrOutput() GoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigPtrOutput
	ToGoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigPtrOutput
}

type googleCloudAiplatformV1SamplingStrategyRandomSampleConfigPtrType GoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigArgs

func GoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigPtr(v *GoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigArgs) GoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigPtrInput {
	return (*googleCloudAiplatformV1SamplingStrategyRandomSampleConfigPtrType)(v)
}

func (*googleCloudAiplatformV1SamplingStrategyRandomSampleConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1SamplingStrategyRandomSampleConfig)(nil)).Elem()
}

func (i *googleCloudAiplatformV1SamplingStrategyRandomSampleConfigPtrType) ToGoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigPtrOutput() GoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1SamplingStrategyRandomSampleConfigPtrType) ToGoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigPtrOutput)
}

// Requests are randomly selected.
type GoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1SamplingStrategyRandomSampleConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigOutput) ToGoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigOutput() GoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigOutput) ToGoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigOutput) ToGoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigPtrOutput() GoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigPtrOutput {
	return o.ToGoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigOutput) ToGoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1SamplingStrategyRandomSampleConfig) *GoogleCloudAiplatformV1SamplingStrategyRandomSampleConfig {
		return &v
	}).(GoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigPtrOutput)
}

// Sample rate (0, 1]
func (o GoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigOutput) SampleRate() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1SamplingStrategyRandomSampleConfig) *float64 { return v.SampleRate }).(pulumi.Float64PtrOutput)
}

type GoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1SamplingStrategyRandomSampleConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigPtrOutput) ToGoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigPtrOutput() GoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigPtrOutput) ToGoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigPtrOutput) Elem() GoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1SamplingStrategyRandomSampleConfig) GoogleCloudAiplatformV1SamplingStrategyRandomSampleConfig {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1SamplingStrategyRandomSampleConfig
		return ret
	}).(GoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigOutput)
}

// Sample rate (0, 1]
func (o GoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigPtrOutput) SampleRate() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1SamplingStrategyRandomSampleConfig) *float64 {
		if v == nil {
			return nil
		}
		return v.SampleRate
	}).(pulumi.Float64PtrOutput)
}

// Requests are randomly selected.
type GoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigResponse struct {
	// Sample rate (0, 1]
	SampleRate float64 `pulumi:"sampleRate"`
}

// Requests are randomly selected.
type GoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigResponseOutput) ToGoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigResponseOutput() GoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigResponseOutput) ToGoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigResponseOutput {
	return o
}

// Sample rate (0, 1]
func (o GoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigResponseOutput) SampleRate() pulumi.Float64Output {
	return o.ApplyT(func(v GoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigResponse) float64 { return v.SampleRate }).(pulumi.Float64Output)
}

// Sampling Strategy for logging, can be for both training and prediction dataset.
type GoogleCloudAiplatformV1SamplingStrategyResponse struct {
	// Random sample config. Will support more sampling strategies later.
	RandomSampleConfig GoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigResponse `pulumi:"randomSampleConfig"`
}

// Sampling Strategy for logging, can be for both training and prediction dataset.
type GoogleCloudAiplatformV1SamplingStrategyResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1SamplingStrategyResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1SamplingStrategyResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1SamplingStrategyResponseOutput) ToGoogleCloudAiplatformV1SamplingStrategyResponseOutput() GoogleCloudAiplatformV1SamplingStrategyResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1SamplingStrategyResponseOutput) ToGoogleCloudAiplatformV1SamplingStrategyResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1SamplingStrategyResponseOutput {
	return o
}

// Random sample config. Will support more sampling strategies later.
func (o GoogleCloudAiplatformV1SamplingStrategyResponseOutput) RandomSampleConfig() GoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1SamplingStrategyResponse) GoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigResponse {
		return v.RandomSampleConfig
	}).(GoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigResponseOutput)
}

// A SavedQuery is a view of the dataset. It references a subset of annotations by problem type and filters.
type GoogleCloudAiplatformV1SavedQuery struct {
	// The user-defined name of the SavedQuery. The name can be up to 128 characters long and can consist of any UTF-8 characters.
	DisplayName string `pulumi:"displayName"`
	// Used to perform a consistent read-modify-write update. If not set, a blind "overwrite" update happens.
	Etag *string `pulumi:"etag"`
	// Some additional information about the SavedQuery.
	Metadata interface{} `pulumi:"metadata"`
	// Problem type of the SavedQuery. Allowed values: * IMAGE_CLASSIFICATION_SINGLE_LABEL * IMAGE_CLASSIFICATION_MULTI_LABEL * IMAGE_BOUNDING_POLY * IMAGE_BOUNDING_BOX * TEXT_CLASSIFICATION_SINGLE_LABEL * TEXT_CLASSIFICATION_MULTI_LABEL * TEXT_EXTRACTION * TEXT_SENTIMENT * VIDEO_CLASSIFICATION * VIDEO_OBJECT_TRACKING
	ProblemType string `pulumi:"problemType"`
}

// GoogleCloudAiplatformV1SavedQueryInput is an input type that accepts GoogleCloudAiplatformV1SavedQueryArgs and GoogleCloudAiplatformV1SavedQueryOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1SavedQueryInput` via:
//
//	GoogleCloudAiplatformV1SavedQueryArgs{...}
type GoogleCloudAiplatformV1SavedQueryInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1SavedQueryOutput() GoogleCloudAiplatformV1SavedQueryOutput
	ToGoogleCloudAiplatformV1SavedQueryOutputWithContext(context.Context) GoogleCloudAiplatformV1SavedQueryOutput
}

// A SavedQuery is a view of the dataset. It references a subset of annotations by problem type and filters.
type GoogleCloudAiplatformV1SavedQueryArgs struct {
	// The user-defined name of the SavedQuery. The name can be up to 128 characters long and can consist of any UTF-8 characters.
	DisplayName pulumi.StringInput `pulumi:"displayName"`
	// Used to perform a consistent read-modify-write update. If not set, a blind "overwrite" update happens.
	Etag pulumi.StringPtrInput `pulumi:"etag"`
	// Some additional information about the SavedQuery.
	Metadata pulumi.Input `pulumi:"metadata"`
	// Problem type of the SavedQuery. Allowed values: * IMAGE_CLASSIFICATION_SINGLE_LABEL * IMAGE_CLASSIFICATION_MULTI_LABEL * IMAGE_BOUNDING_POLY * IMAGE_BOUNDING_BOX * TEXT_CLASSIFICATION_SINGLE_LABEL * TEXT_CLASSIFICATION_MULTI_LABEL * TEXT_EXTRACTION * TEXT_SENTIMENT * VIDEO_CLASSIFICATION * VIDEO_OBJECT_TRACKING
	ProblemType pulumi.StringInput `pulumi:"problemType"`
}

func (GoogleCloudAiplatformV1SavedQueryArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1SavedQuery)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1SavedQueryArgs) ToGoogleCloudAiplatformV1SavedQueryOutput() GoogleCloudAiplatformV1SavedQueryOutput {
	return i.ToGoogleCloudAiplatformV1SavedQueryOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1SavedQueryArgs) ToGoogleCloudAiplatformV1SavedQueryOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1SavedQueryOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1SavedQueryOutput)
}

// GoogleCloudAiplatformV1SavedQueryArrayInput is an input type that accepts GoogleCloudAiplatformV1SavedQueryArray and GoogleCloudAiplatformV1SavedQueryArrayOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1SavedQueryArrayInput` via:
//
//	GoogleCloudAiplatformV1SavedQueryArray{ GoogleCloudAiplatformV1SavedQueryArgs{...} }
type GoogleCloudAiplatformV1SavedQueryArrayInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1SavedQueryArrayOutput() GoogleCloudAiplatformV1SavedQueryArrayOutput
	ToGoogleCloudAiplatformV1SavedQueryArrayOutputWithContext(context.Context) GoogleCloudAiplatformV1SavedQueryArrayOutput
}

type GoogleCloudAiplatformV1SavedQueryArray []GoogleCloudAiplatformV1SavedQueryInput

func (GoogleCloudAiplatformV1SavedQueryArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1SavedQuery)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1SavedQueryArray) ToGoogleCloudAiplatformV1SavedQueryArrayOutput() GoogleCloudAiplatformV1SavedQueryArrayOutput {
	return i.ToGoogleCloudAiplatformV1SavedQueryArrayOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1SavedQueryArray) ToGoogleCloudAiplatformV1SavedQueryArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1SavedQueryArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1SavedQueryArrayOutput)
}

// A SavedQuery is a view of the dataset. It references a subset of annotations by problem type and filters.
type GoogleCloudAiplatformV1SavedQueryOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1SavedQueryOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1SavedQuery)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1SavedQueryOutput) ToGoogleCloudAiplatformV1SavedQueryOutput() GoogleCloudAiplatformV1SavedQueryOutput {
	return o
}

func (o GoogleCloudAiplatformV1SavedQueryOutput) ToGoogleCloudAiplatformV1SavedQueryOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1SavedQueryOutput {
	return o
}

// The user-defined name of the SavedQuery. The name can be up to 128 characters long and can consist of any UTF-8 characters.
func (o GoogleCloudAiplatformV1SavedQueryOutput) DisplayName() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1SavedQuery) string { return v.DisplayName }).(pulumi.StringOutput)
}

// Used to perform a consistent read-modify-write update. If not set, a blind "overwrite" update happens.
func (o GoogleCloudAiplatformV1SavedQueryOutput) Etag() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1SavedQuery) *string { return v.Etag }).(pulumi.StringPtrOutput)
}

// Some additional information about the SavedQuery.
func (o GoogleCloudAiplatformV1SavedQueryOutput) Metadata() pulumi.AnyOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1SavedQuery) interface{} { return v.Metadata }).(pulumi.AnyOutput)
}

// Problem type of the SavedQuery. Allowed values: * IMAGE_CLASSIFICATION_SINGLE_LABEL * IMAGE_CLASSIFICATION_MULTI_LABEL * IMAGE_BOUNDING_POLY * IMAGE_BOUNDING_BOX * TEXT_CLASSIFICATION_SINGLE_LABEL * TEXT_CLASSIFICATION_MULTI_LABEL * TEXT_EXTRACTION * TEXT_SENTIMENT * VIDEO_CLASSIFICATION * VIDEO_OBJECT_TRACKING
func (o GoogleCloudAiplatformV1SavedQueryOutput) ProblemType() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1SavedQuery) string { return v.ProblemType }).(pulumi.StringOutput)
}

type GoogleCloudAiplatformV1SavedQueryArrayOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1SavedQueryArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1SavedQuery)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1SavedQueryArrayOutput) ToGoogleCloudAiplatformV1SavedQueryArrayOutput() GoogleCloudAiplatformV1SavedQueryArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1SavedQueryArrayOutput) ToGoogleCloudAiplatformV1SavedQueryArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1SavedQueryArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1SavedQueryArrayOutput) Index(i pulumi.IntInput) GoogleCloudAiplatformV1SavedQueryOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GoogleCloudAiplatformV1SavedQuery {
		return vs[0].([]GoogleCloudAiplatformV1SavedQuery)[vs[1].(int)]
	}).(GoogleCloudAiplatformV1SavedQueryOutput)
}

// A SavedQuery is a view of the dataset. It references a subset of annotations by problem type and filters.
type GoogleCloudAiplatformV1SavedQueryResponse struct {
	// Filters on the Annotations in the dataset.
	AnnotationFilter string `pulumi:"annotationFilter"`
	// Number of AnnotationSpecs in the context of the SavedQuery.
	AnnotationSpecCount int `pulumi:"annotationSpecCount"`
	// Timestamp when this SavedQuery was created.
	CreateTime string `pulumi:"createTime"`
	// The user-defined name of the SavedQuery. The name can be up to 128 characters long and can consist of any UTF-8 characters.
	DisplayName string `pulumi:"displayName"`
	// Used to perform a consistent read-modify-write update. If not set, a blind "overwrite" update happens.
	Etag string `pulumi:"etag"`
	// Some additional information about the SavedQuery.
	Metadata interface{} `pulumi:"metadata"`
	// Resource name of the SavedQuery.
	Name string `pulumi:"name"`
	// Problem type of the SavedQuery. Allowed values: * IMAGE_CLASSIFICATION_SINGLE_LABEL * IMAGE_CLASSIFICATION_MULTI_LABEL * IMAGE_BOUNDING_POLY * IMAGE_BOUNDING_BOX * TEXT_CLASSIFICATION_SINGLE_LABEL * TEXT_CLASSIFICATION_MULTI_LABEL * TEXT_EXTRACTION * TEXT_SENTIMENT * VIDEO_CLASSIFICATION * VIDEO_OBJECT_TRACKING
	ProblemType string `pulumi:"problemType"`
	// If the Annotations belonging to the SavedQuery can be used for AutoML training.
	SupportAutomlTraining bool `pulumi:"supportAutomlTraining"`
	// Timestamp when SavedQuery was last updated.
	UpdateTime string `pulumi:"updateTime"`
}

// A SavedQuery is a view of the dataset. It references a subset of annotations by problem type and filters.
type GoogleCloudAiplatformV1SavedQueryResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1SavedQueryResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1SavedQueryResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1SavedQueryResponseOutput) ToGoogleCloudAiplatformV1SavedQueryResponseOutput() GoogleCloudAiplatformV1SavedQueryResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1SavedQueryResponseOutput) ToGoogleCloudAiplatformV1SavedQueryResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1SavedQueryResponseOutput {
	return o
}

// Filters on the Annotations in the dataset.
func (o GoogleCloudAiplatformV1SavedQueryResponseOutput) AnnotationFilter() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1SavedQueryResponse) string { return v.AnnotationFilter }).(pulumi.StringOutput)
}

// Number of AnnotationSpecs in the context of the SavedQuery.
func (o GoogleCloudAiplatformV1SavedQueryResponseOutput) AnnotationSpecCount() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1SavedQueryResponse) int { return v.AnnotationSpecCount }).(pulumi.IntOutput)
}

// Timestamp when this SavedQuery was created.
func (o GoogleCloudAiplatformV1SavedQueryResponseOutput) CreateTime() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1SavedQueryResponse) string { return v.CreateTime }).(pulumi.StringOutput)
}

// The user-defined name of the SavedQuery. The name can be up to 128 characters long and can consist of any UTF-8 characters.
func (o GoogleCloudAiplatformV1SavedQueryResponseOutput) DisplayName() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1SavedQueryResponse) string { return v.DisplayName }).(pulumi.StringOutput)
}

// Used to perform a consistent read-modify-write update. If not set, a blind "overwrite" update happens.
func (o GoogleCloudAiplatformV1SavedQueryResponseOutput) Etag() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1SavedQueryResponse) string { return v.Etag }).(pulumi.StringOutput)
}

// Some additional information about the SavedQuery.
func (o GoogleCloudAiplatformV1SavedQueryResponseOutput) Metadata() pulumi.AnyOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1SavedQueryResponse) interface{} { return v.Metadata }).(pulumi.AnyOutput)
}

// Resource name of the SavedQuery.
func (o GoogleCloudAiplatformV1SavedQueryResponseOutput) Name() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1SavedQueryResponse) string { return v.Name }).(pulumi.StringOutput)
}

// Problem type of the SavedQuery. Allowed values: * IMAGE_CLASSIFICATION_SINGLE_LABEL * IMAGE_CLASSIFICATION_MULTI_LABEL * IMAGE_BOUNDING_POLY * IMAGE_BOUNDING_BOX * TEXT_CLASSIFICATION_SINGLE_LABEL * TEXT_CLASSIFICATION_MULTI_LABEL * TEXT_EXTRACTION * TEXT_SENTIMENT * VIDEO_CLASSIFICATION * VIDEO_OBJECT_TRACKING
func (o GoogleCloudAiplatformV1SavedQueryResponseOutput) ProblemType() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1SavedQueryResponse) string { return v.ProblemType }).(pulumi.StringOutput)
}

// If the Annotations belonging to the SavedQuery can be used for AutoML training.
func (o GoogleCloudAiplatformV1SavedQueryResponseOutput) SupportAutomlTraining() pulumi.BoolOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1SavedQueryResponse) bool { return v.SupportAutomlTraining }).(pulumi.BoolOutput)
}

// Timestamp when SavedQuery was last updated.
func (o GoogleCloudAiplatformV1SavedQueryResponseOutput) UpdateTime() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1SavedQueryResponse) string { return v.UpdateTime }).(pulumi.StringOutput)
}

type GoogleCloudAiplatformV1SavedQueryResponseArrayOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1SavedQueryResponseArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1SavedQueryResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1SavedQueryResponseArrayOutput) ToGoogleCloudAiplatformV1SavedQueryResponseArrayOutput() GoogleCloudAiplatformV1SavedQueryResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1SavedQueryResponseArrayOutput) ToGoogleCloudAiplatformV1SavedQueryResponseArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1SavedQueryResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1SavedQueryResponseArrayOutput) Index(i pulumi.IntInput) GoogleCloudAiplatformV1SavedQueryResponseOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GoogleCloudAiplatformV1SavedQueryResponse {
		return vs[0].([]GoogleCloudAiplatformV1SavedQueryResponse)[vs[1].(int)]
	}).(GoogleCloudAiplatformV1SavedQueryResponseOutput)
}

// Status of a scheduled run.
type GoogleCloudAiplatformV1ScheduleRunResponseResponse struct {
	// The response of the scheduled run.
	RunResponse string `pulumi:"runResponse"`
	// The scheduled run time based on the user-specified schedule.
	ScheduledRunTime string `pulumi:"scheduledRunTime"`
}

// Status of a scheduled run.
type GoogleCloudAiplatformV1ScheduleRunResponseResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ScheduleRunResponseResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1ScheduleRunResponseResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ScheduleRunResponseResponseOutput) ToGoogleCloudAiplatformV1ScheduleRunResponseResponseOutput() GoogleCloudAiplatformV1ScheduleRunResponseResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1ScheduleRunResponseResponseOutput) ToGoogleCloudAiplatformV1ScheduleRunResponseResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ScheduleRunResponseResponseOutput {
	return o
}

// The response of the scheduled run.
func (o GoogleCloudAiplatformV1ScheduleRunResponseResponseOutput) RunResponse() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ScheduleRunResponseResponse) string { return v.RunResponse }).(pulumi.StringOutput)
}

// The scheduled run time based on the user-specified schedule.
func (o GoogleCloudAiplatformV1ScheduleRunResponseResponseOutput) ScheduledRunTime() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ScheduleRunResponseResponse) string { return v.ScheduledRunTime }).(pulumi.StringOutput)
}

// All parameters related to queuing and scheduling of custom jobs.
type GoogleCloudAiplatformV1Scheduling struct {
	// Optional. Indicates if the job should retry for internal errors after the job starts running. If true, overrides `Scheduling.restart_job_on_worker_restart` to false.
	DisableRetries *bool `pulumi:"disableRetries"`
	// Restarts the entire CustomJob if a worker gets restarted. This feature can be used by distributed training jobs that are not resilient to workers leaving and joining a job.
	RestartJobOnWorkerRestart *bool `pulumi:"restartJobOnWorkerRestart"`
	// The maximum job running time. The default is 7 days.
	Timeout *string `pulumi:"timeout"`
}

// GoogleCloudAiplatformV1SchedulingInput is an input type that accepts GoogleCloudAiplatformV1SchedulingArgs and GoogleCloudAiplatformV1SchedulingOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1SchedulingInput` via:
//
//	GoogleCloudAiplatformV1SchedulingArgs{...}
type GoogleCloudAiplatformV1SchedulingInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1SchedulingOutput() GoogleCloudAiplatformV1SchedulingOutput
	ToGoogleCloudAiplatformV1SchedulingOutputWithContext(context.Context) GoogleCloudAiplatformV1SchedulingOutput
}

// All parameters related to queuing and scheduling of custom jobs.
type GoogleCloudAiplatformV1SchedulingArgs struct {
	// Optional. Indicates if the job should retry for internal errors after the job starts running. If true, overrides `Scheduling.restart_job_on_worker_restart` to false.
	DisableRetries pulumi.BoolPtrInput `pulumi:"disableRetries"`
	// Restarts the entire CustomJob if a worker gets restarted. This feature can be used by distributed training jobs that are not resilient to workers leaving and joining a job.
	RestartJobOnWorkerRestart pulumi.BoolPtrInput `pulumi:"restartJobOnWorkerRestart"`
	// The maximum job running time. The default is 7 days.
	Timeout pulumi.StringPtrInput `pulumi:"timeout"`
}

func (GoogleCloudAiplatformV1SchedulingArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1Scheduling)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1SchedulingArgs) ToGoogleCloudAiplatformV1SchedulingOutput() GoogleCloudAiplatformV1SchedulingOutput {
	return i.ToGoogleCloudAiplatformV1SchedulingOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1SchedulingArgs) ToGoogleCloudAiplatformV1SchedulingOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1SchedulingOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1SchedulingOutput)
}

func (i GoogleCloudAiplatformV1SchedulingArgs) ToGoogleCloudAiplatformV1SchedulingPtrOutput() GoogleCloudAiplatformV1SchedulingPtrOutput {
	return i.ToGoogleCloudAiplatformV1SchedulingPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1SchedulingArgs) ToGoogleCloudAiplatformV1SchedulingPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1SchedulingPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1SchedulingOutput).ToGoogleCloudAiplatformV1SchedulingPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1SchedulingPtrInput is an input type that accepts GoogleCloudAiplatformV1SchedulingArgs, GoogleCloudAiplatformV1SchedulingPtr and GoogleCloudAiplatformV1SchedulingPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1SchedulingPtrInput` via:
//
//	        GoogleCloudAiplatformV1SchedulingArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1SchedulingPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1SchedulingPtrOutput() GoogleCloudAiplatformV1SchedulingPtrOutput
	ToGoogleCloudAiplatformV1SchedulingPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1SchedulingPtrOutput
}

type googleCloudAiplatformV1SchedulingPtrType GoogleCloudAiplatformV1SchedulingArgs

func GoogleCloudAiplatformV1SchedulingPtr(v *GoogleCloudAiplatformV1SchedulingArgs) GoogleCloudAiplatformV1SchedulingPtrInput {
	return (*googleCloudAiplatformV1SchedulingPtrType)(v)
}

func (*googleCloudAiplatformV1SchedulingPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1Scheduling)(nil)).Elem()
}

func (i *googleCloudAiplatformV1SchedulingPtrType) ToGoogleCloudAiplatformV1SchedulingPtrOutput() GoogleCloudAiplatformV1SchedulingPtrOutput {
	return i.ToGoogleCloudAiplatformV1SchedulingPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1SchedulingPtrType) ToGoogleCloudAiplatformV1SchedulingPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1SchedulingPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1SchedulingPtrOutput)
}

// All parameters related to queuing and scheduling of custom jobs.
type GoogleCloudAiplatformV1SchedulingOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1SchedulingOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1Scheduling)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1SchedulingOutput) ToGoogleCloudAiplatformV1SchedulingOutput() GoogleCloudAiplatformV1SchedulingOutput {
	return o
}

func (o GoogleCloudAiplatformV1SchedulingOutput) ToGoogleCloudAiplatformV1SchedulingOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1SchedulingOutput {
	return o
}

func (o GoogleCloudAiplatformV1SchedulingOutput) ToGoogleCloudAiplatformV1SchedulingPtrOutput() GoogleCloudAiplatformV1SchedulingPtrOutput {
	return o.ToGoogleCloudAiplatformV1SchedulingPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1SchedulingOutput) ToGoogleCloudAiplatformV1SchedulingPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1SchedulingPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1Scheduling) *GoogleCloudAiplatformV1Scheduling {
		return &v
	}).(GoogleCloudAiplatformV1SchedulingPtrOutput)
}

// Optional. Indicates if the job should retry for internal errors after the job starts running. If true, overrides `Scheduling.restart_job_on_worker_restart` to false.
func (o GoogleCloudAiplatformV1SchedulingOutput) DisableRetries() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1Scheduling) *bool { return v.DisableRetries }).(pulumi.BoolPtrOutput)
}

// Restarts the entire CustomJob if a worker gets restarted. This feature can be used by distributed training jobs that are not resilient to workers leaving and joining a job.
func (o GoogleCloudAiplatformV1SchedulingOutput) RestartJobOnWorkerRestart() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1Scheduling) *bool { return v.RestartJobOnWorkerRestart }).(pulumi.BoolPtrOutput)
}

// The maximum job running time. The default is 7 days.
func (o GoogleCloudAiplatformV1SchedulingOutput) Timeout() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1Scheduling) *string { return v.Timeout }).(pulumi.StringPtrOutput)
}

type GoogleCloudAiplatformV1SchedulingPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1SchedulingPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1Scheduling)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1SchedulingPtrOutput) ToGoogleCloudAiplatformV1SchedulingPtrOutput() GoogleCloudAiplatformV1SchedulingPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1SchedulingPtrOutput) ToGoogleCloudAiplatformV1SchedulingPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1SchedulingPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1SchedulingPtrOutput) Elem() GoogleCloudAiplatformV1SchedulingOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1Scheduling) GoogleCloudAiplatformV1Scheduling {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1Scheduling
		return ret
	}).(GoogleCloudAiplatformV1SchedulingOutput)
}

// Optional. Indicates if the job should retry for internal errors after the job starts running. If true, overrides `Scheduling.restart_job_on_worker_restart` to false.
func (o GoogleCloudAiplatformV1SchedulingPtrOutput) DisableRetries() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1Scheduling) *bool {
		if v == nil {
			return nil
		}
		return v.DisableRetries
	}).(pulumi.BoolPtrOutput)
}

// Restarts the entire CustomJob if a worker gets restarted. This feature can be used by distributed training jobs that are not resilient to workers leaving and joining a job.
func (o GoogleCloudAiplatformV1SchedulingPtrOutput) RestartJobOnWorkerRestart() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1Scheduling) *bool {
		if v == nil {
			return nil
		}
		return v.RestartJobOnWorkerRestart
	}).(pulumi.BoolPtrOutput)
}

// The maximum job running time. The default is 7 days.
func (o GoogleCloudAiplatformV1SchedulingPtrOutput) Timeout() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1Scheduling) *string {
		if v == nil {
			return nil
		}
		return v.Timeout
	}).(pulumi.StringPtrOutput)
}

// All parameters related to queuing and scheduling of custom jobs.
type GoogleCloudAiplatformV1SchedulingResponse struct {
	// Optional. Indicates if the job should retry for internal errors after the job starts running. If true, overrides `Scheduling.restart_job_on_worker_restart` to false.
	DisableRetries bool `pulumi:"disableRetries"`
	// Restarts the entire CustomJob if a worker gets restarted. This feature can be used by distributed training jobs that are not resilient to workers leaving and joining a job.
	RestartJobOnWorkerRestart bool `pulumi:"restartJobOnWorkerRestart"`
	// The maximum job running time. The default is 7 days.
	Timeout string `pulumi:"timeout"`
}

// All parameters related to queuing and scheduling of custom jobs.
type GoogleCloudAiplatformV1SchedulingResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1SchedulingResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1SchedulingResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1SchedulingResponseOutput) ToGoogleCloudAiplatformV1SchedulingResponseOutput() GoogleCloudAiplatformV1SchedulingResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1SchedulingResponseOutput) ToGoogleCloudAiplatformV1SchedulingResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1SchedulingResponseOutput {
	return o
}

// Optional. Indicates if the job should retry for internal errors after the job starts running. If true, overrides `Scheduling.restart_job_on_worker_restart` to false.
func (o GoogleCloudAiplatformV1SchedulingResponseOutput) DisableRetries() pulumi.BoolOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1SchedulingResponse) bool { return v.DisableRetries }).(pulumi.BoolOutput)
}

// Restarts the entire CustomJob if a worker gets restarted. This feature can be used by distributed training jobs that are not resilient to workers leaving and joining a job.
func (o GoogleCloudAiplatformV1SchedulingResponseOutput) RestartJobOnWorkerRestart() pulumi.BoolOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1SchedulingResponse) bool { return v.RestartJobOnWorkerRestart }).(pulumi.BoolOutput)
}

// The maximum job running time. The default is 7 days.
func (o GoogleCloudAiplatformV1SchedulingResponseOutput) Timeout() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1SchedulingResponse) string { return v.Timeout }).(pulumi.StringOutput)
}

// Config for SmoothGrad approximation of gradients. When enabled, the gradients are approximated by averaging the gradients from noisy samples in the vicinity of the inputs. Adding noise can help improve the computed gradients. Refer to this paper for more details: https://arxiv.org/pdf/1706.03825.pdf
type GoogleCloudAiplatformV1SmoothGradConfig struct {
	// This is similar to noise_sigma, but provides additional flexibility. A separate noise sigma can be provided for each feature, which is useful if their distributions are different. No noise is added to features that are not set. If this field is unset, noise_sigma will be used for all features.
	FeatureNoiseSigma *GoogleCloudAiplatformV1FeatureNoiseSigma `pulumi:"featureNoiseSigma"`
	// This is a single float value and will be used to add noise to all the features. Use this field when all features are normalized to have the same distribution: scale to range [0, 1], [-1, 1] or z-scoring, where features are normalized to have 0-mean and 1-variance. Learn more about [normalization](https://developers.google.com/machine-learning/data-prep/transform/normalization). For best results the recommended value is about 10% - 20% of the standard deviation of the input feature. Refer to section 3.2 of the SmoothGrad paper: https://arxiv.org/pdf/1706.03825.pdf. Defaults to 0.1. If the distribution is different per feature, set feature_noise_sigma instead for each feature.
	NoiseSigma *float64 `pulumi:"noiseSigma"`
	// The number of gradient samples to use for approximation. The higher this number, the more accurate the gradient is, but the runtime complexity increases by this factor as well. Valid range of its value is [1, 50]. Defaults to 3.
	NoisySampleCount *int `pulumi:"noisySampleCount"`
}

// GoogleCloudAiplatformV1SmoothGradConfigInput is an input type that accepts GoogleCloudAiplatformV1SmoothGradConfigArgs and GoogleCloudAiplatformV1SmoothGradConfigOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1SmoothGradConfigInput` via:
//
//	GoogleCloudAiplatformV1SmoothGradConfigArgs{...}
type GoogleCloudAiplatformV1SmoothGradConfigInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1SmoothGradConfigOutput() GoogleCloudAiplatformV1SmoothGradConfigOutput
	ToGoogleCloudAiplatformV1SmoothGradConfigOutputWithContext(context.Context) GoogleCloudAiplatformV1SmoothGradConfigOutput
}

// Config for SmoothGrad approximation of gradients. When enabled, the gradients are approximated by averaging the gradients from noisy samples in the vicinity of the inputs. Adding noise can help improve the computed gradients. Refer to this paper for more details: https://arxiv.org/pdf/1706.03825.pdf
type GoogleCloudAiplatformV1SmoothGradConfigArgs struct {
	// This is similar to noise_sigma, but provides additional flexibility. A separate noise sigma can be provided for each feature, which is useful if their distributions are different. No noise is added to features that are not set. If this field is unset, noise_sigma will be used for all features.
	FeatureNoiseSigma GoogleCloudAiplatformV1FeatureNoiseSigmaPtrInput `pulumi:"featureNoiseSigma"`
	// This is a single float value and will be used to add noise to all the features. Use this field when all features are normalized to have the same distribution: scale to range [0, 1], [-1, 1] or z-scoring, where features are normalized to have 0-mean and 1-variance. Learn more about [normalization](https://developers.google.com/machine-learning/data-prep/transform/normalization). For best results the recommended value is about 10% - 20% of the standard deviation of the input feature. Refer to section 3.2 of the SmoothGrad paper: https://arxiv.org/pdf/1706.03825.pdf. Defaults to 0.1. If the distribution is different per feature, set feature_noise_sigma instead for each feature.
	NoiseSigma pulumi.Float64PtrInput `pulumi:"noiseSigma"`
	// The number of gradient samples to use for approximation. The higher this number, the more accurate the gradient is, but the runtime complexity increases by this factor as well. Valid range of its value is [1, 50]. Defaults to 3.
	NoisySampleCount pulumi.IntPtrInput `pulumi:"noisySampleCount"`
}

func (GoogleCloudAiplatformV1SmoothGradConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1SmoothGradConfig)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1SmoothGradConfigArgs) ToGoogleCloudAiplatformV1SmoothGradConfigOutput() GoogleCloudAiplatformV1SmoothGradConfigOutput {
	return i.ToGoogleCloudAiplatformV1SmoothGradConfigOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1SmoothGradConfigArgs) ToGoogleCloudAiplatformV1SmoothGradConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1SmoothGradConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1SmoothGradConfigOutput)
}

func (i GoogleCloudAiplatformV1SmoothGradConfigArgs) ToGoogleCloudAiplatformV1SmoothGradConfigPtrOutput() GoogleCloudAiplatformV1SmoothGradConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1SmoothGradConfigPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1SmoothGradConfigArgs) ToGoogleCloudAiplatformV1SmoothGradConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1SmoothGradConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1SmoothGradConfigOutput).ToGoogleCloudAiplatformV1SmoothGradConfigPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1SmoothGradConfigPtrInput is an input type that accepts GoogleCloudAiplatformV1SmoothGradConfigArgs, GoogleCloudAiplatformV1SmoothGradConfigPtr and GoogleCloudAiplatformV1SmoothGradConfigPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1SmoothGradConfigPtrInput` via:
//
//	        GoogleCloudAiplatformV1SmoothGradConfigArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1SmoothGradConfigPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1SmoothGradConfigPtrOutput() GoogleCloudAiplatformV1SmoothGradConfigPtrOutput
	ToGoogleCloudAiplatformV1SmoothGradConfigPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1SmoothGradConfigPtrOutput
}

type googleCloudAiplatformV1SmoothGradConfigPtrType GoogleCloudAiplatformV1SmoothGradConfigArgs

func GoogleCloudAiplatformV1SmoothGradConfigPtr(v *GoogleCloudAiplatformV1SmoothGradConfigArgs) GoogleCloudAiplatformV1SmoothGradConfigPtrInput {
	return (*googleCloudAiplatformV1SmoothGradConfigPtrType)(v)
}

func (*googleCloudAiplatformV1SmoothGradConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1SmoothGradConfig)(nil)).Elem()
}

func (i *googleCloudAiplatformV1SmoothGradConfigPtrType) ToGoogleCloudAiplatformV1SmoothGradConfigPtrOutput() GoogleCloudAiplatformV1SmoothGradConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1SmoothGradConfigPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1SmoothGradConfigPtrType) ToGoogleCloudAiplatformV1SmoothGradConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1SmoothGradConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1SmoothGradConfigPtrOutput)
}

// Config for SmoothGrad approximation of gradients. When enabled, the gradients are approximated by averaging the gradients from noisy samples in the vicinity of the inputs. Adding noise can help improve the computed gradients. Refer to this paper for more details: https://arxiv.org/pdf/1706.03825.pdf
type GoogleCloudAiplatformV1SmoothGradConfigOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1SmoothGradConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1SmoothGradConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1SmoothGradConfigOutput) ToGoogleCloudAiplatformV1SmoothGradConfigOutput() GoogleCloudAiplatformV1SmoothGradConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1SmoothGradConfigOutput) ToGoogleCloudAiplatformV1SmoothGradConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1SmoothGradConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1SmoothGradConfigOutput) ToGoogleCloudAiplatformV1SmoothGradConfigPtrOutput() GoogleCloudAiplatformV1SmoothGradConfigPtrOutput {
	return o.ToGoogleCloudAiplatformV1SmoothGradConfigPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1SmoothGradConfigOutput) ToGoogleCloudAiplatformV1SmoothGradConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1SmoothGradConfigPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1SmoothGradConfig) *GoogleCloudAiplatformV1SmoothGradConfig {
		return &v
	}).(GoogleCloudAiplatformV1SmoothGradConfigPtrOutput)
}

// This is similar to noise_sigma, but provides additional flexibility. A separate noise sigma can be provided for each feature, which is useful if their distributions are different. No noise is added to features that are not set. If this field is unset, noise_sigma will be used for all features.
func (o GoogleCloudAiplatformV1SmoothGradConfigOutput) FeatureNoiseSigma() GoogleCloudAiplatformV1FeatureNoiseSigmaPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1SmoothGradConfig) *GoogleCloudAiplatformV1FeatureNoiseSigma {
		return v.FeatureNoiseSigma
	}).(GoogleCloudAiplatformV1FeatureNoiseSigmaPtrOutput)
}

// This is a single float value and will be used to add noise to all the features. Use this field when all features are normalized to have the same distribution: scale to range [0, 1], [-1, 1] or z-scoring, where features are normalized to have 0-mean and 1-variance. Learn more about [normalization](https://developers.google.com/machine-learning/data-prep/transform/normalization). For best results the recommended value is about 10% - 20% of the standard deviation of the input feature. Refer to section 3.2 of the SmoothGrad paper: https://arxiv.org/pdf/1706.03825.pdf. Defaults to 0.1. If the distribution is different per feature, set feature_noise_sigma instead for each feature.
func (o GoogleCloudAiplatformV1SmoothGradConfigOutput) NoiseSigma() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1SmoothGradConfig) *float64 { return v.NoiseSigma }).(pulumi.Float64PtrOutput)
}

// The number of gradient samples to use for approximation. The higher this number, the more accurate the gradient is, but the runtime complexity increases by this factor as well. Valid range of its value is [1, 50]. Defaults to 3.
func (o GoogleCloudAiplatformV1SmoothGradConfigOutput) NoisySampleCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1SmoothGradConfig) *int { return v.NoisySampleCount }).(pulumi.IntPtrOutput)
}

type GoogleCloudAiplatformV1SmoothGradConfigPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1SmoothGradConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1SmoothGradConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1SmoothGradConfigPtrOutput) ToGoogleCloudAiplatformV1SmoothGradConfigPtrOutput() GoogleCloudAiplatformV1SmoothGradConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1SmoothGradConfigPtrOutput) ToGoogleCloudAiplatformV1SmoothGradConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1SmoothGradConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1SmoothGradConfigPtrOutput) Elem() GoogleCloudAiplatformV1SmoothGradConfigOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1SmoothGradConfig) GoogleCloudAiplatformV1SmoothGradConfig {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1SmoothGradConfig
		return ret
	}).(GoogleCloudAiplatformV1SmoothGradConfigOutput)
}

// This is similar to noise_sigma, but provides additional flexibility. A separate noise sigma can be provided for each feature, which is useful if their distributions are different. No noise is added to features that are not set. If this field is unset, noise_sigma will be used for all features.
func (o GoogleCloudAiplatformV1SmoothGradConfigPtrOutput) FeatureNoiseSigma() GoogleCloudAiplatformV1FeatureNoiseSigmaPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1SmoothGradConfig) *GoogleCloudAiplatformV1FeatureNoiseSigma {
		if v == nil {
			return nil
		}
		return v.FeatureNoiseSigma
	}).(GoogleCloudAiplatformV1FeatureNoiseSigmaPtrOutput)
}

// This is a single float value and will be used to add noise to all the features. Use this field when all features are normalized to have the same distribution: scale to range [0, 1], [-1, 1] or z-scoring, where features are normalized to have 0-mean and 1-variance. Learn more about [normalization](https://developers.google.com/machine-learning/data-prep/transform/normalization). For best results the recommended value is about 10% - 20% of the standard deviation of the input feature. Refer to section 3.2 of the SmoothGrad paper: https://arxiv.org/pdf/1706.03825.pdf. Defaults to 0.1. If the distribution is different per feature, set feature_noise_sigma instead for each feature.
func (o GoogleCloudAiplatformV1SmoothGradConfigPtrOutput) NoiseSigma() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1SmoothGradConfig) *float64 {
		if v == nil {
			return nil
		}
		return v.NoiseSigma
	}).(pulumi.Float64PtrOutput)
}

// The number of gradient samples to use for approximation. The higher this number, the more accurate the gradient is, but the runtime complexity increases by this factor as well. Valid range of its value is [1, 50]. Defaults to 3.
func (o GoogleCloudAiplatformV1SmoothGradConfigPtrOutput) NoisySampleCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1SmoothGradConfig) *int {
		if v == nil {
			return nil
		}
		return v.NoisySampleCount
	}).(pulumi.IntPtrOutput)
}

// Config for SmoothGrad approximation of gradients. When enabled, the gradients are approximated by averaging the gradients from noisy samples in the vicinity of the inputs. Adding noise can help improve the computed gradients. Refer to this paper for more details: https://arxiv.org/pdf/1706.03825.pdf
type GoogleCloudAiplatformV1SmoothGradConfigResponse struct {
	// This is similar to noise_sigma, but provides additional flexibility. A separate noise sigma can be provided for each feature, which is useful if their distributions are different. No noise is added to features that are not set. If this field is unset, noise_sigma will be used for all features.
	FeatureNoiseSigma GoogleCloudAiplatformV1FeatureNoiseSigmaResponse `pulumi:"featureNoiseSigma"`
	// This is a single float value and will be used to add noise to all the features. Use this field when all features are normalized to have the same distribution: scale to range [0, 1], [-1, 1] or z-scoring, where features are normalized to have 0-mean and 1-variance. Learn more about [normalization](https://developers.google.com/machine-learning/data-prep/transform/normalization). For best results the recommended value is about 10% - 20% of the standard deviation of the input feature. Refer to section 3.2 of the SmoothGrad paper: https://arxiv.org/pdf/1706.03825.pdf. Defaults to 0.1. If the distribution is different per feature, set feature_noise_sigma instead for each feature.
	NoiseSigma float64 `pulumi:"noiseSigma"`
	// The number of gradient samples to use for approximation. The higher this number, the more accurate the gradient is, but the runtime complexity increases by this factor as well. Valid range of its value is [1, 50]. Defaults to 3.
	NoisySampleCount int `pulumi:"noisySampleCount"`
}

// Config for SmoothGrad approximation of gradients. When enabled, the gradients are approximated by averaging the gradients from noisy samples in the vicinity of the inputs. Adding noise can help improve the computed gradients. Refer to this paper for more details: https://arxiv.org/pdf/1706.03825.pdf
type GoogleCloudAiplatformV1SmoothGradConfigResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1SmoothGradConfigResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1SmoothGradConfigResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1SmoothGradConfigResponseOutput) ToGoogleCloudAiplatformV1SmoothGradConfigResponseOutput() GoogleCloudAiplatformV1SmoothGradConfigResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1SmoothGradConfigResponseOutput) ToGoogleCloudAiplatformV1SmoothGradConfigResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1SmoothGradConfigResponseOutput {
	return o
}

// This is similar to noise_sigma, but provides additional flexibility. A separate noise sigma can be provided for each feature, which is useful if their distributions are different. No noise is added to features that are not set. If this field is unset, noise_sigma will be used for all features.
func (o GoogleCloudAiplatformV1SmoothGradConfigResponseOutput) FeatureNoiseSigma() GoogleCloudAiplatformV1FeatureNoiseSigmaResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1SmoothGradConfigResponse) GoogleCloudAiplatformV1FeatureNoiseSigmaResponse {
		return v.FeatureNoiseSigma
	}).(GoogleCloudAiplatformV1FeatureNoiseSigmaResponseOutput)
}

// This is a single float value and will be used to add noise to all the features. Use this field when all features are normalized to have the same distribution: scale to range [0, 1], [-1, 1] or z-scoring, where features are normalized to have 0-mean and 1-variance. Learn more about [normalization](https://developers.google.com/machine-learning/data-prep/transform/normalization). For best results the recommended value is about 10% - 20% of the standard deviation of the input feature. Refer to section 3.2 of the SmoothGrad paper: https://arxiv.org/pdf/1706.03825.pdf. Defaults to 0.1. If the distribution is different per feature, set feature_noise_sigma instead for each feature.
func (o GoogleCloudAiplatformV1SmoothGradConfigResponseOutput) NoiseSigma() pulumi.Float64Output {
	return o.ApplyT(func(v GoogleCloudAiplatformV1SmoothGradConfigResponse) float64 { return v.NoiseSigma }).(pulumi.Float64Output)
}

// The number of gradient samples to use for approximation. The higher this number, the more accurate the gradient is, but the runtime complexity increases by this factor as well. Valid range of its value is [1, 50]. Defaults to 3.
func (o GoogleCloudAiplatformV1SmoothGradConfigResponseOutput) NoisySampleCount() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1SmoothGradConfigResponse) int { return v.NoisySampleCount }).(pulumi.IntOutput)
}

// Assigns input data to the training, validation, and test sets so that the distribution of values found in the categorical column (as specified by the `key` field) is mirrored within each split. The fraction values determine the relative sizes of the splits. For example, if the specified column has three values, with 50% of the rows having value "A", 25% value "B", and 25% value "C", and the split fractions are specified as 80/10/10, then the training set will constitute 80% of the training data, with about 50% of the training set rows having the value "A" for the specified column, about 25% having the value "B", and about 25% having the value "C". Only the top 500 occurring values are used; any values not in the top 500 values are randomly assigned to a split. If less than three rows contain a specific value, those rows are randomly assigned. Supported only for tabular Datasets.
type GoogleCloudAiplatformV1StratifiedSplit struct {
	// The key is a name of one of the Dataset's data columns. The key provided must be for a categorical column.
	Key string `pulumi:"key"`
	// The fraction of the input data that is to be used to evaluate the Model.
	TestFraction *float64 `pulumi:"testFraction"`
	// The fraction of the input data that is to be used to train the Model.
	TrainingFraction *float64 `pulumi:"trainingFraction"`
	// The fraction of the input data that is to be used to validate the Model.
	ValidationFraction *float64 `pulumi:"validationFraction"`
}

// GoogleCloudAiplatformV1StratifiedSplitInput is an input type that accepts GoogleCloudAiplatformV1StratifiedSplitArgs and GoogleCloudAiplatformV1StratifiedSplitOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1StratifiedSplitInput` via:
//
//	GoogleCloudAiplatformV1StratifiedSplitArgs{...}
type GoogleCloudAiplatformV1StratifiedSplitInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1StratifiedSplitOutput() GoogleCloudAiplatformV1StratifiedSplitOutput
	ToGoogleCloudAiplatformV1StratifiedSplitOutputWithContext(context.Context) GoogleCloudAiplatformV1StratifiedSplitOutput
}

// Assigns input data to the training, validation, and test sets so that the distribution of values found in the categorical column (as specified by the `key` field) is mirrored within each split. The fraction values determine the relative sizes of the splits. For example, if the specified column has three values, with 50% of the rows having value "A", 25% value "B", and 25% value "C", and the split fractions are specified as 80/10/10, then the training set will constitute 80% of the training data, with about 50% of the training set rows having the value "A" for the specified column, about 25% having the value "B", and about 25% having the value "C". Only the top 500 occurring values are used; any values not in the top 500 values are randomly assigned to a split. If less than three rows contain a specific value, those rows are randomly assigned. Supported only for tabular Datasets.
type GoogleCloudAiplatformV1StratifiedSplitArgs struct {
	// The key is a name of one of the Dataset's data columns. The key provided must be for a categorical column.
	Key pulumi.StringInput `pulumi:"key"`
	// The fraction of the input data that is to be used to evaluate the Model.
	TestFraction pulumi.Float64PtrInput `pulumi:"testFraction"`
	// The fraction of the input data that is to be used to train the Model.
	TrainingFraction pulumi.Float64PtrInput `pulumi:"trainingFraction"`
	// The fraction of the input data that is to be used to validate the Model.
	ValidationFraction pulumi.Float64PtrInput `pulumi:"validationFraction"`
}

func (GoogleCloudAiplatformV1StratifiedSplitArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1StratifiedSplit)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1StratifiedSplitArgs) ToGoogleCloudAiplatformV1StratifiedSplitOutput() GoogleCloudAiplatformV1StratifiedSplitOutput {
	return i.ToGoogleCloudAiplatformV1StratifiedSplitOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1StratifiedSplitArgs) ToGoogleCloudAiplatformV1StratifiedSplitOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StratifiedSplitOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1StratifiedSplitOutput)
}

func (i GoogleCloudAiplatformV1StratifiedSplitArgs) ToGoogleCloudAiplatformV1StratifiedSplitPtrOutput() GoogleCloudAiplatformV1StratifiedSplitPtrOutput {
	return i.ToGoogleCloudAiplatformV1StratifiedSplitPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1StratifiedSplitArgs) ToGoogleCloudAiplatformV1StratifiedSplitPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StratifiedSplitPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1StratifiedSplitOutput).ToGoogleCloudAiplatformV1StratifiedSplitPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1StratifiedSplitPtrInput is an input type that accepts GoogleCloudAiplatformV1StratifiedSplitArgs, GoogleCloudAiplatformV1StratifiedSplitPtr and GoogleCloudAiplatformV1StratifiedSplitPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1StratifiedSplitPtrInput` via:
//
//	        GoogleCloudAiplatformV1StratifiedSplitArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1StratifiedSplitPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1StratifiedSplitPtrOutput() GoogleCloudAiplatformV1StratifiedSplitPtrOutput
	ToGoogleCloudAiplatformV1StratifiedSplitPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1StratifiedSplitPtrOutput
}

type googleCloudAiplatformV1StratifiedSplitPtrType GoogleCloudAiplatformV1StratifiedSplitArgs

func GoogleCloudAiplatformV1StratifiedSplitPtr(v *GoogleCloudAiplatformV1StratifiedSplitArgs) GoogleCloudAiplatformV1StratifiedSplitPtrInput {
	return (*googleCloudAiplatformV1StratifiedSplitPtrType)(v)
}

func (*googleCloudAiplatformV1StratifiedSplitPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1StratifiedSplit)(nil)).Elem()
}

func (i *googleCloudAiplatformV1StratifiedSplitPtrType) ToGoogleCloudAiplatformV1StratifiedSplitPtrOutput() GoogleCloudAiplatformV1StratifiedSplitPtrOutput {
	return i.ToGoogleCloudAiplatformV1StratifiedSplitPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1StratifiedSplitPtrType) ToGoogleCloudAiplatformV1StratifiedSplitPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StratifiedSplitPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1StratifiedSplitPtrOutput)
}

// Assigns input data to the training, validation, and test sets so that the distribution of values found in the categorical column (as specified by the `key` field) is mirrored within each split. The fraction values determine the relative sizes of the splits. For example, if the specified column has three values, with 50% of the rows having value "A", 25% value "B", and 25% value "C", and the split fractions are specified as 80/10/10, then the training set will constitute 80% of the training data, with about 50% of the training set rows having the value "A" for the specified column, about 25% having the value "B", and about 25% having the value "C". Only the top 500 occurring values are used; any values not in the top 500 values are randomly assigned to a split. If less than three rows contain a specific value, those rows are randomly assigned. Supported only for tabular Datasets.
type GoogleCloudAiplatformV1StratifiedSplitOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1StratifiedSplitOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1StratifiedSplit)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1StratifiedSplitOutput) ToGoogleCloudAiplatformV1StratifiedSplitOutput() GoogleCloudAiplatformV1StratifiedSplitOutput {
	return o
}

func (o GoogleCloudAiplatformV1StratifiedSplitOutput) ToGoogleCloudAiplatformV1StratifiedSplitOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StratifiedSplitOutput {
	return o
}

func (o GoogleCloudAiplatformV1StratifiedSplitOutput) ToGoogleCloudAiplatformV1StratifiedSplitPtrOutput() GoogleCloudAiplatformV1StratifiedSplitPtrOutput {
	return o.ToGoogleCloudAiplatformV1StratifiedSplitPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1StratifiedSplitOutput) ToGoogleCloudAiplatformV1StratifiedSplitPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StratifiedSplitPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1StratifiedSplit) *GoogleCloudAiplatformV1StratifiedSplit {
		return &v
	}).(GoogleCloudAiplatformV1StratifiedSplitPtrOutput)
}

// The key is a name of one of the Dataset's data columns. The key provided must be for a categorical column.
func (o GoogleCloudAiplatformV1StratifiedSplitOutput) Key() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StratifiedSplit) string { return v.Key }).(pulumi.StringOutput)
}

// The fraction of the input data that is to be used to evaluate the Model.
func (o GoogleCloudAiplatformV1StratifiedSplitOutput) TestFraction() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StratifiedSplit) *float64 { return v.TestFraction }).(pulumi.Float64PtrOutput)
}

// The fraction of the input data that is to be used to train the Model.
func (o GoogleCloudAiplatformV1StratifiedSplitOutput) TrainingFraction() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StratifiedSplit) *float64 { return v.TrainingFraction }).(pulumi.Float64PtrOutput)
}

// The fraction of the input data that is to be used to validate the Model.
func (o GoogleCloudAiplatformV1StratifiedSplitOutput) ValidationFraction() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StratifiedSplit) *float64 { return v.ValidationFraction }).(pulumi.Float64PtrOutput)
}

type GoogleCloudAiplatformV1StratifiedSplitPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1StratifiedSplitPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1StratifiedSplit)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1StratifiedSplitPtrOutput) ToGoogleCloudAiplatformV1StratifiedSplitPtrOutput() GoogleCloudAiplatformV1StratifiedSplitPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1StratifiedSplitPtrOutput) ToGoogleCloudAiplatformV1StratifiedSplitPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StratifiedSplitPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1StratifiedSplitPtrOutput) Elem() GoogleCloudAiplatformV1StratifiedSplitOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1StratifiedSplit) GoogleCloudAiplatformV1StratifiedSplit {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1StratifiedSplit
		return ret
	}).(GoogleCloudAiplatformV1StratifiedSplitOutput)
}

// The key is a name of one of the Dataset's data columns. The key provided must be for a categorical column.
func (o GoogleCloudAiplatformV1StratifiedSplitPtrOutput) Key() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1StratifiedSplit) *string {
		if v == nil {
			return nil
		}
		return &v.Key
	}).(pulumi.StringPtrOutput)
}

// The fraction of the input data that is to be used to evaluate the Model.
func (o GoogleCloudAiplatformV1StratifiedSplitPtrOutput) TestFraction() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1StratifiedSplit) *float64 {
		if v == nil {
			return nil
		}
		return v.TestFraction
	}).(pulumi.Float64PtrOutput)
}

// The fraction of the input data that is to be used to train the Model.
func (o GoogleCloudAiplatformV1StratifiedSplitPtrOutput) TrainingFraction() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1StratifiedSplit) *float64 {
		if v == nil {
			return nil
		}
		return v.TrainingFraction
	}).(pulumi.Float64PtrOutput)
}

// The fraction of the input data that is to be used to validate the Model.
func (o GoogleCloudAiplatformV1StratifiedSplitPtrOutput) ValidationFraction() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1StratifiedSplit) *float64 {
		if v == nil {
			return nil
		}
		return v.ValidationFraction
	}).(pulumi.Float64PtrOutput)
}

// Assigns input data to the training, validation, and test sets so that the distribution of values found in the categorical column (as specified by the `key` field) is mirrored within each split. The fraction values determine the relative sizes of the splits. For example, if the specified column has three values, with 50% of the rows having value "A", 25% value "B", and 25% value "C", and the split fractions are specified as 80/10/10, then the training set will constitute 80% of the training data, with about 50% of the training set rows having the value "A" for the specified column, about 25% having the value "B", and about 25% having the value "C". Only the top 500 occurring values are used; any values not in the top 500 values are randomly assigned to a split. If less than three rows contain a specific value, those rows are randomly assigned. Supported only for tabular Datasets.
type GoogleCloudAiplatformV1StratifiedSplitResponse struct {
	// The key is a name of one of the Dataset's data columns. The key provided must be for a categorical column.
	Key string `pulumi:"key"`
	// The fraction of the input data that is to be used to evaluate the Model.
	TestFraction float64 `pulumi:"testFraction"`
	// The fraction of the input data that is to be used to train the Model.
	TrainingFraction float64 `pulumi:"trainingFraction"`
	// The fraction of the input data that is to be used to validate the Model.
	ValidationFraction float64 `pulumi:"validationFraction"`
}

// Assigns input data to the training, validation, and test sets so that the distribution of values found in the categorical column (as specified by the `key` field) is mirrored within each split. The fraction values determine the relative sizes of the splits. For example, if the specified column has three values, with 50% of the rows having value "A", 25% value "B", and 25% value "C", and the split fractions are specified as 80/10/10, then the training set will constitute 80% of the training data, with about 50% of the training set rows having the value "A" for the specified column, about 25% having the value "B", and about 25% having the value "C". Only the top 500 occurring values are used; any values not in the top 500 values are randomly assigned to a split. If less than three rows contain a specific value, those rows are randomly assigned. Supported only for tabular Datasets.
type GoogleCloudAiplatformV1StratifiedSplitResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1StratifiedSplitResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1StratifiedSplitResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1StratifiedSplitResponseOutput) ToGoogleCloudAiplatformV1StratifiedSplitResponseOutput() GoogleCloudAiplatformV1StratifiedSplitResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1StratifiedSplitResponseOutput) ToGoogleCloudAiplatformV1StratifiedSplitResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StratifiedSplitResponseOutput {
	return o
}

// The key is a name of one of the Dataset's data columns. The key provided must be for a categorical column.
func (o GoogleCloudAiplatformV1StratifiedSplitResponseOutput) Key() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StratifiedSplitResponse) string { return v.Key }).(pulumi.StringOutput)
}

// The fraction of the input data that is to be used to evaluate the Model.
func (o GoogleCloudAiplatformV1StratifiedSplitResponseOutput) TestFraction() pulumi.Float64Output {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StratifiedSplitResponse) float64 { return v.TestFraction }).(pulumi.Float64Output)
}

// The fraction of the input data that is to be used to train the Model.
func (o GoogleCloudAiplatformV1StratifiedSplitResponseOutput) TrainingFraction() pulumi.Float64Output {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StratifiedSplitResponse) float64 { return v.TrainingFraction }).(pulumi.Float64Output)
}

// The fraction of the input data that is to be used to validate the Model.
func (o GoogleCloudAiplatformV1StratifiedSplitResponseOutput) ValidationFraction() pulumi.Float64Output {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StratifiedSplitResponse) float64 { return v.ValidationFraction }).(pulumi.Float64Output)
}

// Represents specification of a Study.
type GoogleCloudAiplatformV1StudySpec struct {
	// The search algorithm specified for the Study.
	Algorithm *GoogleCloudAiplatformV1StudySpecAlgorithm `pulumi:"algorithm"`
	// The automated early stopping spec using convex stopping rule.
	ConvexAutomatedStoppingSpec *GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpec `pulumi:"convexAutomatedStoppingSpec"`
	// The automated early stopping spec using decay curve rule.
	DecayCurveStoppingSpec *GoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpec `pulumi:"decayCurveStoppingSpec"`
	// Describe which measurement selection type will be used
	MeasurementSelectionType *GoogleCloudAiplatformV1StudySpecMeasurementSelectionType `pulumi:"measurementSelectionType"`
	// The automated early stopping spec using median rule.
	MedianAutomatedStoppingSpec *GoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpec `pulumi:"medianAutomatedStoppingSpec"`
	// Metric specs for the Study.
	Metrics []GoogleCloudAiplatformV1StudySpecMetricSpec `pulumi:"metrics"`
	// The observation noise level of the study. Currently only supported by the Vertex AI Vizier service. Not supported by HyperparameterTuningJob or TrainingPipeline.
	ObservationNoise *GoogleCloudAiplatformV1StudySpecObservationNoise `pulumi:"observationNoise"`
	// The set of parameters to tune.
	Parameters []GoogleCloudAiplatformV1StudySpecParameterSpec `pulumi:"parameters"`
	// Conditions for automated stopping of a Study. Enable automated stopping by configuring at least one condition.
	StudyStoppingConfig *GoogleCloudAiplatformV1StudySpecStudyStoppingConfig `pulumi:"studyStoppingConfig"`
}

// GoogleCloudAiplatformV1StudySpecInput is an input type that accepts GoogleCloudAiplatformV1StudySpecArgs and GoogleCloudAiplatformV1StudySpecOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1StudySpecInput` via:
//
//	GoogleCloudAiplatformV1StudySpecArgs{...}
type GoogleCloudAiplatformV1StudySpecInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1StudySpecOutput() GoogleCloudAiplatformV1StudySpecOutput
	ToGoogleCloudAiplatformV1StudySpecOutputWithContext(context.Context) GoogleCloudAiplatformV1StudySpecOutput
}

// Represents specification of a Study.
type GoogleCloudAiplatformV1StudySpecArgs struct {
	// The search algorithm specified for the Study.
	Algorithm GoogleCloudAiplatformV1StudySpecAlgorithmPtrInput `pulumi:"algorithm"`
	// The automated early stopping spec using convex stopping rule.
	ConvexAutomatedStoppingSpec GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecPtrInput `pulumi:"convexAutomatedStoppingSpec"`
	// The automated early stopping spec using decay curve rule.
	DecayCurveStoppingSpec GoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecPtrInput `pulumi:"decayCurveStoppingSpec"`
	// Describe which measurement selection type will be used
	MeasurementSelectionType GoogleCloudAiplatformV1StudySpecMeasurementSelectionTypePtrInput `pulumi:"measurementSelectionType"`
	// The automated early stopping spec using median rule.
	MedianAutomatedStoppingSpec GoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecPtrInput `pulumi:"medianAutomatedStoppingSpec"`
	// Metric specs for the Study.
	Metrics GoogleCloudAiplatformV1StudySpecMetricSpecArrayInput `pulumi:"metrics"`
	// The observation noise level of the study. Currently only supported by the Vertex AI Vizier service. Not supported by HyperparameterTuningJob or TrainingPipeline.
	ObservationNoise GoogleCloudAiplatformV1StudySpecObservationNoisePtrInput `pulumi:"observationNoise"`
	// The set of parameters to tune.
	Parameters GoogleCloudAiplatformV1StudySpecParameterSpecArrayInput `pulumi:"parameters"`
	// Conditions for automated stopping of a Study. Enable automated stopping by configuring at least one condition.
	StudyStoppingConfig GoogleCloudAiplatformV1StudySpecStudyStoppingConfigPtrInput `pulumi:"studyStoppingConfig"`
}

func (GoogleCloudAiplatformV1StudySpecArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1StudySpec)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1StudySpecArgs) ToGoogleCloudAiplatformV1StudySpecOutput() GoogleCloudAiplatformV1StudySpecOutput {
	return i.ToGoogleCloudAiplatformV1StudySpecOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1StudySpecArgs) ToGoogleCloudAiplatformV1StudySpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1StudySpecOutput)
}

// Represents specification of a Study.
type GoogleCloudAiplatformV1StudySpecOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1StudySpecOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1StudySpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1StudySpecOutput) ToGoogleCloudAiplatformV1StudySpecOutput() GoogleCloudAiplatformV1StudySpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1StudySpecOutput) ToGoogleCloudAiplatformV1StudySpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecOutput {
	return o
}

// The search algorithm specified for the Study.
func (o GoogleCloudAiplatformV1StudySpecOutput) Algorithm() GoogleCloudAiplatformV1StudySpecAlgorithmPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpec) *GoogleCloudAiplatformV1StudySpecAlgorithm {
		return v.Algorithm
	}).(GoogleCloudAiplatformV1StudySpecAlgorithmPtrOutput)
}

// The automated early stopping spec using convex stopping rule.
func (o GoogleCloudAiplatformV1StudySpecOutput) ConvexAutomatedStoppingSpec() GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpec) *GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpec {
		return v.ConvexAutomatedStoppingSpec
	}).(GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecPtrOutput)
}

// The automated early stopping spec using decay curve rule.
func (o GoogleCloudAiplatformV1StudySpecOutput) DecayCurveStoppingSpec() GoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpec) *GoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpec {
		return v.DecayCurveStoppingSpec
	}).(GoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecPtrOutput)
}

// Describe which measurement selection type will be used
func (o GoogleCloudAiplatformV1StudySpecOutput) MeasurementSelectionType() GoogleCloudAiplatformV1StudySpecMeasurementSelectionTypePtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpec) *GoogleCloudAiplatformV1StudySpecMeasurementSelectionType {
		return v.MeasurementSelectionType
	}).(GoogleCloudAiplatformV1StudySpecMeasurementSelectionTypePtrOutput)
}

// The automated early stopping spec using median rule.
func (o GoogleCloudAiplatformV1StudySpecOutput) MedianAutomatedStoppingSpec() GoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpec) *GoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpec {
		return v.MedianAutomatedStoppingSpec
	}).(GoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecPtrOutput)
}

// Metric specs for the Study.
func (o GoogleCloudAiplatformV1StudySpecOutput) Metrics() GoogleCloudAiplatformV1StudySpecMetricSpecArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpec) []GoogleCloudAiplatformV1StudySpecMetricSpec {
		return v.Metrics
	}).(GoogleCloudAiplatformV1StudySpecMetricSpecArrayOutput)
}

// The observation noise level of the study. Currently only supported by the Vertex AI Vizier service. Not supported by HyperparameterTuningJob or TrainingPipeline.
func (o GoogleCloudAiplatformV1StudySpecOutput) ObservationNoise() GoogleCloudAiplatformV1StudySpecObservationNoisePtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpec) *GoogleCloudAiplatformV1StudySpecObservationNoise {
		return v.ObservationNoise
	}).(GoogleCloudAiplatformV1StudySpecObservationNoisePtrOutput)
}

// The set of parameters to tune.
func (o GoogleCloudAiplatformV1StudySpecOutput) Parameters() GoogleCloudAiplatformV1StudySpecParameterSpecArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpec) []GoogleCloudAiplatformV1StudySpecParameterSpec {
		return v.Parameters
	}).(GoogleCloudAiplatformV1StudySpecParameterSpecArrayOutput)
}

// Conditions for automated stopping of a Study. Enable automated stopping by configuring at least one condition.
func (o GoogleCloudAiplatformV1StudySpecOutput) StudyStoppingConfig() GoogleCloudAiplatformV1StudySpecStudyStoppingConfigPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpec) *GoogleCloudAiplatformV1StudySpecStudyStoppingConfig {
		return v.StudyStoppingConfig
	}).(GoogleCloudAiplatformV1StudySpecStudyStoppingConfigPtrOutput)
}

// Configuration for ConvexAutomatedStoppingSpec. When there are enough completed trials (configured by min_measurement_count), for pending trials with enough measurements and steps, the policy first computes an overestimate of the objective value at max_num_steps according to the slope of the incomplete objective value curve. No prediction can be made if the curve is completely flat. If the overestimation is worse than the best objective value of the completed trials, this pending trial will be early-stopped, but a last measurement will be added to the pending trial with max_num_steps and predicted objective value from the autoregression model.
type GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpec struct {
	// The hyper-parameter name used in the tuning job that stands for learning rate. Leave it blank if learning rate is not in a parameter in tuning. The learning_rate is used to estimate the objective value of the ongoing trial.
	LearningRateParameterName *string `pulumi:"learningRateParameterName"`
	// Steps used in predicting the final objective for early stopped trials. In general, it's set to be the same as the defined steps in training / tuning. If not defined, it will learn it from the completed trials. When use_steps is false, this field is set to the maximum elapsed seconds.
	MaxStepCount *string `pulumi:"maxStepCount"`
	// The minimal number of measurements in a Trial. Early-stopping checks will not trigger if less than min_measurement_count+1 completed trials or pending trials with less than min_measurement_count measurements. If not defined, the default value is 5.
	MinMeasurementCount *string `pulumi:"minMeasurementCount"`
	// Minimum number of steps for a trial to complete. Trials which do not have a measurement with step_count > min_step_count won't be considered for early stopping. It's ok to set it to 0, and a trial can be early stopped at any stage. By default, min_step_count is set to be one-tenth of the max_step_count. When use_elapsed_duration is true, this field is set to the minimum elapsed seconds.
	MinStepCount *string `pulumi:"minStepCount"`
	// ConvexAutomatedStoppingSpec by default only updates the trials that needs to be early stopped using a newly trained auto-regressive model. When this flag is set to True, all stopped trials from the beginning are potentially updated in terms of their `final_measurement`. Also, note that the training logic of autoregressive models is different in this case. Enabling this option has shown better results and this may be the default option in the future.
	UpdateAllStoppedTrials *bool `pulumi:"updateAllStoppedTrials"`
	// This bool determines whether or not the rule is applied based on elapsed_secs or steps. If use_elapsed_duration==false, the early stopping decision is made according to the predicted objective values according to the target steps. If use_elapsed_duration==true, elapsed_secs is used instead of steps. Also, in this case, the parameters max_num_steps and min_num_steps are overloaded to contain max_elapsed_seconds and min_elapsed_seconds.
	UseElapsedDuration *bool `pulumi:"useElapsedDuration"`
}

// GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecInput is an input type that accepts GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecArgs and GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecInput` via:
//
//	GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecArgs{...}
type GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecOutput() GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecOutput
	ToGoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecOutputWithContext(context.Context) GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecOutput
}

// Configuration for ConvexAutomatedStoppingSpec. When there are enough completed trials (configured by min_measurement_count), for pending trials with enough measurements and steps, the policy first computes an overestimate of the objective value at max_num_steps according to the slope of the incomplete objective value curve. No prediction can be made if the curve is completely flat. If the overestimation is worse than the best objective value of the completed trials, this pending trial will be early-stopped, but a last measurement will be added to the pending trial with max_num_steps and predicted objective value from the autoregression model.
type GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecArgs struct {
	// The hyper-parameter name used in the tuning job that stands for learning rate. Leave it blank if learning rate is not in a parameter in tuning. The learning_rate is used to estimate the objective value of the ongoing trial.
	LearningRateParameterName pulumi.StringPtrInput `pulumi:"learningRateParameterName"`
	// Steps used in predicting the final objective for early stopped trials. In general, it's set to be the same as the defined steps in training / tuning. If not defined, it will learn it from the completed trials. When use_steps is false, this field is set to the maximum elapsed seconds.
	MaxStepCount pulumi.StringPtrInput `pulumi:"maxStepCount"`
	// The minimal number of measurements in a Trial. Early-stopping checks will not trigger if less than min_measurement_count+1 completed trials or pending trials with less than min_measurement_count measurements. If not defined, the default value is 5.
	MinMeasurementCount pulumi.StringPtrInput `pulumi:"minMeasurementCount"`
	// Minimum number of steps for a trial to complete. Trials which do not have a measurement with step_count > min_step_count won't be considered for early stopping. It's ok to set it to 0, and a trial can be early stopped at any stage. By default, min_step_count is set to be one-tenth of the max_step_count. When use_elapsed_duration is true, this field is set to the minimum elapsed seconds.
	MinStepCount pulumi.StringPtrInput `pulumi:"minStepCount"`
	// ConvexAutomatedStoppingSpec by default only updates the trials that needs to be early stopped using a newly trained auto-regressive model. When this flag is set to True, all stopped trials from the beginning are potentially updated in terms of their `final_measurement`. Also, note that the training logic of autoregressive models is different in this case. Enabling this option has shown better results and this may be the default option in the future.
	UpdateAllStoppedTrials pulumi.BoolPtrInput `pulumi:"updateAllStoppedTrials"`
	// This bool determines whether or not the rule is applied based on elapsed_secs or steps. If use_elapsed_duration==false, the early stopping decision is made according to the predicted objective values according to the target steps. If use_elapsed_duration==true, elapsed_secs is used instead of steps. Also, in this case, the parameters max_num_steps and min_num_steps are overloaded to contain max_elapsed_seconds and min_elapsed_seconds.
	UseElapsedDuration pulumi.BoolPtrInput `pulumi:"useElapsedDuration"`
}

func (GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpec)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecArgs) ToGoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecOutput() GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecOutput {
	return i.ToGoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecArgs) ToGoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecOutput)
}

func (i GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecArgs) ToGoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecPtrOutput() GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecPtrOutput {
	return i.ToGoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecArgs) ToGoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecOutput).ToGoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecPtrInput is an input type that accepts GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecArgs, GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecPtr and GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecPtrInput` via:
//
//	        GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecPtrOutput() GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecPtrOutput
	ToGoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecPtrOutput
}

type googleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecPtrType GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecArgs

func GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecPtr(v *GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecArgs) GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecPtrInput {
	return (*googleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecPtrType)(v)
}

func (*googleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpec)(nil)).Elem()
}

func (i *googleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecPtrType) ToGoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecPtrOutput() GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecPtrOutput {
	return i.ToGoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecPtrType) ToGoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecPtrOutput)
}

// Configuration for ConvexAutomatedStoppingSpec. When there are enough completed trials (configured by min_measurement_count), for pending trials with enough measurements and steps, the policy first computes an overestimate of the objective value at max_num_steps according to the slope of the incomplete objective value curve. No prediction can be made if the curve is completely flat. If the overestimation is worse than the best objective value of the completed trials, this pending trial will be early-stopped, but a last measurement will be added to the pending trial with max_num_steps and predicted objective value from the autoregression model.
type GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecOutput) ToGoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecOutput() GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecOutput) ToGoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecOutput) ToGoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecPtrOutput() GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecPtrOutput {
	return o.ToGoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecOutput) ToGoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpec) *GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpec {
		return &v
	}).(GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecPtrOutput)
}

// The hyper-parameter name used in the tuning job that stands for learning rate. Leave it blank if learning rate is not in a parameter in tuning. The learning_rate is used to estimate the objective value of the ongoing trial.
func (o GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecOutput) LearningRateParameterName() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpec) *string {
		return v.LearningRateParameterName
	}).(pulumi.StringPtrOutput)
}

// Steps used in predicting the final objective for early stopped trials. In general, it's set to be the same as the defined steps in training / tuning. If not defined, it will learn it from the completed trials. When use_steps is false, this field is set to the maximum elapsed seconds.
func (o GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecOutput) MaxStepCount() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpec) *string { return v.MaxStepCount }).(pulumi.StringPtrOutput)
}

// The minimal number of measurements in a Trial. Early-stopping checks will not trigger if less than min_measurement_count+1 completed trials or pending trials with less than min_measurement_count measurements. If not defined, the default value is 5.
func (o GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecOutput) MinMeasurementCount() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpec) *string {
		return v.MinMeasurementCount
	}).(pulumi.StringPtrOutput)
}

// Minimum number of steps for a trial to complete. Trials which do not have a measurement with step_count > min_step_count won't be considered for early stopping. It's ok to set it to 0, and a trial can be early stopped at any stage. By default, min_step_count is set to be one-tenth of the max_step_count. When use_elapsed_duration is true, this field is set to the minimum elapsed seconds.
func (o GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecOutput) MinStepCount() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpec) *string { return v.MinStepCount }).(pulumi.StringPtrOutput)
}

// ConvexAutomatedStoppingSpec by default only updates the trials that needs to be early stopped using a newly trained auto-regressive model. When this flag is set to True, all stopped trials from the beginning are potentially updated in terms of their `final_measurement`. Also, note that the training logic of autoregressive models is different in this case. Enabling this option has shown better results and this may be the default option in the future.
func (o GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecOutput) UpdateAllStoppedTrials() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpec) *bool {
		return v.UpdateAllStoppedTrials
	}).(pulumi.BoolPtrOutput)
}

// This bool determines whether or not the rule is applied based on elapsed_secs or steps. If use_elapsed_duration==false, the early stopping decision is made according to the predicted objective values according to the target steps. If use_elapsed_duration==true, elapsed_secs is used instead of steps. Also, in this case, the parameters max_num_steps and min_num_steps are overloaded to contain max_elapsed_seconds and min_elapsed_seconds.
func (o GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecOutput) UseElapsedDuration() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpec) *bool { return v.UseElapsedDuration }).(pulumi.BoolPtrOutput)
}

type GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecPtrOutput) ToGoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecPtrOutput() GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecPtrOutput) ToGoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecPtrOutput) Elem() GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpec) GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpec {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpec
		return ret
	}).(GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecOutput)
}

// The hyper-parameter name used in the tuning job that stands for learning rate. Leave it blank if learning rate is not in a parameter in tuning. The learning_rate is used to estimate the objective value of the ongoing trial.
func (o GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecPtrOutput) LearningRateParameterName() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpec) *string {
		if v == nil {
			return nil
		}
		return v.LearningRateParameterName
	}).(pulumi.StringPtrOutput)
}

// Steps used in predicting the final objective for early stopped trials. In general, it's set to be the same as the defined steps in training / tuning. If not defined, it will learn it from the completed trials. When use_steps is false, this field is set to the maximum elapsed seconds.
func (o GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecPtrOutput) MaxStepCount() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpec) *string {
		if v == nil {
			return nil
		}
		return v.MaxStepCount
	}).(pulumi.StringPtrOutput)
}

// The minimal number of measurements in a Trial. Early-stopping checks will not trigger if less than min_measurement_count+1 completed trials or pending trials with less than min_measurement_count measurements. If not defined, the default value is 5.
func (o GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecPtrOutput) MinMeasurementCount() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpec) *string {
		if v == nil {
			return nil
		}
		return v.MinMeasurementCount
	}).(pulumi.StringPtrOutput)
}

// Minimum number of steps for a trial to complete. Trials which do not have a measurement with step_count > min_step_count won't be considered for early stopping. It's ok to set it to 0, and a trial can be early stopped at any stage. By default, min_step_count is set to be one-tenth of the max_step_count. When use_elapsed_duration is true, this field is set to the minimum elapsed seconds.
func (o GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecPtrOutput) MinStepCount() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpec) *string {
		if v == nil {
			return nil
		}
		return v.MinStepCount
	}).(pulumi.StringPtrOutput)
}

// ConvexAutomatedStoppingSpec by default only updates the trials that needs to be early stopped using a newly trained auto-regressive model. When this flag is set to True, all stopped trials from the beginning are potentially updated in terms of their `final_measurement`. Also, note that the training logic of autoregressive models is different in this case. Enabling this option has shown better results and this may be the default option in the future.
func (o GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecPtrOutput) UpdateAllStoppedTrials() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpec) *bool {
		if v == nil {
			return nil
		}
		return v.UpdateAllStoppedTrials
	}).(pulumi.BoolPtrOutput)
}

// This bool determines whether or not the rule is applied based on elapsed_secs or steps. If use_elapsed_duration==false, the early stopping decision is made according to the predicted objective values according to the target steps. If use_elapsed_duration==true, elapsed_secs is used instead of steps. Also, in this case, the parameters max_num_steps and min_num_steps are overloaded to contain max_elapsed_seconds and min_elapsed_seconds.
func (o GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecPtrOutput) UseElapsedDuration() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpec) *bool {
		if v == nil {
			return nil
		}
		return v.UseElapsedDuration
	}).(pulumi.BoolPtrOutput)
}

// Configuration for ConvexAutomatedStoppingSpec. When there are enough completed trials (configured by min_measurement_count), for pending trials with enough measurements and steps, the policy first computes an overestimate of the objective value at max_num_steps according to the slope of the incomplete objective value curve. No prediction can be made if the curve is completely flat. If the overestimation is worse than the best objective value of the completed trials, this pending trial will be early-stopped, but a last measurement will be added to the pending trial with max_num_steps and predicted objective value from the autoregression model.
type GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecResponse struct {
	// The hyper-parameter name used in the tuning job that stands for learning rate. Leave it blank if learning rate is not in a parameter in tuning. The learning_rate is used to estimate the objective value of the ongoing trial.
	LearningRateParameterName string `pulumi:"learningRateParameterName"`
	// Steps used in predicting the final objective for early stopped trials. In general, it's set to be the same as the defined steps in training / tuning. If not defined, it will learn it from the completed trials. When use_steps is false, this field is set to the maximum elapsed seconds.
	MaxStepCount string `pulumi:"maxStepCount"`
	// The minimal number of measurements in a Trial. Early-stopping checks will not trigger if less than min_measurement_count+1 completed trials or pending trials with less than min_measurement_count measurements. If not defined, the default value is 5.
	MinMeasurementCount string `pulumi:"minMeasurementCount"`
	// Minimum number of steps for a trial to complete. Trials which do not have a measurement with step_count > min_step_count won't be considered for early stopping. It's ok to set it to 0, and a trial can be early stopped at any stage. By default, min_step_count is set to be one-tenth of the max_step_count. When use_elapsed_duration is true, this field is set to the minimum elapsed seconds.
	MinStepCount string `pulumi:"minStepCount"`
	// ConvexAutomatedStoppingSpec by default only updates the trials that needs to be early stopped using a newly trained auto-regressive model. When this flag is set to True, all stopped trials from the beginning are potentially updated in terms of their `final_measurement`. Also, note that the training logic of autoregressive models is different in this case. Enabling this option has shown better results and this may be the default option in the future.
	UpdateAllStoppedTrials bool `pulumi:"updateAllStoppedTrials"`
	// This bool determines whether or not the rule is applied based on elapsed_secs or steps. If use_elapsed_duration==false, the early stopping decision is made according to the predicted objective values according to the target steps. If use_elapsed_duration==true, elapsed_secs is used instead of steps. Also, in this case, the parameters max_num_steps and min_num_steps are overloaded to contain max_elapsed_seconds and min_elapsed_seconds.
	UseElapsedDuration bool `pulumi:"useElapsedDuration"`
}

// Configuration for ConvexAutomatedStoppingSpec. When there are enough completed trials (configured by min_measurement_count), for pending trials with enough measurements and steps, the policy first computes an overestimate of the objective value at max_num_steps according to the slope of the incomplete objective value curve. No prediction can be made if the curve is completely flat. If the overestimation is worse than the best objective value of the completed trials, this pending trial will be early-stopped, but a last measurement will be added to the pending trial with max_num_steps and predicted objective value from the autoregression model.
type GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecResponseOutput) ToGoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecResponseOutput() GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecResponseOutput) ToGoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecResponseOutput {
	return o
}

// The hyper-parameter name used in the tuning job that stands for learning rate. Leave it blank if learning rate is not in a parameter in tuning. The learning_rate is used to estimate the objective value of the ongoing trial.
func (o GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecResponseOutput) LearningRateParameterName() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecResponse) string {
		return v.LearningRateParameterName
	}).(pulumi.StringOutput)
}

// Steps used in predicting the final objective for early stopped trials. In general, it's set to be the same as the defined steps in training / tuning. If not defined, it will learn it from the completed trials. When use_steps is false, this field is set to the maximum elapsed seconds.
func (o GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecResponseOutput) MaxStepCount() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecResponse) string {
		return v.MaxStepCount
	}).(pulumi.StringOutput)
}

// The minimal number of measurements in a Trial. Early-stopping checks will not trigger if less than min_measurement_count+1 completed trials or pending trials with less than min_measurement_count measurements. If not defined, the default value is 5.
func (o GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecResponseOutput) MinMeasurementCount() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecResponse) string {
		return v.MinMeasurementCount
	}).(pulumi.StringOutput)
}

// Minimum number of steps for a trial to complete. Trials which do not have a measurement with step_count > min_step_count won't be considered for early stopping. It's ok to set it to 0, and a trial can be early stopped at any stage. By default, min_step_count is set to be one-tenth of the max_step_count. When use_elapsed_duration is true, this field is set to the minimum elapsed seconds.
func (o GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecResponseOutput) MinStepCount() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecResponse) string {
		return v.MinStepCount
	}).(pulumi.StringOutput)
}

// ConvexAutomatedStoppingSpec by default only updates the trials that needs to be early stopped using a newly trained auto-regressive model. When this flag is set to True, all stopped trials from the beginning are potentially updated in terms of their `final_measurement`. Also, note that the training logic of autoregressive models is different in this case. Enabling this option has shown better results and this may be the default option in the future.
func (o GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecResponseOutput) UpdateAllStoppedTrials() pulumi.BoolOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecResponse) bool {
		return v.UpdateAllStoppedTrials
	}).(pulumi.BoolOutput)
}

// This bool determines whether or not the rule is applied based on elapsed_secs or steps. If use_elapsed_duration==false, the early stopping decision is made according to the predicted objective values according to the target steps. If use_elapsed_duration==true, elapsed_secs is used instead of steps. Also, in this case, the parameters max_num_steps and min_num_steps are overloaded to contain max_elapsed_seconds and min_elapsed_seconds.
func (o GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecResponseOutput) UseElapsedDuration() pulumi.BoolOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecResponse) bool {
		return v.UseElapsedDuration
	}).(pulumi.BoolOutput)
}

// The decay curve automated stopping rule builds a Gaussian Process Regressor to predict the final objective value of a Trial based on the already completed Trials and the intermediate measurements of the current Trial. Early stopping is requested for the current Trial if there is very low probability to exceed the optimal value found so far.
type GoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpec struct {
	// True if Measurement.elapsed_duration is used as the x-axis of each Trials Decay Curve. Otherwise, Measurement.step_count will be used as the x-axis.
	UseElapsedDuration *bool `pulumi:"useElapsedDuration"`
}

// GoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecInput is an input type that accepts GoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecArgs and GoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecInput` via:
//
//	GoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecArgs{...}
type GoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecOutput() GoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecOutput
	ToGoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecOutputWithContext(context.Context) GoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecOutput
}

// The decay curve automated stopping rule builds a Gaussian Process Regressor to predict the final objective value of a Trial based on the already completed Trials and the intermediate measurements of the current Trial. Early stopping is requested for the current Trial if there is very low probability to exceed the optimal value found so far.
type GoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecArgs struct {
	// True if Measurement.elapsed_duration is used as the x-axis of each Trials Decay Curve. Otherwise, Measurement.step_count will be used as the x-axis.
	UseElapsedDuration pulumi.BoolPtrInput `pulumi:"useElapsedDuration"`
}

func (GoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpec)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecArgs) ToGoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecOutput() GoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecOutput {
	return i.ToGoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecArgs) ToGoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecOutput)
}

func (i GoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecArgs) ToGoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecPtrOutput() GoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecPtrOutput {
	return i.ToGoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecArgs) ToGoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecOutput).ToGoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecPtrInput is an input type that accepts GoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecArgs, GoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecPtr and GoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecPtrInput` via:
//
//	        GoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecPtrOutput() GoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecPtrOutput
	ToGoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecPtrOutput
}

type googleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecPtrType GoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecArgs

func GoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecPtr(v *GoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecArgs) GoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecPtrInput {
	return (*googleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecPtrType)(v)
}

func (*googleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpec)(nil)).Elem()
}

func (i *googleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecPtrType) ToGoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecPtrOutput() GoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecPtrOutput {
	return i.ToGoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecPtrType) ToGoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecPtrOutput)
}

// The decay curve automated stopping rule builds a Gaussian Process Regressor to predict the final objective value of a Trial based on the already completed Trials and the intermediate measurements of the current Trial. Early stopping is requested for the current Trial if there is very low probability to exceed the optimal value found so far.
type GoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecOutput) ToGoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecOutput() GoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecOutput) ToGoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecOutput) ToGoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecPtrOutput() GoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecPtrOutput {
	return o.ToGoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecOutput) ToGoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpec) *GoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpec {
		return &v
	}).(GoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecPtrOutput)
}

// True if Measurement.elapsed_duration is used as the x-axis of each Trials Decay Curve. Otherwise, Measurement.step_count will be used as the x-axis.
func (o GoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecOutput) UseElapsedDuration() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpec) *bool {
		return v.UseElapsedDuration
	}).(pulumi.BoolPtrOutput)
}

type GoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecPtrOutput) ToGoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecPtrOutput() GoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecPtrOutput) ToGoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecPtrOutput) Elem() GoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpec) GoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpec {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpec
		return ret
	}).(GoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecOutput)
}

// True if Measurement.elapsed_duration is used as the x-axis of each Trials Decay Curve. Otherwise, Measurement.step_count will be used as the x-axis.
func (o GoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecPtrOutput) UseElapsedDuration() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpec) *bool {
		if v == nil {
			return nil
		}
		return v.UseElapsedDuration
	}).(pulumi.BoolPtrOutput)
}

// The decay curve automated stopping rule builds a Gaussian Process Regressor to predict the final objective value of a Trial based on the already completed Trials and the intermediate measurements of the current Trial. Early stopping is requested for the current Trial if there is very low probability to exceed the optimal value found so far.
type GoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecResponse struct {
	// True if Measurement.elapsed_duration is used as the x-axis of each Trials Decay Curve. Otherwise, Measurement.step_count will be used as the x-axis.
	UseElapsedDuration bool `pulumi:"useElapsedDuration"`
}

// The decay curve automated stopping rule builds a Gaussian Process Regressor to predict the final objective value of a Trial based on the already completed Trials and the intermediate measurements of the current Trial. Early stopping is requested for the current Trial if there is very low probability to exceed the optimal value found so far.
type GoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecResponseOutput) ToGoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecResponseOutput() GoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecResponseOutput) ToGoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecResponseOutput {
	return o
}

// True if Measurement.elapsed_duration is used as the x-axis of each Trials Decay Curve. Otherwise, Measurement.step_count will be used as the x-axis.
func (o GoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecResponseOutput) UseElapsedDuration() pulumi.BoolOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecResponse) bool {
		return v.UseElapsedDuration
	}).(pulumi.BoolOutput)
}

// The median automated stopping rule stops a pending Trial if the Trial's best objective_value is strictly below the median 'performance' of all completed Trials reported up to the Trial's last measurement. Currently, 'performance' refers to the running average of the objective values reported by the Trial in each measurement.
type GoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpec struct {
	// True if median automated stopping rule applies on Measurement.elapsed_duration. It means that elapsed_duration field of latest measurement of current Trial is used to compute median objective value for each completed Trials.
	UseElapsedDuration *bool `pulumi:"useElapsedDuration"`
}

// GoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecInput is an input type that accepts GoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecArgs and GoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecInput` via:
//
//	GoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecArgs{...}
type GoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecOutput() GoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecOutput
	ToGoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecOutputWithContext(context.Context) GoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecOutput
}

// The median automated stopping rule stops a pending Trial if the Trial's best objective_value is strictly below the median 'performance' of all completed Trials reported up to the Trial's last measurement. Currently, 'performance' refers to the running average of the objective values reported by the Trial in each measurement.
type GoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecArgs struct {
	// True if median automated stopping rule applies on Measurement.elapsed_duration. It means that elapsed_duration field of latest measurement of current Trial is used to compute median objective value for each completed Trials.
	UseElapsedDuration pulumi.BoolPtrInput `pulumi:"useElapsedDuration"`
}

func (GoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpec)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecArgs) ToGoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecOutput() GoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecOutput {
	return i.ToGoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecArgs) ToGoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecOutput)
}

func (i GoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecArgs) ToGoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecPtrOutput() GoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecPtrOutput {
	return i.ToGoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecArgs) ToGoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecOutput).ToGoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecPtrInput is an input type that accepts GoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecArgs, GoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecPtr and GoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecPtrInput` via:
//
//	        GoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecPtrOutput() GoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecPtrOutput
	ToGoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecPtrOutput
}

type googleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecPtrType GoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecArgs

func GoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecPtr(v *GoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecArgs) GoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecPtrInput {
	return (*googleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecPtrType)(v)
}

func (*googleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpec)(nil)).Elem()
}

func (i *googleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecPtrType) ToGoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecPtrOutput() GoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecPtrOutput {
	return i.ToGoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecPtrType) ToGoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecPtrOutput)
}

// The median automated stopping rule stops a pending Trial if the Trial's best objective_value is strictly below the median 'performance' of all completed Trials reported up to the Trial's last measurement. Currently, 'performance' refers to the running average of the objective values reported by the Trial in each measurement.
type GoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecOutput) ToGoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecOutput() GoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecOutput) ToGoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecOutput) ToGoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecPtrOutput() GoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecPtrOutput {
	return o.ToGoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecOutput) ToGoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpec) *GoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpec {
		return &v
	}).(GoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecPtrOutput)
}

// True if median automated stopping rule applies on Measurement.elapsed_duration. It means that elapsed_duration field of latest measurement of current Trial is used to compute median objective value for each completed Trials.
func (o GoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecOutput) UseElapsedDuration() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpec) *bool { return v.UseElapsedDuration }).(pulumi.BoolPtrOutput)
}

type GoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecPtrOutput) ToGoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecPtrOutput() GoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecPtrOutput) ToGoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecPtrOutput) Elem() GoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpec) GoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpec {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpec
		return ret
	}).(GoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecOutput)
}

// True if median automated stopping rule applies on Measurement.elapsed_duration. It means that elapsed_duration field of latest measurement of current Trial is used to compute median objective value for each completed Trials.
func (o GoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecPtrOutput) UseElapsedDuration() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpec) *bool {
		if v == nil {
			return nil
		}
		return v.UseElapsedDuration
	}).(pulumi.BoolPtrOutput)
}

// The median automated stopping rule stops a pending Trial if the Trial's best objective_value is strictly below the median 'performance' of all completed Trials reported up to the Trial's last measurement. Currently, 'performance' refers to the running average of the objective values reported by the Trial in each measurement.
type GoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecResponse struct {
	// True if median automated stopping rule applies on Measurement.elapsed_duration. It means that elapsed_duration field of latest measurement of current Trial is used to compute median objective value for each completed Trials.
	UseElapsedDuration bool `pulumi:"useElapsedDuration"`
}

// The median automated stopping rule stops a pending Trial if the Trial's best objective_value is strictly below the median 'performance' of all completed Trials reported up to the Trial's last measurement. Currently, 'performance' refers to the running average of the objective values reported by the Trial in each measurement.
type GoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecResponseOutput) ToGoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecResponseOutput() GoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecResponseOutput) ToGoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecResponseOutput {
	return o
}

// True if median automated stopping rule applies on Measurement.elapsed_duration. It means that elapsed_duration field of latest measurement of current Trial is used to compute median objective value for each completed Trials.
func (o GoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecResponseOutput) UseElapsedDuration() pulumi.BoolOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecResponse) bool {
		return v.UseElapsedDuration
	}).(pulumi.BoolOutput)
}

// Represents a metric to optimize.
type GoogleCloudAiplatformV1StudySpecMetricSpec struct {
	// The optimization goal of the metric.
	Goal GoogleCloudAiplatformV1StudySpecMetricSpecGoal `pulumi:"goal"`
	// The ID of the metric. Must not contain whitespaces and must be unique amongst all MetricSpecs.
	MetricId string `pulumi:"metricId"`
	// Used for safe search. In the case, the metric will be a safety metric. You must provide a separate metric for objective metric.
	SafetyConfig *GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfig `pulumi:"safetyConfig"`
}

// GoogleCloudAiplatformV1StudySpecMetricSpecInput is an input type that accepts GoogleCloudAiplatformV1StudySpecMetricSpecArgs and GoogleCloudAiplatformV1StudySpecMetricSpecOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1StudySpecMetricSpecInput` via:
//
//	GoogleCloudAiplatformV1StudySpecMetricSpecArgs{...}
type GoogleCloudAiplatformV1StudySpecMetricSpecInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1StudySpecMetricSpecOutput() GoogleCloudAiplatformV1StudySpecMetricSpecOutput
	ToGoogleCloudAiplatformV1StudySpecMetricSpecOutputWithContext(context.Context) GoogleCloudAiplatformV1StudySpecMetricSpecOutput
}

// Represents a metric to optimize.
type GoogleCloudAiplatformV1StudySpecMetricSpecArgs struct {
	// The optimization goal of the metric.
	Goal GoogleCloudAiplatformV1StudySpecMetricSpecGoalInput `pulumi:"goal"`
	// The ID of the metric. Must not contain whitespaces and must be unique amongst all MetricSpecs.
	MetricId pulumi.StringInput `pulumi:"metricId"`
	// Used for safe search. In the case, the metric will be a safety metric. You must provide a separate metric for objective metric.
	SafetyConfig GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigPtrInput `pulumi:"safetyConfig"`
}

func (GoogleCloudAiplatformV1StudySpecMetricSpecArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1StudySpecMetricSpec)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1StudySpecMetricSpecArgs) ToGoogleCloudAiplatformV1StudySpecMetricSpecOutput() GoogleCloudAiplatformV1StudySpecMetricSpecOutput {
	return i.ToGoogleCloudAiplatformV1StudySpecMetricSpecOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1StudySpecMetricSpecArgs) ToGoogleCloudAiplatformV1StudySpecMetricSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecMetricSpecOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1StudySpecMetricSpecOutput)
}

// GoogleCloudAiplatformV1StudySpecMetricSpecArrayInput is an input type that accepts GoogleCloudAiplatformV1StudySpecMetricSpecArray and GoogleCloudAiplatformV1StudySpecMetricSpecArrayOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1StudySpecMetricSpecArrayInput` via:
//
//	GoogleCloudAiplatformV1StudySpecMetricSpecArray{ GoogleCloudAiplatformV1StudySpecMetricSpecArgs{...} }
type GoogleCloudAiplatformV1StudySpecMetricSpecArrayInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1StudySpecMetricSpecArrayOutput() GoogleCloudAiplatformV1StudySpecMetricSpecArrayOutput
	ToGoogleCloudAiplatformV1StudySpecMetricSpecArrayOutputWithContext(context.Context) GoogleCloudAiplatformV1StudySpecMetricSpecArrayOutput
}

type GoogleCloudAiplatformV1StudySpecMetricSpecArray []GoogleCloudAiplatformV1StudySpecMetricSpecInput

func (GoogleCloudAiplatformV1StudySpecMetricSpecArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1StudySpecMetricSpec)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1StudySpecMetricSpecArray) ToGoogleCloudAiplatformV1StudySpecMetricSpecArrayOutput() GoogleCloudAiplatformV1StudySpecMetricSpecArrayOutput {
	return i.ToGoogleCloudAiplatformV1StudySpecMetricSpecArrayOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1StudySpecMetricSpecArray) ToGoogleCloudAiplatformV1StudySpecMetricSpecArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecMetricSpecArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1StudySpecMetricSpecArrayOutput)
}

// Represents a metric to optimize.
type GoogleCloudAiplatformV1StudySpecMetricSpecOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1StudySpecMetricSpecOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1StudySpecMetricSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1StudySpecMetricSpecOutput) ToGoogleCloudAiplatformV1StudySpecMetricSpecOutput() GoogleCloudAiplatformV1StudySpecMetricSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1StudySpecMetricSpecOutput) ToGoogleCloudAiplatformV1StudySpecMetricSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecMetricSpecOutput {
	return o
}

// The optimization goal of the metric.
func (o GoogleCloudAiplatformV1StudySpecMetricSpecOutput) Goal() GoogleCloudAiplatformV1StudySpecMetricSpecGoalOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpecMetricSpec) GoogleCloudAiplatformV1StudySpecMetricSpecGoal {
		return v.Goal
	}).(GoogleCloudAiplatformV1StudySpecMetricSpecGoalOutput)
}

// The ID of the metric. Must not contain whitespaces and must be unique amongst all MetricSpecs.
func (o GoogleCloudAiplatformV1StudySpecMetricSpecOutput) MetricId() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpecMetricSpec) string { return v.MetricId }).(pulumi.StringOutput)
}

// Used for safe search. In the case, the metric will be a safety metric. You must provide a separate metric for objective metric.
func (o GoogleCloudAiplatformV1StudySpecMetricSpecOutput) SafetyConfig() GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpecMetricSpec) *GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfig {
		return v.SafetyConfig
	}).(GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigPtrOutput)
}

type GoogleCloudAiplatformV1StudySpecMetricSpecArrayOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1StudySpecMetricSpecArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1StudySpecMetricSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1StudySpecMetricSpecArrayOutput) ToGoogleCloudAiplatformV1StudySpecMetricSpecArrayOutput() GoogleCloudAiplatformV1StudySpecMetricSpecArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1StudySpecMetricSpecArrayOutput) ToGoogleCloudAiplatformV1StudySpecMetricSpecArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecMetricSpecArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1StudySpecMetricSpecArrayOutput) Index(i pulumi.IntInput) GoogleCloudAiplatformV1StudySpecMetricSpecOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GoogleCloudAiplatformV1StudySpecMetricSpec {
		return vs[0].([]GoogleCloudAiplatformV1StudySpecMetricSpec)[vs[1].(int)]
	}).(GoogleCloudAiplatformV1StudySpecMetricSpecOutput)
}

// Represents a metric to optimize.
type GoogleCloudAiplatformV1StudySpecMetricSpecResponse struct {
	// The optimization goal of the metric.
	Goal string `pulumi:"goal"`
	// The ID of the metric. Must not contain whitespaces and must be unique amongst all MetricSpecs.
	MetricId string `pulumi:"metricId"`
	// Used for safe search. In the case, the metric will be a safety metric. You must provide a separate metric for objective metric.
	SafetyConfig GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigResponse `pulumi:"safetyConfig"`
}

// Represents a metric to optimize.
type GoogleCloudAiplatformV1StudySpecMetricSpecResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1StudySpecMetricSpecResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1StudySpecMetricSpecResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1StudySpecMetricSpecResponseOutput) ToGoogleCloudAiplatformV1StudySpecMetricSpecResponseOutput() GoogleCloudAiplatformV1StudySpecMetricSpecResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1StudySpecMetricSpecResponseOutput) ToGoogleCloudAiplatformV1StudySpecMetricSpecResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecMetricSpecResponseOutput {
	return o
}

// The optimization goal of the metric.
func (o GoogleCloudAiplatformV1StudySpecMetricSpecResponseOutput) Goal() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpecMetricSpecResponse) string { return v.Goal }).(pulumi.StringOutput)
}

// The ID of the metric. Must not contain whitespaces and must be unique amongst all MetricSpecs.
func (o GoogleCloudAiplatformV1StudySpecMetricSpecResponseOutput) MetricId() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpecMetricSpecResponse) string { return v.MetricId }).(pulumi.StringOutput)
}

// Used for safe search. In the case, the metric will be a safety metric. You must provide a separate metric for objective metric.
func (o GoogleCloudAiplatformV1StudySpecMetricSpecResponseOutput) SafetyConfig() GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpecMetricSpecResponse) GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigResponse {
		return v.SafetyConfig
	}).(GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigResponseOutput)
}

type GoogleCloudAiplatformV1StudySpecMetricSpecResponseArrayOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1StudySpecMetricSpecResponseArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1StudySpecMetricSpecResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1StudySpecMetricSpecResponseArrayOutput) ToGoogleCloudAiplatformV1StudySpecMetricSpecResponseArrayOutput() GoogleCloudAiplatformV1StudySpecMetricSpecResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1StudySpecMetricSpecResponseArrayOutput) ToGoogleCloudAiplatformV1StudySpecMetricSpecResponseArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecMetricSpecResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1StudySpecMetricSpecResponseArrayOutput) Index(i pulumi.IntInput) GoogleCloudAiplatformV1StudySpecMetricSpecResponseOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GoogleCloudAiplatformV1StudySpecMetricSpecResponse {
		return vs[0].([]GoogleCloudAiplatformV1StudySpecMetricSpecResponse)[vs[1].(int)]
	}).(GoogleCloudAiplatformV1StudySpecMetricSpecResponseOutput)
}

// Used in safe optimization to specify threshold levels and risk tolerance.
type GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfig struct {
	// Desired minimum fraction of safe trials (over total number of trials) that should be targeted by the algorithm at any time during the study (best effort). This should be between 0.0 and 1.0 and a value of 0.0 means that there is no minimum and an algorithm proceeds without targeting any specific fraction. A value of 1.0 means that the algorithm attempts to only Suggest safe Trials.
	DesiredMinSafeTrialsFraction *float64 `pulumi:"desiredMinSafeTrialsFraction"`
	// Safety threshold (boundary value between safe and unsafe). NOTE that if you leave SafetyMetricConfig unset, a default value of 0 will be used.
	SafetyThreshold *float64 `pulumi:"safetyThreshold"`
}

// GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigInput is an input type that accepts GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigArgs and GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigInput` via:
//
//	GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigArgs{...}
type GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigOutput() GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigOutput
	ToGoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigOutputWithContext(context.Context) GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigOutput
}

// Used in safe optimization to specify threshold levels and risk tolerance.
type GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigArgs struct {
	// Desired minimum fraction of safe trials (over total number of trials) that should be targeted by the algorithm at any time during the study (best effort). This should be between 0.0 and 1.0 and a value of 0.0 means that there is no minimum and an algorithm proceeds without targeting any specific fraction. A value of 1.0 means that the algorithm attempts to only Suggest safe Trials.
	DesiredMinSafeTrialsFraction pulumi.Float64PtrInput `pulumi:"desiredMinSafeTrialsFraction"`
	// Safety threshold (boundary value between safe and unsafe). NOTE that if you leave SafetyMetricConfig unset, a default value of 0 will be used.
	SafetyThreshold pulumi.Float64PtrInput `pulumi:"safetyThreshold"`
}

func (GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfig)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigArgs) ToGoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigOutput() GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigOutput {
	return i.ToGoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigArgs) ToGoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigOutput)
}

func (i GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigArgs) ToGoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigPtrOutput() GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigArgs) ToGoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigOutput).ToGoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigPtrInput is an input type that accepts GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigArgs, GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigPtr and GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigPtrInput` via:
//
//	        GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigPtrOutput() GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigPtrOutput
	ToGoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigPtrOutput
}

type googleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigPtrType GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigArgs

func GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigPtr(v *GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigArgs) GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigPtrInput {
	return (*googleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigPtrType)(v)
}

func (*googleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfig)(nil)).Elem()
}

func (i *googleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigPtrType) ToGoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigPtrOutput() GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigPtrType) ToGoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigPtrOutput)
}

// Used in safe optimization to specify threshold levels and risk tolerance.
type GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigOutput) ToGoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigOutput() GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigOutput) ToGoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigOutput) ToGoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigPtrOutput() GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigPtrOutput {
	return o.ToGoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigOutput) ToGoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfig) *GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfig {
		return &v
	}).(GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigPtrOutput)
}

// Desired minimum fraction of safe trials (over total number of trials) that should be targeted by the algorithm at any time during the study (best effort). This should be between 0.0 and 1.0 and a value of 0.0 means that there is no minimum and an algorithm proceeds without targeting any specific fraction. A value of 1.0 means that the algorithm attempts to only Suggest safe Trials.
func (o GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigOutput) DesiredMinSafeTrialsFraction() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfig) *float64 {
		return v.DesiredMinSafeTrialsFraction
	}).(pulumi.Float64PtrOutput)
}

// Safety threshold (boundary value between safe and unsafe). NOTE that if you leave SafetyMetricConfig unset, a default value of 0 will be used.
func (o GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigOutput) SafetyThreshold() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfig) *float64 {
		return v.SafetyThreshold
	}).(pulumi.Float64PtrOutput)
}

type GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigPtrOutput) ToGoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigPtrOutput() GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigPtrOutput) ToGoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigPtrOutput) Elem() GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfig) GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfig {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfig
		return ret
	}).(GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigOutput)
}

// Desired minimum fraction of safe trials (over total number of trials) that should be targeted by the algorithm at any time during the study (best effort). This should be between 0.0 and 1.0 and a value of 0.0 means that there is no minimum and an algorithm proceeds without targeting any specific fraction. A value of 1.0 means that the algorithm attempts to only Suggest safe Trials.
func (o GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigPtrOutput) DesiredMinSafeTrialsFraction() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfig) *float64 {
		if v == nil {
			return nil
		}
		return v.DesiredMinSafeTrialsFraction
	}).(pulumi.Float64PtrOutput)
}

// Safety threshold (boundary value between safe and unsafe). NOTE that if you leave SafetyMetricConfig unset, a default value of 0 will be used.
func (o GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigPtrOutput) SafetyThreshold() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfig) *float64 {
		if v == nil {
			return nil
		}
		return v.SafetyThreshold
	}).(pulumi.Float64PtrOutput)
}

// Used in safe optimization to specify threshold levels and risk tolerance.
type GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigResponse struct {
	// Desired minimum fraction of safe trials (over total number of trials) that should be targeted by the algorithm at any time during the study (best effort). This should be between 0.0 and 1.0 and a value of 0.0 means that there is no minimum and an algorithm proceeds without targeting any specific fraction. A value of 1.0 means that the algorithm attempts to only Suggest safe Trials.
	DesiredMinSafeTrialsFraction float64 `pulumi:"desiredMinSafeTrialsFraction"`
	// Safety threshold (boundary value between safe and unsafe). NOTE that if you leave SafetyMetricConfig unset, a default value of 0 will be used.
	SafetyThreshold float64 `pulumi:"safetyThreshold"`
}

// Used in safe optimization to specify threshold levels and risk tolerance.
type GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigResponseOutput) ToGoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigResponseOutput() GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigResponseOutput) ToGoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigResponseOutput {
	return o
}

// Desired minimum fraction of safe trials (over total number of trials) that should be targeted by the algorithm at any time during the study (best effort). This should be between 0.0 and 1.0 and a value of 0.0 means that there is no minimum and an algorithm proceeds without targeting any specific fraction. A value of 1.0 means that the algorithm attempts to only Suggest safe Trials.
func (o GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigResponseOutput) DesiredMinSafeTrialsFraction() pulumi.Float64Output {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigResponse) float64 {
		return v.DesiredMinSafeTrialsFraction
	}).(pulumi.Float64Output)
}

// Safety threshold (boundary value between safe and unsafe). NOTE that if you leave SafetyMetricConfig unset, a default value of 0 will be used.
func (o GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigResponseOutput) SafetyThreshold() pulumi.Float64Output {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigResponse) float64 {
		return v.SafetyThreshold
	}).(pulumi.Float64Output)
}

// Represents a single parameter to optimize.
type GoogleCloudAiplatformV1StudySpecParameterSpec struct {
	// The value spec for a 'CATEGORICAL' parameter.
	CategoricalValueSpec *GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpec `pulumi:"categoricalValueSpec"`
	// A conditional parameter node is active if the parameter's value matches the conditional node's parent_value_condition. If two items in conditional_parameter_specs have the same name, they must have disjoint parent_value_condition.
	ConditionalParameterSpecs []GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpec `pulumi:"conditionalParameterSpecs"`
	// The value spec for a 'DISCRETE' parameter.
	DiscreteValueSpec *GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpec `pulumi:"discreteValueSpec"`
	// The value spec for a 'DOUBLE' parameter.
	DoubleValueSpec *GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpec `pulumi:"doubleValueSpec"`
	// The value spec for an 'INTEGER' parameter.
	IntegerValueSpec *GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpec `pulumi:"integerValueSpec"`
	// The ID of the parameter. Must not contain whitespaces and must be unique amongst all ParameterSpecs.
	ParameterId string `pulumi:"parameterId"`
	// How the parameter should be scaled. Leave unset for `CATEGORICAL` parameters.
	ScaleType *GoogleCloudAiplatformV1StudySpecParameterSpecScaleType `pulumi:"scaleType"`
}

// GoogleCloudAiplatformV1StudySpecParameterSpecInput is an input type that accepts GoogleCloudAiplatformV1StudySpecParameterSpecArgs and GoogleCloudAiplatformV1StudySpecParameterSpecOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1StudySpecParameterSpecInput` via:
//
//	GoogleCloudAiplatformV1StudySpecParameterSpecArgs{...}
type GoogleCloudAiplatformV1StudySpecParameterSpecInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1StudySpecParameterSpecOutput() GoogleCloudAiplatformV1StudySpecParameterSpecOutput
	ToGoogleCloudAiplatformV1StudySpecParameterSpecOutputWithContext(context.Context) GoogleCloudAiplatformV1StudySpecParameterSpecOutput
}

// Represents a single parameter to optimize.
type GoogleCloudAiplatformV1StudySpecParameterSpecArgs struct {
	// The value spec for a 'CATEGORICAL' parameter.
	CategoricalValueSpec GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecPtrInput `pulumi:"categoricalValueSpec"`
	// A conditional parameter node is active if the parameter's value matches the conditional node's parent_value_condition. If two items in conditional_parameter_specs have the same name, they must have disjoint parent_value_condition.
	ConditionalParameterSpecs GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecArrayInput `pulumi:"conditionalParameterSpecs"`
	// The value spec for a 'DISCRETE' parameter.
	DiscreteValueSpec GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecPtrInput `pulumi:"discreteValueSpec"`
	// The value spec for a 'DOUBLE' parameter.
	DoubleValueSpec GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecPtrInput `pulumi:"doubleValueSpec"`
	// The value spec for an 'INTEGER' parameter.
	IntegerValueSpec GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecPtrInput `pulumi:"integerValueSpec"`
	// The ID of the parameter. Must not contain whitespaces and must be unique amongst all ParameterSpecs.
	ParameterId pulumi.StringInput `pulumi:"parameterId"`
	// How the parameter should be scaled. Leave unset for `CATEGORICAL` parameters.
	ScaleType GoogleCloudAiplatformV1StudySpecParameterSpecScaleTypePtrInput `pulumi:"scaleType"`
}

func (GoogleCloudAiplatformV1StudySpecParameterSpecArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1StudySpecParameterSpec)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1StudySpecParameterSpecArgs) ToGoogleCloudAiplatformV1StudySpecParameterSpecOutput() GoogleCloudAiplatformV1StudySpecParameterSpecOutput {
	return i.ToGoogleCloudAiplatformV1StudySpecParameterSpecOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1StudySpecParameterSpecArgs) ToGoogleCloudAiplatformV1StudySpecParameterSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecParameterSpecOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1StudySpecParameterSpecOutput)
}

// GoogleCloudAiplatformV1StudySpecParameterSpecArrayInput is an input type that accepts GoogleCloudAiplatformV1StudySpecParameterSpecArray and GoogleCloudAiplatformV1StudySpecParameterSpecArrayOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1StudySpecParameterSpecArrayInput` via:
//
//	GoogleCloudAiplatformV1StudySpecParameterSpecArray{ GoogleCloudAiplatformV1StudySpecParameterSpecArgs{...} }
type GoogleCloudAiplatformV1StudySpecParameterSpecArrayInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1StudySpecParameterSpecArrayOutput() GoogleCloudAiplatformV1StudySpecParameterSpecArrayOutput
	ToGoogleCloudAiplatformV1StudySpecParameterSpecArrayOutputWithContext(context.Context) GoogleCloudAiplatformV1StudySpecParameterSpecArrayOutput
}

type GoogleCloudAiplatformV1StudySpecParameterSpecArray []GoogleCloudAiplatformV1StudySpecParameterSpecInput

func (GoogleCloudAiplatformV1StudySpecParameterSpecArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1StudySpecParameterSpec)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1StudySpecParameterSpecArray) ToGoogleCloudAiplatformV1StudySpecParameterSpecArrayOutput() GoogleCloudAiplatformV1StudySpecParameterSpecArrayOutput {
	return i.ToGoogleCloudAiplatformV1StudySpecParameterSpecArrayOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1StudySpecParameterSpecArray) ToGoogleCloudAiplatformV1StudySpecParameterSpecArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecParameterSpecArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1StudySpecParameterSpecArrayOutput)
}

// Represents a single parameter to optimize.
type GoogleCloudAiplatformV1StudySpecParameterSpecOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1StudySpecParameterSpecOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1StudySpecParameterSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1StudySpecParameterSpecOutput) ToGoogleCloudAiplatformV1StudySpecParameterSpecOutput() GoogleCloudAiplatformV1StudySpecParameterSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1StudySpecParameterSpecOutput) ToGoogleCloudAiplatformV1StudySpecParameterSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecParameterSpecOutput {
	return o
}

// The value spec for a 'CATEGORICAL' parameter.
func (o GoogleCloudAiplatformV1StudySpecParameterSpecOutput) CategoricalValueSpec() GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpecParameterSpec) *GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpec {
		return v.CategoricalValueSpec
	}).(GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecPtrOutput)
}

// A conditional parameter node is active if the parameter's value matches the conditional node's parent_value_condition. If two items in conditional_parameter_specs have the same name, they must have disjoint parent_value_condition.
func (o GoogleCloudAiplatformV1StudySpecParameterSpecOutput) ConditionalParameterSpecs() GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpecParameterSpec) []GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpec {
		return v.ConditionalParameterSpecs
	}).(GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecArrayOutput)
}

// The value spec for a 'DISCRETE' parameter.
func (o GoogleCloudAiplatformV1StudySpecParameterSpecOutput) DiscreteValueSpec() GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpecParameterSpec) *GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpec {
		return v.DiscreteValueSpec
	}).(GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecPtrOutput)
}

// The value spec for a 'DOUBLE' parameter.
func (o GoogleCloudAiplatformV1StudySpecParameterSpecOutput) DoubleValueSpec() GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpecParameterSpec) *GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpec {
		return v.DoubleValueSpec
	}).(GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecPtrOutput)
}

// The value spec for an 'INTEGER' parameter.
func (o GoogleCloudAiplatformV1StudySpecParameterSpecOutput) IntegerValueSpec() GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpecParameterSpec) *GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpec {
		return v.IntegerValueSpec
	}).(GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecPtrOutput)
}

// The ID of the parameter. Must not contain whitespaces and must be unique amongst all ParameterSpecs.
func (o GoogleCloudAiplatformV1StudySpecParameterSpecOutput) ParameterId() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpecParameterSpec) string { return v.ParameterId }).(pulumi.StringOutput)
}

// How the parameter should be scaled. Leave unset for `CATEGORICAL` parameters.
func (o GoogleCloudAiplatformV1StudySpecParameterSpecOutput) ScaleType() GoogleCloudAiplatformV1StudySpecParameterSpecScaleTypePtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpecParameterSpec) *GoogleCloudAiplatformV1StudySpecParameterSpecScaleType {
		return v.ScaleType
	}).(GoogleCloudAiplatformV1StudySpecParameterSpecScaleTypePtrOutput)
}

type GoogleCloudAiplatformV1StudySpecParameterSpecArrayOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1StudySpecParameterSpecArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1StudySpecParameterSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1StudySpecParameterSpecArrayOutput) ToGoogleCloudAiplatformV1StudySpecParameterSpecArrayOutput() GoogleCloudAiplatformV1StudySpecParameterSpecArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1StudySpecParameterSpecArrayOutput) ToGoogleCloudAiplatformV1StudySpecParameterSpecArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecParameterSpecArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1StudySpecParameterSpecArrayOutput) Index(i pulumi.IntInput) GoogleCloudAiplatformV1StudySpecParameterSpecOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GoogleCloudAiplatformV1StudySpecParameterSpec {
		return vs[0].([]GoogleCloudAiplatformV1StudySpecParameterSpec)[vs[1].(int)]
	}).(GoogleCloudAiplatformV1StudySpecParameterSpecOutput)
}

// Value specification for a parameter in `CATEGORICAL` type.
type GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpec struct {
	// A default value for a `CATEGORICAL` parameter that is assumed to be a relatively good starting point. Unset value signals that there is no offered starting point. Currently only supported by the Vertex AI Vizier service. Not supported by HyperparameterTuningJob or TrainingPipeline.
	DefaultValue *string `pulumi:"defaultValue"`
	// The list of possible categories.
	Values []string `pulumi:"values"`
}

// GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecInput is an input type that accepts GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecArgs and GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecInput` via:
//
//	GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecArgs{...}
type GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecOutput() GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecOutput
	ToGoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecOutputWithContext(context.Context) GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecOutput
}

// Value specification for a parameter in `CATEGORICAL` type.
type GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecArgs struct {
	// A default value for a `CATEGORICAL` parameter that is assumed to be a relatively good starting point. Unset value signals that there is no offered starting point. Currently only supported by the Vertex AI Vizier service. Not supported by HyperparameterTuningJob or TrainingPipeline.
	DefaultValue pulumi.StringPtrInput `pulumi:"defaultValue"`
	// The list of possible categories.
	Values pulumi.StringArrayInput `pulumi:"values"`
}

func (GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpec)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecArgs) ToGoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecOutput() GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecOutput {
	return i.ToGoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecArgs) ToGoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecOutput)
}

func (i GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecArgs) ToGoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecPtrOutput() GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecPtrOutput {
	return i.ToGoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecArgs) ToGoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecOutput).ToGoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecPtrInput is an input type that accepts GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecArgs, GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecPtr and GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecPtrInput` via:
//
//	        GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecPtrOutput() GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecPtrOutput
	ToGoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecPtrOutput
}

type googleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecPtrType GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecArgs

func GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecPtr(v *GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecArgs) GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecPtrInput {
	return (*googleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecPtrType)(v)
}

func (*googleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpec)(nil)).Elem()
}

func (i *googleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecPtrType) ToGoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecPtrOutput() GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecPtrOutput {
	return i.ToGoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecPtrType) ToGoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecPtrOutput)
}

// Value specification for a parameter in `CATEGORICAL` type.
type GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecOutput) ToGoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecOutput() GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecOutput) ToGoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecOutput) ToGoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecPtrOutput() GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecPtrOutput {
	return o.ToGoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecOutput) ToGoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpec) *GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpec {
		return &v
	}).(GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecPtrOutput)
}

// A default value for a `CATEGORICAL` parameter that is assumed to be a relatively good starting point. Unset value signals that there is no offered starting point. Currently only supported by the Vertex AI Vizier service. Not supported by HyperparameterTuningJob or TrainingPipeline.
func (o GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecOutput) DefaultValue() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpec) *string {
		return v.DefaultValue
	}).(pulumi.StringPtrOutput)
}

// The list of possible categories.
func (o GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecOutput) Values() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpec) []string { return v.Values }).(pulumi.StringArrayOutput)
}

type GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecPtrOutput) ToGoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecPtrOutput() GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecPtrOutput) ToGoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecPtrOutput) Elem() GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpec) GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpec {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpec
		return ret
	}).(GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecOutput)
}

// A default value for a `CATEGORICAL` parameter that is assumed to be a relatively good starting point. Unset value signals that there is no offered starting point. Currently only supported by the Vertex AI Vizier service. Not supported by HyperparameterTuningJob or TrainingPipeline.
func (o GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecPtrOutput) DefaultValue() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpec) *string {
		if v == nil {
			return nil
		}
		return v.DefaultValue
	}).(pulumi.StringPtrOutput)
}

// The list of possible categories.
func (o GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecPtrOutput) Values() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpec) []string {
		if v == nil {
			return nil
		}
		return v.Values
	}).(pulumi.StringArrayOutput)
}

// Value specification for a parameter in `CATEGORICAL` type.
type GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecResponse struct {
	// A default value for a `CATEGORICAL` parameter that is assumed to be a relatively good starting point. Unset value signals that there is no offered starting point. Currently only supported by the Vertex AI Vizier service. Not supported by HyperparameterTuningJob or TrainingPipeline.
	DefaultValue string `pulumi:"defaultValue"`
	// The list of possible categories.
	Values []string `pulumi:"values"`
}

// Value specification for a parameter in `CATEGORICAL` type.
type GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecResponseOutput) ToGoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecResponseOutput() GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecResponseOutput) ToGoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecResponseOutput {
	return o
}

// A default value for a `CATEGORICAL` parameter that is assumed to be a relatively good starting point. Unset value signals that there is no offered starting point. Currently only supported by the Vertex AI Vizier service. Not supported by HyperparameterTuningJob or TrainingPipeline.
func (o GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecResponseOutput) DefaultValue() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecResponse) string {
		return v.DefaultValue
	}).(pulumi.StringOutput)
}

// The list of possible categories.
func (o GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecResponseOutput) Values() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecResponse) []string {
		return v.Values
	}).(pulumi.StringArrayOutput)
}

// Represents a parameter spec with condition from its parent parameter.
type GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpec struct {
	// The spec for a conditional parameter.
	ParameterSpec GoogleCloudAiplatformV1StudySpecParameterSpec `pulumi:"parameterSpec"`
	// The spec for matching values from a parent parameter of `CATEGORICAL` type.
	ParentCategoricalValues *GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueCondition `pulumi:"parentCategoricalValues"`
	// The spec for matching values from a parent parameter of `DISCRETE` type.
	ParentDiscreteValues *GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueCondition `pulumi:"parentDiscreteValues"`
	// The spec for matching values from a parent parameter of `INTEGER` type.
	ParentIntValues *GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueCondition `pulumi:"parentIntValues"`
}

// GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecInput is an input type that accepts GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecArgs and GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecInput` via:
//
//	GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecArgs{...}
type GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecOutput() GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecOutput
	ToGoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecOutputWithContext(context.Context) GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecOutput
}

// Represents a parameter spec with condition from its parent parameter.
type GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecArgs struct {
	// The spec for a conditional parameter.
	ParameterSpec GoogleCloudAiplatformV1StudySpecParameterSpecInput `pulumi:"parameterSpec"`
	// The spec for matching values from a parent parameter of `CATEGORICAL` type.
	ParentCategoricalValues GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionPtrInput `pulumi:"parentCategoricalValues"`
	// The spec for matching values from a parent parameter of `DISCRETE` type.
	ParentDiscreteValues GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionPtrInput `pulumi:"parentDiscreteValues"`
	// The spec for matching values from a parent parameter of `INTEGER` type.
	ParentIntValues GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionPtrInput `pulumi:"parentIntValues"`
}

func (GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpec)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecArgs) ToGoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecOutput() GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecOutput {
	return i.ToGoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecArgs) ToGoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecOutput)
}

// GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecArrayInput is an input type that accepts GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecArray and GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecArrayOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecArrayInput` via:
//
//	GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecArray{ GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecArgs{...} }
type GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecArrayInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecArrayOutput() GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecArrayOutput
	ToGoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecArrayOutputWithContext(context.Context) GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecArrayOutput
}

type GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecArray []GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecInput

func (GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpec)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecArray) ToGoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecArrayOutput() GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecArrayOutput {
	return i.ToGoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecArrayOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecArray) ToGoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecArrayOutput)
}

// Represents a parameter spec with condition from its parent parameter.
type GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecOutput) ToGoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecOutput() GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecOutput) ToGoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecOutput {
	return o
}

// The spec for a conditional parameter.
func (o GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecOutput) ParameterSpec() GoogleCloudAiplatformV1StudySpecParameterSpecOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpec) GoogleCloudAiplatformV1StudySpecParameterSpec {
		return v.ParameterSpec
	}).(GoogleCloudAiplatformV1StudySpecParameterSpecOutput)
}

// The spec for matching values from a parent parameter of `CATEGORICAL` type.
func (o GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecOutput) ParentCategoricalValues() GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpec) *GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueCondition {
		return v.ParentCategoricalValues
	}).(GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionPtrOutput)
}

// The spec for matching values from a parent parameter of `DISCRETE` type.
func (o GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecOutput) ParentDiscreteValues() GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpec) *GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueCondition {
		return v.ParentDiscreteValues
	}).(GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionPtrOutput)
}

// The spec for matching values from a parent parameter of `INTEGER` type.
func (o GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecOutput) ParentIntValues() GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpec) *GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueCondition {
		return v.ParentIntValues
	}).(GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionPtrOutput)
}

type GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecArrayOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecArrayOutput) ToGoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecArrayOutput() GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecArrayOutput) ToGoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecArrayOutput) Index(i pulumi.IntInput) GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpec {
		return vs[0].([]GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpec)[vs[1].(int)]
	}).(GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecOutput)
}

// Represents the spec to match categorical values from parent parameter.
type GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueCondition struct {
	// Matches values of the parent parameter of 'CATEGORICAL' type. All values must exist in `categorical_value_spec` of parent parameter.
	Values []string `pulumi:"values"`
}

// GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionInput is an input type that accepts GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionArgs and GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionInput` via:
//
//	GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionArgs{...}
type GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionOutput() GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionOutput
	ToGoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionOutputWithContext(context.Context) GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionOutput
}

// Represents the spec to match categorical values from parent parameter.
type GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionArgs struct {
	// Matches values of the parent parameter of 'CATEGORICAL' type. All values must exist in `categorical_value_spec` of parent parameter.
	Values pulumi.StringArrayInput `pulumi:"values"`
}

func (GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueCondition)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionArgs) ToGoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionOutput() GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionOutput {
	return i.ToGoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionArgs) ToGoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionOutput)
}

func (i GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionArgs) ToGoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionPtrOutput() GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionPtrOutput {
	return i.ToGoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionArgs) ToGoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionOutput).ToGoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionPtrInput is an input type that accepts GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionArgs, GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionPtr and GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionPtrInput` via:
//
//	        GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionPtrOutput() GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionPtrOutput
	ToGoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionPtrOutput
}

type googleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionPtrType GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionArgs

func GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionPtr(v *GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionArgs) GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionPtrInput {
	return (*googleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionPtrType)(v)
}

func (*googleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueCondition)(nil)).Elem()
}

func (i *googleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionPtrType) ToGoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionPtrOutput() GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionPtrOutput {
	return i.ToGoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionPtrType) ToGoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionPtrOutput)
}

// Represents the spec to match categorical values from parent parameter.
type GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueCondition)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionOutput) ToGoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionOutput() GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionOutput {
	return o
}

func (o GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionOutput) ToGoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionOutput {
	return o
}

func (o GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionOutput) ToGoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionPtrOutput() GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionPtrOutput {
	return o.ToGoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionOutput) ToGoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueCondition) *GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueCondition {
		return &v
	}).(GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionPtrOutput)
}

// Matches values of the parent parameter of 'CATEGORICAL' type. All values must exist in `categorical_value_spec` of parent parameter.
func (o GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionOutput) Values() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueCondition) []string {
		return v.Values
	}).(pulumi.StringArrayOutput)
}

type GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueCondition)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionPtrOutput) ToGoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionPtrOutput() GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionPtrOutput) ToGoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionPtrOutput) Elem() GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueCondition) GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueCondition {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueCondition
		return ret
	}).(GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionOutput)
}

// Matches values of the parent parameter of 'CATEGORICAL' type. All values must exist in `categorical_value_spec` of parent parameter.
func (o GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionPtrOutput) Values() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueCondition) []string {
		if v == nil {
			return nil
		}
		return v.Values
	}).(pulumi.StringArrayOutput)
}

// Represents the spec to match categorical values from parent parameter.
type GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionResponse struct {
	// Matches values of the parent parameter of 'CATEGORICAL' type. All values must exist in `categorical_value_spec` of parent parameter.
	Values []string `pulumi:"values"`
}

// Represents the spec to match categorical values from parent parameter.
type GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionResponseOutput) ToGoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionResponseOutput() GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionResponseOutput) ToGoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionResponseOutput {
	return o
}

// Matches values of the parent parameter of 'CATEGORICAL' type. All values must exist in `categorical_value_spec` of parent parameter.
func (o GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionResponseOutput) Values() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionResponse) []string {
		return v.Values
	}).(pulumi.StringArrayOutput)
}

// Represents the spec to match discrete values from parent parameter.
type GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueCondition struct {
	// Matches values of the parent parameter of 'DISCRETE' type. All values must exist in `discrete_value_spec` of parent parameter. The Epsilon of the value matching is 1e-10.
	Values []float64 `pulumi:"values"`
}

// GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionInput is an input type that accepts GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionArgs and GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionInput` via:
//
//	GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionArgs{...}
type GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionOutput() GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionOutput
	ToGoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionOutputWithContext(context.Context) GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionOutput
}

// Represents the spec to match discrete values from parent parameter.
type GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionArgs struct {
	// Matches values of the parent parameter of 'DISCRETE' type. All values must exist in `discrete_value_spec` of parent parameter. The Epsilon of the value matching is 1e-10.
	Values pulumi.Float64ArrayInput `pulumi:"values"`
}

func (GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueCondition)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionArgs) ToGoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionOutput() GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionOutput {
	return i.ToGoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionArgs) ToGoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionOutput)
}

func (i GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionArgs) ToGoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionPtrOutput() GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionPtrOutput {
	return i.ToGoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionArgs) ToGoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionOutput).ToGoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionPtrInput is an input type that accepts GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionArgs, GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionPtr and GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionPtrInput` via:
//
//	        GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionPtrOutput() GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionPtrOutput
	ToGoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionPtrOutput
}

type googleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionPtrType GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionArgs

func GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionPtr(v *GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionArgs) GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionPtrInput {
	return (*googleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionPtrType)(v)
}

func (*googleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueCondition)(nil)).Elem()
}

func (i *googleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionPtrType) ToGoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionPtrOutput() GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionPtrOutput {
	return i.ToGoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionPtrType) ToGoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionPtrOutput)
}

// Represents the spec to match discrete values from parent parameter.
type GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueCondition)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionOutput) ToGoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionOutput() GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionOutput {
	return o
}

func (o GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionOutput) ToGoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionOutput {
	return o
}

func (o GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionOutput) ToGoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionPtrOutput() GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionPtrOutput {
	return o.ToGoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionOutput) ToGoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueCondition) *GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueCondition {
		return &v
	}).(GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionPtrOutput)
}

// Matches values of the parent parameter of 'DISCRETE' type. All values must exist in `discrete_value_spec` of parent parameter. The Epsilon of the value matching is 1e-10.
func (o GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionOutput) Values() pulumi.Float64ArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueCondition) []float64 {
		return v.Values
	}).(pulumi.Float64ArrayOutput)
}

type GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueCondition)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionPtrOutput) ToGoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionPtrOutput() GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionPtrOutput) ToGoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionPtrOutput) Elem() GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueCondition) GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueCondition {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueCondition
		return ret
	}).(GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionOutput)
}

// Matches values of the parent parameter of 'DISCRETE' type. All values must exist in `discrete_value_spec` of parent parameter. The Epsilon of the value matching is 1e-10.
func (o GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionPtrOutput) Values() pulumi.Float64ArrayOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueCondition) []float64 {
		if v == nil {
			return nil
		}
		return v.Values
	}).(pulumi.Float64ArrayOutput)
}

// Represents the spec to match discrete values from parent parameter.
type GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionResponse struct {
	// Matches values of the parent parameter of 'DISCRETE' type. All values must exist in `discrete_value_spec` of parent parameter. The Epsilon of the value matching is 1e-10.
	Values []float64 `pulumi:"values"`
}

// Represents the spec to match discrete values from parent parameter.
type GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionResponseOutput) ToGoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionResponseOutput() GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionResponseOutput) ToGoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionResponseOutput {
	return o
}

// Matches values of the parent parameter of 'DISCRETE' type. All values must exist in `discrete_value_spec` of parent parameter. The Epsilon of the value matching is 1e-10.
func (o GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionResponseOutput) Values() pulumi.Float64ArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionResponse) []float64 {
		return v.Values
	}).(pulumi.Float64ArrayOutput)
}

// Represents the spec to match integer values from parent parameter.
type GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueCondition struct {
	// Matches values of the parent parameter of 'INTEGER' type. All values must lie in `integer_value_spec` of parent parameter.
	Values []string `pulumi:"values"`
}

// GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionInput is an input type that accepts GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionArgs and GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionInput` via:
//
//	GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionArgs{...}
type GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionOutput() GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionOutput
	ToGoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionOutputWithContext(context.Context) GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionOutput
}

// Represents the spec to match integer values from parent parameter.
type GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionArgs struct {
	// Matches values of the parent parameter of 'INTEGER' type. All values must lie in `integer_value_spec` of parent parameter.
	Values pulumi.StringArrayInput `pulumi:"values"`
}

func (GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueCondition)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionArgs) ToGoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionOutput() GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionOutput {
	return i.ToGoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionArgs) ToGoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionOutput)
}

func (i GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionArgs) ToGoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionPtrOutput() GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionPtrOutput {
	return i.ToGoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionArgs) ToGoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionOutput).ToGoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionPtrInput is an input type that accepts GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionArgs, GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionPtr and GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionPtrInput` via:
//
//	        GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionPtrOutput() GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionPtrOutput
	ToGoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionPtrOutput
}

type googleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionPtrType GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionArgs

func GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionPtr(v *GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionArgs) GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionPtrInput {
	return (*googleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionPtrType)(v)
}

func (*googleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueCondition)(nil)).Elem()
}

func (i *googleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionPtrType) ToGoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionPtrOutput() GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionPtrOutput {
	return i.ToGoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionPtrType) ToGoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionPtrOutput)
}

// Represents the spec to match integer values from parent parameter.
type GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueCondition)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionOutput) ToGoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionOutput() GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionOutput {
	return o
}

func (o GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionOutput) ToGoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionOutput {
	return o
}

func (o GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionOutput) ToGoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionPtrOutput() GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionPtrOutput {
	return o.ToGoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionOutput) ToGoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueCondition) *GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueCondition {
		return &v
	}).(GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionPtrOutput)
}

// Matches values of the parent parameter of 'INTEGER' type. All values must lie in `integer_value_spec` of parent parameter.
func (o GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionOutput) Values() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueCondition) []string {
		return v.Values
	}).(pulumi.StringArrayOutput)
}

type GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueCondition)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionPtrOutput) ToGoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionPtrOutput() GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionPtrOutput) ToGoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionPtrOutput) Elem() GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueCondition) GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueCondition {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueCondition
		return ret
	}).(GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionOutput)
}

// Matches values of the parent parameter of 'INTEGER' type. All values must lie in `integer_value_spec` of parent parameter.
func (o GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionPtrOutput) Values() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueCondition) []string {
		if v == nil {
			return nil
		}
		return v.Values
	}).(pulumi.StringArrayOutput)
}

// Represents the spec to match integer values from parent parameter.
type GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionResponse struct {
	// Matches values of the parent parameter of 'INTEGER' type. All values must lie in `integer_value_spec` of parent parameter.
	Values []string `pulumi:"values"`
}

// Represents the spec to match integer values from parent parameter.
type GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionResponseOutput) ToGoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionResponseOutput() GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionResponseOutput) ToGoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionResponseOutput {
	return o
}

// Matches values of the parent parameter of 'INTEGER' type. All values must lie in `integer_value_spec` of parent parameter.
func (o GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionResponseOutput) Values() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionResponse) []string {
		return v.Values
	}).(pulumi.StringArrayOutput)
}

// Represents a parameter spec with condition from its parent parameter.
type GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecResponse struct {
	// The spec for a conditional parameter.
	ParameterSpec GoogleCloudAiplatformV1StudySpecParameterSpecResponse `pulumi:"parameterSpec"`
	// The spec for matching values from a parent parameter of `CATEGORICAL` type.
	ParentCategoricalValues GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionResponse `pulumi:"parentCategoricalValues"`
	// The spec for matching values from a parent parameter of `DISCRETE` type.
	ParentDiscreteValues GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionResponse `pulumi:"parentDiscreteValues"`
	// The spec for matching values from a parent parameter of `INTEGER` type.
	ParentIntValues GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionResponse `pulumi:"parentIntValues"`
}

// Represents a parameter spec with condition from its parent parameter.
type GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecResponseOutput) ToGoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecResponseOutput() GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecResponseOutput) ToGoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecResponseOutput {
	return o
}

// The spec for a conditional parameter.
func (o GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecResponseOutput) ParameterSpec() GoogleCloudAiplatformV1StudySpecParameterSpecResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecResponse) GoogleCloudAiplatformV1StudySpecParameterSpecResponse {
		return v.ParameterSpec
	}).(GoogleCloudAiplatformV1StudySpecParameterSpecResponseOutput)
}

// The spec for matching values from a parent parameter of `CATEGORICAL` type.
func (o GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecResponseOutput) ParentCategoricalValues() GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecResponse) GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionResponse {
		return v.ParentCategoricalValues
	}).(GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionResponseOutput)
}

// The spec for matching values from a parent parameter of `DISCRETE` type.
func (o GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecResponseOutput) ParentDiscreteValues() GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecResponse) GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionResponse {
		return v.ParentDiscreteValues
	}).(GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionResponseOutput)
}

// The spec for matching values from a parent parameter of `INTEGER` type.
func (o GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecResponseOutput) ParentIntValues() GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecResponse) GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionResponse {
		return v.ParentIntValues
	}).(GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionResponseOutput)
}

type GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecResponseArrayOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecResponseArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecResponseArrayOutput) ToGoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecResponseArrayOutput() GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecResponseArrayOutput) ToGoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecResponseArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecResponseArrayOutput) Index(i pulumi.IntInput) GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecResponseOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecResponse {
		return vs[0].([]GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecResponse)[vs[1].(int)]
	}).(GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecResponseOutput)
}

// Value specification for a parameter in `DISCRETE` type.
type GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpec struct {
	// A default value for a `DISCRETE` parameter that is assumed to be a relatively good starting point. Unset value signals that there is no offered starting point. It automatically rounds to the nearest feasible discrete point. Currently only supported by the Vertex AI Vizier service. Not supported by HyperparameterTuningJob or TrainingPipeline.
	DefaultValue *float64 `pulumi:"defaultValue"`
	// A list of possible values. The list should be in increasing order and at least 1e-10 apart. For instance, this parameter might have possible settings of 1.5, 2.5, and 4.0. This list should not contain more than 1,000 values.
	Values []float64 `pulumi:"values"`
}

// GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecInput is an input type that accepts GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecArgs and GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecInput` via:
//
//	GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecArgs{...}
type GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecOutput() GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecOutput
	ToGoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecOutputWithContext(context.Context) GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecOutput
}

// Value specification for a parameter in `DISCRETE` type.
type GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecArgs struct {
	// A default value for a `DISCRETE` parameter that is assumed to be a relatively good starting point. Unset value signals that there is no offered starting point. It automatically rounds to the nearest feasible discrete point. Currently only supported by the Vertex AI Vizier service. Not supported by HyperparameterTuningJob or TrainingPipeline.
	DefaultValue pulumi.Float64PtrInput `pulumi:"defaultValue"`
	// A list of possible values. The list should be in increasing order and at least 1e-10 apart. For instance, this parameter might have possible settings of 1.5, 2.5, and 4.0. This list should not contain more than 1,000 values.
	Values pulumi.Float64ArrayInput `pulumi:"values"`
}

func (GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpec)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecArgs) ToGoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecOutput() GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecOutput {
	return i.ToGoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecArgs) ToGoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecOutput)
}

func (i GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecArgs) ToGoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecPtrOutput() GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecPtrOutput {
	return i.ToGoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecArgs) ToGoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecOutput).ToGoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecPtrInput is an input type that accepts GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecArgs, GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecPtr and GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecPtrInput` via:
//
//	        GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecPtrOutput() GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecPtrOutput
	ToGoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecPtrOutput
}

type googleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecPtrType GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecArgs

func GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecPtr(v *GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecArgs) GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecPtrInput {
	return (*googleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecPtrType)(v)
}

func (*googleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpec)(nil)).Elem()
}

func (i *googleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecPtrType) ToGoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecPtrOutput() GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecPtrOutput {
	return i.ToGoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecPtrType) ToGoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecPtrOutput)
}

// Value specification for a parameter in `DISCRETE` type.
type GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecOutput) ToGoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecOutput() GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecOutput) ToGoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecOutput) ToGoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecPtrOutput() GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecPtrOutput {
	return o.ToGoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecOutput) ToGoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpec) *GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpec {
		return &v
	}).(GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecPtrOutput)
}

// A default value for a `DISCRETE` parameter that is assumed to be a relatively good starting point. Unset value signals that there is no offered starting point. It automatically rounds to the nearest feasible discrete point. Currently only supported by the Vertex AI Vizier service. Not supported by HyperparameterTuningJob or TrainingPipeline.
func (o GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecOutput) DefaultValue() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpec) *float64 { return v.DefaultValue }).(pulumi.Float64PtrOutput)
}

// A list of possible values. The list should be in increasing order and at least 1e-10 apart. For instance, this parameter might have possible settings of 1.5, 2.5, and 4.0. This list should not contain more than 1,000 values.
func (o GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecOutput) Values() pulumi.Float64ArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpec) []float64 { return v.Values }).(pulumi.Float64ArrayOutput)
}

type GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecPtrOutput) ToGoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecPtrOutput() GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecPtrOutput) ToGoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecPtrOutput) Elem() GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpec) GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpec {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpec
		return ret
	}).(GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecOutput)
}

// A default value for a `DISCRETE` parameter that is assumed to be a relatively good starting point. Unset value signals that there is no offered starting point. It automatically rounds to the nearest feasible discrete point. Currently only supported by the Vertex AI Vizier service. Not supported by HyperparameterTuningJob or TrainingPipeline.
func (o GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecPtrOutput) DefaultValue() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpec) *float64 {
		if v == nil {
			return nil
		}
		return v.DefaultValue
	}).(pulumi.Float64PtrOutput)
}

// A list of possible values. The list should be in increasing order and at least 1e-10 apart. For instance, this parameter might have possible settings of 1.5, 2.5, and 4.0. This list should not contain more than 1,000 values.
func (o GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecPtrOutput) Values() pulumi.Float64ArrayOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpec) []float64 {
		if v == nil {
			return nil
		}
		return v.Values
	}).(pulumi.Float64ArrayOutput)
}

// Value specification for a parameter in `DISCRETE` type.
type GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecResponse struct {
	// A default value for a `DISCRETE` parameter that is assumed to be a relatively good starting point. Unset value signals that there is no offered starting point. It automatically rounds to the nearest feasible discrete point. Currently only supported by the Vertex AI Vizier service. Not supported by HyperparameterTuningJob or TrainingPipeline.
	DefaultValue float64 `pulumi:"defaultValue"`
	// A list of possible values. The list should be in increasing order and at least 1e-10 apart. For instance, this parameter might have possible settings of 1.5, 2.5, and 4.0. This list should not contain more than 1,000 values.
	Values []float64 `pulumi:"values"`
}

// Value specification for a parameter in `DISCRETE` type.
type GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecResponseOutput) ToGoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecResponseOutput() GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecResponseOutput) ToGoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecResponseOutput {
	return o
}

// A default value for a `DISCRETE` parameter that is assumed to be a relatively good starting point. Unset value signals that there is no offered starting point. It automatically rounds to the nearest feasible discrete point. Currently only supported by the Vertex AI Vizier service. Not supported by HyperparameterTuningJob or TrainingPipeline.
func (o GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecResponseOutput) DefaultValue() pulumi.Float64Output {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecResponse) float64 {
		return v.DefaultValue
	}).(pulumi.Float64Output)
}

// A list of possible values. The list should be in increasing order and at least 1e-10 apart. For instance, this parameter might have possible settings of 1.5, 2.5, and 4.0. This list should not contain more than 1,000 values.
func (o GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecResponseOutput) Values() pulumi.Float64ArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecResponse) []float64 {
		return v.Values
	}).(pulumi.Float64ArrayOutput)
}

// Value specification for a parameter in `DOUBLE` type.
type GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpec struct {
	// A default value for a `DOUBLE` parameter that is assumed to be a relatively good starting point. Unset value signals that there is no offered starting point. Currently only supported by the Vertex AI Vizier service. Not supported by HyperparameterTuningJob or TrainingPipeline.
	DefaultValue *float64 `pulumi:"defaultValue"`
	// Inclusive maximum value of the parameter.
	MaxValue float64 `pulumi:"maxValue"`
	// Inclusive minimum value of the parameter.
	MinValue float64 `pulumi:"minValue"`
}

// GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecInput is an input type that accepts GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecArgs and GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecInput` via:
//
//	GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecArgs{...}
type GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecOutput() GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecOutput
	ToGoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecOutputWithContext(context.Context) GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecOutput
}

// Value specification for a parameter in `DOUBLE` type.
type GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecArgs struct {
	// A default value for a `DOUBLE` parameter that is assumed to be a relatively good starting point. Unset value signals that there is no offered starting point. Currently only supported by the Vertex AI Vizier service. Not supported by HyperparameterTuningJob or TrainingPipeline.
	DefaultValue pulumi.Float64PtrInput `pulumi:"defaultValue"`
	// Inclusive maximum value of the parameter.
	MaxValue pulumi.Float64Input `pulumi:"maxValue"`
	// Inclusive minimum value of the parameter.
	MinValue pulumi.Float64Input `pulumi:"minValue"`
}

func (GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpec)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecArgs) ToGoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecOutput() GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecOutput {
	return i.ToGoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecArgs) ToGoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecOutput)
}

func (i GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecArgs) ToGoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecPtrOutput() GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecPtrOutput {
	return i.ToGoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecArgs) ToGoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecOutput).ToGoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecPtrInput is an input type that accepts GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecArgs, GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecPtr and GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecPtrInput` via:
//
//	        GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecPtrOutput() GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecPtrOutput
	ToGoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecPtrOutput
}

type googleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecPtrType GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecArgs

func GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecPtr(v *GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecArgs) GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecPtrInput {
	return (*googleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecPtrType)(v)
}

func (*googleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpec)(nil)).Elem()
}

func (i *googleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecPtrType) ToGoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecPtrOutput() GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecPtrOutput {
	return i.ToGoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecPtrType) ToGoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecPtrOutput)
}

// Value specification for a parameter in `DOUBLE` type.
type GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecOutput) ToGoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecOutput() GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecOutput) ToGoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecOutput) ToGoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecPtrOutput() GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecPtrOutput {
	return o.ToGoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecOutput) ToGoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpec) *GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpec {
		return &v
	}).(GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecPtrOutput)
}

// A default value for a `DOUBLE` parameter that is assumed to be a relatively good starting point. Unset value signals that there is no offered starting point. Currently only supported by the Vertex AI Vizier service. Not supported by HyperparameterTuningJob or TrainingPipeline.
func (o GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecOutput) DefaultValue() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpec) *float64 { return v.DefaultValue }).(pulumi.Float64PtrOutput)
}

// Inclusive maximum value of the parameter.
func (o GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecOutput) MaxValue() pulumi.Float64Output {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpec) float64 { return v.MaxValue }).(pulumi.Float64Output)
}

// Inclusive minimum value of the parameter.
func (o GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecOutput) MinValue() pulumi.Float64Output {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpec) float64 { return v.MinValue }).(pulumi.Float64Output)
}

type GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecPtrOutput) ToGoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecPtrOutput() GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecPtrOutput) ToGoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecPtrOutput) Elem() GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpec) GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpec {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpec
		return ret
	}).(GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecOutput)
}

// A default value for a `DOUBLE` parameter that is assumed to be a relatively good starting point. Unset value signals that there is no offered starting point. Currently only supported by the Vertex AI Vizier service. Not supported by HyperparameterTuningJob or TrainingPipeline.
func (o GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecPtrOutput) DefaultValue() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpec) *float64 {
		if v == nil {
			return nil
		}
		return v.DefaultValue
	}).(pulumi.Float64PtrOutput)
}

// Inclusive maximum value of the parameter.
func (o GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecPtrOutput) MaxValue() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpec) *float64 {
		if v == nil {
			return nil
		}
		return &v.MaxValue
	}).(pulumi.Float64PtrOutput)
}

// Inclusive minimum value of the parameter.
func (o GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecPtrOutput) MinValue() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpec) *float64 {
		if v == nil {
			return nil
		}
		return &v.MinValue
	}).(pulumi.Float64PtrOutput)
}

// Value specification for a parameter in `DOUBLE` type.
type GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecResponse struct {
	// A default value for a `DOUBLE` parameter that is assumed to be a relatively good starting point. Unset value signals that there is no offered starting point. Currently only supported by the Vertex AI Vizier service. Not supported by HyperparameterTuningJob or TrainingPipeline.
	DefaultValue float64 `pulumi:"defaultValue"`
	// Inclusive maximum value of the parameter.
	MaxValue float64 `pulumi:"maxValue"`
	// Inclusive minimum value of the parameter.
	MinValue float64 `pulumi:"minValue"`
}

// Value specification for a parameter in `DOUBLE` type.
type GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecResponseOutput) ToGoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecResponseOutput() GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecResponseOutput) ToGoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecResponseOutput {
	return o
}

// A default value for a `DOUBLE` parameter that is assumed to be a relatively good starting point. Unset value signals that there is no offered starting point. Currently only supported by the Vertex AI Vizier service. Not supported by HyperparameterTuningJob or TrainingPipeline.
func (o GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecResponseOutput) DefaultValue() pulumi.Float64Output {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecResponse) float64 {
		return v.DefaultValue
	}).(pulumi.Float64Output)
}

// Inclusive maximum value of the parameter.
func (o GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecResponseOutput) MaxValue() pulumi.Float64Output {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecResponse) float64 {
		return v.MaxValue
	}).(pulumi.Float64Output)
}

// Inclusive minimum value of the parameter.
func (o GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecResponseOutput) MinValue() pulumi.Float64Output {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecResponse) float64 {
		return v.MinValue
	}).(pulumi.Float64Output)
}

// Value specification for a parameter in `INTEGER` type.
type GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpec struct {
	// A default value for an `INTEGER` parameter that is assumed to be a relatively good starting point. Unset value signals that there is no offered starting point. Currently only supported by the Vertex AI Vizier service. Not supported by HyperparameterTuningJob or TrainingPipeline.
	DefaultValue *string `pulumi:"defaultValue"`
	// Inclusive maximum value of the parameter.
	MaxValue string `pulumi:"maxValue"`
	// Inclusive minimum value of the parameter.
	MinValue string `pulumi:"minValue"`
}

// GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecInput is an input type that accepts GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecArgs and GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecInput` via:
//
//	GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecArgs{...}
type GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecOutput() GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecOutput
	ToGoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecOutputWithContext(context.Context) GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecOutput
}

// Value specification for a parameter in `INTEGER` type.
type GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecArgs struct {
	// A default value for an `INTEGER` parameter that is assumed to be a relatively good starting point. Unset value signals that there is no offered starting point. Currently only supported by the Vertex AI Vizier service. Not supported by HyperparameterTuningJob or TrainingPipeline.
	DefaultValue pulumi.StringPtrInput `pulumi:"defaultValue"`
	// Inclusive maximum value of the parameter.
	MaxValue pulumi.StringInput `pulumi:"maxValue"`
	// Inclusive minimum value of the parameter.
	MinValue pulumi.StringInput `pulumi:"minValue"`
}

func (GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpec)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecArgs) ToGoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecOutput() GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecOutput {
	return i.ToGoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecArgs) ToGoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecOutput)
}

func (i GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecArgs) ToGoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecPtrOutput() GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecPtrOutput {
	return i.ToGoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecArgs) ToGoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecOutput).ToGoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecPtrInput is an input type that accepts GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecArgs, GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecPtr and GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecPtrInput` via:
//
//	        GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecPtrOutput() GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecPtrOutput
	ToGoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecPtrOutput
}

type googleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecPtrType GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecArgs

func GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecPtr(v *GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecArgs) GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecPtrInput {
	return (*googleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecPtrType)(v)
}

func (*googleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpec)(nil)).Elem()
}

func (i *googleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecPtrType) ToGoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecPtrOutput() GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecPtrOutput {
	return i.ToGoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecPtrType) ToGoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecPtrOutput)
}

// Value specification for a parameter in `INTEGER` type.
type GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecOutput) ToGoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecOutput() GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecOutput) ToGoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecOutput) ToGoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecPtrOutput() GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecPtrOutput {
	return o.ToGoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecOutput) ToGoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpec) *GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpec {
		return &v
	}).(GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecPtrOutput)
}

// A default value for an `INTEGER` parameter that is assumed to be a relatively good starting point. Unset value signals that there is no offered starting point. Currently only supported by the Vertex AI Vizier service. Not supported by HyperparameterTuningJob or TrainingPipeline.
func (o GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecOutput) DefaultValue() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpec) *string { return v.DefaultValue }).(pulumi.StringPtrOutput)
}

// Inclusive maximum value of the parameter.
func (o GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecOutput) MaxValue() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpec) string { return v.MaxValue }).(pulumi.StringOutput)
}

// Inclusive minimum value of the parameter.
func (o GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecOutput) MinValue() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpec) string { return v.MinValue }).(pulumi.StringOutput)
}

type GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecPtrOutput) ToGoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecPtrOutput() GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecPtrOutput) ToGoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecPtrOutput) Elem() GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpec) GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpec {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpec
		return ret
	}).(GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecOutput)
}

// A default value for an `INTEGER` parameter that is assumed to be a relatively good starting point. Unset value signals that there is no offered starting point. Currently only supported by the Vertex AI Vizier service. Not supported by HyperparameterTuningJob or TrainingPipeline.
func (o GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecPtrOutput) DefaultValue() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpec) *string {
		if v == nil {
			return nil
		}
		return v.DefaultValue
	}).(pulumi.StringPtrOutput)
}

// Inclusive maximum value of the parameter.
func (o GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecPtrOutput) MaxValue() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpec) *string {
		if v == nil {
			return nil
		}
		return &v.MaxValue
	}).(pulumi.StringPtrOutput)
}

// Inclusive minimum value of the parameter.
func (o GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecPtrOutput) MinValue() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpec) *string {
		if v == nil {
			return nil
		}
		return &v.MinValue
	}).(pulumi.StringPtrOutput)
}

// Value specification for a parameter in `INTEGER` type.
type GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecResponse struct {
	// A default value for an `INTEGER` parameter that is assumed to be a relatively good starting point. Unset value signals that there is no offered starting point. Currently only supported by the Vertex AI Vizier service. Not supported by HyperparameterTuningJob or TrainingPipeline.
	DefaultValue string `pulumi:"defaultValue"`
	// Inclusive maximum value of the parameter.
	MaxValue string `pulumi:"maxValue"`
	// Inclusive minimum value of the parameter.
	MinValue string `pulumi:"minValue"`
}

// Value specification for a parameter in `INTEGER` type.
type GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecResponseOutput) ToGoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecResponseOutput() GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecResponseOutput) ToGoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecResponseOutput {
	return o
}

// A default value for an `INTEGER` parameter that is assumed to be a relatively good starting point. Unset value signals that there is no offered starting point. Currently only supported by the Vertex AI Vizier service. Not supported by HyperparameterTuningJob or TrainingPipeline.
func (o GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecResponseOutput) DefaultValue() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecResponse) string {
		return v.DefaultValue
	}).(pulumi.StringOutput)
}

// Inclusive maximum value of the parameter.
func (o GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecResponseOutput) MaxValue() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecResponse) string {
		return v.MaxValue
	}).(pulumi.StringOutput)
}

// Inclusive minimum value of the parameter.
func (o GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecResponseOutput) MinValue() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecResponse) string {
		return v.MinValue
	}).(pulumi.StringOutput)
}

// Represents a single parameter to optimize.
type GoogleCloudAiplatformV1StudySpecParameterSpecResponse struct {
	// The value spec for a 'CATEGORICAL' parameter.
	CategoricalValueSpec GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecResponse `pulumi:"categoricalValueSpec"`
	// A conditional parameter node is active if the parameter's value matches the conditional node's parent_value_condition. If two items in conditional_parameter_specs have the same name, they must have disjoint parent_value_condition.
	ConditionalParameterSpecs []GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecResponse `pulumi:"conditionalParameterSpecs"`
	// The value spec for a 'DISCRETE' parameter.
	DiscreteValueSpec GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecResponse `pulumi:"discreteValueSpec"`
	// The value spec for a 'DOUBLE' parameter.
	DoubleValueSpec GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecResponse `pulumi:"doubleValueSpec"`
	// The value spec for an 'INTEGER' parameter.
	IntegerValueSpec GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecResponse `pulumi:"integerValueSpec"`
	// The ID of the parameter. Must not contain whitespaces and must be unique amongst all ParameterSpecs.
	ParameterId string `pulumi:"parameterId"`
	// How the parameter should be scaled. Leave unset for `CATEGORICAL` parameters.
	ScaleType string `pulumi:"scaleType"`
}

// Represents a single parameter to optimize.
type GoogleCloudAiplatformV1StudySpecParameterSpecResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1StudySpecParameterSpecResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1StudySpecParameterSpecResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1StudySpecParameterSpecResponseOutput) ToGoogleCloudAiplatformV1StudySpecParameterSpecResponseOutput() GoogleCloudAiplatformV1StudySpecParameterSpecResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1StudySpecParameterSpecResponseOutput) ToGoogleCloudAiplatformV1StudySpecParameterSpecResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecParameterSpecResponseOutput {
	return o
}

// The value spec for a 'CATEGORICAL' parameter.
func (o GoogleCloudAiplatformV1StudySpecParameterSpecResponseOutput) CategoricalValueSpec() GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpecParameterSpecResponse) GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecResponse {
		return v.CategoricalValueSpec
	}).(GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecResponseOutput)
}

// A conditional parameter node is active if the parameter's value matches the conditional node's parent_value_condition. If two items in conditional_parameter_specs have the same name, they must have disjoint parent_value_condition.
func (o GoogleCloudAiplatformV1StudySpecParameterSpecResponseOutput) ConditionalParameterSpecs() GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecResponseArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpecParameterSpecResponse) []GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecResponse {
		return v.ConditionalParameterSpecs
	}).(GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecResponseArrayOutput)
}

// The value spec for a 'DISCRETE' parameter.
func (o GoogleCloudAiplatformV1StudySpecParameterSpecResponseOutput) DiscreteValueSpec() GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpecParameterSpecResponse) GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecResponse {
		return v.DiscreteValueSpec
	}).(GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecResponseOutput)
}

// The value spec for a 'DOUBLE' parameter.
func (o GoogleCloudAiplatformV1StudySpecParameterSpecResponseOutput) DoubleValueSpec() GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpecParameterSpecResponse) GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecResponse {
		return v.DoubleValueSpec
	}).(GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecResponseOutput)
}

// The value spec for an 'INTEGER' parameter.
func (o GoogleCloudAiplatformV1StudySpecParameterSpecResponseOutput) IntegerValueSpec() GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpecParameterSpecResponse) GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecResponse {
		return v.IntegerValueSpec
	}).(GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecResponseOutput)
}

// The ID of the parameter. Must not contain whitespaces and must be unique amongst all ParameterSpecs.
func (o GoogleCloudAiplatformV1StudySpecParameterSpecResponseOutput) ParameterId() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpecParameterSpecResponse) string { return v.ParameterId }).(pulumi.StringOutput)
}

// How the parameter should be scaled. Leave unset for `CATEGORICAL` parameters.
func (o GoogleCloudAiplatformV1StudySpecParameterSpecResponseOutput) ScaleType() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpecParameterSpecResponse) string { return v.ScaleType }).(pulumi.StringOutput)
}

type GoogleCloudAiplatformV1StudySpecParameterSpecResponseArrayOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1StudySpecParameterSpecResponseArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1StudySpecParameterSpecResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1StudySpecParameterSpecResponseArrayOutput) ToGoogleCloudAiplatformV1StudySpecParameterSpecResponseArrayOutput() GoogleCloudAiplatformV1StudySpecParameterSpecResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1StudySpecParameterSpecResponseArrayOutput) ToGoogleCloudAiplatformV1StudySpecParameterSpecResponseArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecParameterSpecResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1StudySpecParameterSpecResponseArrayOutput) Index(i pulumi.IntInput) GoogleCloudAiplatformV1StudySpecParameterSpecResponseOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GoogleCloudAiplatformV1StudySpecParameterSpecResponse {
		return vs[0].([]GoogleCloudAiplatformV1StudySpecParameterSpecResponse)[vs[1].(int)]
	}).(GoogleCloudAiplatformV1StudySpecParameterSpecResponseOutput)
}

// Represents specification of a Study.
type GoogleCloudAiplatformV1StudySpecResponse struct {
	// The search algorithm specified for the Study.
	Algorithm string `pulumi:"algorithm"`
	// The automated early stopping spec using convex stopping rule.
	ConvexAutomatedStoppingSpec GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecResponse `pulumi:"convexAutomatedStoppingSpec"`
	// The automated early stopping spec using decay curve rule.
	DecayCurveStoppingSpec GoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecResponse `pulumi:"decayCurveStoppingSpec"`
	// Describe which measurement selection type will be used
	MeasurementSelectionType string `pulumi:"measurementSelectionType"`
	// The automated early stopping spec using median rule.
	MedianAutomatedStoppingSpec GoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecResponse `pulumi:"medianAutomatedStoppingSpec"`
	// Metric specs for the Study.
	Metrics []GoogleCloudAiplatformV1StudySpecMetricSpecResponse `pulumi:"metrics"`
	// The observation noise level of the study. Currently only supported by the Vertex AI Vizier service. Not supported by HyperparameterTuningJob or TrainingPipeline.
	ObservationNoise string `pulumi:"observationNoise"`
	// The set of parameters to tune.
	Parameters []GoogleCloudAiplatformV1StudySpecParameterSpecResponse `pulumi:"parameters"`
	// Conditions for automated stopping of a Study. Enable automated stopping by configuring at least one condition.
	StudyStoppingConfig GoogleCloudAiplatformV1StudySpecStudyStoppingConfigResponse `pulumi:"studyStoppingConfig"`
}

// Represents specification of a Study.
type GoogleCloudAiplatformV1StudySpecResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1StudySpecResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1StudySpecResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1StudySpecResponseOutput) ToGoogleCloudAiplatformV1StudySpecResponseOutput() GoogleCloudAiplatformV1StudySpecResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1StudySpecResponseOutput) ToGoogleCloudAiplatformV1StudySpecResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecResponseOutput {
	return o
}

// The search algorithm specified for the Study.
func (o GoogleCloudAiplatformV1StudySpecResponseOutput) Algorithm() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpecResponse) string { return v.Algorithm }).(pulumi.StringOutput)
}

// The automated early stopping spec using convex stopping rule.
func (o GoogleCloudAiplatformV1StudySpecResponseOutput) ConvexAutomatedStoppingSpec() GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpecResponse) GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecResponse {
		return v.ConvexAutomatedStoppingSpec
	}).(GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecResponseOutput)
}

// The automated early stopping spec using decay curve rule.
func (o GoogleCloudAiplatformV1StudySpecResponseOutput) DecayCurveStoppingSpec() GoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpecResponse) GoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecResponse {
		return v.DecayCurveStoppingSpec
	}).(GoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecResponseOutput)
}

// Describe which measurement selection type will be used
func (o GoogleCloudAiplatformV1StudySpecResponseOutput) MeasurementSelectionType() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpecResponse) string { return v.MeasurementSelectionType }).(pulumi.StringOutput)
}

// The automated early stopping spec using median rule.
func (o GoogleCloudAiplatformV1StudySpecResponseOutput) MedianAutomatedStoppingSpec() GoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpecResponse) GoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecResponse {
		return v.MedianAutomatedStoppingSpec
	}).(GoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecResponseOutput)
}

// Metric specs for the Study.
func (o GoogleCloudAiplatformV1StudySpecResponseOutput) Metrics() GoogleCloudAiplatformV1StudySpecMetricSpecResponseArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpecResponse) []GoogleCloudAiplatformV1StudySpecMetricSpecResponse {
		return v.Metrics
	}).(GoogleCloudAiplatformV1StudySpecMetricSpecResponseArrayOutput)
}

// The observation noise level of the study. Currently only supported by the Vertex AI Vizier service. Not supported by HyperparameterTuningJob or TrainingPipeline.
func (o GoogleCloudAiplatformV1StudySpecResponseOutput) ObservationNoise() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpecResponse) string { return v.ObservationNoise }).(pulumi.StringOutput)
}

// The set of parameters to tune.
func (o GoogleCloudAiplatformV1StudySpecResponseOutput) Parameters() GoogleCloudAiplatformV1StudySpecParameterSpecResponseArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpecResponse) []GoogleCloudAiplatformV1StudySpecParameterSpecResponse {
		return v.Parameters
	}).(GoogleCloudAiplatformV1StudySpecParameterSpecResponseArrayOutput)
}

// Conditions for automated stopping of a Study. Enable automated stopping by configuring at least one condition.
func (o GoogleCloudAiplatformV1StudySpecResponseOutput) StudyStoppingConfig() GoogleCloudAiplatformV1StudySpecStudyStoppingConfigResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpecResponse) GoogleCloudAiplatformV1StudySpecStudyStoppingConfigResponse {
		return v.StudyStoppingConfig
	}).(GoogleCloudAiplatformV1StudySpecStudyStoppingConfigResponseOutput)
}

// The configuration (stopping conditions) for automated stopping of a Study. Conditions include trial budgets, time budgets, and convergence detection.
type GoogleCloudAiplatformV1StudySpecStudyStoppingConfig struct {
	// If the objective value has not improved for this much time, stop the study. WARNING: Effective only for single-objective studies.
	MaxDurationNoProgress *string `pulumi:"maxDurationNoProgress"`
	// If there are more than this many trials, stop the study.
	MaxNumTrials *int `pulumi:"maxNumTrials"`
	// If the objective value has not improved for this many consecutive trials, stop the study. WARNING: Effective only for single-objective studies.
	MaxNumTrialsNoProgress *int `pulumi:"maxNumTrialsNoProgress"`
	// If the specified time or duration has passed, stop the study.
	MaximumRuntimeConstraint *GoogleCloudAiplatformV1StudyTimeConstraint `pulumi:"maximumRuntimeConstraint"`
	// If there are fewer than this many COMPLETED trials, do not stop the study.
	MinNumTrials *int `pulumi:"minNumTrials"`
	// Each "stopping rule" in this proto specifies an "if" condition. Before Vizier would generate a new suggestion, it first checks each specified stopping rule, from top to bottom in this list. Note that the first few rules (e.g. minimum_runtime_constraint, min_num_trials) will prevent other stopping rules from being evaluated until they are met. For example, setting `min_num_trials=5` and `always_stop_after= 1 hour` means that the Study will ONLY stop after it has 5 COMPLETED trials, even if more than an hour has passed since its creation. It follows the first applicable rule (whose "if" condition is satisfied) to make a stopping decision. If none of the specified rules are applicable, then Vizier decides that the study should not stop. If Vizier decides that the study should stop, the study enters STOPPING state (or STOPPING_ASAP if should_stop_asap = true). IMPORTANT: The automatic study state transition happens precisely as described above; that is, deleting trials or updating StudyConfig NEVER automatically moves the study state back to ACTIVE. If you want to _resume_ a Study that was stopped, 1) change the stopping conditions if necessary, 2) activate the study, and then 3) ask for suggestions. If the specified time or duration has not passed, do not stop the study.
	MinimumRuntimeConstraint *GoogleCloudAiplatformV1StudyTimeConstraint `pulumi:"minimumRuntimeConstraint"`
	// If true, a Study enters STOPPING_ASAP whenever it would normally enters STOPPING state. The bottom line is: set to true if you want to interrupt on-going evaluations of Trials as soon as the study stopping condition is met. (Please see Study.State documentation for the source of truth).
	ShouldStopAsap *bool `pulumi:"shouldStopAsap"`
}

// GoogleCloudAiplatformV1StudySpecStudyStoppingConfigInput is an input type that accepts GoogleCloudAiplatformV1StudySpecStudyStoppingConfigArgs and GoogleCloudAiplatformV1StudySpecStudyStoppingConfigOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1StudySpecStudyStoppingConfigInput` via:
//
//	GoogleCloudAiplatformV1StudySpecStudyStoppingConfigArgs{...}
type GoogleCloudAiplatformV1StudySpecStudyStoppingConfigInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1StudySpecStudyStoppingConfigOutput() GoogleCloudAiplatformV1StudySpecStudyStoppingConfigOutput
	ToGoogleCloudAiplatformV1StudySpecStudyStoppingConfigOutputWithContext(context.Context) GoogleCloudAiplatformV1StudySpecStudyStoppingConfigOutput
}

// The configuration (stopping conditions) for automated stopping of a Study. Conditions include trial budgets, time budgets, and convergence detection.
type GoogleCloudAiplatformV1StudySpecStudyStoppingConfigArgs struct {
	// If the objective value has not improved for this much time, stop the study. WARNING: Effective only for single-objective studies.
	MaxDurationNoProgress pulumi.StringPtrInput `pulumi:"maxDurationNoProgress"`
	// If there are more than this many trials, stop the study.
	MaxNumTrials pulumi.IntPtrInput `pulumi:"maxNumTrials"`
	// If the objective value has not improved for this many consecutive trials, stop the study. WARNING: Effective only for single-objective studies.
	MaxNumTrialsNoProgress pulumi.IntPtrInput `pulumi:"maxNumTrialsNoProgress"`
	// If the specified time or duration has passed, stop the study.
	MaximumRuntimeConstraint GoogleCloudAiplatformV1StudyTimeConstraintPtrInput `pulumi:"maximumRuntimeConstraint"`
	// If there are fewer than this many COMPLETED trials, do not stop the study.
	MinNumTrials pulumi.IntPtrInput `pulumi:"minNumTrials"`
	// Each "stopping rule" in this proto specifies an "if" condition. Before Vizier would generate a new suggestion, it first checks each specified stopping rule, from top to bottom in this list. Note that the first few rules (e.g. minimum_runtime_constraint, min_num_trials) will prevent other stopping rules from being evaluated until they are met. For example, setting `min_num_trials=5` and `always_stop_after= 1 hour` means that the Study will ONLY stop after it has 5 COMPLETED trials, even if more than an hour has passed since its creation. It follows the first applicable rule (whose "if" condition is satisfied) to make a stopping decision. If none of the specified rules are applicable, then Vizier decides that the study should not stop. If Vizier decides that the study should stop, the study enters STOPPING state (or STOPPING_ASAP if should_stop_asap = true). IMPORTANT: The automatic study state transition happens precisely as described above; that is, deleting trials or updating StudyConfig NEVER automatically moves the study state back to ACTIVE. If you want to _resume_ a Study that was stopped, 1) change the stopping conditions if necessary, 2) activate the study, and then 3) ask for suggestions. If the specified time or duration has not passed, do not stop the study.
	MinimumRuntimeConstraint GoogleCloudAiplatformV1StudyTimeConstraintPtrInput `pulumi:"minimumRuntimeConstraint"`
	// If true, a Study enters STOPPING_ASAP whenever it would normally enters STOPPING state. The bottom line is: set to true if you want to interrupt on-going evaluations of Trials as soon as the study stopping condition is met. (Please see Study.State documentation for the source of truth).
	ShouldStopAsap pulumi.BoolPtrInput `pulumi:"shouldStopAsap"`
}

func (GoogleCloudAiplatformV1StudySpecStudyStoppingConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1StudySpecStudyStoppingConfig)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1StudySpecStudyStoppingConfigArgs) ToGoogleCloudAiplatformV1StudySpecStudyStoppingConfigOutput() GoogleCloudAiplatformV1StudySpecStudyStoppingConfigOutput {
	return i.ToGoogleCloudAiplatformV1StudySpecStudyStoppingConfigOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1StudySpecStudyStoppingConfigArgs) ToGoogleCloudAiplatformV1StudySpecStudyStoppingConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecStudyStoppingConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1StudySpecStudyStoppingConfigOutput)
}

func (i GoogleCloudAiplatformV1StudySpecStudyStoppingConfigArgs) ToGoogleCloudAiplatformV1StudySpecStudyStoppingConfigPtrOutput() GoogleCloudAiplatformV1StudySpecStudyStoppingConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1StudySpecStudyStoppingConfigPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1StudySpecStudyStoppingConfigArgs) ToGoogleCloudAiplatformV1StudySpecStudyStoppingConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecStudyStoppingConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1StudySpecStudyStoppingConfigOutput).ToGoogleCloudAiplatformV1StudySpecStudyStoppingConfigPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1StudySpecStudyStoppingConfigPtrInput is an input type that accepts GoogleCloudAiplatformV1StudySpecStudyStoppingConfigArgs, GoogleCloudAiplatformV1StudySpecStudyStoppingConfigPtr and GoogleCloudAiplatformV1StudySpecStudyStoppingConfigPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1StudySpecStudyStoppingConfigPtrInput` via:
//
//	        GoogleCloudAiplatformV1StudySpecStudyStoppingConfigArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1StudySpecStudyStoppingConfigPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1StudySpecStudyStoppingConfigPtrOutput() GoogleCloudAiplatformV1StudySpecStudyStoppingConfigPtrOutput
	ToGoogleCloudAiplatformV1StudySpecStudyStoppingConfigPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1StudySpecStudyStoppingConfigPtrOutput
}

type googleCloudAiplatformV1StudySpecStudyStoppingConfigPtrType GoogleCloudAiplatformV1StudySpecStudyStoppingConfigArgs

func GoogleCloudAiplatformV1StudySpecStudyStoppingConfigPtr(v *GoogleCloudAiplatformV1StudySpecStudyStoppingConfigArgs) GoogleCloudAiplatformV1StudySpecStudyStoppingConfigPtrInput {
	return (*googleCloudAiplatformV1StudySpecStudyStoppingConfigPtrType)(v)
}

func (*googleCloudAiplatformV1StudySpecStudyStoppingConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1StudySpecStudyStoppingConfig)(nil)).Elem()
}

func (i *googleCloudAiplatformV1StudySpecStudyStoppingConfigPtrType) ToGoogleCloudAiplatformV1StudySpecStudyStoppingConfigPtrOutput() GoogleCloudAiplatformV1StudySpecStudyStoppingConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1StudySpecStudyStoppingConfigPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1StudySpecStudyStoppingConfigPtrType) ToGoogleCloudAiplatformV1StudySpecStudyStoppingConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecStudyStoppingConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1StudySpecStudyStoppingConfigPtrOutput)
}

// The configuration (stopping conditions) for automated stopping of a Study. Conditions include trial budgets, time budgets, and convergence detection.
type GoogleCloudAiplatformV1StudySpecStudyStoppingConfigOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1StudySpecStudyStoppingConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1StudySpecStudyStoppingConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1StudySpecStudyStoppingConfigOutput) ToGoogleCloudAiplatformV1StudySpecStudyStoppingConfigOutput() GoogleCloudAiplatformV1StudySpecStudyStoppingConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1StudySpecStudyStoppingConfigOutput) ToGoogleCloudAiplatformV1StudySpecStudyStoppingConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecStudyStoppingConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1StudySpecStudyStoppingConfigOutput) ToGoogleCloudAiplatformV1StudySpecStudyStoppingConfigPtrOutput() GoogleCloudAiplatformV1StudySpecStudyStoppingConfigPtrOutput {
	return o.ToGoogleCloudAiplatformV1StudySpecStudyStoppingConfigPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1StudySpecStudyStoppingConfigOutput) ToGoogleCloudAiplatformV1StudySpecStudyStoppingConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecStudyStoppingConfigPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1StudySpecStudyStoppingConfig) *GoogleCloudAiplatformV1StudySpecStudyStoppingConfig {
		return &v
	}).(GoogleCloudAiplatformV1StudySpecStudyStoppingConfigPtrOutput)
}

// If the objective value has not improved for this much time, stop the study. WARNING: Effective only for single-objective studies.
func (o GoogleCloudAiplatformV1StudySpecStudyStoppingConfigOutput) MaxDurationNoProgress() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpecStudyStoppingConfig) *string { return v.MaxDurationNoProgress }).(pulumi.StringPtrOutput)
}

// If there are more than this many trials, stop the study.
func (o GoogleCloudAiplatformV1StudySpecStudyStoppingConfigOutput) MaxNumTrials() pulumi.IntPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpecStudyStoppingConfig) *int { return v.MaxNumTrials }).(pulumi.IntPtrOutput)
}

// If the objective value has not improved for this many consecutive trials, stop the study. WARNING: Effective only for single-objective studies.
func (o GoogleCloudAiplatformV1StudySpecStudyStoppingConfigOutput) MaxNumTrialsNoProgress() pulumi.IntPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpecStudyStoppingConfig) *int { return v.MaxNumTrialsNoProgress }).(pulumi.IntPtrOutput)
}

// If the specified time or duration has passed, stop the study.
func (o GoogleCloudAiplatformV1StudySpecStudyStoppingConfigOutput) MaximumRuntimeConstraint() GoogleCloudAiplatformV1StudyTimeConstraintPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpecStudyStoppingConfig) *GoogleCloudAiplatformV1StudyTimeConstraint {
		return v.MaximumRuntimeConstraint
	}).(GoogleCloudAiplatformV1StudyTimeConstraintPtrOutput)
}

// If there are fewer than this many COMPLETED trials, do not stop the study.
func (o GoogleCloudAiplatformV1StudySpecStudyStoppingConfigOutput) MinNumTrials() pulumi.IntPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpecStudyStoppingConfig) *int { return v.MinNumTrials }).(pulumi.IntPtrOutput)
}

// Each "stopping rule" in this proto specifies an "if" condition. Before Vizier would generate a new suggestion, it first checks each specified stopping rule, from top to bottom in this list. Note that the first few rules (e.g. minimum_runtime_constraint, min_num_trials) will prevent other stopping rules from being evaluated until they are met. For example, setting `min_num_trials=5` and `always_stop_after= 1 hour` means that the Study will ONLY stop after it has 5 COMPLETED trials, even if more than an hour has passed since its creation. It follows the first applicable rule (whose "if" condition is satisfied) to make a stopping decision. If none of the specified rules are applicable, then Vizier decides that the study should not stop. If Vizier decides that the study should stop, the study enters STOPPING state (or STOPPING_ASAP if should_stop_asap = true). IMPORTANT: The automatic study state transition happens precisely as described above; that is, deleting trials or updating StudyConfig NEVER automatically moves the study state back to ACTIVE. If you want to _resume_ a Study that was stopped, 1) change the stopping conditions if necessary, 2) activate the study, and then 3) ask for suggestions. If the specified time or duration has not passed, do not stop the study.
func (o GoogleCloudAiplatformV1StudySpecStudyStoppingConfigOutput) MinimumRuntimeConstraint() GoogleCloudAiplatformV1StudyTimeConstraintPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpecStudyStoppingConfig) *GoogleCloudAiplatformV1StudyTimeConstraint {
		return v.MinimumRuntimeConstraint
	}).(GoogleCloudAiplatformV1StudyTimeConstraintPtrOutput)
}

// If true, a Study enters STOPPING_ASAP whenever it would normally enters STOPPING state. The bottom line is: set to true if you want to interrupt on-going evaluations of Trials as soon as the study stopping condition is met. (Please see Study.State documentation for the source of truth).
func (o GoogleCloudAiplatformV1StudySpecStudyStoppingConfigOutput) ShouldStopAsap() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpecStudyStoppingConfig) *bool { return v.ShouldStopAsap }).(pulumi.BoolPtrOutput)
}

type GoogleCloudAiplatformV1StudySpecStudyStoppingConfigPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1StudySpecStudyStoppingConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1StudySpecStudyStoppingConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1StudySpecStudyStoppingConfigPtrOutput) ToGoogleCloudAiplatformV1StudySpecStudyStoppingConfigPtrOutput() GoogleCloudAiplatformV1StudySpecStudyStoppingConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1StudySpecStudyStoppingConfigPtrOutput) ToGoogleCloudAiplatformV1StudySpecStudyStoppingConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecStudyStoppingConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1StudySpecStudyStoppingConfigPtrOutput) Elem() GoogleCloudAiplatformV1StudySpecStudyStoppingConfigOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1StudySpecStudyStoppingConfig) GoogleCloudAiplatformV1StudySpecStudyStoppingConfig {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1StudySpecStudyStoppingConfig
		return ret
	}).(GoogleCloudAiplatformV1StudySpecStudyStoppingConfigOutput)
}

// If the objective value has not improved for this much time, stop the study. WARNING: Effective only for single-objective studies.
func (o GoogleCloudAiplatformV1StudySpecStudyStoppingConfigPtrOutput) MaxDurationNoProgress() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1StudySpecStudyStoppingConfig) *string {
		if v == nil {
			return nil
		}
		return v.MaxDurationNoProgress
	}).(pulumi.StringPtrOutput)
}

// If there are more than this many trials, stop the study.
func (o GoogleCloudAiplatformV1StudySpecStudyStoppingConfigPtrOutput) MaxNumTrials() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1StudySpecStudyStoppingConfig) *int {
		if v == nil {
			return nil
		}
		return v.MaxNumTrials
	}).(pulumi.IntPtrOutput)
}

// If the objective value has not improved for this many consecutive trials, stop the study. WARNING: Effective only for single-objective studies.
func (o GoogleCloudAiplatformV1StudySpecStudyStoppingConfigPtrOutput) MaxNumTrialsNoProgress() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1StudySpecStudyStoppingConfig) *int {
		if v == nil {
			return nil
		}
		return v.MaxNumTrialsNoProgress
	}).(pulumi.IntPtrOutput)
}

// If the specified time or duration has passed, stop the study.
func (o GoogleCloudAiplatformV1StudySpecStudyStoppingConfigPtrOutput) MaximumRuntimeConstraint() GoogleCloudAiplatformV1StudyTimeConstraintPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1StudySpecStudyStoppingConfig) *GoogleCloudAiplatformV1StudyTimeConstraint {
		if v == nil {
			return nil
		}
		return v.MaximumRuntimeConstraint
	}).(GoogleCloudAiplatformV1StudyTimeConstraintPtrOutput)
}

// If there are fewer than this many COMPLETED trials, do not stop the study.
func (o GoogleCloudAiplatformV1StudySpecStudyStoppingConfigPtrOutput) MinNumTrials() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1StudySpecStudyStoppingConfig) *int {
		if v == nil {
			return nil
		}
		return v.MinNumTrials
	}).(pulumi.IntPtrOutput)
}

// Each "stopping rule" in this proto specifies an "if" condition. Before Vizier would generate a new suggestion, it first checks each specified stopping rule, from top to bottom in this list. Note that the first few rules (e.g. minimum_runtime_constraint, min_num_trials) will prevent other stopping rules from being evaluated until they are met. For example, setting `min_num_trials=5` and `always_stop_after= 1 hour` means that the Study will ONLY stop after it has 5 COMPLETED trials, even if more than an hour has passed since its creation. It follows the first applicable rule (whose "if" condition is satisfied) to make a stopping decision. If none of the specified rules are applicable, then Vizier decides that the study should not stop. If Vizier decides that the study should stop, the study enters STOPPING state (or STOPPING_ASAP if should_stop_asap = true). IMPORTANT: The automatic study state transition happens precisely as described above; that is, deleting trials or updating StudyConfig NEVER automatically moves the study state back to ACTIVE. If you want to _resume_ a Study that was stopped, 1) change the stopping conditions if necessary, 2) activate the study, and then 3) ask for suggestions. If the specified time or duration has not passed, do not stop the study.
func (o GoogleCloudAiplatformV1StudySpecStudyStoppingConfigPtrOutput) MinimumRuntimeConstraint() GoogleCloudAiplatformV1StudyTimeConstraintPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1StudySpecStudyStoppingConfig) *GoogleCloudAiplatformV1StudyTimeConstraint {
		if v == nil {
			return nil
		}
		return v.MinimumRuntimeConstraint
	}).(GoogleCloudAiplatformV1StudyTimeConstraintPtrOutput)
}

// If true, a Study enters STOPPING_ASAP whenever it would normally enters STOPPING state. The bottom line is: set to true if you want to interrupt on-going evaluations of Trials as soon as the study stopping condition is met. (Please see Study.State documentation for the source of truth).
func (o GoogleCloudAiplatformV1StudySpecStudyStoppingConfigPtrOutput) ShouldStopAsap() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1StudySpecStudyStoppingConfig) *bool {
		if v == nil {
			return nil
		}
		return v.ShouldStopAsap
	}).(pulumi.BoolPtrOutput)
}

// The configuration (stopping conditions) for automated stopping of a Study. Conditions include trial budgets, time budgets, and convergence detection.
type GoogleCloudAiplatformV1StudySpecStudyStoppingConfigResponse struct {
	// If the objective value has not improved for this much time, stop the study. WARNING: Effective only for single-objective studies.
	MaxDurationNoProgress string `pulumi:"maxDurationNoProgress"`
	// If there are more than this many trials, stop the study.
	MaxNumTrials int `pulumi:"maxNumTrials"`
	// If the objective value has not improved for this many consecutive trials, stop the study. WARNING: Effective only for single-objective studies.
	MaxNumTrialsNoProgress int `pulumi:"maxNumTrialsNoProgress"`
	// If the specified time or duration has passed, stop the study.
	MaximumRuntimeConstraint GoogleCloudAiplatformV1StudyTimeConstraintResponse `pulumi:"maximumRuntimeConstraint"`
	// If there are fewer than this many COMPLETED trials, do not stop the study.
	MinNumTrials int `pulumi:"minNumTrials"`
	// Each "stopping rule" in this proto specifies an "if" condition. Before Vizier would generate a new suggestion, it first checks each specified stopping rule, from top to bottom in this list. Note that the first few rules (e.g. minimum_runtime_constraint, min_num_trials) will prevent other stopping rules from being evaluated until they are met. For example, setting `min_num_trials=5` and `always_stop_after= 1 hour` means that the Study will ONLY stop after it has 5 COMPLETED trials, even if more than an hour has passed since its creation. It follows the first applicable rule (whose "if" condition is satisfied) to make a stopping decision. If none of the specified rules are applicable, then Vizier decides that the study should not stop. If Vizier decides that the study should stop, the study enters STOPPING state (or STOPPING_ASAP if should_stop_asap = true). IMPORTANT: The automatic study state transition happens precisely as described above; that is, deleting trials or updating StudyConfig NEVER automatically moves the study state back to ACTIVE. If you want to _resume_ a Study that was stopped, 1) change the stopping conditions if necessary, 2) activate the study, and then 3) ask for suggestions. If the specified time or duration has not passed, do not stop the study.
	MinimumRuntimeConstraint GoogleCloudAiplatformV1StudyTimeConstraintResponse `pulumi:"minimumRuntimeConstraint"`
	// If true, a Study enters STOPPING_ASAP whenever it would normally enters STOPPING state. The bottom line is: set to true if you want to interrupt on-going evaluations of Trials as soon as the study stopping condition is met. (Please see Study.State documentation for the source of truth).
	ShouldStopAsap bool `pulumi:"shouldStopAsap"`
}

// The configuration (stopping conditions) for automated stopping of a Study. Conditions include trial budgets, time budgets, and convergence detection.
type GoogleCloudAiplatformV1StudySpecStudyStoppingConfigResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1StudySpecStudyStoppingConfigResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1StudySpecStudyStoppingConfigResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1StudySpecStudyStoppingConfigResponseOutput) ToGoogleCloudAiplatformV1StudySpecStudyStoppingConfigResponseOutput() GoogleCloudAiplatformV1StudySpecStudyStoppingConfigResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1StudySpecStudyStoppingConfigResponseOutput) ToGoogleCloudAiplatformV1StudySpecStudyStoppingConfigResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudySpecStudyStoppingConfigResponseOutput {
	return o
}

// If the objective value has not improved for this much time, stop the study. WARNING: Effective only for single-objective studies.
func (o GoogleCloudAiplatformV1StudySpecStudyStoppingConfigResponseOutput) MaxDurationNoProgress() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpecStudyStoppingConfigResponse) string {
		return v.MaxDurationNoProgress
	}).(pulumi.StringOutput)
}

// If there are more than this many trials, stop the study.
func (o GoogleCloudAiplatformV1StudySpecStudyStoppingConfigResponseOutput) MaxNumTrials() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpecStudyStoppingConfigResponse) int { return v.MaxNumTrials }).(pulumi.IntOutput)
}

// If the objective value has not improved for this many consecutive trials, stop the study. WARNING: Effective only for single-objective studies.
func (o GoogleCloudAiplatformV1StudySpecStudyStoppingConfigResponseOutput) MaxNumTrialsNoProgress() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpecStudyStoppingConfigResponse) int {
		return v.MaxNumTrialsNoProgress
	}).(pulumi.IntOutput)
}

// If the specified time or duration has passed, stop the study.
func (o GoogleCloudAiplatformV1StudySpecStudyStoppingConfigResponseOutput) MaximumRuntimeConstraint() GoogleCloudAiplatformV1StudyTimeConstraintResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpecStudyStoppingConfigResponse) GoogleCloudAiplatformV1StudyTimeConstraintResponse {
		return v.MaximumRuntimeConstraint
	}).(GoogleCloudAiplatformV1StudyTimeConstraintResponseOutput)
}

// If there are fewer than this many COMPLETED trials, do not stop the study.
func (o GoogleCloudAiplatformV1StudySpecStudyStoppingConfigResponseOutput) MinNumTrials() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpecStudyStoppingConfigResponse) int { return v.MinNumTrials }).(pulumi.IntOutput)
}

// Each "stopping rule" in this proto specifies an "if" condition. Before Vizier would generate a new suggestion, it first checks each specified stopping rule, from top to bottom in this list. Note that the first few rules (e.g. minimum_runtime_constraint, min_num_trials) will prevent other stopping rules from being evaluated until they are met. For example, setting `min_num_trials=5` and `always_stop_after= 1 hour` means that the Study will ONLY stop after it has 5 COMPLETED trials, even if more than an hour has passed since its creation. It follows the first applicable rule (whose "if" condition is satisfied) to make a stopping decision. If none of the specified rules are applicable, then Vizier decides that the study should not stop. If Vizier decides that the study should stop, the study enters STOPPING state (or STOPPING_ASAP if should_stop_asap = true). IMPORTANT: The automatic study state transition happens precisely as described above; that is, deleting trials or updating StudyConfig NEVER automatically moves the study state back to ACTIVE. If you want to _resume_ a Study that was stopped, 1) change the stopping conditions if necessary, 2) activate the study, and then 3) ask for suggestions. If the specified time or duration has not passed, do not stop the study.
func (o GoogleCloudAiplatformV1StudySpecStudyStoppingConfigResponseOutput) MinimumRuntimeConstraint() GoogleCloudAiplatformV1StudyTimeConstraintResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpecStudyStoppingConfigResponse) GoogleCloudAiplatformV1StudyTimeConstraintResponse {
		return v.MinimumRuntimeConstraint
	}).(GoogleCloudAiplatformV1StudyTimeConstraintResponseOutput)
}

// If true, a Study enters STOPPING_ASAP whenever it would normally enters STOPPING state. The bottom line is: set to true if you want to interrupt on-going evaluations of Trials as soon as the study stopping condition is met. (Please see Study.State documentation for the source of truth).
func (o GoogleCloudAiplatformV1StudySpecStudyStoppingConfigResponseOutput) ShouldStopAsap() pulumi.BoolOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudySpecStudyStoppingConfigResponse) bool { return v.ShouldStopAsap }).(pulumi.BoolOutput)
}

// Time-based Constraint for Study
type GoogleCloudAiplatformV1StudyTimeConstraint struct {
	// Compares the wallclock time to this time. Must use UTC timezone.
	EndTime *string `pulumi:"endTime"`
	// Counts the wallclock time passed since the creation of this Study.
	MaxDuration *string `pulumi:"maxDuration"`
}

// GoogleCloudAiplatformV1StudyTimeConstraintInput is an input type that accepts GoogleCloudAiplatformV1StudyTimeConstraintArgs and GoogleCloudAiplatformV1StudyTimeConstraintOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1StudyTimeConstraintInput` via:
//
//	GoogleCloudAiplatformV1StudyTimeConstraintArgs{...}
type GoogleCloudAiplatformV1StudyTimeConstraintInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1StudyTimeConstraintOutput() GoogleCloudAiplatformV1StudyTimeConstraintOutput
	ToGoogleCloudAiplatformV1StudyTimeConstraintOutputWithContext(context.Context) GoogleCloudAiplatformV1StudyTimeConstraintOutput
}

// Time-based Constraint for Study
type GoogleCloudAiplatformV1StudyTimeConstraintArgs struct {
	// Compares the wallclock time to this time. Must use UTC timezone.
	EndTime pulumi.StringPtrInput `pulumi:"endTime"`
	// Counts the wallclock time passed since the creation of this Study.
	MaxDuration pulumi.StringPtrInput `pulumi:"maxDuration"`
}

func (GoogleCloudAiplatformV1StudyTimeConstraintArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1StudyTimeConstraint)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1StudyTimeConstraintArgs) ToGoogleCloudAiplatformV1StudyTimeConstraintOutput() GoogleCloudAiplatformV1StudyTimeConstraintOutput {
	return i.ToGoogleCloudAiplatformV1StudyTimeConstraintOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1StudyTimeConstraintArgs) ToGoogleCloudAiplatformV1StudyTimeConstraintOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudyTimeConstraintOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1StudyTimeConstraintOutput)
}

func (i GoogleCloudAiplatformV1StudyTimeConstraintArgs) ToGoogleCloudAiplatformV1StudyTimeConstraintPtrOutput() GoogleCloudAiplatformV1StudyTimeConstraintPtrOutput {
	return i.ToGoogleCloudAiplatformV1StudyTimeConstraintPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1StudyTimeConstraintArgs) ToGoogleCloudAiplatformV1StudyTimeConstraintPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudyTimeConstraintPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1StudyTimeConstraintOutput).ToGoogleCloudAiplatformV1StudyTimeConstraintPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1StudyTimeConstraintPtrInput is an input type that accepts GoogleCloudAiplatformV1StudyTimeConstraintArgs, GoogleCloudAiplatformV1StudyTimeConstraintPtr and GoogleCloudAiplatformV1StudyTimeConstraintPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1StudyTimeConstraintPtrInput` via:
//
//	        GoogleCloudAiplatformV1StudyTimeConstraintArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1StudyTimeConstraintPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1StudyTimeConstraintPtrOutput() GoogleCloudAiplatformV1StudyTimeConstraintPtrOutput
	ToGoogleCloudAiplatformV1StudyTimeConstraintPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1StudyTimeConstraintPtrOutput
}

type googleCloudAiplatformV1StudyTimeConstraintPtrType GoogleCloudAiplatformV1StudyTimeConstraintArgs

func GoogleCloudAiplatformV1StudyTimeConstraintPtr(v *GoogleCloudAiplatformV1StudyTimeConstraintArgs) GoogleCloudAiplatformV1StudyTimeConstraintPtrInput {
	return (*googleCloudAiplatformV1StudyTimeConstraintPtrType)(v)
}

func (*googleCloudAiplatformV1StudyTimeConstraintPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1StudyTimeConstraint)(nil)).Elem()
}

func (i *googleCloudAiplatformV1StudyTimeConstraintPtrType) ToGoogleCloudAiplatformV1StudyTimeConstraintPtrOutput() GoogleCloudAiplatformV1StudyTimeConstraintPtrOutput {
	return i.ToGoogleCloudAiplatformV1StudyTimeConstraintPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1StudyTimeConstraintPtrType) ToGoogleCloudAiplatformV1StudyTimeConstraintPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudyTimeConstraintPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1StudyTimeConstraintPtrOutput)
}

// Time-based Constraint for Study
type GoogleCloudAiplatformV1StudyTimeConstraintOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1StudyTimeConstraintOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1StudyTimeConstraint)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1StudyTimeConstraintOutput) ToGoogleCloudAiplatformV1StudyTimeConstraintOutput() GoogleCloudAiplatformV1StudyTimeConstraintOutput {
	return o
}

func (o GoogleCloudAiplatformV1StudyTimeConstraintOutput) ToGoogleCloudAiplatformV1StudyTimeConstraintOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudyTimeConstraintOutput {
	return o
}

func (o GoogleCloudAiplatformV1StudyTimeConstraintOutput) ToGoogleCloudAiplatformV1StudyTimeConstraintPtrOutput() GoogleCloudAiplatformV1StudyTimeConstraintPtrOutput {
	return o.ToGoogleCloudAiplatformV1StudyTimeConstraintPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1StudyTimeConstraintOutput) ToGoogleCloudAiplatformV1StudyTimeConstraintPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudyTimeConstraintPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1StudyTimeConstraint) *GoogleCloudAiplatformV1StudyTimeConstraint {
		return &v
	}).(GoogleCloudAiplatformV1StudyTimeConstraintPtrOutput)
}

// Compares the wallclock time to this time. Must use UTC timezone.
func (o GoogleCloudAiplatformV1StudyTimeConstraintOutput) EndTime() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudyTimeConstraint) *string { return v.EndTime }).(pulumi.StringPtrOutput)
}

// Counts the wallclock time passed since the creation of this Study.
func (o GoogleCloudAiplatformV1StudyTimeConstraintOutput) MaxDuration() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudyTimeConstraint) *string { return v.MaxDuration }).(pulumi.StringPtrOutput)
}

type GoogleCloudAiplatformV1StudyTimeConstraintPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1StudyTimeConstraintPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1StudyTimeConstraint)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1StudyTimeConstraintPtrOutput) ToGoogleCloudAiplatformV1StudyTimeConstraintPtrOutput() GoogleCloudAiplatformV1StudyTimeConstraintPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1StudyTimeConstraintPtrOutput) ToGoogleCloudAiplatformV1StudyTimeConstraintPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudyTimeConstraintPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1StudyTimeConstraintPtrOutput) Elem() GoogleCloudAiplatformV1StudyTimeConstraintOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1StudyTimeConstraint) GoogleCloudAiplatformV1StudyTimeConstraint {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1StudyTimeConstraint
		return ret
	}).(GoogleCloudAiplatformV1StudyTimeConstraintOutput)
}

// Compares the wallclock time to this time. Must use UTC timezone.
func (o GoogleCloudAiplatformV1StudyTimeConstraintPtrOutput) EndTime() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1StudyTimeConstraint) *string {
		if v == nil {
			return nil
		}
		return v.EndTime
	}).(pulumi.StringPtrOutput)
}

// Counts the wallclock time passed since the creation of this Study.
func (o GoogleCloudAiplatformV1StudyTimeConstraintPtrOutput) MaxDuration() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1StudyTimeConstraint) *string {
		if v == nil {
			return nil
		}
		return v.MaxDuration
	}).(pulumi.StringPtrOutput)
}

// Time-based Constraint for Study
type GoogleCloudAiplatformV1StudyTimeConstraintResponse struct {
	// Compares the wallclock time to this time. Must use UTC timezone.
	EndTime string `pulumi:"endTime"`
	// Counts the wallclock time passed since the creation of this Study.
	MaxDuration string `pulumi:"maxDuration"`
}

// Time-based Constraint for Study
type GoogleCloudAiplatformV1StudyTimeConstraintResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1StudyTimeConstraintResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1StudyTimeConstraintResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1StudyTimeConstraintResponseOutput) ToGoogleCloudAiplatformV1StudyTimeConstraintResponseOutput() GoogleCloudAiplatformV1StudyTimeConstraintResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1StudyTimeConstraintResponseOutput) ToGoogleCloudAiplatformV1StudyTimeConstraintResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1StudyTimeConstraintResponseOutput {
	return o
}

// Compares the wallclock time to this time. Must use UTC timezone.
func (o GoogleCloudAiplatformV1StudyTimeConstraintResponseOutput) EndTime() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudyTimeConstraintResponse) string { return v.EndTime }).(pulumi.StringOutput)
}

// Counts the wallclock time passed since the creation of this Study.
func (o GoogleCloudAiplatformV1StudyTimeConstraintResponseOutput) MaxDuration() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1StudyTimeConstraintResponse) string { return v.MaxDuration }).(pulumi.StringOutput)
}

// Describes metadata for a TensorboardTimeSeries.
type GoogleCloudAiplatformV1TensorboardTimeSeriesMetadataResponse struct {
	// The largest blob sequence length (number of blobs) of all data points in this time series, if its ValueType is BLOB_SEQUENCE.
	MaxBlobSequenceLength string `pulumi:"maxBlobSequenceLength"`
	// Max step index of all data points within a TensorboardTimeSeries.
	MaxStep string `pulumi:"maxStep"`
	// Max wall clock timestamp of all data points within a TensorboardTimeSeries.
	MaxWallTime string `pulumi:"maxWallTime"`
}

// Describes metadata for a TensorboardTimeSeries.
type GoogleCloudAiplatformV1TensorboardTimeSeriesMetadataResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1TensorboardTimeSeriesMetadataResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1TensorboardTimeSeriesMetadataResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1TensorboardTimeSeriesMetadataResponseOutput) ToGoogleCloudAiplatformV1TensorboardTimeSeriesMetadataResponseOutput() GoogleCloudAiplatformV1TensorboardTimeSeriesMetadataResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1TensorboardTimeSeriesMetadataResponseOutput) ToGoogleCloudAiplatformV1TensorboardTimeSeriesMetadataResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1TensorboardTimeSeriesMetadataResponseOutput {
	return o
}

// The largest blob sequence length (number of blobs) of all data points in this time series, if its ValueType is BLOB_SEQUENCE.
func (o GoogleCloudAiplatformV1TensorboardTimeSeriesMetadataResponseOutput) MaxBlobSequenceLength() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1TensorboardTimeSeriesMetadataResponse) string {
		return v.MaxBlobSequenceLength
	}).(pulumi.StringOutput)
}

// Max step index of all data points within a TensorboardTimeSeries.
func (o GoogleCloudAiplatformV1TensorboardTimeSeriesMetadataResponseOutput) MaxStep() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1TensorboardTimeSeriesMetadataResponse) string { return v.MaxStep }).(pulumi.StringOutput)
}

// Max wall clock timestamp of all data points within a TensorboardTimeSeries.
func (o GoogleCloudAiplatformV1TensorboardTimeSeriesMetadataResponseOutput) MaxWallTime() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1TensorboardTimeSeriesMetadataResponse) string { return v.MaxWallTime }).(pulumi.StringOutput)
}

// The config for feature monitoring threshold.
type GoogleCloudAiplatformV1ThresholdConfig struct {
	// Specify a threshold value that can trigger the alert. If this threshold config is for feature distribution distance: 1. For categorical feature, the distribution distance is calculated by L-inifinity norm. 2. For numerical feature, the distribution distance is calculated by Jensen–Shannon divergence. Each feature must have a non-zero threshold if they need to be monitored. Otherwise no alert will be triggered for that feature.
	Value *float64 `pulumi:"value"`
}

// GoogleCloudAiplatformV1ThresholdConfigInput is an input type that accepts GoogleCloudAiplatformV1ThresholdConfigArgs and GoogleCloudAiplatformV1ThresholdConfigOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1ThresholdConfigInput` via:
//
//	GoogleCloudAiplatformV1ThresholdConfigArgs{...}
type GoogleCloudAiplatformV1ThresholdConfigInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1ThresholdConfigOutput() GoogleCloudAiplatformV1ThresholdConfigOutput
	ToGoogleCloudAiplatformV1ThresholdConfigOutputWithContext(context.Context) GoogleCloudAiplatformV1ThresholdConfigOutput
}

// The config for feature monitoring threshold.
type GoogleCloudAiplatformV1ThresholdConfigArgs struct {
	// Specify a threshold value that can trigger the alert. If this threshold config is for feature distribution distance: 1. For categorical feature, the distribution distance is calculated by L-inifinity norm. 2. For numerical feature, the distribution distance is calculated by Jensen–Shannon divergence. Each feature must have a non-zero threshold if they need to be monitored. Otherwise no alert will be triggered for that feature.
	Value pulumi.Float64PtrInput `pulumi:"value"`
}

func (GoogleCloudAiplatformV1ThresholdConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1ThresholdConfig)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1ThresholdConfigArgs) ToGoogleCloudAiplatformV1ThresholdConfigOutput() GoogleCloudAiplatformV1ThresholdConfigOutput {
	return i.ToGoogleCloudAiplatformV1ThresholdConfigOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1ThresholdConfigArgs) ToGoogleCloudAiplatformV1ThresholdConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ThresholdConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1ThresholdConfigOutput)
}

func (i GoogleCloudAiplatformV1ThresholdConfigArgs) ToGoogleCloudAiplatformV1ThresholdConfigPtrOutput() GoogleCloudAiplatformV1ThresholdConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1ThresholdConfigPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1ThresholdConfigArgs) ToGoogleCloudAiplatformV1ThresholdConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ThresholdConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1ThresholdConfigOutput).ToGoogleCloudAiplatformV1ThresholdConfigPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1ThresholdConfigPtrInput is an input type that accepts GoogleCloudAiplatformV1ThresholdConfigArgs, GoogleCloudAiplatformV1ThresholdConfigPtr and GoogleCloudAiplatformV1ThresholdConfigPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1ThresholdConfigPtrInput` via:
//
//	        GoogleCloudAiplatformV1ThresholdConfigArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1ThresholdConfigPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1ThresholdConfigPtrOutput() GoogleCloudAiplatformV1ThresholdConfigPtrOutput
	ToGoogleCloudAiplatformV1ThresholdConfigPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1ThresholdConfigPtrOutput
}

type googleCloudAiplatformV1ThresholdConfigPtrType GoogleCloudAiplatformV1ThresholdConfigArgs

func GoogleCloudAiplatformV1ThresholdConfigPtr(v *GoogleCloudAiplatformV1ThresholdConfigArgs) GoogleCloudAiplatformV1ThresholdConfigPtrInput {
	return (*googleCloudAiplatformV1ThresholdConfigPtrType)(v)
}

func (*googleCloudAiplatformV1ThresholdConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1ThresholdConfig)(nil)).Elem()
}

func (i *googleCloudAiplatformV1ThresholdConfigPtrType) ToGoogleCloudAiplatformV1ThresholdConfigPtrOutput() GoogleCloudAiplatformV1ThresholdConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1ThresholdConfigPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1ThresholdConfigPtrType) ToGoogleCloudAiplatformV1ThresholdConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ThresholdConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1ThresholdConfigPtrOutput)
}

// GoogleCloudAiplatformV1ThresholdConfigMapInput is an input type that accepts GoogleCloudAiplatformV1ThresholdConfigMap and GoogleCloudAiplatformV1ThresholdConfigMapOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1ThresholdConfigMapInput` via:
//
//	GoogleCloudAiplatformV1ThresholdConfigMap{ "key": GoogleCloudAiplatformV1ThresholdConfigArgs{...} }
type GoogleCloudAiplatformV1ThresholdConfigMapInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1ThresholdConfigMapOutput() GoogleCloudAiplatformV1ThresholdConfigMapOutput
	ToGoogleCloudAiplatformV1ThresholdConfigMapOutputWithContext(context.Context) GoogleCloudAiplatformV1ThresholdConfigMapOutput
}

type GoogleCloudAiplatformV1ThresholdConfigMap map[string]GoogleCloudAiplatformV1ThresholdConfigInput

func (GoogleCloudAiplatformV1ThresholdConfigMap) ElementType() reflect.Type {
	return reflect.TypeOf((*map[string]GoogleCloudAiplatformV1ThresholdConfig)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1ThresholdConfigMap) ToGoogleCloudAiplatformV1ThresholdConfigMapOutput() GoogleCloudAiplatformV1ThresholdConfigMapOutput {
	return i.ToGoogleCloudAiplatformV1ThresholdConfigMapOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1ThresholdConfigMap) ToGoogleCloudAiplatformV1ThresholdConfigMapOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ThresholdConfigMapOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1ThresholdConfigMapOutput)
}

// The config for feature monitoring threshold.
type GoogleCloudAiplatformV1ThresholdConfigOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ThresholdConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1ThresholdConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ThresholdConfigOutput) ToGoogleCloudAiplatformV1ThresholdConfigOutput() GoogleCloudAiplatformV1ThresholdConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1ThresholdConfigOutput) ToGoogleCloudAiplatformV1ThresholdConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ThresholdConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1ThresholdConfigOutput) ToGoogleCloudAiplatformV1ThresholdConfigPtrOutput() GoogleCloudAiplatformV1ThresholdConfigPtrOutput {
	return o.ToGoogleCloudAiplatformV1ThresholdConfigPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1ThresholdConfigOutput) ToGoogleCloudAiplatformV1ThresholdConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ThresholdConfigPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1ThresholdConfig) *GoogleCloudAiplatformV1ThresholdConfig {
		return &v
	}).(GoogleCloudAiplatformV1ThresholdConfigPtrOutput)
}

// Specify a threshold value that can trigger the alert. If this threshold config is for feature distribution distance: 1. For categorical feature, the distribution distance is calculated by L-inifinity norm. 2. For numerical feature, the distribution distance is calculated by Jensen–Shannon divergence. Each feature must have a non-zero threshold if they need to be monitored. Otherwise no alert will be triggered for that feature.
func (o GoogleCloudAiplatformV1ThresholdConfigOutput) Value() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ThresholdConfig) *float64 { return v.Value }).(pulumi.Float64PtrOutput)
}

type GoogleCloudAiplatformV1ThresholdConfigPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ThresholdConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1ThresholdConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ThresholdConfigPtrOutput) ToGoogleCloudAiplatformV1ThresholdConfigPtrOutput() GoogleCloudAiplatformV1ThresholdConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1ThresholdConfigPtrOutput) ToGoogleCloudAiplatformV1ThresholdConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ThresholdConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1ThresholdConfigPtrOutput) Elem() GoogleCloudAiplatformV1ThresholdConfigOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1ThresholdConfig) GoogleCloudAiplatformV1ThresholdConfig {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1ThresholdConfig
		return ret
	}).(GoogleCloudAiplatformV1ThresholdConfigOutput)
}

// Specify a threshold value that can trigger the alert. If this threshold config is for feature distribution distance: 1. For categorical feature, the distribution distance is calculated by L-inifinity norm. 2. For numerical feature, the distribution distance is calculated by Jensen–Shannon divergence. Each feature must have a non-zero threshold if they need to be monitored. Otherwise no alert will be triggered for that feature.
func (o GoogleCloudAiplatformV1ThresholdConfigPtrOutput) Value() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1ThresholdConfig) *float64 {
		if v == nil {
			return nil
		}
		return v.Value
	}).(pulumi.Float64PtrOutput)
}

type GoogleCloudAiplatformV1ThresholdConfigMapOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ThresholdConfigMapOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*map[string]GoogleCloudAiplatformV1ThresholdConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ThresholdConfigMapOutput) ToGoogleCloudAiplatformV1ThresholdConfigMapOutput() GoogleCloudAiplatformV1ThresholdConfigMapOutput {
	return o
}

func (o GoogleCloudAiplatformV1ThresholdConfigMapOutput) ToGoogleCloudAiplatformV1ThresholdConfigMapOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ThresholdConfigMapOutput {
	return o
}

func (o GoogleCloudAiplatformV1ThresholdConfigMapOutput) MapIndex(k pulumi.StringInput) GoogleCloudAiplatformV1ThresholdConfigOutput {
	return pulumi.All(o, k).ApplyT(func(vs []interface{}) GoogleCloudAiplatformV1ThresholdConfig {
		return vs[0].(map[string]GoogleCloudAiplatformV1ThresholdConfig)[vs[1].(string)]
	}).(GoogleCloudAiplatformV1ThresholdConfigOutput)
}

// The config for feature monitoring threshold.
type GoogleCloudAiplatformV1ThresholdConfigResponse struct {
	// Specify a threshold value that can trigger the alert. If this threshold config is for feature distribution distance: 1. For categorical feature, the distribution distance is calculated by L-inifinity norm. 2. For numerical feature, the distribution distance is calculated by Jensen–Shannon divergence. Each feature must have a non-zero threshold if they need to be monitored. Otherwise no alert will be triggered for that feature.
	Value float64 `pulumi:"value"`
}

// The config for feature monitoring threshold.
type GoogleCloudAiplatformV1ThresholdConfigResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ThresholdConfigResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1ThresholdConfigResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ThresholdConfigResponseOutput) ToGoogleCloudAiplatformV1ThresholdConfigResponseOutput() GoogleCloudAiplatformV1ThresholdConfigResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1ThresholdConfigResponseOutput) ToGoogleCloudAiplatformV1ThresholdConfigResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ThresholdConfigResponseOutput {
	return o
}

// Specify a threshold value that can trigger the alert. If this threshold config is for feature distribution distance: 1. For categorical feature, the distribution distance is calculated by L-inifinity norm. 2. For numerical feature, the distribution distance is calculated by Jensen–Shannon divergence. Each feature must have a non-zero threshold if they need to be monitored. Otherwise no alert will be triggered for that feature.
func (o GoogleCloudAiplatformV1ThresholdConfigResponseOutput) Value() pulumi.Float64Output {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ThresholdConfigResponse) float64 { return v.Value }).(pulumi.Float64Output)
}

type GoogleCloudAiplatformV1ThresholdConfigResponseMapOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ThresholdConfigResponseMapOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*map[string]GoogleCloudAiplatformV1ThresholdConfigResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ThresholdConfigResponseMapOutput) ToGoogleCloudAiplatformV1ThresholdConfigResponseMapOutput() GoogleCloudAiplatformV1ThresholdConfigResponseMapOutput {
	return o
}

func (o GoogleCloudAiplatformV1ThresholdConfigResponseMapOutput) ToGoogleCloudAiplatformV1ThresholdConfigResponseMapOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ThresholdConfigResponseMapOutput {
	return o
}

func (o GoogleCloudAiplatformV1ThresholdConfigResponseMapOutput) MapIndex(k pulumi.StringInput) GoogleCloudAiplatformV1ThresholdConfigResponseOutput {
	return pulumi.All(o, k).ApplyT(func(vs []interface{}) GoogleCloudAiplatformV1ThresholdConfigResponse {
		return vs[0].(map[string]GoogleCloudAiplatformV1ThresholdConfigResponse)[vs[1].(string)]
	}).(GoogleCloudAiplatformV1ThresholdConfigResponseOutput)
}

// Assigns input data to training, validation, and test sets based on a provided timestamps. The youngest data pieces are assigned to training set, next to validation set, and the oldest to the test set. Supported only for tabular Datasets.
type GoogleCloudAiplatformV1TimestampSplit struct {
	// The key is a name of one of the Dataset's data columns. The values of the key (the values in the column) must be in RFC 3339 `date-time` format, where `time-offset` = `"Z"` (e.g. 1985-04-12T23:20:50.52Z). If for a piece of data the key is not present or has an invalid value, that piece is ignored by the pipeline.
	Key string `pulumi:"key"`
	// The fraction of the input data that is to be used to evaluate the Model.
	TestFraction *float64 `pulumi:"testFraction"`
	// The fraction of the input data that is to be used to train the Model.
	TrainingFraction *float64 `pulumi:"trainingFraction"`
	// The fraction of the input data that is to be used to validate the Model.
	ValidationFraction *float64 `pulumi:"validationFraction"`
}

// GoogleCloudAiplatformV1TimestampSplitInput is an input type that accepts GoogleCloudAiplatformV1TimestampSplitArgs and GoogleCloudAiplatformV1TimestampSplitOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1TimestampSplitInput` via:
//
//	GoogleCloudAiplatformV1TimestampSplitArgs{...}
type GoogleCloudAiplatformV1TimestampSplitInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1TimestampSplitOutput() GoogleCloudAiplatformV1TimestampSplitOutput
	ToGoogleCloudAiplatformV1TimestampSplitOutputWithContext(context.Context) GoogleCloudAiplatformV1TimestampSplitOutput
}

// Assigns input data to training, validation, and test sets based on a provided timestamps. The youngest data pieces are assigned to training set, next to validation set, and the oldest to the test set. Supported only for tabular Datasets.
type GoogleCloudAiplatformV1TimestampSplitArgs struct {
	// The key is a name of one of the Dataset's data columns. The values of the key (the values in the column) must be in RFC 3339 `date-time` format, where `time-offset` = `"Z"` (e.g. 1985-04-12T23:20:50.52Z). If for a piece of data the key is not present or has an invalid value, that piece is ignored by the pipeline.
	Key pulumi.StringInput `pulumi:"key"`
	// The fraction of the input data that is to be used to evaluate the Model.
	TestFraction pulumi.Float64PtrInput `pulumi:"testFraction"`
	// The fraction of the input data that is to be used to train the Model.
	TrainingFraction pulumi.Float64PtrInput `pulumi:"trainingFraction"`
	// The fraction of the input data that is to be used to validate the Model.
	ValidationFraction pulumi.Float64PtrInput `pulumi:"validationFraction"`
}

func (GoogleCloudAiplatformV1TimestampSplitArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1TimestampSplit)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1TimestampSplitArgs) ToGoogleCloudAiplatformV1TimestampSplitOutput() GoogleCloudAiplatformV1TimestampSplitOutput {
	return i.ToGoogleCloudAiplatformV1TimestampSplitOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1TimestampSplitArgs) ToGoogleCloudAiplatformV1TimestampSplitOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1TimestampSplitOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1TimestampSplitOutput)
}

func (i GoogleCloudAiplatformV1TimestampSplitArgs) ToGoogleCloudAiplatformV1TimestampSplitPtrOutput() GoogleCloudAiplatformV1TimestampSplitPtrOutput {
	return i.ToGoogleCloudAiplatformV1TimestampSplitPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1TimestampSplitArgs) ToGoogleCloudAiplatformV1TimestampSplitPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1TimestampSplitPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1TimestampSplitOutput).ToGoogleCloudAiplatformV1TimestampSplitPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1TimestampSplitPtrInput is an input type that accepts GoogleCloudAiplatformV1TimestampSplitArgs, GoogleCloudAiplatformV1TimestampSplitPtr and GoogleCloudAiplatformV1TimestampSplitPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1TimestampSplitPtrInput` via:
//
//	        GoogleCloudAiplatformV1TimestampSplitArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1TimestampSplitPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1TimestampSplitPtrOutput() GoogleCloudAiplatformV1TimestampSplitPtrOutput
	ToGoogleCloudAiplatformV1TimestampSplitPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1TimestampSplitPtrOutput
}

type googleCloudAiplatformV1TimestampSplitPtrType GoogleCloudAiplatformV1TimestampSplitArgs

func GoogleCloudAiplatformV1TimestampSplitPtr(v *GoogleCloudAiplatformV1TimestampSplitArgs) GoogleCloudAiplatformV1TimestampSplitPtrInput {
	return (*googleCloudAiplatformV1TimestampSplitPtrType)(v)
}

func (*googleCloudAiplatformV1TimestampSplitPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1TimestampSplit)(nil)).Elem()
}

func (i *googleCloudAiplatformV1TimestampSplitPtrType) ToGoogleCloudAiplatformV1TimestampSplitPtrOutput() GoogleCloudAiplatformV1TimestampSplitPtrOutput {
	return i.ToGoogleCloudAiplatformV1TimestampSplitPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1TimestampSplitPtrType) ToGoogleCloudAiplatformV1TimestampSplitPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1TimestampSplitPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1TimestampSplitPtrOutput)
}

// Assigns input data to training, validation, and test sets based on a provided timestamps. The youngest data pieces are assigned to training set, next to validation set, and the oldest to the test set. Supported only for tabular Datasets.
type GoogleCloudAiplatformV1TimestampSplitOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1TimestampSplitOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1TimestampSplit)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1TimestampSplitOutput) ToGoogleCloudAiplatformV1TimestampSplitOutput() GoogleCloudAiplatformV1TimestampSplitOutput {
	return o
}

func (o GoogleCloudAiplatformV1TimestampSplitOutput) ToGoogleCloudAiplatformV1TimestampSplitOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1TimestampSplitOutput {
	return o
}

func (o GoogleCloudAiplatformV1TimestampSplitOutput) ToGoogleCloudAiplatformV1TimestampSplitPtrOutput() GoogleCloudAiplatformV1TimestampSplitPtrOutput {
	return o.ToGoogleCloudAiplatformV1TimestampSplitPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1TimestampSplitOutput) ToGoogleCloudAiplatformV1TimestampSplitPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1TimestampSplitPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1TimestampSplit) *GoogleCloudAiplatformV1TimestampSplit {
		return &v
	}).(GoogleCloudAiplatformV1TimestampSplitPtrOutput)
}

// The key is a name of one of the Dataset's data columns. The values of the key (the values in the column) must be in RFC 3339 `date-time` format, where `time-offset` = `"Z"` (e.g. 1985-04-12T23:20:50.52Z). If for a piece of data the key is not present or has an invalid value, that piece is ignored by the pipeline.
func (o GoogleCloudAiplatformV1TimestampSplitOutput) Key() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1TimestampSplit) string { return v.Key }).(pulumi.StringOutput)
}

// The fraction of the input data that is to be used to evaluate the Model.
func (o GoogleCloudAiplatformV1TimestampSplitOutput) TestFraction() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1TimestampSplit) *float64 { return v.TestFraction }).(pulumi.Float64PtrOutput)
}

// The fraction of the input data that is to be used to train the Model.
func (o GoogleCloudAiplatformV1TimestampSplitOutput) TrainingFraction() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1TimestampSplit) *float64 { return v.TrainingFraction }).(pulumi.Float64PtrOutput)
}

// The fraction of the input data that is to be used to validate the Model.
func (o GoogleCloudAiplatformV1TimestampSplitOutput) ValidationFraction() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1TimestampSplit) *float64 { return v.ValidationFraction }).(pulumi.Float64PtrOutput)
}

type GoogleCloudAiplatformV1TimestampSplitPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1TimestampSplitPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1TimestampSplit)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1TimestampSplitPtrOutput) ToGoogleCloudAiplatformV1TimestampSplitPtrOutput() GoogleCloudAiplatformV1TimestampSplitPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1TimestampSplitPtrOutput) ToGoogleCloudAiplatformV1TimestampSplitPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1TimestampSplitPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1TimestampSplitPtrOutput) Elem() GoogleCloudAiplatformV1TimestampSplitOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1TimestampSplit) GoogleCloudAiplatformV1TimestampSplit {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1TimestampSplit
		return ret
	}).(GoogleCloudAiplatformV1TimestampSplitOutput)
}

// The key is a name of one of the Dataset's data columns. The values of the key (the values in the column) must be in RFC 3339 `date-time` format, where `time-offset` = `"Z"` (e.g. 1985-04-12T23:20:50.52Z). If for a piece of data the key is not present or has an invalid value, that piece is ignored by the pipeline.
func (o GoogleCloudAiplatformV1TimestampSplitPtrOutput) Key() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1TimestampSplit) *string {
		if v == nil {
			return nil
		}
		return &v.Key
	}).(pulumi.StringPtrOutput)
}

// The fraction of the input data that is to be used to evaluate the Model.
func (o GoogleCloudAiplatformV1TimestampSplitPtrOutput) TestFraction() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1TimestampSplit) *float64 {
		if v == nil {
			return nil
		}
		return v.TestFraction
	}).(pulumi.Float64PtrOutput)
}

// The fraction of the input data that is to be used to train the Model.
func (o GoogleCloudAiplatformV1TimestampSplitPtrOutput) TrainingFraction() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1TimestampSplit) *float64 {
		if v == nil {
			return nil
		}
		return v.TrainingFraction
	}).(pulumi.Float64PtrOutput)
}

// The fraction of the input data that is to be used to validate the Model.
func (o GoogleCloudAiplatformV1TimestampSplitPtrOutput) ValidationFraction() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1TimestampSplit) *float64 {
		if v == nil {
			return nil
		}
		return v.ValidationFraction
	}).(pulumi.Float64PtrOutput)
}

// Assigns input data to training, validation, and test sets based on a provided timestamps. The youngest data pieces are assigned to training set, next to validation set, and the oldest to the test set. Supported only for tabular Datasets.
type GoogleCloudAiplatformV1TimestampSplitResponse struct {
	// The key is a name of one of the Dataset's data columns. The values of the key (the values in the column) must be in RFC 3339 `date-time` format, where `time-offset` = `"Z"` (e.g. 1985-04-12T23:20:50.52Z). If for a piece of data the key is not present or has an invalid value, that piece is ignored by the pipeline.
	Key string `pulumi:"key"`
	// The fraction of the input data that is to be used to evaluate the Model.
	TestFraction float64 `pulumi:"testFraction"`
	// The fraction of the input data that is to be used to train the Model.
	TrainingFraction float64 `pulumi:"trainingFraction"`
	// The fraction of the input data that is to be used to validate the Model.
	ValidationFraction float64 `pulumi:"validationFraction"`
}

// Assigns input data to training, validation, and test sets based on a provided timestamps. The youngest data pieces are assigned to training set, next to validation set, and the oldest to the test set. Supported only for tabular Datasets.
type GoogleCloudAiplatformV1TimestampSplitResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1TimestampSplitResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1TimestampSplitResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1TimestampSplitResponseOutput) ToGoogleCloudAiplatformV1TimestampSplitResponseOutput() GoogleCloudAiplatformV1TimestampSplitResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1TimestampSplitResponseOutput) ToGoogleCloudAiplatformV1TimestampSplitResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1TimestampSplitResponseOutput {
	return o
}

// The key is a name of one of the Dataset's data columns. The values of the key (the values in the column) must be in RFC 3339 `date-time` format, where `time-offset` = `"Z"` (e.g. 1985-04-12T23:20:50.52Z). If for a piece of data the key is not present or has an invalid value, that piece is ignored by the pipeline.
func (o GoogleCloudAiplatformV1TimestampSplitResponseOutput) Key() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1TimestampSplitResponse) string { return v.Key }).(pulumi.StringOutput)
}

// The fraction of the input data that is to be used to evaluate the Model.
func (o GoogleCloudAiplatformV1TimestampSplitResponseOutput) TestFraction() pulumi.Float64Output {
	return o.ApplyT(func(v GoogleCloudAiplatformV1TimestampSplitResponse) float64 { return v.TestFraction }).(pulumi.Float64Output)
}

// The fraction of the input data that is to be used to train the Model.
func (o GoogleCloudAiplatformV1TimestampSplitResponseOutput) TrainingFraction() pulumi.Float64Output {
	return o.ApplyT(func(v GoogleCloudAiplatformV1TimestampSplitResponse) float64 { return v.TrainingFraction }).(pulumi.Float64Output)
}

// The fraction of the input data that is to be used to validate the Model.
func (o GoogleCloudAiplatformV1TimestampSplitResponseOutput) ValidationFraction() pulumi.Float64Output {
	return o.ApplyT(func(v GoogleCloudAiplatformV1TimestampSplitResponse) float64 { return v.ValidationFraction }).(pulumi.Float64Output)
}

// CMLE training config. For every active learning labeling iteration, system will train a machine learning model on CMLE. The trained model will be used by data sampling algorithm to select DataItems.
type GoogleCloudAiplatformV1TrainingConfig struct {
	// The timeout hours for the CMLE training job, expressed in milli hours i.e. 1,000 value in this field means 1 hour.
	TimeoutTrainingMilliHours *string `pulumi:"timeoutTrainingMilliHours"`
}

// GoogleCloudAiplatformV1TrainingConfigInput is an input type that accepts GoogleCloudAiplatformV1TrainingConfigArgs and GoogleCloudAiplatformV1TrainingConfigOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1TrainingConfigInput` via:
//
//	GoogleCloudAiplatformV1TrainingConfigArgs{...}
type GoogleCloudAiplatformV1TrainingConfigInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1TrainingConfigOutput() GoogleCloudAiplatformV1TrainingConfigOutput
	ToGoogleCloudAiplatformV1TrainingConfigOutputWithContext(context.Context) GoogleCloudAiplatformV1TrainingConfigOutput
}

// CMLE training config. For every active learning labeling iteration, system will train a machine learning model on CMLE. The trained model will be used by data sampling algorithm to select DataItems.
type GoogleCloudAiplatformV1TrainingConfigArgs struct {
	// The timeout hours for the CMLE training job, expressed in milli hours i.e. 1,000 value in this field means 1 hour.
	TimeoutTrainingMilliHours pulumi.StringPtrInput `pulumi:"timeoutTrainingMilliHours"`
}

func (GoogleCloudAiplatformV1TrainingConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1TrainingConfig)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1TrainingConfigArgs) ToGoogleCloudAiplatformV1TrainingConfigOutput() GoogleCloudAiplatformV1TrainingConfigOutput {
	return i.ToGoogleCloudAiplatformV1TrainingConfigOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1TrainingConfigArgs) ToGoogleCloudAiplatformV1TrainingConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1TrainingConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1TrainingConfigOutput)
}

func (i GoogleCloudAiplatformV1TrainingConfigArgs) ToGoogleCloudAiplatformV1TrainingConfigPtrOutput() GoogleCloudAiplatformV1TrainingConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1TrainingConfigPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1TrainingConfigArgs) ToGoogleCloudAiplatformV1TrainingConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1TrainingConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1TrainingConfigOutput).ToGoogleCloudAiplatformV1TrainingConfigPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1TrainingConfigPtrInput is an input type that accepts GoogleCloudAiplatformV1TrainingConfigArgs, GoogleCloudAiplatformV1TrainingConfigPtr and GoogleCloudAiplatformV1TrainingConfigPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1TrainingConfigPtrInput` via:
//
//	        GoogleCloudAiplatformV1TrainingConfigArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1TrainingConfigPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1TrainingConfigPtrOutput() GoogleCloudAiplatformV1TrainingConfigPtrOutput
	ToGoogleCloudAiplatformV1TrainingConfigPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1TrainingConfigPtrOutput
}

type googleCloudAiplatformV1TrainingConfigPtrType GoogleCloudAiplatformV1TrainingConfigArgs

func GoogleCloudAiplatformV1TrainingConfigPtr(v *GoogleCloudAiplatformV1TrainingConfigArgs) GoogleCloudAiplatformV1TrainingConfigPtrInput {
	return (*googleCloudAiplatformV1TrainingConfigPtrType)(v)
}

func (*googleCloudAiplatformV1TrainingConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1TrainingConfig)(nil)).Elem()
}

func (i *googleCloudAiplatformV1TrainingConfigPtrType) ToGoogleCloudAiplatformV1TrainingConfigPtrOutput() GoogleCloudAiplatformV1TrainingConfigPtrOutput {
	return i.ToGoogleCloudAiplatformV1TrainingConfigPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1TrainingConfigPtrType) ToGoogleCloudAiplatformV1TrainingConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1TrainingConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1TrainingConfigPtrOutput)
}

// CMLE training config. For every active learning labeling iteration, system will train a machine learning model on CMLE. The trained model will be used by data sampling algorithm to select DataItems.
type GoogleCloudAiplatformV1TrainingConfigOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1TrainingConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1TrainingConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1TrainingConfigOutput) ToGoogleCloudAiplatformV1TrainingConfigOutput() GoogleCloudAiplatformV1TrainingConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1TrainingConfigOutput) ToGoogleCloudAiplatformV1TrainingConfigOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1TrainingConfigOutput {
	return o
}

func (o GoogleCloudAiplatformV1TrainingConfigOutput) ToGoogleCloudAiplatformV1TrainingConfigPtrOutput() GoogleCloudAiplatformV1TrainingConfigPtrOutput {
	return o.ToGoogleCloudAiplatformV1TrainingConfigPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1TrainingConfigOutput) ToGoogleCloudAiplatformV1TrainingConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1TrainingConfigPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1TrainingConfig) *GoogleCloudAiplatformV1TrainingConfig {
		return &v
	}).(GoogleCloudAiplatformV1TrainingConfigPtrOutput)
}

// The timeout hours for the CMLE training job, expressed in milli hours i.e. 1,000 value in this field means 1 hour.
func (o GoogleCloudAiplatformV1TrainingConfigOutput) TimeoutTrainingMilliHours() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1TrainingConfig) *string { return v.TimeoutTrainingMilliHours }).(pulumi.StringPtrOutput)
}

type GoogleCloudAiplatformV1TrainingConfigPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1TrainingConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1TrainingConfig)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1TrainingConfigPtrOutput) ToGoogleCloudAiplatformV1TrainingConfigPtrOutput() GoogleCloudAiplatformV1TrainingConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1TrainingConfigPtrOutput) ToGoogleCloudAiplatformV1TrainingConfigPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1TrainingConfigPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1TrainingConfigPtrOutput) Elem() GoogleCloudAiplatformV1TrainingConfigOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1TrainingConfig) GoogleCloudAiplatformV1TrainingConfig {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1TrainingConfig
		return ret
	}).(GoogleCloudAiplatformV1TrainingConfigOutput)
}

// The timeout hours for the CMLE training job, expressed in milli hours i.e. 1,000 value in this field means 1 hour.
func (o GoogleCloudAiplatformV1TrainingConfigPtrOutput) TimeoutTrainingMilliHours() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1TrainingConfig) *string {
		if v == nil {
			return nil
		}
		return v.TimeoutTrainingMilliHours
	}).(pulumi.StringPtrOutput)
}

// CMLE training config. For every active learning labeling iteration, system will train a machine learning model on CMLE. The trained model will be used by data sampling algorithm to select DataItems.
type GoogleCloudAiplatformV1TrainingConfigResponse struct {
	// The timeout hours for the CMLE training job, expressed in milli hours i.e. 1,000 value in this field means 1 hour.
	TimeoutTrainingMilliHours string `pulumi:"timeoutTrainingMilliHours"`
}

// CMLE training config. For every active learning labeling iteration, system will train a machine learning model on CMLE. The trained model will be used by data sampling algorithm to select DataItems.
type GoogleCloudAiplatformV1TrainingConfigResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1TrainingConfigResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1TrainingConfigResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1TrainingConfigResponseOutput) ToGoogleCloudAiplatformV1TrainingConfigResponseOutput() GoogleCloudAiplatformV1TrainingConfigResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1TrainingConfigResponseOutput) ToGoogleCloudAiplatformV1TrainingConfigResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1TrainingConfigResponseOutput {
	return o
}

// The timeout hours for the CMLE training job, expressed in milli hours i.e. 1,000 value in this field means 1 hour.
func (o GoogleCloudAiplatformV1TrainingConfigResponseOutput) TimeoutTrainingMilliHours() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1TrainingConfigResponse) string { return v.TimeoutTrainingMilliHours }).(pulumi.StringOutput)
}

// A message representing a parameter to be tuned.
type GoogleCloudAiplatformV1TrialParameterResponse struct {
	// The ID of the parameter. The parameter should be defined in StudySpec's Parameters.
	ParameterId string `pulumi:"parameterId"`
	// The value of the parameter. `number_value` will be set if a parameter defined in StudySpec is in type 'INTEGER', 'DOUBLE' or 'DISCRETE'. `string_value` will be set if a parameter defined in StudySpec is in type 'CATEGORICAL'.
	Value interface{} `pulumi:"value"`
}

// A message representing a parameter to be tuned.
type GoogleCloudAiplatformV1TrialParameterResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1TrialParameterResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1TrialParameterResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1TrialParameterResponseOutput) ToGoogleCloudAiplatformV1TrialParameterResponseOutput() GoogleCloudAiplatformV1TrialParameterResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1TrialParameterResponseOutput) ToGoogleCloudAiplatformV1TrialParameterResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1TrialParameterResponseOutput {
	return o
}

// The ID of the parameter. The parameter should be defined in StudySpec's Parameters.
func (o GoogleCloudAiplatformV1TrialParameterResponseOutput) ParameterId() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1TrialParameterResponse) string { return v.ParameterId }).(pulumi.StringOutput)
}

// The value of the parameter. `number_value` will be set if a parameter defined in StudySpec is in type 'INTEGER', 'DOUBLE' or 'DISCRETE'. `string_value` will be set if a parameter defined in StudySpec is in type 'CATEGORICAL'.
func (o GoogleCloudAiplatformV1TrialParameterResponseOutput) Value() pulumi.AnyOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1TrialParameterResponse) interface{} { return v.Value }).(pulumi.AnyOutput)
}

type GoogleCloudAiplatformV1TrialParameterResponseArrayOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1TrialParameterResponseArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1TrialParameterResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1TrialParameterResponseArrayOutput) ToGoogleCloudAiplatformV1TrialParameterResponseArrayOutput() GoogleCloudAiplatformV1TrialParameterResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1TrialParameterResponseArrayOutput) ToGoogleCloudAiplatformV1TrialParameterResponseArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1TrialParameterResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1TrialParameterResponseArrayOutput) Index(i pulumi.IntInput) GoogleCloudAiplatformV1TrialParameterResponseOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GoogleCloudAiplatformV1TrialParameterResponse {
		return vs[0].([]GoogleCloudAiplatformV1TrialParameterResponse)[vs[1].(int)]
	}).(GoogleCloudAiplatformV1TrialParameterResponseOutput)
}

// A message representing a Trial. A Trial contains a unique set of Parameters that has been or will be evaluated, along with the objective metrics got by running the Trial.
type GoogleCloudAiplatformV1TrialResponse struct {
	// The identifier of the client that originally requested this Trial. Each client is identified by a unique client_id. When a client asks for a suggestion, Vertex AI Vizier will assign it a Trial. The client should evaluate the Trial, complete it, and report back to Vertex AI Vizier. If suggestion is asked again by same client_id before the Trial is completed, the same Trial will be returned. Multiple clients with different client_ids can ask for suggestions simultaneously, each of them will get their own Trial.
	ClientId string `pulumi:"clientId"`
	// The CustomJob name linked to the Trial. It's set for a HyperparameterTuningJob's Trial.
	CustomJob string `pulumi:"customJob"`
	// Time when the Trial's status changed to `SUCCEEDED` or `INFEASIBLE`.
	EndTime string `pulumi:"endTime"`
	// The final measurement containing the objective value.
	FinalMeasurement GoogleCloudAiplatformV1MeasurementResponse `pulumi:"finalMeasurement"`
	// A human readable string describing why the Trial is infeasible. This is set only if Trial state is `INFEASIBLE`.
	InfeasibleReason string `pulumi:"infeasibleReason"`
	// A list of measurements that are strictly lexicographically ordered by their induced tuples (steps, elapsed_duration). These are used for early stopping computations.
	Measurements []GoogleCloudAiplatformV1MeasurementResponse `pulumi:"measurements"`
	// Resource name of the Trial assigned by the service.
	Name string `pulumi:"name"`
	// The parameters of the Trial.
	Parameters []GoogleCloudAiplatformV1TrialParameterResponse `pulumi:"parameters"`
	// Time when the Trial was started.
	StartTime string `pulumi:"startTime"`
	// The detailed state of the Trial.
	State string `pulumi:"state"`
	// URIs for accessing [interactive shells](https://cloud.google.com/vertex-ai/docs/training/monitor-debug-interactive-shell) (one URI for each training node). Only available if this trial is part of a HyperparameterTuningJob and the job's trial_job_spec.enable_web_access field is `true`. The keys are names of each node used for the trial; for example, `workerpool0-0` for the primary node, `workerpool1-0` for the first node in the second worker pool, and `workerpool1-1` for the second node in the second worker pool. The values are the URIs for each node's interactive shell.
	WebAccessUris map[string]string `pulumi:"webAccessUris"`
}

// A message representing a Trial. A Trial contains a unique set of Parameters that has been or will be evaluated, along with the objective metrics got by running the Trial.
type GoogleCloudAiplatformV1TrialResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1TrialResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1TrialResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1TrialResponseOutput) ToGoogleCloudAiplatformV1TrialResponseOutput() GoogleCloudAiplatformV1TrialResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1TrialResponseOutput) ToGoogleCloudAiplatformV1TrialResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1TrialResponseOutput {
	return o
}

// The identifier of the client that originally requested this Trial. Each client is identified by a unique client_id. When a client asks for a suggestion, Vertex AI Vizier will assign it a Trial. The client should evaluate the Trial, complete it, and report back to Vertex AI Vizier. If suggestion is asked again by same client_id before the Trial is completed, the same Trial will be returned. Multiple clients with different client_ids can ask for suggestions simultaneously, each of them will get their own Trial.
func (o GoogleCloudAiplatformV1TrialResponseOutput) ClientId() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1TrialResponse) string { return v.ClientId }).(pulumi.StringOutput)
}

// The CustomJob name linked to the Trial. It's set for a HyperparameterTuningJob's Trial.
func (o GoogleCloudAiplatformV1TrialResponseOutput) CustomJob() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1TrialResponse) string { return v.CustomJob }).(pulumi.StringOutput)
}

// Time when the Trial's status changed to `SUCCEEDED` or `INFEASIBLE`.
func (o GoogleCloudAiplatformV1TrialResponseOutput) EndTime() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1TrialResponse) string { return v.EndTime }).(pulumi.StringOutput)
}

// The final measurement containing the objective value.
func (o GoogleCloudAiplatformV1TrialResponseOutput) FinalMeasurement() GoogleCloudAiplatformV1MeasurementResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1TrialResponse) GoogleCloudAiplatformV1MeasurementResponse {
		return v.FinalMeasurement
	}).(GoogleCloudAiplatformV1MeasurementResponseOutput)
}

// A human readable string describing why the Trial is infeasible. This is set only if Trial state is `INFEASIBLE`.
func (o GoogleCloudAiplatformV1TrialResponseOutput) InfeasibleReason() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1TrialResponse) string { return v.InfeasibleReason }).(pulumi.StringOutput)
}

// A list of measurements that are strictly lexicographically ordered by their induced tuples (steps, elapsed_duration). These are used for early stopping computations.
func (o GoogleCloudAiplatformV1TrialResponseOutput) Measurements() GoogleCloudAiplatformV1MeasurementResponseArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1TrialResponse) []GoogleCloudAiplatformV1MeasurementResponse {
		return v.Measurements
	}).(GoogleCloudAiplatformV1MeasurementResponseArrayOutput)
}

// Resource name of the Trial assigned by the service.
func (o GoogleCloudAiplatformV1TrialResponseOutput) Name() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1TrialResponse) string { return v.Name }).(pulumi.StringOutput)
}

// The parameters of the Trial.
func (o GoogleCloudAiplatformV1TrialResponseOutput) Parameters() GoogleCloudAiplatformV1TrialParameterResponseArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1TrialResponse) []GoogleCloudAiplatformV1TrialParameterResponse {
		return v.Parameters
	}).(GoogleCloudAiplatformV1TrialParameterResponseArrayOutput)
}

// Time when the Trial was started.
func (o GoogleCloudAiplatformV1TrialResponseOutput) StartTime() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1TrialResponse) string { return v.StartTime }).(pulumi.StringOutput)
}

// The detailed state of the Trial.
func (o GoogleCloudAiplatformV1TrialResponseOutput) State() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1TrialResponse) string { return v.State }).(pulumi.StringOutput)
}

// URIs for accessing [interactive shells](https://cloud.google.com/vertex-ai/docs/training/monitor-debug-interactive-shell) (one URI for each training node). Only available if this trial is part of a HyperparameterTuningJob and the job's trial_job_spec.enable_web_access field is `true`. The keys are names of each node used for the trial; for example, `workerpool0-0` for the primary node, `workerpool1-0` for the first node in the second worker pool, and `workerpool1-1` for the second node in the second worker pool. The values are the URIs for each node's interactive shell.
func (o GoogleCloudAiplatformV1TrialResponseOutput) WebAccessUris() pulumi.StringMapOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1TrialResponse) map[string]string { return v.WebAccessUris }).(pulumi.StringMapOutput)
}

type GoogleCloudAiplatformV1TrialResponseArrayOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1TrialResponseArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1TrialResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1TrialResponseArrayOutput) ToGoogleCloudAiplatformV1TrialResponseArrayOutput() GoogleCloudAiplatformV1TrialResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1TrialResponseArrayOutput) ToGoogleCloudAiplatformV1TrialResponseArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1TrialResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1TrialResponseArrayOutput) Index(i pulumi.IntInput) GoogleCloudAiplatformV1TrialResponseOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GoogleCloudAiplatformV1TrialResponse {
		return vs[0].([]GoogleCloudAiplatformV1TrialResponse)[vs[1].(int)]
	}).(GoogleCloudAiplatformV1TrialResponseOutput)
}

// Contains model information necessary to perform batch prediction without requiring a full model import.
type GoogleCloudAiplatformV1UnmanagedContainerModel struct {
	// The path to the directory containing the Model artifact and any of its supporting files.
	ArtifactUri *string `pulumi:"artifactUri"`
	// Input only. The specification of the container that is to be used when deploying this Model.
	ContainerSpec *GoogleCloudAiplatformV1ModelContainerSpec `pulumi:"containerSpec"`
	// Contains the schemata used in Model's predictions and explanations
	PredictSchemata *GoogleCloudAiplatformV1PredictSchemata `pulumi:"predictSchemata"`
}

// GoogleCloudAiplatformV1UnmanagedContainerModelInput is an input type that accepts GoogleCloudAiplatformV1UnmanagedContainerModelArgs and GoogleCloudAiplatformV1UnmanagedContainerModelOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1UnmanagedContainerModelInput` via:
//
//	GoogleCloudAiplatformV1UnmanagedContainerModelArgs{...}
type GoogleCloudAiplatformV1UnmanagedContainerModelInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1UnmanagedContainerModelOutput() GoogleCloudAiplatformV1UnmanagedContainerModelOutput
	ToGoogleCloudAiplatformV1UnmanagedContainerModelOutputWithContext(context.Context) GoogleCloudAiplatformV1UnmanagedContainerModelOutput
}

// Contains model information necessary to perform batch prediction without requiring a full model import.
type GoogleCloudAiplatformV1UnmanagedContainerModelArgs struct {
	// The path to the directory containing the Model artifact and any of its supporting files.
	ArtifactUri pulumi.StringPtrInput `pulumi:"artifactUri"`
	// Input only. The specification of the container that is to be used when deploying this Model.
	ContainerSpec GoogleCloudAiplatformV1ModelContainerSpecPtrInput `pulumi:"containerSpec"`
	// Contains the schemata used in Model's predictions and explanations
	PredictSchemata GoogleCloudAiplatformV1PredictSchemataPtrInput `pulumi:"predictSchemata"`
}

func (GoogleCloudAiplatformV1UnmanagedContainerModelArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1UnmanagedContainerModel)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1UnmanagedContainerModelArgs) ToGoogleCloudAiplatformV1UnmanagedContainerModelOutput() GoogleCloudAiplatformV1UnmanagedContainerModelOutput {
	return i.ToGoogleCloudAiplatformV1UnmanagedContainerModelOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1UnmanagedContainerModelArgs) ToGoogleCloudAiplatformV1UnmanagedContainerModelOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1UnmanagedContainerModelOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1UnmanagedContainerModelOutput)
}

func (i GoogleCloudAiplatformV1UnmanagedContainerModelArgs) ToGoogleCloudAiplatformV1UnmanagedContainerModelPtrOutput() GoogleCloudAiplatformV1UnmanagedContainerModelPtrOutput {
	return i.ToGoogleCloudAiplatformV1UnmanagedContainerModelPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1UnmanagedContainerModelArgs) ToGoogleCloudAiplatformV1UnmanagedContainerModelPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1UnmanagedContainerModelPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1UnmanagedContainerModelOutput).ToGoogleCloudAiplatformV1UnmanagedContainerModelPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1UnmanagedContainerModelPtrInput is an input type that accepts GoogleCloudAiplatformV1UnmanagedContainerModelArgs, GoogleCloudAiplatformV1UnmanagedContainerModelPtr and GoogleCloudAiplatformV1UnmanagedContainerModelPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1UnmanagedContainerModelPtrInput` via:
//
//	        GoogleCloudAiplatformV1UnmanagedContainerModelArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1UnmanagedContainerModelPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1UnmanagedContainerModelPtrOutput() GoogleCloudAiplatformV1UnmanagedContainerModelPtrOutput
	ToGoogleCloudAiplatformV1UnmanagedContainerModelPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1UnmanagedContainerModelPtrOutput
}

type googleCloudAiplatformV1UnmanagedContainerModelPtrType GoogleCloudAiplatformV1UnmanagedContainerModelArgs

func GoogleCloudAiplatformV1UnmanagedContainerModelPtr(v *GoogleCloudAiplatformV1UnmanagedContainerModelArgs) GoogleCloudAiplatformV1UnmanagedContainerModelPtrInput {
	return (*googleCloudAiplatformV1UnmanagedContainerModelPtrType)(v)
}

func (*googleCloudAiplatformV1UnmanagedContainerModelPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1UnmanagedContainerModel)(nil)).Elem()
}

func (i *googleCloudAiplatformV1UnmanagedContainerModelPtrType) ToGoogleCloudAiplatformV1UnmanagedContainerModelPtrOutput() GoogleCloudAiplatformV1UnmanagedContainerModelPtrOutput {
	return i.ToGoogleCloudAiplatformV1UnmanagedContainerModelPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1UnmanagedContainerModelPtrType) ToGoogleCloudAiplatformV1UnmanagedContainerModelPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1UnmanagedContainerModelPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1UnmanagedContainerModelPtrOutput)
}

// Contains model information necessary to perform batch prediction without requiring a full model import.
type GoogleCloudAiplatformV1UnmanagedContainerModelOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1UnmanagedContainerModelOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1UnmanagedContainerModel)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1UnmanagedContainerModelOutput) ToGoogleCloudAiplatformV1UnmanagedContainerModelOutput() GoogleCloudAiplatformV1UnmanagedContainerModelOutput {
	return o
}

func (o GoogleCloudAiplatformV1UnmanagedContainerModelOutput) ToGoogleCloudAiplatformV1UnmanagedContainerModelOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1UnmanagedContainerModelOutput {
	return o
}

func (o GoogleCloudAiplatformV1UnmanagedContainerModelOutput) ToGoogleCloudAiplatformV1UnmanagedContainerModelPtrOutput() GoogleCloudAiplatformV1UnmanagedContainerModelPtrOutput {
	return o.ToGoogleCloudAiplatformV1UnmanagedContainerModelPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1UnmanagedContainerModelOutput) ToGoogleCloudAiplatformV1UnmanagedContainerModelPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1UnmanagedContainerModelPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1UnmanagedContainerModel) *GoogleCloudAiplatformV1UnmanagedContainerModel {
		return &v
	}).(GoogleCloudAiplatformV1UnmanagedContainerModelPtrOutput)
}

// The path to the directory containing the Model artifact and any of its supporting files.
func (o GoogleCloudAiplatformV1UnmanagedContainerModelOutput) ArtifactUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1UnmanagedContainerModel) *string { return v.ArtifactUri }).(pulumi.StringPtrOutput)
}

// Input only. The specification of the container that is to be used when deploying this Model.
func (o GoogleCloudAiplatformV1UnmanagedContainerModelOutput) ContainerSpec() GoogleCloudAiplatformV1ModelContainerSpecPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1UnmanagedContainerModel) *GoogleCloudAiplatformV1ModelContainerSpec {
		return v.ContainerSpec
	}).(GoogleCloudAiplatformV1ModelContainerSpecPtrOutput)
}

// Contains the schemata used in Model's predictions and explanations
func (o GoogleCloudAiplatformV1UnmanagedContainerModelOutput) PredictSchemata() GoogleCloudAiplatformV1PredictSchemataPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1UnmanagedContainerModel) *GoogleCloudAiplatformV1PredictSchemata {
		return v.PredictSchemata
	}).(GoogleCloudAiplatformV1PredictSchemataPtrOutput)
}

type GoogleCloudAiplatformV1UnmanagedContainerModelPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1UnmanagedContainerModelPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1UnmanagedContainerModel)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1UnmanagedContainerModelPtrOutput) ToGoogleCloudAiplatformV1UnmanagedContainerModelPtrOutput() GoogleCloudAiplatformV1UnmanagedContainerModelPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1UnmanagedContainerModelPtrOutput) ToGoogleCloudAiplatformV1UnmanagedContainerModelPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1UnmanagedContainerModelPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1UnmanagedContainerModelPtrOutput) Elem() GoogleCloudAiplatformV1UnmanagedContainerModelOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1UnmanagedContainerModel) GoogleCloudAiplatformV1UnmanagedContainerModel {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1UnmanagedContainerModel
		return ret
	}).(GoogleCloudAiplatformV1UnmanagedContainerModelOutput)
}

// The path to the directory containing the Model artifact and any of its supporting files.
func (o GoogleCloudAiplatformV1UnmanagedContainerModelPtrOutput) ArtifactUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1UnmanagedContainerModel) *string {
		if v == nil {
			return nil
		}
		return v.ArtifactUri
	}).(pulumi.StringPtrOutput)
}

// Input only. The specification of the container that is to be used when deploying this Model.
func (o GoogleCloudAiplatformV1UnmanagedContainerModelPtrOutput) ContainerSpec() GoogleCloudAiplatformV1ModelContainerSpecPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1UnmanagedContainerModel) *GoogleCloudAiplatformV1ModelContainerSpec {
		if v == nil {
			return nil
		}
		return v.ContainerSpec
	}).(GoogleCloudAiplatformV1ModelContainerSpecPtrOutput)
}

// Contains the schemata used in Model's predictions and explanations
func (o GoogleCloudAiplatformV1UnmanagedContainerModelPtrOutput) PredictSchemata() GoogleCloudAiplatformV1PredictSchemataPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1UnmanagedContainerModel) *GoogleCloudAiplatformV1PredictSchemata {
		if v == nil {
			return nil
		}
		return v.PredictSchemata
	}).(GoogleCloudAiplatformV1PredictSchemataPtrOutput)
}

// Contains model information necessary to perform batch prediction without requiring a full model import.
type GoogleCloudAiplatformV1UnmanagedContainerModelResponse struct {
	// The path to the directory containing the Model artifact and any of its supporting files.
	ArtifactUri string `pulumi:"artifactUri"`
	// Input only. The specification of the container that is to be used when deploying this Model.
	ContainerSpec GoogleCloudAiplatformV1ModelContainerSpecResponse `pulumi:"containerSpec"`
	// Contains the schemata used in Model's predictions and explanations
	PredictSchemata GoogleCloudAiplatformV1PredictSchemataResponse `pulumi:"predictSchemata"`
}

// Contains model information necessary to perform batch prediction without requiring a full model import.
type GoogleCloudAiplatformV1UnmanagedContainerModelResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1UnmanagedContainerModelResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1UnmanagedContainerModelResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1UnmanagedContainerModelResponseOutput) ToGoogleCloudAiplatformV1UnmanagedContainerModelResponseOutput() GoogleCloudAiplatformV1UnmanagedContainerModelResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1UnmanagedContainerModelResponseOutput) ToGoogleCloudAiplatformV1UnmanagedContainerModelResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1UnmanagedContainerModelResponseOutput {
	return o
}

// The path to the directory containing the Model artifact and any of its supporting files.
func (o GoogleCloudAiplatformV1UnmanagedContainerModelResponseOutput) ArtifactUri() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1UnmanagedContainerModelResponse) string { return v.ArtifactUri }).(pulumi.StringOutput)
}

// Input only. The specification of the container that is to be used when deploying this Model.
func (o GoogleCloudAiplatformV1UnmanagedContainerModelResponseOutput) ContainerSpec() GoogleCloudAiplatformV1ModelContainerSpecResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1UnmanagedContainerModelResponse) GoogleCloudAiplatformV1ModelContainerSpecResponse {
		return v.ContainerSpec
	}).(GoogleCloudAiplatformV1ModelContainerSpecResponseOutput)
}

// Contains the schemata used in Model's predictions and explanations
func (o GoogleCloudAiplatformV1UnmanagedContainerModelResponseOutput) PredictSchemata() GoogleCloudAiplatformV1PredictSchemataResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1UnmanagedContainerModelResponse) GoogleCloudAiplatformV1PredictSchemataResponse {
		return v.PredictSchemata
	}).(GoogleCloudAiplatformV1PredictSchemataResponseOutput)
}

// Value is the value of the field.
type GoogleCloudAiplatformV1Value struct {
	// A double value.
	DoubleValue *float64 `pulumi:"doubleValue"`
	// An integer value.
	IntValue *string `pulumi:"intValue"`
	// A string value.
	StringValue *string `pulumi:"stringValue"`
}

// GoogleCloudAiplatformV1ValueInput is an input type that accepts GoogleCloudAiplatformV1ValueArgs and GoogleCloudAiplatformV1ValueOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1ValueInput` via:
//
//	GoogleCloudAiplatformV1ValueArgs{...}
type GoogleCloudAiplatformV1ValueInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1ValueOutput() GoogleCloudAiplatformV1ValueOutput
	ToGoogleCloudAiplatformV1ValueOutputWithContext(context.Context) GoogleCloudAiplatformV1ValueOutput
}

// Value is the value of the field.
type GoogleCloudAiplatformV1ValueArgs struct {
	// A double value.
	DoubleValue pulumi.Float64PtrInput `pulumi:"doubleValue"`
	// An integer value.
	IntValue pulumi.StringPtrInput `pulumi:"intValue"`
	// A string value.
	StringValue pulumi.StringPtrInput `pulumi:"stringValue"`
}

func (GoogleCloudAiplatformV1ValueArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1Value)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1ValueArgs) ToGoogleCloudAiplatformV1ValueOutput() GoogleCloudAiplatformV1ValueOutput {
	return i.ToGoogleCloudAiplatformV1ValueOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1ValueArgs) ToGoogleCloudAiplatformV1ValueOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ValueOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1ValueOutput)
}

// GoogleCloudAiplatformV1ValueMapInput is an input type that accepts GoogleCloudAiplatformV1ValueMap and GoogleCloudAiplatformV1ValueMapOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1ValueMapInput` via:
//
//	GoogleCloudAiplatformV1ValueMap{ "key": GoogleCloudAiplatformV1ValueArgs{...} }
type GoogleCloudAiplatformV1ValueMapInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1ValueMapOutput() GoogleCloudAiplatformV1ValueMapOutput
	ToGoogleCloudAiplatformV1ValueMapOutputWithContext(context.Context) GoogleCloudAiplatformV1ValueMapOutput
}

type GoogleCloudAiplatformV1ValueMap map[string]GoogleCloudAiplatformV1ValueInput

func (GoogleCloudAiplatformV1ValueMap) ElementType() reflect.Type {
	return reflect.TypeOf((*map[string]GoogleCloudAiplatformV1Value)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1ValueMap) ToGoogleCloudAiplatformV1ValueMapOutput() GoogleCloudAiplatformV1ValueMapOutput {
	return i.ToGoogleCloudAiplatformV1ValueMapOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1ValueMap) ToGoogleCloudAiplatformV1ValueMapOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ValueMapOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1ValueMapOutput)
}

// Value is the value of the field.
type GoogleCloudAiplatformV1ValueOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ValueOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1Value)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ValueOutput) ToGoogleCloudAiplatformV1ValueOutput() GoogleCloudAiplatformV1ValueOutput {
	return o
}

func (o GoogleCloudAiplatformV1ValueOutput) ToGoogleCloudAiplatformV1ValueOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ValueOutput {
	return o
}

// A double value.
func (o GoogleCloudAiplatformV1ValueOutput) DoubleValue() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1Value) *float64 { return v.DoubleValue }).(pulumi.Float64PtrOutput)
}

// An integer value.
func (o GoogleCloudAiplatformV1ValueOutput) IntValue() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1Value) *string { return v.IntValue }).(pulumi.StringPtrOutput)
}

// A string value.
func (o GoogleCloudAiplatformV1ValueOutput) StringValue() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1Value) *string { return v.StringValue }).(pulumi.StringPtrOutput)
}

type GoogleCloudAiplatformV1ValueMapOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ValueMapOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*map[string]GoogleCloudAiplatformV1Value)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ValueMapOutput) ToGoogleCloudAiplatformV1ValueMapOutput() GoogleCloudAiplatformV1ValueMapOutput {
	return o
}

func (o GoogleCloudAiplatformV1ValueMapOutput) ToGoogleCloudAiplatformV1ValueMapOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ValueMapOutput {
	return o
}

func (o GoogleCloudAiplatformV1ValueMapOutput) MapIndex(k pulumi.StringInput) GoogleCloudAiplatformV1ValueOutput {
	return pulumi.All(o, k).ApplyT(func(vs []interface{}) GoogleCloudAiplatformV1Value {
		return vs[0].(map[string]GoogleCloudAiplatformV1Value)[vs[1].(string)]
	}).(GoogleCloudAiplatformV1ValueOutput)
}

// Value is the value of the field.
type GoogleCloudAiplatformV1ValueResponse struct {
	// A double value.
	DoubleValue float64 `pulumi:"doubleValue"`
	// An integer value.
	IntValue string `pulumi:"intValue"`
	// A string value.
	StringValue string `pulumi:"stringValue"`
}

// Value is the value of the field.
type GoogleCloudAiplatformV1ValueResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ValueResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1ValueResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ValueResponseOutput) ToGoogleCloudAiplatformV1ValueResponseOutput() GoogleCloudAiplatformV1ValueResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1ValueResponseOutput) ToGoogleCloudAiplatformV1ValueResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ValueResponseOutput {
	return o
}

// A double value.
func (o GoogleCloudAiplatformV1ValueResponseOutput) DoubleValue() pulumi.Float64Output {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ValueResponse) float64 { return v.DoubleValue }).(pulumi.Float64Output)
}

// An integer value.
func (o GoogleCloudAiplatformV1ValueResponseOutput) IntValue() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ValueResponse) string { return v.IntValue }).(pulumi.StringOutput)
}

// A string value.
func (o GoogleCloudAiplatformV1ValueResponseOutput) StringValue() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1ValueResponse) string { return v.StringValue }).(pulumi.StringOutput)
}

type GoogleCloudAiplatformV1ValueResponseMapOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1ValueResponseMapOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*map[string]GoogleCloudAiplatformV1ValueResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1ValueResponseMapOutput) ToGoogleCloudAiplatformV1ValueResponseMapOutput() GoogleCloudAiplatformV1ValueResponseMapOutput {
	return o
}

func (o GoogleCloudAiplatformV1ValueResponseMapOutput) ToGoogleCloudAiplatformV1ValueResponseMapOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1ValueResponseMapOutput {
	return o
}

func (o GoogleCloudAiplatformV1ValueResponseMapOutput) MapIndex(k pulumi.StringInput) GoogleCloudAiplatformV1ValueResponseOutput {
	return pulumi.All(o, k).ApplyT(func(vs []interface{}) GoogleCloudAiplatformV1ValueResponse {
		return vs[0].(map[string]GoogleCloudAiplatformV1ValueResponse)[vs[1].(string)]
	}).(GoogleCloudAiplatformV1ValueResponseOutput)
}

// Represents the spec of a worker pool in a job.
type GoogleCloudAiplatformV1WorkerPoolSpec struct {
	// The custom container task.
	ContainerSpec *GoogleCloudAiplatformV1ContainerSpec `pulumi:"containerSpec"`
	// Disk spec.
	DiskSpec *GoogleCloudAiplatformV1DiskSpec `pulumi:"diskSpec"`
	// Optional. Immutable. The specification of a single machine.
	MachineSpec *GoogleCloudAiplatformV1MachineSpec `pulumi:"machineSpec"`
	// Optional. List of NFS mount spec.
	NfsMounts []GoogleCloudAiplatformV1NfsMount `pulumi:"nfsMounts"`
	// The Python packaged task.
	PythonPackageSpec *GoogleCloudAiplatformV1PythonPackageSpec `pulumi:"pythonPackageSpec"`
	// Optional. The number of worker replicas to use for this worker pool.
	ReplicaCount *string `pulumi:"replicaCount"`
}

// GoogleCloudAiplatformV1WorkerPoolSpecInput is an input type that accepts GoogleCloudAiplatformV1WorkerPoolSpecArgs and GoogleCloudAiplatformV1WorkerPoolSpecOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1WorkerPoolSpecInput` via:
//
//	GoogleCloudAiplatformV1WorkerPoolSpecArgs{...}
type GoogleCloudAiplatformV1WorkerPoolSpecInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1WorkerPoolSpecOutput() GoogleCloudAiplatformV1WorkerPoolSpecOutput
	ToGoogleCloudAiplatformV1WorkerPoolSpecOutputWithContext(context.Context) GoogleCloudAiplatformV1WorkerPoolSpecOutput
}

// Represents the spec of a worker pool in a job.
type GoogleCloudAiplatformV1WorkerPoolSpecArgs struct {
	// The custom container task.
	ContainerSpec GoogleCloudAiplatformV1ContainerSpecPtrInput `pulumi:"containerSpec"`
	// Disk spec.
	DiskSpec GoogleCloudAiplatformV1DiskSpecPtrInput `pulumi:"diskSpec"`
	// Optional. Immutable. The specification of a single machine.
	MachineSpec GoogleCloudAiplatformV1MachineSpecPtrInput `pulumi:"machineSpec"`
	// Optional. List of NFS mount spec.
	NfsMounts GoogleCloudAiplatformV1NfsMountArrayInput `pulumi:"nfsMounts"`
	// The Python packaged task.
	PythonPackageSpec GoogleCloudAiplatformV1PythonPackageSpecPtrInput `pulumi:"pythonPackageSpec"`
	// Optional. The number of worker replicas to use for this worker pool.
	ReplicaCount pulumi.StringPtrInput `pulumi:"replicaCount"`
}

func (GoogleCloudAiplatformV1WorkerPoolSpecArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1WorkerPoolSpec)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1WorkerPoolSpecArgs) ToGoogleCloudAiplatformV1WorkerPoolSpecOutput() GoogleCloudAiplatformV1WorkerPoolSpecOutput {
	return i.ToGoogleCloudAiplatformV1WorkerPoolSpecOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1WorkerPoolSpecArgs) ToGoogleCloudAiplatformV1WorkerPoolSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1WorkerPoolSpecOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1WorkerPoolSpecOutput)
}

// GoogleCloudAiplatformV1WorkerPoolSpecArrayInput is an input type that accepts GoogleCloudAiplatformV1WorkerPoolSpecArray and GoogleCloudAiplatformV1WorkerPoolSpecArrayOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1WorkerPoolSpecArrayInput` via:
//
//	GoogleCloudAiplatformV1WorkerPoolSpecArray{ GoogleCloudAiplatformV1WorkerPoolSpecArgs{...} }
type GoogleCloudAiplatformV1WorkerPoolSpecArrayInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1WorkerPoolSpecArrayOutput() GoogleCloudAiplatformV1WorkerPoolSpecArrayOutput
	ToGoogleCloudAiplatformV1WorkerPoolSpecArrayOutputWithContext(context.Context) GoogleCloudAiplatformV1WorkerPoolSpecArrayOutput
}

type GoogleCloudAiplatformV1WorkerPoolSpecArray []GoogleCloudAiplatformV1WorkerPoolSpecInput

func (GoogleCloudAiplatformV1WorkerPoolSpecArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1WorkerPoolSpec)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1WorkerPoolSpecArray) ToGoogleCloudAiplatformV1WorkerPoolSpecArrayOutput() GoogleCloudAiplatformV1WorkerPoolSpecArrayOutput {
	return i.ToGoogleCloudAiplatformV1WorkerPoolSpecArrayOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1WorkerPoolSpecArray) ToGoogleCloudAiplatformV1WorkerPoolSpecArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1WorkerPoolSpecArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1WorkerPoolSpecArrayOutput)
}

// Represents the spec of a worker pool in a job.
type GoogleCloudAiplatformV1WorkerPoolSpecOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1WorkerPoolSpecOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1WorkerPoolSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1WorkerPoolSpecOutput) ToGoogleCloudAiplatformV1WorkerPoolSpecOutput() GoogleCloudAiplatformV1WorkerPoolSpecOutput {
	return o
}

func (o GoogleCloudAiplatformV1WorkerPoolSpecOutput) ToGoogleCloudAiplatformV1WorkerPoolSpecOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1WorkerPoolSpecOutput {
	return o
}

// The custom container task.
func (o GoogleCloudAiplatformV1WorkerPoolSpecOutput) ContainerSpec() GoogleCloudAiplatformV1ContainerSpecPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1WorkerPoolSpec) *GoogleCloudAiplatformV1ContainerSpec {
		return v.ContainerSpec
	}).(GoogleCloudAiplatformV1ContainerSpecPtrOutput)
}

// Disk spec.
func (o GoogleCloudAiplatformV1WorkerPoolSpecOutput) DiskSpec() GoogleCloudAiplatformV1DiskSpecPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1WorkerPoolSpec) *GoogleCloudAiplatformV1DiskSpec { return v.DiskSpec }).(GoogleCloudAiplatformV1DiskSpecPtrOutput)
}

// Optional. Immutable. The specification of a single machine.
func (o GoogleCloudAiplatformV1WorkerPoolSpecOutput) MachineSpec() GoogleCloudAiplatformV1MachineSpecPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1WorkerPoolSpec) *GoogleCloudAiplatformV1MachineSpec {
		return v.MachineSpec
	}).(GoogleCloudAiplatformV1MachineSpecPtrOutput)
}

// Optional. List of NFS mount spec.
func (o GoogleCloudAiplatformV1WorkerPoolSpecOutput) NfsMounts() GoogleCloudAiplatformV1NfsMountArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1WorkerPoolSpec) []GoogleCloudAiplatformV1NfsMount { return v.NfsMounts }).(GoogleCloudAiplatformV1NfsMountArrayOutput)
}

// The Python packaged task.
func (o GoogleCloudAiplatformV1WorkerPoolSpecOutput) PythonPackageSpec() GoogleCloudAiplatformV1PythonPackageSpecPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1WorkerPoolSpec) *GoogleCloudAiplatformV1PythonPackageSpec {
		return v.PythonPackageSpec
	}).(GoogleCloudAiplatformV1PythonPackageSpecPtrOutput)
}

// Optional. The number of worker replicas to use for this worker pool.
func (o GoogleCloudAiplatformV1WorkerPoolSpecOutput) ReplicaCount() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1WorkerPoolSpec) *string { return v.ReplicaCount }).(pulumi.StringPtrOutput)
}

type GoogleCloudAiplatformV1WorkerPoolSpecArrayOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1WorkerPoolSpecArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1WorkerPoolSpec)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1WorkerPoolSpecArrayOutput) ToGoogleCloudAiplatformV1WorkerPoolSpecArrayOutput() GoogleCloudAiplatformV1WorkerPoolSpecArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1WorkerPoolSpecArrayOutput) ToGoogleCloudAiplatformV1WorkerPoolSpecArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1WorkerPoolSpecArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1WorkerPoolSpecArrayOutput) Index(i pulumi.IntInput) GoogleCloudAiplatformV1WorkerPoolSpecOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GoogleCloudAiplatformV1WorkerPoolSpec {
		return vs[0].([]GoogleCloudAiplatformV1WorkerPoolSpec)[vs[1].(int)]
	}).(GoogleCloudAiplatformV1WorkerPoolSpecOutput)
}

// Represents the spec of a worker pool in a job.
type GoogleCloudAiplatformV1WorkerPoolSpecResponse struct {
	// The custom container task.
	ContainerSpec GoogleCloudAiplatformV1ContainerSpecResponse `pulumi:"containerSpec"`
	// Disk spec.
	DiskSpec GoogleCloudAiplatformV1DiskSpecResponse `pulumi:"diskSpec"`
	// Optional. Immutable. The specification of a single machine.
	MachineSpec GoogleCloudAiplatformV1MachineSpecResponse `pulumi:"machineSpec"`
	// Optional. List of NFS mount spec.
	NfsMounts []GoogleCloudAiplatformV1NfsMountResponse `pulumi:"nfsMounts"`
	// The Python packaged task.
	PythonPackageSpec GoogleCloudAiplatformV1PythonPackageSpecResponse `pulumi:"pythonPackageSpec"`
	// Optional. The number of worker replicas to use for this worker pool.
	ReplicaCount string `pulumi:"replicaCount"`
}

// Represents the spec of a worker pool in a job.
type GoogleCloudAiplatformV1WorkerPoolSpecResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1WorkerPoolSpecResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1WorkerPoolSpecResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1WorkerPoolSpecResponseOutput) ToGoogleCloudAiplatformV1WorkerPoolSpecResponseOutput() GoogleCloudAiplatformV1WorkerPoolSpecResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1WorkerPoolSpecResponseOutput) ToGoogleCloudAiplatformV1WorkerPoolSpecResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1WorkerPoolSpecResponseOutput {
	return o
}

// The custom container task.
func (o GoogleCloudAiplatformV1WorkerPoolSpecResponseOutput) ContainerSpec() GoogleCloudAiplatformV1ContainerSpecResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1WorkerPoolSpecResponse) GoogleCloudAiplatformV1ContainerSpecResponse {
		return v.ContainerSpec
	}).(GoogleCloudAiplatformV1ContainerSpecResponseOutput)
}

// Disk spec.
func (o GoogleCloudAiplatformV1WorkerPoolSpecResponseOutput) DiskSpec() GoogleCloudAiplatformV1DiskSpecResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1WorkerPoolSpecResponse) GoogleCloudAiplatformV1DiskSpecResponse {
		return v.DiskSpec
	}).(GoogleCloudAiplatformV1DiskSpecResponseOutput)
}

// Optional. Immutable. The specification of a single machine.
func (o GoogleCloudAiplatformV1WorkerPoolSpecResponseOutput) MachineSpec() GoogleCloudAiplatformV1MachineSpecResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1WorkerPoolSpecResponse) GoogleCloudAiplatformV1MachineSpecResponse {
		return v.MachineSpec
	}).(GoogleCloudAiplatformV1MachineSpecResponseOutput)
}

// Optional. List of NFS mount spec.
func (o GoogleCloudAiplatformV1WorkerPoolSpecResponseOutput) NfsMounts() GoogleCloudAiplatformV1NfsMountResponseArrayOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1WorkerPoolSpecResponse) []GoogleCloudAiplatformV1NfsMountResponse {
		return v.NfsMounts
	}).(GoogleCloudAiplatformV1NfsMountResponseArrayOutput)
}

// The Python packaged task.
func (o GoogleCloudAiplatformV1WorkerPoolSpecResponseOutput) PythonPackageSpec() GoogleCloudAiplatformV1PythonPackageSpecResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1WorkerPoolSpecResponse) GoogleCloudAiplatformV1PythonPackageSpecResponse {
		return v.PythonPackageSpec
	}).(GoogleCloudAiplatformV1PythonPackageSpecResponseOutput)
}

// Optional. The number of worker replicas to use for this worker pool.
func (o GoogleCloudAiplatformV1WorkerPoolSpecResponseOutput) ReplicaCount() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1WorkerPoolSpecResponse) string { return v.ReplicaCount }).(pulumi.StringOutput)
}

type GoogleCloudAiplatformV1WorkerPoolSpecResponseArrayOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1WorkerPoolSpecResponseArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleCloudAiplatformV1WorkerPoolSpecResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1WorkerPoolSpecResponseArrayOutput) ToGoogleCloudAiplatformV1WorkerPoolSpecResponseArrayOutput() GoogleCloudAiplatformV1WorkerPoolSpecResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1WorkerPoolSpecResponseArrayOutput) ToGoogleCloudAiplatformV1WorkerPoolSpecResponseArrayOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1WorkerPoolSpecResponseArrayOutput {
	return o
}

func (o GoogleCloudAiplatformV1WorkerPoolSpecResponseArrayOutput) Index(i pulumi.IntInput) GoogleCloudAiplatformV1WorkerPoolSpecResponseOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GoogleCloudAiplatformV1WorkerPoolSpecResponse {
		return vs[0].([]GoogleCloudAiplatformV1WorkerPoolSpecResponse)[vs[1].(int)]
	}).(GoogleCloudAiplatformV1WorkerPoolSpecResponseOutput)
}

// An explanation method that redistributes Integrated Gradients attributions to segmented regions, taking advantage of the model's fully differentiable structure. Refer to this paper for more details: https://arxiv.org/abs/1906.02825 Supported only by image Models.
type GoogleCloudAiplatformV1XraiAttribution struct {
	// Config for XRAI with blur baseline. When enabled, a linear path from the maximally blurred image to the input image is created. Using a blurred baseline instead of zero (black image) is motivated by the BlurIG approach explained here: https://arxiv.org/abs/2004.03383
	BlurBaselineConfig *GoogleCloudAiplatformV1BlurBaselineConfig `pulumi:"blurBaselineConfig"`
	// Config for SmoothGrad approximation of gradients. When enabled, the gradients are approximated by averaging the gradients from noisy samples in the vicinity of the inputs. Adding noise can help improve the computed gradients. Refer to this paper for more details: https://arxiv.org/pdf/1706.03825.pdf
	SmoothGradConfig *GoogleCloudAiplatformV1SmoothGradConfig `pulumi:"smoothGradConfig"`
	// The number of steps for approximating the path integral. A good value to start is 50 and gradually increase until the sum to diff property is met within the desired error range. Valid range of its value is [1, 100], inclusively.
	StepCount int `pulumi:"stepCount"`
}

// GoogleCloudAiplatformV1XraiAttributionInput is an input type that accepts GoogleCloudAiplatformV1XraiAttributionArgs and GoogleCloudAiplatformV1XraiAttributionOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1XraiAttributionInput` via:
//
//	GoogleCloudAiplatformV1XraiAttributionArgs{...}
type GoogleCloudAiplatformV1XraiAttributionInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1XraiAttributionOutput() GoogleCloudAiplatformV1XraiAttributionOutput
	ToGoogleCloudAiplatformV1XraiAttributionOutputWithContext(context.Context) GoogleCloudAiplatformV1XraiAttributionOutput
}

// An explanation method that redistributes Integrated Gradients attributions to segmented regions, taking advantage of the model's fully differentiable structure. Refer to this paper for more details: https://arxiv.org/abs/1906.02825 Supported only by image Models.
type GoogleCloudAiplatformV1XraiAttributionArgs struct {
	// Config for XRAI with blur baseline. When enabled, a linear path from the maximally blurred image to the input image is created. Using a blurred baseline instead of zero (black image) is motivated by the BlurIG approach explained here: https://arxiv.org/abs/2004.03383
	BlurBaselineConfig GoogleCloudAiplatformV1BlurBaselineConfigPtrInput `pulumi:"blurBaselineConfig"`
	// Config for SmoothGrad approximation of gradients. When enabled, the gradients are approximated by averaging the gradients from noisy samples in the vicinity of the inputs. Adding noise can help improve the computed gradients. Refer to this paper for more details: https://arxiv.org/pdf/1706.03825.pdf
	SmoothGradConfig GoogleCloudAiplatformV1SmoothGradConfigPtrInput `pulumi:"smoothGradConfig"`
	// The number of steps for approximating the path integral. A good value to start is 50 and gradually increase until the sum to diff property is met within the desired error range. Valid range of its value is [1, 100], inclusively.
	StepCount pulumi.IntInput `pulumi:"stepCount"`
}

func (GoogleCloudAiplatformV1XraiAttributionArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1XraiAttribution)(nil)).Elem()
}

func (i GoogleCloudAiplatformV1XraiAttributionArgs) ToGoogleCloudAiplatformV1XraiAttributionOutput() GoogleCloudAiplatformV1XraiAttributionOutput {
	return i.ToGoogleCloudAiplatformV1XraiAttributionOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1XraiAttributionArgs) ToGoogleCloudAiplatformV1XraiAttributionOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1XraiAttributionOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1XraiAttributionOutput)
}

func (i GoogleCloudAiplatformV1XraiAttributionArgs) ToGoogleCloudAiplatformV1XraiAttributionPtrOutput() GoogleCloudAiplatformV1XraiAttributionPtrOutput {
	return i.ToGoogleCloudAiplatformV1XraiAttributionPtrOutputWithContext(context.Background())
}

func (i GoogleCloudAiplatformV1XraiAttributionArgs) ToGoogleCloudAiplatformV1XraiAttributionPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1XraiAttributionPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1XraiAttributionOutput).ToGoogleCloudAiplatformV1XraiAttributionPtrOutputWithContext(ctx)
}

// GoogleCloudAiplatformV1XraiAttributionPtrInput is an input type that accepts GoogleCloudAiplatformV1XraiAttributionArgs, GoogleCloudAiplatformV1XraiAttributionPtr and GoogleCloudAiplatformV1XraiAttributionPtrOutput values.
// You can construct a concrete instance of `GoogleCloudAiplatformV1XraiAttributionPtrInput` via:
//
//	        GoogleCloudAiplatformV1XraiAttributionArgs{...}
//
//	or:
//
//	        nil
type GoogleCloudAiplatformV1XraiAttributionPtrInput interface {
	pulumi.Input

	ToGoogleCloudAiplatformV1XraiAttributionPtrOutput() GoogleCloudAiplatformV1XraiAttributionPtrOutput
	ToGoogleCloudAiplatformV1XraiAttributionPtrOutputWithContext(context.Context) GoogleCloudAiplatformV1XraiAttributionPtrOutput
}

type googleCloudAiplatformV1XraiAttributionPtrType GoogleCloudAiplatformV1XraiAttributionArgs

func GoogleCloudAiplatformV1XraiAttributionPtr(v *GoogleCloudAiplatformV1XraiAttributionArgs) GoogleCloudAiplatformV1XraiAttributionPtrInput {
	return (*googleCloudAiplatformV1XraiAttributionPtrType)(v)
}

func (*googleCloudAiplatformV1XraiAttributionPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1XraiAttribution)(nil)).Elem()
}

func (i *googleCloudAiplatformV1XraiAttributionPtrType) ToGoogleCloudAiplatformV1XraiAttributionPtrOutput() GoogleCloudAiplatformV1XraiAttributionPtrOutput {
	return i.ToGoogleCloudAiplatformV1XraiAttributionPtrOutputWithContext(context.Background())
}

func (i *googleCloudAiplatformV1XraiAttributionPtrType) ToGoogleCloudAiplatformV1XraiAttributionPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1XraiAttributionPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleCloudAiplatformV1XraiAttributionPtrOutput)
}

// An explanation method that redistributes Integrated Gradients attributions to segmented regions, taking advantage of the model's fully differentiable structure. Refer to this paper for more details: https://arxiv.org/abs/1906.02825 Supported only by image Models.
type GoogleCloudAiplatformV1XraiAttributionOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1XraiAttributionOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1XraiAttribution)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1XraiAttributionOutput) ToGoogleCloudAiplatformV1XraiAttributionOutput() GoogleCloudAiplatformV1XraiAttributionOutput {
	return o
}

func (o GoogleCloudAiplatformV1XraiAttributionOutput) ToGoogleCloudAiplatformV1XraiAttributionOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1XraiAttributionOutput {
	return o
}

func (o GoogleCloudAiplatformV1XraiAttributionOutput) ToGoogleCloudAiplatformV1XraiAttributionPtrOutput() GoogleCloudAiplatformV1XraiAttributionPtrOutput {
	return o.ToGoogleCloudAiplatformV1XraiAttributionPtrOutputWithContext(context.Background())
}

func (o GoogleCloudAiplatformV1XraiAttributionOutput) ToGoogleCloudAiplatformV1XraiAttributionPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1XraiAttributionPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleCloudAiplatformV1XraiAttribution) *GoogleCloudAiplatformV1XraiAttribution {
		return &v
	}).(GoogleCloudAiplatformV1XraiAttributionPtrOutput)
}

// Config for XRAI with blur baseline. When enabled, a linear path from the maximally blurred image to the input image is created. Using a blurred baseline instead of zero (black image) is motivated by the BlurIG approach explained here: https://arxiv.org/abs/2004.03383
func (o GoogleCloudAiplatformV1XraiAttributionOutput) BlurBaselineConfig() GoogleCloudAiplatformV1BlurBaselineConfigPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1XraiAttribution) *GoogleCloudAiplatformV1BlurBaselineConfig {
		return v.BlurBaselineConfig
	}).(GoogleCloudAiplatformV1BlurBaselineConfigPtrOutput)
}

// Config for SmoothGrad approximation of gradients. When enabled, the gradients are approximated by averaging the gradients from noisy samples in the vicinity of the inputs. Adding noise can help improve the computed gradients. Refer to this paper for more details: https://arxiv.org/pdf/1706.03825.pdf
func (o GoogleCloudAiplatformV1XraiAttributionOutput) SmoothGradConfig() GoogleCloudAiplatformV1SmoothGradConfigPtrOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1XraiAttribution) *GoogleCloudAiplatformV1SmoothGradConfig {
		return v.SmoothGradConfig
	}).(GoogleCloudAiplatformV1SmoothGradConfigPtrOutput)
}

// The number of steps for approximating the path integral. A good value to start is 50 and gradually increase until the sum to diff property is met within the desired error range. Valid range of its value is [1, 100], inclusively.
func (o GoogleCloudAiplatformV1XraiAttributionOutput) StepCount() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1XraiAttribution) int { return v.StepCount }).(pulumi.IntOutput)
}

type GoogleCloudAiplatformV1XraiAttributionPtrOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1XraiAttributionPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleCloudAiplatformV1XraiAttribution)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1XraiAttributionPtrOutput) ToGoogleCloudAiplatformV1XraiAttributionPtrOutput() GoogleCloudAiplatformV1XraiAttributionPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1XraiAttributionPtrOutput) ToGoogleCloudAiplatformV1XraiAttributionPtrOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1XraiAttributionPtrOutput {
	return o
}

func (o GoogleCloudAiplatformV1XraiAttributionPtrOutput) Elem() GoogleCloudAiplatformV1XraiAttributionOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1XraiAttribution) GoogleCloudAiplatformV1XraiAttribution {
		if v != nil {
			return *v
		}
		var ret GoogleCloudAiplatformV1XraiAttribution
		return ret
	}).(GoogleCloudAiplatformV1XraiAttributionOutput)
}

// Config for XRAI with blur baseline. When enabled, a linear path from the maximally blurred image to the input image is created. Using a blurred baseline instead of zero (black image) is motivated by the BlurIG approach explained here: https://arxiv.org/abs/2004.03383
func (o GoogleCloudAiplatformV1XraiAttributionPtrOutput) BlurBaselineConfig() GoogleCloudAiplatformV1BlurBaselineConfigPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1XraiAttribution) *GoogleCloudAiplatformV1BlurBaselineConfig {
		if v == nil {
			return nil
		}
		return v.BlurBaselineConfig
	}).(GoogleCloudAiplatformV1BlurBaselineConfigPtrOutput)
}

// Config for SmoothGrad approximation of gradients. When enabled, the gradients are approximated by averaging the gradients from noisy samples in the vicinity of the inputs. Adding noise can help improve the computed gradients. Refer to this paper for more details: https://arxiv.org/pdf/1706.03825.pdf
func (o GoogleCloudAiplatformV1XraiAttributionPtrOutput) SmoothGradConfig() GoogleCloudAiplatformV1SmoothGradConfigPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1XraiAttribution) *GoogleCloudAiplatformV1SmoothGradConfig {
		if v == nil {
			return nil
		}
		return v.SmoothGradConfig
	}).(GoogleCloudAiplatformV1SmoothGradConfigPtrOutput)
}

// The number of steps for approximating the path integral. A good value to start is 50 and gradually increase until the sum to diff property is met within the desired error range. Valid range of its value is [1, 100], inclusively.
func (o GoogleCloudAiplatformV1XraiAttributionPtrOutput) StepCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *GoogleCloudAiplatformV1XraiAttribution) *int {
		if v == nil {
			return nil
		}
		return &v.StepCount
	}).(pulumi.IntPtrOutput)
}

// An explanation method that redistributes Integrated Gradients attributions to segmented regions, taking advantage of the model's fully differentiable structure. Refer to this paper for more details: https://arxiv.org/abs/1906.02825 Supported only by image Models.
type GoogleCloudAiplatformV1XraiAttributionResponse struct {
	// Config for XRAI with blur baseline. When enabled, a linear path from the maximally blurred image to the input image is created. Using a blurred baseline instead of zero (black image) is motivated by the BlurIG approach explained here: https://arxiv.org/abs/2004.03383
	BlurBaselineConfig GoogleCloudAiplatformV1BlurBaselineConfigResponse `pulumi:"blurBaselineConfig"`
	// Config for SmoothGrad approximation of gradients. When enabled, the gradients are approximated by averaging the gradients from noisy samples in the vicinity of the inputs. Adding noise can help improve the computed gradients. Refer to this paper for more details: https://arxiv.org/pdf/1706.03825.pdf
	SmoothGradConfig GoogleCloudAiplatformV1SmoothGradConfigResponse `pulumi:"smoothGradConfig"`
	// The number of steps for approximating the path integral. A good value to start is 50 and gradually increase until the sum to diff property is met within the desired error range. Valid range of its value is [1, 100], inclusively.
	StepCount int `pulumi:"stepCount"`
}

// An explanation method that redistributes Integrated Gradients attributions to segmented regions, taking advantage of the model's fully differentiable structure. Refer to this paper for more details: https://arxiv.org/abs/1906.02825 Supported only by image Models.
type GoogleCloudAiplatformV1XraiAttributionResponseOutput struct{ *pulumi.OutputState }

func (GoogleCloudAiplatformV1XraiAttributionResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleCloudAiplatformV1XraiAttributionResponse)(nil)).Elem()
}

func (o GoogleCloudAiplatformV1XraiAttributionResponseOutput) ToGoogleCloudAiplatformV1XraiAttributionResponseOutput() GoogleCloudAiplatformV1XraiAttributionResponseOutput {
	return o
}

func (o GoogleCloudAiplatformV1XraiAttributionResponseOutput) ToGoogleCloudAiplatformV1XraiAttributionResponseOutputWithContext(ctx context.Context) GoogleCloudAiplatformV1XraiAttributionResponseOutput {
	return o
}

// Config for XRAI with blur baseline. When enabled, a linear path from the maximally blurred image to the input image is created. Using a blurred baseline instead of zero (black image) is motivated by the BlurIG approach explained here: https://arxiv.org/abs/2004.03383
func (o GoogleCloudAiplatformV1XraiAttributionResponseOutput) BlurBaselineConfig() GoogleCloudAiplatformV1BlurBaselineConfigResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1XraiAttributionResponse) GoogleCloudAiplatformV1BlurBaselineConfigResponse {
		return v.BlurBaselineConfig
	}).(GoogleCloudAiplatformV1BlurBaselineConfigResponseOutput)
}

// Config for SmoothGrad approximation of gradients. When enabled, the gradients are approximated by averaging the gradients from noisy samples in the vicinity of the inputs. Adding noise can help improve the computed gradients. Refer to this paper for more details: https://arxiv.org/pdf/1706.03825.pdf
func (o GoogleCloudAiplatformV1XraiAttributionResponseOutput) SmoothGradConfig() GoogleCloudAiplatformV1SmoothGradConfigResponseOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1XraiAttributionResponse) GoogleCloudAiplatformV1SmoothGradConfigResponse {
		return v.SmoothGradConfig
	}).(GoogleCloudAiplatformV1SmoothGradConfigResponseOutput)
}

// The number of steps for approximating the path integral. A good value to start is 50 and gradually increase until the sum to diff property is met within the desired error range. Valid range of its value is [1, 100], inclusively.
func (o GoogleCloudAiplatformV1XraiAttributionResponseOutput) StepCount() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleCloudAiplatformV1XraiAttributionResponse) int { return v.StepCount }).(pulumi.IntOutput)
}

// Associates `members`, or principals, with a `role`.
type GoogleIamV1Binding struct {
	// The condition that is associated with this binding. If the condition evaluates to `true`, then this binding applies to the current request. If the condition evaluates to `false`, then this binding does not apply to the current request. However, a different role binding might grant the same role to one or more of the principals in this binding. To learn which resources support conditions in their IAM policies, see the [IAM documentation](https://cloud.google.com/iam/help/conditions/resource-policies).
	Condition *GoogleTypeExpr `pulumi:"condition"`
	// Specifies the principals requesting access for a Google Cloud resource. `members` can have the following values: * `allUsers`: A special identifier that represents anyone who is on the internet; with or without a Google account. * `allAuthenticatedUsers`: A special identifier that represents anyone who is authenticated with a Google account or a service account. Does not include identities that come from external identity providers (IdPs) through identity federation. * `user:{emailid}`: An email address that represents a specific Google account. For example, `alice@example.com` . * `serviceAccount:{emailid}`: An email address that represents a Google service account. For example, `my-other-app@appspot.gserviceaccount.com`. * `serviceAccount:{projectid}.svc.id.goog[{namespace}/{kubernetes-sa}]`: An identifier for a [Kubernetes service account](https://cloud.google.com/kubernetes-engine/docs/how-to/kubernetes-service-accounts). For example, `my-project.svc.id.goog[my-namespace/my-kubernetes-sa]`. * `group:{emailid}`: An email address that represents a Google group. For example, `admins@example.com`. * `domain:{domain}`: The G Suite domain (primary) that represents all the users of that domain. For example, `google.com` or `example.com`. * `deleted:user:{emailid}?uid={uniqueid}`: An email address (plus unique identifier) representing a user that has been recently deleted. For example, `alice@example.com?uid=123456789012345678901`. If the user is recovered, this value reverts to `user:{emailid}` and the recovered user retains the role in the binding. * `deleted:serviceAccount:{emailid}?uid={uniqueid}`: An email address (plus unique identifier) representing a service account that has been recently deleted. For example, `my-other-app@appspot.gserviceaccount.com?uid=123456789012345678901`. If the service account is undeleted, this value reverts to `serviceAccount:{emailid}` and the undeleted service account retains the role in the binding. * `deleted:group:{emailid}?uid={uniqueid}`: An email address (plus unique identifier) representing a Google group that has been recently deleted. For example, `admins@example.com?uid=123456789012345678901`. If the group is recovered, this value reverts to `group:{emailid}` and the recovered group retains the role in the binding.
	Members []string `pulumi:"members"`
	// Role that is assigned to the list of `members`, or principals. For example, `roles/viewer`, `roles/editor`, or `roles/owner`.
	Role *string `pulumi:"role"`
}

// GoogleIamV1BindingInput is an input type that accepts GoogleIamV1BindingArgs and GoogleIamV1BindingOutput values.
// You can construct a concrete instance of `GoogleIamV1BindingInput` via:
//
//	GoogleIamV1BindingArgs{...}
type GoogleIamV1BindingInput interface {
	pulumi.Input

	ToGoogleIamV1BindingOutput() GoogleIamV1BindingOutput
	ToGoogleIamV1BindingOutputWithContext(context.Context) GoogleIamV1BindingOutput
}

// Associates `members`, or principals, with a `role`.
type GoogleIamV1BindingArgs struct {
	// The condition that is associated with this binding. If the condition evaluates to `true`, then this binding applies to the current request. If the condition evaluates to `false`, then this binding does not apply to the current request. However, a different role binding might grant the same role to one or more of the principals in this binding. To learn which resources support conditions in their IAM policies, see the [IAM documentation](https://cloud.google.com/iam/help/conditions/resource-policies).
	Condition GoogleTypeExprPtrInput `pulumi:"condition"`
	// Specifies the principals requesting access for a Google Cloud resource. `members` can have the following values: * `allUsers`: A special identifier that represents anyone who is on the internet; with or without a Google account. * `allAuthenticatedUsers`: A special identifier that represents anyone who is authenticated with a Google account or a service account. Does not include identities that come from external identity providers (IdPs) through identity federation. * `user:{emailid}`: An email address that represents a specific Google account. For example, `alice@example.com` . * `serviceAccount:{emailid}`: An email address that represents a Google service account. For example, `my-other-app@appspot.gserviceaccount.com`. * `serviceAccount:{projectid}.svc.id.goog[{namespace}/{kubernetes-sa}]`: An identifier for a [Kubernetes service account](https://cloud.google.com/kubernetes-engine/docs/how-to/kubernetes-service-accounts). For example, `my-project.svc.id.goog[my-namespace/my-kubernetes-sa]`. * `group:{emailid}`: An email address that represents a Google group. For example, `admins@example.com`. * `domain:{domain}`: The G Suite domain (primary) that represents all the users of that domain. For example, `google.com` or `example.com`. * `deleted:user:{emailid}?uid={uniqueid}`: An email address (plus unique identifier) representing a user that has been recently deleted. For example, `alice@example.com?uid=123456789012345678901`. If the user is recovered, this value reverts to `user:{emailid}` and the recovered user retains the role in the binding. * `deleted:serviceAccount:{emailid}?uid={uniqueid}`: An email address (plus unique identifier) representing a service account that has been recently deleted. For example, `my-other-app@appspot.gserviceaccount.com?uid=123456789012345678901`. If the service account is undeleted, this value reverts to `serviceAccount:{emailid}` and the undeleted service account retains the role in the binding. * `deleted:group:{emailid}?uid={uniqueid}`: An email address (plus unique identifier) representing a Google group that has been recently deleted. For example, `admins@example.com?uid=123456789012345678901`. If the group is recovered, this value reverts to `group:{emailid}` and the recovered group retains the role in the binding.
	Members pulumi.StringArrayInput `pulumi:"members"`
	// Role that is assigned to the list of `members`, or principals. For example, `roles/viewer`, `roles/editor`, or `roles/owner`.
	Role pulumi.StringPtrInput `pulumi:"role"`
}

func (GoogleIamV1BindingArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleIamV1Binding)(nil)).Elem()
}

func (i GoogleIamV1BindingArgs) ToGoogleIamV1BindingOutput() GoogleIamV1BindingOutput {
	return i.ToGoogleIamV1BindingOutputWithContext(context.Background())
}

func (i GoogleIamV1BindingArgs) ToGoogleIamV1BindingOutputWithContext(ctx context.Context) GoogleIamV1BindingOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleIamV1BindingOutput)
}

// GoogleIamV1BindingArrayInput is an input type that accepts GoogleIamV1BindingArray and GoogleIamV1BindingArrayOutput values.
// You can construct a concrete instance of `GoogleIamV1BindingArrayInput` via:
//
//	GoogleIamV1BindingArray{ GoogleIamV1BindingArgs{...} }
type GoogleIamV1BindingArrayInput interface {
	pulumi.Input

	ToGoogleIamV1BindingArrayOutput() GoogleIamV1BindingArrayOutput
	ToGoogleIamV1BindingArrayOutputWithContext(context.Context) GoogleIamV1BindingArrayOutput
}

type GoogleIamV1BindingArray []GoogleIamV1BindingInput

func (GoogleIamV1BindingArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleIamV1Binding)(nil)).Elem()
}

func (i GoogleIamV1BindingArray) ToGoogleIamV1BindingArrayOutput() GoogleIamV1BindingArrayOutput {
	return i.ToGoogleIamV1BindingArrayOutputWithContext(context.Background())
}

func (i GoogleIamV1BindingArray) ToGoogleIamV1BindingArrayOutputWithContext(ctx context.Context) GoogleIamV1BindingArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleIamV1BindingArrayOutput)
}

// Associates `members`, or principals, with a `role`.
type GoogleIamV1BindingOutput struct{ *pulumi.OutputState }

func (GoogleIamV1BindingOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleIamV1Binding)(nil)).Elem()
}

func (o GoogleIamV1BindingOutput) ToGoogleIamV1BindingOutput() GoogleIamV1BindingOutput {
	return o
}

func (o GoogleIamV1BindingOutput) ToGoogleIamV1BindingOutputWithContext(ctx context.Context) GoogleIamV1BindingOutput {
	return o
}

// The condition that is associated with this binding. If the condition evaluates to `true`, then this binding applies to the current request. If the condition evaluates to `false`, then this binding does not apply to the current request. However, a different role binding might grant the same role to one or more of the principals in this binding. To learn which resources support conditions in their IAM policies, see the [IAM documentation](https://cloud.google.com/iam/help/conditions/resource-policies).
func (o GoogleIamV1BindingOutput) Condition() GoogleTypeExprPtrOutput {
	return o.ApplyT(func(v GoogleIamV1Binding) *GoogleTypeExpr { return v.Condition }).(GoogleTypeExprPtrOutput)
}

// Specifies the principals requesting access for a Google Cloud resource. `members` can have the following values: * `allUsers`: A special identifier that represents anyone who is on the internet; with or without a Google account. * `allAuthenticatedUsers`: A special identifier that represents anyone who is authenticated with a Google account or a service account. Does not include identities that come from external identity providers (IdPs) through identity federation. * `user:{emailid}`: An email address that represents a specific Google account. For example, `alice@example.com` . * `serviceAccount:{emailid}`: An email address that represents a Google service account. For example, `my-other-app@appspot.gserviceaccount.com`. * `serviceAccount:{projectid}.svc.id.goog[{namespace}/{kubernetes-sa}]`: An identifier for a [Kubernetes service account](https://cloud.google.com/kubernetes-engine/docs/how-to/kubernetes-service-accounts). For example, `my-project.svc.id.goog[my-namespace/my-kubernetes-sa]`. * `group:{emailid}`: An email address that represents a Google group. For example, `admins@example.com`. * `domain:{domain}`: The G Suite domain (primary) that represents all the users of that domain. For example, `google.com` or `example.com`. * `deleted:user:{emailid}?uid={uniqueid}`: An email address (plus unique identifier) representing a user that has been recently deleted. For example, `alice@example.com?uid=123456789012345678901`. If the user is recovered, this value reverts to `user:{emailid}` and the recovered user retains the role in the binding. * `deleted:serviceAccount:{emailid}?uid={uniqueid}`: An email address (plus unique identifier) representing a service account that has been recently deleted. For example, `my-other-app@appspot.gserviceaccount.com?uid=123456789012345678901`. If the service account is undeleted, this value reverts to `serviceAccount:{emailid}` and the undeleted service account retains the role in the binding. * `deleted:group:{emailid}?uid={uniqueid}`: An email address (plus unique identifier) representing a Google group that has been recently deleted. For example, `admins@example.com?uid=123456789012345678901`. If the group is recovered, this value reverts to `group:{emailid}` and the recovered group retains the role in the binding.
func (o GoogleIamV1BindingOutput) Members() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleIamV1Binding) []string { return v.Members }).(pulumi.StringArrayOutput)
}

// Role that is assigned to the list of `members`, or principals. For example, `roles/viewer`, `roles/editor`, or `roles/owner`.
func (o GoogleIamV1BindingOutput) Role() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleIamV1Binding) *string { return v.Role }).(pulumi.StringPtrOutput)
}

type GoogleIamV1BindingArrayOutput struct{ *pulumi.OutputState }

func (GoogleIamV1BindingArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleIamV1Binding)(nil)).Elem()
}

func (o GoogleIamV1BindingArrayOutput) ToGoogleIamV1BindingArrayOutput() GoogleIamV1BindingArrayOutput {
	return o
}

func (o GoogleIamV1BindingArrayOutput) ToGoogleIamV1BindingArrayOutputWithContext(ctx context.Context) GoogleIamV1BindingArrayOutput {
	return o
}

func (o GoogleIamV1BindingArrayOutput) Index(i pulumi.IntInput) GoogleIamV1BindingOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GoogleIamV1Binding {
		return vs[0].([]GoogleIamV1Binding)[vs[1].(int)]
	}).(GoogleIamV1BindingOutput)
}

// Associates `members`, or principals, with a `role`.
type GoogleIamV1BindingResponse struct {
	// The condition that is associated with this binding. If the condition evaluates to `true`, then this binding applies to the current request. If the condition evaluates to `false`, then this binding does not apply to the current request. However, a different role binding might grant the same role to one or more of the principals in this binding. To learn which resources support conditions in their IAM policies, see the [IAM documentation](https://cloud.google.com/iam/help/conditions/resource-policies).
	Condition GoogleTypeExprResponse `pulumi:"condition"`
	// Specifies the principals requesting access for a Google Cloud resource. `members` can have the following values: * `allUsers`: A special identifier that represents anyone who is on the internet; with or without a Google account. * `allAuthenticatedUsers`: A special identifier that represents anyone who is authenticated with a Google account or a service account. Does not include identities that come from external identity providers (IdPs) through identity federation. * `user:{emailid}`: An email address that represents a specific Google account. For example, `alice@example.com` . * `serviceAccount:{emailid}`: An email address that represents a Google service account. For example, `my-other-app@appspot.gserviceaccount.com`. * `serviceAccount:{projectid}.svc.id.goog[{namespace}/{kubernetes-sa}]`: An identifier for a [Kubernetes service account](https://cloud.google.com/kubernetes-engine/docs/how-to/kubernetes-service-accounts). For example, `my-project.svc.id.goog[my-namespace/my-kubernetes-sa]`. * `group:{emailid}`: An email address that represents a Google group. For example, `admins@example.com`. * `domain:{domain}`: The G Suite domain (primary) that represents all the users of that domain. For example, `google.com` or `example.com`. * `deleted:user:{emailid}?uid={uniqueid}`: An email address (plus unique identifier) representing a user that has been recently deleted. For example, `alice@example.com?uid=123456789012345678901`. If the user is recovered, this value reverts to `user:{emailid}` and the recovered user retains the role in the binding. * `deleted:serviceAccount:{emailid}?uid={uniqueid}`: An email address (plus unique identifier) representing a service account that has been recently deleted. For example, `my-other-app@appspot.gserviceaccount.com?uid=123456789012345678901`. If the service account is undeleted, this value reverts to `serviceAccount:{emailid}` and the undeleted service account retains the role in the binding. * `deleted:group:{emailid}?uid={uniqueid}`: An email address (plus unique identifier) representing a Google group that has been recently deleted. For example, `admins@example.com?uid=123456789012345678901`. If the group is recovered, this value reverts to `group:{emailid}` and the recovered group retains the role in the binding.
	Members []string `pulumi:"members"`
	// Role that is assigned to the list of `members`, or principals. For example, `roles/viewer`, `roles/editor`, or `roles/owner`.
	Role string `pulumi:"role"`
}

// Associates `members`, or principals, with a `role`.
type GoogleIamV1BindingResponseOutput struct{ *pulumi.OutputState }

func (GoogleIamV1BindingResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleIamV1BindingResponse)(nil)).Elem()
}

func (o GoogleIamV1BindingResponseOutput) ToGoogleIamV1BindingResponseOutput() GoogleIamV1BindingResponseOutput {
	return o
}

func (o GoogleIamV1BindingResponseOutput) ToGoogleIamV1BindingResponseOutputWithContext(ctx context.Context) GoogleIamV1BindingResponseOutput {
	return o
}

// The condition that is associated with this binding. If the condition evaluates to `true`, then this binding applies to the current request. If the condition evaluates to `false`, then this binding does not apply to the current request. However, a different role binding might grant the same role to one or more of the principals in this binding. To learn which resources support conditions in their IAM policies, see the [IAM documentation](https://cloud.google.com/iam/help/conditions/resource-policies).
func (o GoogleIamV1BindingResponseOutput) Condition() GoogleTypeExprResponseOutput {
	return o.ApplyT(func(v GoogleIamV1BindingResponse) GoogleTypeExprResponse { return v.Condition }).(GoogleTypeExprResponseOutput)
}

// Specifies the principals requesting access for a Google Cloud resource. `members` can have the following values: * `allUsers`: A special identifier that represents anyone who is on the internet; with or without a Google account. * `allAuthenticatedUsers`: A special identifier that represents anyone who is authenticated with a Google account or a service account. Does not include identities that come from external identity providers (IdPs) through identity federation. * `user:{emailid}`: An email address that represents a specific Google account. For example, `alice@example.com` . * `serviceAccount:{emailid}`: An email address that represents a Google service account. For example, `my-other-app@appspot.gserviceaccount.com`. * `serviceAccount:{projectid}.svc.id.goog[{namespace}/{kubernetes-sa}]`: An identifier for a [Kubernetes service account](https://cloud.google.com/kubernetes-engine/docs/how-to/kubernetes-service-accounts). For example, `my-project.svc.id.goog[my-namespace/my-kubernetes-sa]`. * `group:{emailid}`: An email address that represents a Google group. For example, `admins@example.com`. * `domain:{domain}`: The G Suite domain (primary) that represents all the users of that domain. For example, `google.com` or `example.com`. * `deleted:user:{emailid}?uid={uniqueid}`: An email address (plus unique identifier) representing a user that has been recently deleted. For example, `alice@example.com?uid=123456789012345678901`. If the user is recovered, this value reverts to `user:{emailid}` and the recovered user retains the role in the binding. * `deleted:serviceAccount:{emailid}?uid={uniqueid}`: An email address (plus unique identifier) representing a service account that has been recently deleted. For example, `my-other-app@appspot.gserviceaccount.com?uid=123456789012345678901`. If the service account is undeleted, this value reverts to `serviceAccount:{emailid}` and the undeleted service account retains the role in the binding. * `deleted:group:{emailid}?uid={uniqueid}`: An email address (plus unique identifier) representing a Google group that has been recently deleted. For example, `admins@example.com?uid=123456789012345678901`. If the group is recovered, this value reverts to `group:{emailid}` and the recovered group retains the role in the binding.
func (o GoogleIamV1BindingResponseOutput) Members() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GoogleIamV1BindingResponse) []string { return v.Members }).(pulumi.StringArrayOutput)
}

// Role that is assigned to the list of `members`, or principals. For example, `roles/viewer`, `roles/editor`, or `roles/owner`.
func (o GoogleIamV1BindingResponseOutput) Role() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleIamV1BindingResponse) string { return v.Role }).(pulumi.StringOutput)
}

type GoogleIamV1BindingResponseArrayOutput struct{ *pulumi.OutputState }

func (GoogleIamV1BindingResponseArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleIamV1BindingResponse)(nil)).Elem()
}

func (o GoogleIamV1BindingResponseArrayOutput) ToGoogleIamV1BindingResponseArrayOutput() GoogleIamV1BindingResponseArrayOutput {
	return o
}

func (o GoogleIamV1BindingResponseArrayOutput) ToGoogleIamV1BindingResponseArrayOutputWithContext(ctx context.Context) GoogleIamV1BindingResponseArrayOutput {
	return o
}

func (o GoogleIamV1BindingResponseArrayOutput) Index(i pulumi.IntInput) GoogleIamV1BindingResponseOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GoogleIamV1BindingResponse {
		return vs[0].([]GoogleIamV1BindingResponse)[vs[1].(int)]
	}).(GoogleIamV1BindingResponseOutput)
}

// The `Status` type defines a logical error model that is suitable for different programming environments, including REST APIs and RPC APIs. It is used by [gRPC](https://github.com/grpc). Each `Status` message contains three pieces of data: error code, error message, and error details. You can find out more about this error model and how to work with it in the [API Design Guide](https://cloud.google.com/apis/design/errors).
type GoogleRpcStatusResponse struct {
	// The status code, which should be an enum value of google.rpc.Code.
	Code int `pulumi:"code"`
	// A list of messages that carry the error details. There is a common set of message types for APIs to use.
	Details []map[string]interface{} `pulumi:"details"`
	// A developer-facing error message, which should be in English. Any user-facing error message should be localized and sent in the google.rpc.Status.details field, or localized by the client.
	Message string `pulumi:"message"`
}

// The `Status` type defines a logical error model that is suitable for different programming environments, including REST APIs and RPC APIs. It is used by [gRPC](https://github.com/grpc). Each `Status` message contains three pieces of data: error code, error message, and error details. You can find out more about this error model and how to work with it in the [API Design Guide](https://cloud.google.com/apis/design/errors).
type GoogleRpcStatusResponseOutput struct{ *pulumi.OutputState }

func (GoogleRpcStatusResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleRpcStatusResponse)(nil)).Elem()
}

func (o GoogleRpcStatusResponseOutput) ToGoogleRpcStatusResponseOutput() GoogleRpcStatusResponseOutput {
	return o
}

func (o GoogleRpcStatusResponseOutput) ToGoogleRpcStatusResponseOutputWithContext(ctx context.Context) GoogleRpcStatusResponseOutput {
	return o
}

// The status code, which should be an enum value of google.rpc.Code.
func (o GoogleRpcStatusResponseOutput) Code() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleRpcStatusResponse) int { return v.Code }).(pulumi.IntOutput)
}

// A list of messages that carry the error details. There is a common set of message types for APIs to use.
func (o GoogleRpcStatusResponseOutput) Details() pulumi.MapArrayOutput {
	return o.ApplyT(func(v GoogleRpcStatusResponse) []map[string]interface{} { return v.Details }).(pulumi.MapArrayOutput)
}

// A developer-facing error message, which should be in English. Any user-facing error message should be localized and sent in the google.rpc.Status.details field, or localized by the client.
func (o GoogleRpcStatusResponseOutput) Message() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleRpcStatusResponse) string { return v.Message }).(pulumi.StringOutput)
}

type GoogleRpcStatusResponseArrayOutput struct{ *pulumi.OutputState }

func (GoogleRpcStatusResponseArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GoogleRpcStatusResponse)(nil)).Elem()
}

func (o GoogleRpcStatusResponseArrayOutput) ToGoogleRpcStatusResponseArrayOutput() GoogleRpcStatusResponseArrayOutput {
	return o
}

func (o GoogleRpcStatusResponseArrayOutput) ToGoogleRpcStatusResponseArrayOutputWithContext(ctx context.Context) GoogleRpcStatusResponseArrayOutput {
	return o
}

func (o GoogleRpcStatusResponseArrayOutput) Index(i pulumi.IntInput) GoogleRpcStatusResponseOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GoogleRpcStatusResponse {
		return vs[0].([]GoogleRpcStatusResponse)[vs[1].(int)]
	}).(GoogleRpcStatusResponseOutput)
}

// Represents a textual expression in the Common Expression Language (CEL) syntax. CEL is a C-like expression language. The syntax and semantics of CEL are documented at https://github.com/google/cel-spec. Example (Comparison): title: "Summary size limit" description: "Determines if a summary is less than 100 chars" expression: "document.summary.size() < 100" Example (Equality): title: "Requestor is owner" description: "Determines if requestor is the document owner" expression: "document.owner == request.auth.claims.email" Example (Logic): title: "Public documents" description: "Determine whether the document should be publicly visible" expression: "document.type != 'private' && document.type != 'internal'" Example (Data Manipulation): title: "Notification string" description: "Create a notification string with a timestamp." expression: "'New message received at ' + string(document.create_time)" The exact variables and functions that may be referenced within an expression are determined by the service that evaluates it. See the service documentation for additional information.
type GoogleTypeExpr struct {
	// Optional. Description of the expression. This is a longer text which describes the expression, e.g. when hovered over it in a UI.
	Description *string `pulumi:"description"`
	// Textual representation of an expression in Common Expression Language syntax.
	Expression *string `pulumi:"expression"`
	// Optional. String indicating the location of the expression for error reporting, e.g. a file name and a position in the file.
	Location *string `pulumi:"location"`
	// Optional. Title for the expression, i.e. a short string describing its purpose. This can be used e.g. in UIs which allow to enter the expression.
	Title *string `pulumi:"title"`
}

// GoogleTypeExprInput is an input type that accepts GoogleTypeExprArgs and GoogleTypeExprOutput values.
// You can construct a concrete instance of `GoogleTypeExprInput` via:
//
//	GoogleTypeExprArgs{...}
type GoogleTypeExprInput interface {
	pulumi.Input

	ToGoogleTypeExprOutput() GoogleTypeExprOutput
	ToGoogleTypeExprOutputWithContext(context.Context) GoogleTypeExprOutput
}

// Represents a textual expression in the Common Expression Language (CEL) syntax. CEL is a C-like expression language. The syntax and semantics of CEL are documented at https://github.com/google/cel-spec. Example (Comparison): title: "Summary size limit" description: "Determines if a summary is less than 100 chars" expression: "document.summary.size() < 100" Example (Equality): title: "Requestor is owner" description: "Determines if requestor is the document owner" expression: "document.owner == request.auth.claims.email" Example (Logic): title: "Public documents" description: "Determine whether the document should be publicly visible" expression: "document.type != 'private' && document.type != 'internal'" Example (Data Manipulation): title: "Notification string" description: "Create a notification string with a timestamp." expression: "'New message received at ' + string(document.create_time)" The exact variables and functions that may be referenced within an expression are determined by the service that evaluates it. See the service documentation for additional information.
type GoogleTypeExprArgs struct {
	// Optional. Description of the expression. This is a longer text which describes the expression, e.g. when hovered over it in a UI.
	Description pulumi.StringPtrInput `pulumi:"description"`
	// Textual representation of an expression in Common Expression Language syntax.
	Expression pulumi.StringPtrInput `pulumi:"expression"`
	// Optional. String indicating the location of the expression for error reporting, e.g. a file name and a position in the file.
	Location pulumi.StringPtrInput `pulumi:"location"`
	// Optional. Title for the expression, i.e. a short string describing its purpose. This can be used e.g. in UIs which allow to enter the expression.
	Title pulumi.StringPtrInput `pulumi:"title"`
}

func (GoogleTypeExprArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleTypeExpr)(nil)).Elem()
}

func (i GoogleTypeExprArgs) ToGoogleTypeExprOutput() GoogleTypeExprOutput {
	return i.ToGoogleTypeExprOutputWithContext(context.Background())
}

func (i GoogleTypeExprArgs) ToGoogleTypeExprOutputWithContext(ctx context.Context) GoogleTypeExprOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleTypeExprOutput)
}

func (i GoogleTypeExprArgs) ToGoogleTypeExprPtrOutput() GoogleTypeExprPtrOutput {
	return i.ToGoogleTypeExprPtrOutputWithContext(context.Background())
}

func (i GoogleTypeExprArgs) ToGoogleTypeExprPtrOutputWithContext(ctx context.Context) GoogleTypeExprPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleTypeExprOutput).ToGoogleTypeExprPtrOutputWithContext(ctx)
}

// GoogleTypeExprPtrInput is an input type that accepts GoogleTypeExprArgs, GoogleTypeExprPtr and GoogleTypeExprPtrOutput values.
// You can construct a concrete instance of `GoogleTypeExprPtrInput` via:
//
//	        GoogleTypeExprArgs{...}
//
//	or:
//
//	        nil
type GoogleTypeExprPtrInput interface {
	pulumi.Input

	ToGoogleTypeExprPtrOutput() GoogleTypeExprPtrOutput
	ToGoogleTypeExprPtrOutputWithContext(context.Context) GoogleTypeExprPtrOutput
}

type googleTypeExprPtrType GoogleTypeExprArgs

func GoogleTypeExprPtr(v *GoogleTypeExprArgs) GoogleTypeExprPtrInput {
	return (*googleTypeExprPtrType)(v)
}

func (*googleTypeExprPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleTypeExpr)(nil)).Elem()
}

func (i *googleTypeExprPtrType) ToGoogleTypeExprPtrOutput() GoogleTypeExprPtrOutput {
	return i.ToGoogleTypeExprPtrOutputWithContext(context.Background())
}

func (i *googleTypeExprPtrType) ToGoogleTypeExprPtrOutputWithContext(ctx context.Context) GoogleTypeExprPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GoogleTypeExprPtrOutput)
}

// Represents a textual expression in the Common Expression Language (CEL) syntax. CEL is a C-like expression language. The syntax and semantics of CEL are documented at https://github.com/google/cel-spec. Example (Comparison): title: "Summary size limit" description: "Determines if a summary is less than 100 chars" expression: "document.summary.size() < 100" Example (Equality): title: "Requestor is owner" description: "Determines if requestor is the document owner" expression: "document.owner == request.auth.claims.email" Example (Logic): title: "Public documents" description: "Determine whether the document should be publicly visible" expression: "document.type != 'private' && document.type != 'internal'" Example (Data Manipulation): title: "Notification string" description: "Create a notification string with a timestamp." expression: "'New message received at ' + string(document.create_time)" The exact variables and functions that may be referenced within an expression are determined by the service that evaluates it. See the service documentation for additional information.
type GoogleTypeExprOutput struct{ *pulumi.OutputState }

func (GoogleTypeExprOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleTypeExpr)(nil)).Elem()
}

func (o GoogleTypeExprOutput) ToGoogleTypeExprOutput() GoogleTypeExprOutput {
	return o
}

func (o GoogleTypeExprOutput) ToGoogleTypeExprOutputWithContext(ctx context.Context) GoogleTypeExprOutput {
	return o
}

func (o GoogleTypeExprOutput) ToGoogleTypeExprPtrOutput() GoogleTypeExprPtrOutput {
	return o.ToGoogleTypeExprPtrOutputWithContext(context.Background())
}

func (o GoogleTypeExprOutput) ToGoogleTypeExprPtrOutputWithContext(ctx context.Context) GoogleTypeExprPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v GoogleTypeExpr) *GoogleTypeExpr {
		return &v
	}).(GoogleTypeExprPtrOutput)
}

// Optional. Description of the expression. This is a longer text which describes the expression, e.g. when hovered over it in a UI.
func (o GoogleTypeExprOutput) Description() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleTypeExpr) *string { return v.Description }).(pulumi.StringPtrOutput)
}

// Textual representation of an expression in Common Expression Language syntax.
func (o GoogleTypeExprOutput) Expression() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleTypeExpr) *string { return v.Expression }).(pulumi.StringPtrOutput)
}

// Optional. String indicating the location of the expression for error reporting, e.g. a file name and a position in the file.
func (o GoogleTypeExprOutput) Location() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleTypeExpr) *string { return v.Location }).(pulumi.StringPtrOutput)
}

// Optional. Title for the expression, i.e. a short string describing its purpose. This can be used e.g. in UIs which allow to enter the expression.
func (o GoogleTypeExprOutput) Title() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GoogleTypeExpr) *string { return v.Title }).(pulumi.StringPtrOutput)
}

type GoogleTypeExprPtrOutput struct{ *pulumi.OutputState }

func (GoogleTypeExprPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GoogleTypeExpr)(nil)).Elem()
}

func (o GoogleTypeExprPtrOutput) ToGoogleTypeExprPtrOutput() GoogleTypeExprPtrOutput {
	return o
}

func (o GoogleTypeExprPtrOutput) ToGoogleTypeExprPtrOutputWithContext(ctx context.Context) GoogleTypeExprPtrOutput {
	return o
}

func (o GoogleTypeExprPtrOutput) Elem() GoogleTypeExprOutput {
	return o.ApplyT(func(v *GoogleTypeExpr) GoogleTypeExpr {
		if v != nil {
			return *v
		}
		var ret GoogleTypeExpr
		return ret
	}).(GoogleTypeExprOutput)
}

// Optional. Description of the expression. This is a longer text which describes the expression, e.g. when hovered over it in a UI.
func (o GoogleTypeExprPtrOutput) Description() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleTypeExpr) *string {
		if v == nil {
			return nil
		}
		return v.Description
	}).(pulumi.StringPtrOutput)
}

// Textual representation of an expression in Common Expression Language syntax.
func (o GoogleTypeExprPtrOutput) Expression() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleTypeExpr) *string {
		if v == nil {
			return nil
		}
		return v.Expression
	}).(pulumi.StringPtrOutput)
}

// Optional. String indicating the location of the expression for error reporting, e.g. a file name and a position in the file.
func (o GoogleTypeExprPtrOutput) Location() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleTypeExpr) *string {
		if v == nil {
			return nil
		}
		return v.Location
	}).(pulumi.StringPtrOutput)
}

// Optional. Title for the expression, i.e. a short string describing its purpose. This can be used e.g. in UIs which allow to enter the expression.
func (o GoogleTypeExprPtrOutput) Title() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GoogleTypeExpr) *string {
		if v == nil {
			return nil
		}
		return v.Title
	}).(pulumi.StringPtrOutput)
}

// Represents a textual expression in the Common Expression Language (CEL) syntax. CEL is a C-like expression language. The syntax and semantics of CEL are documented at https://github.com/google/cel-spec. Example (Comparison): title: "Summary size limit" description: "Determines if a summary is less than 100 chars" expression: "document.summary.size() < 100" Example (Equality): title: "Requestor is owner" description: "Determines if requestor is the document owner" expression: "document.owner == request.auth.claims.email" Example (Logic): title: "Public documents" description: "Determine whether the document should be publicly visible" expression: "document.type != 'private' && document.type != 'internal'" Example (Data Manipulation): title: "Notification string" description: "Create a notification string with a timestamp." expression: "'New message received at ' + string(document.create_time)" The exact variables and functions that may be referenced within an expression are determined by the service that evaluates it. See the service documentation for additional information.
type GoogleTypeExprResponse struct {
	// Optional. Description of the expression. This is a longer text which describes the expression, e.g. when hovered over it in a UI.
	Description string `pulumi:"description"`
	// Textual representation of an expression in Common Expression Language syntax.
	Expression string `pulumi:"expression"`
	// Optional. String indicating the location of the expression for error reporting, e.g. a file name and a position in the file.
	Location string `pulumi:"location"`
	// Optional. Title for the expression, i.e. a short string describing its purpose. This can be used e.g. in UIs which allow to enter the expression.
	Title string `pulumi:"title"`
}

// Represents a textual expression in the Common Expression Language (CEL) syntax. CEL is a C-like expression language. The syntax and semantics of CEL are documented at https://github.com/google/cel-spec. Example (Comparison): title: "Summary size limit" description: "Determines if a summary is less than 100 chars" expression: "document.summary.size() < 100" Example (Equality): title: "Requestor is owner" description: "Determines if requestor is the document owner" expression: "document.owner == request.auth.claims.email" Example (Logic): title: "Public documents" description: "Determine whether the document should be publicly visible" expression: "document.type != 'private' && document.type != 'internal'" Example (Data Manipulation): title: "Notification string" description: "Create a notification string with a timestamp." expression: "'New message received at ' + string(document.create_time)" The exact variables and functions that may be referenced within an expression are determined by the service that evaluates it. See the service documentation for additional information.
type GoogleTypeExprResponseOutput struct{ *pulumi.OutputState }

func (GoogleTypeExprResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleTypeExprResponse)(nil)).Elem()
}

func (o GoogleTypeExprResponseOutput) ToGoogleTypeExprResponseOutput() GoogleTypeExprResponseOutput {
	return o
}

func (o GoogleTypeExprResponseOutput) ToGoogleTypeExprResponseOutputWithContext(ctx context.Context) GoogleTypeExprResponseOutput {
	return o
}

// Optional. Description of the expression. This is a longer text which describes the expression, e.g. when hovered over it in a UI.
func (o GoogleTypeExprResponseOutput) Description() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleTypeExprResponse) string { return v.Description }).(pulumi.StringOutput)
}

// Textual representation of an expression in Common Expression Language syntax.
func (o GoogleTypeExprResponseOutput) Expression() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleTypeExprResponse) string { return v.Expression }).(pulumi.StringOutput)
}

// Optional. String indicating the location of the expression for error reporting, e.g. a file name and a position in the file.
func (o GoogleTypeExprResponseOutput) Location() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleTypeExprResponse) string { return v.Location }).(pulumi.StringOutput)
}

// Optional. Title for the expression, i.e. a short string describing its purpose. This can be used e.g. in UIs which allow to enter the expression.
func (o GoogleTypeExprResponseOutput) Title() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleTypeExprResponse) string { return v.Title }).(pulumi.StringOutput)
}

// Represents an amount of money with its currency type.
type GoogleTypeMoneyResponse struct {
	// The three-letter currency code defined in ISO 4217.
	CurrencyCode string `pulumi:"currencyCode"`
	// Number of nano (10^-9) units of the amount. The value must be between -999,999,999 and +999,999,999 inclusive. If `units` is positive, `nanos` must be positive or zero. If `units` is zero, `nanos` can be positive, zero, or negative. If `units` is negative, `nanos` must be negative or zero. For example $-1.75 is represented as `units`=-1 and `nanos`=-750,000,000.
	Nanos int `pulumi:"nanos"`
	// The whole units of the amount. For example if `currencyCode` is `"USD"`, then 1 unit is one US dollar.
	Units string `pulumi:"units"`
}

// Represents an amount of money with its currency type.
type GoogleTypeMoneyResponseOutput struct{ *pulumi.OutputState }

func (GoogleTypeMoneyResponseOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GoogleTypeMoneyResponse)(nil)).Elem()
}

func (o GoogleTypeMoneyResponseOutput) ToGoogleTypeMoneyResponseOutput() GoogleTypeMoneyResponseOutput {
	return o
}

func (o GoogleTypeMoneyResponseOutput) ToGoogleTypeMoneyResponseOutputWithContext(ctx context.Context) GoogleTypeMoneyResponseOutput {
	return o
}

// The three-letter currency code defined in ISO 4217.
func (o GoogleTypeMoneyResponseOutput) CurrencyCode() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleTypeMoneyResponse) string { return v.CurrencyCode }).(pulumi.StringOutput)
}

// Number of nano (10^-9) units of the amount. The value must be between -999,999,999 and +999,999,999 inclusive. If `units` is positive, `nanos` must be positive or zero. If `units` is zero, `nanos` can be positive, zero, or negative. If `units` is negative, `nanos` must be negative or zero. For example $-1.75 is represented as `units`=-1 and `nanos`=-750,000,000.
func (o GoogleTypeMoneyResponseOutput) Nanos() pulumi.IntOutput {
	return o.ApplyT(func(v GoogleTypeMoneyResponse) int { return v.Nanos }).(pulumi.IntOutput)
}

// The whole units of the amount. For example if `currencyCode` is `"USD"`, then 1 unit is one US dollar.
func (o GoogleTypeMoneyResponseOutput) Units() pulumi.StringOutput {
	return o.ApplyT(func(v GoogleTypeMoneyResponse) string { return v.Units }).(pulumi.StringOutput)
}

func init() {
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1ActiveLearningConfigInput)(nil)).Elem(), GoogleCloudAiplatformV1ActiveLearningConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1ActiveLearningConfigPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1ActiveLearningConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1AutoscalingMetricSpecInput)(nil)).Elem(), GoogleCloudAiplatformV1AutoscalingMetricSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1AutoscalingMetricSpecArrayInput)(nil)).Elem(), GoogleCloudAiplatformV1AutoscalingMetricSpecArray{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1BatchDedicatedResourcesInput)(nil)).Elem(), GoogleCloudAiplatformV1BatchDedicatedResourcesArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1BatchDedicatedResourcesPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1BatchDedicatedResourcesArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1BatchPredictionJobInputConfigInput)(nil)).Elem(), GoogleCloudAiplatformV1BatchPredictionJobInputConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1BatchPredictionJobInstanceConfigInput)(nil)).Elem(), GoogleCloudAiplatformV1BatchPredictionJobInstanceConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1BatchPredictionJobInstanceConfigPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1BatchPredictionJobInstanceConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1BatchPredictionJobOutputConfigInput)(nil)).Elem(), GoogleCloudAiplatformV1BatchPredictionJobOutputConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1BigQueryDestinationInput)(nil)).Elem(), GoogleCloudAiplatformV1BigQueryDestinationArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1BigQueryDestinationPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1BigQueryDestinationArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1BigQuerySourceInput)(nil)).Elem(), GoogleCloudAiplatformV1BigQuerySourceArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1BigQuerySourcePtrInput)(nil)).Elem(), GoogleCloudAiplatformV1BigQuerySourceArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1BlurBaselineConfigInput)(nil)).Elem(), GoogleCloudAiplatformV1BlurBaselineConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1BlurBaselineConfigPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1BlurBaselineConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1ContainerSpecInput)(nil)).Elem(), GoogleCloudAiplatformV1ContainerSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1ContainerSpecPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1ContainerSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1CreatePipelineJobRequestInput)(nil)).Elem(), GoogleCloudAiplatformV1CreatePipelineJobRequestArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1CreatePipelineJobRequestPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1CreatePipelineJobRequestArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1CustomJobSpecInput)(nil)).Elem(), GoogleCloudAiplatformV1CustomJobSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1CustomJobSpecPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1CustomJobSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1DedicatedResourcesInput)(nil)).Elem(), GoogleCloudAiplatformV1DedicatedResourcesArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1DiskSpecInput)(nil)).Elem(), GoogleCloudAiplatformV1DiskSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1DiskSpecPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1DiskSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1EncryptionSpecInput)(nil)).Elem(), GoogleCloudAiplatformV1EncryptionSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1EncryptionSpecPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1EncryptionSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1EnvVarInput)(nil)).Elem(), GoogleCloudAiplatformV1EnvVarArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1EnvVarArrayInput)(nil)).Elem(), GoogleCloudAiplatformV1EnvVarArray{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1ExamplesInput)(nil)).Elem(), GoogleCloudAiplatformV1ExamplesArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1ExamplesPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1ExamplesArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1ExamplesExampleGcsSourceInput)(nil)).Elem(), GoogleCloudAiplatformV1ExamplesExampleGcsSourceArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1ExamplesExampleGcsSourcePtrInput)(nil)).Elem(), GoogleCloudAiplatformV1ExamplesExampleGcsSourceArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1ExplanationMetadataInput)(nil)).Elem(), GoogleCloudAiplatformV1ExplanationMetadataArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1ExplanationMetadataPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1ExplanationMetadataArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1ExplanationMetadataInputMetadataInput)(nil)).Elem(), GoogleCloudAiplatformV1ExplanationMetadataInputMetadataArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1ExplanationMetadataInputMetadataMapInput)(nil)).Elem(), GoogleCloudAiplatformV1ExplanationMetadataInputMetadataMap{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainInput)(nil)).Elem(), GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationInput)(nil)).Elem(), GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1ExplanationMetadataOutputMetadataInput)(nil)).Elem(), GoogleCloudAiplatformV1ExplanationMetadataOutputMetadataArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1ExplanationMetadataOutputMetadataMapInput)(nil)).Elem(), GoogleCloudAiplatformV1ExplanationMetadataOutputMetadataMap{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1ExplanationParametersInput)(nil)).Elem(), GoogleCloudAiplatformV1ExplanationParametersArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1ExplanationParametersPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1ExplanationParametersArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1ExplanationSpecInput)(nil)).Elem(), GoogleCloudAiplatformV1ExplanationSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1ExplanationSpecPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1ExplanationSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1FeatureGroupBigQueryInput)(nil)).Elem(), GoogleCloudAiplatformV1FeatureGroupBigQueryArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1FeatureGroupBigQueryPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1FeatureGroupBigQueryArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1FeatureNoiseSigmaInput)(nil)).Elem(), GoogleCloudAiplatformV1FeatureNoiseSigmaArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1FeatureNoiseSigmaPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1FeatureNoiseSigmaArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureInput)(nil)).Elem(), GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureArrayInput)(nil)).Elem(), GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureArray{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1FeatureOnlineStoreBigtableInput)(nil)).Elem(), GoogleCloudAiplatformV1FeatureOnlineStoreBigtableArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1FeatureOnlineStoreBigtablePtrInput)(nil)).Elem(), GoogleCloudAiplatformV1FeatureOnlineStoreBigtableArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingInput)(nil)).Elem(), GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1FeatureViewBigQuerySourceInput)(nil)).Elem(), GoogleCloudAiplatformV1FeatureViewBigQuerySourceArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1FeatureViewBigQuerySourcePtrInput)(nil)).Elem(), GoogleCloudAiplatformV1FeatureViewBigQuerySourceArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceInput)(nil)).Elem(), GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourcePtrInput)(nil)).Elem(), GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupInput)(nil)).Elem(), GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupArrayInput)(nil)).Elem(), GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupArray{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1FeatureViewSyncConfigInput)(nil)).Elem(), GoogleCloudAiplatformV1FeatureViewSyncConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1FeatureViewSyncConfigPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1FeatureViewSyncConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1FeaturestoreMonitoringConfigInput)(nil)).Elem(), GoogleCloudAiplatformV1FeaturestoreMonitoringConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1FeaturestoreMonitoringConfigPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1FeaturestoreMonitoringConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisInput)(nil)).Elem(), GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisInput)(nil)).Elem(), GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigInput)(nil)).Elem(), GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigInput)(nil)).Elem(), GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingInput)(nil)).Elem(), GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1FilterSplitInput)(nil)).Elem(), GoogleCloudAiplatformV1FilterSplitArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1FilterSplitPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1FilterSplitArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1FractionSplitInput)(nil)).Elem(), GoogleCloudAiplatformV1FractionSplitArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1FractionSplitPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1FractionSplitArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1GcsDestinationInput)(nil)).Elem(), GoogleCloudAiplatformV1GcsDestinationArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1GcsDestinationPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1GcsDestinationArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1GcsSourceInput)(nil)).Elem(), GoogleCloudAiplatformV1GcsSourceArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1GcsSourcePtrInput)(nil)).Elem(), GoogleCloudAiplatformV1GcsSourceArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1InputDataConfigInput)(nil)).Elem(), GoogleCloudAiplatformV1InputDataConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1InputDataConfigPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1InputDataConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1IntegratedGradientsAttributionInput)(nil)).Elem(), GoogleCloudAiplatformV1IntegratedGradientsAttributionArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1IntegratedGradientsAttributionPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1IntegratedGradientsAttributionArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1MachineSpecInput)(nil)).Elem(), GoogleCloudAiplatformV1MachineSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1MachineSpecPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1MachineSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1ManualBatchTuningParametersInput)(nil)).Elem(), GoogleCloudAiplatformV1ManualBatchTuningParametersArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1ManualBatchTuningParametersPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1ManualBatchTuningParametersArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1ModelInput)(nil)).Elem(), GoogleCloudAiplatformV1ModelArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1ModelPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1ModelArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1ModelContainerSpecInput)(nil)).Elem(), GoogleCloudAiplatformV1ModelContainerSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1ModelContainerSpecPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1ModelContainerSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigInput)(nil)).Elem(), GoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigArrayInput)(nil)).Elem(), GoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigArray{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1ModelDeploymentMonitoringScheduleConfigInput)(nil)).Elem(), GoogleCloudAiplatformV1ModelDeploymentMonitoringScheduleConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1ModelMonitoringAlertConfigInput)(nil)).Elem(), GoogleCloudAiplatformV1ModelMonitoringAlertConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1ModelMonitoringAlertConfigPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1ModelMonitoringAlertConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigInput)(nil)).Elem(), GoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigInput)(nil)).Elem(), GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigInput)(nil)).Elem(), GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineInput)(nil)).Elem(), GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrInput)(nil)).Elem(), GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigInput)(nil)).Elem(), GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetInput)(nil)).Elem(), GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigInput)(nil)).Elem(), GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1NasJobSpecInput)(nil)).Elem(), GoogleCloudAiplatformV1NasJobSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecInput)(nil)).Elem(), GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecInput)(nil)).Elem(), GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecInput)(nil)).Elem(), GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecInput)(nil)).Elem(), GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1NetworkSpecInput)(nil)).Elem(), GoogleCloudAiplatformV1NetworkSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1NetworkSpecPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1NetworkSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1NfsMountInput)(nil)).Elem(), GoogleCloudAiplatformV1NfsMountArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1NfsMountArrayInput)(nil)).Elem(), GoogleCloudAiplatformV1NfsMountArray{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1NotebookEucConfigInput)(nil)).Elem(), GoogleCloudAiplatformV1NotebookEucConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1NotebookEucConfigPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1NotebookEucConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1NotebookIdleShutdownConfigInput)(nil)).Elem(), GoogleCloudAiplatformV1NotebookIdleShutdownConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1NotebookIdleShutdownConfigPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1NotebookIdleShutdownConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1PersistentDiskSpecInput)(nil)).Elem(), GoogleCloudAiplatformV1PersistentDiskSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1PersistentDiskSpecPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1PersistentDiskSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1PipelineJobInput)(nil)).Elem(), GoogleCloudAiplatformV1PipelineJobArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1PipelineJobPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1PipelineJobArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1PipelineJobRuntimeConfigInput)(nil)).Elem(), GoogleCloudAiplatformV1PipelineJobRuntimeConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1PipelineJobRuntimeConfigPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1PipelineJobRuntimeConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactInput)(nil)).Elem(), GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactMapInput)(nil)).Elem(), GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactMap{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1PortInput)(nil)).Elem(), GoogleCloudAiplatformV1PortArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1PortArrayInput)(nil)).Elem(), GoogleCloudAiplatformV1PortArray{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1PredefinedSplitInput)(nil)).Elem(), GoogleCloudAiplatformV1PredefinedSplitArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1PredefinedSplitPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1PredefinedSplitArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1PredictRequestResponseLoggingConfigInput)(nil)).Elem(), GoogleCloudAiplatformV1PredictRequestResponseLoggingConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1PredictRequestResponseLoggingConfigPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1PredictRequestResponseLoggingConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1PredictSchemataInput)(nil)).Elem(), GoogleCloudAiplatformV1PredictSchemataArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1PredictSchemataPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1PredictSchemataArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1PresetsInput)(nil)).Elem(), GoogleCloudAiplatformV1PresetsArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1PresetsPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1PresetsArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1PrivateServiceConnectConfigInput)(nil)).Elem(), GoogleCloudAiplatformV1PrivateServiceConnectConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1PrivateServiceConnectConfigPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1PrivateServiceConnectConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1ProbeInput)(nil)).Elem(), GoogleCloudAiplatformV1ProbeArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1ProbePtrInput)(nil)).Elem(), GoogleCloudAiplatformV1ProbeArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1ProbeExecActionInput)(nil)).Elem(), GoogleCloudAiplatformV1ProbeExecActionArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1ProbeExecActionPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1ProbeExecActionArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1PythonPackageSpecInput)(nil)).Elem(), GoogleCloudAiplatformV1PythonPackageSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1PythonPackageSpecPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1PythonPackageSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1SampleConfigInput)(nil)).Elem(), GoogleCloudAiplatformV1SampleConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1SampleConfigPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1SampleConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1SampledShapleyAttributionInput)(nil)).Elem(), GoogleCloudAiplatformV1SampledShapleyAttributionArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1SampledShapleyAttributionPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1SampledShapleyAttributionArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1SamplingStrategyInput)(nil)).Elem(), GoogleCloudAiplatformV1SamplingStrategyArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1SamplingStrategyPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1SamplingStrategyArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigInput)(nil)).Elem(), GoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1SavedQueryInput)(nil)).Elem(), GoogleCloudAiplatformV1SavedQueryArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1SavedQueryArrayInput)(nil)).Elem(), GoogleCloudAiplatformV1SavedQueryArray{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1SchedulingInput)(nil)).Elem(), GoogleCloudAiplatformV1SchedulingArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1SchedulingPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1SchedulingArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1SmoothGradConfigInput)(nil)).Elem(), GoogleCloudAiplatformV1SmoothGradConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1SmoothGradConfigPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1SmoothGradConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1StratifiedSplitInput)(nil)).Elem(), GoogleCloudAiplatformV1StratifiedSplitArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1StratifiedSplitPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1StratifiedSplitArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1StudySpecInput)(nil)).Elem(), GoogleCloudAiplatformV1StudySpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecInput)(nil)).Elem(), GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecInput)(nil)).Elem(), GoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecInput)(nil)).Elem(), GoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1StudySpecMetricSpecInput)(nil)).Elem(), GoogleCloudAiplatformV1StudySpecMetricSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1StudySpecMetricSpecArrayInput)(nil)).Elem(), GoogleCloudAiplatformV1StudySpecMetricSpecArray{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigInput)(nil)).Elem(), GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1StudySpecParameterSpecInput)(nil)).Elem(), GoogleCloudAiplatformV1StudySpecParameterSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1StudySpecParameterSpecArrayInput)(nil)).Elem(), GoogleCloudAiplatformV1StudySpecParameterSpecArray{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecInput)(nil)).Elem(), GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecInput)(nil)).Elem(), GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecArrayInput)(nil)).Elem(), GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecArray{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionInput)(nil)).Elem(), GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionInput)(nil)).Elem(), GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionInput)(nil)).Elem(), GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecInput)(nil)).Elem(), GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecInput)(nil)).Elem(), GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecInput)(nil)).Elem(), GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1StudySpecStudyStoppingConfigInput)(nil)).Elem(), GoogleCloudAiplatformV1StudySpecStudyStoppingConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1StudySpecStudyStoppingConfigPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1StudySpecStudyStoppingConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1StudyTimeConstraintInput)(nil)).Elem(), GoogleCloudAiplatformV1StudyTimeConstraintArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1StudyTimeConstraintPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1StudyTimeConstraintArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1ThresholdConfigInput)(nil)).Elem(), GoogleCloudAiplatformV1ThresholdConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1ThresholdConfigPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1ThresholdConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1ThresholdConfigMapInput)(nil)).Elem(), GoogleCloudAiplatformV1ThresholdConfigMap{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1TimestampSplitInput)(nil)).Elem(), GoogleCloudAiplatformV1TimestampSplitArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1TimestampSplitPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1TimestampSplitArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1TrainingConfigInput)(nil)).Elem(), GoogleCloudAiplatformV1TrainingConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1TrainingConfigPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1TrainingConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1UnmanagedContainerModelInput)(nil)).Elem(), GoogleCloudAiplatformV1UnmanagedContainerModelArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1UnmanagedContainerModelPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1UnmanagedContainerModelArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1ValueInput)(nil)).Elem(), GoogleCloudAiplatformV1ValueArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1ValueMapInput)(nil)).Elem(), GoogleCloudAiplatformV1ValueMap{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1WorkerPoolSpecInput)(nil)).Elem(), GoogleCloudAiplatformV1WorkerPoolSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1WorkerPoolSpecArrayInput)(nil)).Elem(), GoogleCloudAiplatformV1WorkerPoolSpecArray{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1XraiAttributionInput)(nil)).Elem(), GoogleCloudAiplatformV1XraiAttributionArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleCloudAiplatformV1XraiAttributionPtrInput)(nil)).Elem(), GoogleCloudAiplatformV1XraiAttributionArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleIamV1BindingInput)(nil)).Elem(), GoogleIamV1BindingArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleIamV1BindingArrayInput)(nil)).Elem(), GoogleIamV1BindingArray{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleTypeExprInput)(nil)).Elem(), GoogleTypeExprArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GoogleTypeExprPtrInput)(nil)).Elem(), GoogleTypeExprArgs{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ActiveLearningConfigOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ActiveLearningConfigPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ActiveLearningConfigResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ArtifactResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ArtifactResponseArrayOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1AutomaticResourcesResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1AutoscalingMetricSpecOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1AutoscalingMetricSpecArrayOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1AutoscalingMetricSpecResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1AutoscalingMetricSpecResponseArrayOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1BatchDedicatedResourcesOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1BatchDedicatedResourcesPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1BatchDedicatedResourcesResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1BatchPredictionJobInputConfigOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1BatchPredictionJobInputConfigResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1BatchPredictionJobInstanceConfigOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1BatchPredictionJobInstanceConfigPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1BatchPredictionJobInstanceConfigResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1BatchPredictionJobOutputConfigOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1BatchPredictionJobOutputConfigResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1BatchPredictionJobOutputInfoResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1BigQueryDestinationOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1BigQueryDestinationPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1BigQueryDestinationResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1BigQuerySourceOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1BigQuerySourcePtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1BigQuerySourceResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1BlurBaselineConfigOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1BlurBaselineConfigPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1BlurBaselineConfigResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1CompletionStatsResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ContainerSpecOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ContainerSpecPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ContainerSpecResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ContextResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1CreatePipelineJobRequestOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1CreatePipelineJobRequestPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1CreatePipelineJobRequestResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1CustomJobSpecOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1CustomJobSpecPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1CustomJobSpecResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1DedicatedResourcesOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1DedicatedResourcesResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1DeployedIndexAuthConfigAuthProviderResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1DeployedIndexAuthConfigResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1DeployedIndexRefResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1DeployedIndexRefResponseArrayOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1DeployedIndexResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1DeployedIndexResponseArrayOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1DeployedModelRefResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1DeployedModelRefResponseArrayOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1DeployedModelResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1DeployedModelResponseArrayOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1DiskSpecOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1DiskSpecPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1DiskSpecResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1EncryptionSpecOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1EncryptionSpecPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1EncryptionSpecResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1EnvVarOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1EnvVarArrayOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1EnvVarResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1EnvVarResponseArrayOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ExamplesOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ExamplesPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ExamplesExampleGcsSourceOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ExamplesExampleGcsSourcePtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ExamplesExampleGcsSourceResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ExamplesResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ExecutionResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ExplanationMetadataOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ExplanationMetadataPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ExplanationMetadataInputMetadataOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ExplanationMetadataInputMetadataMapOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomainResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ExplanationMetadataInputMetadataResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ExplanationMetadataInputMetadataResponseMapOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualizationResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ExplanationMetadataOutputMetadataOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ExplanationMetadataOutputMetadataMapOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ExplanationMetadataOutputMetadataResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ExplanationMetadataOutputMetadataResponseMapOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ExplanationMetadataResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ExplanationParametersOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ExplanationParametersPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ExplanationParametersResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ExplanationSpecOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ExplanationSpecPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ExplanationSpecResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1FeatureGroupBigQueryOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1FeatureGroupBigQueryPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1FeatureGroupBigQueryResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1FeatureMonitoringStatsAnomalyResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1FeatureMonitoringStatsAnomalyResponseArrayOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1FeatureNoiseSigmaOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1FeatureNoiseSigmaPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureArrayOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1FeatureNoiseSigmaNoiseSigmaForFeatureResponseArrayOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1FeatureNoiseSigmaResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1FeatureOnlineStoreBigtableOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1FeatureOnlineStoreBigtablePtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1FeatureOnlineStoreBigtableAutoScalingResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1FeatureOnlineStoreBigtableResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1FeatureStatsAnomalyResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1FeatureViewBigQuerySourceOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1FeatureViewBigQuerySourcePtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1FeatureViewBigQuerySourceResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourcePtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupArrayOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceFeatureGroupResponseArrayOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1FeatureViewFeatureRegistrySourceResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1FeatureViewSyncConfigOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1FeatureViewSyncConfigPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1FeatureViewSyncConfigResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1FeaturestoreMonitoringConfigOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1FeaturestoreMonitoringConfigPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1FeaturestoreMonitoringConfigImportFeaturesAnalysisResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1FeaturestoreMonitoringConfigResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1FeaturestoreMonitoringConfigSnapshotAnalysisResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1FeaturestoreMonitoringConfigThresholdConfigResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1FeaturestoreOnlineServingConfigScalingResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1FilterSplitOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1FilterSplitPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1FilterSplitResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1FractionSplitOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1FractionSplitPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1FractionSplitResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1GcsDestinationOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1GcsDestinationPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1GcsDestinationResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1GcsSourceOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1GcsSourcePtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1GcsSourceResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1IndexPrivateEndpointsResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1IndexStatsResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1InputDataConfigOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1InputDataConfigPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1InputDataConfigResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1IntegratedGradientsAttributionOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1IntegratedGradientsAttributionPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1IntegratedGradientsAttributionResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1MachineSpecOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1MachineSpecPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1MachineSpecResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ManualBatchTuningParametersOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ManualBatchTuningParametersPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ManualBatchTuningParametersResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1MeasurementMetricResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1MeasurementMetricResponseArrayOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1MeasurementResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1MeasurementResponseArrayOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1MetadataStoreMetadataStoreStateResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ModelOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ModelPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ModelContainerSpecOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ModelContainerSpecPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ModelContainerSpecResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ModelDeploymentMonitoringBigQueryTableResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ModelDeploymentMonitoringBigQueryTableResponseArrayOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ModelDeploymentMonitoringJobLatestMonitoringPipelineMetadataResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigArrayOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ModelDeploymentMonitoringObjectiveConfigResponseArrayOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ModelDeploymentMonitoringScheduleConfigOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ModelDeploymentMonitoringScheduleConfigResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ModelExportFormatResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ModelExportFormatResponseArrayOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ModelMonitoringAlertConfigOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ModelMonitoringAlertConfigPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ModelMonitoringAlertConfigEmailAlertConfigResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ModelMonitoringAlertConfigResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselinePtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigExplanationBaselineResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigExplanationConfigResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigPredictionDriftDetectionConfigResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingDatasetResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ModelMonitoringObjectiveConfigTrainingPredictionSkewDetectionConfigResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ModelOriginalModelInfoResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ModelResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ModelSourceInfoResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1NasJobOutputMultiTrialJobOutputResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1NasJobOutputResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1NasJobSpecOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecMetricSpecResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecSearchTrialSpecResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1NasJobSpecMultiTrialAlgorithmSpecTrainTrialSpecResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1NasJobSpecResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1NasTrialResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1NasTrialResponseArrayOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1NetworkSpecOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1NetworkSpecPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1NetworkSpecResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1NfsMountOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1NfsMountArrayOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1NfsMountResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1NfsMountResponseArrayOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1NotebookEucConfigOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1NotebookEucConfigPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1NotebookEucConfigResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1NotebookIdleShutdownConfigOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1NotebookIdleShutdownConfigPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1NotebookIdleShutdownConfigResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1PersistentDiskSpecOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1PersistentDiskSpecPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1PersistentDiskSpecResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1PipelineJobOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1PipelineJobPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1PipelineJobDetailResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1PipelineJobResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1PipelineJobRuntimeConfigOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1PipelineJobRuntimeConfigPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactMapOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifactResponseMapOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1PipelineJobRuntimeConfigResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1PipelineTaskDetailArtifactListResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1PipelineTaskDetailArtifactListResponseMapOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1PipelineTaskDetailPipelineTaskStatusResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1PipelineTaskDetailPipelineTaskStatusResponseArrayOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1PipelineTaskDetailResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1PipelineTaskDetailResponseArrayOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1PipelineTaskExecutorDetailContainerDetailResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1PipelineTaskExecutorDetailCustomJobDetailResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1PipelineTaskExecutorDetailResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1PipelineTemplateMetadataResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1PortOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1PortArrayOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1PortResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1PortResponseArrayOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1PredefinedSplitOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1PredefinedSplitPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1PredefinedSplitResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1PredictRequestResponseLoggingConfigOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1PredictRequestResponseLoggingConfigPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1PredictRequestResponseLoggingConfigResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1PredictSchemataOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1PredictSchemataPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1PredictSchemataResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1PresetsOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1PresetsPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1PresetsResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1PrivateEndpointsResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1PrivateServiceConnectConfigOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1PrivateServiceConnectConfigPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1PrivateServiceConnectConfigResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ProbeOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ProbePtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ProbeExecActionOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ProbeExecActionPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ProbeExecActionResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ProbeResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1PythonPackageSpecOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1PythonPackageSpecPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1PythonPackageSpecResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ResourcesConsumedResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1SampleConfigOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1SampleConfigPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1SampleConfigResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1SampledShapleyAttributionOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1SampledShapleyAttributionPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1SampledShapleyAttributionResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1SamplingStrategyOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1SamplingStrategyPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1SamplingStrategyRandomSampleConfigResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1SamplingStrategyResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1SavedQueryOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1SavedQueryArrayOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1SavedQueryResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1SavedQueryResponseArrayOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ScheduleRunResponseResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1SchedulingOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1SchedulingPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1SchedulingResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1SmoothGradConfigOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1SmoothGradConfigPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1SmoothGradConfigResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1StratifiedSplitOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1StratifiedSplitPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1StratifiedSplitResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1StudySpecOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1StudySpecConvexAutomatedStoppingSpecResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1StudySpecDecayCurveAutomatedStoppingSpecResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1StudySpecMedianAutomatedStoppingSpecResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1StudySpecMetricSpecOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1StudySpecMetricSpecArrayOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1StudySpecMetricSpecResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1StudySpecMetricSpecResponseArrayOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1StudySpecMetricSpecSafetyMetricConfigResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1StudySpecParameterSpecOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1StudySpecParameterSpecArrayOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1StudySpecParameterSpecCategoricalValueSpecResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecArrayOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecCategoricalValueConditionResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecDiscreteValueConditionResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecIntValueConditionResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1StudySpecParameterSpecConditionalParameterSpecResponseArrayOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1StudySpecParameterSpecDiscreteValueSpecResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1StudySpecParameterSpecDoubleValueSpecResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1StudySpecParameterSpecIntegerValueSpecResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1StudySpecParameterSpecResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1StudySpecParameterSpecResponseArrayOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1StudySpecResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1StudySpecStudyStoppingConfigOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1StudySpecStudyStoppingConfigPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1StudySpecStudyStoppingConfigResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1StudyTimeConstraintOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1StudyTimeConstraintPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1StudyTimeConstraintResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1TensorboardTimeSeriesMetadataResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ThresholdConfigOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ThresholdConfigPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ThresholdConfigMapOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ThresholdConfigResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ThresholdConfigResponseMapOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1TimestampSplitOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1TimestampSplitPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1TimestampSplitResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1TrainingConfigOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1TrainingConfigPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1TrainingConfigResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1TrialParameterResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1TrialParameterResponseArrayOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1TrialResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1TrialResponseArrayOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1UnmanagedContainerModelOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1UnmanagedContainerModelPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1UnmanagedContainerModelResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ValueOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ValueMapOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ValueResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1ValueResponseMapOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1WorkerPoolSpecOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1WorkerPoolSpecArrayOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1WorkerPoolSpecResponseOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1WorkerPoolSpecResponseArrayOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1XraiAttributionOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1XraiAttributionPtrOutput{})
	pulumi.RegisterOutputType(GoogleCloudAiplatformV1XraiAttributionResponseOutput{})
	pulumi.RegisterOutputType(GoogleIamV1BindingOutput{})
	pulumi.RegisterOutputType(GoogleIamV1BindingArrayOutput{})
	pulumi.RegisterOutputType(GoogleIamV1BindingResponseOutput{})
	pulumi.RegisterOutputType(GoogleIamV1BindingResponseArrayOutput{})
	pulumi.RegisterOutputType(GoogleRpcStatusResponseOutput{})
	pulumi.RegisterOutputType(GoogleRpcStatusResponseArrayOutput{})
	pulumi.RegisterOutputType(GoogleTypeExprOutput{})
	pulumi.RegisterOutputType(GoogleTypeExprPtrOutput{})
	pulumi.RegisterOutputType(GoogleTypeExprResponseOutput{})
	pulumi.RegisterOutputType(GoogleTypeMoneyResponseOutput{})
}
